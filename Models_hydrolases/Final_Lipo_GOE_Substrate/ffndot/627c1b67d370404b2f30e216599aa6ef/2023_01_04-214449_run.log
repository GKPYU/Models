2023-01-04 21:45:05,364 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffndot/627c1b67d370404b2f30e216599aa6ef/2023_01_04-214449",
  "seed": 1,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "morgan1024",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffndot",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.95,
  "val_size": 0.05,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.00015553873022161447,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 5,
  "hidden_size": 30,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2023-01-04 21:45:05,373 INFO: Starting stage: BUILD FEATURIZERS
2023-01-04 21:45:05,376 INFO:   Creating esm representation model
2023-01-04 21:45:05,376 INFO:   Done esm representation model
2023-01-04 21:45:05,376 INFO: Done with stage: BUILD FEATURIZERS
2023-01-04 21:45:05,376 INFO: Starting stage: BUILDING DATASET
2023-01-04 21:45:05,431 INFO: Done with stage: BUILDING DATASET
2023-01-04 21:45:05,432 INFO: Starting stage: FEATURIZING DATA
2023-01-04 21:45:05,432 INFO:   Featurizing proteins
2023-01-04 21:45:05,434 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2023-01-04 21:45:05,469 INFO:   Loaded feature cache of size 489
2023-01-04 21:45:05,470 INFO:   Starting to pool ESM Embeddings
2023-01-04 21:45:05,604 INFO:   Featurizing molecules
2023-01-04 21:45:05,606 INFO:   Loading cache file data/program_cache/739a0d20a6c75d701bd3663cec254635
2023-01-04 21:45:05,608 INFO:   Loaded feature cache of size 498
2023-01-04 21:45:06,953 INFO: Done with stage: FEATURIZING DATA
2023-01-04 21:45:06,954 INFO: Starting stage: RUNNING SPLITS
2023-01-04 21:45:06,962 INFO:   Leaving out SEQ value Fold_0
2023-01-04 21:45:06,976 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 21:45:06,976 INFO:   Starting stage: FEATURE SCALING
2023-01-04 21:45:07,702 INFO:   Done with stage: FEATURE SCALING
2023-01-04 21:45:07,702 INFO:   Starting stage: SCALING TARGETS
2023-01-04 21:45:07,771 INFO:   Done with stage: SCALING TARGETS
2023-01-04 21:45:07,771 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 21:45:07,771 INFO:     No hyperparam tuning for this model
2023-01-04 21:45:07,771 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 21:45:07,771 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 21:45:07,772 INFO:     None feature selector for col prot
2023-01-04 21:45:07,772 INFO:     None feature selector for col prot
2023-01-04 21:45:07,772 INFO:     None feature selector for col prot
2023-01-04 21:45:07,772 INFO:     None feature selector for col chem
2023-01-04 21:45:07,773 INFO:     None feature selector for col chem
2023-01-04 21:45:07,773 INFO:     None feature selector for col chem
2023-01-04 21:45:07,773 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 21:45:07,773 INFO:   Starting stage: BUILD MODEL
2023-01-04 21:45:07,774 INFO:     Number of params in model 72931
2023-01-04 21:45:07,774 INFO:   Done with stage: BUILD MODEL
2023-01-04 21:45:07,774 INFO:   Starting stage: TRAINING
2023-01-04 21:45:09,437 INFO:     Val loss before train {'Reaction outcome loss': 0.9742656071980794, 'Total loss': 0.9742656071980794}
2023-01-04 21:45:09,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:09,438 INFO:     Epoch: 0
2023-01-04 21:45:11,593 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7773428479830424, 'Total loss': 0.7773428479830424} | train loss {'Reaction outcome loss': 0.9832502664663852, 'Total loss': 0.9832502664663852}
2023-01-04 21:45:11,593 INFO:     Found new best model at epoch 0
2023-01-04 21:45:11,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:11,595 INFO:     Epoch: 1
2023-01-04 21:45:13,770 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.534784056742986, 'Total loss': 0.534784056742986} | train loss {'Reaction outcome loss': 0.6976346645381425, 'Total loss': 0.6976346645381425}
2023-01-04 21:45:13,770 INFO:     Found new best model at epoch 1
2023-01-04 21:45:13,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:13,771 INFO:     Epoch: 2
2023-01-04 21:45:15,970 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5036932488282522, 'Total loss': 0.5036932488282522} | train loss {'Reaction outcome loss': 0.5377512339625384, 'Total loss': 0.5377512339625384}
2023-01-04 21:45:15,971 INFO:     Found new best model at epoch 2
2023-01-04 21:45:15,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:15,973 INFO:     Epoch: 3
2023-01-04 21:45:18,156 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.513973993062973, 'Total loss': 0.513973993062973} | train loss {'Reaction outcome loss': 0.4894671910630041, 'Total loss': 0.4894671910630041}
2023-01-04 21:45:18,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:18,157 INFO:     Epoch: 4
2023-01-04 21:45:20,347 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47828112840652465, 'Total loss': 0.47828112840652465} | train loss {'Reaction outcome loss': 0.45934003842619314, 'Total loss': 0.45934003842619314}
2023-01-04 21:45:20,348 INFO:     Found new best model at epoch 4
2023-01-04 21:45:20,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:20,349 INFO:     Epoch: 5
2023-01-04 21:45:22,587 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4447463115056356, 'Total loss': 0.4447463115056356} | train loss {'Reaction outcome loss': 0.4399004081612105, 'Total loss': 0.4399004081612105}
2023-01-04 21:45:22,587 INFO:     Found new best model at epoch 5
2023-01-04 21:45:22,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:22,588 INFO:     Epoch: 6
2023-01-04 21:45:24,794 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4633885721365611, 'Total loss': 0.4633885721365611} | train loss {'Reaction outcome loss': 0.41994987499146236, 'Total loss': 0.41994987499146236}
2023-01-04 21:45:24,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:24,794 INFO:     Epoch: 7
2023-01-04 21:45:26,983 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4397425274054209, 'Total loss': 0.4397425274054209} | train loss {'Reaction outcome loss': 0.3999034895565047, 'Total loss': 0.3999034895565047}
2023-01-04 21:45:26,984 INFO:     Found new best model at epoch 7
2023-01-04 21:45:26,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:26,986 INFO:     Epoch: 8
2023-01-04 21:45:29,181 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44655445516109465, 'Total loss': 0.44655445516109465} | train loss {'Reaction outcome loss': 0.3870075853753003, 'Total loss': 0.3870075853753003}
2023-01-04 21:45:29,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:29,181 INFO:     Epoch: 9
2023-01-04 21:45:31,375 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4428294400374095, 'Total loss': 0.4428294400374095} | train loss {'Reaction outcome loss': 0.37858969420740457, 'Total loss': 0.37858969420740457}
2023-01-04 21:45:31,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:31,375 INFO:     Epoch: 10
2023-01-04 21:45:33,385 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43655184507369993, 'Total loss': 0.43655184507369993} | train loss {'Reaction outcome loss': 0.36494388780641907, 'Total loss': 0.36494388780641907}
2023-01-04 21:45:33,386 INFO:     Found new best model at epoch 10
2023-01-04 21:45:33,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:33,388 INFO:     Epoch: 11
2023-01-04 21:45:35,531 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4521511991818746, 'Total loss': 0.4521511991818746} | train loss {'Reaction outcome loss': 0.356553132553677, 'Total loss': 0.356553132553677}
2023-01-04 21:45:35,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:35,532 INFO:     Epoch: 12
2023-01-04 21:45:37,668 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44740523099899293, 'Total loss': 0.44740523099899293} | train loss {'Reaction outcome loss': 0.3469716793833635, 'Total loss': 0.3469716793833635}
2023-01-04 21:45:37,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:37,669 INFO:     Epoch: 13
2023-01-04 21:45:39,889 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4198071445027987, 'Total loss': 0.4198071445027987} | train loss {'Reaction outcome loss': 0.3385162435390137, 'Total loss': 0.3385162435390137}
2023-01-04 21:45:39,890 INFO:     Found new best model at epoch 13
2023-01-04 21:45:39,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:39,891 INFO:     Epoch: 14
2023-01-04 21:45:42,057 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43347483277320864, 'Total loss': 0.43347483277320864} | train loss {'Reaction outcome loss': 0.33290521028168474, 'Total loss': 0.33290521028168474}
2023-01-04 21:45:42,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:42,057 INFO:     Epoch: 15
2023-01-04 21:45:44,246 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.424884424606959, 'Total loss': 0.424884424606959} | train loss {'Reaction outcome loss': 0.3250578185031702, 'Total loss': 0.3250578185031702}
2023-01-04 21:45:44,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:44,246 INFO:     Epoch: 16
2023-01-04 21:45:46,457 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43511636555194855, 'Total loss': 0.43511636555194855} | train loss {'Reaction outcome loss': 0.31656880594871856, 'Total loss': 0.31656880594871856}
2023-01-04 21:45:46,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:46,458 INFO:     Epoch: 17
2023-01-04 21:45:48,664 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44787209033966063, 'Total loss': 0.44787209033966063} | train loss {'Reaction outcome loss': 0.31068052496119736, 'Total loss': 0.31068052496119736}
2023-01-04 21:45:48,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:48,664 INFO:     Epoch: 18
2023-01-04 21:45:50,856 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4440043399731318, 'Total loss': 0.4440043399731318} | train loss {'Reaction outcome loss': 0.3066234953305769, 'Total loss': 0.3066234953305769}
2023-01-04 21:45:50,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:50,856 INFO:     Epoch: 19
2023-01-04 21:45:53,069 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43463019728660585, 'Total loss': 0.43463019728660585} | train loss {'Reaction outcome loss': 0.29693101369690544, 'Total loss': 0.29693101369690544}
2023-01-04 21:45:53,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:53,070 INFO:     Epoch: 20
2023-01-04 21:45:55,279 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4414016882578532, 'Total loss': 0.4414016882578532} | train loss {'Reaction outcome loss': 0.2972153934749055, 'Total loss': 0.2972153934749055}
2023-01-04 21:45:55,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:55,280 INFO:     Epoch: 21
2023-01-04 21:45:57,442 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4516710738341014, 'Total loss': 0.4516710738341014} | train loss {'Reaction outcome loss': 0.2892924593215733, 'Total loss': 0.2892924593215733}
2023-01-04 21:45:57,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:57,443 INFO:     Epoch: 22
2023-01-04 21:45:59,609 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4330263465642929, 'Total loss': 0.4330263465642929} | train loss {'Reaction outcome loss': 0.28472549697527516, 'Total loss': 0.28472549697527516}
2023-01-04 21:45:59,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:45:59,610 INFO:     Epoch: 23
2023-01-04 21:46:01,766 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46065745850404105, 'Total loss': 0.46065745850404105} | train loss {'Reaction outcome loss': 0.28288898724489486, 'Total loss': 0.28288898724489486}
2023-01-04 21:46:01,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:01,766 INFO:     Epoch: 24
2023-01-04 21:46:03,939 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4710506483912468, 'Total loss': 0.4710506483912468} | train loss {'Reaction outcome loss': 0.2755556116392324, 'Total loss': 0.2755556116392324}
2023-01-04 21:46:03,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:03,941 INFO:     Epoch: 25
2023-01-04 21:46:06,106 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4284579465786616, 'Total loss': 0.4284579465786616} | train loss {'Reaction outcome loss': 0.2709285525038784, 'Total loss': 0.2709285525038784}
2023-01-04 21:46:06,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:06,106 INFO:     Epoch: 26
2023-01-04 21:46:08,273 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43276643455028535, 'Total loss': 0.43276643455028535} | train loss {'Reaction outcome loss': 0.2631249449355698, 'Total loss': 0.2631249449355698}
2023-01-04 21:46:08,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:08,274 INFO:     Epoch: 27
2023-01-04 21:46:10,440 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45270642439524333, 'Total loss': 0.45270642439524333} | train loss {'Reaction outcome loss': 0.262592614358871, 'Total loss': 0.262592614358871}
2023-01-04 21:46:10,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:10,441 INFO:     Epoch: 28
2023-01-04 21:46:12,610 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43264010548591614, 'Total loss': 0.43264010548591614} | train loss {'Reaction outcome loss': 0.25587240250392274, 'Total loss': 0.25587240250392274}
2023-01-04 21:46:12,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:12,610 INFO:     Epoch: 29
2023-01-04 21:46:14,767 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43377132415771485, 'Total loss': 0.43377132415771485} | train loss {'Reaction outcome loss': 0.2529371497067776, 'Total loss': 0.2529371497067776}
2023-01-04 21:46:14,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:14,768 INFO:     Epoch: 30
2023-01-04 21:46:16,944 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4143205647667249, 'Total loss': 0.4143205647667249} | train loss {'Reaction outcome loss': 0.25258416277202933, 'Total loss': 0.25258416277202933}
2023-01-04 21:46:16,945 INFO:     Found new best model at epoch 30
2023-01-04 21:46:16,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:16,946 INFO:     Epoch: 31
2023-01-04 21:46:19,114 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4461119691530863, 'Total loss': 0.4461119691530863} | train loss {'Reaction outcome loss': 0.2472285990374702, 'Total loss': 0.2472285990374702}
2023-01-04 21:46:19,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:19,114 INFO:     Epoch: 32
2023-01-04 21:46:21,314 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.452156404654185, 'Total loss': 0.452156404654185} | train loss {'Reaction outcome loss': 0.25194836433826784, 'Total loss': 0.25194836433826784}
2023-01-04 21:46:21,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:21,315 INFO:     Epoch: 33
2023-01-04 21:46:23,510 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4448208034038544, 'Total loss': 0.4448208034038544} | train loss {'Reaction outcome loss': 0.2485534901945637, 'Total loss': 0.2485534901945637}
2023-01-04 21:46:23,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:23,510 INFO:     Epoch: 34
2023-01-04 21:46:25,513 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4279872258504232, 'Total loss': 0.4279872258504232} | train loss {'Reaction outcome loss': 0.244353522154274, 'Total loss': 0.244353522154274}
2023-01-04 21:46:25,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:25,514 INFO:     Epoch: 35
2023-01-04 21:46:27,328 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4434766228000323, 'Total loss': 0.4434766228000323} | train loss {'Reaction outcome loss': 0.2411745035741137, 'Total loss': 0.2411745035741137}
2023-01-04 21:46:27,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:27,329 INFO:     Epoch: 36
2023-01-04 21:46:29,266 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4601392686367035, 'Total loss': 0.4601392686367035} | train loss {'Reaction outcome loss': 0.23723493128223516, 'Total loss': 0.23723493128223516}
2023-01-04 21:46:29,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:29,266 INFO:     Epoch: 37
2023-01-04 21:46:31,475 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4682082662979762, 'Total loss': 0.4682082662979762} | train loss {'Reaction outcome loss': 0.23437296119160378, 'Total loss': 0.23437296119160378}
2023-01-04 21:46:31,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:31,475 INFO:     Epoch: 38
2023-01-04 21:46:33,660 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4586599498987198, 'Total loss': 0.4586599498987198} | train loss {'Reaction outcome loss': 0.23410728053895982, 'Total loss': 0.23410728053895982}
2023-01-04 21:46:33,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:33,661 INFO:     Epoch: 39
2023-01-04 21:46:35,849 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4469635953505834, 'Total loss': 0.4469635953505834} | train loss {'Reaction outcome loss': 0.23219701355057104, 'Total loss': 0.23219701355057104}
2023-01-04 21:46:35,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:35,849 INFO:     Epoch: 40
2023-01-04 21:46:38,075 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45448044935862225, 'Total loss': 0.45448044935862225} | train loss {'Reaction outcome loss': 0.23239951760204502, 'Total loss': 0.23239951760204502}
2023-01-04 21:46:38,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:38,076 INFO:     Epoch: 41
2023-01-04 21:46:40,247 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47809735337893167, 'Total loss': 0.47809735337893167} | train loss {'Reaction outcome loss': 0.23181200976527871, 'Total loss': 0.23181200976527871}
2023-01-04 21:46:40,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:40,248 INFO:     Epoch: 42
2023-01-04 21:46:42,414 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4181368256608645, 'Total loss': 0.4181368256608645} | train loss {'Reaction outcome loss': 0.22926222648976485, 'Total loss': 0.22926222648976485}
2023-01-04 21:46:42,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:42,414 INFO:     Epoch: 43
2023-01-04 21:46:44,584 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47643662095069883, 'Total loss': 0.47643662095069883} | train loss {'Reaction outcome loss': 0.22687315374558226, 'Total loss': 0.22687315374558226}
2023-01-04 21:46:44,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:44,585 INFO:     Epoch: 44
2023-01-04 21:46:46,759 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4346949448188146, 'Total loss': 0.4346949448188146} | train loss {'Reaction outcome loss': 0.22359284663047546, 'Total loss': 0.22359284663047546}
2023-01-04 21:46:46,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:46,760 INFO:     Epoch: 45
2023-01-04 21:46:48,935 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4198638752102852, 'Total loss': 0.4198638752102852} | train loss {'Reaction outcome loss': 0.22268195216281292, 'Total loss': 0.22268195216281292}
2023-01-04 21:46:48,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:48,935 INFO:     Epoch: 46
2023-01-04 21:46:51,124 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4580903867880503, 'Total loss': 0.4580903867880503} | train loss {'Reaction outcome loss': 0.21786408456581416, 'Total loss': 0.21786408456581416}
2023-01-04 21:46:51,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:51,126 INFO:     Epoch: 47
2023-01-04 21:46:53,280 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4555872559547424, 'Total loss': 0.4555872559547424} | train loss {'Reaction outcome loss': 0.21608740604745272, 'Total loss': 0.21608740604745272}
2023-01-04 21:46:53,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:53,280 INFO:     Epoch: 48
2023-01-04 21:46:55,445 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40824919790029524, 'Total loss': 0.40824919790029524} | train loss {'Reaction outcome loss': 0.21468506937662324, 'Total loss': 0.21468506937662324}
2023-01-04 21:46:55,445 INFO:     Found new best model at epoch 48
2023-01-04 21:46:55,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:55,446 INFO:     Epoch: 49
2023-01-04 21:46:57,633 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4383139193058014, 'Total loss': 0.4383139193058014} | train loss {'Reaction outcome loss': 0.21611742571596698, 'Total loss': 0.21611742571596698}
2023-01-04 21:46:57,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:57,634 INFO:     Epoch: 50
2023-01-04 21:46:59,811 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43672769218683244, 'Total loss': 0.43672769218683244} | train loss {'Reaction outcome loss': 0.21439502721195255, 'Total loss': 0.21439502721195255}
2023-01-04 21:46:59,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:46:59,811 INFO:     Epoch: 51
2023-01-04 21:47:02,001 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4259717623392741, 'Total loss': 0.4259717623392741} | train loss {'Reaction outcome loss': 0.2132643947698476, 'Total loss': 0.2132643947698476}
2023-01-04 21:47:02,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:02,003 INFO:     Epoch: 52
2023-01-04 21:47:04,161 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4634872004389763, 'Total loss': 0.4634872004389763} | train loss {'Reaction outcome loss': 0.21244027970133575, 'Total loss': 0.21244027970133575}
2023-01-04 21:47:04,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:04,162 INFO:     Epoch: 53
2023-01-04 21:47:06,343 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44697028001149497, 'Total loss': 0.44697028001149497} | train loss {'Reaction outcome loss': 0.21181328622658394, 'Total loss': 0.21181328622658394}
2023-01-04 21:47:06,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:06,344 INFO:     Epoch: 54
2023-01-04 21:47:08,502 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44837987224260967, 'Total loss': 0.44837987224260967} | train loss {'Reaction outcome loss': 0.21273519148565692, 'Total loss': 0.21273519148565692}
2023-01-04 21:47:08,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:08,503 INFO:     Epoch: 55
2023-01-04 21:47:10,673 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45139593283335366, 'Total loss': 0.45139593283335366} | train loss {'Reaction outcome loss': 0.20580822255141734, 'Total loss': 0.20580822255141734}
2023-01-04 21:47:10,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:10,673 INFO:     Epoch: 56
2023-01-04 21:47:12,864 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45803378988057375, 'Total loss': 0.45803378988057375} | train loss {'Reaction outcome loss': 0.2071291302627587, 'Total loss': 0.2071291302627587}
2023-01-04 21:47:12,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:12,865 INFO:     Epoch: 57
2023-01-04 21:47:15,128 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4266017893950144, 'Total loss': 0.4266017893950144} | train loss {'Reaction outcome loss': 0.20364589420157475, 'Total loss': 0.20364589420157475}
2023-01-04 21:47:15,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:15,128 INFO:     Epoch: 58
2023-01-04 21:47:17,314 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.428386319677035, 'Total loss': 0.428386319677035} | train loss {'Reaction outcome loss': 0.2060503942803258, 'Total loss': 0.2060503942803258}
2023-01-04 21:47:17,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:17,314 INFO:     Epoch: 59
2023-01-04 21:47:19,452 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42004815886418023, 'Total loss': 0.42004815886418023} | train loss {'Reaction outcome loss': 0.19995938323356294, 'Total loss': 0.19995938323356294}
2023-01-04 21:47:19,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:19,453 INFO:     Epoch: 60
2023-01-04 21:47:21,616 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41396943971825145, 'Total loss': 0.41396943971825145} | train loss {'Reaction outcome loss': 0.20340481116317022, 'Total loss': 0.20340481116317022}
2023-01-04 21:47:21,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:21,616 INFO:     Epoch: 61
2023-01-04 21:47:23,799 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4373121743400892, 'Total loss': 0.4373121743400892} | train loss {'Reaction outcome loss': 0.2046775604417418, 'Total loss': 0.2046775604417418}
2023-01-04 21:47:23,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:23,801 INFO:     Epoch: 62
2023-01-04 21:47:25,959 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42947807361682255, 'Total loss': 0.42947807361682255} | train loss {'Reaction outcome loss': 0.19988474610769924, 'Total loss': 0.19988474610769924}
2023-01-04 21:47:25,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:25,960 INFO:     Epoch: 63
2023-01-04 21:47:28,160 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4362509921193123, 'Total loss': 0.4362509921193123} | train loss {'Reaction outcome loss': 0.19673114763265784, 'Total loss': 0.19673114763265784}
2023-01-04 21:47:28,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:28,160 INFO:     Epoch: 64
2023-01-04 21:47:30,398 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4353390314771483, 'Total loss': 0.4353390314771483} | train loss {'Reaction outcome loss': 0.1997098740388131, 'Total loss': 0.1997098740388131}
2023-01-04 21:47:30,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:30,400 INFO:     Epoch: 65
2023-01-04 21:47:32,630 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44465087552865346, 'Total loss': 0.44465087552865346} | train loss {'Reaction outcome loss': 0.1974415420162263, 'Total loss': 0.1974415420162263}
2023-01-04 21:47:32,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:32,630 INFO:     Epoch: 66
2023-01-04 21:47:34,851 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4581747924288114, 'Total loss': 0.4581747924288114} | train loss {'Reaction outcome loss': 0.19559779962790863, 'Total loss': 0.19559779962790863}
2023-01-04 21:47:34,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:34,852 INFO:     Epoch: 67
2023-01-04 21:47:37,096 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4611385335524877, 'Total loss': 0.4611385335524877} | train loss {'Reaction outcome loss': 0.19346336580577542, 'Total loss': 0.19346336580577542}
2023-01-04 21:47:37,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:37,097 INFO:     Epoch: 68
2023-01-04 21:47:39,326 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4234382450580597, 'Total loss': 0.4234382450580597} | train loss {'Reaction outcome loss': 0.19870046697277235, 'Total loss': 0.19870046697277235}
2023-01-04 21:47:39,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:39,327 INFO:     Epoch: 69
2023-01-04 21:47:41,593 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44405469397703806, 'Total loss': 0.44405469397703806} | train loss {'Reaction outcome loss': 0.19337360965831704, 'Total loss': 0.19337360965831704}
2023-01-04 21:47:41,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:41,595 INFO:     Epoch: 70
2023-01-04 21:47:43,803 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46970268338918686, 'Total loss': 0.46970268338918686} | train loss {'Reaction outcome loss': 0.19697221631573125, 'Total loss': 0.19697221631573125}
2023-01-04 21:47:43,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:43,803 INFO:     Epoch: 71
2023-01-04 21:47:46,012 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.441917289296786, 'Total loss': 0.441917289296786} | train loss {'Reaction outcome loss': 0.18792729426325458, 'Total loss': 0.18792729426325458}
2023-01-04 21:47:46,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:46,012 INFO:     Epoch: 72
2023-01-04 21:47:48,224 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4748457024494807, 'Total loss': 0.4748457024494807} | train loss {'Reaction outcome loss': 0.18529813147521826, 'Total loss': 0.18529813147521826}
2023-01-04 21:47:48,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:48,226 INFO:     Epoch: 73
2023-01-04 21:47:50,413 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4329660993690292, 'Total loss': 0.4329660993690292} | train loss {'Reaction outcome loss': 0.18790142653226824, 'Total loss': 0.18790142653226824}
2023-01-04 21:47:50,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:50,413 INFO:     Epoch: 74
2023-01-04 21:47:52,634 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4683156987031301, 'Total loss': 0.4683156987031301} | train loss {'Reaction outcome loss': 0.1900614635377522, 'Total loss': 0.1900614635377522}
2023-01-04 21:47:52,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:52,635 INFO:     Epoch: 75
2023-01-04 21:47:54,857 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4354841207464536, 'Total loss': 0.4354841207464536} | train loss {'Reaction outcome loss': 0.18961266948305916, 'Total loss': 0.18961266948305916}
2023-01-04 21:47:54,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:54,857 INFO:     Epoch: 76
2023-01-04 21:47:57,054 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45733074347178143, 'Total loss': 0.45733074347178143} | train loss {'Reaction outcome loss': 0.18348083682290037, 'Total loss': 0.18348083682290037}
2023-01-04 21:47:57,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:57,054 INFO:     Epoch: 77
2023-01-04 21:47:59,245 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47190687457720437, 'Total loss': 0.47190687457720437} | train loss {'Reaction outcome loss': 0.18951133725612046, 'Total loss': 0.18951133725612046}
2023-01-04 21:47:59,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:47:59,247 INFO:     Epoch: 78
2023-01-04 21:48:01,413 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4440357079108556, 'Total loss': 0.4440357079108556} | train loss {'Reaction outcome loss': 0.1859041332939278, 'Total loss': 0.1859041332939278}
2023-01-04 21:48:01,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:01,413 INFO:     Epoch: 79
2023-01-04 21:48:03,604 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4591313570737839, 'Total loss': 0.4591313570737839} | train loss {'Reaction outcome loss': 0.18522418149484274, 'Total loss': 0.18522418149484274}
2023-01-04 21:48:03,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:03,604 INFO:     Epoch: 80
2023-01-04 21:48:05,784 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42512091199556984, 'Total loss': 0.42512091199556984} | train loss {'Reaction outcome loss': 0.1870015770838265, 'Total loss': 0.1870015770838265}
2023-01-04 21:48:05,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:05,785 INFO:     Epoch: 81
2023-01-04 21:48:07,980 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5113662461439769, 'Total loss': 0.5113662461439769} | train loss {'Reaction outcome loss': 0.1842031452238505, 'Total loss': 0.1842031452238505}
2023-01-04 21:48:07,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:07,980 INFO:     Epoch: 82
2023-01-04 21:48:10,173 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46468490567058324, 'Total loss': 0.46468490567058324} | train loss {'Reaction outcome loss': 0.1813074526250799, 'Total loss': 0.1813074526250799}
2023-01-04 21:48:10,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:10,173 INFO:     Epoch: 83
2023-01-04 21:48:12,348 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45484178761641186, 'Total loss': 0.45484178761641186} | train loss {'Reaction outcome loss': 0.18317868972313164, 'Total loss': 0.18317868972313164}
2023-01-04 21:48:12,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:12,349 INFO:     Epoch: 84
2023-01-04 21:48:14,507 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4644782940546672, 'Total loss': 0.4644782940546672} | train loss {'Reaction outcome loss': 0.18128737248309748, 'Total loss': 0.18128737248309748}
2023-01-04 21:48:14,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:14,507 INFO:     Epoch: 85
2023-01-04 21:48:16,693 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46594676474730173, 'Total loss': 0.46594676474730173} | train loss {'Reaction outcome loss': 0.18136323286363712, 'Total loss': 0.18136323286363712}
2023-01-04 21:48:16,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:16,694 INFO:     Epoch: 86
2023-01-04 21:48:18,869 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4547899215482175, 'Total loss': 0.4547899215482175} | train loss {'Reaction outcome loss': 0.18635090555733022, 'Total loss': 0.18635090555733022}
2023-01-04 21:48:18,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:18,870 INFO:     Epoch: 87
2023-01-04 21:48:21,047 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5144495585312446, 'Total loss': 0.5144495585312446} | train loss {'Reaction outcome loss': 0.17940077845061764, 'Total loss': 0.17940077845061764}
2023-01-04 21:48:21,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:21,048 INFO:     Epoch: 88
2023-01-04 21:48:23,216 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.487494166692098, 'Total loss': 0.487494166692098} | train loss {'Reaction outcome loss': 0.1769991233022099, 'Total loss': 0.1769991233022099}
2023-01-04 21:48:23,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:23,217 INFO:     Epoch: 89
2023-01-04 21:48:25,393 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4419572023053964, 'Total loss': 0.4419572023053964} | train loss {'Reaction outcome loss': 0.18081808149568981, 'Total loss': 0.18081808149568981}
2023-01-04 21:48:25,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:25,394 INFO:     Epoch: 90
2023-01-04 21:48:27,582 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4274371492365996, 'Total loss': 0.4274371492365996} | train loss {'Reaction outcome loss': 0.17960577833401414, 'Total loss': 0.17960577833401414}
2023-01-04 21:48:27,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:27,583 INFO:     Epoch: 91
2023-01-04 21:48:29,764 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4847548355658849, 'Total loss': 0.4847548355658849} | train loss {'Reaction outcome loss': 0.17671906930350123, 'Total loss': 0.17671906930350123}
2023-01-04 21:48:29,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:29,765 INFO:     Epoch: 92
2023-01-04 21:48:31,937 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4402494768301646, 'Total loss': 0.4402494768301646} | train loss {'Reaction outcome loss': 0.1780554555687412, 'Total loss': 0.1780554555687412}
2023-01-04 21:48:31,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:31,938 INFO:     Epoch: 93
2023-01-04 21:48:34,096 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46109446982542673, 'Total loss': 0.46109446982542673} | train loss {'Reaction outcome loss': 0.17700511457111973, 'Total loss': 0.17700511457111973}
2023-01-04 21:48:34,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:34,096 INFO:     Epoch: 94
2023-01-04 21:48:36,267 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46639292935530346, 'Total loss': 0.46639292935530346} | train loss {'Reaction outcome loss': 0.1717717032606676, 'Total loss': 0.1717717032606676}
2023-01-04 21:48:36,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:36,269 INFO:     Epoch: 95
2023-01-04 21:48:38,454 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4620660712321599, 'Total loss': 0.4620660712321599} | train loss {'Reaction outcome loss': 0.17256251552002333, 'Total loss': 0.17256251552002333}
2023-01-04 21:48:38,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:38,454 INFO:     Epoch: 96
2023-01-04 21:48:40,627 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4921794633070628, 'Total loss': 0.4921794633070628} | train loss {'Reaction outcome loss': 0.17426060868816062, 'Total loss': 0.17426060868816062}
2023-01-04 21:48:40,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:40,627 INFO:     Epoch: 97
2023-01-04 21:48:42,805 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4565386692682902, 'Total loss': 0.4565386692682902} | train loss {'Reaction outcome loss': 0.17129127424715201, 'Total loss': 0.17129127424715201}
2023-01-04 21:48:42,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:42,806 INFO:     Epoch: 98
2023-01-04 21:48:44,975 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4533577966193358, 'Total loss': 0.4533577966193358} | train loss {'Reaction outcome loss': 0.17261102508016668, 'Total loss': 0.17261102508016668}
2023-01-04 21:48:44,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:44,975 INFO:     Epoch: 99
2023-01-04 21:48:47,154 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4471378979583581, 'Total loss': 0.4471378979583581} | train loss {'Reaction outcome loss': 0.17435846742815697, 'Total loss': 0.17435846742815697}
2023-01-04 21:48:47,155 INFO:     Best model found after epoch 49 of 100.
2023-01-04 21:48:47,155 INFO:   Done with stage: TRAINING
2023-01-04 21:48:47,155 INFO:   Starting stage: EVALUATION
2023-01-04 21:48:47,302 INFO:   Done with stage: EVALUATION
2023-01-04 21:48:47,302 INFO:   Leaving out SEQ value Fold_1
2023-01-04 21:48:47,314 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 21:48:47,315 INFO:   Starting stage: FEATURE SCALING
2023-01-04 21:48:47,981 INFO:   Done with stage: FEATURE SCALING
2023-01-04 21:48:47,981 INFO:   Starting stage: SCALING TARGETS
2023-01-04 21:48:48,053 INFO:   Done with stage: SCALING TARGETS
2023-01-04 21:48:48,053 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 21:48:48,053 INFO:     No hyperparam tuning for this model
2023-01-04 21:48:48,053 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 21:48:48,053 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 21:48:48,054 INFO:     None feature selector for col prot
2023-01-04 21:48:48,054 INFO:     None feature selector for col prot
2023-01-04 21:48:48,054 INFO:     None feature selector for col prot
2023-01-04 21:48:48,054 INFO:     None feature selector for col chem
2023-01-04 21:48:48,054 INFO:     None feature selector for col chem
2023-01-04 21:48:48,054 INFO:     None feature selector for col chem
2023-01-04 21:48:48,055 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 21:48:48,055 INFO:   Starting stage: BUILD MODEL
2023-01-04 21:48:48,056 INFO:     Number of params in model 72931
2023-01-04 21:48:48,059 INFO:   Done with stage: BUILD MODEL
2023-01-04 21:48:48,059 INFO:   Starting stage: TRAINING
2023-01-04 21:48:48,117 INFO:     Val loss before train {'Reaction outcome loss': 1.0153802792231241, 'Total loss': 1.0153802792231241}
2023-01-04 21:48:48,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:48,117 INFO:     Epoch: 0
2023-01-04 21:48:50,312 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7578919907410939, 'Total loss': 0.7578919907410939} | train loss {'Reaction outcome loss': 0.9251616915714913, 'Total loss': 0.9251616915714913}
2023-01-04 21:48:50,312 INFO:     Found new best model at epoch 0
2023-01-04 21:48:50,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:50,313 INFO:     Epoch: 1
2023-01-04 21:48:52,498 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6796245654424031, 'Total loss': 0.6796245654424031} | train loss {'Reaction outcome loss': 0.6344574235912844, 'Total loss': 0.6344574235912844}
2023-01-04 21:48:52,500 INFO:     Found new best model at epoch 1
2023-01-04 21:48:52,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:52,501 INFO:     Epoch: 2
2023-01-04 21:48:54,690 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6418846209843954, 'Total loss': 0.6418846209843954} | train loss {'Reaction outcome loss': 0.5439125979184241, 'Total loss': 0.5439125979184241}
2023-01-04 21:48:54,690 INFO:     Found new best model at epoch 2
2023-01-04 21:48:54,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:54,691 INFO:     Epoch: 3
2023-01-04 21:48:56,888 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6004328697919845, 'Total loss': 0.6004328697919845} | train loss {'Reaction outcome loss': 0.4982457615543103, 'Total loss': 0.4982457615543103}
2023-01-04 21:48:56,888 INFO:     Found new best model at epoch 3
2023-01-04 21:48:56,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:56,889 INFO:     Epoch: 4
2023-01-04 21:48:59,100 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6042738040288289, 'Total loss': 0.6042738040288289} | train loss {'Reaction outcome loss': 0.47412336309966835, 'Total loss': 0.47412336309966835}
2023-01-04 21:48:59,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:48:59,101 INFO:     Epoch: 5
2023-01-04 21:49:01,347 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5552236080169678, 'Total loss': 0.5552236080169678} | train loss {'Reaction outcome loss': 0.4568250246814822, 'Total loss': 0.4568250246814822}
2023-01-04 21:49:01,347 INFO:     Found new best model at epoch 5
2023-01-04 21:49:01,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:01,348 INFO:     Epoch: 6
2023-01-04 21:49:03,590 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5591041465600332, 'Total loss': 0.5591041465600332} | train loss {'Reaction outcome loss': 0.4265060038778229, 'Total loss': 0.4265060038778229}
2023-01-04 21:49:03,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:03,590 INFO:     Epoch: 7
2023-01-04 21:49:05,795 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5607788642247518, 'Total loss': 0.5607788642247518} | train loss {'Reaction outcome loss': 0.41055338170237676, 'Total loss': 0.41055338170237676}
2023-01-04 21:49:05,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:05,796 INFO:     Epoch: 8
2023-01-04 21:49:08,008 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5432291567325592, 'Total loss': 0.5432291567325592} | train loss {'Reaction outcome loss': 0.3967042539747047, 'Total loss': 0.3967042539747047}
2023-01-04 21:49:08,008 INFO:     Found new best model at epoch 8
2023-01-04 21:49:08,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:08,009 INFO:     Epoch: 9
2023-01-04 21:49:10,268 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5341813166936239, 'Total loss': 0.5341813166936239} | train loss {'Reaction outcome loss': 0.3836713184187513, 'Total loss': 0.3836713184187513}
2023-01-04 21:49:10,269 INFO:     Found new best model at epoch 9
2023-01-04 21:49:10,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:10,270 INFO:     Epoch: 10
2023-01-04 21:49:12,457 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5298058052857717, 'Total loss': 0.5298058052857717} | train loss {'Reaction outcome loss': 0.37380408187248354, 'Total loss': 0.37380408187248354}
2023-01-04 21:49:12,457 INFO:     Found new best model at epoch 10
2023-01-04 21:49:12,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:12,459 INFO:     Epoch: 11
2023-01-04 21:49:14,664 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5455507854620616, 'Total loss': 0.5455507854620616} | train loss {'Reaction outcome loss': 0.36749757183850673, 'Total loss': 0.36749757183850673}
2023-01-04 21:49:14,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:14,664 INFO:     Epoch: 12
2023-01-04 21:49:16,697 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5231814503669738, 'Total loss': 0.5231814503669738} | train loss {'Reaction outcome loss': 0.36843010156914807, 'Total loss': 0.36843010156914807}
2023-01-04 21:49:16,699 INFO:     Found new best model at epoch 12
2023-01-04 21:49:16,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:16,700 INFO:     Epoch: 13
2023-01-04 21:49:18,874 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4983401288588842, 'Total loss': 0.4983401288588842} | train loss {'Reaction outcome loss': 0.35954638565148134, 'Total loss': 0.35954638565148134}
2023-01-04 21:49:18,874 INFO:     Found new best model at epoch 13
2023-01-04 21:49:18,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:18,876 INFO:     Epoch: 14
2023-01-04 21:49:21,068 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5159820199012757, 'Total loss': 0.5159820199012757} | train loss {'Reaction outcome loss': 0.3369766602096944, 'Total loss': 0.3369766602096944}
2023-01-04 21:49:21,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:21,070 INFO:     Epoch: 15
2023-01-04 21:49:23,275 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5136188467343649, 'Total loss': 0.5136188467343649} | train loss {'Reaction outcome loss': 0.32949999426275917, 'Total loss': 0.32949999426275917}
2023-01-04 21:49:23,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:23,276 INFO:     Epoch: 16
2023-01-04 21:49:25,506 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5240130325158437, 'Total loss': 0.5240130325158437} | train loss {'Reaction outcome loss': 0.32509410719596443, 'Total loss': 0.32509410719596443}
2023-01-04 21:49:25,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:25,506 INFO:     Epoch: 17
2023-01-04 21:49:27,702 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4981036146481832, 'Total loss': 0.4981036146481832} | train loss {'Reaction outcome loss': 0.3201387406164861, 'Total loss': 0.3201387406164861}
2023-01-04 21:49:27,703 INFO:     Found new best model at epoch 17
2023-01-04 21:49:27,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:27,704 INFO:     Epoch: 18
2023-01-04 21:49:29,878 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5350072701772054, 'Total loss': 0.5350072701772054} | train loss {'Reaction outcome loss': 0.3119411335758649, 'Total loss': 0.3119411335758649}
2023-01-04 21:49:29,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:29,879 INFO:     Epoch: 19
2023-01-04 21:49:32,085 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5021251569191615, 'Total loss': 0.5021251569191615} | train loss {'Reaction outcome loss': 0.3084361886432052, 'Total loss': 0.3084361886432052}
2023-01-04 21:49:32,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:32,086 INFO:     Epoch: 20
2023-01-04 21:49:34,270 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5163996974627177, 'Total loss': 0.5163996974627177} | train loss {'Reaction outcome loss': 0.2993116628360071, 'Total loss': 0.2993116628360071}
2023-01-04 21:49:34,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:34,271 INFO:     Epoch: 21
2023-01-04 21:49:36,470 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5413174043099086, 'Total loss': 0.5413174043099086} | train loss {'Reaction outcome loss': 0.2937242855638771, 'Total loss': 0.2937242855638771}
2023-01-04 21:49:36,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:36,470 INFO:     Epoch: 22
2023-01-04 21:49:38,653 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5238146354754766, 'Total loss': 0.5238146354754766} | train loss {'Reaction outcome loss': 0.28917561759073473, 'Total loss': 0.28917561759073473}
2023-01-04 21:49:38,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:38,653 INFO:     Epoch: 23
2023-01-04 21:49:40,878 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5107832501331965, 'Total loss': 0.5107832501331965} | train loss {'Reaction outcome loss': 0.2860750181843405, 'Total loss': 0.2860750181843405}
2023-01-04 21:49:40,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:40,880 INFO:     Epoch: 24
2023-01-04 21:49:43,066 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5470425705115001, 'Total loss': 0.5470425705115001} | train loss {'Reaction outcome loss': 0.2849426853531243, 'Total loss': 0.2849426853531243}
2023-01-04 21:49:43,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:43,066 INFO:     Epoch: 25
2023-01-04 21:49:45,246 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49707913796106973, 'Total loss': 0.49707913796106973} | train loss {'Reaction outcome loss': 0.2815920009372243, 'Total loss': 0.2815920009372243}
2023-01-04 21:49:45,246 INFO:     Found new best model at epoch 25
2023-01-04 21:49:45,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:45,248 INFO:     Epoch: 26
2023-01-04 21:49:47,439 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5208014269669851, 'Total loss': 0.5208014269669851} | train loss {'Reaction outcome loss': 0.27048621895770286, 'Total loss': 0.27048621895770286}
2023-01-04 21:49:47,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:47,440 INFO:     Epoch: 27
2023-01-04 21:49:49,635 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49057550927003224, 'Total loss': 0.49057550927003224} | train loss {'Reaction outcome loss': 0.2704235218850005, 'Total loss': 0.2704235218850005}
2023-01-04 21:49:49,635 INFO:     Found new best model at epoch 27
2023-01-04 21:49:49,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:49,636 INFO:     Epoch: 28
2023-01-04 21:49:51,828 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5163381338119507, 'Total loss': 0.5163381338119507} | train loss {'Reaction outcome loss': 0.2661791732446189, 'Total loss': 0.2661791732446189}
2023-01-04 21:49:51,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:51,828 INFO:     Epoch: 29
2023-01-04 21:49:54,016 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5174334704875946, 'Total loss': 0.5174334704875946} | train loss {'Reaction outcome loss': 0.2601291606113301, 'Total loss': 0.2601291606113301}
2023-01-04 21:49:54,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:54,017 INFO:     Epoch: 30
2023-01-04 21:49:56,222 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5594452808300654, 'Total loss': 0.5594452808300654} | train loss {'Reaction outcome loss': 0.27377960888965835, 'Total loss': 0.27377960888965835}
2023-01-04 21:49:56,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:56,222 INFO:     Epoch: 31
2023-01-04 21:49:58,466 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5036322702964147, 'Total loss': 0.5036322702964147} | train loss {'Reaction outcome loss': 0.2711952044510458, 'Total loss': 0.2711952044510458}
2023-01-04 21:49:58,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:49:58,466 INFO:     Epoch: 32
2023-01-04 21:50:00,676 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5000595390796662, 'Total loss': 0.5000595390796662} | train loss {'Reaction outcome loss': 0.2577460876436553, 'Total loss': 0.2577460876436553}
2023-01-04 21:50:00,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:00,678 INFO:     Epoch: 33
2023-01-04 21:50:02,879 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5015328625837961, 'Total loss': 0.5015328625837961} | train loss {'Reaction outcome loss': 0.2592614848213945, 'Total loss': 0.2592614848213945}
2023-01-04 21:50:02,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:02,879 INFO:     Epoch: 34
2023-01-04 21:50:05,071 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5176526308059692, 'Total loss': 0.5176526308059692} | train loss {'Reaction outcome loss': 0.24684872880807499, 'Total loss': 0.24684872880807499}
2023-01-04 21:50:05,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:05,071 INFO:     Epoch: 35
2023-01-04 21:50:07,279 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.51283171971639, 'Total loss': 0.51283171971639} | train loss {'Reaction outcome loss': 0.24744165300027185, 'Total loss': 0.24744165300027185}
2023-01-04 21:50:07,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:07,280 INFO:     Epoch: 36
2023-01-04 21:50:09,472 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5288730929295222, 'Total loss': 0.5288730929295222} | train loss {'Reaction outcome loss': 0.24243269000789555, 'Total loss': 0.24243269000789555}
2023-01-04 21:50:09,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:09,472 INFO:     Epoch: 37
2023-01-04 21:50:11,685 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5241910030444463, 'Total loss': 0.5241910030444463} | train loss {'Reaction outcome loss': 0.23572317325308995, 'Total loss': 0.23572317325308995}
2023-01-04 21:50:11,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:11,686 INFO:     Epoch: 38
2023-01-04 21:50:13,898 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5139639342824618, 'Total loss': 0.5139639342824618} | train loss {'Reaction outcome loss': 0.23306701883700662, 'Total loss': 0.23306701883700662}
2023-01-04 21:50:13,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:13,899 INFO:     Epoch: 39
2023-01-04 21:50:16,093 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5117298175891241, 'Total loss': 0.5117298175891241} | train loss {'Reaction outcome loss': 0.23120466980121884, 'Total loss': 0.23120466980121884}
2023-01-04 21:50:16,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:16,093 INFO:     Epoch: 40
2023-01-04 21:50:18,304 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5154458671808243, 'Total loss': 0.5154458671808243} | train loss {'Reaction outcome loss': 0.22670318971158585, 'Total loss': 0.22670318971158585}
2023-01-04 21:50:18,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:18,305 INFO:     Epoch: 41
2023-01-04 21:50:20,499 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5092907865842183, 'Total loss': 0.5092907865842183} | train loss {'Reaction outcome loss': 0.22797258908057288, 'Total loss': 0.22797258908057288}
2023-01-04 21:50:20,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:20,499 INFO:     Epoch: 42
2023-01-04 21:50:22,704 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5634658972422282, 'Total loss': 0.5634658972422282} | train loss {'Reaction outcome loss': 0.2252391438848555, 'Total loss': 0.2252391438848555}
2023-01-04 21:50:22,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:22,704 INFO:     Epoch: 43
2023-01-04 21:50:24,909 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5155217776695887, 'Total loss': 0.5155217776695887} | train loss {'Reaction outcome loss': 0.22530202650080394, 'Total loss': 0.22530202650080394}
2023-01-04 21:50:24,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:24,911 INFO:     Epoch: 44
2023-01-04 21:50:27,106 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5267596125602723, 'Total loss': 0.5267596125602723} | train loss {'Reaction outcome loss': 0.22372115583351368, 'Total loss': 0.22372115583351368}
2023-01-04 21:50:27,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:27,107 INFO:     Epoch: 45
2023-01-04 21:50:29,298 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5434187730153401, 'Total loss': 0.5434187730153401} | train loss {'Reaction outcome loss': 0.22425982502181138, 'Total loss': 0.22425982502181138}
2023-01-04 21:50:29,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:29,300 INFO:     Epoch: 46
2023-01-04 21:50:31,488 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5253184139728546, 'Total loss': 0.5253184139728546} | train loss {'Reaction outcome loss': 0.22083922426310787, 'Total loss': 0.22083922426310787}
2023-01-04 21:50:31,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:31,488 INFO:     Epoch: 47
2023-01-04 21:50:33,684 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5350292325019836, 'Total loss': 0.5350292325019836} | train loss {'Reaction outcome loss': 0.2153557451961535, 'Total loss': 0.2153557451961535}
2023-01-04 21:50:33,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:33,684 INFO:     Epoch: 48
2023-01-04 21:50:35,879 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5363327870766322, 'Total loss': 0.5363327870766322} | train loss {'Reaction outcome loss': 0.21671669539300373, 'Total loss': 0.21671669539300373}
2023-01-04 21:50:35,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:35,880 INFO:     Epoch: 49
2023-01-04 21:50:38,068 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5369804819424947, 'Total loss': 0.5369804819424947} | train loss {'Reaction outcome loss': 0.21757762088436985, 'Total loss': 0.21757762088436985}
2023-01-04 21:50:38,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:38,068 INFO:     Epoch: 50
2023-01-04 21:50:40,272 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5281401733557384, 'Total loss': 0.5281401733557384} | train loss {'Reaction outcome loss': 0.2112297375426641, 'Total loss': 0.2112297375426641}
2023-01-04 21:50:40,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:40,272 INFO:     Epoch: 51
2023-01-04 21:50:42,465 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5356151272853216, 'Total loss': 0.5356151272853216} | train loss {'Reaction outcome loss': 0.2107073936300973, 'Total loss': 0.2107073936300973}
2023-01-04 21:50:42,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:42,466 INFO:     Epoch: 52
2023-01-04 21:50:44,671 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5473603129386901, 'Total loss': 0.5473603129386901} | train loss {'Reaction outcome loss': 0.212432896549665, 'Total loss': 0.212432896549665}
2023-01-04 21:50:44,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:44,671 INFO:     Epoch: 53
2023-01-04 21:50:46,877 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5436691264311473, 'Total loss': 0.5436691264311473} | train loss {'Reaction outcome loss': 0.25409205077111424, 'Total loss': 0.25409205077111424}
2023-01-04 21:50:46,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:46,877 INFO:     Epoch: 54
2023-01-04 21:50:49,086 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5157333791255951, 'Total loss': 0.5157333791255951} | train loss {'Reaction outcome loss': 0.2162640845785643, 'Total loss': 0.2162640845785643}
2023-01-04 21:50:49,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:49,087 INFO:     Epoch: 55
2023-01-04 21:50:51,286 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5252121220032374, 'Total loss': 0.5252121220032374} | train loss {'Reaction outcome loss': 0.20492100210095235, 'Total loss': 0.20492100210095235}
2023-01-04 21:50:51,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:51,286 INFO:     Epoch: 56
2023-01-04 21:50:53,503 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.574634865919749, 'Total loss': 0.574634865919749} | train loss {'Reaction outcome loss': 0.20087250008330465, 'Total loss': 0.20087250008330465}
2023-01-04 21:50:53,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:53,504 INFO:     Epoch: 57
2023-01-04 21:50:55,688 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5362901816765467, 'Total loss': 0.5362901816765467} | train loss {'Reaction outcome loss': 0.2026157486788166, 'Total loss': 0.2026157486788166}
2023-01-04 21:50:55,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:55,689 INFO:     Epoch: 58
2023-01-04 21:50:57,891 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5461290379365286, 'Total loss': 0.5461290379365286} | train loss {'Reaction outcome loss': 0.20547080306573332, 'Total loss': 0.20547080306573332}
2023-01-04 21:50:57,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:50:57,891 INFO:     Epoch: 59
2023-01-04 21:51:00,101 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5243061383565267, 'Total loss': 0.5243061383565267} | train loss {'Reaction outcome loss': 0.20392023781449467, 'Total loss': 0.20392023781449467}
2023-01-04 21:51:00,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:00,101 INFO:     Epoch: 60
2023-01-04 21:51:02,269 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5772574906547864, 'Total loss': 0.5772574906547864} | train loss {'Reaction outcome loss': 0.1979776174403673, 'Total loss': 0.1979776174403673}
2023-01-04 21:51:02,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:02,270 INFO:     Epoch: 61
2023-01-04 21:51:04,509 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5565816859404246, 'Total loss': 0.5565816859404246} | train loss {'Reaction outcome loss': 0.19789433336573775, 'Total loss': 0.19789433336573775}
2023-01-04 21:51:04,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:04,509 INFO:     Epoch: 62
2023-01-04 21:51:06,737 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5241698364416758, 'Total loss': 0.5241698364416758} | train loss {'Reaction outcome loss': 0.1979481577147743, 'Total loss': 0.1979481577147743}
2023-01-04 21:51:06,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:06,737 INFO:     Epoch: 63
2023-01-04 21:51:08,994 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5442674527565639, 'Total loss': 0.5442674527565639} | train loss {'Reaction outcome loss': 0.19523727690861764, 'Total loss': 0.19523727690861764}
2023-01-04 21:51:08,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:08,996 INFO:     Epoch: 64
2023-01-04 21:51:11,237 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5551157156626384, 'Total loss': 0.5551157156626384} | train loss {'Reaction outcome loss': 0.19422970728761435, 'Total loss': 0.19422970728761435}
2023-01-04 21:51:11,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:11,237 INFO:     Epoch: 65
2023-01-04 21:51:13,440 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5806745092074076, 'Total loss': 0.5806745092074076} | train loss {'Reaction outcome loss': 0.1954366744671395, 'Total loss': 0.1954366744671395}
2023-01-04 21:51:13,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:13,440 INFO:     Epoch: 66
2023-01-04 21:51:15,651 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.562416543563207, 'Total loss': 0.562416543563207} | train loss {'Reaction outcome loss': 0.1958238324082956, 'Total loss': 0.1958238324082956}
2023-01-04 21:51:15,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:15,653 INFO:     Epoch: 67
2023-01-04 21:51:17,834 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5447726130485535, 'Total loss': 0.5447726130485535} | train loss {'Reaction outcome loss': 0.19498289909814417, 'Total loss': 0.19498289909814417}
2023-01-04 21:51:17,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:17,834 INFO:     Epoch: 68
2023-01-04 21:51:20,035 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5452437241872151, 'Total loss': 0.5452437241872151} | train loss {'Reaction outcome loss': 0.19167404159215157, 'Total loss': 0.19167404159215157}
2023-01-04 21:51:20,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:20,037 INFO:     Epoch: 69
2023-01-04 21:51:22,251 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5655085384845734, 'Total loss': 0.5655085384845734} | train loss {'Reaction outcome loss': 0.1896398466167317, 'Total loss': 0.1896398466167317}
2023-01-04 21:51:22,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:22,252 INFO:     Epoch: 70
2023-01-04 21:51:24,451 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5545129358768464, 'Total loss': 0.5545129358768464} | train loss {'Reaction outcome loss': 0.18799243407472427, 'Total loss': 0.18799243407472427}
2023-01-04 21:51:24,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:24,451 INFO:     Epoch: 71
2023-01-04 21:51:26,657 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5496520598729452, 'Total loss': 0.5496520598729452} | train loss {'Reaction outcome loss': 0.19310343133258648, 'Total loss': 0.19310343133258648}
2023-01-04 21:51:26,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:26,658 INFO:     Epoch: 72
2023-01-04 21:51:28,857 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5320164958635966, 'Total loss': 0.5320164958635966} | train loss {'Reaction outcome loss': 0.19032677335823225, 'Total loss': 0.19032677335823225}
2023-01-04 21:51:28,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:28,857 INFO:     Epoch: 73
2023-01-04 21:51:31,063 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5283505360285441, 'Total loss': 0.5283505360285441} | train loss {'Reaction outcome loss': 0.1870459166686118, 'Total loss': 0.1870459166686118}
2023-01-04 21:51:31,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:31,065 INFO:     Epoch: 74
2023-01-04 21:51:33,276 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5955469638109208, 'Total loss': 0.5955469638109208} | train loss {'Reaction outcome loss': 0.18659094159248407, 'Total loss': 0.18659094159248407}
2023-01-04 21:51:33,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:33,277 INFO:     Epoch: 75
2023-01-04 21:51:35,473 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5505632410446802, 'Total loss': 0.5505632410446802} | train loss {'Reaction outcome loss': 0.18653378851077496, 'Total loss': 0.18653378851077496}
2023-01-04 21:51:35,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:35,475 INFO:     Epoch: 76
2023-01-04 21:51:37,690 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5547296901543936, 'Total loss': 0.5547296901543936} | train loss {'Reaction outcome loss': 0.1838742535472018, 'Total loss': 0.1838742535472018}
2023-01-04 21:51:37,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:37,690 INFO:     Epoch: 77
2023-01-04 21:51:39,908 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5436952928702037, 'Total loss': 0.5436952928702037} | train loss {'Reaction outcome loss': 0.17784425529543366, 'Total loss': 0.17784425529543366}
2023-01-04 21:51:39,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:39,909 INFO:     Epoch: 78
2023-01-04 21:51:42,143 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5546050002177556, 'Total loss': 0.5546050002177556} | train loss {'Reaction outcome loss': 0.18443781370465792, 'Total loss': 0.18443781370465792}
2023-01-04 21:51:42,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:42,144 INFO:     Epoch: 79
2023-01-04 21:51:44,391 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5664163808027903, 'Total loss': 0.5664163808027903} | train loss {'Reaction outcome loss': 0.18285407649481372, 'Total loss': 0.18285407649481372}
2023-01-04 21:51:44,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:44,392 INFO:     Epoch: 80
2023-01-04 21:51:46,635 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5637179434299469, 'Total loss': 0.5637179434299469} | train loss {'Reaction outcome loss': 0.1819246754133223, 'Total loss': 0.1819246754133223}
2023-01-04 21:51:46,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:46,635 INFO:     Epoch: 81
2023-01-04 21:51:48,891 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5460282286008199, 'Total loss': 0.5460282286008199} | train loss {'Reaction outcome loss': 0.18071298035163083, 'Total loss': 0.18071298035163083}
2023-01-04 21:51:48,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:48,893 INFO:     Epoch: 82
2023-01-04 21:51:51,129 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5885537544886271, 'Total loss': 0.5885537544886271} | train loss {'Reaction outcome loss': 0.1791027870515962, 'Total loss': 0.1791027870515962}
2023-01-04 21:51:51,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:51,130 INFO:     Epoch: 83
2023-01-04 21:51:53,331 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5548173824946085, 'Total loss': 0.5548173824946085} | train loss {'Reaction outcome loss': 0.18522520312937585, 'Total loss': 0.18522520312937585}
2023-01-04 21:51:53,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:53,332 INFO:     Epoch: 84
2023-01-04 21:51:55,539 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5829270631074905, 'Total loss': 0.5829270631074905} | train loss {'Reaction outcome loss': 0.17799794054295437, 'Total loss': 0.17799794054295437}
2023-01-04 21:51:55,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:55,539 INFO:     Epoch: 85
2023-01-04 21:51:57,735 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5774484276771545, 'Total loss': 0.5774484276771545} | train loss {'Reaction outcome loss': 0.17804498197443352, 'Total loss': 0.17804498197443352}
2023-01-04 21:51:57,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:57,736 INFO:     Epoch: 86
2023-01-04 21:51:59,940 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5855062782764435, 'Total loss': 0.5855062782764435} | train loss {'Reaction outcome loss': 0.17371573598137585, 'Total loss': 0.17371573598137585}
2023-01-04 21:51:59,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:51:59,941 INFO:     Epoch: 87
2023-01-04 21:52:02,151 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5456945349772772, 'Total loss': 0.5456945349772772} | train loss {'Reaction outcome loss': 0.2000269802418821, 'Total loss': 0.2000269802418821}
2023-01-04 21:52:02,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:02,151 INFO:     Epoch: 88
2023-01-04 21:52:04,340 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5600854128599166, 'Total loss': 0.5600854128599166} | train loss {'Reaction outcome loss': 0.17997389865079153, 'Total loss': 0.17997389865079153}
2023-01-04 21:52:04,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:04,342 INFO:     Epoch: 89
2023-01-04 21:52:06,537 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5419168313344319, 'Total loss': 0.5419168313344319} | train loss {'Reaction outcome loss': 0.16871052792091665, 'Total loss': 0.16871052792091665}
2023-01-04 21:52:06,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:06,537 INFO:     Epoch: 90
2023-01-04 21:52:08,707 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5386888206005096, 'Total loss': 0.5386888206005096} | train loss {'Reaction outcome loss': 0.17440478931909995, 'Total loss': 0.17440478931909995}
2023-01-04 21:52:08,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:08,708 INFO:     Epoch: 91
2023-01-04 21:52:10,948 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5497352143128713, 'Total loss': 0.5497352143128713} | train loss {'Reaction outcome loss': 0.17087293175163853, 'Total loss': 0.17087293175163853}
2023-01-04 21:52:10,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:10,949 INFO:     Epoch: 92
2023-01-04 21:52:13,197 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5464826901753743, 'Total loss': 0.5464826901753743} | train loss {'Reaction outcome loss': 0.17206603320100575, 'Total loss': 0.17206603320100575}
2023-01-04 21:52:13,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:13,197 INFO:     Epoch: 93
2023-01-04 21:52:15,395 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5251753588517507, 'Total loss': 0.5251753588517507} | train loss {'Reaction outcome loss': 0.17285687096106508, 'Total loss': 0.17285687096106508}
2023-01-04 21:52:15,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:15,395 INFO:     Epoch: 94
2023-01-04 21:52:17,592 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.556353900829951, 'Total loss': 0.556353900829951} | train loss {'Reaction outcome loss': 0.17766089848220767, 'Total loss': 0.17766089848220767}
2023-01-04 21:52:17,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:17,593 INFO:     Epoch: 95
2023-01-04 21:52:19,782 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5873845835526784, 'Total loss': 0.5873845835526784} | train loss {'Reaction outcome loss': 0.17076559302327898, 'Total loss': 0.17076559302327898}
2023-01-04 21:52:19,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:19,783 INFO:     Epoch: 96
2023-01-04 21:52:21,968 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5725556959708532, 'Total loss': 0.5725556959708532} | train loss {'Reaction outcome loss': 0.17054475328726423, 'Total loss': 0.17054475328726423}
2023-01-04 21:52:21,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:21,969 INFO:     Epoch: 97
2023-01-04 21:52:24,163 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5438016752401987, 'Total loss': 0.5438016752401987} | train loss {'Reaction outcome loss': 0.1710928870918418, 'Total loss': 0.1710928870918418}
2023-01-04 21:52:24,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:24,164 INFO:     Epoch: 98
2023-01-04 21:52:26,338 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5649526437123616, 'Total loss': 0.5649526437123616} | train loss {'Reaction outcome loss': 0.1717343723833345, 'Total loss': 0.1717343723833345}
2023-01-04 21:52:26,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:26,338 INFO:     Epoch: 99
2023-01-04 21:52:28,542 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5811586598555247, 'Total loss': 0.5811586598555247} | train loss {'Reaction outcome loss': 0.16709470827692607, 'Total loss': 0.16709470827692607}
2023-01-04 21:52:28,543 INFO:     Best model found after epoch 28 of 100.
2023-01-04 21:52:28,543 INFO:   Done with stage: TRAINING
2023-01-04 21:52:28,544 INFO:   Starting stage: EVALUATION
2023-01-04 21:52:28,680 INFO:   Done with stage: EVALUATION
2023-01-04 21:52:28,680 INFO:   Leaving out SEQ value Fold_2
2023-01-04 21:52:28,693 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 21:52:28,693 INFO:   Starting stage: FEATURE SCALING
2023-01-04 21:52:29,347 INFO:   Done with stage: FEATURE SCALING
2023-01-04 21:52:29,347 INFO:   Starting stage: SCALING TARGETS
2023-01-04 21:52:29,418 INFO:   Done with stage: SCALING TARGETS
2023-01-04 21:52:29,418 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 21:52:29,418 INFO:     No hyperparam tuning for this model
2023-01-04 21:52:29,418 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 21:52:29,418 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 21:52:29,419 INFO:     None feature selector for col prot
2023-01-04 21:52:29,419 INFO:     None feature selector for col prot
2023-01-04 21:52:29,419 INFO:     None feature selector for col prot
2023-01-04 21:52:29,420 INFO:     None feature selector for col chem
2023-01-04 21:52:29,420 INFO:     None feature selector for col chem
2023-01-04 21:52:29,420 INFO:     None feature selector for col chem
2023-01-04 21:52:29,420 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 21:52:29,420 INFO:   Starting stage: BUILD MODEL
2023-01-04 21:52:29,422 INFO:     Number of params in model 72931
2023-01-04 21:52:29,425 INFO:   Done with stage: BUILD MODEL
2023-01-04 21:52:29,425 INFO:   Starting stage: TRAINING
2023-01-04 21:52:29,485 INFO:     Val loss before train {'Reaction outcome loss': 0.9186755577723186, 'Total loss': 0.9186755577723186}
2023-01-04 21:52:29,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:29,485 INFO:     Epoch: 0
2023-01-04 21:52:31,668 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7050742884476979, 'Total loss': 0.7050742884476979} | train loss {'Reaction outcome loss': 0.95245474761855, 'Total loss': 0.95245474761855}
2023-01-04 21:52:31,668 INFO:     Found new best model at epoch 0
2023-01-04 21:52:31,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:31,670 INFO:     Epoch: 1
2023-01-04 21:52:33,895 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5001580913861593, 'Total loss': 0.5001580913861593} | train loss {'Reaction outcome loss': 0.6311085909931329, 'Total loss': 0.6311085909931329}
2023-01-04 21:52:33,896 INFO:     Found new best model at epoch 1
2023-01-04 21:52:33,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:33,898 INFO:     Epoch: 2
2023-01-04 21:52:36,102 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4694181750218073, 'Total loss': 0.4694181750218073} | train loss {'Reaction outcome loss': 0.5421147331269118, 'Total loss': 0.5421147331269118}
2023-01-04 21:52:36,102 INFO:     Found new best model at epoch 2
2023-01-04 21:52:36,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:36,104 INFO:     Epoch: 3
2023-01-04 21:52:38,254 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4413711875677109, 'Total loss': 0.4413711875677109} | train loss {'Reaction outcome loss': 0.5057672706507418, 'Total loss': 0.5057672706507418}
2023-01-04 21:52:38,255 INFO:     Found new best model at epoch 3
2023-01-04 21:52:38,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:38,256 INFO:     Epoch: 4
2023-01-04 21:52:40,431 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4371031135320663, 'Total loss': 0.4371031135320663} | train loss {'Reaction outcome loss': 0.48041796396030995, 'Total loss': 0.48041796396030995}
2023-01-04 21:52:40,431 INFO:     Found new best model at epoch 4
2023-01-04 21:52:40,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:40,432 INFO:     Epoch: 5
2023-01-04 21:52:42,616 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4390377471844355, 'Total loss': 0.4390377471844355} | train loss {'Reaction outcome loss': 0.45974714591772886, 'Total loss': 0.45974714591772886}
2023-01-04 21:52:42,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:42,617 INFO:     Epoch: 6
2023-01-04 21:52:44,819 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4299494286378225, 'Total loss': 0.4299494286378225} | train loss {'Reaction outcome loss': 0.4448966027176293, 'Total loss': 0.4448966027176293}
2023-01-04 21:52:44,820 INFO:     Found new best model at epoch 6
2023-01-04 21:52:44,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:44,821 INFO:     Epoch: 7
2023-01-04 21:52:47,013 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4295289327700933, 'Total loss': 0.4295289327700933} | train loss {'Reaction outcome loss': 0.42795118559015927, 'Total loss': 0.42795118559015927}
2023-01-04 21:52:47,013 INFO:     Found new best model at epoch 7
2023-01-04 21:52:47,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:47,014 INFO:     Epoch: 8
2023-01-04 21:52:49,192 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4069591720898946, 'Total loss': 0.4069591720898946} | train loss {'Reaction outcome loss': 0.42274107139584793, 'Total loss': 0.42274107139584793}
2023-01-04 21:52:49,193 INFO:     Found new best model at epoch 8
2023-01-04 21:52:49,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:49,194 INFO:     Epoch: 9
2023-01-04 21:52:51,381 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4265559703111649, 'Total loss': 0.4265559703111649} | train loss {'Reaction outcome loss': 0.4027136381253274, 'Total loss': 0.4027136381253274}
2023-01-04 21:52:51,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:51,382 INFO:     Epoch: 10
2023-01-04 21:52:53,581 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39781014223893485, 'Total loss': 0.39781014223893485} | train loss {'Reaction outcome loss': 0.4010344019608341, 'Total loss': 0.4010344019608341}
2023-01-04 21:52:53,581 INFO:     Found new best model at epoch 10
2023-01-04 21:52:53,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:53,582 INFO:     Epoch: 11
2023-01-04 21:52:55,768 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3974622925122579, 'Total loss': 0.3974622925122579} | train loss {'Reaction outcome loss': 0.3898668519228044, 'Total loss': 0.3898668519228044}
2023-01-04 21:52:55,768 INFO:     Found new best model at epoch 11
2023-01-04 21:52:55,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:55,770 INFO:     Epoch: 12
2023-01-04 21:52:57,967 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4023539304733276, 'Total loss': 0.4023539304733276} | train loss {'Reaction outcome loss': 0.3778708936089147, 'Total loss': 0.3778708936089147}
2023-01-04 21:52:57,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:57,968 INFO:     Epoch: 13
2023-01-04 21:52:59,995 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39167231718699136, 'Total loss': 0.39167231718699136} | train loss {'Reaction outcome loss': 0.3653275878270612, 'Total loss': 0.3653275878270612}
2023-01-04 21:52:59,995 INFO:     Found new best model at epoch 13
2023-01-04 21:52:59,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:52:59,997 INFO:     Epoch: 14
2023-01-04 21:53:02,202 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3792075018088023, 'Total loss': 0.3792075018088023} | train loss {'Reaction outcome loss': 0.36028382769466316, 'Total loss': 0.36028382769466316}
2023-01-04 21:53:02,202 INFO:     Found new best model at epoch 14
2023-01-04 21:53:02,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:02,203 INFO:     Epoch: 15
2023-01-04 21:53:04,510 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.36844399813562634, 'Total loss': 0.36844399813562634} | train loss {'Reaction outcome loss': 0.35231750425848646, 'Total loss': 0.35231750425848646}
2023-01-04 21:53:04,511 INFO:     Found new best model at epoch 15
2023-01-04 21:53:04,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:04,512 INFO:     Epoch: 16
2023-01-04 21:53:06,701 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3858090817928314, 'Total loss': 0.3858090817928314} | train loss {'Reaction outcome loss': 0.34709791055996053, 'Total loss': 0.34709791055996053}
2023-01-04 21:53:06,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:06,701 INFO:     Epoch: 17
2023-01-04 21:53:08,891 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3614987522363663, 'Total loss': 0.3614987522363663} | train loss {'Reaction outcome loss': 0.33711279716587417, 'Total loss': 0.33711279716587417}
2023-01-04 21:53:08,891 INFO:     Found new best model at epoch 17
2023-01-04 21:53:08,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:08,893 INFO:     Epoch: 18
2023-01-04 21:53:11,077 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39460149109363557, 'Total loss': 0.39460149109363557} | train loss {'Reaction outcome loss': 0.33463291100559445, 'Total loss': 0.33463291100559445}
2023-01-04 21:53:11,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:11,078 INFO:     Epoch: 19
2023-01-04 21:53:13,248 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3786230355501175, 'Total loss': 0.3786230355501175} | train loss {'Reaction outcome loss': 0.3261270360599687, 'Total loss': 0.3261270360599687}
2023-01-04 21:53:13,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:13,248 INFO:     Epoch: 20
2023-01-04 21:53:15,477 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40616069932778676, 'Total loss': 0.40616069932778676} | train loss {'Reaction outcome loss': 0.3224203458776439, 'Total loss': 0.3224203458776439}
2023-01-04 21:53:15,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:15,478 INFO:     Epoch: 21
2023-01-04 21:53:17,702 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39370104571183523, 'Total loss': 0.39370104571183523} | train loss {'Reaction outcome loss': 0.3185943798128053, 'Total loss': 0.3185943798128053}
2023-01-04 21:53:17,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:17,702 INFO:     Epoch: 22
2023-01-04 21:53:19,881 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4090079262852669, 'Total loss': 0.4090079262852669} | train loss {'Reaction outcome loss': 0.3136388914809175, 'Total loss': 0.3136388914809175}
2023-01-04 21:53:19,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:19,881 INFO:     Epoch: 23
2023-01-04 21:53:22,053 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41344315310319263, 'Total loss': 0.41344315310319263} | train loss {'Reaction outcome loss': 0.3041417031093453, 'Total loss': 0.3041417031093453}
2023-01-04 21:53:22,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:22,054 INFO:     Epoch: 24
2023-01-04 21:53:24,231 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3996842900911967, 'Total loss': 0.3996842900911967} | train loss {'Reaction outcome loss': 0.3008255484874231, 'Total loss': 0.3008255484874231}
2023-01-04 21:53:24,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:24,231 INFO:     Epoch: 25
2023-01-04 21:53:26,453 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39470805823802946, 'Total loss': 0.39470805823802946} | train loss {'Reaction outcome loss': 0.29362782935210824, 'Total loss': 0.29362782935210824}
2023-01-04 21:53:26,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:26,455 INFO:     Epoch: 26
2023-01-04 21:53:28,654 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.421639613310496, 'Total loss': 0.421639613310496} | train loss {'Reaction outcome loss': 0.28703234324326915, 'Total loss': 0.28703234324326915}
2023-01-04 21:53:28,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:28,655 INFO:     Epoch: 27
2023-01-04 21:53:30,854 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.386441012720267, 'Total loss': 0.386441012720267} | train loss {'Reaction outcome loss': 0.2857831479016229, 'Total loss': 0.2857831479016229}
2023-01-04 21:53:30,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:30,855 INFO:     Epoch: 28
2023-01-04 21:53:33,056 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4122949371735255, 'Total loss': 0.4122949371735255} | train loss {'Reaction outcome loss': 0.28049393585563576, 'Total loss': 0.28049393585563576}
2023-01-04 21:53:33,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:33,057 INFO:     Epoch: 29
2023-01-04 21:53:35,248 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38794694989919665, 'Total loss': 0.38794694989919665} | train loss {'Reaction outcome loss': 0.2772493651952513, 'Total loss': 0.2772493651952513}
2023-01-04 21:53:35,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:35,248 INFO:     Epoch: 30
2023-01-04 21:53:37,457 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4021395886937777, 'Total loss': 0.4021395886937777} | train loss {'Reaction outcome loss': 0.2691631504082984, 'Total loss': 0.2691631504082984}
2023-01-04 21:53:37,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:37,459 INFO:     Epoch: 31
2023-01-04 21:53:39,644 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4128855273127556, 'Total loss': 0.4128855273127556} | train loss {'Reaction outcome loss': 0.2688974096732092, 'Total loss': 0.2688974096732092}
2023-01-04 21:53:39,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:39,644 INFO:     Epoch: 32
2023-01-04 21:53:41,854 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3954431494077047, 'Total loss': 0.3954431494077047} | train loss {'Reaction outcome loss': 0.26257626037283316, 'Total loss': 0.26257626037283316}
2023-01-04 21:53:41,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:41,855 INFO:     Epoch: 33
2023-01-04 21:53:44,046 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4005462110042572, 'Total loss': 0.4005462110042572} | train loss {'Reaction outcome loss': 0.25877350820296435, 'Total loss': 0.25877350820296435}
2023-01-04 21:53:44,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:44,047 INFO:     Epoch: 34
2023-01-04 21:53:46,256 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4126021772623062, 'Total loss': 0.4126021772623062} | train loss {'Reaction outcome loss': 0.2585426718064577, 'Total loss': 0.2585426718064577}
2023-01-04 21:53:46,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:46,256 INFO:     Epoch: 35
2023-01-04 21:53:48,436 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38303411106268564, 'Total loss': 0.38303411106268564} | train loss {'Reaction outcome loss': 0.2575274613298421, 'Total loss': 0.2575274613298421}
2023-01-04 21:53:48,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:48,436 INFO:     Epoch: 36
2023-01-04 21:53:50,615 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3941097111751636, 'Total loss': 0.3941097111751636} | train loss {'Reaction outcome loss': 0.2548365884453711, 'Total loss': 0.2548365884453711}
2023-01-04 21:53:50,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:50,616 INFO:     Epoch: 37
2023-01-04 21:53:52,815 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.387728151679039, 'Total loss': 0.387728151679039} | train loss {'Reaction outcome loss': 0.2503748371734889, 'Total loss': 0.2503748371734889}
2023-01-04 21:53:52,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:52,816 INFO:     Epoch: 38
2023-01-04 21:53:55,028 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4315410405397415, 'Total loss': 0.4315410405397415} | train loss {'Reaction outcome loss': 0.24526918491851674, 'Total loss': 0.24526918491851674}
2023-01-04 21:53:55,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:55,030 INFO:     Epoch: 39
2023-01-04 21:53:57,213 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4156484136978785, 'Total loss': 0.4156484136978785} | train loss {'Reaction outcome loss': 0.24245670088056992, 'Total loss': 0.24245670088056992}
2023-01-04 21:53:57,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:57,213 INFO:     Epoch: 40
2023-01-04 21:53:59,424 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4101547946532567, 'Total loss': 0.4101547946532567} | train loss {'Reaction outcome loss': 0.24222048642589664, 'Total loss': 0.24222048642589664}
2023-01-04 21:53:59,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:53:59,424 INFO:     Epoch: 41
2023-01-04 21:54:01,600 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42640150189399717, 'Total loss': 0.42640150189399717} | train loss {'Reaction outcome loss': 0.23992747834536934, 'Total loss': 0.23992747834536934}
2023-01-04 21:54:01,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:01,601 INFO:     Epoch: 42
2023-01-04 21:54:03,784 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44542496303717294, 'Total loss': 0.44542496303717294} | train loss {'Reaction outcome loss': 0.2345997883401213, 'Total loss': 0.2345997883401213}
2023-01-04 21:54:03,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:03,784 INFO:     Epoch: 43
2023-01-04 21:54:05,964 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4066294093926748, 'Total loss': 0.4066294093926748} | train loss {'Reaction outcome loss': 0.23768436930475445, 'Total loss': 0.23768436930475445}
2023-01-04 21:54:05,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:05,964 INFO:     Epoch: 44
2023-01-04 21:54:08,138 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3902093122402827, 'Total loss': 0.3902093122402827} | train loss {'Reaction outcome loss': 0.23036020524786227, 'Total loss': 0.23036020524786227}
2023-01-04 21:54:08,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:08,139 INFO:     Epoch: 45
2023-01-04 21:54:10,324 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38743071258068085, 'Total loss': 0.38743071258068085} | train loss {'Reaction outcome loss': 0.22601339028617978, 'Total loss': 0.22601339028617978}
2023-01-04 21:54:10,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:10,324 INFO:     Epoch: 46
2023-01-04 21:54:12,505 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3993352840344111, 'Total loss': 0.3993352840344111} | train loss {'Reaction outcome loss': 0.22842333817269897, 'Total loss': 0.22842333817269897}
2023-01-04 21:54:12,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:12,507 INFO:     Epoch: 47
2023-01-04 21:54:14,681 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3675013403097788, 'Total loss': 0.3675013403097788} | train loss {'Reaction outcome loss': 0.22131138559036556, 'Total loss': 0.22131138559036556}
2023-01-04 21:54:14,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:14,682 INFO:     Epoch: 48
2023-01-04 21:54:16,856 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38567658712466557, 'Total loss': 0.38567658712466557} | train loss {'Reaction outcome loss': 0.2167900844211996, 'Total loss': 0.2167900844211996}
2023-01-04 21:54:16,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:16,856 INFO:     Epoch: 49
2023-01-04 21:54:19,001 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4001015911499659, 'Total loss': 0.4001015911499659} | train loss {'Reaction outcome loss': 0.2238331973539108, 'Total loss': 0.2238331973539108}
2023-01-04 21:54:19,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:19,002 INFO:     Epoch: 50
2023-01-04 21:54:21,193 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3872765193382899, 'Total loss': 0.3872765193382899} | train loss {'Reaction outcome loss': 0.21774266289723834, 'Total loss': 0.21774266289723834}
2023-01-04 21:54:21,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:21,193 INFO:     Epoch: 51
2023-01-04 21:54:23,379 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4404441366593043, 'Total loss': 0.4404441366593043} | train loss {'Reaction outcome loss': 0.2161807216377589, 'Total loss': 0.2161807216377589}
2023-01-04 21:54:23,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:23,380 INFO:     Epoch: 52
2023-01-04 21:54:25,552 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3942945017168919, 'Total loss': 0.3942945017168919} | train loss {'Reaction outcome loss': 0.2184465319992308, 'Total loss': 0.2184465319992308}
2023-01-04 21:54:25,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:25,552 INFO:     Epoch: 53
2023-01-04 21:54:27,736 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4220251788695653, 'Total loss': 0.4220251788695653} | train loss {'Reaction outcome loss': 0.22041205154990193, 'Total loss': 0.22041205154990193}
2023-01-04 21:54:27,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:27,736 INFO:     Epoch: 54
2023-01-04 21:54:29,925 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42843387424945834, 'Total loss': 0.42843387424945834} | train loss {'Reaction outcome loss': 0.21699214592086571, 'Total loss': 0.21699214592086571}
2023-01-04 21:54:29,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:29,927 INFO:     Epoch: 55
2023-01-04 21:54:32,120 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40185958445072173, 'Total loss': 0.40185958445072173} | train loss {'Reaction outcome loss': 0.21094645046880536, 'Total loss': 0.21094645046880536}
2023-01-04 21:54:32,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:32,120 INFO:     Epoch: 56
2023-01-04 21:54:34,298 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3936813478668531, 'Total loss': 0.3936813478668531} | train loss {'Reaction outcome loss': 0.21296315126963994, 'Total loss': 0.21296315126963994}
2023-01-04 21:54:34,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:34,299 INFO:     Epoch: 57
2023-01-04 21:54:36,455 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39134301791588466, 'Total loss': 0.39134301791588466} | train loss {'Reaction outcome loss': 0.21155919002736137, 'Total loss': 0.21155919002736137}
2023-01-04 21:54:36,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:36,456 INFO:     Epoch: 58
2023-01-04 21:54:38,646 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42408510943253835, 'Total loss': 0.42408510943253835} | train loss {'Reaction outcome loss': 0.20809674517584653, 'Total loss': 0.20809674517584653}
2023-01-04 21:54:38,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:38,646 INFO:     Epoch: 59
2023-01-04 21:54:40,838 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41508835305770236, 'Total loss': 0.41508835305770236} | train loss {'Reaction outcome loss': 0.2096112448242867, 'Total loss': 0.2096112448242867}
2023-01-04 21:54:40,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:40,838 INFO:     Epoch: 60
2023-01-04 21:54:43,025 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42567425494392713, 'Total loss': 0.42567425494392713} | train loss {'Reaction outcome loss': 0.20446855562270014, 'Total loss': 0.20446855562270014}
2023-01-04 21:54:43,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:43,026 INFO:     Epoch: 61
2023-01-04 21:54:45,200 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41021217008431754, 'Total loss': 0.41021217008431754} | train loss {'Reaction outcome loss': 0.2027897307017043, 'Total loss': 0.2027897307017043}
2023-01-04 21:54:45,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:45,200 INFO:     Epoch: 62
2023-01-04 21:54:47,372 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40316079755624135, 'Total loss': 0.40316079755624135} | train loss {'Reaction outcome loss': 0.20359490442354858, 'Total loss': 0.20359490442354858}
2023-01-04 21:54:47,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:47,373 INFO:     Epoch: 63
2023-01-04 21:54:49,559 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3872019556661447, 'Total loss': 0.3872019556661447} | train loss {'Reaction outcome loss': 0.20108645221891466, 'Total loss': 0.20108645221891466}
2023-01-04 21:54:49,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:49,560 INFO:     Epoch: 64
2023-01-04 21:54:51,747 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39137778580188753, 'Total loss': 0.39137778580188753} | train loss {'Reaction outcome loss': 0.20149991837377748, 'Total loss': 0.20149991837377748}
2023-01-04 21:54:51,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:51,747 INFO:     Epoch: 65
2023-01-04 21:54:53,940 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.36229405626654626, 'Total loss': 0.36229405626654626} | train loss {'Reaction outcome loss': 0.19944534860347418, 'Total loss': 0.19944534860347418}
2023-01-04 21:54:53,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:53,940 INFO:     Epoch: 66
2023-01-04 21:54:56,128 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4004653553167979, 'Total loss': 0.4004653553167979} | train loss {'Reaction outcome loss': 0.19737555004357205, 'Total loss': 0.19737555004357205}
2023-01-04 21:54:56,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:56,129 INFO:     Epoch: 67
2023-01-04 21:54:58,309 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38541075189908347, 'Total loss': 0.38541075189908347} | train loss {'Reaction outcome loss': 0.1901352143112271, 'Total loss': 0.1901352143112271}
2023-01-04 21:54:58,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:54:58,310 INFO:     Epoch: 68
2023-01-04 21:55:00,493 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39016352221369743, 'Total loss': 0.39016352221369743} | train loss {'Reaction outcome loss': 0.19578583926016832, 'Total loss': 0.19578583926016832}
2023-01-04 21:55:00,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:00,494 INFO:     Epoch: 69
2023-01-04 21:55:02,679 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3716248497366905, 'Total loss': 0.3716248497366905} | train loss {'Reaction outcome loss': 0.1953478450411047, 'Total loss': 0.1953478450411047}
2023-01-04 21:55:02,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:02,680 INFO:     Epoch: 70
2023-01-04 21:55:04,873 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4393455147743225, 'Total loss': 0.4393455147743225} | train loss {'Reaction outcome loss': 0.19212885377894626, 'Total loss': 0.19212885377894626}
2023-01-04 21:55:04,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:04,874 INFO:     Epoch: 71
2023-01-04 21:55:07,066 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40654325087865195, 'Total loss': 0.40654325087865195} | train loss {'Reaction outcome loss': 0.188234686433426, 'Total loss': 0.188234686433426}
2023-01-04 21:55:07,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:07,067 INFO:     Epoch: 72
2023-01-04 21:55:09,249 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44412418057521186, 'Total loss': 0.44412418057521186} | train loss {'Reaction outcome loss': 0.19256227486936825, 'Total loss': 0.19256227486936825}
2023-01-04 21:55:09,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:09,249 INFO:     Epoch: 73
2023-01-04 21:55:11,423 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4544933984676997, 'Total loss': 0.4544933984676997} | train loss {'Reaction outcome loss': 0.1913087362980973, 'Total loss': 0.1913087362980973}
2023-01-04 21:55:11,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:11,425 INFO:     Epoch: 74
2023-01-04 21:55:13,614 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39933992773294447, 'Total loss': 0.39933992773294447} | train loss {'Reaction outcome loss': 0.18661271125744402, 'Total loss': 0.18661271125744402}
2023-01-04 21:55:13,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:13,615 INFO:     Epoch: 75
2023-01-04 21:55:15,798 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4021253670255343, 'Total loss': 0.4021253670255343} | train loss {'Reaction outcome loss': 0.1894104151585459, 'Total loss': 0.1894104151585459}
2023-01-04 21:55:15,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:15,799 INFO:     Epoch: 76
2023-01-04 21:55:17,995 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4136370559533437, 'Total loss': 0.4136370559533437} | train loss {'Reaction outcome loss': 0.18473228314605944, 'Total loss': 0.18473228314605944}
2023-01-04 21:55:17,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:17,996 INFO:     Epoch: 77
2023-01-04 21:55:20,179 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4077372640371323, 'Total loss': 0.4077372640371323} | train loss {'Reaction outcome loss': 0.18486216173840375, 'Total loss': 0.18486216173840375}
2023-01-04 21:55:20,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:20,180 INFO:     Epoch: 78
2023-01-04 21:55:22,353 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4090423360466957, 'Total loss': 0.4090423360466957} | train loss {'Reaction outcome loss': 0.18523298485211376, 'Total loss': 0.18523298485211376}
2023-01-04 21:55:22,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:22,355 INFO:     Epoch: 79
2023-01-04 21:55:24,540 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41072154641151426, 'Total loss': 0.41072154641151426} | train loss {'Reaction outcome loss': 0.18420620566492316, 'Total loss': 0.18420620566492316}
2023-01-04 21:55:24,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:24,541 INFO:     Epoch: 80
2023-01-04 21:55:26,738 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3849123934904734, 'Total loss': 0.3849123934904734} | train loss {'Reaction outcome loss': 0.18249476842758974, 'Total loss': 0.18249476842758974}
2023-01-04 21:55:26,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:26,738 INFO:     Epoch: 81
2023-01-04 21:55:28,925 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4109629362821579, 'Total loss': 0.4109629362821579} | train loss {'Reaction outcome loss': 0.18361300814991993, 'Total loss': 0.18361300814991993}
2023-01-04 21:55:28,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:28,926 INFO:     Epoch: 82
2023-01-04 21:55:31,097 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3932293380300204, 'Total loss': 0.3932293380300204} | train loss {'Reaction outcome loss': 0.18343102879461962, 'Total loss': 0.18343102879461962}
2023-01-04 21:55:31,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:31,097 INFO:     Epoch: 83
2023-01-04 21:55:33,272 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4083062479893366, 'Total loss': 0.4083062479893366} | train loss {'Reaction outcome loss': 0.18340673089625625, 'Total loss': 0.18340673089625625}
2023-01-04 21:55:33,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:33,274 INFO:     Epoch: 84
2023-01-04 21:55:35,466 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4267584763467312, 'Total loss': 0.4267584763467312} | train loss {'Reaction outcome loss': 0.18438423245152744, 'Total loss': 0.18438423245152744}
2023-01-04 21:55:35,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:35,467 INFO:     Epoch: 85
2023-01-04 21:55:37,649 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38258170485496523, 'Total loss': 0.38258170485496523} | train loss {'Reaction outcome loss': 0.18065082636002425, 'Total loss': 0.18065082636002425}
2023-01-04 21:55:37,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:37,649 INFO:     Epoch: 86
2023-01-04 21:55:39,846 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3986286799112956, 'Total loss': 0.3986286799112956} | train loss {'Reaction outcome loss': 0.17575172004187956, 'Total loss': 0.17575172004187956}
2023-01-04 21:55:39,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:39,847 INFO:     Epoch: 87
2023-01-04 21:55:42,022 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39455109238624575, 'Total loss': 0.39455109238624575} | train loss {'Reaction outcome loss': 0.1746225281156273, 'Total loss': 0.1746225281156273}
2023-01-04 21:55:42,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:42,022 INFO:     Epoch: 88
2023-01-04 21:55:44,200 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4302379168570042, 'Total loss': 0.4302379168570042} | train loss {'Reaction outcome loss': 0.17759929086849854, 'Total loss': 0.17759929086849854}
2023-01-04 21:55:44,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:44,200 INFO:     Epoch: 89
2023-01-04 21:55:46,384 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39072794367869695, 'Total loss': 0.39072794367869695} | train loss {'Reaction outcome loss': 0.18144820768549277, 'Total loss': 0.18144820768549277}
2023-01-04 21:55:46,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:46,385 INFO:     Epoch: 90
2023-01-04 21:55:48,582 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43304141859213513, 'Total loss': 0.43304141859213513} | train loss {'Reaction outcome loss': 0.17561567141708448, 'Total loss': 0.17561567141708448}
2023-01-04 21:55:48,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:48,583 INFO:     Epoch: 91
2023-01-04 21:55:50,774 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4197412287195524, 'Total loss': 0.4197412287195524} | train loss {'Reaction outcome loss': 0.17391208869602232, 'Total loss': 0.17391208869602232}
2023-01-04 21:55:50,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:50,774 INFO:     Epoch: 92
2023-01-04 21:55:52,959 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39243651628494264, 'Total loss': 0.39243651628494264} | train loss {'Reaction outcome loss': 0.17903982516187822, 'Total loss': 0.17903982516187822}
2023-01-04 21:55:52,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:52,960 INFO:     Epoch: 93
2023-01-04 21:55:55,114 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4337692528963089, 'Total loss': 0.4337692528963089} | train loss {'Reaction outcome loss': 0.1764893084628521, 'Total loss': 0.1764893084628521}
2023-01-04 21:55:55,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:55,115 INFO:     Epoch: 94
2023-01-04 21:55:57,305 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4432108168800672, 'Total loss': 0.4432108168800672} | train loss {'Reaction outcome loss': 0.17264377788545388, 'Total loss': 0.17264377788545388}
2023-01-04 21:55:57,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:57,305 INFO:     Epoch: 95
2023-01-04 21:55:59,494 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39596593578656514, 'Total loss': 0.39596593578656514} | train loss {'Reaction outcome loss': 0.1783949732805949, 'Total loss': 0.1783949732805949}
2023-01-04 21:55:59,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:55:59,495 INFO:     Epoch: 96
2023-01-04 21:56:01,662 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.402479849755764, 'Total loss': 0.402479849755764} | train loss {'Reaction outcome loss': 0.16839656813994702, 'Total loss': 0.16839656813994702}
2023-01-04 21:56:01,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:01,662 INFO:     Epoch: 97
2023-01-04 21:56:03,825 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41807959030071895, 'Total loss': 0.41807959030071895} | train loss {'Reaction outcome loss': 0.17340540464450843, 'Total loss': 0.17340540464450843}
2023-01-04 21:56:03,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:03,826 INFO:     Epoch: 98
2023-01-04 21:56:05,819 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4027554968992869, 'Total loss': 0.4027554968992869} | train loss {'Reaction outcome loss': 0.17368602688104784, 'Total loss': 0.17368602688104784}
2023-01-04 21:56:05,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:05,820 INFO:     Epoch: 99
2023-01-04 21:56:07,608 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4234664579232534, 'Total loss': 0.4234664579232534} | train loss {'Reaction outcome loss': 0.1720025873144776, 'Total loss': 0.1720025873144776}
2023-01-04 21:56:07,608 INFO:     Best model found after epoch 18 of 100.
2023-01-04 21:56:07,609 INFO:   Done with stage: TRAINING
2023-01-04 21:56:07,609 INFO:   Starting stage: EVALUATION
2023-01-04 21:56:07,746 INFO:   Done with stage: EVALUATION
2023-01-04 21:56:07,746 INFO:   Leaving out SEQ value Fold_3
2023-01-04 21:56:07,759 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 21:56:07,759 INFO:   Starting stage: FEATURE SCALING
2023-01-04 21:56:08,410 INFO:   Done with stage: FEATURE SCALING
2023-01-04 21:56:08,410 INFO:   Starting stage: SCALING TARGETS
2023-01-04 21:56:08,481 INFO:   Done with stage: SCALING TARGETS
2023-01-04 21:56:08,481 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 21:56:08,481 INFO:     No hyperparam tuning for this model
2023-01-04 21:56:08,481 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 21:56:08,481 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 21:56:08,482 INFO:     None feature selector for col prot
2023-01-04 21:56:08,482 INFO:     None feature selector for col prot
2023-01-04 21:56:08,482 INFO:     None feature selector for col prot
2023-01-04 21:56:08,483 INFO:     None feature selector for col chem
2023-01-04 21:56:08,483 INFO:     None feature selector for col chem
2023-01-04 21:56:08,483 INFO:     None feature selector for col chem
2023-01-04 21:56:08,483 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 21:56:08,483 INFO:   Starting stage: BUILD MODEL
2023-01-04 21:56:08,484 INFO:     Number of params in model 72931
2023-01-04 21:56:08,488 INFO:   Done with stage: BUILD MODEL
2023-01-04 21:56:08,488 INFO:   Starting stage: TRAINING
2023-01-04 21:56:08,532 INFO:     Val loss before train {'Reaction outcome loss': 0.9778772910435994, 'Total loss': 0.9778772910435994}
2023-01-04 21:56:08,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:08,532 INFO:     Epoch: 0
2023-01-04 21:56:10,572 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7434745709101359, 'Total loss': 0.7434745709101359} | train loss {'Reaction outcome loss': 0.9352917848494802, 'Total loss': 0.9352917848494802}
2023-01-04 21:56:10,573 INFO:     Found new best model at epoch 0
2023-01-04 21:56:10,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:10,574 INFO:     Epoch: 1
2023-01-04 21:56:12,796 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5474715769290924, 'Total loss': 0.5474715769290924} | train loss {'Reaction outcome loss': 0.6437093563867311, 'Total loss': 0.6437093563867311}
2023-01-04 21:56:12,797 INFO:     Found new best model at epoch 1
2023-01-04 21:56:12,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:12,799 INFO:     Epoch: 2
2023-01-04 21:56:15,090 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5174167394638062, 'Total loss': 0.5174167394638062} | train loss {'Reaction outcome loss': 0.5435588246170622, 'Total loss': 0.5435588246170622}
2023-01-04 21:56:15,090 INFO:     Found new best model at epoch 2
2023-01-04 21:56:15,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:15,092 INFO:     Epoch: 3
2023-01-04 21:56:17,274 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5005266845226288, 'Total loss': 0.5005266845226288} | train loss {'Reaction outcome loss': 0.5043776559024832, 'Total loss': 0.5043776559024832}
2023-01-04 21:56:17,275 INFO:     Found new best model at epoch 3
2023-01-04 21:56:17,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:17,277 INFO:     Epoch: 4
2023-01-04 21:56:19,474 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47697200377782184, 'Total loss': 0.47697200377782184} | train loss {'Reaction outcome loss': 0.4807148125484912, 'Total loss': 0.4807148125484912}
2023-01-04 21:56:19,475 INFO:     Found new best model at epoch 4
2023-01-04 21:56:19,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:19,476 INFO:     Epoch: 5
2023-01-04 21:56:21,646 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4759777357180913, 'Total loss': 0.4759777357180913} | train loss {'Reaction outcome loss': 0.4590369456984701, 'Total loss': 0.4590369456984701}
2023-01-04 21:56:21,646 INFO:     Found new best model at epoch 5
2023-01-04 21:56:21,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:21,647 INFO:     Epoch: 6
2023-01-04 21:56:23,825 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4502287040154139, 'Total loss': 0.4502287040154139} | train loss {'Reaction outcome loss': 0.4428522236590838, 'Total loss': 0.4428522236590838}
2023-01-04 21:56:23,827 INFO:     Found new best model at epoch 6
2023-01-04 21:56:23,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:23,828 INFO:     Epoch: 7
2023-01-04 21:56:26,000 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45488004783789315, 'Total loss': 0.45488004783789315} | train loss {'Reaction outcome loss': 0.42477263309007146, 'Total loss': 0.42477263309007146}
2023-01-04 21:56:26,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:26,000 INFO:     Epoch: 8
2023-01-04 21:56:28,150 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4182259142398834, 'Total loss': 0.4182259142398834} | train loss {'Reaction outcome loss': 0.41082677234263315, 'Total loss': 0.41082677234263315}
2023-01-04 21:56:28,150 INFO:     Found new best model at epoch 8
2023-01-04 21:56:28,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:28,152 INFO:     Epoch: 9
2023-01-04 21:56:30,352 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42361491719881694, 'Total loss': 0.42361491719881694} | train loss {'Reaction outcome loss': 0.3986692385353746, 'Total loss': 0.3986692385353746}
2023-01-04 21:56:30,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:30,353 INFO:     Epoch: 10
2023-01-04 21:56:32,610 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4217361479997635, 'Total loss': 0.4217361479997635} | train loss {'Reaction outcome loss': 0.3846827987173613, 'Total loss': 0.3846827987173613}
2023-01-04 21:56:32,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:32,610 INFO:     Epoch: 11
2023-01-04 21:56:34,788 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4229419161876043, 'Total loss': 0.4229419161876043} | train loss {'Reaction outcome loss': 0.37297355922034187, 'Total loss': 0.37297355922034187}
2023-01-04 21:56:34,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:34,789 INFO:     Epoch: 12
2023-01-04 21:56:36,967 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39888177315394086, 'Total loss': 0.39888177315394086} | train loss {'Reaction outcome loss': 0.36429986036824485, 'Total loss': 0.36429986036824485}
2023-01-04 21:56:36,967 INFO:     Found new best model at epoch 12
2023-01-04 21:56:36,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:36,969 INFO:     Epoch: 13
2023-01-04 21:56:39,152 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42230304380257927, 'Total loss': 0.42230304380257927} | train loss {'Reaction outcome loss': 0.3525131503052085, 'Total loss': 0.3525131503052085}
2023-01-04 21:56:39,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:39,152 INFO:     Epoch: 14
2023-01-04 21:56:41,244 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3980384935935338, 'Total loss': 0.3980384935935338} | train loss {'Reaction outcome loss': 0.35103967777677697, 'Total loss': 0.35103967777677697}
2023-01-04 21:56:41,246 INFO:     Found new best model at epoch 14
2023-01-04 21:56:41,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:41,247 INFO:     Epoch: 15
2023-01-04 21:56:43,404 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42731324434280393, 'Total loss': 0.42731324434280393} | train loss {'Reaction outcome loss': 0.3371733381229378, 'Total loss': 0.3371733381229378}
2023-01-04 21:56:43,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:43,404 INFO:     Epoch: 16
2023-01-04 21:56:45,570 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4038488775491714, 'Total loss': 0.4038488775491714} | train loss {'Reaction outcome loss': 0.33144926006504655, 'Total loss': 0.33144926006504655}
2023-01-04 21:56:45,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:45,571 INFO:     Epoch: 17
2023-01-04 21:56:47,770 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41944799025853474, 'Total loss': 0.41944799025853474} | train loss {'Reaction outcome loss': 0.3208158052098142, 'Total loss': 0.3208158052098142}
2023-01-04 21:56:47,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:47,771 INFO:     Epoch: 18
2023-01-04 21:56:49,989 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4112587203582128, 'Total loss': 0.4112587203582128} | train loss {'Reaction outcome loss': 0.3214503856661328, 'Total loss': 0.3214503856661328}
2023-01-04 21:56:49,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:49,989 INFO:     Epoch: 19
2023-01-04 21:56:53,238 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4455284217993418, 'Total loss': 0.4455284217993418} | train loss {'Reaction outcome loss': 0.3051604176769509, 'Total loss': 0.3051604176769509}
2023-01-04 21:56:53,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:53,239 INFO:     Epoch: 20
2023-01-04 21:56:55,438 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43770560522874197, 'Total loss': 0.43770560522874197} | train loss {'Reaction outcome loss': 0.3021588958256001, 'Total loss': 0.3021588958256001}
2023-01-04 21:56:55,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:55,438 INFO:     Epoch: 21
2023-01-04 21:56:57,651 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4176041026910146, 'Total loss': 0.4176041026910146} | train loss {'Reaction outcome loss': 0.2948060489538377, 'Total loss': 0.2948060489538377}
2023-01-04 21:56:57,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:57,651 INFO:     Epoch: 22
2023-01-04 21:56:59,885 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4269849677880605, 'Total loss': 0.4269849677880605} | train loss {'Reaction outcome loss': 0.28875400977086846, 'Total loss': 0.28875400977086846}
2023-01-04 21:56:59,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:56:59,886 INFO:     Epoch: 23
2023-01-04 21:57:02,070 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41846020420392355, 'Total loss': 0.41846020420392355} | train loss {'Reaction outcome loss': 0.2863475953425913, 'Total loss': 0.2863475953425913}
2023-01-04 21:57:02,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:02,070 INFO:     Epoch: 24
2023-01-04 21:57:04,242 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40970592498779296, 'Total loss': 0.40970592498779296} | train loss {'Reaction outcome loss': 0.2797250477461158, 'Total loss': 0.2797250477461158}
2023-01-04 21:57:04,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:04,244 INFO:     Epoch: 25
2023-01-04 21:57:06,432 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4218817998965581, 'Total loss': 0.4218817998965581} | train loss {'Reaction outcome loss': 0.2773906753881134, 'Total loss': 0.2773906753881134}
2023-01-04 21:57:06,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:06,432 INFO:     Epoch: 26
2023-01-04 21:57:08,607 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41167913178602855, 'Total loss': 0.41167913178602855} | train loss {'Reaction outcome loss': 0.2735686603879189, 'Total loss': 0.2735686603879189}
2023-01-04 21:57:08,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:08,607 INFO:     Epoch: 27
2023-01-04 21:57:10,800 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.426442089676857, 'Total loss': 0.426442089676857} | train loss {'Reaction outcome loss': 0.2639690883131358, 'Total loss': 0.2639690883131358}
2023-01-04 21:57:10,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:10,801 INFO:     Epoch: 28
2023-01-04 21:57:12,985 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.429816772043705, 'Total loss': 0.429816772043705} | train loss {'Reaction outcome loss': 0.26712288015460883, 'Total loss': 0.26712288015460883}
2023-01-04 21:57:12,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:12,985 INFO:     Epoch: 29
2023-01-04 21:57:15,148 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44819396634896597, 'Total loss': 0.44819396634896597} | train loss {'Reaction outcome loss': 0.25641650903670893, 'Total loss': 0.25641650903670893}
2023-01-04 21:57:15,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:15,149 INFO:     Epoch: 30
2023-01-04 21:57:17,367 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4228136976559957, 'Total loss': 0.4228136976559957} | train loss {'Reaction outcome loss': 0.2577235954847649, 'Total loss': 0.2577235954847649}
2023-01-04 21:57:17,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:17,368 INFO:     Epoch: 31
2023-01-04 21:57:19,590 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44418861319621405, 'Total loss': 0.44418861319621405} | train loss {'Reaction outcome loss': 0.2514686943541696, 'Total loss': 0.2514686943541696}
2023-01-04 21:57:19,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:19,590 INFO:     Epoch: 32
2023-01-04 21:57:21,782 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.454623818397522, 'Total loss': 0.454623818397522} | train loss {'Reaction outcome loss': 0.25239968209452657, 'Total loss': 0.25239968209452657}
2023-01-04 21:57:21,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:21,782 INFO:     Epoch: 33
2023-01-04 21:57:23,976 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43843903541564944, 'Total loss': 0.43843903541564944} | train loss {'Reaction outcome loss': 0.24735414377502063, 'Total loss': 0.24735414377502063}
2023-01-04 21:57:23,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:23,977 INFO:     Epoch: 34
2023-01-04 21:57:26,151 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4428599298000336, 'Total loss': 0.4428599298000336} | train loss {'Reaction outcome loss': 0.24012562440178037, 'Total loss': 0.24012562440178037}
2023-01-04 21:57:26,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:26,151 INFO:     Epoch: 35
2023-01-04 21:57:28,331 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4616987903912862, 'Total loss': 0.4616987903912862} | train loss {'Reaction outcome loss': 0.2451065298523346, 'Total loss': 0.2451065298523346}
2023-01-04 21:57:28,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:28,332 INFO:     Epoch: 36
2023-01-04 21:57:30,518 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41826958196858566, 'Total loss': 0.41826958196858566} | train loss {'Reaction outcome loss': 0.2408383910945297, 'Total loss': 0.2408383910945297}
2023-01-04 21:57:30,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:30,518 INFO:     Epoch: 37
2023-01-04 21:57:32,698 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41592920472224554, 'Total loss': 0.41592920472224554} | train loss {'Reaction outcome loss': 0.239519069046054, 'Total loss': 0.239519069046054}
2023-01-04 21:57:32,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:32,698 INFO:     Epoch: 38
2023-01-04 21:57:34,894 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43353168964385985, 'Total loss': 0.43353168964385985} | train loss {'Reaction outcome loss': 0.23464821074429873, 'Total loss': 0.23464821074429873}
2023-01-04 21:57:34,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:34,895 INFO:     Epoch: 39
2023-01-04 21:57:37,076 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4194230119387309, 'Total loss': 0.4194230119387309} | train loss {'Reaction outcome loss': 0.2316947933082489, 'Total loss': 0.2316947933082489}
2023-01-04 21:57:37,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:37,077 INFO:     Epoch: 40
2023-01-04 21:57:39,273 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43578529357910156, 'Total loss': 0.43578529357910156} | train loss {'Reaction outcome loss': 0.23221016793518606, 'Total loss': 0.23221016793518606}
2023-01-04 21:57:39,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:39,275 INFO:     Epoch: 41
2023-01-04 21:57:41,466 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4415031403303146, 'Total loss': 0.4415031403303146} | train loss {'Reaction outcome loss': 0.22569272739228105, 'Total loss': 0.22569272739228105}
2023-01-04 21:57:41,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:41,467 INFO:     Epoch: 42
2023-01-04 21:57:43,645 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4228999249637127, 'Total loss': 0.4228999249637127} | train loss {'Reaction outcome loss': 0.2260691257071321, 'Total loss': 0.2260691257071321}
2023-01-04 21:57:43,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:43,645 INFO:     Epoch: 43
2023-01-04 21:57:45,842 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45352037648359933, 'Total loss': 0.45352037648359933} | train loss {'Reaction outcome loss': 0.2203800259429934, 'Total loss': 0.2203800259429934}
2023-01-04 21:57:45,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:45,843 INFO:     Epoch: 44
2023-01-04 21:57:48,033 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42189869632323584, 'Total loss': 0.42189869632323584} | train loss {'Reaction outcome loss': 0.2193407318724768, 'Total loss': 0.2193407318724768}
2023-01-04 21:57:48,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:48,034 INFO:     Epoch: 45
2023-01-04 21:57:50,223 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4169502089576175, 'Total loss': 0.4169502089576175} | train loss {'Reaction outcome loss': 0.21760061366932235, 'Total loss': 0.21760061366932235}
2023-01-04 21:57:50,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:50,224 INFO:     Epoch: 46
2023-01-04 21:57:52,418 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43426171044508616, 'Total loss': 0.43426171044508616} | train loss {'Reaction outcome loss': 0.21456382443693323, 'Total loss': 0.21456382443693323}
2023-01-04 21:57:52,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:52,418 INFO:     Epoch: 47
2023-01-04 21:57:54,605 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4271960442264875, 'Total loss': 0.4271960442264875} | train loss {'Reaction outcome loss': 0.2120833249599503, 'Total loss': 0.2120833249599503}
2023-01-04 21:57:54,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:54,605 INFO:     Epoch: 48
2023-01-04 21:57:56,807 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46945700645446775, 'Total loss': 0.46945700645446775} | train loss {'Reaction outcome loss': 0.21092761468726898, 'Total loss': 0.21092761468726898}
2023-01-04 21:57:56,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:56,808 INFO:     Epoch: 49
2023-01-04 21:57:59,006 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4428299327691396, 'Total loss': 0.4428299327691396} | train loss {'Reaction outcome loss': 0.2106452858021116, 'Total loss': 0.2106452858021116}
2023-01-04 21:57:59,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:57:59,006 INFO:     Epoch: 50
2023-01-04 21:58:01,204 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39934985935688017, 'Total loss': 0.39934985935688017} | train loss {'Reaction outcome loss': 0.21038569807734367, 'Total loss': 0.21038569807734367}
2023-01-04 21:58:01,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:01,206 INFO:     Epoch: 51
2023-01-04 21:58:03,408 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48122071524461113, 'Total loss': 0.48122071524461113} | train loss {'Reaction outcome loss': 0.2119534619383677, 'Total loss': 0.2119534619383677}
2023-01-04 21:58:03,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:03,409 INFO:     Epoch: 52
2023-01-04 21:58:05,609 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44667062163352966, 'Total loss': 0.44667062163352966} | train loss {'Reaction outcome loss': 0.20942400637198322, 'Total loss': 0.20942400637198322}
2023-01-04 21:58:05,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:05,609 INFO:     Epoch: 53
2023-01-04 21:58:07,810 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46201626857121786, 'Total loss': 0.46201626857121786} | train loss {'Reaction outcome loss': 0.2034171120566146, 'Total loss': 0.2034171120566146}
2023-01-04 21:58:07,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:07,812 INFO:     Epoch: 54
2023-01-04 21:58:10,008 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4670700376232465, 'Total loss': 0.4670700376232465} | train loss {'Reaction outcome loss': 0.20525888555146155, 'Total loss': 0.20525888555146155}
2023-01-04 21:58:10,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:10,008 INFO:     Epoch: 55
2023-01-04 21:58:12,201 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47478888034820554, 'Total loss': 0.47478888034820554} | train loss {'Reaction outcome loss': 0.19921542149390617, 'Total loss': 0.19921542149390617}
2023-01-04 21:58:12,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:12,201 INFO:     Epoch: 56
2023-01-04 21:58:14,397 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4850329299767812, 'Total loss': 0.4850329299767812} | train loss {'Reaction outcome loss': 0.19549929819334924, 'Total loss': 0.19549929819334924}
2023-01-04 21:58:14,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:14,398 INFO:     Epoch: 57
2023-01-04 21:58:16,591 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.440061542019248, 'Total loss': 0.440061542019248} | train loss {'Reaction outcome loss': 0.2015295076102399, 'Total loss': 0.2015295076102399}
2023-01-04 21:58:16,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:16,591 INFO:     Epoch: 58
2023-01-04 21:58:18,768 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4728858749071757, 'Total loss': 0.4728858749071757} | train loss {'Reaction outcome loss': 0.19716837390047245, 'Total loss': 0.19716837390047245}
2023-01-04 21:58:18,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:18,768 INFO:     Epoch: 59
2023-01-04 21:58:20,945 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45977730825543406, 'Total loss': 0.45977730825543406} | train loss {'Reaction outcome loss': 0.19716948191261421, 'Total loss': 0.19716948191261421}
2023-01-04 21:58:20,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:20,946 INFO:     Epoch: 60
2023-01-04 21:58:23,128 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45549421906471255, 'Total loss': 0.45549421906471255} | train loss {'Reaction outcome loss': 0.19343165408507207, 'Total loss': 0.19343165408507207}
2023-01-04 21:58:23,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:23,128 INFO:     Epoch: 61
2023-01-04 21:58:25,314 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48790360912680625, 'Total loss': 0.48790360912680625} | train loss {'Reaction outcome loss': 0.19372877250527487, 'Total loss': 0.19372877250527487}
2023-01-04 21:58:25,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:25,316 INFO:     Epoch: 62
2023-01-04 21:58:27,506 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4548938194910685, 'Total loss': 0.4548938194910685} | train loss {'Reaction outcome loss': 0.19468706173917455, 'Total loss': 0.19468706173917455}
2023-01-04 21:58:27,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:27,507 INFO:     Epoch: 63
2023-01-04 21:58:29,677 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43803054715196293, 'Total loss': 0.43803054715196293} | train loss {'Reaction outcome loss': 0.19441500273499177, 'Total loss': 0.19441500273499177}
2023-01-04 21:58:29,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:29,677 INFO:     Epoch: 64
2023-01-04 21:58:31,856 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44600453128417333, 'Total loss': 0.44600453128417333} | train loss {'Reaction outcome loss': 0.19216196084680565, 'Total loss': 0.19216196084680565}
2023-01-04 21:58:31,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:31,857 INFO:     Epoch: 65
2023-01-04 21:58:34,033 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44676916897296903, 'Total loss': 0.44676916897296903} | train loss {'Reaction outcome loss': 0.1928290689812742, 'Total loss': 0.1928290689812742}
2023-01-04 21:58:34,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:34,034 INFO:     Epoch: 66
2023-01-04 21:58:36,218 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4328311763703823, 'Total loss': 0.4328311763703823} | train loss {'Reaction outcome loss': 0.19001651714372375, 'Total loss': 0.19001651714372375}
2023-01-04 21:58:36,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:36,220 INFO:     Epoch: 67
2023-01-04 21:58:38,413 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4517150819301605, 'Total loss': 0.4517150819301605} | train loss {'Reaction outcome loss': 0.18949773381838073, 'Total loss': 0.18949773381838073}
2023-01-04 21:58:38,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:38,413 INFO:     Epoch: 68
2023-01-04 21:58:40,587 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45027684544523555, 'Total loss': 0.45027684544523555} | train loss {'Reaction outcome loss': 0.18468886516294883, 'Total loss': 0.18468886516294883}
2023-01-04 21:58:40,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:40,588 INFO:     Epoch: 69
2023-01-04 21:58:42,789 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4422544141610463, 'Total loss': 0.4422544141610463} | train loss {'Reaction outcome loss': 0.18391629252038952, 'Total loss': 0.18391629252038952}
2023-01-04 21:58:42,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:42,790 INFO:     Epoch: 70
2023-01-04 21:58:44,980 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45919856826464334, 'Total loss': 0.45919856826464334} | train loss {'Reaction outcome loss': 0.1842229765751501, 'Total loss': 0.1842229765751501}
2023-01-04 21:58:44,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:44,981 INFO:     Epoch: 71
2023-01-04 21:58:47,155 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4974271714687347, 'Total loss': 0.4974271714687347} | train loss {'Reaction outcome loss': 0.18406632761335015, 'Total loss': 0.18406632761335015}
2023-01-04 21:58:47,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:47,155 INFO:     Epoch: 72
2023-01-04 21:58:49,329 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4985711211959521, 'Total loss': 0.4985711211959521} | train loss {'Reaction outcome loss': 0.18558066101561227, 'Total loss': 0.18558066101561227}
2023-01-04 21:58:49,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:49,330 INFO:     Epoch: 73
2023-01-04 21:58:51,505 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4631396695971489, 'Total loss': 0.4631396695971489} | train loss {'Reaction outcome loss': 0.18525999615709876, 'Total loss': 0.18525999615709876}
2023-01-04 21:58:51,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:51,506 INFO:     Epoch: 74
2023-01-04 21:58:53,685 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45710368156433107, 'Total loss': 0.45710368156433107} | train loss {'Reaction outcome loss': 0.18324942998995963, 'Total loss': 0.18324942998995963}
2023-01-04 21:58:53,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:53,686 INFO:     Epoch: 75
2023-01-04 21:58:55,875 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.462089600165685, 'Total loss': 0.462089600165685} | train loss {'Reaction outcome loss': 0.18392071431930973, 'Total loss': 0.18392071431930973}
2023-01-04 21:58:55,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:55,877 INFO:     Epoch: 76
2023-01-04 21:58:58,057 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4790365849932035, 'Total loss': 0.4790365849932035} | train loss {'Reaction outcome loss': 0.18108421679667747, 'Total loss': 0.18108421679667747}
2023-01-04 21:58:58,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:58:58,058 INFO:     Epoch: 77
2023-01-04 21:59:00,242 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4413392961025238, 'Total loss': 0.4413392961025238} | train loss {'Reaction outcome loss': 0.18353866993102932, 'Total loss': 0.18353866993102932}
2023-01-04 21:59:00,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:00,242 INFO:     Epoch: 78
2023-01-04 21:59:02,430 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45972453951835635, 'Total loss': 0.45972453951835635} | train loss {'Reaction outcome loss': 0.18072077115304278, 'Total loss': 0.18072077115304278}
2023-01-04 21:59:02,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:02,431 INFO:     Epoch: 79
2023-01-04 21:59:04,605 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.486263873676459, 'Total loss': 0.486263873676459} | train loss {'Reaction outcome loss': 0.18275689308014936, 'Total loss': 0.18275689308014936}
2023-01-04 21:59:04,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:04,606 INFO:     Epoch: 80
2023-01-04 21:59:06,787 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4562339608867963, 'Total loss': 0.4562339608867963} | train loss {'Reaction outcome loss': 0.1788934509059156, 'Total loss': 0.1788934509059156}
2023-01-04 21:59:06,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:06,787 INFO:     Epoch: 81
2023-01-04 21:59:08,961 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47583880126476286, 'Total loss': 0.47583880126476286} | train loss {'Reaction outcome loss': 0.18032794468016466, 'Total loss': 0.18032794468016466}
2023-01-04 21:59:08,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:08,963 INFO:     Epoch: 82
2023-01-04 21:59:11,158 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47730929851531984, 'Total loss': 0.47730929851531984} | train loss {'Reaction outcome loss': 0.17362563894640137, 'Total loss': 0.17362563894640137}
2023-01-04 21:59:11,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:11,158 INFO:     Epoch: 83
2023-01-04 21:59:13,345 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.489595635732015, 'Total loss': 0.489595635732015} | train loss {'Reaction outcome loss': 0.17801914439302102, 'Total loss': 0.17801914439302102}
2023-01-04 21:59:13,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:13,345 INFO:     Epoch: 84
2023-01-04 21:59:15,523 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46244280139605204, 'Total loss': 0.46244280139605204} | train loss {'Reaction outcome loss': 0.17998156918851782, 'Total loss': 0.17998156918851782}
2023-01-04 21:59:15,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:15,524 INFO:     Epoch: 85
2023-01-04 21:59:17,715 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4405419717232386, 'Total loss': 0.4405419717232386} | train loss {'Reaction outcome loss': 0.17607735667758398, 'Total loss': 0.17607735667758398}
2023-01-04 21:59:17,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:17,715 INFO:     Epoch: 86
2023-01-04 21:59:19,915 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45972891052563986, 'Total loss': 0.45972891052563986} | train loss {'Reaction outcome loss': 0.17436308156950467, 'Total loss': 0.17436308156950467}
2023-01-04 21:59:19,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:19,916 INFO:     Epoch: 87
2023-01-04 21:59:22,118 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45893269081910454, 'Total loss': 0.45893269081910454} | train loss {'Reaction outcome loss': 0.1707825523921812, 'Total loss': 0.1707825523921812}
2023-01-04 21:59:22,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:22,120 INFO:     Epoch: 88
2023-01-04 21:59:24,287 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4827039768298467, 'Total loss': 0.4827039768298467} | train loss {'Reaction outcome loss': 0.1735538508688664, 'Total loss': 0.1735538508688664}
2023-01-04 21:59:24,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:24,288 INFO:     Epoch: 89
2023-01-04 21:59:26,454 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46541986962159476, 'Total loss': 0.46541986962159476} | train loss {'Reaction outcome loss': 0.17452076925168725, 'Total loss': 0.17452076925168725}
2023-01-04 21:59:26,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:26,454 INFO:     Epoch: 90
2023-01-04 21:59:28,647 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4571378973623117, 'Total loss': 0.4571378973623117} | train loss {'Reaction outcome loss': 0.1733405695833864, 'Total loss': 0.1733405695833864}
2023-01-04 21:59:28,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:28,648 INFO:     Epoch: 91
2023-01-04 21:59:30,812 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44736763288577397, 'Total loss': 0.44736763288577397} | train loss {'Reaction outcome loss': 0.17339744116009695, 'Total loss': 0.17339744116009695}
2023-01-04 21:59:30,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:30,812 INFO:     Epoch: 92
2023-01-04 21:59:32,999 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43531851669152577, 'Total loss': 0.43531851669152577} | train loss {'Reaction outcome loss': 0.17327491957252425, 'Total loss': 0.17327491957252425}
2023-01-04 21:59:33,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:33,000 INFO:     Epoch: 93
2023-01-04 21:59:35,170 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47528451681137085, 'Total loss': 0.47528451681137085} | train loss {'Reaction outcome loss': 0.16946473704773363, 'Total loss': 0.16946473704773363}
2023-01-04 21:59:35,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:35,170 INFO:     Epoch: 94
2023-01-04 21:59:37,357 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4523715709646543, 'Total loss': 0.4523715709646543} | train loss {'Reaction outcome loss': 0.16980856139362402, 'Total loss': 0.16980856139362402}
2023-01-04 21:59:37,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:37,357 INFO:     Epoch: 95
2023-01-04 21:59:39,535 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4325764795144399, 'Total loss': 0.4325764795144399} | train loss {'Reaction outcome loss': 0.16535687571761953, 'Total loss': 0.16535687571761953}
2023-01-04 21:59:39,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:39,537 INFO:     Epoch: 96
2023-01-04 21:59:41,733 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47663684089978536, 'Total loss': 0.47663684089978536} | train loss {'Reaction outcome loss': 0.16731219978010567, 'Total loss': 0.16731219978010567}
2023-01-04 21:59:41,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:41,733 INFO:     Epoch: 97
2023-01-04 21:59:43,926 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49020695288976035, 'Total loss': 0.49020695288976035} | train loss {'Reaction outcome loss': 0.16521418611960906, 'Total loss': 0.16521418611960906}
2023-01-04 21:59:43,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:43,928 INFO:     Epoch: 98
2023-01-04 21:59:46,125 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4529159352183342, 'Total loss': 0.4529159352183342} | train loss {'Reaction outcome loss': 0.1694433695558513, 'Total loss': 0.1694433695558513}
2023-01-04 21:59:46,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:46,125 INFO:     Epoch: 99
2023-01-04 21:59:48,319 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45291127764309447, 'Total loss': 0.45291127764309447} | train loss {'Reaction outcome loss': 0.1680886731007184, 'Total loss': 0.1680886731007184}
2023-01-04 21:59:48,319 INFO:     Best model found after epoch 15 of 100.
2023-01-04 21:59:48,319 INFO:   Done with stage: TRAINING
2023-01-04 21:59:48,319 INFO:   Starting stage: EVALUATION
2023-01-04 21:59:48,460 INFO:   Done with stage: EVALUATION
2023-01-04 21:59:48,460 INFO:   Leaving out SEQ value Fold_4
2023-01-04 21:59:48,473 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 21:59:48,473 INFO:   Starting stage: FEATURE SCALING
2023-01-04 21:59:49,119 INFO:   Done with stage: FEATURE SCALING
2023-01-04 21:59:49,120 INFO:   Starting stage: SCALING TARGETS
2023-01-04 21:59:49,191 INFO:   Done with stage: SCALING TARGETS
2023-01-04 21:59:49,191 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 21:59:49,192 INFO:     No hyperparam tuning for this model
2023-01-04 21:59:49,192 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 21:59:49,192 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 21:59:49,192 INFO:     None feature selector for col prot
2023-01-04 21:59:49,193 INFO:     None feature selector for col prot
2023-01-04 21:59:49,193 INFO:     None feature selector for col prot
2023-01-04 21:59:49,193 INFO:     None feature selector for col chem
2023-01-04 21:59:49,193 INFO:     None feature selector for col chem
2023-01-04 21:59:49,193 INFO:     None feature selector for col chem
2023-01-04 21:59:49,193 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 21:59:49,193 INFO:   Starting stage: BUILD MODEL
2023-01-04 21:59:49,195 INFO:     Number of params in model 72931
2023-01-04 21:59:49,198 INFO:   Done with stage: BUILD MODEL
2023-01-04 21:59:49,198 INFO:   Starting stage: TRAINING
2023-01-04 21:59:49,258 INFO:     Val loss before train {'Reaction outcome loss': 1.0193548619747161, 'Total loss': 1.0193548619747161}
2023-01-04 21:59:49,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:49,258 INFO:     Epoch: 0
2023-01-04 21:59:51,444 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7399527788162231, 'Total loss': 0.7399527788162231} | train loss {'Reaction outcome loss': 0.9592702666120808, 'Total loss': 0.9592702666120808}
2023-01-04 21:59:51,444 INFO:     Found new best model at epoch 0
2023-01-04 21:59:51,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:51,446 INFO:     Epoch: 1
2023-01-04 21:59:53,625 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5528992672761281, 'Total loss': 0.5528992672761281} | train loss {'Reaction outcome loss': 0.62106317939767, 'Total loss': 0.62106317939767}
2023-01-04 21:59:53,625 INFO:     Found new best model at epoch 1
2023-01-04 21:59:53,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:53,627 INFO:     Epoch: 2
2023-01-04 21:59:55,828 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5218691805998484, 'Total loss': 0.5218691805998484} | train loss {'Reaction outcome loss': 0.5209918265251348, 'Total loss': 0.5209918265251348}
2023-01-04 21:59:55,829 INFO:     Found new best model at epoch 2
2023-01-04 21:59:55,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:55,831 INFO:     Epoch: 3
2023-01-04 21:59:58,008 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47138619124889375, 'Total loss': 0.47138619124889375} | train loss {'Reaction outcome loss': 0.4750855801640636, 'Total loss': 0.4750855801640636}
2023-01-04 21:59:58,008 INFO:     Found new best model at epoch 3
2023-01-04 21:59:58,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 21:59:58,010 INFO:     Epoch: 4
2023-01-04 22:00:00,201 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45270140369733175, 'Total loss': 0.45270140369733175} | train loss {'Reaction outcome loss': 0.44854346736177914, 'Total loss': 0.44854346736177914}
2023-01-04 22:00:00,202 INFO:     Found new best model at epoch 4
2023-01-04 22:00:00,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:00,204 INFO:     Epoch: 5
2023-01-04 22:00:02,360 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46308502554893494, 'Total loss': 0.46308502554893494} | train loss {'Reaction outcome loss': 0.4283701756248509, 'Total loss': 0.4283701756248509}
2023-01-04 22:00:02,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:02,360 INFO:     Epoch: 6
2023-01-04 22:00:04,535 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4321310887734095, 'Total loss': 0.4321310887734095} | train loss {'Reaction outcome loss': 0.4132789067488952, 'Total loss': 0.4132789067488952}
2023-01-04 22:00:04,535 INFO:     Found new best model at epoch 6
2023-01-04 22:00:04,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:04,537 INFO:     Epoch: 7
2023-01-04 22:00:06,723 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43796473840872446, 'Total loss': 0.43796473840872446} | train loss {'Reaction outcome loss': 0.4037188756803091, 'Total loss': 0.4037188756803091}
2023-01-04 22:00:06,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:06,724 INFO:     Epoch: 8
2023-01-04 22:00:08,883 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4467427333196004, 'Total loss': 0.4467427333196004} | train loss {'Reaction outcome loss': 0.3860842660341385, 'Total loss': 0.3860842660341385}
2023-01-04 22:00:08,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:08,883 INFO:     Epoch: 9
2023-01-04 22:00:11,029 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4483928859233856, 'Total loss': 0.4483928859233856} | train loss {'Reaction outcome loss': 0.37828367440043575, 'Total loss': 0.37828367440043575}
2023-01-04 22:00:11,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:11,029 INFO:     Epoch: 10
2023-01-04 22:00:13,230 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44136237998803457, 'Total loss': 0.44136237998803457} | train loss {'Reaction outcome loss': 0.37411272691657943, 'Total loss': 0.37411272691657943}
2023-01-04 22:00:13,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:13,232 INFO:     Epoch: 11
2023-01-04 22:00:15,432 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4138573189576467, 'Total loss': 0.4138573189576467} | train loss {'Reaction outcome loss': 0.35881485444677136, 'Total loss': 0.35881485444677136}
2023-01-04 22:00:15,433 INFO:     Found new best model at epoch 11
2023-01-04 22:00:15,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:15,434 INFO:     Epoch: 12
2023-01-04 22:00:17,631 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3965845500429471, 'Total loss': 0.3965845500429471} | train loss {'Reaction outcome loss': 0.3557367039042233, 'Total loss': 0.3557367039042233}
2023-01-04 22:00:17,632 INFO:     Found new best model at epoch 12
2023-01-04 22:00:17,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:17,633 INFO:     Epoch: 13
2023-01-04 22:00:19,820 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4088214417298635, 'Total loss': 0.4088214417298635} | train loss {'Reaction outcome loss': 0.3463094666273925, 'Total loss': 0.3463094666273925}
2023-01-04 22:00:19,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:19,820 INFO:     Epoch: 14
2023-01-04 22:00:21,998 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4154522821307182, 'Total loss': 0.4154522821307182} | train loss {'Reaction outcome loss': 0.3341974469758298, 'Total loss': 0.3341974469758298}
2023-01-04 22:00:21,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:21,998 INFO:     Epoch: 15
2023-01-04 22:00:24,180 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4143693298101425, 'Total loss': 0.4143693298101425} | train loss {'Reaction outcome loss': 0.3264782795560186, 'Total loss': 0.3264782795560186}
2023-01-04 22:00:24,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:24,182 INFO:     Epoch: 16
2023-01-04 22:00:26,222 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4160782014330228, 'Total loss': 0.4160782014330228} | train loss {'Reaction outcome loss': 0.3249511462058464, 'Total loss': 0.3249511462058464}
2023-01-04 22:00:26,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:26,222 INFO:     Epoch: 17
2023-01-04 22:00:28,431 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42372440695762636, 'Total loss': 0.42372440695762636} | train loss {'Reaction outcome loss': 0.3187565878033638, 'Total loss': 0.3187565878033638}
2023-01-04 22:00:28,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:28,431 INFO:     Epoch: 18
2023-01-04 22:00:30,617 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4250536414484183, 'Total loss': 0.4250536414484183} | train loss {'Reaction outcome loss': 0.3123253579557377, 'Total loss': 0.3123253579557377}
2023-01-04 22:00:30,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:30,618 INFO:     Epoch: 19
2023-01-04 22:00:32,805 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4404898703098297, 'Total loss': 0.4404898703098297} | train loss {'Reaction outcome loss': 0.30419387694203504, 'Total loss': 0.30419387694203504}
2023-01-04 22:00:32,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:32,806 INFO:     Epoch: 20
2023-01-04 22:00:34,996 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4048508584499359, 'Total loss': 0.4048508584499359} | train loss {'Reaction outcome loss': 0.3005018127388763, 'Total loss': 0.3005018127388763}
2023-01-04 22:00:34,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:34,998 INFO:     Epoch: 21
2023-01-04 22:00:37,193 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43208003640174864, 'Total loss': 0.43208003640174864} | train loss {'Reaction outcome loss': 0.2967752322391437, 'Total loss': 0.2967752322391437}
2023-01-04 22:00:37,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:37,193 INFO:     Epoch: 22
2023-01-04 22:00:39,381 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40426696042219795, 'Total loss': 0.40426696042219795} | train loss {'Reaction outcome loss': 0.28959181407181017, 'Total loss': 0.28959181407181017}
2023-01-04 22:00:39,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:39,381 INFO:     Epoch: 23
2023-01-04 22:00:41,656 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44445642630259197, 'Total loss': 0.44445642630259197} | train loss {'Reaction outcome loss': 0.2848753810853419, 'Total loss': 0.2848753810853419}
2023-01-04 22:00:41,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:41,658 INFO:     Epoch: 24
2023-01-04 22:00:43,836 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4026864434281985, 'Total loss': 0.4026864434281985} | train loss {'Reaction outcome loss': 0.2756624662718416, 'Total loss': 0.2756624662718416}
2023-01-04 22:00:43,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:43,836 INFO:     Epoch: 25
2023-01-04 22:00:46,026 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.423660538593928, 'Total loss': 0.423660538593928} | train loss {'Reaction outcome loss': 0.2762574188846306, 'Total loss': 0.2762574188846306}
2023-01-04 22:00:46,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:46,027 INFO:     Epoch: 26
2023-01-04 22:00:48,176 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41205250322818754, 'Total loss': 0.41205250322818754} | train loss {'Reaction outcome loss': 0.27116327478557173, 'Total loss': 0.27116327478557173}
2023-01-04 22:00:48,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:48,178 INFO:     Epoch: 27
2023-01-04 22:00:50,343 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40013102094332376, 'Total loss': 0.40013102094332376} | train loss {'Reaction outcome loss': 0.2664496779278682, 'Total loss': 0.2664496779278682}
2023-01-04 22:00:50,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:50,343 INFO:     Epoch: 28
2023-01-04 22:00:52,492 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40043347974618276, 'Total loss': 0.40043347974618276} | train loss {'Reaction outcome loss': 0.26007431090204386, 'Total loss': 0.26007431090204386}
2023-01-04 22:00:52,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:52,493 INFO:     Epoch: 29
2023-01-04 22:00:54,645 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40806178748607635, 'Total loss': 0.40806178748607635} | train loss {'Reaction outcome loss': 0.2590175081234779, 'Total loss': 0.2590175081234779}
2023-01-04 22:00:54,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:54,646 INFO:     Epoch: 30
2023-01-04 22:00:56,808 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4330840369065603, 'Total loss': 0.4330840369065603} | train loss {'Reaction outcome loss': 0.25613909202498675, 'Total loss': 0.25613909202498675}
2023-01-04 22:00:56,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:56,808 INFO:     Epoch: 31
2023-01-04 22:00:58,962 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40363147954146067, 'Total loss': 0.40363147954146067} | train loss {'Reaction outcome loss': 0.24853228751814713, 'Total loss': 0.24853228751814713}
2023-01-04 22:00:58,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:00:58,962 INFO:     Epoch: 32
2023-01-04 22:01:01,135 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4519491950670878, 'Total loss': 0.4519491950670878} | train loss {'Reaction outcome loss': 0.249770684908722, 'Total loss': 0.249770684908722}
2023-01-04 22:01:01,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:01,136 INFO:     Epoch: 33
2023-01-04 22:01:03,306 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42015534937381743, 'Total loss': 0.42015534937381743} | train loss {'Reaction outcome loss': 0.24369856242063273, 'Total loss': 0.24369856242063273}
2023-01-04 22:01:03,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:03,307 INFO:     Epoch: 34
2023-01-04 22:01:05,499 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3960527366648118, 'Total loss': 0.3960527366648118} | train loss {'Reaction outcome loss': 0.24648865769161796, 'Total loss': 0.24648865769161796}
2023-01-04 22:01:05,499 INFO:     Found new best model at epoch 34
2023-01-04 22:01:05,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:05,500 INFO:     Epoch: 35
2023-01-04 22:01:07,676 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4096964110930761, 'Total loss': 0.4096964110930761} | train loss {'Reaction outcome loss': 0.2377736737788485, 'Total loss': 0.2377736737788485}
2023-01-04 22:01:07,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:07,677 INFO:     Epoch: 36
2023-01-04 22:01:09,851 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40850856304168703, 'Total loss': 0.40850856304168703} | train loss {'Reaction outcome loss': 0.237130299863154, 'Total loss': 0.237130299863154}
2023-01-04 22:01:09,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:09,851 INFO:     Epoch: 37
2023-01-04 22:01:12,007 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4192595683038235, 'Total loss': 0.4192595683038235} | train loss {'Reaction outcome loss': 0.23325558837136104, 'Total loss': 0.23325558837136104}
2023-01-04 22:01:12,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:12,008 INFO:     Epoch: 38
2023-01-04 22:01:14,165 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4198031355937322, 'Total loss': 0.4198031355937322} | train loss {'Reaction outcome loss': 0.22635779667129047, 'Total loss': 0.22635779667129047}
2023-01-04 22:01:14,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:14,165 INFO:     Epoch: 39
2023-01-04 22:01:16,327 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4020858213305473, 'Total loss': 0.4020858213305473} | train loss {'Reaction outcome loss': 0.23180590835773815, 'Total loss': 0.23180590835773815}
2023-01-04 22:01:16,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:16,327 INFO:     Epoch: 40
2023-01-04 22:01:18,511 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4097519010305405, 'Total loss': 0.4097519010305405} | train loss {'Reaction outcome loss': 0.22546420002995182, 'Total loss': 0.22546420002995182}
2023-01-04 22:01:18,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:18,512 INFO:     Epoch: 41
2023-01-04 22:01:20,698 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3989007562398911, 'Total loss': 0.3989007562398911} | train loss {'Reaction outcome loss': 0.22118908615551724, 'Total loss': 0.22118908615551724}
2023-01-04 22:01:20,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:20,698 INFO:     Epoch: 42
2023-01-04 22:01:22,882 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3802662839492162, 'Total loss': 0.3802662839492162} | train loss {'Reaction outcome loss': 0.21942902212609014, 'Total loss': 0.21942902212609014}
2023-01-04 22:01:22,883 INFO:     Found new best model at epoch 42
2023-01-04 22:01:22,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:22,884 INFO:     Epoch: 43
2023-01-04 22:01:25,059 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39192753930886587, 'Total loss': 0.39192753930886587} | train loss {'Reaction outcome loss': 0.22062188249937917, 'Total loss': 0.22062188249937917}
2023-01-04 22:01:25,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:25,059 INFO:     Epoch: 44
2023-01-04 22:01:27,241 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4182103435198466, 'Total loss': 0.4182103435198466} | train loss {'Reaction outcome loss': 0.21495872692470133, 'Total loss': 0.21495872692470133}
2023-01-04 22:01:27,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:27,242 INFO:     Epoch: 45
2023-01-04 22:01:29,423 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4079132338364919, 'Total loss': 0.4079132338364919} | train loss {'Reaction outcome loss': 0.21536456856427946, 'Total loss': 0.21536456856427946}
2023-01-04 22:01:29,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:29,424 INFO:     Epoch: 46
2023-01-04 22:01:31,621 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43319128851095834, 'Total loss': 0.43319128851095834} | train loss {'Reaction outcome loss': 0.2148085331585068, 'Total loss': 0.2148085331585068}
2023-01-04 22:01:31,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:31,621 INFO:     Epoch: 47
2023-01-04 22:01:33,791 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39158389568328855, 'Total loss': 0.39158389568328855} | train loss {'Reaction outcome loss': 0.21352471964923245, 'Total loss': 0.21352471964923245}
2023-01-04 22:01:33,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:33,793 INFO:     Epoch: 48
2023-01-04 22:01:35,973 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4075909594694773, 'Total loss': 0.4075909594694773} | train loss {'Reaction outcome loss': 0.2067786489144294, 'Total loss': 0.2067786489144294}
2023-01-04 22:01:35,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:35,973 INFO:     Epoch: 49
2023-01-04 22:01:38,163 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4020215690135956, 'Total loss': 0.4020215690135956} | train loss {'Reaction outcome loss': 0.20842728332147328, 'Total loss': 0.20842728332147328}
2023-01-04 22:01:38,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:38,163 INFO:     Epoch: 50
2023-01-04 22:01:40,357 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40415563186009723, 'Total loss': 0.40415563186009723} | train loss {'Reaction outcome loss': 0.20990376895715068, 'Total loss': 0.20990376895715068}
2023-01-04 22:01:40,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:40,358 INFO:     Epoch: 51
2023-01-04 22:01:42,546 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41175157527128853, 'Total loss': 0.41175157527128853} | train loss {'Reaction outcome loss': 0.20157394795100728, 'Total loss': 0.20157394795100728}
2023-01-04 22:01:42,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:42,546 INFO:     Epoch: 52
2023-01-04 22:01:44,721 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4199204166730245, 'Total loss': 0.4199204166730245} | train loss {'Reaction outcome loss': 0.20166541976568692, 'Total loss': 0.20166541976568692}
2023-01-04 22:01:44,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:44,721 INFO:     Epoch: 53
2023-01-04 22:01:46,897 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4137033959229787, 'Total loss': 0.4137033959229787} | train loss {'Reaction outcome loss': 0.20121547513145166, 'Total loss': 0.20121547513145166}
2023-01-04 22:01:46,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:46,899 INFO:     Epoch: 54
2023-01-04 22:01:49,087 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40925353616476057, 'Total loss': 0.40925353616476057} | train loss {'Reaction outcome loss': 0.20394969177534328, 'Total loss': 0.20394969177534328}
2023-01-04 22:01:49,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:49,087 INFO:     Epoch: 55
2023-01-04 22:01:51,274 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.36774889019628365, 'Total loss': 0.36774889019628365} | train loss {'Reaction outcome loss': 0.20306369062703455, 'Total loss': 0.20306369062703455}
2023-01-04 22:01:51,274 INFO:     Found new best model at epoch 55
2023-01-04 22:01:51,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:51,275 INFO:     Epoch: 56
2023-01-04 22:01:53,454 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3767826790610949, 'Total loss': 0.3767826790610949} | train loss {'Reaction outcome loss': 0.1976081181868204, 'Total loss': 0.1976081181868204}
2023-01-04 22:01:53,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:53,455 INFO:     Epoch: 57
2023-01-04 22:01:55,638 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4073525369167328, 'Total loss': 0.4073525369167328} | train loss {'Reaction outcome loss': 0.1961688261315988, 'Total loss': 0.1961688261315988}
2023-01-04 22:01:55,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:55,639 INFO:     Epoch: 58
2023-01-04 22:01:57,785 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43823000192642214, 'Total loss': 0.43823000192642214} | train loss {'Reaction outcome loss': 0.18856929849670098, 'Total loss': 0.18856929849670098}
2023-01-04 22:01:57,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:57,785 INFO:     Epoch: 59
2023-01-04 22:01:59,971 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4188905636469523, 'Total loss': 0.4188905636469523} | train loss {'Reaction outcome loss': 0.1977487104931289, 'Total loss': 0.1977487104931289}
2023-01-04 22:01:59,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:01:59,973 INFO:     Epoch: 60
2023-01-04 22:02:02,145 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43431366483370465, 'Total loss': 0.43431366483370465} | train loss {'Reaction outcome loss': 0.19202297420859554, 'Total loss': 0.19202297420859554}
2023-01-04 22:02:02,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:02,145 INFO:     Epoch: 61
2023-01-04 22:02:04,337 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40060663868983587, 'Total loss': 0.40060663868983587} | train loss {'Reaction outcome loss': 0.18655305480870016, 'Total loss': 0.18655305480870016}
2023-01-04 22:02:04,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:04,338 INFO:     Epoch: 62
2023-01-04 22:02:06,574 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4109614501396815, 'Total loss': 0.4109614501396815} | train loss {'Reaction outcome loss': 0.18790438523121777, 'Total loss': 0.18790438523121777}
2023-01-04 22:02:06,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:06,575 INFO:     Epoch: 63
2023-01-04 22:02:08,776 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4396466722091039, 'Total loss': 0.4396466722091039} | train loss {'Reaction outcome loss': 0.18526749081066707, 'Total loss': 0.18526749081066707}
2023-01-04 22:02:08,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:08,777 INFO:     Epoch: 64
2023-01-04 22:02:11,011 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40986942847569785, 'Total loss': 0.40986942847569785} | train loss {'Reaction outcome loss': 0.18731641871378804, 'Total loss': 0.18731641871378804}
2023-01-04 22:02:11,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:11,012 INFO:     Epoch: 65
2023-01-04 22:02:13,211 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41564612835645676, 'Total loss': 0.41564612835645676} | train loss {'Reaction outcome loss': 0.182424895733894, 'Total loss': 0.182424895733894}
2023-01-04 22:02:13,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:13,212 INFO:     Epoch: 66
2023-01-04 22:02:15,391 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4389935071269671, 'Total loss': 0.4389935071269671} | train loss {'Reaction outcome loss': 0.1830865916180812, 'Total loss': 0.1830865916180812}
2023-01-04 22:02:15,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:15,391 INFO:     Epoch: 67
2023-01-04 22:02:17,573 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4327969253063202, 'Total loss': 0.4327969253063202} | train loss {'Reaction outcome loss': 0.18009418023777377, 'Total loss': 0.18009418023777377}
2023-01-04 22:02:17,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:17,574 INFO:     Epoch: 68
2023-01-04 22:02:19,759 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43059299886226654, 'Total loss': 0.43059299886226654} | train loss {'Reaction outcome loss': 0.1835515535892035, 'Total loss': 0.1835515535892035}
2023-01-04 22:02:19,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:19,760 INFO:     Epoch: 69
2023-01-04 22:02:21,947 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41564699163039526, 'Total loss': 0.41564699163039526} | train loss {'Reaction outcome loss': 0.1815100030864786, 'Total loss': 0.1815100030864786}
2023-01-04 22:02:21,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:21,948 INFO:     Epoch: 70
2023-01-04 22:02:24,157 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4370696504910787, 'Total loss': 0.4370696504910787} | train loss {'Reaction outcome loss': 0.18359864147271227, 'Total loss': 0.18359864147271227}
2023-01-04 22:02:24,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:24,158 INFO:     Epoch: 71
2023-01-04 22:02:26,369 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4282331163684527, 'Total loss': 0.4282331163684527} | train loss {'Reaction outcome loss': 0.1744037996603679, 'Total loss': 0.1744037996603679}
2023-01-04 22:02:26,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:26,370 INFO:     Epoch: 72
2023-01-04 22:02:28,565 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42585702836513517, 'Total loss': 0.42585702836513517} | train loss {'Reaction outcome loss': 0.17856670489847443, 'Total loss': 0.17856670489847443}
2023-01-04 22:02:28,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:28,566 INFO:     Epoch: 73
2023-01-04 22:02:30,754 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41158049255609513, 'Total loss': 0.41158049255609513} | train loss {'Reaction outcome loss': 0.1781740541175606, 'Total loss': 0.1781740541175606}
2023-01-04 22:02:30,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:30,754 INFO:     Epoch: 74
2023-01-04 22:02:32,924 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3963357592622439, 'Total loss': 0.3963357592622439} | train loss {'Reaction outcome loss': 0.17529474293989858, 'Total loss': 0.17529474293989858}
2023-01-04 22:02:32,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:32,925 INFO:     Epoch: 75
2023-01-04 22:02:35,101 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41745514671007794, 'Total loss': 0.41745514671007794} | train loss {'Reaction outcome loss': 0.17227074972618997, 'Total loss': 0.17227074972618997}
2023-01-04 22:02:35,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:35,101 INFO:     Epoch: 76
2023-01-04 22:02:37,333 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4342816452185313, 'Total loss': 0.4342816452185313} | train loss {'Reaction outcome loss': 0.17615015678155324, 'Total loss': 0.17615015678155324}
2023-01-04 22:02:37,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:37,333 INFO:     Epoch: 77
2023-01-04 22:02:39,564 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4530682216087977, 'Total loss': 0.4530682216087977} | train loss {'Reaction outcome loss': 0.17412403665557777, 'Total loss': 0.17412403665557777}
2023-01-04 22:02:39,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:39,566 INFO:     Epoch: 78
2023-01-04 22:02:41,795 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40933322136600814, 'Total loss': 0.40933322136600814} | train loss {'Reaction outcome loss': 0.1739008575066054, 'Total loss': 0.1739008575066054}
2023-01-04 22:02:41,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:41,795 INFO:     Epoch: 79
2023-01-04 22:02:43,993 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3985090916355451, 'Total loss': 0.3985090916355451} | train loss {'Reaction outcome loss': 0.1724137900580727, 'Total loss': 0.1724137900580727}
2023-01-04 22:02:43,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:43,993 INFO:     Epoch: 80
2023-01-04 22:02:46,176 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4922894835472107, 'Total loss': 0.4922894835472107} | train loss {'Reaction outcome loss': 0.17669472992624136, 'Total loss': 0.17669472992624136}
2023-01-04 22:02:46,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:46,178 INFO:     Epoch: 81
2023-01-04 22:02:48,356 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4346437801917394, 'Total loss': 0.4346437801917394} | train loss {'Reaction outcome loss': 0.1709658610948912, 'Total loss': 0.1709658610948912}
2023-01-04 22:02:48,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:48,356 INFO:     Epoch: 82
2023-01-04 22:02:50,540 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4254074588418007, 'Total loss': 0.4254074588418007} | train loss {'Reaction outcome loss': 0.1693884277457956, 'Total loss': 0.1693884277457956}
2023-01-04 22:02:50,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:50,541 INFO:     Epoch: 83
2023-01-04 22:02:52,769 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44373514552911125, 'Total loss': 0.44373514552911125} | train loss {'Reaction outcome loss': 0.1675408840439466, 'Total loss': 0.1675408840439466}
2023-01-04 22:02:52,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:52,770 INFO:     Epoch: 84
2023-01-04 22:02:54,936 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42677055317908524, 'Total loss': 0.42677055317908524} | train loss {'Reaction outcome loss': 0.16647945685706433, 'Total loss': 0.16647945685706433}
2023-01-04 22:02:54,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:54,937 INFO:     Epoch: 85
2023-01-04 22:02:57,103 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43923492431640626, 'Total loss': 0.43923492431640626} | train loss {'Reaction outcome loss': 0.16039149386699508, 'Total loss': 0.16039149386699508}
2023-01-04 22:02:57,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:57,104 INFO:     Epoch: 86
2023-01-04 22:02:59,322 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38497719367345173, 'Total loss': 0.38497719367345173} | train loss {'Reaction outcome loss': 0.1640888989680399, 'Total loss': 0.1640888989680399}
2023-01-04 22:02:59,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:02:59,322 INFO:     Epoch: 87
2023-01-04 22:03:01,532 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4374000012874603, 'Total loss': 0.4374000012874603} | train loss {'Reaction outcome loss': 0.16361825491376494, 'Total loss': 0.16361825491376494}
2023-01-04 22:03:01,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:01,532 INFO:     Epoch: 88
2023-01-04 22:03:03,753 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.393785843004783, 'Total loss': 0.393785843004783} | train loss {'Reaction outcome loss': 0.17307202058783086, 'Total loss': 0.17307202058783086}
2023-01-04 22:03:03,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:03,754 INFO:     Epoch: 89
2023-01-04 22:03:05,941 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44036065141359965, 'Total loss': 0.44036065141359965} | train loss {'Reaction outcome loss': 0.163817199907286, 'Total loss': 0.163817199907286}
2023-01-04 22:03:05,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:05,941 INFO:     Epoch: 90
2023-01-04 22:03:08,118 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4637823522090912, 'Total loss': 0.4637823522090912} | train loss {'Reaction outcome loss': 0.15689254699981886, 'Total loss': 0.15689254699981886}
2023-01-04 22:03:08,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:08,120 INFO:     Epoch: 91
2023-01-04 22:03:10,299 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4000177270422379, 'Total loss': 0.4000177270422379} | train loss {'Reaction outcome loss': 0.15925352397395204, 'Total loss': 0.15925352397395204}
2023-01-04 22:03:10,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:10,299 INFO:     Epoch: 92
2023-01-04 22:03:12,482 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41804959358026583, 'Total loss': 0.41804959358026583} | train loss {'Reaction outcome loss': 0.160880116086426, 'Total loss': 0.160880116086426}
2023-01-04 22:03:12,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:12,482 INFO:     Epoch: 93
2023-01-04 22:03:14,661 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4860524028539658, 'Total loss': 0.4860524028539658} | train loss {'Reaction outcome loss': 0.16246067413492604, 'Total loss': 0.16246067413492604}
2023-01-04 22:03:14,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:14,662 INFO:     Epoch: 94
2023-01-04 22:03:16,805 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4333784264978021, 'Total loss': 0.4333784264978021} | train loss {'Reaction outcome loss': 0.16061663863514244, 'Total loss': 0.16061663863514244}
2023-01-04 22:03:16,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:16,805 INFO:     Epoch: 95
2023-01-04 22:03:18,985 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.459044220050176, 'Total loss': 0.459044220050176} | train loss {'Reaction outcome loss': 0.1570524952330212, 'Total loss': 0.1570524952330212}
2023-01-04 22:03:18,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:18,986 INFO:     Epoch: 96
2023-01-04 22:03:21,170 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39724688599817454, 'Total loss': 0.39724688599817454} | train loss {'Reaction outcome loss': 0.15575038519752532, 'Total loss': 0.15575038519752532}
2023-01-04 22:03:21,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:21,170 INFO:     Epoch: 97
2023-01-04 22:03:23,349 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4419639935096105, 'Total loss': 0.4419639935096105} | train loss {'Reaction outcome loss': 0.1574426634835392, 'Total loss': 0.1574426634835392}
2023-01-04 22:03:23,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:23,350 INFO:     Epoch: 98
2023-01-04 22:03:25,529 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4352262725432714, 'Total loss': 0.4352262725432714} | train loss {'Reaction outcome loss': 0.16090419666882413, 'Total loss': 0.16090419666882413}
2023-01-04 22:03:25,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:25,530 INFO:     Epoch: 99
2023-01-04 22:03:27,709 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41418811480204265, 'Total loss': 0.41418811480204265} | train loss {'Reaction outcome loss': 0.15837049841316567, 'Total loss': 0.15837049841316567}
2023-01-04 22:03:27,709 INFO:     Best model found after epoch 56 of 100.
2023-01-04 22:03:27,709 INFO:   Done with stage: TRAINING
2023-01-04 22:03:27,709 INFO:   Starting stage: EVALUATION
2023-01-04 22:03:27,850 INFO:   Done with stage: EVALUATION
2023-01-04 22:03:27,850 INFO:   Leaving out SEQ value Fold_5
2023-01-04 22:03:27,863 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 22:03:27,863 INFO:   Starting stage: FEATURE SCALING
2023-01-04 22:03:28,512 INFO:   Done with stage: FEATURE SCALING
2023-01-04 22:03:28,513 INFO:   Starting stage: SCALING TARGETS
2023-01-04 22:03:28,585 INFO:   Done with stage: SCALING TARGETS
2023-01-04 22:03:28,585 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:03:28,585 INFO:     No hyperparam tuning for this model
2023-01-04 22:03:28,585 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:03:28,585 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 22:03:28,586 INFO:     None feature selector for col prot
2023-01-04 22:03:28,586 INFO:     None feature selector for col prot
2023-01-04 22:03:28,586 INFO:     None feature selector for col prot
2023-01-04 22:03:28,587 INFO:     None feature selector for col chem
2023-01-04 22:03:28,587 INFO:     None feature selector for col chem
2023-01-04 22:03:28,587 INFO:     None feature selector for col chem
2023-01-04 22:03:28,587 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 22:03:28,587 INFO:   Starting stage: BUILD MODEL
2023-01-04 22:03:28,588 INFO:     Number of params in model 72931
2023-01-04 22:03:28,592 INFO:   Done with stage: BUILD MODEL
2023-01-04 22:03:28,592 INFO:   Starting stage: TRAINING
2023-01-04 22:03:28,651 INFO:     Val loss before train {'Reaction outcome loss': 1.0790635426839192, 'Total loss': 1.0790635426839192}
2023-01-04 22:03:28,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:28,651 INFO:     Epoch: 0
2023-01-04 22:03:30,855 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8252071022987366, 'Total loss': 0.8252071022987366} | train loss {'Reaction outcome loss': 0.9533858639390572, 'Total loss': 0.9533858639390572}
2023-01-04 22:03:30,856 INFO:     Found new best model at epoch 0
2023-01-04 22:03:30,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:30,858 INFO:     Epoch: 1
2023-01-04 22:03:33,052 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5821157256762187, 'Total loss': 0.5821157256762187} | train loss {'Reaction outcome loss': 0.6828112959502386, 'Total loss': 0.6828112959502386}
2023-01-04 22:03:33,052 INFO:     Found new best model at epoch 1
2023-01-04 22:03:33,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:33,053 INFO:     Epoch: 2
2023-01-04 22:03:35,246 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.507235570748647, 'Total loss': 0.507235570748647} | train loss {'Reaction outcome loss': 0.5540902396137624, 'Total loss': 0.5540902396137624}
2023-01-04 22:03:35,248 INFO:     Found new best model at epoch 2
2023-01-04 22:03:35,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:35,249 INFO:     Epoch: 3
2023-01-04 22:03:37,433 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4804869751135508, 'Total loss': 0.4804869751135508} | train loss {'Reaction outcome loss': 0.5086527441061385, 'Total loss': 0.5086527441061385}
2023-01-04 22:03:37,433 INFO:     Found new best model at epoch 3
2023-01-04 22:03:37,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:37,434 INFO:     Epoch: 4
2023-01-04 22:03:39,580 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45949427286783856, 'Total loss': 0.45949427286783856} | train loss {'Reaction outcome loss': 0.4762894212558488, 'Total loss': 0.4762894212558488}
2023-01-04 22:03:39,580 INFO:     Found new best model at epoch 4
2023-01-04 22:03:39,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:39,582 INFO:     Epoch: 5
2023-01-04 22:03:41,771 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46159052749474844, 'Total loss': 0.46159052749474844} | train loss {'Reaction outcome loss': 0.4532841995149257, 'Total loss': 0.4532841995149257}
2023-01-04 22:03:41,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:41,772 INFO:     Epoch: 6
2023-01-04 22:03:43,966 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4600869317849477, 'Total loss': 0.4600869317849477} | train loss {'Reaction outcome loss': 0.43560108377267537, 'Total loss': 0.43560108377267537}
2023-01-04 22:03:43,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:43,966 INFO:     Epoch: 7
2023-01-04 22:03:46,154 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.442112934589386, 'Total loss': 0.442112934589386} | train loss {'Reaction outcome loss': 0.4163482472843801, 'Total loss': 0.4163482472843801}
2023-01-04 22:03:46,154 INFO:     Found new best model at epoch 7
2023-01-04 22:03:46,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:46,156 INFO:     Epoch: 8
2023-01-04 22:03:48,353 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45046632885932925, 'Total loss': 0.45046632885932925} | train loss {'Reaction outcome loss': 0.409214710208724, 'Total loss': 0.409214710208724}
2023-01-04 22:03:48,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:48,355 INFO:     Epoch: 9
2023-01-04 22:03:50,542 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4234483887751897, 'Total loss': 0.4234483887751897} | train loss {'Reaction outcome loss': 0.39618393370503746, 'Total loss': 0.39618393370503746}
2023-01-04 22:03:50,542 INFO:     Found new best model at epoch 9
2023-01-04 22:03:50,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:50,544 INFO:     Epoch: 10
2023-01-04 22:03:52,760 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44419533212979634, 'Total loss': 0.44419533212979634} | train loss {'Reaction outcome loss': 0.38390302304448426, 'Total loss': 0.38390302304448426}
2023-01-04 22:03:52,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:52,761 INFO:     Epoch: 11
2023-01-04 22:03:54,942 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4161502222220103, 'Total loss': 0.4161502222220103} | train loss {'Reaction outcome loss': 0.3742019735965068, 'Total loss': 0.3742019735965068}
2023-01-04 22:03:54,942 INFO:     Found new best model at epoch 11
2023-01-04 22:03:54,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:54,944 INFO:     Epoch: 12
2023-01-04 22:03:57,120 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4166771203279495, 'Total loss': 0.4166771203279495} | train loss {'Reaction outcome loss': 0.3684307873869936, 'Total loss': 0.3684307873869936}
2023-01-04 22:03:57,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:57,120 INFO:     Epoch: 13
2023-01-04 22:03:59,321 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4227381149927775, 'Total loss': 0.4227381149927775} | train loss {'Reaction outcome loss': 0.36925168236906547, 'Total loss': 0.36925168236906547}
2023-01-04 22:03:59,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:03:59,322 INFO:     Epoch: 14
2023-01-04 22:04:01,508 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4141654352347056, 'Total loss': 0.4141654352347056} | train loss {'Reaction outcome loss': 0.3478173145423711, 'Total loss': 0.3478173145423711}
2023-01-04 22:04:01,508 INFO:     Found new best model at epoch 14
2023-01-04 22:04:01,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:01,510 INFO:     Epoch: 15
2023-01-04 22:04:03,704 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4074607213338216, 'Total loss': 0.4074607213338216} | train loss {'Reaction outcome loss': 0.3434924298869547, 'Total loss': 0.3434924298869547}
2023-01-04 22:04:03,704 INFO:     Found new best model at epoch 15
2023-01-04 22:04:03,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:03,706 INFO:     Epoch: 16
2023-01-04 22:04:05,896 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4080474187930425, 'Total loss': 0.4080474187930425} | train loss {'Reaction outcome loss': 0.3357421965776956, 'Total loss': 0.3357421965776956}
2023-01-04 22:04:05,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:05,897 INFO:     Epoch: 17
2023-01-04 22:04:08,085 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3978726158539454, 'Total loss': 0.3978726158539454} | train loss {'Reaction outcome loss': 0.32592341609884845, 'Total loss': 0.32592341609884845}
2023-01-04 22:04:08,085 INFO:     Found new best model at epoch 17
2023-01-04 22:04:08,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:08,086 INFO:     Epoch: 18
2023-01-04 22:04:10,024 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41545010209083555, 'Total loss': 0.41545010209083555} | train loss {'Reaction outcome loss': 0.32010289887008525, 'Total loss': 0.32010289887008525}
2023-01-04 22:04:10,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:10,024 INFO:     Epoch: 19
2023-01-04 22:04:11,851 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.383761090785265, 'Total loss': 0.383761090785265} | train loss {'Reaction outcome loss': 0.31399221340805106, 'Total loss': 0.31399221340805106}
2023-01-04 22:04:11,852 INFO:     Found new best model at epoch 19
2023-01-04 22:04:11,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:11,853 INFO:     Epoch: 20
2023-01-04 22:04:13,662 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39908826947212217, 'Total loss': 0.39908826947212217} | train loss {'Reaction outcome loss': 0.3088543081615606, 'Total loss': 0.3088543081615606}
2023-01-04 22:04:13,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:13,662 INFO:     Epoch: 21
2023-01-04 22:04:15,539 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41347291668256125, 'Total loss': 0.41347291668256125} | train loss {'Reaction outcome loss': 0.30172559977032454, 'Total loss': 0.30172559977032454}
2023-01-04 22:04:15,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:15,539 INFO:     Epoch: 22
2023-01-04 22:04:17,568 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40921762535969414, 'Total loss': 0.40921762535969414} | train loss {'Reaction outcome loss': 0.29213718106410047, 'Total loss': 0.29213718106410047}
2023-01-04 22:04:17,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:17,568 INFO:     Epoch: 23
2023-01-04 22:04:19,840 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41266324520111086, 'Total loss': 0.41266324520111086} | train loss {'Reaction outcome loss': 0.31463521714929654, 'Total loss': 0.31463521714929654}
2023-01-04 22:04:19,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:19,841 INFO:     Epoch: 24
2023-01-04 22:04:22,111 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4236651837825775, 'Total loss': 0.4236651837825775} | train loss {'Reaction outcome loss': 0.2881297634271702, 'Total loss': 0.2881297634271702}
2023-01-04 22:04:22,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:22,111 INFO:     Epoch: 25
2023-01-04 22:04:24,346 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41507068773110706, 'Total loss': 0.41507068773110706} | train loss {'Reaction outcome loss': 0.29151805904626416, 'Total loss': 0.29151805904626416}
2023-01-04 22:04:24,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:24,346 INFO:     Epoch: 26
2023-01-04 22:04:26,569 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41182722051938375, 'Total loss': 0.41182722051938375} | train loss {'Reaction outcome loss': 0.30537021496886574, 'Total loss': 0.30537021496886574}
2023-01-04 22:04:26,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:26,569 INFO:     Epoch: 27
2023-01-04 22:04:28,823 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40558720628420514, 'Total loss': 0.40558720628420514} | train loss {'Reaction outcome loss': 0.2743120984616352, 'Total loss': 0.2743120984616352}
2023-01-04 22:04:28,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:28,823 INFO:     Epoch: 28
2023-01-04 22:04:31,072 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43001929521560667, 'Total loss': 0.43001929521560667} | train loss {'Reaction outcome loss': 0.27045549506294553, 'Total loss': 0.27045549506294553}
2023-01-04 22:04:31,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:31,073 INFO:     Epoch: 29
2023-01-04 22:04:33,333 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39017875989278156, 'Total loss': 0.39017875989278156} | train loss {'Reaction outcome loss': 0.2663573095340563, 'Total loss': 0.2663573095340563}
2023-01-04 22:04:33,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:33,334 INFO:     Epoch: 30
2023-01-04 22:04:35,556 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3998921235402425, 'Total loss': 0.3998921235402425} | train loss {'Reaction outcome loss': 0.2623472069862528, 'Total loss': 0.2623472069862528}
2023-01-04 22:04:35,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:35,557 INFO:     Epoch: 31
2023-01-04 22:04:37,810 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3986749326189359, 'Total loss': 0.3986749326189359} | train loss {'Reaction outcome loss': 0.2590519354355596, 'Total loss': 0.2590519354355596}
2023-01-04 22:04:37,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:37,811 INFO:     Epoch: 32
2023-01-04 22:04:40,031 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40595035056273143, 'Total loss': 0.40595035056273143} | train loss {'Reaction outcome loss': 0.2542198706782917, 'Total loss': 0.2542198706782917}
2023-01-04 22:04:40,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:40,031 INFO:     Epoch: 33
2023-01-04 22:04:42,286 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3984867612520854, 'Total loss': 0.3984867612520854} | train loss {'Reaction outcome loss': 0.2539887121786613, 'Total loss': 0.2539887121786613}
2023-01-04 22:04:42,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:42,287 INFO:     Epoch: 34
2023-01-04 22:04:44,445 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41866038540999095, 'Total loss': 0.41866038540999095} | train loss {'Reaction outcome loss': 0.24930199555785584, 'Total loss': 0.24930199555785584}
2023-01-04 22:04:44,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:44,446 INFO:     Epoch: 35
2023-01-04 22:04:46,681 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38545118470986683, 'Total loss': 0.38545118470986683} | train loss {'Reaction outcome loss': 0.24905160359127837, 'Total loss': 0.24905160359127837}
2023-01-04 22:04:46,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:46,681 INFO:     Epoch: 36
2023-01-04 22:04:48,915 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.410605975240469, 'Total loss': 0.410605975240469} | train loss {'Reaction outcome loss': 0.24582226319319528, 'Total loss': 0.24582226319319528}
2023-01-04 22:04:48,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:48,916 INFO:     Epoch: 37
2023-01-04 22:04:51,163 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40201151569684346, 'Total loss': 0.40201151569684346} | train loss {'Reaction outcome loss': 0.24698588267096142, 'Total loss': 0.24698588267096142}
2023-01-04 22:04:51,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:51,164 INFO:     Epoch: 38
2023-01-04 22:04:53,424 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4016140249868234, 'Total loss': 0.4016140249868234} | train loss {'Reaction outcome loss': 0.23988694563023813, 'Total loss': 0.23988694563023813}
2023-01-04 22:04:53,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:53,424 INFO:     Epoch: 39
2023-01-04 22:04:55,670 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40168310900529225, 'Total loss': 0.40168310900529225} | train loss {'Reaction outcome loss': 0.23510121356398947, 'Total loss': 0.23510121356398947}
2023-01-04 22:04:55,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:55,671 INFO:     Epoch: 40
2023-01-04 22:04:57,894 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3845325703422228, 'Total loss': 0.3845325703422228} | train loss {'Reaction outcome loss': 0.2375257731798321, 'Total loss': 0.2375257731798321}
2023-01-04 22:04:57,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:04:57,894 INFO:     Epoch: 41
2023-01-04 22:05:00,102 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4029911349217097, 'Total loss': 0.4029911349217097} | train loss {'Reaction outcome loss': 0.23205500161545217, 'Total loss': 0.23205500161545217}
2023-01-04 22:05:00,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:00,103 INFO:     Epoch: 42
2023-01-04 22:05:02,356 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39038268725077313, 'Total loss': 0.39038268725077313} | train loss {'Reaction outcome loss': 0.23133594359176746, 'Total loss': 0.23133594359176746}
2023-01-04 22:05:02,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:02,356 INFO:     Epoch: 43
2023-01-04 22:05:04,556 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3785003026326497, 'Total loss': 0.3785003026326497} | train loss {'Reaction outcome loss': 0.23263996094465256, 'Total loss': 0.23263996094465256}
2023-01-04 22:05:04,556 INFO:     Found new best model at epoch 43
2023-01-04 22:05:04,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:04,557 INFO:     Epoch: 44
2023-01-04 22:05:06,825 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4029757231473923, 'Total loss': 0.4029757231473923} | train loss {'Reaction outcome loss': 0.22603111293342343, 'Total loss': 0.22603111293342343}
2023-01-04 22:05:06,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:06,826 INFO:     Epoch: 45
2023-01-04 22:05:09,105 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3947474420070648, 'Total loss': 0.3947474420070648} | train loss {'Reaction outcome loss': 0.225838384213115, 'Total loss': 0.225838384213115}
2023-01-04 22:05:09,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:09,105 INFO:     Epoch: 46
2023-01-04 22:05:11,365 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40916573504606885, 'Total loss': 0.40916573504606885} | train loss {'Reaction outcome loss': 0.22160844827854104, 'Total loss': 0.22160844827854104}
2023-01-04 22:05:11,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:11,365 INFO:     Epoch: 47
2023-01-04 22:05:13,593 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3869869997104009, 'Total loss': 0.3869869997104009} | train loss {'Reaction outcome loss': 0.2227682389885835, 'Total loss': 0.2227682389885835}
2023-01-04 22:05:13,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:13,594 INFO:     Epoch: 48
2023-01-04 22:05:15,844 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4106134310364723, 'Total loss': 0.4106134310364723} | train loss {'Reaction outcome loss': 0.2273805715697075, 'Total loss': 0.2273805715697075}
2023-01-04 22:05:15,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:15,844 INFO:     Epoch: 49
2023-01-04 22:05:18,099 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4125381549199422, 'Total loss': 0.4125381549199422} | train loss {'Reaction outcome loss': 0.22514838352124544, 'Total loss': 0.22514838352124544}
2023-01-04 22:05:18,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:18,101 INFO:     Epoch: 50
2023-01-04 22:05:20,301 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4072966694831848, 'Total loss': 0.4072966694831848} | train loss {'Reaction outcome loss': 0.21912425653199138, 'Total loss': 0.21912425653199138}
2023-01-04 22:05:20,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:20,301 INFO:     Epoch: 51
2023-01-04 22:05:22,271 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4191012104352315, 'Total loss': 0.4191012104352315} | train loss {'Reaction outcome loss': 0.21130863686799337, 'Total loss': 0.21130863686799337}
2023-01-04 22:05:22,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:22,271 INFO:     Epoch: 52
2023-01-04 22:05:24,090 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4147808531920115, 'Total loss': 0.4147808531920115} | train loss {'Reaction outcome loss': 0.21253296020090667, 'Total loss': 0.21253296020090667}
2023-01-04 22:05:24,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:24,091 INFO:     Epoch: 53
2023-01-04 22:05:26,100 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.389963040749232, 'Total loss': 0.389963040749232} | train loss {'Reaction outcome loss': 0.21594243570892274, 'Total loss': 0.21594243570892274}
2023-01-04 22:05:26,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:26,101 INFO:     Epoch: 54
2023-01-04 22:05:28,332 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4051917403936386, 'Total loss': 0.4051917403936386} | train loss {'Reaction outcome loss': 0.2079930660429586, 'Total loss': 0.2079930660429586}
2023-01-04 22:05:28,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:28,332 INFO:     Epoch: 55
2023-01-04 22:05:30,586 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40254017810026804, 'Total loss': 0.40254017810026804} | train loss {'Reaction outcome loss': 0.20673244652958153, 'Total loss': 0.20673244652958153}
2023-01-04 22:05:30,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:30,588 INFO:     Epoch: 56
2023-01-04 22:05:32,851 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4416331072648366, 'Total loss': 0.4416331072648366} | train loss {'Reaction outcome loss': 0.21047653866918298, 'Total loss': 0.21047653866918298}
2023-01-04 22:05:32,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:32,851 INFO:     Epoch: 57
2023-01-04 22:05:35,097 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41598686476548513, 'Total loss': 0.41598686476548513} | train loss {'Reaction outcome loss': 0.2211183590923716, 'Total loss': 0.2211183590923716}
2023-01-04 22:05:35,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:35,097 INFO:     Epoch: 58
2023-01-04 22:05:37,331 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40049540599187217, 'Total loss': 0.40049540599187217} | train loss {'Reaction outcome loss': 0.20499601157422623, 'Total loss': 0.20499601157422623}
2023-01-04 22:05:37,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:37,332 INFO:     Epoch: 59
2023-01-04 22:05:39,550 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4110022763411204, 'Total loss': 0.4110022763411204} | train loss {'Reaction outcome loss': 0.22712216263070054, 'Total loss': 0.22712216263070054}
2023-01-04 22:05:39,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:39,551 INFO:     Epoch: 60
2023-01-04 22:05:41,825 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42242688635985054, 'Total loss': 0.42242688635985054} | train loss {'Reaction outcome loss': 0.20940696997886465, 'Total loss': 0.20940696997886465}
2023-01-04 22:05:41,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:41,826 INFO:     Epoch: 61
2023-01-04 22:05:44,102 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.397385240594546, 'Total loss': 0.397385240594546} | train loss {'Reaction outcome loss': 0.20256331772617303, 'Total loss': 0.20256331772617303}
2023-01-04 22:05:44,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:44,102 INFO:     Epoch: 62
2023-01-04 22:05:46,376 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4256076325972875, 'Total loss': 0.4256076325972875} | train loss {'Reaction outcome loss': 0.19624519707429208, 'Total loss': 0.19624519707429208}
2023-01-04 22:05:46,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:46,376 INFO:     Epoch: 63
2023-01-04 22:05:48,628 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4046118309100469, 'Total loss': 0.4046118309100469} | train loss {'Reaction outcome loss': 0.19395665076824473, 'Total loss': 0.19395665076824473}
2023-01-04 22:05:48,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:48,630 INFO:     Epoch: 64
2023-01-04 22:05:50,901 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4059228479862213, 'Total loss': 0.4059228479862213} | train loss {'Reaction outcome loss': 0.19209839652743857, 'Total loss': 0.19209839652743857}
2023-01-04 22:05:50,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:50,901 INFO:     Epoch: 65
2023-01-04 22:05:53,168 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3875312621394793, 'Total loss': 0.3875312621394793} | train loss {'Reaction outcome loss': 0.19064843842415544, 'Total loss': 0.19064843842415544}
2023-01-04 22:05:53,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:53,169 INFO:     Epoch: 66
2023-01-04 22:05:55,449 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4065734754006068, 'Total loss': 0.4065734754006068} | train loss {'Reaction outcome loss': 0.19398996155233245, 'Total loss': 0.19398996155233245}
2023-01-04 22:05:55,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:55,449 INFO:     Epoch: 67
2023-01-04 22:05:57,707 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4260113683839639, 'Total loss': 0.4260113683839639} | train loss {'Reaction outcome loss': 0.193400525950879, 'Total loss': 0.193400525950879}
2023-01-04 22:05:57,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:57,708 INFO:     Epoch: 68
2023-01-04 22:05:59,972 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39169754516333344, 'Total loss': 0.39169754516333344} | train loss {'Reaction outcome loss': 0.1850245218096382, 'Total loss': 0.1850245218096382}
2023-01-04 22:05:59,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:05:59,973 INFO:     Epoch: 69
2023-01-04 22:06:02,155 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39401354094346364, 'Total loss': 0.39401354094346364} | train loss {'Reaction outcome loss': 0.1899250502214325, 'Total loss': 0.1899250502214325}
2023-01-04 22:06:02,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:02,156 INFO:     Epoch: 70
2023-01-04 22:06:04,393 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4053720990816752, 'Total loss': 0.4053720990816752} | train loss {'Reaction outcome loss': 0.18771821786219295, 'Total loss': 0.18771821786219295}
2023-01-04 22:06:04,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:04,393 INFO:     Epoch: 71
2023-01-04 22:06:06,536 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42449476520220436, 'Total loss': 0.42449476520220436} | train loss {'Reaction outcome loss': 0.18949843471046482, 'Total loss': 0.18949843471046482}
2023-01-04 22:06:06,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:06,538 INFO:     Epoch: 72
2023-01-04 22:06:08,775 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4020831237236659, 'Total loss': 0.4020831237236659} | train loss {'Reaction outcome loss': 0.18736830888361589, 'Total loss': 0.18736830888361589}
2023-01-04 22:06:08,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:08,776 INFO:     Epoch: 73
2023-01-04 22:06:11,029 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41022781829039257, 'Total loss': 0.41022781829039257} | train loss {'Reaction outcome loss': 0.18554572805347244, 'Total loss': 0.18554572805347244}
2023-01-04 22:06:11,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:11,030 INFO:     Epoch: 74
2023-01-04 22:06:13,267 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39641324480374657, 'Total loss': 0.39641324480374657} | train loss {'Reaction outcome loss': 0.18622489005708526, 'Total loss': 0.18622489005708526}
2023-01-04 22:06:13,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:13,268 INFO:     Epoch: 75
2023-01-04 22:06:15,478 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4202615002791087, 'Total loss': 0.4202615002791087} | train loss {'Reaction outcome loss': 0.1845797481963519, 'Total loss': 0.1845797481963519}
2023-01-04 22:06:15,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:15,478 INFO:     Epoch: 76
2023-01-04 22:06:17,699 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4098007375995318, 'Total loss': 0.4098007375995318} | train loss {'Reaction outcome loss': 0.18016017224247832, 'Total loss': 0.18016017224247832}
2023-01-04 22:06:17,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:17,699 INFO:     Epoch: 77
2023-01-04 22:06:19,944 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39499892940123876, 'Total loss': 0.39499892940123876} | train loss {'Reaction outcome loss': 0.1910121766863006, 'Total loss': 0.1910121766863006}
2023-01-04 22:06:19,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:19,945 INFO:     Epoch: 78
2023-01-04 22:06:22,193 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4286384791135788, 'Total loss': 0.4286384791135788} | train loss {'Reaction outcome loss': 0.18651695616553415, 'Total loss': 0.18651695616553415}
2023-01-04 22:06:22,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:22,194 INFO:     Epoch: 79
2023-01-04 22:06:24,419 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4116502230366071, 'Total loss': 0.4116502230366071} | train loss {'Reaction outcome loss': 0.17871527793898206, 'Total loss': 0.17871527793898206}
2023-01-04 22:06:24,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:24,420 INFO:     Epoch: 80
2023-01-04 22:06:26,675 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3840965787569682, 'Total loss': 0.3840965787569682} | train loss {'Reaction outcome loss': 0.1791040201851106, 'Total loss': 0.1791040201851106}
2023-01-04 22:06:26,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:26,676 INFO:     Epoch: 81
2023-01-04 22:06:28,920 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41323056717713674, 'Total loss': 0.41323056717713674} | train loss {'Reaction outcome loss': 0.17625462495303457, 'Total loss': 0.17625462495303457}
2023-01-04 22:06:28,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:28,920 INFO:     Epoch: 82
2023-01-04 22:06:31,151 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39233797242244084, 'Total loss': 0.39233797242244084} | train loss {'Reaction outcome loss': 0.18030143785880934, 'Total loss': 0.18030143785880934}
2023-01-04 22:06:31,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:31,153 INFO:     Epoch: 83
2023-01-04 22:06:33,415 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43478238185246787, 'Total loss': 0.43478238185246787} | train loss {'Reaction outcome loss': 0.17348071022897257, 'Total loss': 0.17348071022897257}
2023-01-04 22:06:33,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:33,416 INFO:     Epoch: 84
2023-01-04 22:06:35,721 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4109773869315783, 'Total loss': 0.4109773869315783} | train loss {'Reaction outcome loss': 0.18257911265085358, 'Total loss': 0.18257911265085358}
2023-01-04 22:06:35,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:35,721 INFO:     Epoch: 85
2023-01-04 22:06:37,990 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4397711902856827, 'Total loss': 0.4397711902856827} | train loss {'Reaction outcome loss': 0.17793180366330172, 'Total loss': 0.17793180366330172}
2023-01-04 22:06:37,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:37,991 INFO:     Epoch: 86
2023-01-04 22:06:40,233 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45552793741226194, 'Total loss': 0.45552793741226194} | train loss {'Reaction outcome loss': 0.18425806402524028, 'Total loss': 0.18425806402524028}
2023-01-04 22:06:40,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:40,234 INFO:     Epoch: 87
2023-01-04 22:06:42,410 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43413243889808656, 'Total loss': 0.43413243889808656} | train loss {'Reaction outcome loss': 0.17967053592893417, 'Total loss': 0.17967053592893417}
2023-01-04 22:06:42,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:42,411 INFO:     Epoch: 88
2023-01-04 22:06:44,665 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41051989297072095, 'Total loss': 0.41051989297072095} | train loss {'Reaction outcome loss': 0.17114443055723552, 'Total loss': 0.17114443055723552}
2023-01-04 22:06:44,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:44,665 INFO:     Epoch: 89
2023-01-04 22:06:46,927 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4090584069490433, 'Total loss': 0.4090584069490433} | train loss {'Reaction outcome loss': 0.17766650651095045, 'Total loss': 0.17766650651095045}
2023-01-04 22:06:46,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:46,928 INFO:     Epoch: 90
2023-01-04 22:06:49,080 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42472342650095624, 'Total loss': 0.42472342650095624} | train loss {'Reaction outcome loss': 0.17080254332213898, 'Total loss': 0.17080254332213898}
2023-01-04 22:06:49,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:49,081 INFO:     Epoch: 91
2023-01-04 22:06:51,339 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.417392506202062, 'Total loss': 0.417392506202062} | train loss {'Reaction outcome loss': 0.18574917028941537, 'Total loss': 0.18574917028941537}
2023-01-04 22:06:51,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:51,339 INFO:     Epoch: 92
2023-01-04 22:06:53,517 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4556102007627487, 'Total loss': 0.4556102007627487} | train loss {'Reaction outcome loss': 0.18400229738714793, 'Total loss': 0.18400229738714793}
2023-01-04 22:06:53,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:53,517 INFO:     Epoch: 93
2023-01-04 22:06:55,759 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4227698020637035, 'Total loss': 0.4227698020637035} | train loss {'Reaction outcome loss': 0.18034427891003704, 'Total loss': 0.18034427891003704}
2023-01-04 22:06:55,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:55,760 INFO:     Epoch: 94
2023-01-04 22:06:57,970 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4092123428980509, 'Total loss': 0.4092123428980509} | train loss {'Reaction outcome loss': 0.1732300128933275, 'Total loss': 0.1732300128933275}
2023-01-04 22:06:57,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:06:57,971 INFO:     Epoch: 95
2023-01-04 22:07:00,186 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41424636244773866, 'Total loss': 0.41424636244773866} | train loss {'Reaction outcome loss': 0.17355412888792815, 'Total loss': 0.17355412888792815}
2023-01-04 22:07:00,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:00,186 INFO:     Epoch: 96
2023-01-04 22:07:02,422 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41960235834121706, 'Total loss': 0.41960235834121706} | train loss {'Reaction outcome loss': 0.17037960860719634, 'Total loss': 0.17037960860719634}
2023-01-04 22:07:02,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:02,424 INFO:     Epoch: 97
2023-01-04 22:07:04,692 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45854789301132165, 'Total loss': 0.45854789301132165} | train loss {'Reaction outcome loss': 0.173810721874453, 'Total loss': 0.173810721874453}
2023-01-04 22:07:04,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:04,692 INFO:     Epoch: 98
2023-01-04 22:07:06,949 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44812369445959727, 'Total loss': 0.44812369445959727} | train loss {'Reaction outcome loss': 0.1767324622437034, 'Total loss': 0.1767324622437034}
2023-01-04 22:07:06,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:06,950 INFO:     Epoch: 99
2023-01-04 22:07:09,203 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40871442556381227, 'Total loss': 0.40871442556381227} | train loss {'Reaction outcome loss': 0.17574461809683428, 'Total loss': 0.17574461809683428}
2023-01-04 22:07:09,203 INFO:     Best model found after epoch 44 of 100.
2023-01-04 22:07:09,204 INFO:   Done with stage: TRAINING
2023-01-04 22:07:09,204 INFO:   Starting stage: EVALUATION
2023-01-04 22:07:09,340 INFO:   Done with stage: EVALUATION
2023-01-04 22:07:09,340 INFO:   Leaving out SEQ value Fold_6
2023-01-04 22:07:09,353 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 22:07:09,353 INFO:   Starting stage: FEATURE SCALING
2023-01-04 22:07:10,018 INFO:   Done with stage: FEATURE SCALING
2023-01-04 22:07:10,018 INFO:   Starting stage: SCALING TARGETS
2023-01-04 22:07:10,091 INFO:   Done with stage: SCALING TARGETS
2023-01-04 22:07:10,091 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:07:10,091 INFO:     No hyperparam tuning for this model
2023-01-04 22:07:10,091 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:07:10,092 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 22:07:10,092 INFO:     None feature selector for col prot
2023-01-04 22:07:10,092 INFO:     None feature selector for col prot
2023-01-04 22:07:10,093 INFO:     None feature selector for col prot
2023-01-04 22:07:10,093 INFO:     None feature selector for col chem
2023-01-04 22:07:10,093 INFO:     None feature selector for col chem
2023-01-04 22:07:10,093 INFO:     None feature selector for col chem
2023-01-04 22:07:10,093 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 22:07:10,093 INFO:   Starting stage: BUILD MODEL
2023-01-04 22:07:10,095 INFO:     Number of params in model 72931
2023-01-04 22:07:10,098 INFO:   Done with stage: BUILD MODEL
2023-01-04 22:07:10,098 INFO:   Starting stage: TRAINING
2023-01-04 22:07:10,156 INFO:     Val loss before train {'Reaction outcome loss': 1.0287265698115031, 'Total loss': 1.0287265698115031}
2023-01-04 22:07:10,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:10,157 INFO:     Epoch: 0
2023-01-04 22:07:12,435 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.771040391921997, 'Total loss': 0.771040391921997} | train loss {'Reaction outcome loss': 0.9434646519728086, 'Total loss': 0.9434646519728086}
2023-01-04 22:07:12,435 INFO:     Found new best model at epoch 0
2023-01-04 22:07:12,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:12,436 INFO:     Epoch: 1
2023-01-04 22:07:14,714 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5493626832962036, 'Total loss': 0.5493626832962036} | train loss {'Reaction outcome loss': 0.6478852345624986, 'Total loss': 0.6478852345624986}
2023-01-04 22:07:14,715 INFO:     Found new best model at epoch 1
2023-01-04 22:07:14,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:14,716 INFO:     Epoch: 2
2023-01-04 22:07:16,994 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4926913460095724, 'Total loss': 0.4926913460095724} | train loss {'Reaction outcome loss': 0.5481199231065998, 'Total loss': 0.5481199231065998}
2023-01-04 22:07:16,994 INFO:     Found new best model at epoch 2
2023-01-04 22:07:16,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:16,995 INFO:     Epoch: 3
2023-01-04 22:07:19,250 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45653294523557025, 'Total loss': 0.45653294523557025} | train loss {'Reaction outcome loss': 0.503680251834625, 'Total loss': 0.503680251834625}
2023-01-04 22:07:19,251 INFO:     Found new best model at epoch 3
2023-01-04 22:07:19,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:19,252 INFO:     Epoch: 4
2023-01-04 22:07:21,451 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4519801100095113, 'Total loss': 0.4519801100095113} | train loss {'Reaction outcome loss': 0.47563058697359656, 'Total loss': 0.47563058697359656}
2023-01-04 22:07:21,451 INFO:     Found new best model at epoch 4
2023-01-04 22:07:21,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:21,452 INFO:     Epoch: 5
2023-01-04 22:07:23,633 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43303073942661285, 'Total loss': 0.43303073942661285} | train loss {'Reaction outcome loss': 0.4517286925539643, 'Total loss': 0.4517286925539643}
2023-01-04 22:07:23,633 INFO:     Found new best model at epoch 5
2023-01-04 22:07:23,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:23,634 INFO:     Epoch: 6
2023-01-04 22:07:25,881 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43346360127131145, 'Total loss': 0.43346360127131145} | train loss {'Reaction outcome loss': 0.4326706013040422, 'Total loss': 0.4326706013040422}
2023-01-04 22:07:25,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:25,882 INFO:     Epoch: 7
2023-01-04 22:07:28,155 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42211591402689613, 'Total loss': 0.42211591402689613} | train loss {'Reaction outcome loss': 0.4188483896453458, 'Total loss': 0.4188483896453458}
2023-01-04 22:07:28,155 INFO:     Found new best model at epoch 7
2023-01-04 22:07:28,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:28,156 INFO:     Epoch: 8
2023-01-04 22:07:30,430 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.40973894794782, 'Total loss': 0.40973894794782} | train loss {'Reaction outcome loss': 0.4026119857219582, 'Total loss': 0.4026119857219582}
2023-01-04 22:07:30,431 INFO:     Found new best model at epoch 8
2023-01-04 22:07:30,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:30,433 INFO:     Epoch: 9
2023-01-04 22:07:32,676 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3949536780516307, 'Total loss': 0.3949536780516307} | train loss {'Reaction outcome loss': 0.3918669976778194, 'Total loss': 0.3918669976778194}
2023-01-04 22:07:32,676 INFO:     Found new best model at epoch 9
2023-01-04 22:07:32,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:32,677 INFO:     Epoch: 10
2023-01-04 22:07:34,952 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4078506628672282, 'Total loss': 0.4078506628672282} | train loss {'Reaction outcome loss': 0.37879344976981194, 'Total loss': 0.37879344976981194}
2023-01-04 22:07:34,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:34,952 INFO:     Epoch: 11
2023-01-04 22:07:37,219 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39092446664969127, 'Total loss': 0.39092446664969127} | train loss {'Reaction outcome loss': 0.37268435933529687, 'Total loss': 0.37268435933529687}
2023-01-04 22:07:37,220 INFO:     Found new best model at epoch 11
2023-01-04 22:07:37,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:37,221 INFO:     Epoch: 12
2023-01-04 22:07:39,503 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3908318946758906, 'Total loss': 0.3908318946758906} | train loss {'Reaction outcome loss': 0.36045359524256054, 'Total loss': 0.36045359524256054}
2023-01-04 22:07:39,503 INFO:     Found new best model at epoch 12
2023-01-04 22:07:39,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:39,504 INFO:     Epoch: 13
2023-01-04 22:07:41,780 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3755905826886495, 'Total loss': 0.3755905826886495} | train loss {'Reaction outcome loss': 0.35378821382453723, 'Total loss': 0.35378821382453723}
2023-01-04 22:07:41,782 INFO:     Found new best model at epoch 13
2023-01-04 22:07:41,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:41,783 INFO:     Epoch: 14
2023-01-04 22:07:44,041 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.37268771131833395, 'Total loss': 0.37268771131833395} | train loss {'Reaction outcome loss': 0.348273015745818, 'Total loss': 0.348273015745818}
2023-01-04 22:07:44,041 INFO:     Found new best model at epoch 14
2023-01-04 22:07:44,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:44,042 INFO:     Epoch: 15
2023-01-04 22:07:46,310 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3913796186447144, 'Total loss': 0.3913796186447144} | train loss {'Reaction outcome loss': 0.3375944420964279, 'Total loss': 0.3375944420964279}
2023-01-04 22:07:46,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:46,311 INFO:     Epoch: 16
2023-01-04 22:07:48,570 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.38671379586060844, 'Total loss': 0.38671379586060844} | train loss {'Reaction outcome loss': 0.33251184467159023, 'Total loss': 0.33251184467159023}
2023-01-04 22:07:48,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:48,571 INFO:     Epoch: 17
2023-01-04 22:07:50,847 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.37088771164417267, 'Total loss': 0.37088771164417267} | train loss {'Reaction outcome loss': 0.3195605991065287, 'Total loss': 0.3195605991065287}
2023-01-04 22:07:50,847 INFO:     Found new best model at epoch 17
2023-01-04 22:07:50,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:50,849 INFO:     Epoch: 18
2023-01-04 22:07:53,122 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3984047532081604, 'Total loss': 0.3984047532081604} | train loss {'Reaction outcome loss': 0.3171239347476176, 'Total loss': 0.3171239347476176}
2023-01-04 22:07:53,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:53,123 INFO:     Epoch: 19
2023-01-04 22:07:55,372 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3780920565128326, 'Total loss': 0.3780920565128326} | train loss {'Reaction outcome loss': 0.31683985564844275, 'Total loss': 0.31683985564844275}
2023-01-04 22:07:55,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:55,372 INFO:     Epoch: 20
2023-01-04 22:07:57,600 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38500398099422456, 'Total loss': 0.38500398099422456} | train loss {'Reaction outcome loss': 0.3045184443089506, 'Total loss': 0.3045184443089506}
2023-01-04 22:07:57,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:57,601 INFO:     Epoch: 21
2023-01-04 22:07:59,872 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39953694740931195, 'Total loss': 0.39953694740931195} | train loss {'Reaction outcome loss': 0.3040636996553693, 'Total loss': 0.3040636996553693}
2023-01-04 22:07:59,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:07:59,873 INFO:     Epoch: 22
2023-01-04 22:08:02,142 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.36832944105068843, 'Total loss': 0.36832944105068843} | train loss {'Reaction outcome loss': 0.2944709147841061, 'Total loss': 0.2944709147841061}
2023-01-04 22:08:02,142 INFO:     Found new best model at epoch 22
2023-01-04 22:08:02,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:02,143 INFO:     Epoch: 23
2023-01-04 22:08:04,365 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3717617367704709, 'Total loss': 0.3717617367704709} | train loss {'Reaction outcome loss': 0.2916720533871263, 'Total loss': 0.2916720533871263}
2023-01-04 22:08:04,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:04,366 INFO:     Epoch: 24
2023-01-04 22:08:06,546 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3870223343372345, 'Total loss': 0.3870223343372345} | train loss {'Reaction outcome loss': 0.28158395260653124, 'Total loss': 0.28158395260653124}
2023-01-04 22:08:06,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:06,547 INFO:     Epoch: 25
2023-01-04 22:08:08,764 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3616655538479487, 'Total loss': 0.3616655538479487} | train loss {'Reaction outcome loss': 0.2831182437629476, 'Total loss': 0.2831182437629476}
2023-01-04 22:08:08,764 INFO:     Found new best model at epoch 25
2023-01-04 22:08:08,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:08,766 INFO:     Epoch: 26
2023-01-04 22:08:11,041 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4049217442671458, 'Total loss': 0.4049217442671458} | train loss {'Reaction outcome loss': 0.279814622206916, 'Total loss': 0.279814622206916}
2023-01-04 22:08:11,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:11,042 INFO:     Epoch: 27
2023-01-04 22:08:13,314 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4140517423550288, 'Total loss': 0.4140517423550288} | train loss {'Reaction outcome loss': 0.2729510155637557, 'Total loss': 0.2729510155637557}
2023-01-04 22:08:13,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:13,314 INFO:     Epoch: 28
2023-01-04 22:08:15,594 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38597432275613147, 'Total loss': 0.38597432275613147} | train loss {'Reaction outcome loss': 0.2699292563439922, 'Total loss': 0.2699292563439922}
2023-01-04 22:08:15,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:15,595 INFO:     Epoch: 29
2023-01-04 22:08:17,779 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3912434384226799, 'Total loss': 0.3912434384226799} | train loss {'Reaction outcome loss': 0.26509901262241475, 'Total loss': 0.26509901262241475}
2023-01-04 22:08:17,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:17,779 INFO:     Epoch: 30
2023-01-04 22:08:20,023 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3877341126402219, 'Total loss': 0.3877341126402219} | train loss {'Reaction outcome loss': 0.26801039617414507, 'Total loss': 0.26801039617414507}
2023-01-04 22:08:20,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:20,024 INFO:     Epoch: 31
2023-01-04 22:08:22,176 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4086342771848043, 'Total loss': 0.4086342771848043} | train loss {'Reaction outcome loss': 0.2604729580736655, 'Total loss': 0.2604729580736655}
2023-01-04 22:08:22,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:22,177 INFO:     Epoch: 32
2023-01-04 22:08:24,186 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4045560340086619, 'Total loss': 0.4045560340086619} | train loss {'Reaction outcome loss': 0.2595984994060619, 'Total loss': 0.2595984994060619}
2023-01-04 22:08:24,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:24,187 INFO:     Epoch: 33
2023-01-04 22:08:26,460 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4021614849567413, 'Total loss': 0.4021614849567413} | train loss {'Reaction outcome loss': 0.2532344364766233, 'Total loss': 0.2532344364766233}
2023-01-04 22:08:26,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:26,460 INFO:     Epoch: 34
2023-01-04 22:08:28,706 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3864206612110138, 'Total loss': 0.3864206612110138} | train loss {'Reaction outcome loss': 0.2510852512200817, 'Total loss': 0.2510852512200817}
2023-01-04 22:08:28,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:28,707 INFO:     Epoch: 35
2023-01-04 22:08:30,960 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3934647925508519, 'Total loss': 0.3934647925508519} | train loss {'Reaction outcome loss': 0.24893504507597602, 'Total loss': 0.24893504507597602}
2023-01-04 22:08:30,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:30,960 INFO:     Epoch: 36
2023-01-04 22:08:33,220 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3889705941081047, 'Total loss': 0.3889705941081047} | train loss {'Reaction outcome loss': 0.2417012622062157, 'Total loss': 0.2417012622062157}
2023-01-04 22:08:33,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:33,220 INFO:     Epoch: 37
2023-01-04 22:08:35,486 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42267726560433705, 'Total loss': 0.42267726560433705} | train loss {'Reaction outcome loss': 0.24411649201132546, 'Total loss': 0.24411649201132546}
2023-01-04 22:08:35,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:35,488 INFO:     Epoch: 38
2023-01-04 22:08:37,760 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4121498207251231, 'Total loss': 0.4121498207251231} | train loss {'Reaction outcome loss': 0.24077053521742997, 'Total loss': 0.24077053521742997}
2023-01-04 22:08:37,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:37,761 INFO:     Epoch: 39
2023-01-04 22:08:40,040 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4368579268455505, 'Total loss': 0.4368579268455505} | train loss {'Reaction outcome loss': 0.23907578554313752, 'Total loss': 0.23907578554313752}
2023-01-04 22:08:40,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:40,042 INFO:     Epoch: 40
2023-01-04 22:08:42,280 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39254615555206934, 'Total loss': 0.39254615555206934} | train loss {'Reaction outcome loss': 0.2381916608735381, 'Total loss': 0.2381916608735381}
2023-01-04 22:08:42,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:42,280 INFO:     Epoch: 41
2023-01-04 22:08:44,547 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4471178693075975, 'Total loss': 0.4471178693075975} | train loss {'Reaction outcome loss': 0.23592522231666943, 'Total loss': 0.23592522231666943}
2023-01-04 22:08:44,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:44,548 INFO:     Epoch: 42
2023-01-04 22:08:46,899 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39142345587412514, 'Total loss': 0.39142345587412514} | train loss {'Reaction outcome loss': 0.22939664813007365, 'Total loss': 0.22939664813007365}
2023-01-04 22:08:46,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:46,901 INFO:     Epoch: 43
2023-01-04 22:08:49,262 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4183287004629771, 'Total loss': 0.4183287004629771} | train loss {'Reaction outcome loss': 0.23447731866531532, 'Total loss': 0.23447731866531532}
2023-01-04 22:08:49,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:49,262 INFO:     Epoch: 44
2023-01-04 22:08:51,627 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4272861897945404, 'Total loss': 0.4272861897945404} | train loss {'Reaction outcome loss': 0.22604554654889158, 'Total loss': 0.22604554654889158}
2023-01-04 22:08:51,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:51,628 INFO:     Epoch: 45
2023-01-04 22:08:53,936 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4092061758041382, 'Total loss': 0.4092061758041382} | train loss {'Reaction outcome loss': 0.2305115679319316, 'Total loss': 0.2305115679319316}
2023-01-04 22:08:53,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:53,936 INFO:     Epoch: 46
2023-01-04 22:08:56,150 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4150644948085149, 'Total loss': 0.4150644948085149} | train loss {'Reaction outcome loss': 0.2197747693938415, 'Total loss': 0.2197747693938415}
2023-01-04 22:08:56,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:56,150 INFO:     Epoch: 47
2023-01-04 22:08:58,349 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42411532004674274, 'Total loss': 0.42411532004674274} | train loss {'Reaction outcome loss': 0.2236780283992794, 'Total loss': 0.2236780283992794}
2023-01-04 22:08:58,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:08:58,351 INFO:     Epoch: 48
2023-01-04 22:09:00,628 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40065060754617055, 'Total loss': 0.40065060754617055} | train loss {'Reaction outcome loss': 0.224011687070992, 'Total loss': 0.224011687070992}
2023-01-04 22:09:00,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:00,629 INFO:     Epoch: 49
2023-01-04 22:09:02,868 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4207330028216044, 'Total loss': 0.4207330028216044} | train loss {'Reaction outcome loss': 0.21915104654399067, 'Total loss': 0.21915104654399067}
2023-01-04 22:09:02,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:02,870 INFO:     Epoch: 50
2023-01-04 22:09:05,131 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3880382572611173, 'Total loss': 0.3880382572611173} | train loss {'Reaction outcome loss': 0.21840798511885995, 'Total loss': 0.21840798511885995}
2023-01-04 22:09:05,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:05,131 INFO:     Epoch: 51
2023-01-04 22:09:07,355 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41640736112991966, 'Total loss': 0.41640736112991966} | train loss {'Reaction outcome loss': 0.2197928224162397, 'Total loss': 0.2197928224162397}
2023-01-04 22:09:07,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:07,356 INFO:     Epoch: 52
2023-01-04 22:09:09,599 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3981244405110677, 'Total loss': 0.3981244405110677} | train loss {'Reaction outcome loss': 0.21461214120449357, 'Total loss': 0.21461214120449357}
2023-01-04 22:09:09,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:09,600 INFO:     Epoch: 53
2023-01-04 22:09:11,839 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4326671242713928, 'Total loss': 0.4326671242713928} | train loss {'Reaction outcome loss': 0.21237879857716793, 'Total loss': 0.21237879857716793}
2023-01-04 22:09:11,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:11,840 INFO:     Epoch: 54
2023-01-04 22:09:14,075 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3999158690373103, 'Total loss': 0.3999158690373103} | train loss {'Reaction outcome loss': 0.2132721901450992, 'Total loss': 0.2132721901450992}
2023-01-04 22:09:14,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:14,077 INFO:     Epoch: 55
2023-01-04 22:09:16,277 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3908900072177251, 'Total loss': 0.3908900072177251} | train loss {'Reaction outcome loss': 0.21334915330115747, 'Total loss': 0.21334915330115747}
2023-01-04 22:09:16,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:16,277 INFO:     Epoch: 56
2023-01-04 22:09:18,497 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4238650858402252, 'Total loss': 0.4238650858402252} | train loss {'Reaction outcome loss': 0.21084854352735116, 'Total loss': 0.21084854352735116}
2023-01-04 22:09:18,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:18,498 INFO:     Epoch: 57
2023-01-04 22:09:20,739 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4036796446268757, 'Total loss': 0.4036796446268757} | train loss {'Reaction outcome loss': 0.20357243831703165, 'Total loss': 0.20357243831703165}
2023-01-04 22:09:20,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:20,741 INFO:     Epoch: 58
2023-01-04 22:09:23,001 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41787149260441464, 'Total loss': 0.41787149260441464} | train loss {'Reaction outcome loss': 0.20781309738593842, 'Total loss': 0.20781309738593842}
2023-01-04 22:09:23,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:23,001 INFO:     Epoch: 59
2023-01-04 22:09:25,256 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38520399034023284, 'Total loss': 0.38520399034023284} | train loss {'Reaction outcome loss': 0.20574325053794612, 'Total loss': 0.20574325053794612}
2023-01-04 22:09:25,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:25,256 INFO:     Epoch: 60
2023-01-04 22:09:27,474 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3826233903566996, 'Total loss': 0.3826233903566996} | train loss {'Reaction outcome loss': 0.20787458171536777, 'Total loss': 0.20787458171536777}
2023-01-04 22:09:27,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:27,475 INFO:     Epoch: 61
2023-01-04 22:09:29,707 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3954131335020065, 'Total loss': 0.3954131335020065} | train loss {'Reaction outcome loss': 0.20542902291318677, 'Total loss': 0.20542902291318677}
2023-01-04 22:09:29,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:29,708 INFO:     Epoch: 62
2023-01-04 22:09:31,979 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42008375426133476, 'Total loss': 0.42008375426133476} | train loss {'Reaction outcome loss': 0.20305184824291334, 'Total loss': 0.20305184824291334}
2023-01-04 22:09:31,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:31,981 INFO:     Epoch: 63
2023-01-04 22:09:34,211 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4016413360834122, 'Total loss': 0.4016413360834122} | train loss {'Reaction outcome loss': 0.20070621137934255, 'Total loss': 0.20070621137934255}
2023-01-04 22:09:34,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:34,211 INFO:     Epoch: 64
2023-01-04 22:09:36,446 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40200931231180825, 'Total loss': 0.40200931231180825} | train loss {'Reaction outcome loss': 0.19937729554432393, 'Total loss': 0.19937729554432393}
2023-01-04 22:09:36,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:36,447 INFO:     Epoch: 65
2023-01-04 22:09:38,673 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42954435646533967, 'Total loss': 0.42954435646533967} | train loss {'Reaction outcome loss': 0.20334845067536464, 'Total loss': 0.20334845067536464}
2023-01-04 22:09:38,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:38,674 INFO:     Epoch: 66
2023-01-04 22:09:40,913 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40458390371253095, 'Total loss': 0.40458390371253095} | train loss {'Reaction outcome loss': 0.19817568063198013, 'Total loss': 0.19817568063198013}
2023-01-04 22:09:40,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:40,914 INFO:     Epoch: 67
2023-01-04 22:09:43,131 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41618711153666177, 'Total loss': 0.41618711153666177} | train loss {'Reaction outcome loss': 0.19889122817248428, 'Total loss': 0.19889122817248428}
2023-01-04 22:09:43,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:43,132 INFO:     Epoch: 68
2023-01-04 22:09:45,383 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4376620983084043, 'Total loss': 0.4376620983084043} | train loss {'Reaction outcome loss': 0.20094992671941914, 'Total loss': 0.20094992671941914}
2023-01-04 22:09:45,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:45,384 INFO:     Epoch: 69
2023-01-04 22:09:47,618 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4012187351783117, 'Total loss': 0.4012187351783117} | train loss {'Reaction outcome loss': 0.1990166259761429, 'Total loss': 0.1990166259761429}
2023-01-04 22:09:47,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:47,619 INFO:     Epoch: 70
2023-01-04 22:09:49,814 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4159196565548579, 'Total loss': 0.4159196565548579} | train loss {'Reaction outcome loss': 0.1931581753255658, 'Total loss': 0.1931581753255658}
2023-01-04 22:09:49,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:49,815 INFO:     Epoch: 71
2023-01-04 22:09:52,070 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4329273521900177, 'Total loss': 0.4329273521900177} | train loss {'Reaction outcome loss': 0.19210180610633498, 'Total loss': 0.19210180610633498}
2023-01-04 22:09:52,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:52,070 INFO:     Epoch: 72
2023-01-04 22:09:54,312 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.400133282939593, 'Total loss': 0.400133282939593} | train loss {'Reaction outcome loss': 0.19842257221239462, 'Total loss': 0.19842257221239462}
2023-01-04 22:09:54,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:54,312 INFO:     Epoch: 73
2023-01-04 22:09:56,556 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41407304306825005, 'Total loss': 0.41407304306825005} | train loss {'Reaction outcome loss': 0.19195830104838962, 'Total loss': 0.19195830104838962}
2023-01-04 22:09:56,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:56,557 INFO:     Epoch: 74
2023-01-04 22:09:58,790 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4192679425080617, 'Total loss': 0.4192679425080617} | train loss {'Reaction outcome loss': 0.18648159274636408, 'Total loss': 0.18648159274636408}
2023-01-04 22:09:58,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:09:58,790 INFO:     Epoch: 75
2023-01-04 22:10:01,039 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4109464749693871, 'Total loss': 0.4109464749693871} | train loss {'Reaction outcome loss': 0.19138638105324138, 'Total loss': 0.19138638105324138}
2023-01-04 22:10:01,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:01,040 INFO:     Epoch: 76
2023-01-04 22:10:03,253 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42957261502742766, 'Total loss': 0.42957261502742766} | train loss {'Reaction outcome loss': 0.1916472393572196, 'Total loss': 0.1916472393572196}
2023-01-04 22:10:03,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:03,254 INFO:     Epoch: 77
2023-01-04 22:10:05,471 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4218817094961802, 'Total loss': 0.4218817094961802} | train loss {'Reaction outcome loss': 0.19575186035955586, 'Total loss': 0.19575186035955586}
2023-01-04 22:10:05,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:05,472 INFO:     Epoch: 78
2023-01-04 22:10:07,722 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42662734587987267, 'Total loss': 0.42662734587987267} | train loss {'Reaction outcome loss': 0.18746638689559988, 'Total loss': 0.18746638689559988}
2023-01-04 22:10:07,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:07,723 INFO:     Epoch: 79
2023-01-04 22:10:09,945 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4289944638808568, 'Total loss': 0.4289944638808568} | train loss {'Reaction outcome loss': 0.18570604030083232, 'Total loss': 0.18570604030083232}
2023-01-04 22:10:09,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:09,945 INFO:     Epoch: 80
2023-01-04 22:10:12,135 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41243442595005037, 'Total loss': 0.41243442595005037} | train loss {'Reaction outcome loss': 0.18906123432858649, 'Total loss': 0.18906123432858649}
2023-01-04 22:10:12,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:12,135 INFO:     Epoch: 81
2023-01-04 22:10:14,405 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4175859137127797, 'Total loss': 0.4175859137127797} | train loss {'Reaction outcome loss': 0.18927986985442333, 'Total loss': 0.18927986985442333}
2023-01-04 22:10:14,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:14,406 INFO:     Epoch: 82
2023-01-04 22:10:16,654 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4133319478482008, 'Total loss': 0.4133319478482008} | train loss {'Reaction outcome loss': 0.18873890547169245, 'Total loss': 0.18873890547169245}
2023-01-04 22:10:16,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:16,655 INFO:     Epoch: 83
2023-01-04 22:10:18,805 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4055860976378123, 'Total loss': 0.4055860976378123} | train loss {'Reaction outcome loss': 0.1867763010199965, 'Total loss': 0.1867763010199965}
2023-01-04 22:10:18,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:18,806 INFO:     Epoch: 84
2023-01-04 22:10:21,015 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4164273162682851, 'Total loss': 0.4164273162682851} | train loss {'Reaction outcome loss': 0.19000127267879216, 'Total loss': 0.19000127267879216}
2023-01-04 22:10:21,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:21,015 INFO:     Epoch: 85
2023-01-04 22:10:23,284 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40004319200913113, 'Total loss': 0.40004319200913113} | train loss {'Reaction outcome loss': 0.18353276335657825, 'Total loss': 0.18353276335657825}
2023-01-04 22:10:23,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:23,284 INFO:     Epoch: 86
2023-01-04 22:10:25,546 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4009920408328374, 'Total loss': 0.4009920408328374} | train loss {'Reaction outcome loss': 0.18159772468804775, 'Total loss': 0.18159772468804775}
2023-01-04 22:10:25,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:25,547 INFO:     Epoch: 87
2023-01-04 22:10:27,786 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40815381407737733, 'Total loss': 0.40815381407737733} | train loss {'Reaction outcome loss': 0.18378762843672333, 'Total loss': 0.18378762843672333}
2023-01-04 22:10:27,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:27,786 INFO:     Epoch: 88
2023-01-04 22:10:30,028 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40848714131861924, 'Total loss': 0.40848714131861924} | train loss {'Reaction outcome loss': 0.17851691953299922, 'Total loss': 0.17851691953299922}
2023-01-04 22:10:30,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:30,029 INFO:     Epoch: 89
2023-01-04 22:10:32,261 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42628729343414307, 'Total loss': 0.42628729343414307} | train loss {'Reaction outcome loss': 0.1788576429454267, 'Total loss': 0.1788576429454267}
2023-01-04 22:10:32,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:32,261 INFO:     Epoch: 90
2023-01-04 22:10:34,517 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44533824026584623, 'Total loss': 0.44533824026584623} | train loss {'Reaction outcome loss': 0.18445810539116714, 'Total loss': 0.18445810539116714}
2023-01-04 22:10:34,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:34,517 INFO:     Epoch: 91
2023-01-04 22:10:36,786 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42813403308391573, 'Total loss': 0.42813403308391573} | train loss {'Reaction outcome loss': 0.17954477838270824, 'Total loss': 0.17954477838270824}
2023-01-04 22:10:36,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:36,788 INFO:     Epoch: 92
2023-01-04 22:10:39,057 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43607230881849923, 'Total loss': 0.43607230881849923} | train loss {'Reaction outcome loss': 0.1750633413995875, 'Total loss': 0.1750633413995875}
2023-01-04 22:10:39,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:39,057 INFO:     Epoch: 93
2023-01-04 22:10:41,256 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4138943473498026, 'Total loss': 0.4138943473498026} | train loss {'Reaction outcome loss': 0.1819784450395174, 'Total loss': 0.1819784450395174}
2023-01-04 22:10:41,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:41,256 INFO:     Epoch: 94
2023-01-04 22:10:43,557 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4198491252958775, 'Total loss': 0.4198491252958775} | train loss {'Reaction outcome loss': 0.179554168101306, 'Total loss': 0.179554168101306}
2023-01-04 22:10:43,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:43,559 INFO:     Epoch: 95
2023-01-04 22:10:45,857 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4232443188627561, 'Total loss': 0.4232443188627561} | train loss {'Reaction outcome loss': 0.17888266989114, 'Total loss': 0.17888266989114}
2023-01-04 22:10:45,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:45,857 INFO:     Epoch: 96
2023-01-04 22:10:48,133 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4005350480477015, 'Total loss': 0.4005350480477015} | train loss {'Reaction outcome loss': 0.17378689047782966, 'Total loss': 0.17378689047782966}
2023-01-04 22:10:48,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:48,134 INFO:     Epoch: 97
2023-01-04 22:10:50,391 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3874434034029643, 'Total loss': 0.3874434034029643} | train loss {'Reaction outcome loss': 0.17934181790173537, 'Total loss': 0.17934181790173537}
2023-01-04 22:10:50,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:50,392 INFO:     Epoch: 98
2023-01-04 22:10:52,598 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4014336879054705, 'Total loss': 0.4014336879054705} | train loss {'Reaction outcome loss': 0.17696584866715037, 'Total loss': 0.17696584866715037}
2023-01-04 22:10:52,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:52,599 INFO:     Epoch: 99
2023-01-04 22:10:54,872 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4033809115489324, 'Total loss': 0.4033809115489324} | train loss {'Reaction outcome loss': 0.17656436731823677, 'Total loss': 0.17656436731823677}
2023-01-04 22:10:54,873 INFO:     Best model found after epoch 26 of 100.
2023-01-04 22:10:54,873 INFO:   Done with stage: TRAINING
2023-01-04 22:10:54,873 INFO:   Starting stage: EVALUATION
2023-01-04 22:10:55,002 INFO:   Done with stage: EVALUATION
2023-01-04 22:10:55,002 INFO:   Leaving out SEQ value Fold_7
2023-01-04 22:10:55,015 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 22:10:55,015 INFO:   Starting stage: FEATURE SCALING
2023-01-04 22:10:55,671 INFO:   Done with stage: FEATURE SCALING
2023-01-04 22:10:55,671 INFO:   Starting stage: SCALING TARGETS
2023-01-04 22:10:55,743 INFO:   Done with stage: SCALING TARGETS
2023-01-04 22:10:55,743 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:10:55,743 INFO:     No hyperparam tuning for this model
2023-01-04 22:10:55,743 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:10:55,743 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 22:10:55,744 INFO:     None feature selector for col prot
2023-01-04 22:10:55,744 INFO:     None feature selector for col prot
2023-01-04 22:10:55,744 INFO:     None feature selector for col prot
2023-01-04 22:10:55,745 INFO:     None feature selector for col chem
2023-01-04 22:10:55,745 INFO:     None feature selector for col chem
2023-01-04 22:10:55,745 INFO:     None feature selector for col chem
2023-01-04 22:10:55,745 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 22:10:55,745 INFO:   Starting stage: BUILD MODEL
2023-01-04 22:10:55,747 INFO:     Number of params in model 72931
2023-01-04 22:10:55,750 INFO:   Done with stage: BUILD MODEL
2023-01-04 22:10:55,750 INFO:   Starting stage: TRAINING
2023-01-04 22:10:55,810 INFO:     Val loss before train {'Reaction outcome loss': 0.9399624069531759, 'Total loss': 0.9399624069531759}
2023-01-04 22:10:55,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:55,810 INFO:     Epoch: 0
2023-01-04 22:10:58,067 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6677878499031067, 'Total loss': 0.6677878499031067} | train loss {'Reaction outcome loss': 0.9096492849293746, 'Total loss': 0.9096492849293746}
2023-01-04 22:10:58,067 INFO:     Found new best model at epoch 0
2023-01-04 22:10:58,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:10:58,068 INFO:     Epoch: 1
2023-01-04 22:11:00,335 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5880679100751877, 'Total loss': 0.5880679100751877} | train loss {'Reaction outcome loss': 0.6049297818495636, 'Total loss': 0.6049297818495636}
2023-01-04 22:11:00,336 INFO:     Found new best model at epoch 1
2023-01-04 22:11:00,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:00,338 INFO:     Epoch: 2
2023-01-04 22:11:02,579 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5619139671325684, 'Total loss': 0.5619139671325684} | train loss {'Reaction outcome loss': 0.528370932939098, 'Total loss': 0.528370932939098}
2023-01-04 22:11:02,579 INFO:     Found new best model at epoch 2
2023-01-04 22:11:02,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:02,581 INFO:     Epoch: 3
2023-01-04 22:11:04,812 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5288233558336893, 'Total loss': 0.5288233558336893} | train loss {'Reaction outcome loss': 0.4832876305639123, 'Total loss': 0.4832876305639123}
2023-01-04 22:11:04,812 INFO:     Found new best model at epoch 3
2023-01-04 22:11:04,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:04,813 INFO:     Epoch: 4
2023-01-04 22:11:07,083 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49957590699195864, 'Total loss': 0.49957590699195864} | train loss {'Reaction outcome loss': 0.47871552901747433, 'Total loss': 0.47871552901747433}
2023-01-04 22:11:07,084 INFO:     Found new best model at epoch 4
2023-01-04 22:11:07,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:07,085 INFO:     Epoch: 5
2023-01-04 22:11:09,392 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48437303900718687, 'Total loss': 0.48437303900718687} | train loss {'Reaction outcome loss': 0.4290531496111383, 'Total loss': 0.4290531496111383}
2023-01-04 22:11:09,392 INFO:     Found new best model at epoch 5
2023-01-04 22:11:09,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:09,394 INFO:     Epoch: 6
2023-01-04 22:11:11,678 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46719235678513843, 'Total loss': 0.46719235678513843} | train loss {'Reaction outcome loss': 0.4037411550728037, 'Total loss': 0.4037411550728037}
2023-01-04 22:11:11,678 INFO:     Found new best model at epoch 6
2023-01-04 22:11:11,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:11,679 INFO:     Epoch: 7
2023-01-04 22:11:13,922 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4739629775285721, 'Total loss': 0.4739629775285721} | train loss {'Reaction outcome loss': 0.3879697983359, 'Total loss': 0.3879697983359}
2023-01-04 22:11:13,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:13,923 INFO:     Epoch: 8
2023-01-04 22:11:16,179 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46487857898076373, 'Total loss': 0.46487857898076373} | train loss {'Reaction outcome loss': 0.37522689255791297, 'Total loss': 0.37522689255791297}
2023-01-04 22:11:16,179 INFO:     Found new best model at epoch 8
2023-01-04 22:11:16,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:16,180 INFO:     Epoch: 9
2023-01-04 22:11:18,436 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45384748876094816, 'Total loss': 0.45384748876094816} | train loss {'Reaction outcome loss': 0.3636854765869245, 'Total loss': 0.3636854765869245}
2023-01-04 22:11:18,437 INFO:     Found new best model at epoch 9
2023-01-04 22:11:18,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:18,439 INFO:     Epoch: 10
2023-01-04 22:11:20,683 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45570656458536785, 'Total loss': 0.45570656458536785} | train loss {'Reaction outcome loss': 0.3546824201239624, 'Total loss': 0.3546824201239624}
2023-01-04 22:11:20,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:20,683 INFO:     Epoch: 11
2023-01-04 22:11:22,943 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4469053313136101, 'Total loss': 0.4469053313136101} | train loss {'Reaction outcome loss': 0.34224098932632396, 'Total loss': 0.34224098932632396}
2023-01-04 22:11:22,943 INFO:     Found new best model at epoch 11
2023-01-04 22:11:22,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:22,944 INFO:     Epoch: 12
2023-01-04 22:11:25,210 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45158717731634773, 'Total loss': 0.45158717731634773} | train loss {'Reaction outcome loss': 0.332015663496745, 'Total loss': 0.332015663496745}
2023-01-04 22:11:25,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:25,211 INFO:     Epoch: 13
2023-01-04 22:11:27,375 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44776472871502243, 'Total loss': 0.44776472871502243} | train loss {'Reaction outcome loss': 0.3228940546830637, 'Total loss': 0.3228940546830637}
2023-01-04 22:11:27,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:27,375 INFO:     Epoch: 14
2023-01-04 22:11:29,640 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4578238467375437, 'Total loss': 0.4578238467375437} | train loss {'Reaction outcome loss': 0.315615940147309, 'Total loss': 0.315615940147309}
2023-01-04 22:11:29,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:29,641 INFO:     Epoch: 15
2023-01-04 22:11:31,925 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4570036252339681, 'Total loss': 0.4570036252339681} | train loss {'Reaction outcome loss': 0.30642411648337997, 'Total loss': 0.30642411648337997}
2023-01-04 22:11:31,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:31,926 INFO:     Epoch: 16
2023-01-04 22:11:34,201 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.454485230644544, 'Total loss': 0.454485230644544} | train loss {'Reaction outcome loss': 0.295996799199518, 'Total loss': 0.295996799199518}
2023-01-04 22:11:34,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:34,201 INFO:     Epoch: 17
2023-01-04 22:11:36,473 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44907144556442896, 'Total loss': 0.44907144556442896} | train loss {'Reaction outcome loss': 0.2923172834519958, 'Total loss': 0.2923172834519958}
2023-01-04 22:11:36,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:36,474 INFO:     Epoch: 18
2023-01-04 22:11:38,733 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4569938490788142, 'Total loss': 0.4569938490788142} | train loss {'Reaction outcome loss': 0.28336669180129503, 'Total loss': 0.28336669180129503}
2023-01-04 22:11:38,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:38,733 INFO:     Epoch: 19
2023-01-04 22:11:40,991 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47751027544339497, 'Total loss': 0.47751027544339497} | train loss {'Reaction outcome loss': 0.2791873705529421, 'Total loss': 0.2791873705529421}
2023-01-04 22:11:40,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:40,993 INFO:     Epoch: 20
2023-01-04 22:11:43,262 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4840441564718882, 'Total loss': 0.4840441564718882} | train loss {'Reaction outcome loss': 0.2747612732295554, 'Total loss': 0.2747612732295554}
2023-01-04 22:11:43,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:43,263 INFO:     Epoch: 21
2023-01-04 22:11:45,509 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.468964417775472, 'Total loss': 0.468964417775472} | train loss {'Reaction outcome loss': 0.26752318660947966, 'Total loss': 0.26752318660947966}
2023-01-04 22:11:45,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:45,511 INFO:     Epoch: 22
2023-01-04 22:11:47,770 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4657174358765284, 'Total loss': 0.4657174358765284} | train loss {'Reaction outcome loss': 0.26024347482598387, 'Total loss': 0.26024347482598387}
2023-01-04 22:11:47,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:47,770 INFO:     Epoch: 23
2023-01-04 22:11:50,015 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4837172051270803, 'Total loss': 0.4837172051270803} | train loss {'Reaction outcome loss': 0.25480281892974954, 'Total loss': 0.25480281892974954}
2023-01-04 22:11:50,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:50,015 INFO:     Epoch: 24
2023-01-04 22:11:52,254 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47616185347239176, 'Total loss': 0.47616185347239176} | train loss {'Reaction outcome loss': 0.2543132483749988, 'Total loss': 0.2543132483749988}
2023-01-04 22:11:52,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:52,256 INFO:     Epoch: 25
2023-01-04 22:11:54,518 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44818973739941914, 'Total loss': 0.44818973739941914} | train loss {'Reaction outcome loss': 0.24911959758163363, 'Total loss': 0.24911959758163363}
2023-01-04 22:11:54,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:54,518 INFO:     Epoch: 26
2023-01-04 22:11:56,779 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46529107689857485, 'Total loss': 0.46529107689857485} | train loss {'Reaction outcome loss': 0.2527985416379744, 'Total loss': 0.2527985416379744}
2023-01-04 22:11:56,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:56,780 INFO:     Epoch: 27
2023-01-04 22:11:59,029 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4689502070347468, 'Total loss': 0.4689502070347468} | train loss {'Reaction outcome loss': 0.24822382938683682, 'Total loss': 0.24822382938683682}
2023-01-04 22:11:59,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:11:59,029 INFO:     Epoch: 28
2023-01-04 22:12:01,259 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4601798584063848, 'Total loss': 0.4601798584063848} | train loss {'Reaction outcome loss': 0.2374494718084031, 'Total loss': 0.2374494718084031}
2023-01-04 22:12:01,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:01,260 INFO:     Epoch: 29
2023-01-04 22:12:03,501 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4499621217449506, 'Total loss': 0.4499621217449506} | train loss {'Reaction outcome loss': 0.23782162148510932, 'Total loss': 0.23782162148510932}
2023-01-04 22:12:03,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:03,502 INFO:     Epoch: 30
2023-01-04 22:12:05,769 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47692521860202153, 'Total loss': 0.47692521860202153} | train loss {'Reaction outcome loss': 0.23360620520712025, 'Total loss': 0.23360620520712025}
2023-01-04 22:12:05,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:05,769 INFO:     Epoch: 31
2023-01-04 22:12:08,037 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46249015629291534, 'Total loss': 0.46249015629291534} | train loss {'Reaction outcome loss': 0.22953435733177066, 'Total loss': 0.22953435733177066}
2023-01-04 22:12:08,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:08,037 INFO:     Epoch: 32
2023-01-04 22:12:10,304 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46370731194814047, 'Total loss': 0.46370731194814047} | train loss {'Reaction outcome loss': 0.22863117101399216, 'Total loss': 0.22863117101399216}
2023-01-04 22:12:10,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:10,305 INFO:     Epoch: 33
2023-01-04 22:12:12,551 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46571974754333495, 'Total loss': 0.46571974754333495} | train loss {'Reaction outcome loss': 0.22543072522924942, 'Total loss': 0.22543072522924942}
2023-01-04 22:12:12,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:12,551 INFO:     Epoch: 34
2023-01-04 22:12:14,798 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5002482439080874, 'Total loss': 0.5002482439080874} | train loss {'Reaction outcome loss': 0.22292966001850142, 'Total loss': 0.22292966001850142}
2023-01-04 22:12:14,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:14,799 INFO:     Epoch: 35
2023-01-04 22:12:17,054 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47375736832618714, 'Total loss': 0.47375736832618714} | train loss {'Reaction outcome loss': 0.22354352952591042, 'Total loss': 0.22354352952591042}
2023-01-04 22:12:17,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:17,056 INFO:     Epoch: 36
2023-01-04 22:12:19,323 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46635522643725075, 'Total loss': 0.46635522643725075} | train loss {'Reaction outcome loss': 0.21779590393186704, 'Total loss': 0.21779590393186704}
2023-01-04 22:12:19,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:19,323 INFO:     Epoch: 37
2023-01-04 22:12:21,609 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4685115086535613, 'Total loss': 0.4685115086535613} | train loss {'Reaction outcome loss': 0.21910412045047228, 'Total loss': 0.21910412045047228}
2023-01-04 22:12:21,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:21,610 INFO:     Epoch: 38
2023-01-04 22:12:23,836 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46718514561653135, 'Total loss': 0.46718514561653135} | train loss {'Reaction outcome loss': 0.21918281989485916, 'Total loss': 0.21918281989485916}
2023-01-04 22:12:23,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:23,836 INFO:     Epoch: 39
2023-01-04 22:12:26,070 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44299063890551527, 'Total loss': 0.44299063890551527} | train loss {'Reaction outcome loss': 0.214605590349453, 'Total loss': 0.214605590349453}
2023-01-04 22:12:26,070 INFO:     Found new best model at epoch 39
2023-01-04 22:12:26,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:26,071 INFO:     Epoch: 40
2023-01-04 22:12:28,329 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.49920386970043185, 'Total loss': 0.49920386970043185} | train loss {'Reaction outcome loss': 0.20664615930825123, 'Total loss': 0.20664615930825123}
2023-01-04 22:12:28,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:28,331 INFO:     Epoch: 41
2023-01-04 22:12:30,597 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4521699051062266, 'Total loss': 0.4521699051062266} | train loss {'Reaction outcome loss': 0.21021483261543122, 'Total loss': 0.21021483261543122}
2023-01-04 22:12:30,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:30,597 INFO:     Epoch: 42
2023-01-04 22:12:32,661 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47661968469619753, 'Total loss': 0.47661968469619753} | train loss {'Reaction outcome loss': 0.2112341832714497, 'Total loss': 0.2112341832714497}
2023-01-04 22:12:32,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:32,661 INFO:     Epoch: 43
2023-01-04 22:12:34,869 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48988698919614154, 'Total loss': 0.48988698919614154} | train loss {'Reaction outcome loss': 0.20003191395295764, 'Total loss': 0.20003191395295764}
2023-01-04 22:12:34,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:34,871 INFO:     Epoch: 44
2023-01-04 22:12:37,084 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5267853140830994, 'Total loss': 0.5267853140830994} | train loss {'Reaction outcome loss': 0.20414056317151888, 'Total loss': 0.20414056317151888}
2023-01-04 22:12:37,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:37,084 INFO:     Epoch: 45
2023-01-04 22:12:39,303 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4683187494675318, 'Total loss': 0.4683187494675318} | train loss {'Reaction outcome loss': 0.2044187588552882, 'Total loss': 0.2044187588552882}
2023-01-04 22:12:39,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:39,303 INFO:     Epoch: 46
2023-01-04 22:12:41,577 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43935156961282096, 'Total loss': 0.43935156961282096} | train loss {'Reaction outcome loss': 0.19711682032599734, 'Total loss': 0.19711682032599734}
2023-01-04 22:12:41,578 INFO:     Found new best model at epoch 46
2023-01-04 22:12:41,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:41,580 INFO:     Epoch: 47
2023-01-04 22:12:43,843 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48352309266726173, 'Total loss': 0.48352309266726173} | train loss {'Reaction outcome loss': 0.20064557632482002, 'Total loss': 0.20064557632482002}
2023-01-04 22:12:43,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:43,843 INFO:     Epoch: 48
2023-01-04 22:12:46,089 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4927052150170008, 'Total loss': 0.4927052150170008} | train loss {'Reaction outcome loss': 0.19869012011559276, 'Total loss': 0.19869012011559276}
2023-01-04 22:12:46,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:46,091 INFO:     Epoch: 49
2023-01-04 22:12:48,329 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.446244561423858, 'Total loss': 0.446244561423858} | train loss {'Reaction outcome loss': 0.19325064075808873, 'Total loss': 0.19325064075808873}
2023-01-04 22:12:48,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:48,329 INFO:     Epoch: 50
2023-01-04 22:12:50,551 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4525963057453434, 'Total loss': 0.4525963057453434} | train loss {'Reaction outcome loss': 0.19458429743805766, 'Total loss': 0.19458429743805766}
2023-01-04 22:12:50,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:50,552 INFO:     Epoch: 51
2023-01-04 22:12:52,802 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49388259649276733, 'Total loss': 0.49388259649276733} | train loss {'Reaction outcome loss': 0.19718832617555576, 'Total loss': 0.19718832617555576}
2023-01-04 22:12:52,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:52,803 INFO:     Epoch: 52
2023-01-04 22:12:55,045 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47755765517552695, 'Total loss': 0.47755765517552695} | train loss {'Reaction outcome loss': 0.1913999404411592, 'Total loss': 0.1913999404411592}
2023-01-04 22:12:55,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:55,045 INFO:     Epoch: 53
2023-01-04 22:12:57,278 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5103777562578519, 'Total loss': 0.5103777562578519} | train loss {'Reaction outcome loss': 0.1896097736072092, 'Total loss': 0.1896097736072092}
2023-01-04 22:12:57,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:57,278 INFO:     Epoch: 54
2023-01-04 22:12:59,515 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4721790999174118, 'Total loss': 0.4721790999174118} | train loss {'Reaction outcome loss': 0.19266963928796188, 'Total loss': 0.19266963928796188}
2023-01-04 22:12:59,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:12:59,516 INFO:     Epoch: 55
2023-01-04 22:13:01,761 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48505801558494566, 'Total loss': 0.48505801558494566} | train loss {'Reaction outcome loss': 0.1890917139404548, 'Total loss': 0.1890917139404548}
2023-01-04 22:13:01,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:01,761 INFO:     Epoch: 56
2023-01-04 22:13:03,951 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4704270263512929, 'Total loss': 0.4704270263512929} | train loss {'Reaction outcome loss': 0.19090341204655883, 'Total loss': 0.19090341204655883}
2023-01-04 22:13:03,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:03,953 INFO:     Epoch: 57
2023-01-04 22:13:06,209 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4781140565872192, 'Total loss': 0.4781140565872192} | train loss {'Reaction outcome loss': 0.1870070260779028, 'Total loss': 0.1870070260779028}
2023-01-04 22:13:06,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:06,210 INFO:     Epoch: 58
2023-01-04 22:13:08,478 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49805088912447293, 'Total loss': 0.49805088912447293} | train loss {'Reaction outcome loss': 0.17951280336073713, 'Total loss': 0.17951280336073713}
2023-01-04 22:13:08,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:08,478 INFO:     Epoch: 59
2023-01-04 22:13:10,710 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5315456539392471, 'Total loss': 0.5315456539392471} | train loss {'Reaction outcome loss': 0.18257380196946146, 'Total loss': 0.18257380196946146}
2023-01-04 22:13:10,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:10,712 INFO:     Epoch: 60
2023-01-04 22:13:12,893 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48828651833658415, 'Total loss': 0.48828651833658415} | train loss {'Reaction outcome loss': 0.19798948115372247, 'Total loss': 0.19798948115372247}
2023-01-04 22:13:12,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:12,894 INFO:     Epoch: 61
2023-01-04 22:13:15,172 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49177909791469576, 'Total loss': 0.49177909791469576} | train loss {'Reaction outcome loss': 0.19518808216747383, 'Total loss': 0.19518808216747383}
2023-01-04 22:13:15,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:15,173 INFO:     Epoch: 62
2023-01-04 22:13:17,486 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48908283313115436, 'Total loss': 0.48908283313115436} | train loss {'Reaction outcome loss': 0.2186824309705169, 'Total loss': 0.2186824309705169}
2023-01-04 22:13:17,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:17,486 INFO:     Epoch: 63
2023-01-04 22:13:19,713 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4866522431373596, 'Total loss': 0.4866522431373596} | train loss {'Reaction outcome loss': 0.18432801023827514, 'Total loss': 0.18432801023827514}
2023-01-04 22:13:19,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:19,714 INFO:     Epoch: 64
2023-01-04 22:13:21,914 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4839560091495514, 'Total loss': 0.4839560091495514} | train loss {'Reaction outcome loss': 0.177698373416944, 'Total loss': 0.177698373416944}
2023-01-04 22:13:21,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:21,914 INFO:     Epoch: 65
2023-01-04 22:13:24,145 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4769787232081095, 'Total loss': 0.4769787232081095} | train loss {'Reaction outcome loss': 0.1729136547700087, 'Total loss': 0.1729136547700087}
2023-01-04 22:13:24,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:24,146 INFO:     Epoch: 66
2023-01-04 22:13:26,356 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4919128268957138, 'Total loss': 0.4919128268957138} | train loss {'Reaction outcome loss': 0.17469889413418507, 'Total loss': 0.17469889413418507}
2023-01-04 22:13:26,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:26,357 INFO:     Epoch: 67
2023-01-04 22:13:28,578 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5157785842816035, 'Total loss': 0.5157785842816035} | train loss {'Reaction outcome loss': 0.17315560909565134, 'Total loss': 0.17315560909565134}
2023-01-04 22:13:28,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:28,578 INFO:     Epoch: 68
2023-01-04 22:13:30,844 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4698232114315033, 'Total loss': 0.4698232114315033} | train loss {'Reaction outcome loss': 0.17106398976276346, 'Total loss': 0.17106398976276346}
2023-01-04 22:13:30,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:30,844 INFO:     Epoch: 69
2023-01-04 22:13:33,110 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5139549672603607, 'Total loss': 0.5139549672603607} | train loss {'Reaction outcome loss': 0.16973576008762314, 'Total loss': 0.16973576008762314}
2023-01-04 22:13:33,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:33,111 INFO:     Epoch: 70
2023-01-04 22:13:35,363 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48643156290054324, 'Total loss': 0.48643156290054324} | train loss {'Reaction outcome loss': 0.17546751595986332, 'Total loss': 0.17546751595986332}
2023-01-04 22:13:35,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:35,363 INFO:     Epoch: 71
2023-01-04 22:13:37,613 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4611930896838506, 'Total loss': 0.4611930896838506} | train loss {'Reaction outcome loss': 0.16901572720709498, 'Total loss': 0.16901572720709498}
2023-01-04 22:13:37,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:37,613 INFO:     Epoch: 72
2023-01-04 22:13:39,833 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5301067709922791, 'Total loss': 0.5301067709922791} | train loss {'Reaction outcome loss': 0.17174561788704232, 'Total loss': 0.17174561788704232}
2023-01-04 22:13:39,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:39,835 INFO:     Epoch: 73
2023-01-04 22:13:42,146 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4831699957450231, 'Total loss': 0.4831699957450231} | train loss {'Reaction outcome loss': 0.1706599789301264, 'Total loss': 0.1706599789301264}
2023-01-04 22:13:42,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:42,147 INFO:     Epoch: 74
2023-01-04 22:13:44,412 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48833972165981926, 'Total loss': 0.48833972165981926} | train loss {'Reaction outcome loss': 0.1709030439659187, 'Total loss': 0.1709030439659187}
2023-01-04 22:13:44,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:44,413 INFO:     Epoch: 75
2023-01-04 22:13:46,656 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4791604608297348, 'Total loss': 0.4791604608297348} | train loss {'Reaction outcome loss': 0.16784710853792512, 'Total loss': 0.16784710853792512}
2023-01-04 22:13:46,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:46,656 INFO:     Epoch: 76
2023-01-04 22:13:48,898 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5075035283962885, 'Total loss': 0.5075035283962885} | train loss {'Reaction outcome loss': 0.1643334045753228, 'Total loss': 0.1643334045753228}
2023-01-04 22:13:48,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:48,898 INFO:     Epoch: 77
2023-01-04 22:13:51,160 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49925975799560546, 'Total loss': 0.49925975799560546} | train loss {'Reaction outcome loss': 0.16438886672546252, 'Total loss': 0.16438886672546252}
2023-01-04 22:13:51,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:51,162 INFO:     Epoch: 78
2023-01-04 22:13:53,426 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47171374162038165, 'Total loss': 0.47171374162038165} | train loss {'Reaction outcome loss': 0.16839501045414826, 'Total loss': 0.16839501045414826}
2023-01-04 22:13:53,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:53,426 INFO:     Epoch: 79
2023-01-04 22:13:55,673 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48406440317630767, 'Total loss': 0.48406440317630767} | train loss {'Reaction outcome loss': 0.16237673682332135, 'Total loss': 0.16237673682332135}
2023-01-04 22:13:55,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:55,673 INFO:     Epoch: 80
2023-01-04 22:13:57,884 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4916967213153839, 'Total loss': 0.4916967213153839} | train loss {'Reaction outcome loss': 0.16753654525245856, 'Total loss': 0.16753654525245856}
2023-01-04 22:13:57,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:13:57,885 INFO:     Epoch: 81
2023-01-04 22:14:00,122 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5174494047959646, 'Total loss': 0.5174494047959646} | train loss {'Reaction outcome loss': 0.1667198314671071, 'Total loss': 0.1667198314671071}
2023-01-04 22:14:00,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:00,123 INFO:     Epoch: 82
2023-01-04 22:14:02,409 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4902508755524953, 'Total loss': 0.4902508755524953} | train loss {'Reaction outcome loss': 0.16433498848303882, 'Total loss': 0.16433498848303882}
2023-01-04 22:14:02,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:02,416 INFO:     Epoch: 83
2023-01-04 22:14:04,690 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49042426347732543, 'Total loss': 0.49042426347732543} | train loss {'Reaction outcome loss': 0.1591355033119495, 'Total loss': 0.1591355033119495}
2023-01-04 22:14:04,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:04,690 INFO:     Epoch: 84
2023-01-04 22:14:06,938 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5071658968925477, 'Total loss': 0.5071658968925477} | train loss {'Reaction outcome loss': 0.1600044901127188, 'Total loss': 0.1600044901127188}
2023-01-04 22:14:06,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:06,938 INFO:     Epoch: 85
2023-01-04 22:14:09,194 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5288657714923223, 'Total loss': 0.5288657714923223} | train loss {'Reaction outcome loss': 0.16002842253985125, 'Total loss': 0.16002842253985125}
2023-01-04 22:14:09,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:09,196 INFO:     Epoch: 86
2023-01-04 22:14:11,455 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5222614248593648, 'Total loss': 0.5222614248593648} | train loss {'Reaction outcome loss': 0.16505731380775746, 'Total loss': 0.16505731380775746}
2023-01-04 22:14:11,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:11,455 INFO:     Epoch: 87
2023-01-04 22:14:13,715 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5264975657065709, 'Total loss': 0.5264975657065709} | train loss {'Reaction outcome loss': 0.1659957135140059, 'Total loss': 0.1659957135140059}
2023-01-04 22:14:13,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:13,715 INFO:     Epoch: 88
2023-01-04 22:14:15,977 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5262153029441834, 'Total loss': 0.5262153029441834} | train loss {'Reaction outcome loss': 0.18348999327661106, 'Total loss': 0.18348999327661106}
2023-01-04 22:14:15,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:15,978 INFO:     Epoch: 89
2023-01-04 22:14:18,252 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4798440833886464, 'Total loss': 0.4798440833886464} | train loss {'Reaction outcome loss': 0.15933246219756783, 'Total loss': 0.15933246219756783}
2023-01-04 22:14:18,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:18,253 INFO:     Epoch: 90
2023-01-04 22:14:20,529 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4841083208719889, 'Total loss': 0.4841083208719889} | train loss {'Reaction outcome loss': 0.15710629589233102, 'Total loss': 0.15710629589233102}
2023-01-04 22:14:20,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:20,530 INFO:     Epoch: 91
2023-01-04 22:14:22,796 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5179488201936086, 'Total loss': 0.5179488201936086} | train loss {'Reaction outcome loss': 0.15743788493800556, 'Total loss': 0.15743788493800556}
2023-01-04 22:14:22,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:22,797 INFO:     Epoch: 92
2023-01-04 22:14:24,952 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49721505840619407, 'Total loss': 0.49721505840619407} | train loss {'Reaction outcome loss': 0.15992915091624457, 'Total loss': 0.15992915091624457}
2023-01-04 22:14:24,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:24,952 INFO:     Epoch: 93
2023-01-04 22:14:27,188 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.528064814209938, 'Total loss': 0.528064814209938} | train loss {'Reaction outcome loss': 0.1543407408437064, 'Total loss': 0.1543407408437064}
2023-01-04 22:14:27,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:27,189 INFO:     Epoch: 94
2023-01-04 22:14:29,413 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5010361701250077, 'Total loss': 0.5010361701250077} | train loss {'Reaction outcome loss': 0.15800259498190944, 'Total loss': 0.15800259498190944}
2023-01-04 22:14:29,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:29,413 INFO:     Epoch: 95
2023-01-04 22:14:31,673 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5115083158016205, 'Total loss': 0.5115083158016205} | train loss {'Reaction outcome loss': 0.16074202537023718, 'Total loss': 0.16074202537023718}
2023-01-04 22:14:31,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:31,673 INFO:     Epoch: 96
2023-01-04 22:14:33,899 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4958680957555771, 'Total loss': 0.4958680957555771} | train loss {'Reaction outcome loss': 0.15924540170016227, 'Total loss': 0.15924540170016227}
2023-01-04 22:14:33,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:33,900 INFO:     Epoch: 97
2023-01-04 22:14:36,140 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48383883833885194, 'Total loss': 0.48383883833885194} | train loss {'Reaction outcome loss': 0.15732685977886635, 'Total loss': 0.15732685977886635}
2023-01-04 22:14:36,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:36,140 INFO:     Epoch: 98
2023-01-04 22:14:38,398 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5065396716197331, 'Total loss': 0.5065396716197331} | train loss {'Reaction outcome loss': 0.15479687905188758, 'Total loss': 0.15479687905188758}
2023-01-04 22:14:38,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:38,398 INFO:     Epoch: 99
2023-01-04 22:14:40,653 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49135277916987735, 'Total loss': 0.49135277916987735} | train loss {'Reaction outcome loss': 0.16135639960766243, 'Total loss': 0.16135639960766243}
2023-01-04 22:14:40,654 INFO:     Best model found after epoch 47 of 100.
2023-01-04 22:14:40,654 INFO:   Done with stage: TRAINING
2023-01-04 22:14:40,654 INFO:   Starting stage: EVALUATION
2023-01-04 22:14:40,790 INFO:   Done with stage: EVALUATION
2023-01-04 22:14:40,790 INFO:   Leaving out SEQ value Fold_8
2023-01-04 22:14:40,803 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 22:14:40,803 INFO:   Starting stage: FEATURE SCALING
2023-01-04 22:14:41,456 INFO:   Done with stage: FEATURE SCALING
2023-01-04 22:14:41,456 INFO:   Starting stage: SCALING TARGETS
2023-01-04 22:14:41,527 INFO:   Done with stage: SCALING TARGETS
2023-01-04 22:14:41,528 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:14:41,528 INFO:     No hyperparam tuning for this model
2023-01-04 22:14:41,528 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:14:41,528 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 22:14:41,529 INFO:     None feature selector for col prot
2023-01-04 22:14:41,529 INFO:     None feature selector for col prot
2023-01-04 22:14:41,529 INFO:     None feature selector for col prot
2023-01-04 22:14:41,529 INFO:     None feature selector for col chem
2023-01-04 22:14:41,529 INFO:     None feature selector for col chem
2023-01-04 22:14:41,529 INFO:     None feature selector for col chem
2023-01-04 22:14:41,530 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 22:14:41,530 INFO:   Starting stage: BUILD MODEL
2023-01-04 22:14:41,531 INFO:     Number of params in model 72931
2023-01-04 22:14:41,534 INFO:   Done with stage: BUILD MODEL
2023-01-04 22:14:41,534 INFO:   Starting stage: TRAINING
2023-01-04 22:14:41,595 INFO:     Val loss before train {'Reaction outcome loss': 0.9315282086531321, 'Total loss': 0.9315282086531321}
2023-01-04 22:14:41,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:41,595 INFO:     Epoch: 0
2023-01-04 22:14:43,841 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7328050136566162, 'Total loss': 0.7328050136566162} | train loss {'Reaction outcome loss': 0.9478175688831918, 'Total loss': 0.9478175688831918}
2023-01-04 22:14:43,841 INFO:     Found new best model at epoch 0
2023-01-04 22:14:43,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:43,843 INFO:     Epoch: 1
2023-01-04 22:14:46,104 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5474149296681087, 'Total loss': 0.5474149296681087} | train loss {'Reaction outcome loss': 0.6352358139928768, 'Total loss': 0.6352358139928768}
2023-01-04 22:14:46,105 INFO:     Found new best model at epoch 1
2023-01-04 22:14:46,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:46,106 INFO:     Epoch: 2
2023-01-04 22:14:48,324 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49386569460233054, 'Total loss': 0.49386569460233054} | train loss {'Reaction outcome loss': 0.5483177958083325, 'Total loss': 0.5483177958083325}
2023-01-04 22:14:48,324 INFO:     Found new best model at epoch 2
2023-01-04 22:14:48,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:48,326 INFO:     Epoch: 3
2023-01-04 22:14:50,581 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4792559583981832, 'Total loss': 0.4792559583981832} | train loss {'Reaction outcome loss': 0.5084347831345993, 'Total loss': 0.5084347831345993}
2023-01-04 22:14:50,583 INFO:     Found new best model at epoch 3
2023-01-04 22:14:50,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:50,584 INFO:     Epoch: 4
2023-01-04 22:14:52,886 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4643138378858566, 'Total loss': 0.4643138378858566} | train loss {'Reaction outcome loss': 0.47716612866539776, 'Total loss': 0.47716612866539776}
2023-01-04 22:14:52,886 INFO:     Found new best model at epoch 4
2023-01-04 22:14:52,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:52,888 INFO:     Epoch: 5
2023-01-04 22:14:55,156 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45340654452641804, 'Total loss': 0.45340654452641804} | train loss {'Reaction outcome loss': 0.45223548357471766, 'Total loss': 0.45223548357471766}
2023-01-04 22:14:55,157 INFO:     Found new best model at epoch 5
2023-01-04 22:14:55,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:55,158 INFO:     Epoch: 6
2023-01-04 22:14:57,493 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43058667580286664, 'Total loss': 0.43058667580286664} | train loss {'Reaction outcome loss': 0.42925811115233903, 'Total loss': 0.42925811115233903}
2023-01-04 22:14:57,494 INFO:     Found new best model at epoch 6
2023-01-04 22:14:57,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:57,495 INFO:     Epoch: 7
2023-01-04 22:14:59,783 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44082937041918435, 'Total loss': 0.44082937041918435} | train loss {'Reaction outcome loss': 0.41929125061184436, 'Total loss': 0.41929125061184436}
2023-01-04 22:14:59,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:14:59,784 INFO:     Epoch: 8
2023-01-04 22:15:02,067 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4369488745927811, 'Total loss': 0.4369488745927811} | train loss {'Reaction outcome loss': 0.4021176322959313, 'Total loss': 0.4021176322959313}
2023-01-04 22:15:02,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:02,068 INFO:     Epoch: 9
2023-01-04 22:15:04,355 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40200137297312416, 'Total loss': 0.40200137297312416} | train loss {'Reaction outcome loss': 0.39285613224785554, 'Total loss': 0.39285613224785554}
2023-01-04 22:15:04,355 INFO:     Found new best model at epoch 9
2023-01-04 22:15:04,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:04,357 INFO:     Epoch: 10
2023-01-04 22:15:06,610 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40568005641301474, 'Total loss': 0.40568005641301474} | train loss {'Reaction outcome loss': 0.3824641773480571, 'Total loss': 0.3824641773480571}
2023-01-04 22:15:06,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:06,611 INFO:     Epoch: 11
2023-01-04 22:15:08,896 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4171587268511454, 'Total loss': 0.4171587268511454} | train loss {'Reaction outcome loss': 0.37242571297827165, 'Total loss': 0.37242571297827165}
2023-01-04 22:15:08,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:08,896 INFO:     Epoch: 12
2023-01-04 22:15:11,161 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3952356457710266, 'Total loss': 0.3952356457710266} | train loss {'Reaction outcome loss': 0.3639148186784292, 'Total loss': 0.3639148186784292}
2023-01-04 22:15:11,161 INFO:     Found new best model at epoch 12
2023-01-04 22:15:11,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:11,162 INFO:     Epoch: 13
2023-01-04 22:15:13,438 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40431808431943256, 'Total loss': 0.40431808431943256} | train loss {'Reaction outcome loss': 0.3549991229623286, 'Total loss': 0.3549991229623286}
2023-01-04 22:15:13,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:13,439 INFO:     Epoch: 14
2023-01-04 22:15:15,715 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41867416103680927, 'Total loss': 0.41867416103680927} | train loss {'Reaction outcome loss': 0.3454171629849082, 'Total loss': 0.3454171629849082}
2023-01-04 22:15:15,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:15,716 INFO:     Epoch: 15
2023-01-04 22:15:17,997 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.38993083834648135, 'Total loss': 0.38993083834648135} | train loss {'Reaction outcome loss': 0.3327708079047717, 'Total loss': 0.3327708079047717}
2023-01-04 22:15:17,997 INFO:     Found new best model at epoch 15
2023-01-04 22:15:17,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:17,999 INFO:     Epoch: 16
2023-01-04 22:15:20,271 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39427267710367836, 'Total loss': 0.39427267710367836} | train loss {'Reaction outcome loss': 0.3347175807314183, 'Total loss': 0.3347175807314183}
2023-01-04 22:15:20,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:20,272 INFO:     Epoch: 17
2023-01-04 22:15:22,542 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38913374543190005, 'Total loss': 0.38913374543190005} | train loss {'Reaction outcome loss': 0.3230766447233981, 'Total loss': 0.3230766447233981}
2023-01-04 22:15:22,542 INFO:     Found new best model at epoch 17
2023-01-04 22:15:22,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:22,544 INFO:     Epoch: 18
2023-01-04 22:15:24,829 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3934795168538888, 'Total loss': 0.3934795168538888} | train loss {'Reaction outcome loss': 0.3179155082671323, 'Total loss': 0.3179155082671323}
2023-01-04 22:15:24,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:24,831 INFO:     Epoch: 19
2023-01-04 22:15:27,099 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3934076209863027, 'Total loss': 0.3934076209863027} | train loss {'Reaction outcome loss': 0.3120858115340209, 'Total loss': 0.3120858115340209}
2023-01-04 22:15:27,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:27,100 INFO:     Epoch: 20
2023-01-04 22:15:29,366 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.37069864322741825, 'Total loss': 0.37069864322741825} | train loss {'Reaction outcome loss': 0.3073531367961128, 'Total loss': 0.3073531367961128}
2023-01-04 22:15:29,366 INFO:     Found new best model at epoch 20
2023-01-04 22:15:29,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:29,367 INFO:     Epoch: 21
2023-01-04 22:15:31,589 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39331154773632687, 'Total loss': 0.39331154773632687} | train loss {'Reaction outcome loss': 0.30427285433625395, 'Total loss': 0.30427285433625395}
2023-01-04 22:15:31,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:31,591 INFO:     Epoch: 22
2023-01-04 22:15:33,835 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3857819616794586, 'Total loss': 0.3857819616794586} | train loss {'Reaction outcome loss': 0.296672252932668, 'Total loss': 0.296672252932668}
2023-01-04 22:15:33,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:33,835 INFO:     Epoch: 23
2023-01-04 22:15:35,704 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.37368711332480115, 'Total loss': 0.37368711332480115} | train loss {'Reaction outcome loss': 0.2932720819435022, 'Total loss': 0.2932720819435022}
2023-01-04 22:15:35,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:35,705 INFO:     Epoch: 24
2023-01-04 22:15:37,603 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40937582949797313, 'Total loss': 0.40937582949797313} | train loss {'Reaction outcome loss': 0.2867881812803123, 'Total loss': 0.2867881812803123}
2023-01-04 22:15:37,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:37,605 INFO:     Epoch: 25
2023-01-04 22:15:39,771 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.37317080597082775, 'Total loss': 0.37317080597082775} | train loss {'Reaction outcome loss': 0.28402748400980854, 'Total loss': 0.28402748400980854}
2023-01-04 22:15:39,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:39,771 INFO:     Epoch: 26
2023-01-04 22:15:41,995 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39447975357373555, 'Total loss': 0.39447975357373555} | train loss {'Reaction outcome loss': 0.281051248392981, 'Total loss': 0.281051248392981}
2023-01-04 22:15:41,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:41,996 INFO:     Epoch: 27
2023-01-04 22:15:44,259 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3950691193342209, 'Total loss': 0.3950691193342209} | train loss {'Reaction outcome loss': 0.27101314671850507, 'Total loss': 0.27101314671850507}
2023-01-04 22:15:44,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:44,260 INFO:     Epoch: 28
2023-01-04 22:15:46,538 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3980882495641708, 'Total loss': 0.3980882495641708} | train loss {'Reaction outcome loss': 0.26566426274476346, 'Total loss': 0.26566426274476346}
2023-01-04 22:15:46,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:46,538 INFO:     Epoch: 29
2023-01-04 22:15:48,771 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3905527003109455, 'Total loss': 0.3905527003109455} | train loss {'Reaction outcome loss': 0.2660142925143173, 'Total loss': 0.2660142925143173}
2023-01-04 22:15:48,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:48,773 INFO:     Epoch: 30
2023-01-04 22:15:51,013 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3695237363378207, 'Total loss': 0.3695237363378207} | train loss {'Reaction outcome loss': 0.26031391371878376, 'Total loss': 0.26031391371878376}
2023-01-04 22:15:51,013 INFO:     Found new best model at epoch 30
2023-01-04 22:15:51,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:51,014 INFO:     Epoch: 31
2023-01-04 22:15:53,233 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3996053715546926, 'Total loss': 0.3996053715546926} | train loss {'Reaction outcome loss': 0.26017671242606005, 'Total loss': 0.26017671242606005}
2023-01-04 22:15:53,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:53,234 INFO:     Epoch: 32
2023-01-04 22:15:55,517 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39762442409992216, 'Total loss': 0.39762442409992216} | train loss {'Reaction outcome loss': 0.25515410844051023, 'Total loss': 0.25515410844051023}
2023-01-04 22:15:55,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:55,518 INFO:     Epoch: 33
2023-01-04 22:15:57,777 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42874644498030345, 'Total loss': 0.42874644498030345} | train loss {'Reaction outcome loss': 0.25268318379918736, 'Total loss': 0.25268318379918736}
2023-01-04 22:15:57,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:15:57,777 INFO:     Epoch: 34
2023-01-04 22:16:00,050 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3849001511931419, 'Total loss': 0.3849001511931419} | train loss {'Reaction outcome loss': 0.2688306955539662, 'Total loss': 0.2688306955539662}
2023-01-04 22:16:00,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:00,051 INFO:     Epoch: 35
2023-01-04 22:16:02,301 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3807052959998449, 'Total loss': 0.3807052959998449} | train loss {'Reaction outcome loss': 0.25032690333445434, 'Total loss': 0.25032690333445434}
2023-01-04 22:16:02,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:02,302 INFO:     Epoch: 36
2023-01-04 22:16:04,559 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.388809568186601, 'Total loss': 0.388809568186601} | train loss {'Reaction outcome loss': 0.2421974026719513, 'Total loss': 0.2421974026719513}
2023-01-04 22:16:04,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:04,559 INFO:     Epoch: 37
2023-01-04 22:16:06,794 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3588103393713633, 'Total loss': 0.3588103393713633} | train loss {'Reaction outcome loss': 0.24580825205581883, 'Total loss': 0.24580825205581883}
2023-01-04 22:16:06,795 INFO:     Found new best model at epoch 37
2023-01-04 22:16:06,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:06,796 INFO:     Epoch: 38
2023-01-04 22:16:09,033 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.37842754969994225, 'Total loss': 0.37842754969994225} | train loss {'Reaction outcome loss': 0.2399729822350639, 'Total loss': 0.2399729822350639}
2023-01-04 22:16:09,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:09,033 INFO:     Epoch: 39
2023-01-04 22:16:11,266 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3851948787768682, 'Total loss': 0.3851948787768682} | train loss {'Reaction outcome loss': 0.2366621260939544, 'Total loss': 0.2366621260939544}
2023-01-04 22:16:11,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:11,267 INFO:     Epoch: 40
2023-01-04 22:16:13,498 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3743248467644056, 'Total loss': 0.3743248467644056} | train loss {'Reaction outcome loss': 0.23474162591931721, 'Total loss': 0.23474162591931721}
2023-01-04 22:16:13,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:13,499 INFO:     Epoch: 41
2023-01-04 22:16:15,712 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3972529118259748, 'Total loss': 0.3972529118259748} | train loss {'Reaction outcome loss': 0.2331384774024891, 'Total loss': 0.2331384774024891}
2023-01-04 22:16:15,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:15,712 INFO:     Epoch: 42
2023-01-04 22:16:17,952 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3723564053575198, 'Total loss': 0.3723564053575198} | train loss {'Reaction outcome loss': 0.24269830390298064, 'Total loss': 0.24269830390298064}
2023-01-04 22:16:17,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:17,953 INFO:     Epoch: 43
2023-01-04 22:16:20,196 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3867954519887765, 'Total loss': 0.3867954519887765} | train loss {'Reaction outcome loss': 0.23537947695729308, 'Total loss': 0.23537947695729308}
2023-01-04 22:16:20,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:20,196 INFO:     Epoch: 44
2023-01-04 22:16:22,416 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.395202166835467, 'Total loss': 0.395202166835467} | train loss {'Reaction outcome loss': 0.2366497327870541, 'Total loss': 0.2366497327870541}
2023-01-04 22:16:22,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:22,417 INFO:     Epoch: 45
2023-01-04 22:16:24,658 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42409875988960266, 'Total loss': 0.42409875988960266} | train loss {'Reaction outcome loss': 0.23949662334727717, 'Total loss': 0.23949662334727717}
2023-01-04 22:16:24,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:24,658 INFO:     Epoch: 46
2023-01-04 22:16:26,882 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.37018321057160697, 'Total loss': 0.37018321057160697} | train loss {'Reaction outcome loss': 0.22277720897471992, 'Total loss': 0.22277720897471992}
2023-01-04 22:16:26,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:26,882 INFO:     Epoch: 47
2023-01-04 22:16:29,114 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3929606209198634, 'Total loss': 0.3929606209198634} | train loss {'Reaction outcome loss': 0.21881329470678515, 'Total loss': 0.21881329470678515}
2023-01-04 22:16:29,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:29,116 INFO:     Epoch: 48
2023-01-04 22:16:31,346 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4062536810835203, 'Total loss': 0.4062536810835203} | train loss {'Reaction outcome loss': 0.21423513734855765, 'Total loss': 0.21423513734855765}
2023-01-04 22:16:31,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:31,347 INFO:     Epoch: 49
2023-01-04 22:16:33,582 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40499796768029533, 'Total loss': 0.40499796768029533} | train loss {'Reaction outcome loss': 0.21745375652993232, 'Total loss': 0.21745375652993232}
2023-01-04 22:16:33,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:33,583 INFO:     Epoch: 50
2023-01-04 22:16:35,817 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39408150215943655, 'Total loss': 0.39408150215943655} | train loss {'Reaction outcome loss': 0.21379640859062868, 'Total loss': 0.21379640859062868}
2023-01-04 22:16:35,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:35,818 INFO:     Epoch: 51
2023-01-04 22:16:38,038 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43848230987787246, 'Total loss': 0.43848230987787246} | train loss {'Reaction outcome loss': 0.20821608409797604, 'Total loss': 0.20821608409797604}
2023-01-04 22:16:38,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:38,038 INFO:     Epoch: 52
2023-01-04 22:16:40,141 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39684983491897585, 'Total loss': 0.39684983491897585} | train loss {'Reaction outcome loss': 0.21215736172566918, 'Total loss': 0.21215736172566918}
2023-01-04 22:16:40,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:40,142 INFO:     Epoch: 53
2023-01-04 22:16:42,337 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41422213315963746, 'Total loss': 0.41422213315963746} | train loss {'Reaction outcome loss': 0.21165036093578607, 'Total loss': 0.21165036093578607}
2023-01-04 22:16:42,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:42,337 INFO:     Epoch: 54
2023-01-04 22:16:44,615 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42470684349536897, 'Total loss': 0.42470684349536897} | train loss {'Reaction outcome loss': 0.20412009258828787, 'Total loss': 0.20412009258828787}
2023-01-04 22:16:44,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:44,615 INFO:     Epoch: 55
2023-01-04 22:16:46,771 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3680994313210249, 'Total loss': 0.3680994313210249} | train loss {'Reaction outcome loss': 0.20122159711436194, 'Total loss': 0.20122159711436194}
2023-01-04 22:16:46,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:46,772 INFO:     Epoch: 56
2023-01-04 22:16:49,046 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3992865651845932, 'Total loss': 0.3992865651845932} | train loss {'Reaction outcome loss': 0.20129240182807512, 'Total loss': 0.20129240182807512}
2023-01-04 22:16:49,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:49,046 INFO:     Epoch: 57
2023-01-04 22:16:51,329 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42806543012460074, 'Total loss': 0.42806543012460074} | train loss {'Reaction outcome loss': 0.20123218471670282, 'Total loss': 0.20123218471670282}
2023-01-04 22:16:51,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:51,330 INFO:     Epoch: 58
2023-01-04 22:16:53,620 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44690546989440916, 'Total loss': 0.44690546989440916} | train loss {'Reaction outcome loss': 0.19758185688188215, 'Total loss': 0.19758185688188215}
2023-01-04 22:16:53,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:53,620 INFO:     Epoch: 59
2023-01-04 22:16:55,897 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3981285775701205, 'Total loss': 0.3981285775701205} | train loss {'Reaction outcome loss': 0.20026325673117393, 'Total loss': 0.20026325673117393}
2023-01-04 22:16:55,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:55,897 INFO:     Epoch: 60
2023-01-04 22:16:58,166 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4095614830652873, 'Total loss': 0.4095614830652873} | train loss {'Reaction outcome loss': 0.20148011777158556, 'Total loss': 0.20148011777158556}
2023-01-04 22:16:58,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:16:58,167 INFO:     Epoch: 61
2023-01-04 22:17:00,437 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.393302313486735, 'Total loss': 0.393302313486735} | train loss {'Reaction outcome loss': 0.19264722565539938, 'Total loss': 0.19264722565539938}
2023-01-04 22:17:00,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:00,438 INFO:     Epoch: 62
2023-01-04 22:17:02,647 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4296509673198064, 'Total loss': 0.4296509673198064} | train loss {'Reaction outcome loss': 0.1936101363465676, 'Total loss': 0.1936101363465676}
2023-01-04 22:17:02,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:02,648 INFO:     Epoch: 63
2023-01-04 22:17:04,915 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4157102207342784, 'Total loss': 0.4157102207342784} | train loss {'Reaction outcome loss': 0.19351379396986912, 'Total loss': 0.19351379396986912}
2023-01-04 22:17:04,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:04,915 INFO:     Epoch: 64
2023-01-04 22:17:07,192 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4220429539680481, 'Total loss': 0.4220429539680481} | train loss {'Reaction outcome loss': 0.19459938459402876, 'Total loss': 0.19459938459402876}
2023-01-04 22:17:07,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:07,192 INFO:     Epoch: 65
2023-01-04 22:17:09,476 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41674538850784304, 'Total loss': 0.41674538850784304} | train loss {'Reaction outcome loss': 0.19484012480656468, 'Total loss': 0.19484012480656468}
2023-01-04 22:17:09,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:09,477 INFO:     Epoch: 66
2023-01-04 22:17:11,759 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40969842076301577, 'Total loss': 0.40969842076301577} | train loss {'Reaction outcome loss': 0.18876270799428577, 'Total loss': 0.18876270799428577}
2023-01-04 22:17:11,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:11,759 INFO:     Epoch: 67
2023-01-04 22:17:13,978 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41873112618923186, 'Total loss': 0.41873112618923186} | train loss {'Reaction outcome loss': 0.1948896272485887, 'Total loss': 0.1948896272485887}
2023-01-04 22:17:13,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:13,978 INFO:     Epoch: 68
2023-01-04 22:17:16,249 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.395251785715421, 'Total loss': 0.395251785715421} | train loss {'Reaction outcome loss': 0.1873694087692496, 'Total loss': 0.1873694087692496}
2023-01-04 22:17:16,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:16,251 INFO:     Epoch: 69
2023-01-04 22:17:18,441 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46585795780022937, 'Total loss': 0.46585795780022937} | train loss {'Reaction outcome loss': 0.18565525070421837, 'Total loss': 0.18565525070421837}
2023-01-04 22:17:18,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:18,441 INFO:     Epoch: 70
2023-01-04 22:17:20,721 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4106689612070719, 'Total loss': 0.4106689612070719} | train loss {'Reaction outcome loss': 0.194332586418634, 'Total loss': 0.194332586418634}
2023-01-04 22:17:20,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:20,723 INFO:     Epoch: 71
2023-01-04 22:17:22,993 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4260863761107127, 'Total loss': 0.4260863761107127} | train loss {'Reaction outcome loss': 0.18919675775556982, 'Total loss': 0.18919675775556982}
2023-01-04 22:17:22,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:22,993 INFO:     Epoch: 72
2023-01-04 22:17:25,247 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4485437422990799, 'Total loss': 0.4485437422990799} | train loss {'Reaction outcome loss': 0.18531411770938733, 'Total loss': 0.18531411770938733}
2023-01-04 22:17:25,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:25,248 INFO:     Epoch: 73
2023-01-04 22:17:27,523 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42190398077170055, 'Total loss': 0.42190398077170055} | train loss {'Reaction outcome loss': 0.18605503156879052, 'Total loss': 0.18605503156879052}
2023-01-04 22:17:27,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:27,524 INFO:     Epoch: 74
2023-01-04 22:17:29,808 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4288657486438751, 'Total loss': 0.4288657486438751} | train loss {'Reaction outcome loss': 0.18165224453787232, 'Total loss': 0.18165224453787232}
2023-01-04 22:17:29,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:29,809 INFO:     Epoch: 75
2023-01-04 22:17:32,087 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41604772955179214, 'Total loss': 0.41604772955179214} | train loss {'Reaction outcome loss': 0.1837418158032486, 'Total loss': 0.1837418158032486}
2023-01-04 22:17:32,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:32,088 INFO:     Epoch: 76
2023-01-04 22:17:34,367 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4696339190006256, 'Total loss': 0.4696339190006256} | train loss {'Reaction outcome loss': 0.1836284973786847, 'Total loss': 0.1836284973786847}
2023-01-04 22:17:34,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:34,367 INFO:     Epoch: 77
2023-01-04 22:17:36,632 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4319000686208407, 'Total loss': 0.4319000686208407} | train loss {'Reaction outcome loss': 0.21318707753148308, 'Total loss': 0.21318707753148308}
2023-01-04 22:17:36,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:36,633 INFO:     Epoch: 78
2023-01-04 22:17:38,912 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41748290409644445, 'Total loss': 0.41748290409644445} | train loss {'Reaction outcome loss': 0.19069602196206056, 'Total loss': 0.19069602196206056}
2023-01-04 22:17:38,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:38,914 INFO:     Epoch: 79
2023-01-04 22:17:41,204 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4393512666225433, 'Total loss': 0.4393512666225433} | train loss {'Reaction outcome loss': 0.17803998041510263, 'Total loss': 0.17803998041510263}
2023-01-04 22:17:41,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:41,205 INFO:     Epoch: 80
2023-01-04 22:17:43,506 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44211422801017763, 'Total loss': 0.44211422801017763} | train loss {'Reaction outcome loss': 0.20206872190760475, 'Total loss': 0.20206872190760475}
2023-01-04 22:17:43,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:43,508 INFO:     Epoch: 81
2023-01-04 22:17:45,799 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4414238154888153, 'Total loss': 0.4414238154888153} | train loss {'Reaction outcome loss': 0.17697462269469447, 'Total loss': 0.17697462269469447}
2023-01-04 22:17:45,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:45,800 INFO:     Epoch: 82
2023-01-04 22:17:48,035 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4502021352450053, 'Total loss': 0.4502021352450053} | train loss {'Reaction outcome loss': 0.17679891557149266, 'Total loss': 0.17679891557149266}
2023-01-04 22:17:48,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:48,036 INFO:     Epoch: 83
2023-01-04 22:17:50,322 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44318272868792213, 'Total loss': 0.44318272868792213} | train loss {'Reaction outcome loss': 0.17463142322916267, 'Total loss': 0.17463142322916267}
2023-01-04 22:17:50,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:50,323 INFO:     Epoch: 84
2023-01-04 22:17:52,615 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42418674131234485, 'Total loss': 0.42418674131234485} | train loss {'Reaction outcome loss': 0.17552750950225332, 'Total loss': 0.17552750950225332}
2023-01-04 22:17:52,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:52,615 INFO:     Epoch: 85
2023-01-04 22:17:54,905 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4523175239562988, 'Total loss': 0.4523175239562988} | train loss {'Reaction outcome loss': 0.17782043115964727, 'Total loss': 0.17782043115964727}
2023-01-04 22:17:54,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:54,906 INFO:     Epoch: 86
2023-01-04 22:17:57,147 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44655778507391614, 'Total loss': 0.44655778507391614} | train loss {'Reaction outcome loss': 0.1752091132565102, 'Total loss': 0.1752091132565102}
2023-01-04 22:17:57,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:57,149 INFO:     Epoch: 87
2023-01-04 22:17:59,426 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4551048984130224, 'Total loss': 0.4551048984130224} | train loss {'Reaction outcome loss': 0.17680281990433813, 'Total loss': 0.17680281990433813}
2023-01-04 22:17:59,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:17:59,427 INFO:     Epoch: 88
2023-01-04 22:18:01,704 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4134250735243162, 'Total loss': 0.4134250735243162} | train loss {'Reaction outcome loss': 0.17325067827798615, 'Total loss': 0.17325067827798615}
2023-01-04 22:18:01,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:01,706 INFO:     Epoch: 89
2023-01-04 22:18:03,987 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43361762414375943, 'Total loss': 0.43361762414375943} | train loss {'Reaction outcome loss': 0.17822249397379009, 'Total loss': 0.17822249397379009}
2023-01-04 22:18:03,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:03,987 INFO:     Epoch: 90
2023-01-04 22:18:06,272 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4517840007940928, 'Total loss': 0.4517840007940928} | train loss {'Reaction outcome loss': 0.21047964837888014, 'Total loss': 0.21047964837888014}
2023-01-04 22:18:06,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:06,273 INFO:     Epoch: 91
2023-01-04 22:18:08,568 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4097946281234423, 'Total loss': 0.4097946281234423} | train loss {'Reaction outcome loss': 0.17654941344222028, 'Total loss': 0.17654941344222028}
2023-01-04 22:18:08,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:08,569 INFO:     Epoch: 92
2023-01-04 22:18:10,831 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41557773649692537, 'Total loss': 0.41557773649692537} | train loss {'Reaction outcome loss': 0.17149357507646462, 'Total loss': 0.17149357507646462}
2023-01-04 22:18:10,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:10,831 INFO:     Epoch: 93
2023-01-04 22:18:13,066 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4183431647717953, 'Total loss': 0.4183431647717953} | train loss {'Reaction outcome loss': 0.16858347902967397, 'Total loss': 0.16858347902967397}
2023-01-04 22:18:13,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:13,067 INFO:     Epoch: 94
2023-01-04 22:18:15,344 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4306778366367022, 'Total loss': 0.4306778366367022} | train loss {'Reaction outcome loss': 0.17283503475398215, 'Total loss': 0.17283503475398215}
2023-01-04 22:18:15,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:15,344 INFO:     Epoch: 95
2023-01-04 22:18:17,624 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4368323594331741, 'Total loss': 0.4368323594331741} | train loss {'Reaction outcome loss': 0.17102436485541714, 'Total loss': 0.17102436485541714}
2023-01-04 22:18:17,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:17,625 INFO:     Epoch: 96
2023-01-04 22:18:19,908 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47220927675565083, 'Total loss': 0.47220927675565083} | train loss {'Reaction outcome loss': 0.17011672077532622, 'Total loss': 0.17011672077532622}
2023-01-04 22:18:19,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:19,909 INFO:     Epoch: 97
2023-01-04 22:18:22,173 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4528216560681661, 'Total loss': 0.4528216560681661} | train loss {'Reaction outcome loss': 0.16782681282063056, 'Total loss': 0.16782681282063056}
2023-01-04 22:18:22,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:22,173 INFO:     Epoch: 98
2023-01-04 22:18:24,352 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4501723647117615, 'Total loss': 0.4501723647117615} | train loss {'Reaction outcome loss': 0.17152809292378335, 'Total loss': 0.17152809292378335}
2023-01-04 22:18:24,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:24,352 INFO:     Epoch: 99
2023-01-04 22:18:26,638 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4621557891368866, 'Total loss': 0.4621557891368866} | train loss {'Reaction outcome loss': 0.16731881052491834, 'Total loss': 0.16731881052491834}
2023-01-04 22:18:26,639 INFO:     Best model found after epoch 38 of 100.
2023-01-04 22:18:26,639 INFO:   Done with stage: TRAINING
2023-01-04 22:18:26,639 INFO:   Starting stage: EVALUATION
2023-01-04 22:18:26,775 INFO:   Done with stage: EVALUATION
2023-01-04 22:18:26,775 INFO:   Leaving out SEQ value Fold_9
2023-01-04 22:18:26,788 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 22:18:26,788 INFO:   Starting stage: FEATURE SCALING
2023-01-04 22:18:27,443 INFO:   Done with stage: FEATURE SCALING
2023-01-04 22:18:27,443 INFO:   Starting stage: SCALING TARGETS
2023-01-04 22:18:27,514 INFO:   Done with stage: SCALING TARGETS
2023-01-04 22:18:27,514 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:18:27,514 INFO:     No hyperparam tuning for this model
2023-01-04 22:18:27,514 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:18:27,514 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 22:18:27,515 INFO:     None feature selector for col prot
2023-01-04 22:18:27,515 INFO:     None feature selector for col prot
2023-01-04 22:18:27,515 INFO:     None feature selector for col prot
2023-01-04 22:18:27,516 INFO:     None feature selector for col chem
2023-01-04 22:18:27,516 INFO:     None feature selector for col chem
2023-01-04 22:18:27,516 INFO:     None feature selector for col chem
2023-01-04 22:18:27,516 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 22:18:27,516 INFO:   Starting stage: BUILD MODEL
2023-01-04 22:18:27,517 INFO:     Number of params in model 72931
2023-01-04 22:18:27,521 INFO:   Done with stage: BUILD MODEL
2023-01-04 22:18:27,521 INFO:   Starting stage: TRAINING
2023-01-04 22:18:27,581 INFO:     Val loss before train {'Reaction outcome loss': 1.0325557152430216, 'Total loss': 1.0325557152430216}
2023-01-04 22:18:27,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:27,582 INFO:     Epoch: 0
2023-01-04 22:18:29,853 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8687454342842102, 'Total loss': 0.8687454342842102} | train loss {'Reaction outcome loss': 0.9682816531968074, 'Total loss': 0.9682816531968074}
2023-01-04 22:18:29,853 INFO:     Found new best model at epoch 0
2023-01-04 22:18:29,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:29,854 INFO:     Epoch: 1
2023-01-04 22:18:32,116 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5756277829408646, 'Total loss': 0.5756277829408646} | train loss {'Reaction outcome loss': 0.6811897659782267, 'Total loss': 0.6811897659782267}
2023-01-04 22:18:32,117 INFO:     Found new best model at epoch 1
2023-01-04 22:18:32,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:32,119 INFO:     Epoch: 2
2023-01-04 22:18:34,355 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5528504351774851, 'Total loss': 0.5528504351774851} | train loss {'Reaction outcome loss': 0.5498829230213154, 'Total loss': 0.5498829230213154}
2023-01-04 22:18:34,355 INFO:     Found new best model at epoch 2
2023-01-04 22:18:34,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:34,356 INFO:     Epoch: 3
2023-01-04 22:18:36,587 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5360025286674499, 'Total loss': 0.5360025286674499} | train loss {'Reaction outcome loss': 0.5116622791882011, 'Total loss': 0.5116622791882011}
2023-01-04 22:18:36,587 INFO:     Found new best model at epoch 3
2023-01-04 22:18:36,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:36,589 INFO:     Epoch: 4
2023-01-04 22:18:38,805 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5330516974131266, 'Total loss': 0.5330516974131266} | train loss {'Reaction outcome loss': 0.48505678819239384, 'Total loss': 0.48505678819239384}
2023-01-04 22:18:38,806 INFO:     Found new best model at epoch 4
2023-01-04 22:18:38,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:38,808 INFO:     Epoch: 5
2023-01-04 22:18:41,021 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5111403206984202, 'Total loss': 0.5111403206984202} | train loss {'Reaction outcome loss': 0.4674033346789234, 'Total loss': 0.4674033346789234}
2023-01-04 22:18:41,022 INFO:     Found new best model at epoch 5
2023-01-04 22:18:41,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:41,023 INFO:     Epoch: 6
2023-01-04 22:18:43,287 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5082882603009542, 'Total loss': 0.5082882603009542} | train loss {'Reaction outcome loss': 0.4518232693055483, 'Total loss': 0.4518232693055483}
2023-01-04 22:18:43,287 INFO:     Found new best model at epoch 6
2023-01-04 22:18:43,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:43,289 INFO:     Epoch: 7
2023-01-04 22:18:45,554 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5119044423103333, 'Total loss': 0.5119044423103333} | train loss {'Reaction outcome loss': 0.439089390128662, 'Total loss': 0.439089390128662}
2023-01-04 22:18:45,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:45,554 INFO:     Epoch: 8
2023-01-04 22:18:47,850 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.506506723165512, 'Total loss': 0.506506723165512} | train loss {'Reaction outcome loss': 0.42347954498414975, 'Total loss': 0.42347954498414975}
2023-01-04 22:18:47,851 INFO:     Found new best model at epoch 8
2023-01-04 22:18:47,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:47,852 INFO:     Epoch: 9
2023-01-04 22:18:50,130 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4873378853003184, 'Total loss': 0.4873378853003184} | train loss {'Reaction outcome loss': 0.41205002997826407, 'Total loss': 0.41205002997826407}
2023-01-04 22:18:50,131 INFO:     Found new best model at epoch 9
2023-01-04 22:18:50,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:50,132 INFO:     Epoch: 10
2023-01-04 22:18:52,416 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48806653221448265, 'Total loss': 0.48806653221448265} | train loss {'Reaction outcome loss': 0.40578253221684607, 'Total loss': 0.40578253221684607}
2023-01-04 22:18:52,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:52,417 INFO:     Epoch: 11
2023-01-04 22:18:54,702 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5044122795263927, 'Total loss': 0.5044122795263927} | train loss {'Reaction outcome loss': 0.3954962724684805, 'Total loss': 0.3954962724684805}
2023-01-04 22:18:54,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:54,704 INFO:     Epoch: 12
2023-01-04 22:18:56,981 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4823261320590973, 'Total loss': 0.4823261320590973} | train loss {'Reaction outcome loss': 0.39246403394719126, 'Total loss': 0.39246403394719126}
2023-01-04 22:18:56,981 INFO:     Found new best model at epoch 12
2023-01-04 22:18:56,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:56,982 INFO:     Epoch: 13
2023-01-04 22:18:59,225 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4951555411020915, 'Total loss': 0.4951555411020915} | train loss {'Reaction outcome loss': 0.3777105442646459, 'Total loss': 0.3777105442646459}
2023-01-04 22:18:59,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:18:59,225 INFO:     Epoch: 14
2023-01-04 22:19:01,494 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4643789956967036, 'Total loss': 0.4643789956967036} | train loss {'Reaction outcome loss': 0.3658355502816646, 'Total loss': 0.3658355502816646}
2023-01-04 22:19:01,495 INFO:     Found new best model at epoch 14
2023-01-04 22:19:01,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:01,496 INFO:     Epoch: 15
2023-01-04 22:19:03,763 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5025664259990056, 'Total loss': 0.5025664259990056} | train loss {'Reaction outcome loss': 0.36163778858178336, 'Total loss': 0.36163778858178336}
2023-01-04 22:19:03,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:03,764 INFO:     Epoch: 16
2023-01-04 22:19:06,053 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4919049680233002, 'Total loss': 0.4919049680233002} | train loss {'Reaction outcome loss': 0.3546337416695863, 'Total loss': 0.3546337416695863}
2023-01-04 22:19:06,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:06,054 INFO:     Epoch: 17
2023-01-04 22:19:08,330 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4864973376194636, 'Total loss': 0.4864973376194636} | train loss {'Reaction outcome loss': 0.3630908595641022, 'Total loss': 0.3630908595641022}
2023-01-04 22:19:08,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:08,330 INFO:     Epoch: 18
2023-01-04 22:19:10,568 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4788031389315923, 'Total loss': 0.4788031389315923} | train loss {'Reaction outcome loss': 0.35428147868968657, 'Total loss': 0.35428147868968657}
2023-01-04 22:19:10,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:10,568 INFO:     Epoch: 19
2023-01-04 22:19:12,825 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4675146996974945, 'Total loss': 0.4675146996974945} | train loss {'Reaction outcome loss': 0.333496874732415, 'Total loss': 0.333496874732415}
2023-01-04 22:19:12,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:12,827 INFO:     Epoch: 20
2023-01-04 22:19:15,112 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4865206599235535, 'Total loss': 0.4865206599235535} | train loss {'Reaction outcome loss': 0.3262709134251581, 'Total loss': 0.3262709134251581}
2023-01-04 22:19:15,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:15,112 INFO:     Epoch: 21
2023-01-04 22:19:17,380 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4791469862063726, 'Total loss': 0.4791469862063726} | train loss {'Reaction outcome loss': 0.32097506188396097, 'Total loss': 0.32097506188396097}
2023-01-04 22:19:17,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:17,381 INFO:     Epoch: 22
2023-01-04 22:19:19,660 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45271446704864504, 'Total loss': 0.45271446704864504} | train loss {'Reaction outcome loss': 0.3200634129925806, 'Total loss': 0.3200634129925806}
2023-01-04 22:19:19,660 INFO:     Found new best model at epoch 22
2023-01-04 22:19:19,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:19,662 INFO:     Epoch: 23
2023-01-04 22:19:21,897 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.462619549036026, 'Total loss': 0.462619549036026} | train loss {'Reaction outcome loss': 0.31384411524387373, 'Total loss': 0.31384411524387373}
2023-01-04 22:19:21,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:21,897 INFO:     Epoch: 24
2023-01-04 22:19:24,159 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45724908312161766, 'Total loss': 0.45724908312161766} | train loss {'Reaction outcome loss': 0.3101964620198461, 'Total loss': 0.3101964620198461}
2023-01-04 22:19:24,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:24,160 INFO:     Epoch: 25
2023-01-04 22:19:26,419 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44587535882989565, 'Total loss': 0.44587535882989565} | train loss {'Reaction outcome loss': 0.29727361789910123, 'Total loss': 0.29727361789910123}
2023-01-04 22:19:26,419 INFO:     Found new best model at epoch 25
2023-01-04 22:19:26,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:26,421 INFO:     Epoch: 26
2023-01-04 22:19:28,686 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.464041010538737, 'Total loss': 0.464041010538737} | train loss {'Reaction outcome loss': 0.29411933974420273, 'Total loss': 0.29411933974420273}
2023-01-04 22:19:28,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:28,686 INFO:     Epoch: 27
2023-01-04 22:19:30,974 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48235870599746705, 'Total loss': 0.48235870599746705} | train loss {'Reaction outcome loss': 0.2861426117546532, 'Total loss': 0.2861426117546532}
2023-01-04 22:19:30,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:30,975 INFO:     Epoch: 28
2023-01-04 22:19:33,217 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4949609408775965, 'Total loss': 0.4949609408775965} | train loss {'Reaction outcome loss': 0.2827589366366948, 'Total loss': 0.2827589366366948}
2023-01-04 22:19:33,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:33,217 INFO:     Epoch: 29
2023-01-04 22:19:35,497 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4665302594502767, 'Total loss': 0.4665302594502767} | train loss {'Reaction outcome loss': 0.2820226871341035, 'Total loss': 0.2820226871341035}
2023-01-04 22:19:35,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:35,498 INFO:     Epoch: 30
2023-01-04 22:19:37,733 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46568395296732584, 'Total loss': 0.46568395296732584} | train loss {'Reaction outcome loss': 0.2752740400323671, 'Total loss': 0.2752740400323671}
2023-01-04 22:19:37,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:37,734 INFO:     Epoch: 31
2023-01-04 22:19:40,002 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4820268978675207, 'Total loss': 0.4820268978675207} | train loss {'Reaction outcome loss': 0.2707129543324049, 'Total loss': 0.2707129543324049}
2023-01-04 22:19:40,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:40,002 INFO:     Epoch: 32
2023-01-04 22:19:42,283 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46912270585695903, 'Total loss': 0.46912270585695903} | train loss {'Reaction outcome loss': 0.27116237173533486, 'Total loss': 0.27116237173533486}
2023-01-04 22:19:42,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:42,284 INFO:     Epoch: 33
2023-01-04 22:19:44,538 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4871907869974772, 'Total loss': 0.4871907869974772} | train loss {'Reaction outcome loss': 0.2630468604148136, 'Total loss': 0.2630468604148136}
2023-01-04 22:19:44,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:44,539 INFO:     Epoch: 34
2023-01-04 22:19:46,818 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46302713031570114, 'Total loss': 0.46302713031570114} | train loss {'Reaction outcome loss': 0.2659969161116127, 'Total loss': 0.2659969161116127}
2023-01-04 22:19:46,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:46,819 INFO:     Epoch: 35
2023-01-04 22:19:49,064 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47765203217665353, 'Total loss': 0.47765203217665353} | train loss {'Reaction outcome loss': 0.27968301354673236, 'Total loss': 0.27968301354673236}
2023-01-04 22:19:49,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:49,064 INFO:     Epoch: 36
2023-01-04 22:19:51,342 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4834703544775645, 'Total loss': 0.4834703544775645} | train loss {'Reaction outcome loss': 0.25780150124236295, 'Total loss': 0.25780150124236295}
2023-01-04 22:19:51,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:51,343 INFO:     Epoch: 37
2023-01-04 22:19:53,622 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5002003490924836, 'Total loss': 0.5002003490924836} | train loss {'Reaction outcome loss': 0.2547447193845047, 'Total loss': 0.2547447193845047}
2023-01-04 22:19:53,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:53,623 INFO:     Epoch: 38
2023-01-04 22:19:55,880 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48798157274723053, 'Total loss': 0.48798157274723053} | train loss {'Reaction outcome loss': 0.2492448042764369, 'Total loss': 0.2492448042764369}
2023-01-04 22:19:55,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:55,880 INFO:     Epoch: 39
2023-01-04 22:19:58,084 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47650499939918517, 'Total loss': 0.47650499939918517} | train loss {'Reaction outcome loss': 0.25094651958257286, 'Total loss': 0.25094651958257286}
2023-01-04 22:19:58,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:19:58,085 INFO:     Epoch: 40
2023-01-04 22:20:00,335 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4841179996728897, 'Total loss': 0.4841179996728897} | train loss {'Reaction outcome loss': 0.24318324508435646, 'Total loss': 0.24318324508435646}
2023-01-04 22:20:00,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:00,336 INFO:     Epoch: 41
2023-01-04 22:20:02,588 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4602189858754476, 'Total loss': 0.4602189858754476} | train loss {'Reaction outcome loss': 0.2400310241294695, 'Total loss': 0.2400310241294695}
2023-01-04 22:20:02,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:02,588 INFO:     Epoch: 42
2023-01-04 22:20:04,865 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47388778428236644, 'Total loss': 0.47388778428236644} | train loss {'Reaction outcome loss': 0.2371184179294463, 'Total loss': 0.2371184179294463}
2023-01-04 22:20:04,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:04,866 INFO:     Epoch: 43
2023-01-04 22:20:07,135 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4872094084819158, 'Total loss': 0.4872094084819158} | train loss {'Reaction outcome loss': 0.2386243657624025, 'Total loss': 0.2386243657624025}
2023-01-04 22:20:07,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:07,136 INFO:     Epoch: 44
2023-01-04 22:20:09,398 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5097268164157868, 'Total loss': 0.5097268164157868} | train loss {'Reaction outcome loss': 0.23442664449702125, 'Total loss': 0.23442664449702125}
2023-01-04 22:20:09,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:09,398 INFO:     Epoch: 45
2023-01-04 22:20:11,623 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5091058701276779, 'Total loss': 0.5091058701276779} | train loss {'Reaction outcome loss': 0.231086517026162, 'Total loss': 0.231086517026162}
2023-01-04 22:20:11,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:11,625 INFO:     Epoch: 46
2023-01-04 22:20:13,921 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48379040559132896, 'Total loss': 0.48379040559132896} | train loss {'Reaction outcome loss': 0.23500320570251526, 'Total loss': 0.23500320570251526}
2023-01-04 22:20:13,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:13,922 INFO:     Epoch: 47
2023-01-04 22:20:16,221 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4576608270406723, 'Total loss': 0.4576608270406723} | train loss {'Reaction outcome loss': 0.22786572920307188, 'Total loss': 0.22786572920307188}
2023-01-04 22:20:16,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:16,223 INFO:     Epoch: 48
2023-01-04 22:20:18,509 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.48232463796933495, 'Total loss': 0.48232463796933495} | train loss {'Reaction outcome loss': 0.2276377004193331, 'Total loss': 0.2276377004193331}
2023-01-04 22:20:18,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:18,509 INFO:     Epoch: 49
2023-01-04 22:20:20,771 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4759068042039871, 'Total loss': 0.4759068042039871} | train loss {'Reaction outcome loss': 0.22757982506848656, 'Total loss': 0.22757982506848656}
2023-01-04 22:20:20,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:20,771 INFO:     Epoch: 50
2023-01-04 22:20:22,960 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49968645373980203, 'Total loss': 0.49968645373980203} | train loss {'Reaction outcome loss': 0.23026923349707562, 'Total loss': 0.23026923349707562}
2023-01-04 22:20:22,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:22,961 INFO:     Epoch: 51
2023-01-04 22:20:25,129 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48168495247761406, 'Total loss': 0.48168495247761406} | train loss {'Reaction outcome loss': 0.22526912846091285, 'Total loss': 0.22526912846091285}
2023-01-04 22:20:25,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:25,130 INFO:     Epoch: 52
2023-01-04 22:20:27,416 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5080128073692322, 'Total loss': 0.5080128073692322} | train loss {'Reaction outcome loss': 0.22253767982803527, 'Total loss': 0.22253767982803527}
2023-01-04 22:20:27,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:27,417 INFO:     Epoch: 53
2023-01-04 22:20:29,698 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48818501830101013, 'Total loss': 0.48818501830101013} | train loss {'Reaction outcome loss': 0.2228331085560954, 'Total loss': 0.2228331085560954}
2023-01-04 22:20:29,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:29,700 INFO:     Epoch: 54
2023-01-04 22:20:31,944 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49446728626887004, 'Total loss': 0.49446728626887004} | train loss {'Reaction outcome loss': 0.23473520728462524, 'Total loss': 0.23473520728462524}
2023-01-04 22:20:31,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:31,944 INFO:     Epoch: 55
2023-01-04 22:20:34,224 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4967134614785512, 'Total loss': 0.4967134614785512} | train loss {'Reaction outcome loss': 0.2395343766620499, 'Total loss': 0.2395343766620499}
2023-01-04 22:20:34,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:34,225 INFO:     Epoch: 56
2023-01-04 22:20:36,493 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5037041753530502, 'Total loss': 0.5037041753530502} | train loss {'Reaction outcome loss': 0.22398927881115832, 'Total loss': 0.22398927881115832}
2023-01-04 22:20:36,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:36,494 INFO:     Epoch: 57
2023-01-04 22:20:38,771 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4857656498750051, 'Total loss': 0.4857656498750051} | train loss {'Reaction outcome loss': 0.22042674002190377, 'Total loss': 0.22042674002190377}
2023-01-04 22:20:38,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:38,772 INFO:     Epoch: 58
2023-01-04 22:20:41,044 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5108707924683888, 'Total loss': 0.5108707924683888} | train loss {'Reaction outcome loss': 0.21615140321512666, 'Total loss': 0.21615140321512666}
2023-01-04 22:20:41,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:41,046 INFO:     Epoch: 59
2023-01-04 22:20:43,312 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5194394807020823, 'Total loss': 0.5194394807020823} | train loss {'Reaction outcome loss': 0.2101308894039982, 'Total loss': 0.2101308894039982}
2023-01-04 22:20:43,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:43,312 INFO:     Epoch: 60
2023-01-04 22:20:45,588 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5148086945215861, 'Total loss': 0.5148086945215861} | train loss {'Reaction outcome loss': 0.2172174783612507, 'Total loss': 0.2172174783612507}
2023-01-04 22:20:45,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:45,589 INFO:     Epoch: 61
2023-01-04 22:20:47,874 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5081365336974462, 'Total loss': 0.5081365336974462} | train loss {'Reaction outcome loss': 0.21426891974186985, 'Total loss': 0.21426891974186985}
2023-01-04 22:20:47,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:47,874 INFO:     Epoch: 62
2023-01-04 22:20:50,124 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5191093315680821, 'Total loss': 0.5191093315680821} | train loss {'Reaction outcome loss': 0.20755943618006195, 'Total loss': 0.20755943618006195}
2023-01-04 22:20:50,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:50,125 INFO:     Epoch: 63
2023-01-04 22:20:52,282 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5064933220545451, 'Total loss': 0.5064933220545451} | train loss {'Reaction outcome loss': 0.20489731949983517, 'Total loss': 0.20489731949983517}
2023-01-04 22:20:52,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:52,283 INFO:     Epoch: 64
2023-01-04 22:20:54,481 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5114275415738424, 'Total loss': 0.5114275415738424} | train loss {'Reaction outcome loss': 0.20447486379197327, 'Total loss': 0.20447486379197327}
2023-01-04 22:20:54,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:54,482 INFO:     Epoch: 65
2023-01-04 22:20:56,696 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.49712738196055095, 'Total loss': 0.49712738196055095} | train loss {'Reaction outcome loss': 0.20225972534778217, 'Total loss': 0.20225972534778217}
2023-01-04 22:20:56,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:56,697 INFO:     Epoch: 66
2023-01-04 22:20:59,007 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4757228383173545, 'Total loss': 0.4757228383173545} | train loss {'Reaction outcome loss': 0.20126638204142774, 'Total loss': 0.20126638204142774}
2023-01-04 22:20:59,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:20:59,008 INFO:     Epoch: 67
2023-01-04 22:21:01,251 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5504942933718363, 'Total loss': 0.5504942933718363} | train loss {'Reaction outcome loss': 0.20339814825253427, 'Total loss': 0.20339814825253427}
2023-01-04 22:21:01,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:01,251 INFO:     Epoch: 68
2023-01-04 22:21:03,496 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5406438728173574, 'Total loss': 0.5406438728173574} | train loss {'Reaction outcome loss': 0.19484091112995436, 'Total loss': 0.19484091112995436}
2023-01-04 22:21:03,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:03,497 INFO:     Epoch: 69
2023-01-04 22:21:05,747 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5049648990233739, 'Total loss': 0.5049648990233739} | train loss {'Reaction outcome loss': 0.1961697922693481, 'Total loss': 0.1961697922693481}
2023-01-04 22:21:05,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:05,747 INFO:     Epoch: 70
2023-01-04 22:21:08,000 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5203244090080261, 'Total loss': 0.5203244090080261} | train loss {'Reaction outcome loss': 0.2015254968740181, 'Total loss': 0.2015254968740181}
2023-01-04 22:21:08,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:08,001 INFO:     Epoch: 71
2023-01-04 22:21:10,208 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5215840458869934, 'Total loss': 0.5215840458869934} | train loss {'Reaction outcome loss': 0.1977853720060354, 'Total loss': 0.1977853720060354}
2023-01-04 22:21:10,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:10,208 INFO:     Epoch: 72
2023-01-04 22:21:12,470 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5172366261482239, 'Total loss': 0.5172366261482239} | train loss {'Reaction outcome loss': 0.1918764289036609, 'Total loss': 0.1918764289036609}
2023-01-04 22:21:12,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:12,470 INFO:     Epoch: 73
2023-01-04 22:21:14,744 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5158352315425873, 'Total loss': 0.5158352315425873} | train loss {'Reaction outcome loss': 0.1906674101221564, 'Total loss': 0.1906674101221564}
2023-01-04 22:21:14,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:14,746 INFO:     Epoch: 74
2023-01-04 22:21:17,004 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5139625052611033, 'Total loss': 0.5139625052611033} | train loss {'Reaction outcome loss': 0.19103321043286892, 'Total loss': 0.19103321043286892}
2023-01-04 22:21:17,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:17,004 INFO:     Epoch: 75
2023-01-04 22:21:19,246 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5186946441729864, 'Total loss': 0.5186946441729864} | train loss {'Reaction outcome loss': 0.19203687459198787, 'Total loss': 0.19203687459198787}
2023-01-04 22:21:19,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:19,247 INFO:     Epoch: 76
2023-01-04 22:21:21,513 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.519938733180364, 'Total loss': 0.519938733180364} | train loss {'Reaction outcome loss': 0.1886435390627847, 'Total loss': 0.1886435390627847}
2023-01-04 22:21:21,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:21,513 INFO:     Epoch: 77
2023-01-04 22:21:23,794 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5263059228658676, 'Total loss': 0.5263059228658676} | train loss {'Reaction outcome loss': 0.18454392903578887, 'Total loss': 0.18454392903578887}
2023-01-04 22:21:23,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:23,794 INFO:     Epoch: 78
2023-01-04 22:21:26,073 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4812652627627055, 'Total loss': 0.4812652627627055} | train loss {'Reaction outcome loss': 0.187322718222909, 'Total loss': 0.187322718222909}
2023-01-04 22:21:26,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:26,074 INFO:     Epoch: 79
2023-01-04 22:21:28,339 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.517268047730128, 'Total loss': 0.517268047730128} | train loss {'Reaction outcome loss': 0.18606606055332253, 'Total loss': 0.18606606055332253}
2023-01-04 22:21:28,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:28,339 INFO:     Epoch: 80
2023-01-04 22:21:30,470 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5553760339816411, 'Total loss': 0.5553760339816411} | train loss {'Reaction outcome loss': 0.18152486709574156, 'Total loss': 0.18152486709574156}
2023-01-04 22:21:30,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:30,470 INFO:     Epoch: 81
2023-01-04 22:21:32,716 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49933088620503746, 'Total loss': 0.49933088620503746} | train loss {'Reaction outcome loss': 0.1865920911786025, 'Total loss': 0.1865920911786025}
2023-01-04 22:21:32,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:32,718 INFO:     Epoch: 82
2023-01-04 22:21:34,975 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49155604460587105, 'Total loss': 0.49155604460587105} | train loss {'Reaction outcome loss': 0.185716555983611, 'Total loss': 0.185716555983611}
2023-01-04 22:21:34,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:34,975 INFO:     Epoch: 83
2023-01-04 22:21:37,223 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5141342381636301, 'Total loss': 0.5141342381636301} | train loss {'Reaction outcome loss': 0.18512576105633238, 'Total loss': 0.18512576105633238}
2023-01-04 22:21:37,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:37,224 INFO:     Epoch: 84
2023-01-04 22:21:39,482 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5441414634386699, 'Total loss': 0.5441414634386699} | train loss {'Reaction outcome loss': 0.18018983015697787, 'Total loss': 0.18018983015697787}
2023-01-04 22:21:39,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:39,482 INFO:     Epoch: 85
2023-01-04 22:21:41,738 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5042825758457183, 'Total loss': 0.5042825758457183} | train loss {'Reaction outcome loss': 0.18031542132337272, 'Total loss': 0.18031542132337272}
2023-01-04 22:21:41,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:41,738 INFO:     Epoch: 86
2023-01-04 22:21:43,980 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.526429837445418, 'Total loss': 0.526429837445418} | train loss {'Reaction outcome loss': 0.1810096939249585, 'Total loss': 0.1810096939249585}
2023-01-04 22:21:43,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:43,981 INFO:     Epoch: 87
2023-01-04 22:21:46,256 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5141436556975046, 'Total loss': 0.5141436556975046} | train loss {'Reaction outcome loss': 0.18121974267726898, 'Total loss': 0.18121974267726898}
2023-01-04 22:21:46,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:46,257 INFO:     Epoch: 88
2023-01-04 22:21:48,541 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5186133374770482, 'Total loss': 0.5186133374770482} | train loss {'Reaction outcome loss': 0.20416167587973177, 'Total loss': 0.20416167587973177}
2023-01-04 22:21:48,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:48,542 INFO:     Epoch: 89
2023-01-04 22:21:50,784 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5340152194102605, 'Total loss': 0.5340152194102605} | train loss {'Reaction outcome loss': 0.21179703491314128, 'Total loss': 0.21179703491314128}
2023-01-04 22:21:50,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:50,784 INFO:     Epoch: 90
2023-01-04 22:21:53,046 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5008069356282552, 'Total loss': 0.5008069356282552} | train loss {'Reaction outcome loss': 0.18563490372321542, 'Total loss': 0.18563490372321542}
2023-01-04 22:21:53,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:53,046 INFO:     Epoch: 91
2023-01-04 22:21:55,269 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5216537257035573, 'Total loss': 0.5216537257035573} | train loss {'Reaction outcome loss': 0.20373513443611455, 'Total loss': 0.20373513443611455}
2023-01-04 22:21:55,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:55,270 INFO:     Epoch: 92
2023-01-04 22:21:57,554 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5321511477231979, 'Total loss': 0.5321511477231979} | train loss {'Reaction outcome loss': 0.17669710831250995, 'Total loss': 0.17669710831250995}
2023-01-04 22:21:57,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:57,555 INFO:     Epoch: 93
2023-01-04 22:21:59,806 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5213109175364177, 'Total loss': 0.5213109175364177} | train loss {'Reaction outcome loss': 0.17655241550444084, 'Total loss': 0.17655241550444084}
2023-01-04 22:21:59,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:21:59,806 INFO:     Epoch: 94
2023-01-04 22:22:02,072 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5523440321286519, 'Total loss': 0.5523440321286519} | train loss {'Reaction outcome loss': 0.1757321659976657, 'Total loss': 0.1757321659976657}
2023-01-04 22:22:02,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:02,074 INFO:     Epoch: 95
2023-01-04 22:22:04,302 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5018056457241377, 'Total loss': 0.5018056457241377} | train loss {'Reaction outcome loss': 0.1751455146468947, 'Total loss': 0.1751455146468947}
2023-01-04 22:22:04,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:04,302 INFO:     Epoch: 96
2023-01-04 22:22:06,528 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.519701733191808, 'Total loss': 0.519701733191808} | train loss {'Reaction outcome loss': 0.17879351378067349, 'Total loss': 0.17879351378067349}
2023-01-04 22:22:06,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:06,529 INFO:     Epoch: 97
2023-01-04 22:22:08,771 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5175225774447123, 'Total loss': 0.5175225774447123} | train loss {'Reaction outcome loss': 0.17413555315790186, 'Total loss': 0.17413555315790186}
2023-01-04 22:22:08,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:08,771 INFO:     Epoch: 98
2023-01-04 22:22:11,023 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5462138772010803, 'Total loss': 0.5462138772010803} | train loss {'Reaction outcome loss': 0.17225860349645844, 'Total loss': 0.17225860349645844}
2023-01-04 22:22:11,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:11,023 INFO:     Epoch: 99
2023-01-04 22:22:13,238 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5286136627197265, 'Total loss': 0.5286136627197265} | train loss {'Reaction outcome loss': 0.17199337257192962, 'Total loss': 0.17199337257192962}
2023-01-04 22:22:13,239 INFO:     Best model found after epoch 26 of 100.
2023-01-04 22:22:13,239 INFO:   Done with stage: TRAINING
2023-01-04 22:22:13,239 INFO:   Starting stage: EVALUATION
2023-01-04 22:22:13,374 INFO:   Done with stage: EVALUATION
2023-01-04 22:22:13,382 INFO:   Leaving out SEQ value Fold_0
2023-01-04 22:22:13,395 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-04 22:22:13,395 INFO:   Starting stage: FEATURE SCALING
2023-01-04 22:22:14,040 INFO:   Done with stage: FEATURE SCALING
2023-01-04 22:22:14,040 INFO:   Starting stage: SCALING TARGETS
2023-01-04 22:22:14,112 INFO:   Done with stage: SCALING TARGETS
2023-01-04 22:22:14,112 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:22:14,112 INFO:     No hyperparam tuning for this model
2023-01-04 22:22:14,112 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:22:14,112 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 22:22:14,113 INFO:     None feature selector for col prot
2023-01-04 22:22:14,113 INFO:     None feature selector for col prot
2023-01-04 22:22:14,113 INFO:     None feature selector for col prot
2023-01-04 22:22:14,113 INFO:     None feature selector for col chem
2023-01-04 22:22:14,114 INFO:     None feature selector for col chem
2023-01-04 22:22:14,114 INFO:     None feature selector for col chem
2023-01-04 22:22:14,114 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 22:22:14,114 INFO:   Starting stage: BUILD MODEL
2023-01-04 22:22:14,115 INFO:     Number of params in model 72931
2023-01-04 22:22:14,118 INFO:   Done with stage: BUILD MODEL
2023-01-04 22:22:14,119 INFO:   Starting stage: TRAINING
2023-01-04 22:22:14,180 INFO:     Val loss before train {'Reaction outcome loss': 0.9416993975639343, 'Total loss': 0.9416993975639343}
2023-01-04 22:22:14,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:14,180 INFO:     Epoch: 0
2023-01-04 22:22:16,360 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7653347929318746, 'Total loss': 0.7653347929318746} | train loss {'Reaction outcome loss': 0.9306950359106944, 'Total loss': 0.9306950359106944}
2023-01-04 22:22:16,361 INFO:     Found new best model at epoch 0
2023-01-04 22:22:16,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:16,362 INFO:     Epoch: 1
2023-01-04 22:22:18,547 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5292027294635773, 'Total loss': 0.5292027294635773} | train loss {'Reaction outcome loss': 0.5897705354263861, 'Total loss': 0.5897705354263861}
2023-01-04 22:22:18,548 INFO:     Found new best model at epoch 1
2023-01-04 22:22:18,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:18,549 INFO:     Epoch: 2
2023-01-04 22:22:20,738 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5285602033138275, 'Total loss': 0.5285602033138275} | train loss {'Reaction outcome loss': 0.5166934312929526, 'Total loss': 0.5166934312929526}
2023-01-04 22:22:20,738 INFO:     Found new best model at epoch 2
2023-01-04 22:22:20,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:20,739 INFO:     Epoch: 3
2023-01-04 22:22:22,970 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5088327447573344, 'Total loss': 0.5088327447573344} | train loss {'Reaction outcome loss': 0.4755059896909883, 'Total loss': 0.4755059896909883}
2023-01-04 22:22:22,970 INFO:     Found new best model at epoch 3
2023-01-04 22:22:22,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:22,972 INFO:     Epoch: 4
2023-01-04 22:22:25,167 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46876413623491925, 'Total loss': 0.46876413623491925} | train loss {'Reaction outcome loss': 0.4501881029223164, 'Total loss': 0.4501881029223164}
2023-01-04 22:22:25,168 INFO:     Found new best model at epoch 4
2023-01-04 22:22:25,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:25,170 INFO:     Epoch: 5
2023-01-04 22:22:27,384 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43328313479820885, 'Total loss': 0.43328313479820885} | train loss {'Reaction outcome loss': 0.4292117942303309, 'Total loss': 0.4292117942303309}
2023-01-04 22:22:27,384 INFO:     Found new best model at epoch 5
2023-01-04 22:22:27,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:27,385 INFO:     Epoch: 6
2023-01-04 22:22:29,598 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43011240623891356, 'Total loss': 0.43011240623891356} | train loss {'Reaction outcome loss': 0.41407065016537137, 'Total loss': 0.41407065016537137}
2023-01-04 22:22:29,599 INFO:     Found new best model at epoch 6
2023-01-04 22:22:29,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:29,601 INFO:     Epoch: 7
2023-01-04 22:22:31,824 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42248753532767297, 'Total loss': 0.42248753532767297} | train loss {'Reaction outcome loss': 0.39845565761477303, 'Total loss': 0.39845565761477303}
2023-01-04 22:22:31,824 INFO:     Found new best model at epoch 7
2023-01-04 22:22:31,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:31,826 INFO:     Epoch: 8
2023-01-04 22:22:34,061 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4277340054512024, 'Total loss': 0.4277340054512024} | train loss {'Reaction outcome loss': 0.38265954914788036, 'Total loss': 0.38265954914788036}
2023-01-04 22:22:34,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:34,062 INFO:     Epoch: 9
2023-01-04 22:22:36,284 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42749939461549125, 'Total loss': 0.42749939461549125} | train loss {'Reaction outcome loss': 0.37568409262548075, 'Total loss': 0.37568409262548075}
2023-01-04 22:22:36,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:36,285 INFO:     Epoch: 10
2023-01-04 22:22:38,468 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44905505180358884, 'Total loss': 0.44905505180358884} | train loss {'Reaction outcome loss': 0.36432013076444836, 'Total loss': 0.36432013076444836}
2023-01-04 22:22:38,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:38,469 INFO:     Epoch: 11
2023-01-04 22:22:40,636 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43431850473086037, 'Total loss': 0.43431850473086037} | train loss {'Reaction outcome loss': 0.3569408780534329, 'Total loss': 0.3569408780534329}
2023-01-04 22:22:40,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:40,636 INFO:     Epoch: 12
2023-01-04 22:22:42,832 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4377565880616506, 'Total loss': 0.4377565880616506} | train loss {'Reaction outcome loss': 0.34759209046614564, 'Total loss': 0.34759209046614564}
2023-01-04 22:22:42,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:42,834 INFO:     Epoch: 13
2023-01-04 22:22:45,057 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42076476315657296, 'Total loss': 0.42076476315657296} | train loss {'Reaction outcome loss': 0.33303421625104557, 'Total loss': 0.33303421625104557}
2023-01-04 22:22:45,057 INFO:     Found new best model at epoch 13
2023-01-04 22:22:45,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:45,058 INFO:     Epoch: 14
2023-01-04 22:22:47,258 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4166568696498871, 'Total loss': 0.4166568696498871} | train loss {'Reaction outcome loss': 0.32633954590372055, 'Total loss': 0.32633954590372055}
2023-01-04 22:22:47,259 INFO:     Found new best model at epoch 14
2023-01-04 22:22:47,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:47,260 INFO:     Epoch: 15
2023-01-04 22:22:49,470 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4101168617606163, 'Total loss': 0.4101168617606163} | train loss {'Reaction outcome loss': 0.3234580241666069, 'Total loss': 0.3234580241666069}
2023-01-04 22:22:49,470 INFO:     Found new best model at epoch 15
2023-01-04 22:22:49,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:49,471 INFO:     Epoch: 16
2023-01-04 22:22:51,697 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4293758620818456, 'Total loss': 0.4293758620818456} | train loss {'Reaction outcome loss': 0.3132155197930292, 'Total loss': 0.3132155197930292}
2023-01-04 22:22:51,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:51,697 INFO:     Epoch: 17
2023-01-04 22:22:53,897 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4165005664030711, 'Total loss': 0.4165005664030711} | train loss {'Reaction outcome loss': 0.30896634546648094, 'Total loss': 0.30896634546648094}
2023-01-04 22:22:53,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:53,898 INFO:     Epoch: 18
2023-01-04 22:22:56,112 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4274365941683451, 'Total loss': 0.4274365941683451} | train loss {'Reaction outcome loss': 0.30313058927435277, 'Total loss': 0.30313058927435277}
2023-01-04 22:22:56,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:56,113 INFO:     Epoch: 19
2023-01-04 22:22:58,307 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4301694020628929, 'Total loss': 0.4301694020628929} | train loss {'Reaction outcome loss': 0.29847298748103895, 'Total loss': 0.29847298748103895}
2023-01-04 22:22:58,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:22:58,307 INFO:     Epoch: 20
2023-01-04 22:23:00,489 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41533640135700506, 'Total loss': 0.41533640135700506} | train loss {'Reaction outcome loss': 0.2934133781195787, 'Total loss': 0.2934133781195787}
2023-01-04 22:23:00,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:00,491 INFO:     Epoch: 21
2023-01-04 22:23:02,701 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43682594199975333, 'Total loss': 0.43682594199975333} | train loss {'Reaction outcome loss': 0.28994853206226306, 'Total loss': 0.28994853206226306}
2023-01-04 22:23:02,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:02,701 INFO:     Epoch: 22
2023-01-04 22:23:04,912 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.439375110467275, 'Total loss': 0.439375110467275} | train loss {'Reaction outcome loss': 0.2819399418948541, 'Total loss': 0.2819399418948541}
2023-01-04 22:23:04,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:04,913 INFO:     Epoch: 23
2023-01-04 22:23:07,109 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4118316548255583, 'Total loss': 0.4118316548255583} | train loss {'Reaction outcome loss': 0.2757648399058468, 'Total loss': 0.2757648399058468}
2023-01-04 22:23:07,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:07,110 INFO:     Epoch: 24
2023-01-04 22:23:09,329 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.422991802295049, 'Total loss': 0.422991802295049} | train loss {'Reaction outcome loss': 0.27071750383287996, 'Total loss': 0.27071750383287996}
2023-01-04 22:23:09,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:09,329 INFO:     Epoch: 25
2023-01-04 22:23:11,560 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4033120935472349, 'Total loss': 0.4033120935472349} | train loss {'Reaction outcome loss': 0.26850490112586217, 'Total loss': 0.26850490112586217}
2023-01-04 22:23:11,561 INFO:     Found new best model at epoch 25
2023-01-04 22:23:11,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:11,563 INFO:     Epoch: 26
2023-01-04 22:23:13,812 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4437314957380295, 'Total loss': 0.4437314957380295} | train loss {'Reaction outcome loss': 0.26705076309725145, 'Total loss': 0.26705076309725145}
2023-01-04 22:23:13,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:13,813 INFO:     Epoch: 27
2023-01-04 22:23:16,064 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39087963551282884, 'Total loss': 0.39087963551282884} | train loss {'Reaction outcome loss': 0.2642301930685105, 'Total loss': 0.2642301930685105}
2023-01-04 22:23:16,065 INFO:     Found new best model at epoch 27
2023-01-04 22:23:16,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:16,067 INFO:     Epoch: 28
2023-01-04 22:23:18,280 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39929677645365397, 'Total loss': 0.39929677645365397} | train loss {'Reaction outcome loss': 0.2596635968111648, 'Total loss': 0.2596635968111648}
2023-01-04 22:23:18,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:18,280 INFO:     Epoch: 29
2023-01-04 22:23:20,479 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4055027642597755, 'Total loss': 0.4055027642597755} | train loss {'Reaction outcome loss': 0.2538831849201029, 'Total loss': 0.2538831849201029}
2023-01-04 22:23:20,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:20,480 INFO:     Epoch: 30
2023-01-04 22:23:22,697 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43093664447466534, 'Total loss': 0.43093664447466534} | train loss {'Reaction outcome loss': 0.2502366057236256, 'Total loss': 0.2502366057236256}
2023-01-04 22:23:22,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:22,699 INFO:     Epoch: 31
2023-01-04 22:23:24,941 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42276585698127744, 'Total loss': 0.42276585698127744} | train loss {'Reaction outcome loss': 0.24267254106535463, 'Total loss': 0.24267254106535463}
2023-01-04 22:23:24,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:24,942 INFO:     Epoch: 32
2023-01-04 22:23:27,130 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39429240754495065, 'Total loss': 0.39429240754495065} | train loss {'Reaction outcome loss': 0.24352382429329011, 'Total loss': 0.24352382429329011}
2023-01-04 22:23:27,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:27,130 INFO:     Epoch: 33
2023-01-04 22:23:29,365 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40930445194244386, 'Total loss': 0.40930445194244386} | train loss {'Reaction outcome loss': 0.2394664110925145, 'Total loss': 0.2394664110925145}
2023-01-04 22:23:29,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:29,366 INFO:     Epoch: 34
2023-01-04 22:23:31,609 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42789470255374906, 'Total loss': 0.42789470255374906} | train loss {'Reaction outcome loss': 0.2344621549673186, 'Total loss': 0.2344621549673186}
2023-01-04 22:23:31,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:31,609 INFO:     Epoch: 35
2023-01-04 22:23:33,832 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45005309184392295, 'Total loss': 0.45005309184392295} | train loss {'Reaction outcome loss': 0.23233225214470357, 'Total loss': 0.23233225214470357}
2023-01-04 22:23:33,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:33,833 INFO:     Epoch: 36
2023-01-04 22:23:36,066 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38169991175333656, 'Total loss': 0.38169991175333656} | train loss {'Reaction outcome loss': 0.23121021135033168, 'Total loss': 0.23121021135033168}
2023-01-04 22:23:36,066 INFO:     Found new best model at epoch 36
2023-01-04 22:23:36,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:36,067 INFO:     Epoch: 37
2023-01-04 22:23:38,285 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4576817403237025, 'Total loss': 0.4576817403237025} | train loss {'Reaction outcome loss': 0.22767065330734992, 'Total loss': 0.22767065330734992}
2023-01-04 22:23:38,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:38,285 INFO:     Epoch: 38
2023-01-04 22:23:40,506 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4256987830003103, 'Total loss': 0.4256987830003103} | train loss {'Reaction outcome loss': 0.22464661699860627, 'Total loss': 0.22464661699860627}
2023-01-04 22:23:40,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:40,507 INFO:     Epoch: 39
2023-01-04 22:23:42,742 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4225820074478785, 'Total loss': 0.4225820074478785} | train loss {'Reaction outcome loss': 0.22533828939046588, 'Total loss': 0.22533828939046588}
2023-01-04 22:23:42,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:42,742 INFO:     Epoch: 40
2023-01-04 22:23:44,985 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4639102339744568, 'Total loss': 0.4639102339744568} | train loss {'Reaction outcome loss': 0.22239141698026293, 'Total loss': 0.22239141698026293}
2023-01-04 22:23:44,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:44,986 INFO:     Epoch: 41
2023-01-04 22:23:47,222 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.405343473640581, 'Total loss': 0.405343473640581} | train loss {'Reaction outcome loss': 0.21788740772547757, 'Total loss': 0.21788740772547757}
2023-01-04 22:23:47,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:47,224 INFO:     Epoch: 42
2023-01-04 22:23:49,461 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4279693933824698, 'Total loss': 0.4279693933824698} | train loss {'Reaction outcome loss': 0.21768283498270705, 'Total loss': 0.21768283498270705}
2023-01-04 22:23:49,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:49,461 INFO:     Epoch: 43
2023-01-04 22:23:51,689 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.424017326037089, 'Total loss': 0.424017326037089} | train loss {'Reaction outcome loss': 0.21353919578997962, 'Total loss': 0.21353919578997962}
2023-01-04 22:23:51,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:51,690 INFO:     Epoch: 44
2023-01-04 22:23:53,894 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4021784245967865, 'Total loss': 0.4021784245967865} | train loss {'Reaction outcome loss': 0.20953320702915923, 'Total loss': 0.20953320702915923}
2023-01-04 22:23:53,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:53,895 INFO:     Epoch: 45
2023-01-04 22:23:56,063 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41386239031950633, 'Total loss': 0.41386239031950633} | train loss {'Reaction outcome loss': 0.21052476592925531, 'Total loss': 0.21052476592925531}
2023-01-04 22:23:56,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:56,064 INFO:     Epoch: 46
2023-01-04 22:23:58,340 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3926137020190557, 'Total loss': 0.3926137020190557} | train loss {'Reaction outcome loss': 0.2090383519236397, 'Total loss': 0.2090383519236397}
2023-01-04 22:23:58,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:23:58,342 INFO:     Epoch: 47
2023-01-04 22:24:00,644 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3985401431719462, 'Total loss': 0.3985401431719462} | train loss {'Reaction outcome loss': 0.204365453146728, 'Total loss': 0.204365453146728}
2023-01-04 22:24:00,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:00,644 INFO:     Epoch: 48
2023-01-04 22:24:02,874 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4104157254720728, 'Total loss': 0.4104157254720728} | train loss {'Reaction outcome loss': 0.2039191489265991, 'Total loss': 0.2039191489265991}
2023-01-04 22:24:02,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:02,875 INFO:     Epoch: 49
2023-01-04 22:24:05,090 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4560692290465037, 'Total loss': 0.4560692290465037} | train loss {'Reaction outcome loss': 0.2040979789666199, 'Total loss': 0.2040979789666199}
2023-01-04 22:24:05,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:05,090 INFO:     Epoch: 50
2023-01-04 22:24:07,287 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4121374537547429, 'Total loss': 0.4121374537547429} | train loss {'Reaction outcome loss': 0.2032659847385549, 'Total loss': 0.2032659847385549}
2023-01-04 22:24:07,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:07,288 INFO:     Epoch: 51
2023-01-04 22:24:09,533 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3956259459257126, 'Total loss': 0.3956259459257126} | train loss {'Reaction outcome loss': 0.20425208144549734, 'Total loss': 0.20425208144549734}
2023-01-04 22:24:09,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:09,534 INFO:     Epoch: 52
2023-01-04 22:24:11,742 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4404231086373329, 'Total loss': 0.4404231086373329} | train loss {'Reaction outcome loss': 0.200349914635157, 'Total loss': 0.200349914635157}
2023-01-04 22:24:11,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:11,742 INFO:     Epoch: 53
2023-01-04 22:24:13,959 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44123479624589285, 'Total loss': 0.44123479624589285} | train loss {'Reaction outcome loss': 0.20101585511351863, 'Total loss': 0.20101585511351863}
2023-01-04 22:24:13,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:13,960 INFO:     Epoch: 54
2023-01-04 22:24:16,143 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39102573196093243, 'Total loss': 0.39102573196093243} | train loss {'Reaction outcome loss': 0.19629113461368639, 'Total loss': 0.19629113461368639}
2023-01-04 22:24:16,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:16,143 INFO:     Epoch: 55
2023-01-04 22:24:18,293 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41169702510039013, 'Total loss': 0.41169702510039013} | train loss {'Reaction outcome loss': 0.1964655557090616, 'Total loss': 0.1964655557090616}
2023-01-04 22:24:18,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:18,294 INFO:     Epoch: 56
2023-01-04 22:24:20,474 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4075200505554676, 'Total loss': 0.4075200505554676} | train loss {'Reaction outcome loss': 0.18967242164509818, 'Total loss': 0.18967242164509818}
2023-01-04 22:24:20,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:20,475 INFO:     Epoch: 57
2023-01-04 22:24:22,712 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4583310604095459, 'Total loss': 0.4583310604095459} | train loss {'Reaction outcome loss': 0.19188852794812064, 'Total loss': 0.19188852794812064}
2023-01-04 22:24:22,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:22,712 INFO:     Epoch: 58
2023-01-04 22:24:24,928 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4215394260982672, 'Total loss': 0.4215394260982672} | train loss {'Reaction outcome loss': 0.18996795839406688, 'Total loss': 0.18996795839406688}
2023-01-04 22:24:24,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:24,928 INFO:     Epoch: 59
2023-01-04 22:24:27,165 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4878666599591573, 'Total loss': 0.4878666599591573} | train loss {'Reaction outcome loss': 0.18588544357210618, 'Total loss': 0.18588544357210618}
2023-01-04 22:24:27,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:27,166 INFO:     Epoch: 60
2023-01-04 22:24:29,388 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40435500085974735, 'Total loss': 0.40435500085974735} | train loss {'Reaction outcome loss': 0.1892298974811591, 'Total loss': 0.1892298974811591}
2023-01-04 22:24:29,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:29,388 INFO:     Epoch: 61
2023-01-04 22:24:31,612 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47097114771604537, 'Total loss': 0.47097114771604537} | train loss {'Reaction outcome loss': 0.1882546206805649, 'Total loss': 0.1882546206805649}
2023-01-04 22:24:31,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:31,613 INFO:     Epoch: 62
2023-01-04 22:24:33,803 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44955251812934877, 'Total loss': 0.44955251812934877} | train loss {'Reaction outcome loss': 0.18498063725642722, 'Total loss': 0.18498063725642722}
2023-01-04 22:24:33,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:33,803 INFO:     Epoch: 63
2023-01-04 22:24:35,995 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4257626016934713, 'Total loss': 0.4257626016934713} | train loss {'Reaction outcome loss': 0.18207982705383668, 'Total loss': 0.18207982705383668}
2023-01-04 22:24:35,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:35,995 INFO:     Epoch: 64
2023-01-04 22:24:38,192 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42782926162083945, 'Total loss': 0.42782926162083945} | train loss {'Reaction outcome loss': 0.18870784617218145, 'Total loss': 0.18870784617218145}
2023-01-04 22:24:38,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:38,193 INFO:     Epoch: 65
2023-01-04 22:24:40,401 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44089991648991905, 'Total loss': 0.44089991648991905} | train loss {'Reaction outcome loss': 0.1831427171733574, 'Total loss': 0.1831427171733574}
2023-01-04 22:24:40,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:40,401 INFO:     Epoch: 66
2023-01-04 22:24:42,572 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4779187778631846, 'Total loss': 0.4779187778631846} | train loss {'Reaction outcome loss': 0.17956152856281213, 'Total loss': 0.17956152856281213}
2023-01-04 22:24:42,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:42,572 INFO:     Epoch: 67
2023-01-04 22:24:44,776 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43161480824152626, 'Total loss': 0.43161480824152626} | train loss {'Reaction outcome loss': 0.18107144546959672, 'Total loss': 0.18107144546959672}
2023-01-04 22:24:44,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:44,778 INFO:     Epoch: 68
2023-01-04 22:24:46,987 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.394463116923968, 'Total loss': 0.394463116923968} | train loss {'Reaction outcome loss': 0.17565708358967985, 'Total loss': 0.17565708358967985}
2023-01-04 22:24:46,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:46,987 INFO:     Epoch: 69
2023-01-04 22:24:48,850 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46106404264767964, 'Total loss': 0.46106404264767964} | train loss {'Reaction outcome loss': 0.1779853043033023, 'Total loss': 0.1779853043033023}
2023-01-04 22:24:48,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:48,851 INFO:     Epoch: 70
2023-01-04 22:24:50,674 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40836299608151116, 'Total loss': 0.40836299608151116} | train loss {'Reaction outcome loss': 0.17482381147019757, 'Total loss': 0.17482381147019757}
2023-01-04 22:24:50,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:50,676 INFO:     Epoch: 71
2023-01-04 22:24:52,746 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4454122324784597, 'Total loss': 0.4454122324784597} | train loss {'Reaction outcome loss': 0.17243958973047424, 'Total loss': 0.17243958973047424}
2023-01-04 22:24:52,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:52,747 INFO:     Epoch: 72
2023-01-04 22:24:54,937 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40071158309777577, 'Total loss': 0.40071158309777577} | train loss {'Reaction outcome loss': 0.17375379403523852, 'Total loss': 0.17375379403523852}
2023-01-04 22:24:54,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:54,937 INFO:     Epoch: 73
2023-01-04 22:24:57,151 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5137074808279674, 'Total loss': 0.5137074808279674} | train loss {'Reaction outcome loss': 0.170698498695319, 'Total loss': 0.170698498695319}
2023-01-04 22:24:57,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:57,153 INFO:     Epoch: 74
2023-01-04 22:24:59,192 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.441635396083196, 'Total loss': 0.441635396083196} | train loss {'Reaction outcome loss': 0.1772712977788655, 'Total loss': 0.1772712977788655}
2023-01-04 22:24:59,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:24:59,192 INFO:     Epoch: 75
2023-01-04 22:25:01,331 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49335374136765797, 'Total loss': 0.49335374136765797} | train loss {'Reaction outcome loss': 0.17273383391196273, 'Total loss': 0.17273383391196273}
2023-01-04 22:25:01,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:01,332 INFO:     Epoch: 76
2023-01-04 22:25:03,458 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4098304636310786, 'Total loss': 0.4098304636310786} | train loss {'Reaction outcome loss': 0.1741875923682018, 'Total loss': 0.1741875923682018}
2023-01-04 22:25:03,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:03,459 INFO:     Epoch: 77
2023-01-04 22:25:05,666 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44611648420492805, 'Total loss': 0.44611648420492805} | train loss {'Reaction outcome loss': 0.17123434362706222, 'Total loss': 0.17123434362706222}
2023-01-04 22:25:05,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:05,666 INFO:     Epoch: 78
2023-01-04 22:25:07,890 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4162736922502518, 'Total loss': 0.4162736922502518} | train loss {'Reaction outcome loss': 0.17135637671587048, 'Total loss': 0.17135637671587048}
2023-01-04 22:25:07,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:07,890 INFO:     Epoch: 79
2023-01-04 22:25:10,124 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4338023990392685, 'Total loss': 0.4338023990392685} | train loss {'Reaction outcome loss': 0.16711988994968555, 'Total loss': 0.16711988994968555}
2023-01-04 22:25:10,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:10,125 INFO:     Epoch: 80
2023-01-04 22:25:12,328 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40917359391848246, 'Total loss': 0.40917359391848246} | train loss {'Reaction outcome loss': 0.16511736662776597, 'Total loss': 0.16511736662776597}
2023-01-04 22:25:12,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:12,328 INFO:     Epoch: 81
2023-01-04 22:25:14,535 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42406876186529796, 'Total loss': 0.42406876186529796} | train loss {'Reaction outcome loss': 0.16524110496219427, 'Total loss': 0.16524110496219427}
2023-01-04 22:25:14,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:14,535 INFO:     Epoch: 82
2023-01-04 22:25:16,750 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4459660453100999, 'Total loss': 0.4459660453100999} | train loss {'Reaction outcome loss': 0.16331181720215346, 'Total loss': 0.16331181720215346}
2023-01-04 22:25:16,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:16,751 INFO:     Epoch: 83
2023-01-04 22:25:18,978 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44548600614070893, 'Total loss': 0.44548600614070893} | train loss {'Reaction outcome loss': 0.16738426561271463, 'Total loss': 0.16738426561271463}
2023-01-04 22:25:18,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:18,978 INFO:     Epoch: 84
2023-01-04 22:25:21,262 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43447058498859403, 'Total loss': 0.43447058498859403} | train loss {'Reaction outcome loss': 0.1678226095438691, 'Total loss': 0.1678226095438691}
2023-01-04 22:25:21,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:21,263 INFO:     Epoch: 85
2023-01-04 22:25:23,491 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4676895931440716, 'Total loss': 0.4676895931440716} | train loss {'Reaction outcome loss': 0.16472771330616295, 'Total loss': 0.16472771330616295}
2023-01-04 22:25:23,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:23,491 INFO:     Epoch: 86
2023-01-04 22:25:25,691 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47174280186494194, 'Total loss': 0.47174280186494194} | train loss {'Reaction outcome loss': 0.1669747427387706, 'Total loss': 0.1669747427387706}
2023-01-04 22:25:25,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:25,691 INFO:     Epoch: 87
2023-01-04 22:25:27,881 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.37328652714689575, 'Total loss': 0.37328652714689575} | train loss {'Reaction outcome loss': 0.16501297150580452, 'Total loss': 0.16501297150580452}
2023-01-04 22:25:27,882 INFO:     Found new best model at epoch 87
2023-01-04 22:25:27,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:27,883 INFO:     Epoch: 88
2023-01-04 22:25:30,063 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46594062944253284, 'Total loss': 0.46594062944253284} | train loss {'Reaction outcome loss': 0.1627272625867882, 'Total loss': 0.1627272625867882}
2023-01-04 22:25:30,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:30,063 INFO:     Epoch: 89
2023-01-04 22:25:32,247 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4607578088839849, 'Total loss': 0.4607578088839849} | train loss {'Reaction outcome loss': 0.16008898163234947, 'Total loss': 0.16008898163234947}
2023-01-04 22:25:32,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:32,248 INFO:     Epoch: 90
2023-01-04 22:25:34,427 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42719448953866956, 'Total loss': 0.42719448953866956} | train loss {'Reaction outcome loss': 0.16112895228992805, 'Total loss': 0.16112895228992805}
2023-01-04 22:25:34,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:34,427 INFO:     Epoch: 91
2023-01-04 22:25:36,633 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4560081700483958, 'Total loss': 0.4560081700483958} | train loss {'Reaction outcome loss': 0.16040966852062907, 'Total loss': 0.16040966852062907}
2023-01-04 22:25:36,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:36,633 INFO:     Epoch: 92
2023-01-04 22:25:38,825 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46526940365632374, 'Total loss': 0.46526940365632374} | train loss {'Reaction outcome loss': 0.16125189069129278, 'Total loss': 0.16125189069129278}
2023-01-04 22:25:38,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:38,826 INFO:     Epoch: 93
2023-01-04 22:25:41,033 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4351074387629827, 'Total loss': 0.4351074387629827} | train loss {'Reaction outcome loss': 0.16131473974087637, 'Total loss': 0.16131473974087637}
2023-01-04 22:25:41,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:41,033 INFO:     Epoch: 94
2023-01-04 22:25:43,268 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45298219720522565, 'Total loss': 0.45298219720522565} | train loss {'Reaction outcome loss': 0.15737041650508354, 'Total loss': 0.15737041650508354}
2023-01-04 22:25:43,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:43,269 INFO:     Epoch: 95
2023-01-04 22:25:45,495 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4300568143526713, 'Total loss': 0.4300568143526713} | train loss {'Reaction outcome loss': 0.1548018602162902, 'Total loss': 0.1548018602162902}
2023-01-04 22:25:45,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:45,496 INFO:     Epoch: 96
2023-01-04 22:25:47,720 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48932029902935026, 'Total loss': 0.48932029902935026} | train loss {'Reaction outcome loss': 0.16137098528468824, 'Total loss': 0.16137098528468824}
2023-01-04 22:25:47,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:47,720 INFO:     Epoch: 97
2023-01-04 22:25:49,868 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.438553054134051, 'Total loss': 0.438553054134051} | train loss {'Reaction outcome loss': 0.16061070913576084, 'Total loss': 0.16061070913576084}
2023-01-04 22:25:49,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:49,868 INFO:     Epoch: 98
2023-01-04 22:25:52,081 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43801988164583844, 'Total loss': 0.43801988164583844} | train loss {'Reaction outcome loss': 0.1629395787458097, 'Total loss': 0.1629395787458097}
2023-01-04 22:25:52,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:52,082 INFO:     Epoch: 99
2023-01-04 22:25:54,287 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5193091293176015, 'Total loss': 0.5193091293176015} | train loss {'Reaction outcome loss': 0.15567093350618694, 'Total loss': 0.15567093350618694}
2023-01-04 22:25:54,287 INFO:     Best model found after epoch 88 of 100.
2023-01-04 22:25:54,287 INFO:   Done with stage: TRAINING
2023-01-04 22:25:54,287 INFO:   Starting stage: EVALUATION
2023-01-04 22:25:54,441 INFO:   Done with stage: EVALUATION
2023-01-04 22:25:54,442 INFO:   Leaving out SEQ value Fold_1
2023-01-04 22:25:54,455 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 22:25:54,455 INFO:   Starting stage: FEATURE SCALING
2023-01-04 22:25:55,109 INFO:   Done with stage: FEATURE SCALING
2023-01-04 22:25:55,109 INFO:   Starting stage: SCALING TARGETS
2023-01-04 22:25:55,181 INFO:   Done with stage: SCALING TARGETS
2023-01-04 22:25:55,181 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:25:55,181 INFO:     No hyperparam tuning for this model
2023-01-04 22:25:55,181 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:25:55,181 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 22:25:55,182 INFO:     None feature selector for col prot
2023-01-04 22:25:55,182 INFO:     None feature selector for col prot
2023-01-04 22:25:55,182 INFO:     None feature selector for col prot
2023-01-04 22:25:55,183 INFO:     None feature selector for col chem
2023-01-04 22:25:55,183 INFO:     None feature selector for col chem
2023-01-04 22:25:55,183 INFO:     None feature selector for col chem
2023-01-04 22:25:55,183 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 22:25:55,183 INFO:   Starting stage: BUILD MODEL
2023-01-04 22:25:55,184 INFO:     Number of params in model 72931
2023-01-04 22:25:55,188 INFO:   Done with stage: BUILD MODEL
2023-01-04 22:25:55,188 INFO:   Starting stage: TRAINING
2023-01-04 22:25:55,248 INFO:     Val loss before train {'Reaction outcome loss': 1.0953881065050761, 'Total loss': 1.0953881065050761}
2023-01-04 22:25:55,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:55,249 INFO:     Epoch: 0
2023-01-04 22:25:57,513 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7247945189476013, 'Total loss': 0.7247945189476013} | train loss {'Reaction outcome loss': 0.9114881358041927, 'Total loss': 0.9114881358041927}
2023-01-04 22:25:57,514 INFO:     Found new best model at epoch 0
2023-01-04 22:25:57,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:57,516 INFO:     Epoch: 1
2023-01-04 22:25:59,782 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5869546631971995, 'Total loss': 0.5869546631971995} | train loss {'Reaction outcome loss': 0.6379491719214813, 'Total loss': 0.6379491719214813}
2023-01-04 22:25:59,782 INFO:     Found new best model at epoch 1
2023-01-04 22:25:59,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:25:59,784 INFO:     Epoch: 2
2023-01-04 22:26:02,035 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5208633581797282, 'Total loss': 0.5208633581797282} | train loss {'Reaction outcome loss': 0.5425601425357973, 'Total loss': 0.5425601425357973}
2023-01-04 22:26:02,035 INFO:     Found new best model at epoch 2
2023-01-04 22:26:02,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:02,036 INFO:     Epoch: 3
2023-01-04 22:26:04,266 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5129186968008678, 'Total loss': 0.5129186968008678} | train loss {'Reaction outcome loss': 0.5060989678014016, 'Total loss': 0.5060989678014016}
2023-01-04 22:26:04,267 INFO:     Found new best model at epoch 3
2023-01-04 22:26:04,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:04,269 INFO:     Epoch: 4
2023-01-04 22:26:06,556 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4822400132815043, 'Total loss': 0.4822400132815043} | train loss {'Reaction outcome loss': 0.4726949650283896, 'Total loss': 0.4726949650283896}
2023-01-04 22:26:06,556 INFO:     Found new best model at epoch 4
2023-01-04 22:26:06,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:06,557 INFO:     Epoch: 5
2023-01-04 22:26:08,828 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4746444046497345, 'Total loss': 0.4746444046497345} | train loss {'Reaction outcome loss': 0.4496964205501844, 'Total loss': 0.4496964205501844}
2023-01-04 22:26:08,830 INFO:     Found new best model at epoch 5
2023-01-04 22:26:08,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:08,831 INFO:     Epoch: 6
2023-01-04 22:26:11,109 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44761127332846323, 'Total loss': 0.44761127332846323} | train loss {'Reaction outcome loss': 0.43036551981745963, 'Total loss': 0.43036551981745963}
2023-01-04 22:26:11,110 INFO:     Found new best model at epoch 6
2023-01-04 22:26:11,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:11,112 INFO:     Epoch: 7
2023-01-04 22:26:13,322 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4345694124698639, 'Total loss': 0.4345694124698639} | train loss {'Reaction outcome loss': 0.4133735024568497, 'Total loss': 0.4133735024568497}
2023-01-04 22:26:13,322 INFO:     Found new best model at epoch 7
2023-01-04 22:26:13,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:13,323 INFO:     Epoch: 8
2023-01-04 22:26:15,543 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45666841268539426, 'Total loss': 0.45666841268539426} | train loss {'Reaction outcome loss': 0.4003606495174134, 'Total loss': 0.4003606495174134}
2023-01-04 22:26:15,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:15,544 INFO:     Epoch: 9
2023-01-04 22:26:17,814 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4423273126284281, 'Total loss': 0.4423273126284281} | train loss {'Reaction outcome loss': 0.3905681392869261, 'Total loss': 0.3905681392869261}
2023-01-04 22:26:17,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:17,814 INFO:     Epoch: 10
2023-01-04 22:26:20,075 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42435991366704306, 'Total loss': 0.42435991366704306} | train loss {'Reaction outcome loss': 0.3865735452028288, 'Total loss': 0.3865735452028288}
2023-01-04 22:26:20,076 INFO:     Found new best model at epoch 10
2023-01-04 22:26:20,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:20,077 INFO:     Epoch: 11
2023-01-04 22:26:22,351 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42907396455605823, 'Total loss': 0.42907396455605823} | train loss {'Reaction outcome loss': 0.3842404227217902, 'Total loss': 0.3842404227217902}
2023-01-04 22:26:22,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:22,351 INFO:     Epoch: 12
2023-01-04 22:26:24,563 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4197573741277059, 'Total loss': 0.4197573741277059} | train loss {'Reaction outcome loss': 0.3655318016575673, 'Total loss': 0.3655318016575673}
2023-01-04 22:26:24,563 INFO:     Found new best model at epoch 12
2023-01-04 22:26:24,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:24,565 INFO:     Epoch: 13
2023-01-04 22:26:26,834 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41650484800338744, 'Total loss': 0.41650484800338744} | train loss {'Reaction outcome loss': 0.35578519832072913, 'Total loss': 0.35578519832072913}
2023-01-04 22:26:26,835 INFO:     Found new best model at epoch 13
2023-01-04 22:26:26,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:26,836 INFO:     Epoch: 14
2023-01-04 22:26:29,170 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42952948609987895, 'Total loss': 0.42952948609987895} | train loss {'Reaction outcome loss': 0.3458020364008574, 'Total loss': 0.3458020364008574}
2023-01-04 22:26:29,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:29,171 INFO:     Epoch: 15
2023-01-04 22:26:31,510 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.415854533513387, 'Total loss': 0.415854533513387} | train loss {'Reaction outcome loss': 0.34066193602115347, 'Total loss': 0.34066193602115347}
2023-01-04 22:26:31,510 INFO:     Found new best model at epoch 15
2023-01-04 22:26:31,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:31,512 INFO:     Epoch: 16
2023-01-04 22:26:33,786 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4410622944434484, 'Total loss': 0.4410622944434484} | train loss {'Reaction outcome loss': 0.33463160679473175, 'Total loss': 0.33463160679473175}
2023-01-04 22:26:33,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:33,786 INFO:     Epoch: 17
2023-01-04 22:26:36,021 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4158331195513407, 'Total loss': 0.4158331195513407} | train loss {'Reaction outcome loss': 0.3237317386690689, 'Total loss': 0.3237317386690689}
2023-01-04 22:26:36,021 INFO:     Found new best model at epoch 17
2023-01-04 22:26:36,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:36,023 INFO:     Epoch: 18
2023-01-04 22:26:38,267 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42191186447938284, 'Total loss': 0.42191186447938284} | train loss {'Reaction outcome loss': 0.31665706116431125, 'Total loss': 0.31665706116431125}
2023-01-04 22:26:38,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:38,269 INFO:     Epoch: 19
2023-01-04 22:26:40,570 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4110145797332128, 'Total loss': 0.4110145797332128} | train loss {'Reaction outcome loss': 0.31652176755385986, 'Total loss': 0.31652176755385986}
2023-01-04 22:26:40,570 INFO:     Found new best model at epoch 19
2023-01-04 22:26:40,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:40,571 INFO:     Epoch: 20
2023-01-04 22:26:42,853 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4365048189957937, 'Total loss': 0.4365048189957937} | train loss {'Reaction outcome loss': 0.31261716995799943, 'Total loss': 0.31261716995799943}
2023-01-04 22:26:42,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:42,853 INFO:     Epoch: 21
2023-01-04 22:26:45,150 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4436463793118795, 'Total loss': 0.4436463793118795} | train loss {'Reaction outcome loss': 0.3048261343434021, 'Total loss': 0.3048261343434021}
2023-01-04 22:26:45,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:45,152 INFO:     Epoch: 22
2023-01-04 22:26:47,441 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4037472556034724, 'Total loss': 0.4037472556034724} | train loss {'Reaction outcome loss': 0.3187546075416216, 'Total loss': 0.3187546075416216}
2023-01-04 22:26:47,441 INFO:     Found new best model at epoch 22
2023-01-04 22:26:47,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:47,443 INFO:     Epoch: 23
2023-01-04 22:26:49,703 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42939986983935036, 'Total loss': 0.42939986983935036} | train loss {'Reaction outcome loss': 0.29830433454438776, 'Total loss': 0.29830433454438776}
2023-01-04 22:26:49,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:49,704 INFO:     Epoch: 24
2023-01-04 22:26:51,996 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41184006283680596, 'Total loss': 0.41184006283680596} | train loss {'Reaction outcome loss': 0.28630945248406153, 'Total loss': 0.28630945248406153}
2023-01-04 22:26:51,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:51,997 INFO:     Epoch: 25
2023-01-04 22:26:54,292 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42192630767822265, 'Total loss': 0.42192630767822265} | train loss {'Reaction outcome loss': 0.2847200648798405, 'Total loss': 0.2847200648798405}
2023-01-04 22:26:54,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:54,293 INFO:     Epoch: 26
2023-01-04 22:26:56,584 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41027860740820565, 'Total loss': 0.41027860740820565} | train loss {'Reaction outcome loss': 0.2784084240911002, 'Total loss': 0.2784084240911002}
2023-01-04 22:26:56,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:56,585 INFO:     Epoch: 27
2023-01-04 22:26:58,887 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41368993520736697, 'Total loss': 0.41368993520736697} | train loss {'Reaction outcome loss': 0.2768755598943613, 'Total loss': 0.2768755598943613}
2023-01-04 22:26:58,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:26:58,887 INFO:     Epoch: 28
2023-01-04 22:27:01,137 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42441847622394563, 'Total loss': 0.42441847622394563} | train loss {'Reaction outcome loss': 0.268663029955781, 'Total loss': 0.268663029955781}
2023-01-04 22:27:01,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:01,137 INFO:     Epoch: 29
2023-01-04 22:27:03,413 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43208271463712056, 'Total loss': 0.43208271463712056} | train loss {'Reaction outcome loss': 0.26724503316277615, 'Total loss': 0.26724503316277615}
2023-01-04 22:27:03,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:03,415 INFO:     Epoch: 30
2023-01-04 22:27:05,704 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40646670858065287, 'Total loss': 0.40646670858065287} | train loss {'Reaction outcome loss': 0.2632666649091782, 'Total loss': 0.2632666649091782}
2023-01-04 22:27:05,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:05,704 INFO:     Epoch: 31
2023-01-04 22:27:07,995 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43062292238076527, 'Total loss': 0.43062292238076527} | train loss {'Reaction outcome loss': 0.26145762936423544, 'Total loss': 0.26145762936423544}
2023-01-04 22:27:07,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:07,995 INFO:     Epoch: 32
2023-01-04 22:27:10,277 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4357850035031637, 'Total loss': 0.4357850035031637} | train loss {'Reaction outcome loss': 0.2548450257290033, 'Total loss': 0.2548450257290033}
2023-01-04 22:27:10,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:10,279 INFO:     Epoch: 33
2023-01-04 22:27:12,522 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45418871541817984, 'Total loss': 0.45418871541817984} | train loss {'Reaction outcome loss': 0.2552430939616423, 'Total loss': 0.2552430939616423}
2023-01-04 22:27:12,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:12,522 INFO:     Epoch: 34
2023-01-04 22:27:14,817 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41667901277542113, 'Total loss': 0.41667901277542113} | train loss {'Reaction outcome loss': 0.2485967648225715, 'Total loss': 0.2485967648225715}
2023-01-04 22:27:14,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:14,819 INFO:     Epoch: 35
2023-01-04 22:27:17,096 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41821799079577127, 'Total loss': 0.41821799079577127} | train loss {'Reaction outcome loss': 0.24697025060194774, 'Total loss': 0.24697025060194774}
2023-01-04 22:27:17,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:17,096 INFO:     Epoch: 36
2023-01-04 22:27:19,373 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.434157661596934, 'Total loss': 0.434157661596934} | train loss {'Reaction outcome loss': 0.25055103462891304, 'Total loss': 0.25055103462891304}
2023-01-04 22:27:19,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:19,373 INFO:     Epoch: 37
2023-01-04 22:27:21,656 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42272427255908646, 'Total loss': 0.42272427255908646} | train loss {'Reaction outcome loss': 0.258664859849386, 'Total loss': 0.258664859849386}
2023-01-04 22:27:21,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:21,657 INFO:     Epoch: 38
2023-01-04 22:27:23,904 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44462183912595116, 'Total loss': 0.44462183912595116} | train loss {'Reaction outcome loss': 0.2395447442144412, 'Total loss': 0.2395447442144412}
2023-01-04 22:27:23,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:23,904 INFO:     Epoch: 39
2023-01-04 22:27:26,162 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45300882359345757, 'Total loss': 0.45300882359345757} | train loss {'Reaction outcome loss': 0.23597461407315795, 'Total loss': 0.23597461407315795}
2023-01-04 22:27:26,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:26,163 INFO:     Epoch: 40
2023-01-04 22:27:28,412 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43195897738138833, 'Total loss': 0.43195897738138833} | train loss {'Reaction outcome loss': 0.23151167763791053, 'Total loss': 0.23151167763791053}
2023-01-04 22:27:28,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:28,412 INFO:     Epoch: 41
2023-01-04 22:27:30,690 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4302736481030782, 'Total loss': 0.4302736481030782} | train loss {'Reaction outcome loss': 0.2333372263692845, 'Total loss': 0.2333372263692845}
2023-01-04 22:27:30,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:30,691 INFO:     Epoch: 42
2023-01-04 22:27:32,969 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45910948713620503, 'Total loss': 0.45910948713620503} | train loss {'Reaction outcome loss': 0.22895502671008874, 'Total loss': 0.22895502671008874}
2023-01-04 22:27:32,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:32,970 INFO:     Epoch: 43
2023-01-04 22:27:35,224 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46046076714992523, 'Total loss': 0.46046076714992523} | train loss {'Reaction outcome loss': 0.2329929385408489, 'Total loss': 0.2329929385408489}
2023-01-04 22:27:35,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:35,224 INFO:     Epoch: 44
2023-01-04 22:27:37,494 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44542347888151806, 'Total loss': 0.44542347888151806} | train loss {'Reaction outcome loss': 0.22879850455016518, 'Total loss': 0.22879850455016518}
2023-01-04 22:27:37,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:37,495 INFO:     Epoch: 45
2023-01-04 22:27:39,740 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4420698881149292, 'Total loss': 0.4420698881149292} | train loss {'Reaction outcome loss': 0.22794280225059702, 'Total loss': 0.22794280225059702}
2023-01-04 22:27:39,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:39,740 INFO:     Epoch: 46
2023-01-04 22:27:42,013 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43770513534545896, 'Total loss': 0.43770513534545896} | train loss {'Reaction outcome loss': 0.22401550857255748, 'Total loss': 0.22401550857255748}
2023-01-04 22:27:42,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:42,013 INFO:     Epoch: 47
2023-01-04 22:27:44,275 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4503572295109431, 'Total loss': 0.4503572295109431} | train loss {'Reaction outcome loss': 0.21506276377139316, 'Total loss': 0.21506276377139316}
2023-01-04 22:27:44,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:44,276 INFO:     Epoch: 48
2023-01-04 22:27:46,505 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44797843595345815, 'Total loss': 0.44797843595345815} | train loss {'Reaction outcome loss': 0.21858323099972357, 'Total loss': 0.21858323099972357}
2023-01-04 22:27:46,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:46,506 INFO:     Epoch: 49
2023-01-04 22:27:48,795 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45984311898549396, 'Total loss': 0.45984311898549396} | train loss {'Reaction outcome loss': 0.2193988123908639, 'Total loss': 0.2193988123908639}
2023-01-04 22:27:48,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:48,796 INFO:     Epoch: 50
2023-01-04 22:27:51,084 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4391443540652593, 'Total loss': 0.4391443540652593} | train loss {'Reaction outcome loss': 0.21515120683318895, 'Total loss': 0.21515120683318895}
2023-01-04 22:27:51,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:51,084 INFO:     Epoch: 51
2023-01-04 22:27:53,314 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4584971606731415, 'Total loss': 0.4584971606731415} | train loss {'Reaction outcome loss': 0.2161467514992894, 'Total loss': 0.2161467514992894}
2023-01-04 22:27:53,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:53,314 INFO:     Epoch: 52
2023-01-04 22:27:55,587 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.471077032883962, 'Total loss': 0.471077032883962} | train loss {'Reaction outcome loss': 0.20879960212246457, 'Total loss': 0.20879960212246457}
2023-01-04 22:27:55,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:55,588 INFO:     Epoch: 53
2023-01-04 22:27:57,845 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4700244863828023, 'Total loss': 0.4700244863828023} | train loss {'Reaction outcome loss': 0.21079704540687194, 'Total loss': 0.21079704540687194}
2023-01-04 22:27:57,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:27:57,845 INFO:     Epoch: 54
2023-01-04 22:28:00,139 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45493836601575216, 'Total loss': 0.45493836601575216} | train loss {'Reaction outcome loss': 0.21348968642237393, 'Total loss': 0.21348968642237393}
2023-01-04 22:28:00,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:00,140 INFO:     Epoch: 55
2023-01-04 22:28:02,411 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4260554661353429, 'Total loss': 0.4260554661353429} | train loss {'Reaction outcome loss': 0.2021303445267815, 'Total loss': 0.2021303445267815}
2023-01-04 22:28:02,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:02,411 INFO:     Epoch: 56
2023-01-04 22:28:04,699 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43239210844039916, 'Total loss': 0.43239210844039916} | train loss {'Reaction outcome loss': 0.20800766225822398, 'Total loss': 0.20800766225822398}
2023-01-04 22:28:04,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:04,699 INFO:     Epoch: 57
2023-01-04 22:28:06,976 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4519614761074384, 'Total loss': 0.4519614761074384} | train loss {'Reaction outcome loss': 0.20657218749988385, 'Total loss': 0.20657218749988385}
2023-01-04 22:28:06,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:06,977 INFO:     Epoch: 58
2023-01-04 22:28:09,232 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4677860389153163, 'Total loss': 0.4677860389153163} | train loss {'Reaction outcome loss': 0.20655631078835027, 'Total loss': 0.20655631078835027}
2023-01-04 22:28:09,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:09,232 INFO:     Epoch: 59
2023-01-04 22:28:11,510 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4506316705296437, 'Total loss': 0.4506316705296437} | train loss {'Reaction outcome loss': 0.2160813742219403, 'Total loss': 0.2160813742219403}
2023-01-04 22:28:11,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:11,512 INFO:     Epoch: 60
2023-01-04 22:28:13,815 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4313580532868703, 'Total loss': 0.4313580532868703} | train loss {'Reaction outcome loss': 0.2233628168621141, 'Total loss': 0.2233628168621141}
2023-01-04 22:28:13,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:13,815 INFO:     Epoch: 61
2023-01-04 22:28:16,113 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4741176009178162, 'Total loss': 0.4741176009178162} | train loss {'Reaction outcome loss': 0.20179879618808627, 'Total loss': 0.20179879618808627}
2023-01-04 22:28:16,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:16,114 INFO:     Epoch: 62
2023-01-04 22:28:18,389 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42503834615151087, 'Total loss': 0.42503834615151087} | train loss {'Reaction outcome loss': 0.2074679551963303, 'Total loss': 0.2074679551963303}
2023-01-04 22:28:18,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:18,390 INFO:     Epoch: 63
2023-01-04 22:28:20,649 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4863651772340139, 'Total loss': 0.4863651772340139} | train loss {'Reaction outcome loss': 0.20322533944567692, 'Total loss': 0.20322533944567692}
2023-01-04 22:28:20,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:20,649 INFO:     Epoch: 64
2023-01-04 22:28:22,918 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4965496559937795, 'Total loss': 0.4965496559937795} | train loss {'Reaction outcome loss': 0.19722752400464716, 'Total loss': 0.19722752400464716}
2023-01-04 22:28:22,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:22,918 INFO:     Epoch: 65
2023-01-04 22:28:25,187 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45360598613818487, 'Total loss': 0.45360598613818487} | train loss {'Reaction outcome loss': 0.1927387325405911, 'Total loss': 0.1927387325405911}
2023-01-04 22:28:25,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:25,188 INFO:     Epoch: 66
2023-01-04 22:28:27,434 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4776758263508479, 'Total loss': 0.4776758263508479} | train loss {'Reaction outcome loss': 0.1873912695808795, 'Total loss': 0.1873912695808795}
2023-01-04 22:28:27,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:27,435 INFO:     Epoch: 67
2023-01-04 22:28:29,668 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45209172864754993, 'Total loss': 0.45209172864754993} | train loss {'Reaction outcome loss': 0.1940079725826618, 'Total loss': 0.1940079725826618}
2023-01-04 22:28:29,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:29,668 INFO:     Epoch: 68
2023-01-04 22:28:31,946 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48847657640775044, 'Total loss': 0.48847657640775044} | train loss {'Reaction outcome loss': 0.1929631609996052, 'Total loss': 0.1929631609996052}
2023-01-04 22:28:31,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:31,947 INFO:     Epoch: 69
2023-01-04 22:28:34,179 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4573738137880961, 'Total loss': 0.4573738137880961} | train loss {'Reaction outcome loss': 0.19101464154854234, 'Total loss': 0.19101464154854234}
2023-01-04 22:28:34,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:34,180 INFO:     Epoch: 70
2023-01-04 22:28:36,473 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4747539152701696, 'Total loss': 0.4747539152701696} | train loss {'Reaction outcome loss': 0.18958164374782718, 'Total loss': 0.18958164374782718}
2023-01-04 22:28:36,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:36,475 INFO:     Epoch: 71
2023-01-04 22:28:38,695 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4333506683508555, 'Total loss': 0.4333506683508555} | train loss {'Reaction outcome loss': 0.1862034553128794, 'Total loss': 0.1862034553128794}
2023-01-04 22:28:38,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:38,696 INFO:     Epoch: 72
2023-01-04 22:28:40,950 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44200866868098576, 'Total loss': 0.44200866868098576} | train loss {'Reaction outcome loss': 0.1926331856903625, 'Total loss': 0.1926331856903625}
2023-01-04 22:28:40,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:40,951 INFO:     Epoch: 73
2023-01-04 22:28:43,121 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4632774978876114, 'Total loss': 0.4632774978876114} | train loss {'Reaction outcome loss': 0.18789575134523792, 'Total loss': 0.18789575134523792}
2023-01-04 22:28:43,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:43,123 INFO:     Epoch: 74
2023-01-04 22:28:45,361 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49042932788530985, 'Total loss': 0.49042932788530985} | train loss {'Reaction outcome loss': 0.2127609839460448, 'Total loss': 0.2127609839460448}
2023-01-04 22:28:45,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:45,361 INFO:     Epoch: 75
2023-01-04 22:28:47,624 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4395481785138448, 'Total loss': 0.4395481785138448} | train loss {'Reaction outcome loss': 0.1929059352715621, 'Total loss': 0.1929059352715621}
2023-01-04 22:28:47,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:47,626 INFO:     Epoch: 76
2023-01-04 22:28:49,905 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4484113891919454, 'Total loss': 0.4484113891919454} | train loss {'Reaction outcome loss': 0.18812159744961915, 'Total loss': 0.18812159744961915}
2023-01-04 22:28:49,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:49,905 INFO:     Epoch: 77
2023-01-04 22:28:52,173 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46857752203941344, 'Total loss': 0.46857752203941344} | train loss {'Reaction outcome loss': 0.1884935425064675, 'Total loss': 0.1884935425064675}
2023-01-04 22:28:52,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:52,174 INFO:     Epoch: 78
2023-01-04 22:28:54,442 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4379707324008147, 'Total loss': 0.4379707324008147} | train loss {'Reaction outcome loss': 0.19333065694039417, 'Total loss': 0.19333065694039417}
2023-01-04 22:28:54,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:54,443 INFO:     Epoch: 79
2023-01-04 22:28:56,694 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4915629188219706, 'Total loss': 0.4915629188219706} | train loss {'Reaction outcome loss': 0.1850664016649756, 'Total loss': 0.1850664016649756}
2023-01-04 22:28:56,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:56,694 INFO:     Epoch: 80
2023-01-04 22:28:58,947 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.457393608490626, 'Total loss': 0.457393608490626} | train loss {'Reaction outcome loss': 0.17969106910058527, 'Total loss': 0.17969106910058527}
2023-01-04 22:28:58,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:28:58,949 INFO:     Epoch: 81
2023-01-04 22:29:01,209 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48086661100387573, 'Total loss': 0.48086661100387573} | train loss {'Reaction outcome loss': 0.17828871090402929, 'Total loss': 0.17828871090402929}
2023-01-04 22:29:01,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:01,209 INFO:     Epoch: 82
2023-01-04 22:29:03,487 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43969822824001314, 'Total loss': 0.43969822824001314} | train loss {'Reaction outcome loss': 0.18163144712562443, 'Total loss': 0.18163144712562443}
2023-01-04 22:29:03,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:03,487 INFO:     Epoch: 83
2023-01-04 22:29:05,741 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4573248356580734, 'Total loss': 0.4573248356580734} | train loss {'Reaction outcome loss': 0.1817202606024153, 'Total loss': 0.1817202606024153}
2023-01-04 22:29:05,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:05,742 INFO:     Epoch: 84
2023-01-04 22:29:08,013 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4564844806989034, 'Total loss': 0.4564844806989034} | train loss {'Reaction outcome loss': 0.17344675923485067, 'Total loss': 0.17344675923485067}
2023-01-04 22:29:08,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:08,014 INFO:     Epoch: 85
2023-01-04 22:29:10,072 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4486060209572315, 'Total loss': 0.4486060209572315} | train loss {'Reaction outcome loss': 0.17968904749917178, 'Total loss': 0.17968904749917178}
2023-01-04 22:29:10,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:10,073 INFO:     Epoch: 86
2023-01-04 22:29:12,344 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4511973043282827, 'Total loss': 0.4511973043282827} | train loss {'Reaction outcome loss': 0.18038669710243255, 'Total loss': 0.18038669710243255}
2023-01-04 22:29:12,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:12,344 INFO:     Epoch: 87
2023-01-04 22:29:14,610 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4674965480963389, 'Total loss': 0.4674965480963389} | train loss {'Reaction outcome loss': 0.17527956644619774, 'Total loss': 0.17527956644619774}
2023-01-04 22:29:14,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:14,611 INFO:     Epoch: 88
2023-01-04 22:29:16,897 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46602030197779337, 'Total loss': 0.46602030197779337} | train loss {'Reaction outcome loss': 0.1866669695439708, 'Total loss': 0.1866669695439708}
2023-01-04 22:29:16,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:16,897 INFO:     Epoch: 89
2023-01-04 22:29:19,159 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4740441769361496, 'Total loss': 0.4740441769361496} | train loss {'Reaction outcome loss': 0.18152573134621902, 'Total loss': 0.18152573134621902}
2023-01-04 22:29:19,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:19,160 INFO:     Epoch: 90
2023-01-04 22:29:21,429 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44234183927377063, 'Total loss': 0.44234183927377063} | train loss {'Reaction outcome loss': 0.17396806071648852, 'Total loss': 0.17396806071648852}
2023-01-04 22:29:21,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:21,430 INFO:     Epoch: 91
2023-01-04 22:29:23,699 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46577227910359703, 'Total loss': 0.46577227910359703} | train loss {'Reaction outcome loss': 0.1715575077552416, 'Total loss': 0.1715575077552416}
2023-01-04 22:29:23,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:23,700 INFO:     Epoch: 92
2023-01-04 22:29:25,959 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4661175588766734, 'Total loss': 0.4661175588766734} | train loss {'Reaction outcome loss': 0.17208845542434878, 'Total loss': 0.17208845542434878}
2023-01-04 22:29:25,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:25,960 INFO:     Epoch: 93
2023-01-04 22:29:28,243 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4818862646818161, 'Total loss': 0.4818862646818161} | train loss {'Reaction outcome loss': 0.17571705888781583, 'Total loss': 0.17571705888781583}
2023-01-04 22:29:28,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:28,243 INFO:     Epoch: 94
2023-01-04 22:29:30,488 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48384886384010317, 'Total loss': 0.48384886384010317} | train loss {'Reaction outcome loss': 0.17154337103947645, 'Total loss': 0.17154337103947645}
2023-01-04 22:29:30,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:30,489 INFO:     Epoch: 95
2023-01-04 22:29:32,735 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4957122544447581, 'Total loss': 0.4957122544447581} | train loss {'Reaction outcome loss': 0.16956562096543232, 'Total loss': 0.16956562096543232}
2023-01-04 22:29:32,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:32,737 INFO:     Epoch: 96
2023-01-04 22:29:34,999 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.49424610336621605, 'Total loss': 0.49424610336621605} | train loss {'Reaction outcome loss': 0.1751857576571216, 'Total loss': 0.1751857576571216}
2023-01-04 22:29:34,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:34,999 INFO:     Epoch: 97
2023-01-04 22:29:37,199 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4520598145822684, 'Total loss': 0.4520598145822684} | train loss {'Reaction outcome loss': 0.16934448360478965, 'Total loss': 0.16934448360478965}
2023-01-04 22:29:37,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:37,199 INFO:     Epoch: 98
2023-01-04 22:29:39,468 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4918341894944509, 'Total loss': 0.4918341894944509} | train loss {'Reaction outcome loss': 0.1717974130432054, 'Total loss': 0.1717974130432054}
2023-01-04 22:29:39,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:39,469 INFO:     Epoch: 99
2023-01-04 22:29:41,654 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47813229312499367, 'Total loss': 0.47813229312499367} | train loss {'Reaction outcome loss': 0.17301172165341838, 'Total loss': 0.17301172165341838}
2023-01-04 22:29:41,654 INFO:     Best model found after epoch 23 of 100.
2023-01-04 22:29:41,654 INFO:   Done with stage: TRAINING
2023-01-04 22:29:41,654 INFO:   Starting stage: EVALUATION
2023-01-04 22:29:41,791 INFO:   Done with stage: EVALUATION
2023-01-04 22:29:41,791 INFO:   Leaving out SEQ value Fold_2
2023-01-04 22:29:41,804 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 22:29:41,805 INFO:   Starting stage: FEATURE SCALING
2023-01-04 22:29:42,467 INFO:   Done with stage: FEATURE SCALING
2023-01-04 22:29:42,467 INFO:   Starting stage: SCALING TARGETS
2023-01-04 22:29:42,538 INFO:   Done with stage: SCALING TARGETS
2023-01-04 22:29:42,538 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:29:42,538 INFO:     No hyperparam tuning for this model
2023-01-04 22:29:42,538 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:29:42,538 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 22:29:42,539 INFO:     None feature selector for col prot
2023-01-04 22:29:42,539 INFO:     None feature selector for col prot
2023-01-04 22:29:42,539 INFO:     None feature selector for col prot
2023-01-04 22:29:42,540 INFO:     None feature selector for col chem
2023-01-04 22:29:42,540 INFO:     None feature selector for col chem
2023-01-04 22:29:42,540 INFO:     None feature selector for col chem
2023-01-04 22:29:42,540 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 22:29:42,540 INFO:   Starting stage: BUILD MODEL
2023-01-04 22:29:42,541 INFO:     Number of params in model 72931
2023-01-04 22:29:42,545 INFO:   Done with stage: BUILD MODEL
2023-01-04 22:29:42,545 INFO:   Starting stage: TRAINING
2023-01-04 22:29:42,606 INFO:     Val loss before train {'Reaction outcome loss': 1.1066210389137268, 'Total loss': 1.1066210389137268}
2023-01-04 22:29:42,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:42,606 INFO:     Epoch: 0
2023-01-04 22:29:44,848 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8292766292889913, 'Total loss': 0.8292766292889913} | train loss {'Reaction outcome loss': 0.9105622668335908, 'Total loss': 0.9105622668335908}
2023-01-04 22:29:44,850 INFO:     Found new best model at epoch 0
2023-01-04 22:29:44,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:44,851 INFO:     Epoch: 1
2023-01-04 22:29:47,112 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6341822564601898, 'Total loss': 0.6341822564601898} | train loss {'Reaction outcome loss': 0.6154156091765766, 'Total loss': 0.6154156091765766}
2023-01-04 22:29:47,113 INFO:     Found new best model at epoch 1
2023-01-04 22:29:47,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:47,114 INFO:     Epoch: 2
2023-01-04 22:29:49,368 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5856551110744477, 'Total loss': 0.5856551110744477} | train loss {'Reaction outcome loss': 0.5262879267008636, 'Total loss': 0.5262879267008636}
2023-01-04 22:29:49,368 INFO:     Found new best model at epoch 2
2023-01-04 22:29:49,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:49,369 INFO:     Epoch: 3
2023-01-04 22:29:51,572 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5905119746923446, 'Total loss': 0.5905119746923446} | train loss {'Reaction outcome loss': 0.4837973766083265, 'Total loss': 0.4837973766083265}
2023-01-04 22:29:51,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:51,573 INFO:     Epoch: 4
2023-01-04 22:29:53,713 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5575941552718481, 'Total loss': 0.5575941552718481} | train loss {'Reaction outcome loss': 0.4602120938527323, 'Total loss': 0.4602120938527323}
2023-01-04 22:29:53,714 INFO:     Found new best model at epoch 4
2023-01-04 22:29:53,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:53,715 INFO:     Epoch: 5
2023-01-04 22:29:55,953 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5594179729620615, 'Total loss': 0.5594179729620615} | train loss {'Reaction outcome loss': 0.43697986713726156, 'Total loss': 0.43697986713726156}
2023-01-04 22:29:55,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:55,954 INFO:     Epoch: 6
2023-01-04 22:29:58,198 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5836914757887522, 'Total loss': 0.5836914757887522} | train loss {'Reaction outcome loss': 0.42556648152152987, 'Total loss': 0.42556648152152987}
2023-01-04 22:29:58,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:29:58,199 INFO:     Epoch: 7
2023-01-04 22:30:00,467 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5461756110191345, 'Total loss': 0.5461756110191345} | train loss {'Reaction outcome loss': 0.4113122702297503, 'Total loss': 0.4113122702297503}
2023-01-04 22:30:00,467 INFO:     Found new best model at epoch 7
2023-01-04 22:30:00,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:00,468 INFO:     Epoch: 8
2023-01-04 22:30:02,735 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5702278792858124, 'Total loss': 0.5702278792858124} | train loss {'Reaction outcome loss': 0.39644981689588, 'Total loss': 0.39644981689588}
2023-01-04 22:30:02,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:02,736 INFO:     Epoch: 9
2023-01-04 22:30:04,990 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5360801994800568, 'Total loss': 0.5360801994800568} | train loss {'Reaction outcome loss': 0.38648874584558235, 'Total loss': 0.38648874584558235}
2023-01-04 22:30:04,990 INFO:     Found new best model at epoch 9
2023-01-04 22:30:04,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:04,992 INFO:     Epoch: 10
2023-01-04 22:30:07,247 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.572888974348704, 'Total loss': 0.572888974348704} | train loss {'Reaction outcome loss': 0.37343866106149926, 'Total loss': 0.37343866106149926}
2023-01-04 22:30:07,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:07,248 INFO:     Epoch: 11
2023-01-04 22:30:09,488 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5344710568586986, 'Total loss': 0.5344710568586986} | train loss {'Reaction outcome loss': 0.3619292309630091, 'Total loss': 0.3619292309630091}
2023-01-04 22:30:09,488 INFO:     Found new best model at epoch 11
2023-01-04 22:30:09,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:09,490 INFO:     Epoch: 12
2023-01-04 22:30:11,716 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5180983195702235, 'Total loss': 0.5180983195702235} | train loss {'Reaction outcome loss': 0.3586696717534622, 'Total loss': 0.3586696717534622}
2023-01-04 22:30:11,717 INFO:     Found new best model at epoch 12
2023-01-04 22:30:11,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:11,718 INFO:     Epoch: 13
2023-01-04 22:30:13,992 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5507307380437851, 'Total loss': 0.5507307380437851} | train loss {'Reaction outcome loss': 0.3503682803988022, 'Total loss': 0.3503682803988022}
2023-01-04 22:30:13,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:13,992 INFO:     Epoch: 14
2023-01-04 22:30:16,251 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5479197005430857, 'Total loss': 0.5479197005430857} | train loss {'Reaction outcome loss': 0.33685507630779793, 'Total loss': 0.33685507630779793}
2023-01-04 22:30:16,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:16,252 INFO:     Epoch: 15
2023-01-04 22:30:18,478 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5420300304889679, 'Total loss': 0.5420300304889679} | train loss {'Reaction outcome loss': 0.33332448131846687, 'Total loss': 0.33332448131846687}
2023-01-04 22:30:18,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:18,479 INFO:     Epoch: 16
2023-01-04 22:30:20,727 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5298066685597101, 'Total loss': 0.5298066685597101} | train loss {'Reaction outcome loss': 0.329096903412664, 'Total loss': 0.329096903412664}
2023-01-04 22:30:20,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:20,728 INFO:     Epoch: 17
2023-01-04 22:30:22,996 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5404175202051799, 'Total loss': 0.5404175202051799} | train loss {'Reaction outcome loss': 0.3193129040300846, 'Total loss': 0.3193129040300846}
2023-01-04 22:30:22,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:22,996 INFO:     Epoch: 18
2023-01-04 22:30:25,280 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5403169631958008, 'Total loss': 0.5403169631958008} | train loss {'Reaction outcome loss': 0.3122112213287258, 'Total loss': 0.3122112213287258}
2023-01-04 22:30:25,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:25,281 INFO:     Epoch: 19
2023-01-04 22:30:27,501 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5004139214754104, 'Total loss': 0.5004139214754104} | train loss {'Reaction outcome loss': 0.30840339798507466, 'Total loss': 0.30840339798507466}
2023-01-04 22:30:27,501 INFO:     Found new best model at epoch 19
2023-01-04 22:30:27,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:27,503 INFO:     Epoch: 20
2023-01-04 22:30:29,747 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5453201899925868, 'Total loss': 0.5453201899925868} | train loss {'Reaction outcome loss': 0.2975238054501314, 'Total loss': 0.2975238054501314}
2023-01-04 22:30:29,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:29,747 INFO:     Epoch: 21
2023-01-04 22:30:32,020 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5407557596762975, 'Total loss': 0.5407557596762975} | train loss {'Reaction outcome loss': 0.2909466986252117, 'Total loss': 0.2909466986252117}
2023-01-04 22:30:32,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:32,021 INFO:     Epoch: 22
2023-01-04 22:30:34,288 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5027972807486852, 'Total loss': 0.5027972807486852} | train loss {'Reaction outcome loss': 0.2909644175538399, 'Total loss': 0.2909644175538399}
2023-01-04 22:30:34,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:34,288 INFO:     Epoch: 23
2023-01-04 22:30:36,552 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5268844644228617, 'Total loss': 0.5268844644228617} | train loss {'Reaction outcome loss': 0.2810505537900829, 'Total loss': 0.2810505537900829}
2023-01-04 22:30:36,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:36,552 INFO:     Epoch: 24
2023-01-04 22:30:38,810 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5131528114279111, 'Total loss': 0.5131528114279111} | train loss {'Reaction outcome loss': 0.2842436831743613, 'Total loss': 0.2842436831743613}
2023-01-04 22:30:38,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:38,811 INFO:     Epoch: 25
2023-01-04 22:30:40,999 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5262200564146042, 'Total loss': 0.5262200564146042} | train loss {'Reaction outcome loss': 0.27247361189610986, 'Total loss': 0.27247361189610986}
2023-01-04 22:30:40,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:40,999 INFO:     Epoch: 26
2023-01-04 22:30:43,179 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5490716060002645, 'Total loss': 0.5490716060002645} | train loss {'Reaction outcome loss': 0.2674099782305042, 'Total loss': 0.2674099782305042}
2023-01-04 22:30:43,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:43,181 INFO:     Epoch: 27
2023-01-04 22:30:45,429 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5310064285993576, 'Total loss': 0.5310064285993576} | train loss {'Reaction outcome loss': 0.26524542804372353, 'Total loss': 0.26524542804372353}
2023-01-04 22:30:45,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:45,430 INFO:     Epoch: 28
2023-01-04 22:30:47,680 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5405187567075094, 'Total loss': 0.5405187567075094} | train loss {'Reaction outcome loss': 0.26122121081558347, 'Total loss': 0.26122121081558347}
2023-01-04 22:30:47,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:47,681 INFO:     Epoch: 29
2023-01-04 22:30:49,922 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.540902578830719, 'Total loss': 0.540902578830719} | train loss {'Reaction outcome loss': 0.25993276396970244, 'Total loss': 0.25993276396970244}
2023-01-04 22:30:49,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:49,922 INFO:     Epoch: 30
2023-01-04 22:30:52,160 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.546812258164088, 'Total loss': 0.546812258164088} | train loss {'Reaction outcome loss': 0.25469086675422037, 'Total loss': 0.25469086675422037}
2023-01-04 22:30:52,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:52,160 INFO:     Epoch: 31
2023-01-04 22:30:54,413 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5592952092488607, 'Total loss': 0.5592952092488607} | train loss {'Reaction outcome loss': 0.2535101269936039, 'Total loss': 0.2535101269936039}
2023-01-04 22:30:54,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:54,414 INFO:     Epoch: 32
2023-01-04 22:30:56,664 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5483572373787562, 'Total loss': 0.5483572373787562} | train loss {'Reaction outcome loss': 0.2486161302645983, 'Total loss': 0.2486161302645983}
2023-01-04 22:30:56,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:56,664 INFO:     Epoch: 33
2023-01-04 22:30:58,899 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5402832249800364, 'Total loss': 0.5402832249800364} | train loss {'Reaction outcome loss': 0.24671062872656724, 'Total loss': 0.24671062872656724}
2023-01-04 22:30:58,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:30:58,900 INFO:     Epoch: 34
2023-01-04 22:31:01,104 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5338155140479406, 'Total loss': 0.5338155140479406} | train loss {'Reaction outcome loss': 0.24280564939045776, 'Total loss': 0.24280564939045776}
2023-01-04 22:31:01,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:01,105 INFO:     Epoch: 35
2023-01-04 22:31:03,352 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5403121034304301, 'Total loss': 0.5403121034304301} | train loss {'Reaction outcome loss': 0.2401647602350716, 'Total loss': 0.2401647602350716}
2023-01-04 22:31:03,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:03,352 INFO:     Epoch: 36
2023-01-04 22:31:05,533 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5477827941377957, 'Total loss': 0.5477827941377957} | train loss {'Reaction outcome loss': 0.23689841397487335, 'Total loss': 0.23689841397487335}
2023-01-04 22:31:05,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:05,535 INFO:     Epoch: 37
2023-01-04 22:31:07,794 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5417778591314951, 'Total loss': 0.5417778591314951} | train loss {'Reaction outcome loss': 0.23705948639090044, 'Total loss': 0.23705948639090044}
2023-01-04 22:31:07,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:07,794 INFO:     Epoch: 38
2023-01-04 22:31:10,037 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.527475006878376, 'Total loss': 0.527475006878376} | train loss {'Reaction outcome loss': 0.22762506845046895, 'Total loss': 0.22762506845046895}
2023-01-04 22:31:10,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:10,037 INFO:     Epoch: 39
2023-01-04 22:31:12,297 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5667998313903808, 'Total loss': 0.5667998313903808} | train loss {'Reaction outcome loss': 0.22524441646609156, 'Total loss': 0.22524441646609156}
2023-01-04 22:31:12,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:12,298 INFO:     Epoch: 40
2023-01-04 22:31:14,538 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5574570059776306, 'Total loss': 0.5574570059776306} | train loss {'Reaction outcome loss': 0.23124947230311205, 'Total loss': 0.23124947230311205}
2023-01-04 22:31:14,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:14,539 INFO:     Epoch: 41
2023-01-04 22:31:16,754 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5775211125612258, 'Total loss': 0.5775211125612258} | train loss {'Reaction outcome loss': 0.22530004101717016, 'Total loss': 0.22530004101717016}
2023-01-04 22:31:16,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:16,755 INFO:     Epoch: 42
2023-01-04 22:31:18,977 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5553259313106537, 'Total loss': 0.5553259313106537} | train loss {'Reaction outcome loss': 0.22279438262560616, 'Total loss': 0.22279438262560616}
2023-01-04 22:31:18,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:18,977 INFO:     Epoch: 43
2023-01-04 22:31:21,210 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5554804434378942, 'Total loss': 0.5554804434378942} | train loss {'Reaction outcome loss': 0.2252458066213876, 'Total loss': 0.2252458066213876}
2023-01-04 22:31:21,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:21,210 INFO:     Epoch: 44
2023-01-04 22:31:23,404 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5532529989878336, 'Total loss': 0.5532529989878336} | train loss {'Reaction outcome loss': 0.22079098691830723, 'Total loss': 0.22079098691830723}
2023-01-04 22:31:23,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:23,406 INFO:     Epoch: 45
2023-01-04 22:31:25,633 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5286779542764027, 'Total loss': 0.5286779542764027} | train loss {'Reaction outcome loss': 0.21571689411440362, 'Total loss': 0.21571689411440362}
2023-01-04 22:31:25,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:25,633 INFO:     Epoch: 46
2023-01-04 22:31:27,865 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.53445908476909, 'Total loss': 0.53445908476909} | train loss {'Reaction outcome loss': 0.21596570680747285, 'Total loss': 0.21596570680747285}
2023-01-04 22:31:27,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:27,865 INFO:     Epoch: 47
2023-01-04 22:31:30,092 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5814224819342295, 'Total loss': 0.5814224819342295} | train loss {'Reaction outcome loss': 0.21222391205561095, 'Total loss': 0.21222391205561095}
2023-01-04 22:31:30,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:30,093 INFO:     Epoch: 48
2023-01-04 22:31:32,304 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.559515651067098, 'Total loss': 0.559515651067098} | train loss {'Reaction outcome loss': 0.20980966317528574, 'Total loss': 0.20980966317528574}
2023-01-04 22:31:32,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:32,304 INFO:     Epoch: 49
2023-01-04 22:31:34,529 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5524471258123715, 'Total loss': 0.5524471258123715} | train loss {'Reaction outcome loss': 0.2091689419212078, 'Total loss': 0.2091689419212078}
2023-01-04 22:31:34,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:34,530 INFO:     Epoch: 50
2023-01-04 22:31:36,753 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5451670269171397, 'Total loss': 0.5451670269171397} | train loss {'Reaction outcome loss': 0.21043983780282693, 'Total loss': 0.21043983780282693}
2023-01-04 22:31:36,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:36,753 INFO:     Epoch: 51
2023-01-04 22:31:38,978 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5897011955579122, 'Total loss': 0.5897011955579122} | train loss {'Reaction outcome loss': 0.20446564721106722, 'Total loss': 0.20446564721106722}
2023-01-04 22:31:38,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:38,979 INFO:     Epoch: 52
2023-01-04 22:31:41,210 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.6127247353394826, 'Total loss': 0.6127247353394826} | train loss {'Reaction outcome loss': 0.20295830489727704, 'Total loss': 0.20295830489727704}
2023-01-04 22:31:41,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:41,211 INFO:     Epoch: 53
2023-01-04 22:31:43,441 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5727625767389933, 'Total loss': 0.5727625767389933} | train loss {'Reaction outcome loss': 0.20501377436937424, 'Total loss': 0.20501377436937424}
2023-01-04 22:31:43,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:43,442 INFO:     Epoch: 54
2023-01-04 22:31:45,693 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.532984548031042, 'Total loss': 0.532984548031042} | train loss {'Reaction outcome loss': 0.2001842711644288, 'Total loss': 0.2001842711644288}
2023-01-04 22:31:45,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:45,693 INFO:     Epoch: 55
2023-01-04 22:31:47,893 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.550624457001686, 'Total loss': 0.550624457001686} | train loss {'Reaction outcome loss': 0.20080797798102246, 'Total loss': 0.20080797798102246}
2023-01-04 22:31:47,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:47,895 INFO:     Epoch: 56
2023-01-04 22:31:50,093 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5590196241935094, 'Total loss': 0.5590196241935094} | train loss {'Reaction outcome loss': 0.20373877916267535, 'Total loss': 0.20373877916267535}
2023-01-04 22:31:50,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:50,093 INFO:     Epoch: 57
2023-01-04 22:31:52,335 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5397585064172745, 'Total loss': 0.5397585064172745} | train loss {'Reaction outcome loss': 0.19963167574474194, 'Total loss': 0.19963167574474194}
2023-01-04 22:31:52,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:52,336 INFO:     Epoch: 58
2023-01-04 22:31:54,560 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5523487195372582, 'Total loss': 0.5523487195372582} | train loss {'Reaction outcome loss': 0.19594517564842898, 'Total loss': 0.19594517564842898}
2023-01-04 22:31:54,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:54,560 INFO:     Epoch: 59
2023-01-04 22:31:56,729 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5538517133022348, 'Total loss': 0.5538517133022348} | train loss {'Reaction outcome loss': 0.2031230020547544, 'Total loss': 0.2031230020547544}
2023-01-04 22:31:56,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:56,730 INFO:     Epoch: 60
2023-01-04 22:31:58,957 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5760824859142304, 'Total loss': 0.5760824859142304} | train loss {'Reaction outcome loss': 0.19503207772759462, 'Total loss': 0.19503207772759462}
2023-01-04 22:31:58,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:31:58,958 INFO:     Epoch: 61
2023-01-04 22:32:01,135 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5261749939372142, 'Total loss': 0.5261749939372142} | train loss {'Reaction outcome loss': 0.1953150422149168, 'Total loss': 0.1953150422149168}
2023-01-04 22:32:01,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:01,135 INFO:     Epoch: 62
2023-01-04 22:32:03,338 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.552404793103536, 'Total loss': 0.552404793103536} | train loss {'Reaction outcome loss': 0.18660059498527842, 'Total loss': 0.18660059498527842}
2023-01-04 22:32:03,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:03,339 INFO:     Epoch: 63
2023-01-04 22:32:05,558 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5500327010949453, 'Total loss': 0.5500327010949453} | train loss {'Reaction outcome loss': 0.1859109011805025, 'Total loss': 0.1859109011805025}
2023-01-04 22:32:05,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:05,558 INFO:     Epoch: 64
2023-01-04 22:32:07,810 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.525762178353034, 'Total loss': 0.525762178353034} | train loss {'Reaction outcome loss': 0.19019247305980563, 'Total loss': 0.19019247305980563}
2023-01-04 22:32:07,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:07,810 INFO:     Epoch: 65
2023-01-04 22:32:09,999 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5762807031472524, 'Total loss': 0.5762807031472524} | train loss {'Reaction outcome loss': 0.18928931313260955, 'Total loss': 0.18928931313260955}
2023-01-04 22:32:10,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:10,000 INFO:     Epoch: 66
2023-01-04 22:32:12,254 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5505142052968343, 'Total loss': 0.5505142052968343} | train loss {'Reaction outcome loss': 0.18944565373656413, 'Total loss': 0.18944565373656413}
2023-01-04 22:32:12,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:12,254 INFO:     Epoch: 67
2023-01-04 22:32:14,448 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5270490114887555, 'Total loss': 0.5270490114887555} | train loss {'Reaction outcome loss': 0.1858381579059047, 'Total loss': 0.1858381579059047}
2023-01-04 22:32:14,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:14,449 INFO:     Epoch: 68
2023-01-04 22:32:16,656 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5501852711041768, 'Total loss': 0.5501852711041768} | train loss {'Reaction outcome loss': 0.18927779653870982, 'Total loss': 0.18927779653870982}
2023-01-04 22:32:16,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:16,657 INFO:     Epoch: 69
2023-01-04 22:32:18,890 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5497224013010661, 'Total loss': 0.5497224013010661} | train loss {'Reaction outcome loss': 0.18974511768927213, 'Total loss': 0.18974511768927213}
2023-01-04 22:32:18,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:18,890 INFO:     Epoch: 70
2023-01-04 22:32:21,152 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5334476896872123, 'Total loss': 0.5334476896872123} | train loss {'Reaction outcome loss': 0.18550468528520886, 'Total loss': 0.18550468528520886}
2023-01-04 22:32:21,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:21,153 INFO:     Epoch: 71
2023-01-04 22:32:23,415 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5523016154766083, 'Total loss': 0.5523016154766083} | train loss {'Reaction outcome loss': 0.17690106875596256, 'Total loss': 0.17690106875596256}
2023-01-04 22:32:23,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:23,415 INFO:     Epoch: 72
2023-01-04 22:32:25,638 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5877790331840516, 'Total loss': 0.5877790331840516} | train loss {'Reaction outcome loss': 0.17994735487413857, 'Total loss': 0.17994735487413857}
2023-01-04 22:32:25,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:25,640 INFO:     Epoch: 73
2023-01-04 22:32:27,845 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5656994958718617, 'Total loss': 0.5656994958718617} | train loss {'Reaction outcome loss': 0.17762165524772483, 'Total loss': 0.17762165524772483}
2023-01-04 22:32:27,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:27,846 INFO:     Epoch: 74
2023-01-04 22:32:30,090 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5506399174531301, 'Total loss': 0.5506399174531301} | train loss {'Reaction outcome loss': 0.17747168830276405, 'Total loss': 0.17747168830276405}
2023-01-04 22:32:30,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:30,091 INFO:     Epoch: 75
2023-01-04 22:32:32,350 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5634663661321004, 'Total loss': 0.5634663661321004} | train loss {'Reaction outcome loss': 0.1770310507930924, 'Total loss': 0.1770310507930924}
2023-01-04 22:32:32,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:32,352 INFO:     Epoch: 76
2023-01-04 22:32:34,622 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5981345504522324, 'Total loss': 0.5981345504522324} | train loss {'Reaction outcome loss': 0.18437401620657556, 'Total loss': 0.18437401620657556}
2023-01-04 22:32:34,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:34,622 INFO:     Epoch: 77
2023-01-04 22:32:36,884 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5592159827550253, 'Total loss': 0.5592159827550253} | train loss {'Reaction outcome loss': 0.18058458360822965, 'Total loss': 0.18058458360822965}
2023-01-04 22:32:36,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:36,884 INFO:     Epoch: 78
2023-01-04 22:32:39,152 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5730501870314281, 'Total loss': 0.5730501870314281} | train loss {'Reaction outcome loss': 0.17432121911007967, 'Total loss': 0.17432121911007967}
2023-01-04 22:32:39,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:39,153 INFO:     Epoch: 79
2023-01-04 22:32:41,403 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5620956281820934, 'Total loss': 0.5620956281820934} | train loss {'Reaction outcome loss': 0.17434681928376702, 'Total loss': 0.17434681928376702}
2023-01-04 22:32:41,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:41,403 INFO:     Epoch: 80
2023-01-04 22:32:43,657 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5669368301828702, 'Total loss': 0.5669368301828702} | train loss {'Reaction outcome loss': 0.17175676881668778, 'Total loss': 0.17175676881668778}
2023-01-04 22:32:43,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:43,659 INFO:     Epoch: 81
2023-01-04 22:32:45,914 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5932767768700917, 'Total loss': 0.5932767768700917} | train loss {'Reaction outcome loss': 0.17190251583029537, 'Total loss': 0.17190251583029537}
2023-01-04 22:32:45,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:45,914 INFO:     Epoch: 82
2023-01-04 22:32:48,122 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.586060713728269, 'Total loss': 0.586060713728269} | train loss {'Reaction outcome loss': 0.17193192781465821, 'Total loss': 0.17193192781465821}
2023-01-04 22:32:48,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:48,123 INFO:     Epoch: 83
2023-01-04 22:32:50,395 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5612507417798043, 'Total loss': 0.5612507417798043} | train loss {'Reaction outcome loss': 0.17078636666882213, 'Total loss': 0.17078636666882213}
2023-01-04 22:32:50,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:50,395 INFO:     Epoch: 84
2023-01-04 22:32:52,627 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5830111145973206, 'Total loss': 0.5830111145973206} | train loss {'Reaction outcome loss': 0.17476136624697514, 'Total loss': 0.17476136624697514}
2023-01-04 22:32:52,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:52,628 INFO:     Epoch: 85
2023-01-04 22:32:54,889 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5461734433968862, 'Total loss': 0.5461734433968862} | train loss {'Reaction outcome loss': 0.17321830006727582, 'Total loss': 0.17321830006727582}
2023-01-04 22:32:54,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:54,890 INFO:     Epoch: 86
2023-01-04 22:32:57,150 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5713727235794067, 'Total loss': 0.5713727235794067} | train loss {'Reaction outcome loss': 0.1720194772096609, 'Total loss': 0.1720194772096609}
2023-01-04 22:32:57,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:57,150 INFO:     Epoch: 87
2023-01-04 22:32:59,386 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5722334285577139, 'Total loss': 0.5722334285577139} | train loss {'Reaction outcome loss': 0.17941724006800375, 'Total loss': 0.17941724006800375}
2023-01-04 22:32:59,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:32:59,387 INFO:     Epoch: 88
2023-01-04 22:33:01,638 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5820842703183492, 'Total loss': 0.5820842703183492} | train loss {'Reaction outcome loss': 0.17069527195820952, 'Total loss': 0.17069527195820952}
2023-01-04 22:33:01,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:01,639 INFO:     Epoch: 89
2023-01-04 22:33:03,811 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5783622115850449, 'Total loss': 0.5783622115850449} | train loss {'Reaction outcome loss': 0.16869429527632349, 'Total loss': 0.16869429527632349}
2023-01-04 22:33:03,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:03,811 INFO:     Epoch: 90
2023-01-04 22:33:06,057 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5716865370670955, 'Total loss': 0.5716865370670955} | train loss {'Reaction outcome loss': 0.16217914921483093, 'Total loss': 0.16217914921483093}
2023-01-04 22:33:06,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:06,057 INFO:     Epoch: 91
2023-01-04 22:33:08,271 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5689607630173366, 'Total loss': 0.5689607630173366} | train loss {'Reaction outcome loss': 0.16730753708814344, 'Total loss': 0.16730753708814344}
2023-01-04 22:33:08,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:08,272 INFO:     Epoch: 92
2023-01-04 22:33:10,529 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5691305299599966, 'Total loss': 0.5691305299599966} | train loss {'Reaction outcome loss': 0.1691861679525978, 'Total loss': 0.1691861679525978}
2023-01-04 22:33:10,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:10,529 INFO:     Epoch: 93
2023-01-04 22:33:12,768 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.60523368815581, 'Total loss': 0.60523368815581} | train loss {'Reaction outcome loss': 0.16339268347581537, 'Total loss': 0.16339268347581537}
2023-01-04 22:33:12,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:12,770 INFO:     Epoch: 94
2023-01-04 22:33:15,013 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5476932935416698, 'Total loss': 0.5476932935416698} | train loss {'Reaction outcome loss': 0.16549400707373707, 'Total loss': 0.16549400707373707}
2023-01-04 22:33:15,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:15,013 INFO:     Epoch: 95
2023-01-04 22:33:17,236 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5527905752261479, 'Total loss': 0.5527905752261479} | train loss {'Reaction outcome loss': 0.16942640506138984, 'Total loss': 0.16942640506138984}
2023-01-04 22:33:17,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:17,236 INFO:     Epoch: 96
2023-01-04 22:33:19,351 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5442483276128769, 'Total loss': 0.5442483276128769} | train loss {'Reaction outcome loss': 0.1634460082719524, 'Total loss': 0.1634460082719524}
2023-01-04 22:33:19,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:19,352 INFO:     Epoch: 97
2023-01-04 22:33:21,617 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5547555565834046, 'Total loss': 0.5547555565834046} | train loss {'Reaction outcome loss': 0.16858809581876183, 'Total loss': 0.16858809581876183}
2023-01-04 22:33:21,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:21,617 INFO:     Epoch: 98
2023-01-04 22:33:23,859 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.562810077269872, 'Total loss': 0.562810077269872} | train loss {'Reaction outcome loss': 0.16292726967558538, 'Total loss': 0.16292726967558538}
2023-01-04 22:33:23,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:23,861 INFO:     Epoch: 99
2023-01-04 22:33:26,136 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5357380126913388, 'Total loss': 0.5357380126913388} | train loss {'Reaction outcome loss': 0.1676031931738512, 'Total loss': 0.1676031931738512}
2023-01-04 22:33:26,136 INFO:     Best model found after epoch 20 of 100.
2023-01-04 22:33:26,136 INFO:   Done with stage: TRAINING
2023-01-04 22:33:26,136 INFO:   Starting stage: EVALUATION
2023-01-04 22:33:26,279 INFO:   Done with stage: EVALUATION
2023-01-04 22:33:26,279 INFO:   Leaving out SEQ value Fold_3
2023-01-04 22:33:26,292 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 22:33:26,292 INFO:   Starting stage: FEATURE SCALING
2023-01-04 22:33:26,935 INFO:   Done with stage: FEATURE SCALING
2023-01-04 22:33:26,935 INFO:   Starting stage: SCALING TARGETS
2023-01-04 22:33:27,005 INFO:   Done with stage: SCALING TARGETS
2023-01-04 22:33:27,006 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:33:27,006 INFO:     No hyperparam tuning for this model
2023-01-04 22:33:27,006 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:33:27,006 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 22:33:27,007 INFO:     None feature selector for col prot
2023-01-04 22:33:27,007 INFO:     None feature selector for col prot
2023-01-04 22:33:27,007 INFO:     None feature selector for col prot
2023-01-04 22:33:27,007 INFO:     None feature selector for col chem
2023-01-04 22:33:27,007 INFO:     None feature selector for col chem
2023-01-04 22:33:27,008 INFO:     None feature selector for col chem
2023-01-04 22:33:27,008 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 22:33:27,008 INFO:   Starting stage: BUILD MODEL
2023-01-04 22:33:27,009 INFO:     Number of params in model 72931
2023-01-04 22:33:27,012 INFO:   Done with stage: BUILD MODEL
2023-01-04 22:33:27,013 INFO:   Starting stage: TRAINING
2023-01-04 22:33:27,074 INFO:     Val loss before train {'Reaction outcome loss': 0.9392196774482727, 'Total loss': 0.9392196774482727}
2023-01-04 22:33:27,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:27,074 INFO:     Epoch: 0
2023-01-04 22:33:29,308 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7978243271509806, 'Total loss': 0.7978243271509806} | train loss {'Reaction outcome loss': 0.9462610956950065, 'Total loss': 0.9462610956950065}
2023-01-04 22:33:29,309 INFO:     Found new best model at epoch 0
2023-01-04 22:33:29,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:29,311 INFO:     Epoch: 1
2023-01-04 22:33:31,567 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5780031224091847, 'Total loss': 0.5780031224091847} | train loss {'Reaction outcome loss': 0.6460060470706814, 'Total loss': 0.6460060470706814}
2023-01-04 22:33:31,567 INFO:     Found new best model at epoch 1
2023-01-04 22:33:31,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:31,568 INFO:     Epoch: 2
2023-01-04 22:33:33,805 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5952313969532649, 'Total loss': 0.5952313969532649} | train loss {'Reaction outcome loss': 0.5231290359200139, 'Total loss': 0.5231290359200139}
2023-01-04 22:33:33,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:33,805 INFO:     Epoch: 3
2023-01-04 22:33:36,061 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5289978682994843, 'Total loss': 0.5289978682994843} | train loss {'Reaction outcome loss': 0.4777857584285212, 'Total loss': 0.4777857584285212}
2023-01-04 22:33:36,063 INFO:     Found new best model at epoch 3
2023-01-04 22:33:36,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:36,064 INFO:     Epoch: 4
2023-01-04 22:33:38,315 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5208817745248476, 'Total loss': 0.5208817745248476} | train loss {'Reaction outcome loss': 0.4446098247727195, 'Total loss': 0.4446098247727195}
2023-01-04 22:33:38,315 INFO:     Found new best model at epoch 4
2023-01-04 22:33:38,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:38,316 INFO:     Epoch: 5
2023-01-04 22:33:40,554 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5216988225777944, 'Total loss': 0.5216988225777944} | train loss {'Reaction outcome loss': 0.42603674510514344, 'Total loss': 0.42603674510514344}
2023-01-04 22:33:40,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:40,556 INFO:     Epoch: 6
2023-01-04 22:33:42,819 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4877832528203726, 'Total loss': 0.4877832528203726} | train loss {'Reaction outcome loss': 0.40615404711101516, 'Total loss': 0.40615404711101516}
2023-01-04 22:33:42,819 INFO:     Found new best model at epoch 6
2023-01-04 22:33:42,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:42,821 INFO:     Epoch: 7
2023-01-04 22:33:45,067 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5039404730002085, 'Total loss': 0.5039404730002085} | train loss {'Reaction outcome loss': 0.394250546564986, 'Total loss': 0.394250546564986}
2023-01-04 22:33:45,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:45,068 INFO:     Epoch: 8
2023-01-04 22:33:47,273 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5055680672327677, 'Total loss': 0.5055680672327677} | train loss {'Reaction outcome loss': 0.3787904181978205, 'Total loss': 0.3787904181978205}
2023-01-04 22:33:47,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:47,275 INFO:     Epoch: 9
2023-01-04 22:33:49,514 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4912211187183857, 'Total loss': 0.4912211187183857} | train loss {'Reaction outcome loss': 0.37231122756943164, 'Total loss': 0.37231122756943164}
2023-01-04 22:33:49,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:49,514 INFO:     Epoch: 10
2023-01-04 22:33:51,740 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4770144273837407, 'Total loss': 0.4770144273837407} | train loss {'Reaction outcome loss': 0.3585266029605499, 'Total loss': 0.3585266029605499}
2023-01-04 22:33:51,740 INFO:     Found new best model at epoch 10
2023-01-04 22:33:51,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:51,741 INFO:     Epoch: 11
2023-01-04 22:33:53,992 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5015230586131414, 'Total loss': 0.5015230586131414} | train loss {'Reaction outcome loss': 0.34865229642325707, 'Total loss': 0.34865229642325707}
2023-01-04 22:33:53,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:53,993 INFO:     Epoch: 12
2023-01-04 22:33:56,232 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5151798764864604, 'Total loss': 0.5151798764864604} | train loss {'Reaction outcome loss': 0.3420485895222578, 'Total loss': 0.3420485895222578}
2023-01-04 22:33:56,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:56,232 INFO:     Epoch: 13
2023-01-04 22:33:58,465 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4705198605855306, 'Total loss': 0.4705198605855306} | train loss {'Reaction outcome loss': 0.33733237652114895, 'Total loss': 0.33733237652114895}
2023-01-04 22:33:58,466 INFO:     Found new best model at epoch 13
2023-01-04 22:33:58,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:33:58,468 INFO:     Epoch: 14
2023-01-04 22:34:00,690 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47371978710095086, 'Total loss': 0.47371978710095086} | train loss {'Reaction outcome loss': 0.3293316218961071, 'Total loss': 0.3293316218961071}
2023-01-04 22:34:00,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:00,690 INFO:     Epoch: 15
2023-01-04 22:34:02,930 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5024752140045166, 'Total loss': 0.5024752140045166} | train loss {'Reaction outcome loss': 0.3218727517368156, 'Total loss': 0.3218727517368156}
2023-01-04 22:34:02,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:02,930 INFO:     Epoch: 16
2023-01-04 22:34:05,163 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49428622821966806, 'Total loss': 0.49428622821966806} | train loss {'Reaction outcome loss': 0.3144993557707294, 'Total loss': 0.3144993557707294}
2023-01-04 22:34:05,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:05,164 INFO:     Epoch: 17
2023-01-04 22:34:07,304 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5769920835892359, 'Total loss': 0.5769920835892359} | train loss {'Reaction outcome loss': 0.3101382060829318, 'Total loss': 0.3101382060829318}
2023-01-04 22:34:07,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:07,304 INFO:     Epoch: 18
2023-01-04 22:34:09,519 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5060303469498952, 'Total loss': 0.5060303469498952} | train loss {'Reaction outcome loss': 0.3075032421684527, 'Total loss': 0.3075032421684527}
2023-01-04 22:34:09,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:09,520 INFO:     Epoch: 19
2023-01-04 22:34:11,754 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5290665283799172, 'Total loss': 0.5290665283799172} | train loss {'Reaction outcome loss': 0.2988447458329764, 'Total loss': 0.2988447458329764}
2023-01-04 22:34:11,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:11,755 INFO:     Epoch: 20
2023-01-04 22:34:13,950 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48497905731201174, 'Total loss': 0.48497905731201174} | train loss {'Reaction outcome loss': 0.2927135696204809, 'Total loss': 0.2927135696204809}
2023-01-04 22:34:13,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:13,950 INFO:     Epoch: 21
2023-01-04 22:34:16,140 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4889644955595334, 'Total loss': 0.4889644955595334} | train loss {'Reaction outcome loss': 0.29193293681920884, 'Total loss': 0.29193293681920884}
2023-01-04 22:34:16,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:16,140 INFO:     Epoch: 22
2023-01-04 22:34:18,380 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.500280213356018, 'Total loss': 0.500280213356018} | train loss {'Reaction outcome loss': 0.28809407507598184, 'Total loss': 0.28809407507598184}
2023-01-04 22:34:18,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:18,381 INFO:     Epoch: 23
2023-01-04 22:34:20,571 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5111172725756963, 'Total loss': 0.5111172725756963} | train loss {'Reaction outcome loss': 0.2815051331515714, 'Total loss': 0.2815051331515714}
2023-01-04 22:34:20,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:20,571 INFO:     Epoch: 24
2023-01-04 22:34:22,827 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5290860772132874, 'Total loss': 0.5290860772132874} | train loss {'Reaction outcome loss': 0.2775206443454538, 'Total loss': 0.2775206443454538}
2023-01-04 22:34:22,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:22,828 INFO:     Epoch: 25
2023-01-04 22:34:25,017 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4787944475809733, 'Total loss': 0.4787944475809733} | train loss {'Reaction outcome loss': 0.27055640686508065, 'Total loss': 0.27055640686508065}
2023-01-04 22:34:25,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:25,018 INFO:     Epoch: 26
2023-01-04 22:34:27,252 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4949183791875839, 'Total loss': 0.4949183791875839} | train loss {'Reaction outcome loss': 0.27200552889388124, 'Total loss': 0.27200552889388124}
2023-01-04 22:34:27,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:27,252 INFO:     Epoch: 27
2023-01-04 22:34:29,503 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49663961430390674, 'Total loss': 0.49663961430390674} | train loss {'Reaction outcome loss': 0.2716679561460193, 'Total loss': 0.2716679561460193}
2023-01-04 22:34:29,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:29,504 INFO:     Epoch: 28
2023-01-04 22:34:31,736 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5083163499832153, 'Total loss': 0.5083163499832153} | train loss {'Reaction outcome loss': 0.26422159199094597, 'Total loss': 0.26422159199094597}
2023-01-04 22:34:31,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:31,736 INFO:     Epoch: 29
2023-01-04 22:34:33,992 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5046425531307857, 'Total loss': 0.5046425531307857} | train loss {'Reaction outcome loss': 0.2597747245332697, 'Total loss': 0.2597747245332697}
2023-01-04 22:34:33,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:33,994 INFO:     Epoch: 30
2023-01-04 22:34:36,206 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5369059473276139, 'Total loss': 0.5369059473276139} | train loss {'Reaction outcome loss': 0.26039718279116975, 'Total loss': 0.26039718279116975}
2023-01-04 22:34:36,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:36,206 INFO:     Epoch: 31
2023-01-04 22:34:38,452 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5227616508801778, 'Total loss': 0.5227616508801778} | train loss {'Reaction outcome loss': 0.2503915185538622, 'Total loss': 0.2503915185538622}
2023-01-04 22:34:38,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:38,452 INFO:     Epoch: 32
2023-01-04 22:34:40,704 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5170827627182006, 'Total loss': 0.5170827627182006} | train loss {'Reaction outcome loss': 0.25194982652153286, 'Total loss': 0.25194982652153286}
2023-01-04 22:34:40,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:40,705 INFO:     Epoch: 33
2023-01-04 22:34:42,951 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48150574217240016, 'Total loss': 0.48150574217240016} | train loss {'Reaction outcome loss': 0.25250721248992525, 'Total loss': 0.25250721248992525}
2023-01-04 22:34:42,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:42,951 INFO:     Epoch: 34
2023-01-04 22:34:45,222 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5281141857306163, 'Total loss': 0.5281141857306163} | train loss {'Reaction outcome loss': 0.24379949517984748, 'Total loss': 0.24379949517984748}
2023-01-04 22:34:45,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:45,223 INFO:     Epoch: 35
2023-01-04 22:34:47,527 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5133025666077932, 'Total loss': 0.5133025666077932} | train loss {'Reaction outcome loss': 0.24374319344755577, 'Total loss': 0.24374319344755577}
2023-01-04 22:34:47,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:47,529 INFO:     Epoch: 36
2023-01-04 22:34:49,822 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.495108096798261, 'Total loss': 0.495108096798261} | train loss {'Reaction outcome loss': 0.24497334957941547, 'Total loss': 0.24497334957941547}
2023-01-04 22:34:49,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:49,822 INFO:     Epoch: 37
2023-01-04 22:34:52,078 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5244658410549163, 'Total loss': 0.5244658410549163} | train loss {'Reaction outcome loss': 0.2400218991685536, 'Total loss': 0.2400218991685536}
2023-01-04 22:34:52,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:52,079 INFO:     Epoch: 38
2023-01-04 22:34:54,347 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5694162587324778, 'Total loss': 0.5694162587324778} | train loss {'Reaction outcome loss': 0.23193810384843375, 'Total loss': 0.23193810384843375}
2023-01-04 22:34:54,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:54,347 INFO:     Epoch: 39
2023-01-04 22:34:56,592 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5200767397880555, 'Total loss': 0.5200767397880555} | train loss {'Reaction outcome loss': 0.23582093489966988, 'Total loss': 0.23582093489966988}
2023-01-04 22:34:56,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:56,593 INFO:     Epoch: 40
2023-01-04 22:34:58,875 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5162324249744416, 'Total loss': 0.5162324249744416} | train loss {'Reaction outcome loss': 0.24226177233397525, 'Total loss': 0.24226177233397525}
2023-01-04 22:34:58,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:34:58,876 INFO:     Epoch: 41
2023-01-04 22:35:01,150 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5383462568124135, 'Total loss': 0.5383462568124135} | train loss {'Reaction outcome loss': 0.23313534847928055, 'Total loss': 0.23313534847928055}
2023-01-04 22:35:01,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:01,150 INFO:     Epoch: 42
2023-01-04 22:35:03,398 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5290709575017293, 'Total loss': 0.5290709575017293} | train loss {'Reaction outcome loss': 0.23135360839329797, 'Total loss': 0.23135360839329797}
2023-01-04 22:35:03,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:03,400 INFO:     Epoch: 43
2023-01-04 22:35:05,674 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.519669434428215, 'Total loss': 0.519669434428215} | train loss {'Reaction outcome loss': 0.23081718027189155, 'Total loss': 0.23081718027189155}
2023-01-04 22:35:05,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:05,675 INFO:     Epoch: 44
2023-01-04 22:35:07,905 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5088033457597096, 'Total loss': 0.5088033457597096} | train loss {'Reaction outcome loss': 0.22424761033292873, 'Total loss': 0.22424761033292873}
2023-01-04 22:35:07,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:07,905 INFO:     Epoch: 45
2023-01-04 22:35:10,180 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5358758787314097, 'Total loss': 0.5358758787314097} | train loss {'Reaction outcome loss': 0.22168168636386867, 'Total loss': 0.22168168636386867}
2023-01-04 22:35:10,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:10,181 INFO:     Epoch: 46
2023-01-04 22:35:12,446 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48960142731666567, 'Total loss': 0.48960142731666567} | train loss {'Reaction outcome loss': 0.2199212115994849, 'Total loss': 0.2199212115994849}
2023-01-04 22:35:12,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:12,447 INFO:     Epoch: 47
2023-01-04 22:35:14,553 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5393204828103383, 'Total loss': 0.5393204828103383} | train loss {'Reaction outcome loss': 0.2172077264527589, 'Total loss': 0.2172077264527589}
2023-01-04 22:35:14,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:14,553 INFO:     Epoch: 48
2023-01-04 22:35:16,413 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5285017053286235, 'Total loss': 0.5285017053286235} | train loss {'Reaction outcome loss': 0.21593150498103283, 'Total loss': 0.21593150498103283}
2023-01-04 22:35:16,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:16,414 INFO:     Epoch: 49
2023-01-04 22:35:18,296 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.520197682082653, 'Total loss': 0.520197682082653} | train loss {'Reaction outcome loss': 0.2187292374697797, 'Total loss': 0.2187292374697797}
2023-01-04 22:35:18,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:18,296 INFO:     Epoch: 50
2023-01-04 22:35:20,591 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4735483368470644, 'Total loss': 0.4735483368470644} | train loss {'Reaction outcome loss': 0.21130059321748687, 'Total loss': 0.21130059321748687}
2023-01-04 22:35:20,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:20,591 INFO:     Epoch: 51
2023-01-04 22:35:22,853 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5239596664905548, 'Total loss': 0.5239596664905548} | train loss {'Reaction outcome loss': 0.21429240882939116, 'Total loss': 0.21429240882939116}
2023-01-04 22:35:22,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:22,854 INFO:     Epoch: 52
2023-01-04 22:35:25,046 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48945464889208473, 'Total loss': 0.48945464889208473} | train loss {'Reaction outcome loss': 0.21453015011609036, 'Total loss': 0.21453015011609036}
2023-01-04 22:35:25,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:25,046 INFO:     Epoch: 53
2023-01-04 22:35:27,296 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5379678299029668, 'Total loss': 0.5379678299029668} | train loss {'Reaction outcome loss': 0.2035120229403942, 'Total loss': 0.2035120229403942}
2023-01-04 22:35:27,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:27,298 INFO:     Epoch: 54
2023-01-04 22:35:29,526 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.536161740620931, 'Total loss': 0.536161740620931} | train loss {'Reaction outcome loss': 0.2096799665468407, 'Total loss': 0.2096799665468407}
2023-01-04 22:35:29,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:29,526 INFO:     Epoch: 55
2023-01-04 22:35:31,758 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5410105049610138, 'Total loss': 0.5410105049610138} | train loss {'Reaction outcome loss': 0.2067542755498718, 'Total loss': 0.2067542755498718}
2023-01-04 22:35:31,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:31,759 INFO:     Epoch: 56
2023-01-04 22:35:34,017 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5441013713677724, 'Total loss': 0.5441013713677724} | train loss {'Reaction outcome loss': 0.20412144766636056, 'Total loss': 0.20412144766636056}
2023-01-04 22:35:34,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:34,018 INFO:     Epoch: 57
2023-01-04 22:35:36,268 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5507064451773961, 'Total loss': 0.5507064451773961} | train loss {'Reaction outcome loss': 0.20284709530872302, 'Total loss': 0.20284709530872302}
2023-01-04 22:35:36,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:36,268 INFO:     Epoch: 58
2023-01-04 22:35:38,513 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5444652775923411, 'Total loss': 0.5444652775923411} | train loss {'Reaction outcome loss': 0.1976012414263309, 'Total loss': 0.1976012414263309}
2023-01-04 22:35:38,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:38,514 INFO:     Epoch: 59
2023-01-04 22:35:40,750 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5472593088944753, 'Total loss': 0.5472593088944753} | train loss {'Reaction outcome loss': 0.19788522985610332, 'Total loss': 0.19788522985610332}
2023-01-04 22:35:40,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:40,751 INFO:     Epoch: 60
2023-01-04 22:35:42,959 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.564202269911766, 'Total loss': 0.564202269911766} | train loss {'Reaction outcome loss': 0.19535793202345844, 'Total loss': 0.19535793202345844}
2023-01-04 22:35:42,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:42,959 INFO:     Epoch: 61
2023-01-04 22:35:45,222 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5857323328653972, 'Total loss': 0.5857323328653972} | train loss {'Reaction outcome loss': 0.19916124213759825, 'Total loss': 0.19916124213759825}
2023-01-04 22:35:45,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:45,223 INFO:     Epoch: 62
2023-01-04 22:35:47,431 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5225663820902506, 'Total loss': 0.5225663820902506} | train loss {'Reaction outcome loss': 0.20159516477404715, 'Total loss': 0.20159516477404715}
2023-01-04 22:35:47,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:47,431 INFO:     Epoch: 63
2023-01-04 22:35:49,690 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5477919379870096, 'Total loss': 0.5477919379870096} | train loss {'Reaction outcome loss': 0.1943759224872231, 'Total loss': 0.1943759224872231}
2023-01-04 22:35:49,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:49,691 INFO:     Epoch: 64
2023-01-04 22:35:51,954 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5742814083894093, 'Total loss': 0.5742814083894093} | train loss {'Reaction outcome loss': 0.19034678239508399, 'Total loss': 0.19034678239508399}
2023-01-04 22:35:51,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:51,954 INFO:     Epoch: 65
2023-01-04 22:35:54,230 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5356229561070601, 'Total loss': 0.5356229561070601} | train loss {'Reaction outcome loss': 0.19085663515433068, 'Total loss': 0.19085663515433068}
2023-01-04 22:35:54,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:54,231 INFO:     Epoch: 66
2023-01-04 22:35:56,490 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5470370431741078, 'Total loss': 0.5470370431741078} | train loss {'Reaction outcome loss': 0.19270009636169388, 'Total loss': 0.19270009636169388}
2023-01-04 22:35:56,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:56,491 INFO:     Epoch: 67
2023-01-04 22:35:58,705 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5243221600850423, 'Total loss': 0.5243221600850423} | train loss {'Reaction outcome loss': 0.19452007634449245, 'Total loss': 0.19452007634449245}
2023-01-04 22:35:58,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:35:58,705 INFO:     Epoch: 68
2023-01-04 22:36:00,953 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5399044622977575, 'Total loss': 0.5399044622977575} | train loss {'Reaction outcome loss': 0.19689451358639276, 'Total loss': 0.19689451358639276}
2023-01-04 22:36:00,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:00,953 INFO:     Epoch: 69
2023-01-04 22:36:03,205 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5302244931459427, 'Total loss': 0.5302244931459427} | train loss {'Reaction outcome loss': 0.19260786193330864, 'Total loss': 0.19260786193330864}
2023-01-04 22:36:03,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:03,207 INFO:     Epoch: 70
2023-01-04 22:36:05,444 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5992852757374446, 'Total loss': 0.5992852757374446} | train loss {'Reaction outcome loss': 0.1927935153471081, 'Total loss': 0.1927935153471081}
2023-01-04 22:36:05,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:05,444 INFO:     Epoch: 71
2023-01-04 22:36:07,665 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5242607588569324, 'Total loss': 0.5242607588569324} | train loss {'Reaction outcome loss': 0.18855279740696643, 'Total loss': 0.18855279740696643}
2023-01-04 22:36:07,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:07,667 INFO:     Epoch: 72
2023-01-04 22:36:09,895 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5319799900054931, 'Total loss': 0.5319799900054931} | train loss {'Reaction outcome loss': 0.18332961360299652, 'Total loss': 0.18332961360299652}
2023-01-04 22:36:09,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:09,896 INFO:     Epoch: 73
2023-01-04 22:36:12,160 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.572093113263448, 'Total loss': 0.572093113263448} | train loss {'Reaction outcome loss': 0.18812510748854377, 'Total loss': 0.18812510748854377}
2023-01-04 22:36:12,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:12,161 INFO:     Epoch: 74
2023-01-04 22:36:14,431 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5703895092010498, 'Total loss': 0.5703895092010498} | train loss {'Reaction outcome loss': 0.1884372580281353, 'Total loss': 0.1884372580281353}
2023-01-04 22:36:14,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:14,431 INFO:     Epoch: 75
2023-01-04 22:36:16,681 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5345478594303131, 'Total loss': 0.5345478594303131} | train loss {'Reaction outcome loss': 0.1896351150308664, 'Total loss': 0.1896351150308664}
2023-01-04 22:36:16,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:16,682 INFO:     Epoch: 76
2023-01-04 22:36:18,927 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5260308623313904, 'Total loss': 0.5260308623313904} | train loss {'Reaction outcome loss': 0.18770407665616426, 'Total loss': 0.18770407665616426}
2023-01-04 22:36:18,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:18,928 INFO:     Epoch: 77
2023-01-04 22:36:21,107 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5689903597036997, 'Total loss': 0.5689903597036997} | train loss {'Reaction outcome loss': 0.18179905512233713, 'Total loss': 0.18179905512233713}
2023-01-04 22:36:21,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:21,108 INFO:     Epoch: 78
2023-01-04 22:36:23,361 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5452845732371012, 'Total loss': 0.5452845732371012} | train loss {'Reaction outcome loss': 0.1804720044149693, 'Total loss': 0.1804720044149693}
2023-01-04 22:36:23,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:23,361 INFO:     Epoch: 79
2023-01-04 22:36:25,617 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.6220032751560212, 'Total loss': 0.6220032751560212} | train loss {'Reaction outcome loss': 0.17977175653499344, 'Total loss': 0.17977175653499344}
2023-01-04 22:36:25,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:25,619 INFO:     Epoch: 80
2023-01-04 22:36:27,859 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5336594000458718, 'Total loss': 0.5336594000458718} | train loss {'Reaction outcome loss': 0.18188471907422274, 'Total loss': 0.18188471907422274}
2023-01-04 22:36:27,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:27,860 INFO:     Epoch: 81
2023-01-04 22:36:30,087 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5661182691653569, 'Total loss': 0.5661182691653569} | train loss {'Reaction outcome loss': 0.18178970206208228, 'Total loss': 0.18178970206208228}
2023-01-04 22:36:30,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:30,089 INFO:     Epoch: 82
2023-01-04 22:36:32,354 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5627639309270307, 'Total loss': 0.5627639309270307} | train loss {'Reaction outcome loss': 0.1811513089243964, 'Total loss': 0.1811513089243964}
2023-01-04 22:36:32,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:32,354 INFO:     Epoch: 83
2023-01-04 22:36:34,627 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5806285212437312, 'Total loss': 0.5806285212437312} | train loss {'Reaction outcome loss': 0.18052805968365826, 'Total loss': 0.18052805968365826}
2023-01-04 22:36:34,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:34,627 INFO:     Epoch: 84
2023-01-04 22:36:36,849 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5768031507730484, 'Total loss': 0.5768031507730484} | train loss {'Reaction outcome loss': 0.17399684459162065, 'Total loss': 0.17399684459162065}
2023-01-04 22:36:36,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:36,850 INFO:     Epoch: 85
2023-01-04 22:36:39,086 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5767485062281291, 'Total loss': 0.5767485062281291} | train loss {'Reaction outcome loss': 0.17960092531442096, 'Total loss': 0.17960092531442096}
2023-01-04 22:36:39,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:39,086 INFO:     Epoch: 86
2023-01-04 22:36:41,301 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.6027778714895249, 'Total loss': 0.6027778714895249} | train loss {'Reaction outcome loss': 0.1790434379171539, 'Total loss': 0.1790434379171539}
2023-01-04 22:36:41,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:41,302 INFO:     Epoch: 87
2023-01-04 22:36:43,550 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.532155775030454, 'Total loss': 0.532155775030454} | train loss {'Reaction outcome loss': 0.17460479624842332, 'Total loss': 0.17460479624842332}
2023-01-04 22:36:43,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:43,550 INFO:     Epoch: 88
2023-01-04 22:36:45,812 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.6025789240996043, 'Total loss': 0.6025789240996043} | train loss {'Reaction outcome loss': 0.17838070234931977, 'Total loss': 0.17838070234931977}
2023-01-04 22:36:45,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:45,812 INFO:     Epoch: 89
2023-01-04 22:36:48,063 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5653508762518565, 'Total loss': 0.5653508762518565} | train loss {'Reaction outcome loss': 0.18002851091789238, 'Total loss': 0.18002851091789238}
2023-01-04 22:36:48,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:48,064 INFO:     Epoch: 90
2023-01-04 22:36:50,299 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48858080903689066, 'Total loss': 0.48858080903689066} | train loss {'Reaction outcome loss': 0.17360129304598648, 'Total loss': 0.17360129304598648}
2023-01-04 22:36:50,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:50,299 INFO:     Epoch: 91
2023-01-04 22:36:52,503 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5451058526833852, 'Total loss': 0.5451058526833852} | train loss {'Reaction outcome loss': 0.1748539380654147, 'Total loss': 0.1748539380654147}
2023-01-04 22:36:52,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:52,503 INFO:     Epoch: 92
2023-01-04 22:36:54,731 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5731044630209605, 'Total loss': 0.5731044630209605} | train loss {'Reaction outcome loss': 0.1768652279997729, 'Total loss': 0.1768652279997729}
2023-01-04 22:36:54,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:54,732 INFO:     Epoch: 93
2023-01-04 22:36:57,005 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.6016575316588084, 'Total loss': 0.6016575316588084} | train loss {'Reaction outcome loss': 0.17867979406628198, 'Total loss': 0.17867979406628198}
2023-01-04 22:36:57,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:57,006 INFO:     Epoch: 94
2023-01-04 22:36:59,252 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5460058470567067, 'Total loss': 0.5460058470567067} | train loss {'Reaction outcome loss': 0.1755202131383394, 'Total loss': 0.1755202131383394}
2023-01-04 22:36:59,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:36:59,252 INFO:     Epoch: 95
2023-01-04 22:37:01,458 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5185296297073364, 'Total loss': 0.5185296297073364} | train loss {'Reaction outcome loss': 0.1754366214022095, 'Total loss': 0.1754366214022095}
2023-01-04 22:37:01,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:01,459 INFO:     Epoch: 96
2023-01-04 22:37:03,645 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.6035824778179327, 'Total loss': 0.6035824778179327} | train loss {'Reaction outcome loss': 0.17213769423717382, 'Total loss': 0.17213769423717382}
2023-01-04 22:37:03,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:03,645 INFO:     Epoch: 97
2023-01-04 22:37:05,880 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5614265153805414, 'Total loss': 0.5614265153805414} | train loss {'Reaction outcome loss': 0.16847468006949967, 'Total loss': 0.16847468006949967}
2023-01-04 22:37:05,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:05,881 INFO:     Epoch: 98
2023-01-04 22:37:08,142 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5561547031005224, 'Total loss': 0.5561547031005224} | train loss {'Reaction outcome loss': 0.17019689824745987, 'Total loss': 0.17019689824745987}
2023-01-04 22:37:08,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:08,142 INFO:     Epoch: 99
2023-01-04 22:37:10,406 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5551819741725922, 'Total loss': 0.5551819741725922} | train loss {'Reaction outcome loss': 0.17097646308271386, 'Total loss': 0.17097646308271386}
2023-01-04 22:37:10,406 INFO:     Best model found after epoch 14 of 100.
2023-01-04 22:37:10,406 INFO:   Done with stage: TRAINING
2023-01-04 22:37:10,406 INFO:   Starting stage: EVALUATION
2023-01-04 22:37:10,555 INFO:   Done with stage: EVALUATION
2023-01-04 22:37:10,555 INFO:   Leaving out SEQ value Fold_4
2023-01-04 22:37:10,568 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 22:37:10,568 INFO:   Starting stage: FEATURE SCALING
2023-01-04 22:37:11,221 INFO:   Done with stage: FEATURE SCALING
2023-01-04 22:37:11,221 INFO:   Starting stage: SCALING TARGETS
2023-01-04 22:37:11,292 INFO:   Done with stage: SCALING TARGETS
2023-01-04 22:37:11,292 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:37:11,292 INFO:     No hyperparam tuning for this model
2023-01-04 22:37:11,292 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:37:11,292 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 22:37:11,293 INFO:     None feature selector for col prot
2023-01-04 22:37:11,293 INFO:     None feature selector for col prot
2023-01-04 22:37:11,293 INFO:     None feature selector for col prot
2023-01-04 22:37:11,294 INFO:     None feature selector for col chem
2023-01-04 22:37:11,294 INFO:     None feature selector for col chem
2023-01-04 22:37:11,294 INFO:     None feature selector for col chem
2023-01-04 22:37:11,294 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 22:37:11,294 INFO:   Starting stage: BUILD MODEL
2023-01-04 22:37:11,295 INFO:     Number of params in model 72931
2023-01-04 22:37:11,298 INFO:   Done with stage: BUILD MODEL
2023-01-04 22:37:11,299 INFO:   Starting stage: TRAINING
2023-01-04 22:37:11,358 INFO:     Val loss before train {'Reaction outcome loss': 0.9904931386311849, 'Total loss': 0.9904931386311849}
2023-01-04 22:37:11,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:11,358 INFO:     Epoch: 0
2023-01-04 22:37:13,616 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8188941200574239, 'Total loss': 0.8188941200574239} | train loss {'Reaction outcome loss': 0.9417127103266054, 'Total loss': 0.9417127103266054}
2023-01-04 22:37:13,617 INFO:     Found new best model at epoch 0
2023-01-04 22:37:13,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:13,619 INFO:     Epoch: 1
2023-01-04 22:37:15,914 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6060939888159435, 'Total loss': 0.6060939888159435} | train loss {'Reaction outcome loss': 0.6445313751915075, 'Total loss': 0.6445313751915075}
2023-01-04 22:37:15,914 INFO:     Found new best model at epoch 1
2023-01-04 22:37:15,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:15,915 INFO:     Epoch: 2
2023-01-04 22:37:18,244 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5626472453276317, 'Total loss': 0.5626472453276317} | train loss {'Reaction outcome loss': 0.5439920745191783, 'Total loss': 0.5439920745191783}
2023-01-04 22:37:18,245 INFO:     Found new best model at epoch 2
2023-01-04 22:37:18,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:18,247 INFO:     Epoch: 3
2023-01-04 22:37:20,503 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5581470668315888, 'Total loss': 0.5581470668315888} | train loss {'Reaction outcome loss': 0.49793745789432176, 'Total loss': 0.49793745789432176}
2023-01-04 22:37:20,503 INFO:     Found new best model at epoch 3
2023-01-04 22:37:20,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:20,504 INFO:     Epoch: 4
2023-01-04 22:37:22,763 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5416884998480479, 'Total loss': 0.5416884998480479} | train loss {'Reaction outcome loss': 0.467240288935221, 'Total loss': 0.467240288935221}
2023-01-04 22:37:22,764 INFO:     Found new best model at epoch 4
2023-01-04 22:37:22,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:22,765 INFO:     Epoch: 5
2023-01-04 22:37:25,007 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.51607293287913, 'Total loss': 0.51607293287913} | train loss {'Reaction outcome loss': 0.4443258195299737, 'Total loss': 0.4443258195299737}
2023-01-04 22:37:25,008 INFO:     Found new best model at epoch 5
2023-01-04 22:37:25,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:25,009 INFO:     Epoch: 6
2023-01-04 22:37:27,035 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.507181407014529, 'Total loss': 0.507181407014529} | train loss {'Reaction outcome loss': 0.4269471699847792, 'Total loss': 0.4269471699847792}
2023-01-04 22:37:27,035 INFO:     Found new best model at epoch 6
2023-01-04 22:37:27,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:27,037 INFO:     Epoch: 7
2023-01-04 22:37:29,300 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5484987477461497, 'Total loss': 0.5484987477461497} | train loss {'Reaction outcome loss': 0.41041914332848395, 'Total loss': 0.41041914332848395}
2023-01-04 22:37:29,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:29,302 INFO:     Epoch: 8
2023-01-04 22:37:31,563 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5214313308397929, 'Total loss': 0.5214313308397929} | train loss {'Reaction outcome loss': 0.4026735536482212, 'Total loss': 0.4026735536482212}
2023-01-04 22:37:31,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:31,564 INFO:     Epoch: 9
2023-01-04 22:37:33,800 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5361324608325958, 'Total loss': 0.5361324608325958} | train loss {'Reaction outcome loss': 0.38538120102382056, 'Total loss': 0.38538120102382056}
2023-01-04 22:37:33,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:33,801 INFO:     Epoch: 10
2023-01-04 22:37:36,041 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5218150476614635, 'Total loss': 0.5218150476614635} | train loss {'Reaction outcome loss': 0.373622197005218, 'Total loss': 0.373622197005218}
2023-01-04 22:37:36,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:36,042 INFO:     Epoch: 11
2023-01-04 22:37:38,295 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5151919553677241, 'Total loss': 0.5151919553677241} | train loss {'Reaction outcome loss': 0.36155929188006114, 'Total loss': 0.36155929188006114}
2023-01-04 22:37:38,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:38,296 INFO:     Epoch: 12
2023-01-04 22:37:40,545 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5072562019030253, 'Total loss': 0.5072562019030253} | train loss {'Reaction outcome loss': 0.349943583844787, 'Total loss': 0.349943583844787}
2023-01-04 22:37:40,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:40,546 INFO:     Epoch: 13
2023-01-04 22:37:42,800 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49847351213296254, 'Total loss': 0.49847351213296254} | train loss {'Reaction outcome loss': 0.3499455378275283, 'Total loss': 0.3499455378275283}
2023-01-04 22:37:42,800 INFO:     Found new best model at epoch 13
2023-01-04 22:37:42,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:42,801 INFO:     Epoch: 14
2023-01-04 22:37:45,064 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5024916132291158, 'Total loss': 0.5024916132291158} | train loss {'Reaction outcome loss': 0.339445323268645, 'Total loss': 0.339445323268645}
2023-01-04 22:37:45,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:45,064 INFO:     Epoch: 15
2023-01-04 22:37:47,320 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5025467505057652, 'Total loss': 0.5025467505057652} | train loss {'Reaction outcome loss': 0.3298815446531903, 'Total loss': 0.3298815446531903}
2023-01-04 22:37:47,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:47,321 INFO:     Epoch: 16
2023-01-04 22:37:49,552 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5008368353048961, 'Total loss': 0.5008368353048961} | train loss {'Reaction outcome loss': 0.32458943335244256, 'Total loss': 0.32458943335244256}
2023-01-04 22:37:49,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:49,553 INFO:     Epoch: 17
2023-01-04 22:37:51,800 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4833568960428238, 'Total loss': 0.4833568960428238} | train loss {'Reaction outcome loss': 0.3135448966352065, 'Total loss': 0.3135448966352065}
2023-01-04 22:37:51,800 INFO:     Found new best model at epoch 17
2023-01-04 22:37:51,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:51,802 INFO:     Epoch: 18
2023-01-04 22:37:54,060 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49574687878290813, 'Total loss': 0.49574687878290813} | train loss {'Reaction outcome loss': 0.3078306726431542, 'Total loss': 0.3078306726431542}
2023-01-04 22:37:54,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:54,062 INFO:     Epoch: 19
2023-01-04 22:37:56,332 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5155067483584086, 'Total loss': 0.5155067483584086} | train loss {'Reaction outcome loss': 0.30312003181689845, 'Total loss': 0.30312003181689845}
2023-01-04 22:37:56,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:56,332 INFO:     Epoch: 20
2023-01-04 22:37:58,595 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48799849152565, 'Total loss': 0.48799849152565} | train loss {'Reaction outcome loss': 0.29755171484918924, 'Total loss': 0.29755171484918924}
2023-01-04 22:37:58,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:37:58,597 INFO:     Epoch: 21
2023-01-04 22:38:00,845 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5253074675798416, 'Total loss': 0.5253074675798416} | train loss {'Reaction outcome loss': 0.2941264967794401, 'Total loss': 0.2941264967794401}
2023-01-04 22:38:00,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:00,845 INFO:     Epoch: 22
2023-01-04 22:38:03,085 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5018631368875504, 'Total loss': 0.5018631368875504} | train loss {'Reaction outcome loss': 0.286821948915013, 'Total loss': 0.286821948915013}
2023-01-04 22:38:03,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:03,086 INFO:     Epoch: 23
2023-01-04 22:38:05,354 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4973619023958842, 'Total loss': 0.4973619023958842} | train loss {'Reaction outcome loss': 0.2839434901864207, 'Total loss': 0.2839434901864207}
2023-01-04 22:38:05,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:05,355 INFO:     Epoch: 24
2023-01-04 22:38:07,605 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4956272562344869, 'Total loss': 0.4956272562344869} | train loss {'Reaction outcome loss': 0.27770633096160896, 'Total loss': 0.27770633096160896}
2023-01-04 22:38:07,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:07,605 INFO:     Epoch: 25
2023-01-04 22:38:09,858 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4782351781924566, 'Total loss': 0.4782351781924566} | train loss {'Reaction outcome loss': 0.2746246021213758, 'Total loss': 0.2746246021213758}
2023-01-04 22:38:09,859 INFO:     Found new best model at epoch 25
2023-01-04 22:38:09,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:09,860 INFO:     Epoch: 26
2023-01-04 22:38:12,118 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49576258659362793, 'Total loss': 0.49576258659362793} | train loss {'Reaction outcome loss': 0.26961542124839594, 'Total loss': 0.26961542124839594}
2023-01-04 22:38:12,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:12,120 INFO:     Epoch: 27
2023-01-04 22:38:14,365 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.50937879383564, 'Total loss': 0.50937879383564} | train loss {'Reaction outcome loss': 0.26656956789865544, 'Total loss': 0.26656956789865544}
2023-01-04 22:38:14,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:14,366 INFO:     Epoch: 28
2023-01-04 22:38:16,620 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5169906814893087, 'Total loss': 0.5169906814893087} | train loss {'Reaction outcome loss': 0.2598832802860624, 'Total loss': 0.2598832802860624}
2023-01-04 22:38:16,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:16,621 INFO:     Epoch: 29
2023-01-04 22:38:18,872 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4972079207499822, 'Total loss': 0.4972079207499822} | train loss {'Reaction outcome loss': 0.2592780673808425, 'Total loss': 0.2592780673808425}
2023-01-04 22:38:18,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:18,872 INFO:     Epoch: 30
2023-01-04 22:38:21,139 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.49730637272198996, 'Total loss': 0.49730637272198996} | train loss {'Reaction outcome loss': 0.25294836626870787, 'Total loss': 0.25294836626870787}
2023-01-04 22:38:21,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:21,139 INFO:     Epoch: 31
2023-01-04 22:38:23,389 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47616138371328515, 'Total loss': 0.47616138371328515} | train loss {'Reaction outcome loss': 0.2479228636209112, 'Total loss': 0.2479228636209112}
2023-01-04 22:38:23,390 INFO:     Found new best model at epoch 31
2023-01-04 22:38:23,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:23,392 INFO:     Epoch: 32
2023-01-04 22:38:25,654 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5036185264587403, 'Total loss': 0.5036185264587403} | train loss {'Reaction outcome loss': 0.24689065605184457, 'Total loss': 0.24689065605184457}
2023-01-04 22:38:25,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:25,655 INFO:     Epoch: 33
2023-01-04 22:38:27,900 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49296991030375165, 'Total loss': 0.49296991030375165} | train loss {'Reaction outcome loss': 0.2459617339509682, 'Total loss': 0.2459617339509682}
2023-01-04 22:38:27,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:27,901 INFO:     Epoch: 34
2023-01-04 22:38:30,168 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.522014339764913, 'Total loss': 0.522014339764913} | train loss {'Reaction outcome loss': 0.24065771995343432, 'Total loss': 0.24065771995343432}
2023-01-04 22:38:30,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:30,168 INFO:     Epoch: 35
2023-01-04 22:38:32,430 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4892964760462443, 'Total loss': 0.4892964760462443} | train loss {'Reaction outcome loss': 0.2373575299475206, 'Total loss': 0.2373575299475206}
2023-01-04 22:38:32,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:32,431 INFO:     Epoch: 36
2023-01-04 22:38:34,684 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4964168131351471, 'Total loss': 0.4964168131351471} | train loss {'Reaction outcome loss': 0.23627200396051698, 'Total loss': 0.23627200396051698}
2023-01-04 22:38:34,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:34,686 INFO:     Epoch: 37
2023-01-04 22:38:36,940 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4978861262400945, 'Total loss': 0.4978861262400945} | train loss {'Reaction outcome loss': 0.232331321452384, 'Total loss': 0.232331321452384}
2023-01-04 22:38:36,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:36,940 INFO:     Epoch: 38
2023-01-04 22:38:39,175 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5029826581478118, 'Total loss': 0.5029826581478118} | train loss {'Reaction outcome loss': 0.2273508040132477, 'Total loss': 0.2273508040132477}
2023-01-04 22:38:39,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:39,175 INFO:     Epoch: 39
2023-01-04 22:38:41,433 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4912986526886622, 'Total loss': 0.4912986526886622} | train loss {'Reaction outcome loss': 0.22724599491152234, 'Total loss': 0.22724599491152234}
2023-01-04 22:38:41,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:41,434 INFO:     Epoch: 40
2023-01-04 22:38:43,696 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.515648822983106, 'Total loss': 0.515648822983106} | train loss {'Reaction outcome loss': 0.22659937713811867, 'Total loss': 0.22659937713811867}
2023-01-04 22:38:43,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:43,696 INFO:     Epoch: 41
2023-01-04 22:38:45,960 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5061710814634959, 'Total loss': 0.5061710814634959} | train loss {'Reaction outcome loss': 0.2267598572431853, 'Total loss': 0.2267598572431853}
2023-01-04 22:38:45,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:45,961 INFO:     Epoch: 42
2023-01-04 22:38:48,196 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5018780728181204, 'Total loss': 0.5018780728181204} | train loss {'Reaction outcome loss': 0.22420801213487004, 'Total loss': 0.22420801213487004}
2023-01-04 22:38:48,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:48,197 INFO:     Epoch: 43
2023-01-04 22:38:50,436 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5027558883031209, 'Total loss': 0.5027558883031209} | train loss {'Reaction outcome loss': 0.21881982782026277, 'Total loss': 0.21881982782026277}
2023-01-04 22:38:50,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:50,436 INFO:     Epoch: 44
2023-01-04 22:38:52,655 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5326447685559591, 'Total loss': 0.5326447685559591} | train loss {'Reaction outcome loss': 0.21931045308681954, 'Total loss': 0.21931045308681954}
2023-01-04 22:38:52,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:52,656 INFO:     Epoch: 45
2023-01-04 22:38:54,920 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5236572782198589, 'Total loss': 0.5236572782198589} | train loss {'Reaction outcome loss': 0.21768015752254177, 'Total loss': 0.21768015752254177}
2023-01-04 22:38:54,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:54,921 INFO:     Epoch: 46
2023-01-04 22:38:57,193 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5167679240306219, 'Total loss': 0.5167679240306219} | train loss {'Reaction outcome loss': 0.2158681150070344, 'Total loss': 0.2158681150070344}
2023-01-04 22:38:57,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:57,193 INFO:     Epoch: 47
2023-01-04 22:38:59,454 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.527411871155103, 'Total loss': 0.527411871155103} | train loss {'Reaction outcome loss': 0.21434527866025693, 'Total loss': 0.21434527866025693}
2023-01-04 22:38:59,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:38:59,455 INFO:     Epoch: 48
2023-01-04 22:39:01,680 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5229371805985769, 'Total loss': 0.5229371805985769} | train loss {'Reaction outcome loss': 0.21222336611023893, 'Total loss': 0.21222336611023893}
2023-01-04 22:39:01,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:01,680 INFO:     Epoch: 49
2023-01-04 22:39:03,934 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5023071229457855, 'Total loss': 0.5023071229457855} | train loss {'Reaction outcome loss': 0.20913885904299298, 'Total loss': 0.20913885904299298}
2023-01-04 22:39:03,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:03,936 INFO:     Epoch: 50
2023-01-04 22:39:06,155 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5237649033466975, 'Total loss': 0.5237649033466975} | train loss {'Reaction outcome loss': 0.21079776556414626, 'Total loss': 0.21079776556414626}
2023-01-04 22:39:06,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:06,156 INFO:     Epoch: 51
2023-01-04 22:39:08,408 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49523160656293236, 'Total loss': 0.49523160656293236} | train loss {'Reaction outcome loss': 0.21003994232138795, 'Total loss': 0.21003994232138795}
2023-01-04 22:39:08,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:08,408 INFO:     Epoch: 52
2023-01-04 22:39:10,654 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5451080799102783, 'Total loss': 0.5451080799102783} | train loss {'Reaction outcome loss': 0.20780277989437654, 'Total loss': 0.20780277989437654}
2023-01-04 22:39:10,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:10,655 INFO:     Epoch: 53
2023-01-04 22:39:12,907 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4945558849722147, 'Total loss': 0.4945558849722147} | train loss {'Reaction outcome loss': 0.20394628290358904, 'Total loss': 0.20394628290358904}
2023-01-04 22:39:12,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:12,907 INFO:     Epoch: 54
2023-01-04 22:39:15,171 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49356014231840767, 'Total loss': 0.49356014231840767} | train loss {'Reaction outcome loss': 0.20196441990615677, 'Total loss': 0.20196441990615677}
2023-01-04 22:39:15,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:15,172 INFO:     Epoch: 55
2023-01-04 22:39:17,439 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5125435034434, 'Total loss': 0.5125435034434} | train loss {'Reaction outcome loss': 0.20370801916876197, 'Total loss': 0.20370801916876197}
2023-01-04 22:39:17,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:17,440 INFO:     Epoch: 56
2023-01-04 22:39:19,705 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5214598586161932, 'Total loss': 0.5214598586161932} | train loss {'Reaction outcome loss': 0.19870067267155234, 'Total loss': 0.19870067267155234}
2023-01-04 22:39:19,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:19,706 INFO:     Epoch: 57
2023-01-04 22:39:21,894 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4946437617142995, 'Total loss': 0.4946437617142995} | train loss {'Reaction outcome loss': 0.1957433625076809, 'Total loss': 0.1957433625076809}
2023-01-04 22:39:21,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:21,895 INFO:     Epoch: 58
2023-01-04 22:39:24,170 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.506666412949562, 'Total loss': 0.506666412949562} | train loss {'Reaction outcome loss': 0.19845192326253186, 'Total loss': 0.19845192326253186}
2023-01-04 22:39:24,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:24,171 INFO:     Epoch: 59
2023-01-04 22:39:26,425 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5017824590206146, 'Total loss': 0.5017824590206146} | train loss {'Reaction outcome loss': 0.1975452111503721, 'Total loss': 0.1975452111503721}
2023-01-04 22:39:26,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:26,426 INFO:     Epoch: 60
2023-01-04 22:39:28,695 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5131387208898862, 'Total loss': 0.5131387208898862} | train loss {'Reaction outcome loss': 0.19810850361198948, 'Total loss': 0.19810850361198948}
2023-01-04 22:39:28,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:28,695 INFO:     Epoch: 61
2023-01-04 22:39:30,964 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5124669204155604, 'Total loss': 0.5124669204155604} | train loss {'Reaction outcome loss': 0.19949582136188546, 'Total loss': 0.19949582136188546}
2023-01-04 22:39:30,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:30,964 INFO:     Epoch: 62
2023-01-04 22:39:33,225 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5102471900482972, 'Total loss': 0.5102471900482972} | train loss {'Reaction outcome loss': 0.1884212988789064, 'Total loss': 0.1884212988789064}
2023-01-04 22:39:33,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:33,226 INFO:     Epoch: 63
2023-01-04 22:39:35,481 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5197590271631877, 'Total loss': 0.5197590271631877} | train loss {'Reaction outcome loss': 0.1957865535403962, 'Total loss': 0.1957865535403962}
2023-01-04 22:39:35,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:35,481 INFO:     Epoch: 64
2023-01-04 22:39:37,735 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5380948603153228, 'Total loss': 0.5380948603153228} | train loss {'Reaction outcome loss': 0.18802327921029424, 'Total loss': 0.18802327921029424}
2023-01-04 22:39:37,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:37,737 INFO:     Epoch: 65
2023-01-04 22:39:40,012 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5059460550546646, 'Total loss': 0.5059460550546646} | train loss {'Reaction outcome loss': 0.19320752027437743, 'Total loss': 0.19320752027437743}
2023-01-04 22:39:40,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:40,013 INFO:     Epoch: 66
2023-01-04 22:39:42,302 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4795376472796003, 'Total loss': 0.4795376472796003} | train loss {'Reaction outcome loss': 0.18593139833954236, 'Total loss': 0.18593139833954236}
2023-01-04 22:39:42,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:42,302 INFO:     Epoch: 67
2023-01-04 22:39:44,570 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5216610034306844, 'Total loss': 0.5216610034306844} | train loss {'Reaction outcome loss': 0.18430436521523844, 'Total loss': 0.18430436521523844}
2023-01-04 22:39:44,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:44,571 INFO:     Epoch: 68
2023-01-04 22:39:46,866 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5064023658633232, 'Total loss': 0.5064023658633232} | train loss {'Reaction outcome loss': 0.18365733325141517, 'Total loss': 0.18365733325141517}
2023-01-04 22:39:46,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:46,866 INFO:     Epoch: 69
2023-01-04 22:39:49,138 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.492276257276535, 'Total loss': 0.492276257276535} | train loss {'Reaction outcome loss': 0.1846041888267101, 'Total loss': 0.1846041888267101}
2023-01-04 22:39:49,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:49,138 INFO:     Epoch: 70
2023-01-04 22:39:51,416 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.510315990447998, 'Total loss': 0.510315990447998} | train loss {'Reaction outcome loss': 0.18514951220611586, 'Total loss': 0.18514951220611586}
2023-01-04 22:39:51,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:51,417 INFO:     Epoch: 71
2023-01-04 22:39:53,700 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5493080014983813, 'Total loss': 0.5493080014983813} | train loss {'Reaction outcome loss': 0.1823321361108309, 'Total loss': 0.1823321361108309}
2023-01-04 22:39:53,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:53,701 INFO:     Epoch: 72
2023-01-04 22:39:55,982 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5243766963481903, 'Total loss': 0.5243766963481903} | train loss {'Reaction outcome loss': 0.18253951457356285, 'Total loss': 0.18253951457356285}
2023-01-04 22:39:55,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:55,983 INFO:     Epoch: 73
2023-01-04 22:39:58,239 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4901786302526792, 'Total loss': 0.4901786302526792} | train loss {'Reaction outcome loss': 0.18415075512670906, 'Total loss': 0.18415075512670906}
2023-01-04 22:39:58,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:39:58,239 INFO:     Epoch: 74
2023-01-04 22:40:00,486 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5149972667296727, 'Total loss': 0.5149972667296727} | train loss {'Reaction outcome loss': 0.1860201830574631, 'Total loss': 0.1860201830574631}
2023-01-04 22:40:00,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:00,487 INFO:     Epoch: 75
2023-01-04 22:40:02,736 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5261713782946269, 'Total loss': 0.5261713782946269} | train loss {'Reaction outcome loss': 0.18390689413301156, 'Total loss': 0.18390689413301156}
2023-01-04 22:40:02,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:02,737 INFO:     Epoch: 76
2023-01-04 22:40:04,964 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5047792911529541, 'Total loss': 0.5047792911529541} | train loss {'Reaction outcome loss': 0.17432187698495977, 'Total loss': 0.17432187698495977}
2023-01-04 22:40:04,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:04,964 INFO:     Epoch: 77
2023-01-04 22:40:07,164 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47633046507835386, 'Total loss': 0.47633046507835386} | train loss {'Reaction outcome loss': 0.1794061437657062, 'Total loss': 0.1794061437657062}
2023-01-04 22:40:07,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:07,165 INFO:     Epoch: 78
2023-01-04 22:40:09,409 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5097582439581553, 'Total loss': 0.5097582439581553} | train loss {'Reaction outcome loss': 0.1781264283374822, 'Total loss': 0.1781264283374822}
2023-01-04 22:40:09,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:09,410 INFO:     Epoch: 79
2023-01-04 22:40:11,632 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48925443391005197, 'Total loss': 0.48925443391005197} | train loss {'Reaction outcome loss': 0.17435523781612733, 'Total loss': 0.17435523781612733}
2023-01-04 22:40:11,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:11,632 INFO:     Epoch: 80
2023-01-04 22:40:13,874 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5343135714530944, 'Total loss': 0.5343135714530944} | train loss {'Reaction outcome loss': 0.1745786461078419, 'Total loss': 0.1745786461078419}
2023-01-04 22:40:13,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:13,875 INFO:     Epoch: 81
2023-01-04 22:40:16,122 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5072866201400756, 'Total loss': 0.5072866201400756} | train loss {'Reaction outcome loss': 0.1754165367039777, 'Total loss': 0.1754165367039777}
2023-01-04 22:40:16,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:16,122 INFO:     Epoch: 82
2023-01-04 22:40:18,384 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5273295670747757, 'Total loss': 0.5273295670747757} | train loss {'Reaction outcome loss': 0.17837837303438, 'Total loss': 0.17837837303438}
2023-01-04 22:40:18,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:18,385 INFO:     Epoch: 83
2023-01-04 22:40:20,627 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48965292690942686, 'Total loss': 0.48965292690942686} | train loss {'Reaction outcome loss': 0.17329515936532922, 'Total loss': 0.17329515936532922}
2023-01-04 22:40:20,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:20,628 INFO:     Epoch: 84
2023-01-04 22:40:22,902 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5574155191580454, 'Total loss': 0.5574155191580454} | train loss {'Reaction outcome loss': 0.17262356776241078, 'Total loss': 0.17262356776241078}
2023-01-04 22:40:22,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:22,903 INFO:     Epoch: 85
2023-01-04 22:40:25,159 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5281596827010314, 'Total loss': 0.5281596827010314} | train loss {'Reaction outcome loss': 0.17277443985094446, 'Total loss': 0.17277443985094446}
2023-01-04 22:40:25,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:25,159 INFO:     Epoch: 86
2023-01-04 22:40:27,440 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4978707426848511, 'Total loss': 0.4978707426848511} | train loss {'Reaction outcome loss': 0.17284038064178814, 'Total loss': 0.17284038064178814}
2023-01-04 22:40:27,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:27,441 INFO:     Epoch: 87
2023-01-04 22:40:29,719 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5398842612902324, 'Total loss': 0.5398842612902324} | train loss {'Reaction outcome loss': 0.16969047247833252, 'Total loss': 0.16969047247833252}
2023-01-04 22:40:29,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:29,719 INFO:     Epoch: 88
2023-01-04 22:40:31,970 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5185209929943084, 'Total loss': 0.5185209929943084} | train loss {'Reaction outcome loss': 0.17159075993894987, 'Total loss': 0.17159075993894987}
2023-01-04 22:40:31,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:31,971 INFO:     Epoch: 89
2023-01-04 22:40:34,245 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5206185758113862, 'Total loss': 0.5206185758113862} | train loss {'Reaction outcome loss': 0.17132900614141874, 'Total loss': 0.17132900614141874}
2023-01-04 22:40:34,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:34,246 INFO:     Epoch: 90
2023-01-04 22:40:36,498 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5264836649099985, 'Total loss': 0.5264836649099985} | train loss {'Reaction outcome loss': 0.16967987189626824, 'Total loss': 0.16967987189626824}
2023-01-04 22:40:36,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:36,498 INFO:     Epoch: 91
2023-01-04 22:40:38,763 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4969178234227002, 'Total loss': 0.4969178234227002} | train loss {'Reaction outcome loss': 0.16812205759053847, 'Total loss': 0.16812205759053847}
2023-01-04 22:40:38,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:38,764 INFO:     Epoch: 92
2023-01-04 22:40:41,011 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.518747192621231, 'Total loss': 0.518747192621231} | train loss {'Reaction outcome loss': 0.1665943851065652, 'Total loss': 0.1665943851065652}
2023-01-04 22:40:41,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:41,011 INFO:     Epoch: 93
2023-01-04 22:40:43,288 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5244568169116974, 'Total loss': 0.5244568169116974} | train loss {'Reaction outcome loss': 0.16888746699950502, 'Total loss': 0.16888746699950502}
2023-01-04 22:40:43,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:43,289 INFO:     Epoch: 94
2023-01-04 22:40:45,539 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5166575079783797, 'Total loss': 0.5166575079783797} | train loss {'Reaction outcome loss': 0.16617884508327302, 'Total loss': 0.16617884508327302}
2023-01-04 22:40:45,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:45,539 INFO:     Epoch: 95
2023-01-04 22:40:47,781 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4943762595454852, 'Total loss': 0.4943762595454852} | train loss {'Reaction outcome loss': 0.16486461402807576, 'Total loss': 0.16486461402807576}
2023-01-04 22:40:47,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:47,781 INFO:     Epoch: 96
2023-01-04 22:40:50,034 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.546705295642217, 'Total loss': 0.546705295642217} | train loss {'Reaction outcome loss': 0.16630287084517742, 'Total loss': 0.16630287084517742}
2023-01-04 22:40:50,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:50,035 INFO:     Epoch: 97
2023-01-04 22:40:52,310 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5082681030035019, 'Total loss': 0.5082681030035019} | train loss {'Reaction outcome loss': 0.1673188167726145, 'Total loss': 0.1673188167726145}
2023-01-04 22:40:52,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:52,310 INFO:     Epoch: 98
2023-01-04 22:40:54,559 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5323603252569834, 'Total loss': 0.5323603252569834} | train loss {'Reaction outcome loss': 0.16526640331828082, 'Total loss': 0.16526640331828082}
2023-01-04 22:40:54,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:54,559 INFO:     Epoch: 99
2023-01-04 22:40:56,803 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5491771082083384, 'Total loss': 0.5491771082083384} | train loss {'Reaction outcome loss': 0.16753100415514985, 'Total loss': 0.16753100415514985}
2023-01-04 22:40:56,804 INFO:     Best model found after epoch 32 of 100.
2023-01-04 22:40:56,805 INFO:   Done with stage: TRAINING
2023-01-04 22:40:56,805 INFO:   Starting stage: EVALUATION
2023-01-04 22:40:56,947 INFO:   Done with stage: EVALUATION
2023-01-04 22:40:56,947 INFO:   Leaving out SEQ value Fold_5
2023-01-04 22:40:56,960 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 22:40:56,960 INFO:   Starting stage: FEATURE SCALING
2023-01-04 22:40:57,619 INFO:   Done with stage: FEATURE SCALING
2023-01-04 22:40:57,619 INFO:   Starting stage: SCALING TARGETS
2023-01-04 22:40:57,690 INFO:   Done with stage: SCALING TARGETS
2023-01-04 22:40:57,690 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:40:57,690 INFO:     No hyperparam tuning for this model
2023-01-04 22:40:57,690 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:40:57,690 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 22:40:57,691 INFO:     None feature selector for col prot
2023-01-04 22:40:57,691 INFO:     None feature selector for col prot
2023-01-04 22:40:57,691 INFO:     None feature selector for col prot
2023-01-04 22:40:57,692 INFO:     None feature selector for col chem
2023-01-04 22:40:57,692 INFO:     None feature selector for col chem
2023-01-04 22:40:57,692 INFO:     None feature selector for col chem
2023-01-04 22:40:57,692 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 22:40:57,692 INFO:   Starting stage: BUILD MODEL
2023-01-04 22:40:57,694 INFO:     Number of params in model 72931
2023-01-04 22:40:57,697 INFO:   Done with stage: BUILD MODEL
2023-01-04 22:40:57,697 INFO:   Starting stage: TRAINING
2023-01-04 22:40:57,757 INFO:     Val loss before train {'Reaction outcome loss': 1.061040492852529, 'Total loss': 1.061040492852529}
2023-01-04 22:40:57,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:40:57,757 INFO:     Epoch: 0
2023-01-04 22:41:00,024 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.801259970664978, 'Total loss': 0.801259970664978} | train loss {'Reaction outcome loss': 0.9269514250150626, 'Total loss': 0.9269514250150626}
2023-01-04 22:41:00,024 INFO:     Found new best model at epoch 0
2023-01-04 22:41:00,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:00,025 INFO:     Epoch: 1
2023-01-04 22:41:02,322 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6432112514972687, 'Total loss': 0.6432112514972687} | train loss {'Reaction outcome loss': 0.6391884827601683, 'Total loss': 0.6391884827601683}
2023-01-04 22:41:02,323 INFO:     Found new best model at epoch 1
2023-01-04 22:41:02,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:02,325 INFO:     Epoch: 2
2023-01-04 22:41:04,603 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5881578842798869, 'Total loss': 0.5881578842798869} | train loss {'Reaction outcome loss': 0.5445414296877773, 'Total loss': 0.5445414296877773}
2023-01-04 22:41:04,603 INFO:     Found new best model at epoch 2
2023-01-04 22:41:04,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:04,605 INFO:     Epoch: 3
2023-01-04 22:41:06,886 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5554676314194997, 'Total loss': 0.5554676314194997} | train loss {'Reaction outcome loss': 0.5074389180087525, 'Total loss': 0.5074389180087525}
2023-01-04 22:41:06,887 INFO:     Found new best model at epoch 3
2023-01-04 22:41:06,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:06,888 INFO:     Epoch: 4
2023-01-04 22:41:09,186 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5535228848457336, 'Total loss': 0.5535228848457336} | train loss {'Reaction outcome loss': 0.4842635914261547, 'Total loss': 0.4842635914261547}
2023-01-04 22:41:09,187 INFO:     Found new best model at epoch 4
2023-01-04 22:41:09,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:09,188 INFO:     Epoch: 5
2023-01-04 22:41:11,456 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5145454108715057, 'Total loss': 0.5145454108715057} | train loss {'Reaction outcome loss': 0.4594341028832655, 'Total loss': 0.4594341028832655}
2023-01-04 22:41:11,456 INFO:     Found new best model at epoch 5
2023-01-04 22:41:11,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:11,457 INFO:     Epoch: 6
2023-01-04 22:41:13,749 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4969277262687683, 'Total loss': 0.4969277262687683} | train loss {'Reaction outcome loss': 0.436829173236839, 'Total loss': 0.436829173236839}
2023-01-04 22:41:13,750 INFO:     Found new best model at epoch 6
2023-01-04 22:41:13,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:13,751 INFO:     Epoch: 7
2023-01-04 22:41:16,038 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4794050375620524, 'Total loss': 0.4794050375620524} | train loss {'Reaction outcome loss': 0.4229406443107333, 'Total loss': 0.4229406443107333}
2023-01-04 22:41:16,038 INFO:     Found new best model at epoch 7
2023-01-04 22:41:16,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:16,039 INFO:     Epoch: 8
2023-01-04 22:41:18,294 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4703386505444845, 'Total loss': 0.4703386505444845} | train loss {'Reaction outcome loss': 0.40337162305587443, 'Total loss': 0.40337162305587443}
2023-01-04 22:41:18,295 INFO:     Found new best model at epoch 8
2023-01-04 22:41:18,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:18,296 INFO:     Epoch: 9
2023-01-04 22:41:20,534 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46827908953030906, 'Total loss': 0.46827908953030906} | train loss {'Reaction outcome loss': 0.3948896806585886, 'Total loss': 0.3948896806585886}
2023-01-04 22:41:20,534 INFO:     Found new best model at epoch 9
2023-01-04 22:41:20,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:20,536 INFO:     Epoch: 10
2023-01-04 22:41:22,784 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45286055505275724, 'Total loss': 0.45286055505275724} | train loss {'Reaction outcome loss': 0.37923269141195476, 'Total loss': 0.37923269141195476}
2023-01-04 22:41:22,784 INFO:     Found new best model at epoch 10
2023-01-04 22:41:22,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:22,785 INFO:     Epoch: 11
2023-01-04 22:41:25,036 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4564178228378296, 'Total loss': 0.4564178228378296} | train loss {'Reaction outcome loss': 0.3673843092544922, 'Total loss': 0.3673843092544922}
2023-01-04 22:41:25,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:25,037 INFO:     Epoch: 12
2023-01-04 22:41:27,303 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4486174136400223, 'Total loss': 0.4486174136400223} | train loss {'Reaction outcome loss': 0.3568568761050077, 'Total loss': 0.3568568761050077}
2023-01-04 22:41:27,303 INFO:     Found new best model at epoch 12
2023-01-04 22:41:27,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:27,305 INFO:     Epoch: 13
2023-01-04 22:41:29,544 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4397066255410512, 'Total loss': 0.4397066255410512} | train loss {'Reaction outcome loss': 0.3457012892012363, 'Total loss': 0.3457012892012363}
2023-01-04 22:41:29,544 INFO:     Found new best model at epoch 13
2023-01-04 22:41:29,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:29,546 INFO:     Epoch: 14
2023-01-04 22:41:31,805 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4531709223985672, 'Total loss': 0.4531709223985672} | train loss {'Reaction outcome loss': 0.3377668199709792, 'Total loss': 0.3377668199709792}
2023-01-04 22:41:31,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:31,806 INFO:     Epoch: 15
2023-01-04 22:41:34,039 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4138205240170161, 'Total loss': 0.4138205240170161} | train loss {'Reaction outcome loss': 0.32236287886194803, 'Total loss': 0.32236287886194803}
2023-01-04 22:41:34,039 INFO:     Found new best model at epoch 15
2023-01-04 22:41:34,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:34,041 INFO:     Epoch: 16
2023-01-04 22:41:36,293 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4263311455647151, 'Total loss': 0.4263311455647151} | train loss {'Reaction outcome loss': 0.3212044344619389, 'Total loss': 0.3212044344619389}
2023-01-04 22:41:36,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:36,294 INFO:     Epoch: 17
2023-01-04 22:41:38,371 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45281221767266594, 'Total loss': 0.45281221767266594} | train loss {'Reaction outcome loss': 0.3081583412408097, 'Total loss': 0.3081583412408097}
2023-01-04 22:41:38,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:38,371 INFO:     Epoch: 18
2023-01-04 22:41:40,615 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4390294949213664, 'Total loss': 0.4390294949213664} | train loss {'Reaction outcome loss': 0.30371875854705094, 'Total loss': 0.30371875854705094}
2023-01-04 22:41:40,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:40,615 INFO:     Epoch: 19
2023-01-04 22:41:42,821 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44079967637856804, 'Total loss': 0.44079967637856804} | train loss {'Reaction outcome loss': 0.2952159454804903, 'Total loss': 0.2952159454804903}
2023-01-04 22:41:42,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:42,823 INFO:     Epoch: 20
2023-01-04 22:41:45,078 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.419096103310585, 'Total loss': 0.419096103310585} | train loss {'Reaction outcome loss': 0.2889165434914859, 'Total loss': 0.2889165434914859}
2023-01-04 22:41:45,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:45,078 INFO:     Epoch: 21
2023-01-04 22:41:47,409 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41713274319966637, 'Total loss': 0.41713274319966637} | train loss {'Reaction outcome loss': 0.2809089924524322, 'Total loss': 0.2809089924524322}
2023-01-04 22:41:47,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:47,409 INFO:     Epoch: 22
2023-01-04 22:41:49,730 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40965431903799376, 'Total loss': 0.40965431903799376} | train loss {'Reaction outcome loss': 0.27877979664375796, 'Total loss': 0.27877979664375796}
2023-01-04 22:41:49,731 INFO:     Found new best model at epoch 22
2023-01-04 22:41:49,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:49,733 INFO:     Epoch: 23
2023-01-04 22:41:51,992 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4197324057420095, 'Total loss': 0.4197324057420095} | train loss {'Reaction outcome loss': 0.2716506700093885, 'Total loss': 0.2716506700093885}
2023-01-04 22:41:51,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:51,992 INFO:     Epoch: 24
2023-01-04 22:41:54,207 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4446684444944064, 'Total loss': 0.4446684444944064} | train loss {'Reaction outcome loss': 0.27528140908512083, 'Total loss': 0.27528140908512083}
2023-01-04 22:41:54,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:54,209 INFO:     Epoch: 25
2023-01-04 22:41:56,440 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41323200513919195, 'Total loss': 0.41323200513919195} | train loss {'Reaction outcome loss': 0.28339204362867126, 'Total loss': 0.28339204362867126}
2023-01-04 22:41:56,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:56,440 INFO:     Epoch: 26
2023-01-04 22:41:58,773 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41826959550380705, 'Total loss': 0.41826959550380705} | train loss {'Reaction outcome loss': 0.2592848584768101, 'Total loss': 0.2592848584768101}
2023-01-04 22:41:58,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:41:58,773 INFO:     Epoch: 27
2023-01-04 22:42:01,132 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4314325342575709, 'Total loss': 0.4314325342575709} | train loss {'Reaction outcome loss': 0.2509724881602924, 'Total loss': 0.2509724881602924}
2023-01-04 22:42:01,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:01,134 INFO:     Epoch: 28
2023-01-04 22:42:03,490 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42629293402036034, 'Total loss': 0.42629293402036034} | train loss {'Reaction outcome loss': 0.24709643883363533, 'Total loss': 0.24709643883363533}
2023-01-04 22:42:03,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:03,490 INFO:     Epoch: 29
2023-01-04 22:42:05,763 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4334723169604937, 'Total loss': 0.4334723169604937} | train loss {'Reaction outcome loss': 0.24876886014181512, 'Total loss': 0.24876886014181512}
2023-01-04 22:42:05,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:05,764 INFO:     Epoch: 30
2023-01-04 22:42:08,031 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4174417912960052, 'Total loss': 0.4174417912960052} | train loss {'Reaction outcome loss': 0.24294363475148228, 'Total loss': 0.24294363475148228}
2023-01-04 22:42:08,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:08,038 INFO:     Epoch: 31
2023-01-04 22:42:10,305 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42742102046807606, 'Total loss': 0.42742102046807606} | train loss {'Reaction outcome loss': 0.2399857943418665, 'Total loss': 0.2399857943418665}
2023-01-04 22:42:10,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:10,305 INFO:     Epoch: 32
2023-01-04 22:42:12,594 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4427352577447891, 'Total loss': 0.4427352577447891} | train loss {'Reaction outcome loss': 0.2360445237752266, 'Total loss': 0.2360445237752266}
2023-01-04 22:42:12,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:12,595 INFO:     Epoch: 33
2023-01-04 22:42:14,872 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4330408225456874, 'Total loss': 0.4330408225456874} | train loss {'Reaction outcome loss': 0.23551394363386097, 'Total loss': 0.23551394363386097}
2023-01-04 22:42:14,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:14,872 INFO:     Epoch: 34
2023-01-04 22:42:17,129 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42897223234176635, 'Total loss': 0.42897223234176635} | train loss {'Reaction outcome loss': 0.23397275083360897, 'Total loss': 0.23397275083360897}
2023-01-04 22:42:17,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:17,131 INFO:     Epoch: 35
2023-01-04 22:42:19,420 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4450050264596939, 'Total loss': 0.4450050264596939} | train loss {'Reaction outcome loss': 0.22892769339157076, 'Total loss': 0.22892769339157076}
2023-01-04 22:42:19,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:19,420 INFO:     Epoch: 36
2023-01-04 22:42:21,706 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4308716023961703, 'Total loss': 0.4308716023961703} | train loss {'Reaction outcome loss': 0.22192702303067746, 'Total loss': 0.22192702303067746}
2023-01-04 22:42:21,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:21,707 INFO:     Epoch: 37
2023-01-04 22:42:23,997 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4297826508680979, 'Total loss': 0.4297826508680979} | train loss {'Reaction outcome loss': 0.22423242793930526, 'Total loss': 0.22423242793930526}
2023-01-04 22:42:23,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:23,998 INFO:     Epoch: 38
2023-01-04 22:42:26,276 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4048975040515264, 'Total loss': 0.4048975040515264} | train loss {'Reaction outcome loss': 0.22127871568536517, 'Total loss': 0.22127871568536517}
2023-01-04 22:42:26,277 INFO:     Found new best model at epoch 38
2023-01-04 22:42:26,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:26,278 INFO:     Epoch: 39
2023-01-04 22:42:28,526 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44219851394494375, 'Total loss': 0.44219851394494375} | train loss {'Reaction outcome loss': 0.22362756821920798, 'Total loss': 0.22362756821920798}
2023-01-04 22:42:28,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:28,527 INFO:     Epoch: 40
2023-01-04 22:42:30,800 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42169763644536334, 'Total loss': 0.42169763644536334} | train loss {'Reaction outcome loss': 0.2332643359305634, 'Total loss': 0.2332643359305634}
2023-01-04 22:42:30,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:30,801 INFO:     Epoch: 41
2023-01-04 22:42:33,046 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43703856964906057, 'Total loss': 0.43703856964906057} | train loss {'Reaction outcome loss': 0.21516355907690435, 'Total loss': 0.21516355907690435}
2023-01-04 22:42:33,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:33,047 INFO:     Epoch: 42
2023-01-04 22:42:35,331 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4330484728018443, 'Total loss': 0.4330484728018443} | train loss {'Reaction outcome loss': 0.21307700250780318, 'Total loss': 0.21307700250780318}
2023-01-04 22:42:35,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:35,332 INFO:     Epoch: 43
2023-01-04 22:42:37,611 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4416502207517624, 'Total loss': 0.4416502207517624} | train loss {'Reaction outcome loss': 0.21136083514726994, 'Total loss': 0.21136083514726994}
2023-01-04 22:42:37,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:37,612 INFO:     Epoch: 44
2023-01-04 22:42:39,833 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4419826289017995, 'Total loss': 0.4419826289017995} | train loss {'Reaction outcome loss': 0.20803448037527825, 'Total loss': 0.20803448037527825}
2023-01-04 22:42:39,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:39,833 INFO:     Epoch: 45
2023-01-04 22:42:42,113 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4112604861458143, 'Total loss': 0.4112604861458143} | train loss {'Reaction outcome loss': 0.21149943372153718, 'Total loss': 0.21149943372153718}
2023-01-04 22:42:42,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:42,114 INFO:     Epoch: 46
2023-01-04 22:42:44,378 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4134503165880839, 'Total loss': 0.4134503165880839} | train loss {'Reaction outcome loss': 0.20363386254588925, 'Total loss': 0.20363386254588925}
2023-01-04 22:42:44,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:44,378 INFO:     Epoch: 47
2023-01-04 22:42:46,607 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4300474683443705, 'Total loss': 0.4300474683443705} | train loss {'Reaction outcome loss': 0.2056459933789312, 'Total loss': 0.2056459933789312}
2023-01-04 22:42:46,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:46,608 INFO:     Epoch: 48
2023-01-04 22:42:48,870 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4029218020538489, 'Total loss': 0.4029218020538489} | train loss {'Reaction outcome loss': 0.22526898077668864, 'Total loss': 0.22526898077668864}
2023-01-04 22:42:48,870 INFO:     Found new best model at epoch 48
2023-01-04 22:42:48,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:48,871 INFO:     Epoch: 49
2023-01-04 22:42:51,086 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4214678724606832, 'Total loss': 0.4214678724606832} | train loss {'Reaction outcome loss': 0.2033543142206063, 'Total loss': 0.2033543142206063}
2023-01-04 22:42:51,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:51,086 INFO:     Epoch: 50
2023-01-04 22:42:53,375 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43108640710512797, 'Total loss': 0.43108640710512797} | train loss {'Reaction outcome loss': 0.20192539718245034, 'Total loss': 0.20192539718245034}
2023-01-04 22:42:53,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:53,377 INFO:     Epoch: 51
2023-01-04 22:42:55,648 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40360630849997203, 'Total loss': 0.40360630849997203} | train loss {'Reaction outcome loss': 0.19587133110136443, 'Total loss': 0.19587133110136443}
2023-01-04 22:42:55,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:55,649 INFO:     Epoch: 52
2023-01-04 22:42:57,905 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41404953797658284, 'Total loss': 0.41404953797658284} | train loss {'Reaction outcome loss': 0.20041200577532806, 'Total loss': 0.20041200577532806}
2023-01-04 22:42:57,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:42:57,906 INFO:     Epoch: 53
2023-01-04 22:43:00,194 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41985907753308616, 'Total loss': 0.41985907753308616} | train loss {'Reaction outcome loss': 0.19575431465130785, 'Total loss': 0.19575431465130785}
2023-01-04 22:43:00,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:00,194 INFO:     Epoch: 54
2023-01-04 22:43:02,438 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.425996736685435, 'Total loss': 0.425996736685435} | train loss {'Reaction outcome loss': 0.19145719876742343, 'Total loss': 0.19145719876742343}
2023-01-04 22:43:02,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:02,438 INFO:     Epoch: 55
2023-01-04 22:43:04,712 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4531291355689367, 'Total loss': 0.4531291355689367} | train loss {'Reaction outcome loss': 0.19478009214904835, 'Total loss': 0.19478009214904835}
2023-01-04 22:43:04,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:04,714 INFO:     Epoch: 56
2023-01-04 22:43:06,985 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4292539358139038, 'Total loss': 0.4292539358139038} | train loss {'Reaction outcome loss': 0.1959556743023458, 'Total loss': 0.1959556743023458}
2023-01-04 22:43:06,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:06,986 INFO:     Epoch: 57
2023-01-04 22:43:09,262 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4060428738594055, 'Total loss': 0.4060428738594055} | train loss {'Reaction outcome loss': 0.1934822843025398, 'Total loss': 0.1934822843025398}
2023-01-04 22:43:09,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:09,263 INFO:     Epoch: 58
2023-01-04 22:43:11,568 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41843350132306417, 'Total loss': 0.41843350132306417} | train loss {'Reaction outcome loss': 0.1864908671561642, 'Total loss': 0.1864908671561642}
2023-01-04 22:43:11,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:11,569 INFO:     Epoch: 59
2023-01-04 22:43:13,855 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4156112054983775, 'Total loss': 0.4156112054983775} | train loss {'Reaction outcome loss': 0.1903962502561837, 'Total loss': 0.1903962502561837}
2023-01-04 22:43:13,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:13,855 INFO:     Epoch: 60
2023-01-04 22:43:16,146 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4288164019584656, 'Total loss': 0.4288164019584656} | train loss {'Reaction outcome loss': 0.1897776140046873, 'Total loss': 0.1897776140046873}
2023-01-04 22:43:16,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:16,147 INFO:     Epoch: 61
2023-01-04 22:43:18,445 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44984895884990694, 'Total loss': 0.44984895884990694} | train loss {'Reaction outcome loss': 0.19016022087400442, 'Total loss': 0.19016022087400442}
2023-01-04 22:43:18,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:18,446 INFO:     Epoch: 62
2023-01-04 22:43:20,698 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39814473092556, 'Total loss': 0.39814473092556} | train loss {'Reaction outcome loss': 0.18876969695017012, 'Total loss': 0.18876969695017012}
2023-01-04 22:43:20,698 INFO:     Found new best model at epoch 62
2023-01-04 22:43:20,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:20,699 INFO:     Epoch: 63
2023-01-04 22:43:23,002 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4301634778579076, 'Total loss': 0.4301634778579076} | train loss {'Reaction outcome loss': 0.18677491852903969, 'Total loss': 0.18677491852903969}
2023-01-04 22:43:23,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:23,003 INFO:     Epoch: 64
2023-01-04 22:43:25,274 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40759106998642286, 'Total loss': 0.40759106998642286} | train loss {'Reaction outcome loss': 0.18715205930335366, 'Total loss': 0.18715205930335366}
2023-01-04 22:43:25,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:25,275 INFO:     Epoch: 65
2023-01-04 22:43:27,545 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4174665649731954, 'Total loss': 0.4174665649731954} | train loss {'Reaction outcome loss': 0.18932610891921364, 'Total loss': 0.18932610891921364}
2023-01-04 22:43:27,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:27,547 INFO:     Epoch: 66
2023-01-04 22:43:29,820 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4435496573646863, 'Total loss': 0.4435496573646863} | train loss {'Reaction outcome loss': 0.20105423572902614, 'Total loss': 0.20105423572902614}
2023-01-04 22:43:29,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:29,820 INFO:     Epoch: 67
2023-01-04 22:43:32,075 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45546331306298576, 'Total loss': 0.45546331306298576} | train loss {'Reaction outcome loss': 0.19116987749821154, 'Total loss': 0.19116987749821154}
2023-01-04 22:43:32,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:32,075 INFO:     Epoch: 68
2023-01-04 22:43:34,319 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4241586446762085, 'Total loss': 0.4241586446762085} | train loss {'Reaction outcome loss': 0.18569198680705046, 'Total loss': 0.18569198680705046}
2023-01-04 22:43:34,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:34,320 INFO:     Epoch: 69
2023-01-04 22:43:36,547 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43565105299154916, 'Total loss': 0.43565105299154916} | train loss {'Reaction outcome loss': 0.18463277125635574, 'Total loss': 0.18463277125635574}
2023-01-04 22:43:36,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:36,548 INFO:     Epoch: 70
2023-01-04 22:43:38,776 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40635376820961633, 'Total loss': 0.40635376820961633} | train loss {'Reaction outcome loss': 0.1812285596953597, 'Total loss': 0.1812285596953597}
2023-01-04 22:43:38,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:38,777 INFO:     Epoch: 71
2023-01-04 22:43:41,030 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4316750486691793, 'Total loss': 0.4316750486691793} | train loss {'Reaction outcome loss': 0.1837243277552551, 'Total loss': 0.1837243277552551}
2023-01-04 22:43:41,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:41,031 INFO:     Epoch: 72
2023-01-04 22:43:43,280 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4343573272228241, 'Total loss': 0.4343573272228241} | train loss {'Reaction outcome loss': 0.17740122051707105, 'Total loss': 0.17740122051707105}
2023-01-04 22:43:43,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:43,281 INFO:     Epoch: 73
2023-01-04 22:43:45,559 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4369753450155258, 'Total loss': 0.4369753450155258} | train loss {'Reaction outcome loss': 0.17882002205621667, 'Total loss': 0.17882002205621667}
2023-01-04 22:43:45,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:45,560 INFO:     Epoch: 74
2023-01-04 22:43:47,847 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4002772609392802, 'Total loss': 0.4002772609392802} | train loss {'Reaction outcome loss': 0.1794826862608096, 'Total loss': 0.1794826862608096}
2023-01-04 22:43:47,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:47,847 INFO:     Epoch: 75
2023-01-04 22:43:50,118 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44361679752667743, 'Total loss': 0.44361679752667743} | train loss {'Reaction outcome loss': 0.17656375899948046, 'Total loss': 0.17656375899948046}
2023-01-04 22:43:50,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:50,119 INFO:     Epoch: 76
2023-01-04 22:43:52,385 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41335411816835405, 'Total loss': 0.41335411816835405} | train loss {'Reaction outcome loss': 0.17823381932659843, 'Total loss': 0.17823381932659843}
2023-01-04 22:43:52,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:52,386 INFO:     Epoch: 77
2023-01-04 22:43:54,629 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40468624780575435, 'Total loss': 0.40468624780575435} | train loss {'Reaction outcome loss': 0.17298455939269025, 'Total loss': 0.17298455939269025}
2023-01-04 22:43:54,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:54,629 INFO:     Epoch: 78
2023-01-04 22:43:56,910 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39717665712038674, 'Total loss': 0.39717665712038674} | train loss {'Reaction outcome loss': 0.17682496383043844, 'Total loss': 0.17682496383043844}
2023-01-04 22:43:56,911 INFO:     Found new best model at epoch 78
2023-01-04 22:43:56,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:56,912 INFO:     Epoch: 79
2023-01-04 22:43:59,184 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41842041835188865, 'Total loss': 0.41842041835188865} | train loss {'Reaction outcome loss': 0.17675096604954518, 'Total loss': 0.17675096604954518}
2023-01-04 22:43:59,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:43:59,184 INFO:     Epoch: 80
2023-01-04 22:44:01,457 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41650223632653555, 'Total loss': 0.41650223632653555} | train loss {'Reaction outcome loss': 0.17389618643231358, 'Total loss': 0.17389618643231358}
2023-01-04 22:44:01,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:01,457 INFO:     Epoch: 81
2023-01-04 22:44:03,742 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4069436659415563, 'Total loss': 0.4069436659415563} | train loss {'Reaction outcome loss': 0.17436535304425005, 'Total loss': 0.17436535304425005}
2023-01-04 22:44:03,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:03,744 INFO:     Epoch: 82
2023-01-04 22:44:06,019 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4422047356764475, 'Total loss': 0.4422047356764475} | train loss {'Reaction outcome loss': 0.17460210541553417, 'Total loss': 0.17460210541553417}
2023-01-04 22:44:06,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:06,019 INFO:     Epoch: 83
2023-01-04 22:44:08,337 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4189892973440389, 'Total loss': 0.4189892973440389} | train loss {'Reaction outcome loss': 0.17039071816522494, 'Total loss': 0.17039071816522494}
2023-01-04 22:44:08,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:08,339 INFO:     Epoch: 84
2023-01-04 22:44:10,572 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4462153842051824, 'Total loss': 0.4462153842051824} | train loss {'Reaction outcome loss': 0.17096892622472967, 'Total loss': 0.17096892622472967}
2023-01-04 22:44:10,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:10,572 INFO:     Epoch: 85
2023-01-04 22:44:12,695 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42435929278532664, 'Total loss': 0.42435929278532664} | train loss {'Reaction outcome loss': 0.16980819568414227, 'Total loss': 0.16980819568414227}
2023-01-04 22:44:12,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:12,696 INFO:     Epoch: 86
2023-01-04 22:44:14,546 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4042659908533096, 'Total loss': 0.4042659908533096} | train loss {'Reaction outcome loss': 0.16854008729395623, 'Total loss': 0.16854008729395623}
2023-01-04 22:44:14,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:14,548 INFO:     Epoch: 87
2023-01-04 22:44:16,481 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4217006196578344, 'Total loss': 0.4217006196578344} | train loss {'Reaction outcome loss': 0.1673973416234704, 'Total loss': 0.1673973416234704}
2023-01-04 22:44:16,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:16,481 INFO:     Epoch: 88
2023-01-04 22:44:18,659 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43318544526894887, 'Total loss': 0.43318544526894887} | train loss {'Reaction outcome loss': 0.16596557655155766, 'Total loss': 0.16596557655155766}
2023-01-04 22:44:18,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:18,659 INFO:     Epoch: 89
2023-01-04 22:44:20,936 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39599125379075606, 'Total loss': 0.39599125379075606} | train loss {'Reaction outcome loss': 0.1684815787374501, 'Total loss': 0.1684815787374501}
2023-01-04 22:44:20,937 INFO:     Found new best model at epoch 89
2023-01-04 22:44:20,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:20,939 INFO:     Epoch: 90
2023-01-04 22:44:23,220 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44586658080418906, 'Total loss': 0.44586658080418906} | train loss {'Reaction outcome loss': 0.16868871927969545, 'Total loss': 0.16868871927969545}
2023-01-04 22:44:23,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:23,220 INFO:     Epoch: 91
2023-01-04 22:44:25,500 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40670072436332705, 'Total loss': 0.40670072436332705} | train loss {'Reaction outcome loss': 0.17991345361941427, 'Total loss': 0.17991345361941427}
2023-01-04 22:44:25,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:25,502 INFO:     Epoch: 92
2023-01-04 22:44:27,774 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45163416862487793, 'Total loss': 0.45163416862487793} | train loss {'Reaction outcome loss': 0.18126790346940508, 'Total loss': 0.18126790346940508}
2023-01-04 22:44:27,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:27,774 INFO:     Epoch: 93
2023-01-04 22:44:30,005 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4462306688229243, 'Total loss': 0.4462306688229243} | train loss {'Reaction outcome loss': 0.1704994492973036, 'Total loss': 0.1704994492973036}
2023-01-04 22:44:30,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:30,005 INFO:     Epoch: 94
2023-01-04 22:44:32,279 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4186205923557281, 'Total loss': 0.4186205923557281} | train loss {'Reaction outcome loss': 0.16496333856122108, 'Total loss': 0.16496333856122108}
2023-01-04 22:44:32,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:32,280 INFO:     Epoch: 95
2023-01-04 22:44:34,569 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42940183778603874, 'Total loss': 0.42940183778603874} | train loss {'Reaction outcome loss': 0.16293843272665137, 'Total loss': 0.16293843272665137}
2023-01-04 22:44:34,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:34,570 INFO:     Epoch: 96
2023-01-04 22:44:36,852 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41880797942479453, 'Total loss': 0.41880797942479453} | train loss {'Reaction outcome loss': 0.18318675630692177, 'Total loss': 0.18318675630692177}
2023-01-04 22:44:36,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:36,852 INFO:     Epoch: 97
2023-01-04 22:44:39,112 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4313405786951383, 'Total loss': 0.4313405786951383} | train loss {'Reaction outcome loss': 0.18285708834984057, 'Total loss': 0.18285708834984057}
2023-01-04 22:44:39,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:39,113 INFO:     Epoch: 98
2023-01-04 22:44:41,369 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41923549175262453, 'Total loss': 0.41923549175262453} | train loss {'Reaction outcome loss': 0.16813316156470176, 'Total loss': 0.16813316156470176}
2023-01-04 22:44:41,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:41,369 INFO:     Epoch: 99
2023-01-04 22:44:43,647 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4237746953964233, 'Total loss': 0.4237746953964233} | train loss {'Reaction outcome loss': 0.15913061800655787, 'Total loss': 0.15913061800655787}
2023-01-04 22:44:43,648 INFO:     Best model found after epoch 90 of 100.
2023-01-04 22:44:43,648 INFO:   Done with stage: TRAINING
2023-01-04 22:44:43,648 INFO:   Starting stage: EVALUATION
2023-01-04 22:44:43,785 INFO:   Done with stage: EVALUATION
2023-01-04 22:44:43,785 INFO:   Leaving out SEQ value Fold_6
2023-01-04 22:44:43,798 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 22:44:43,798 INFO:   Starting stage: FEATURE SCALING
2023-01-04 22:44:44,658 INFO:   Done with stage: FEATURE SCALING
2023-01-04 22:44:44,658 INFO:   Starting stage: SCALING TARGETS
2023-01-04 22:44:44,729 INFO:   Done with stage: SCALING TARGETS
2023-01-04 22:44:44,729 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:44:44,729 INFO:     No hyperparam tuning for this model
2023-01-04 22:44:44,729 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:44:44,729 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 22:44:44,730 INFO:     None feature selector for col prot
2023-01-04 22:44:44,730 INFO:     None feature selector for col prot
2023-01-04 22:44:44,730 INFO:     None feature selector for col prot
2023-01-04 22:44:44,731 INFO:     None feature selector for col chem
2023-01-04 22:44:44,731 INFO:     None feature selector for col chem
2023-01-04 22:44:44,731 INFO:     None feature selector for col chem
2023-01-04 22:44:44,731 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 22:44:44,731 INFO:   Starting stage: BUILD MODEL
2023-01-04 22:44:44,732 INFO:     Number of params in model 72931
2023-01-04 22:44:44,736 INFO:   Done with stage: BUILD MODEL
2023-01-04 22:44:44,736 INFO:   Starting stage: TRAINING
2023-01-04 22:44:44,797 INFO:     Val loss before train {'Reaction outcome loss': 1.0742747068405152, 'Total loss': 1.0742747068405152}
2023-01-04 22:44:44,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:44,797 INFO:     Epoch: 0
2023-01-04 22:44:47,073 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7423048575719198, 'Total loss': 0.7423048575719198} | train loss {'Reaction outcome loss': 0.9106578302942889, 'Total loss': 0.9106578302942889}
2023-01-04 22:44:47,073 INFO:     Found new best model at epoch 0
2023-01-04 22:44:47,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:47,074 INFO:     Epoch: 1
2023-01-04 22:44:49,345 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6145150105158488, 'Total loss': 0.6145150105158488} | train loss {'Reaction outcome loss': 0.5971862710608903, 'Total loss': 0.5971862710608903}
2023-01-04 22:44:49,346 INFO:     Found new best model at epoch 1
2023-01-04 22:44:49,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:49,348 INFO:     Epoch: 2
2023-01-04 22:44:51,609 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5745407164096832, 'Total loss': 0.5745407164096832} | train loss {'Reaction outcome loss': 0.5151765531043283, 'Total loss': 0.5151765531043283}
2023-01-04 22:44:51,609 INFO:     Found new best model at epoch 2
2023-01-04 22:44:51,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:51,610 INFO:     Epoch: 3
2023-01-04 22:44:53,864 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5573809226353963, 'Total loss': 0.5573809226353963} | train loss {'Reaction outcome loss': 0.4736891509393492, 'Total loss': 0.4736891509393492}
2023-01-04 22:44:53,865 INFO:     Found new best model at epoch 3
2023-01-04 22:44:53,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:53,866 INFO:     Epoch: 4
2023-01-04 22:44:56,149 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5442244946956635, 'Total loss': 0.5442244946956635} | train loss {'Reaction outcome loss': 0.45162431745107423, 'Total loss': 0.45162431745107423}
2023-01-04 22:44:56,149 INFO:     Found new best model at epoch 4
2023-01-04 22:44:56,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:56,151 INFO:     Epoch: 5
2023-01-04 22:44:58,404 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5287974198659261, 'Total loss': 0.5287974198659261} | train loss {'Reaction outcome loss': 0.4309491384976177, 'Total loss': 0.4309491384976177}
2023-01-04 22:44:58,404 INFO:     Found new best model at epoch 5
2023-01-04 22:44:58,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:44:58,405 INFO:     Epoch: 6
2023-01-04 22:45:00,677 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.522882251938184, 'Total loss': 0.522882251938184} | train loss {'Reaction outcome loss': 0.41513146183013055, 'Total loss': 0.41513146183013055}
2023-01-04 22:45:00,678 INFO:     Found new best model at epoch 6
2023-01-04 22:45:00,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:00,679 INFO:     Epoch: 7
2023-01-04 22:45:02,949 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5267716869711876, 'Total loss': 0.5267716869711876} | train loss {'Reaction outcome loss': 0.3955810587005925, 'Total loss': 0.3955810587005925}
2023-01-04 22:45:02,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:02,949 INFO:     Epoch: 8
2023-01-04 22:45:05,209 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5156335075696309, 'Total loss': 0.5156335075696309} | train loss {'Reaction outcome loss': 0.3879737041702339, 'Total loss': 0.3879737041702339}
2023-01-04 22:45:05,210 INFO:     Found new best model at epoch 8
2023-01-04 22:45:05,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:05,211 INFO:     Epoch: 9
2023-01-04 22:45:07,495 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5278112719456355, 'Total loss': 0.5278112719456355} | train loss {'Reaction outcome loss': 0.3765484346648416, 'Total loss': 0.3765484346648416}
2023-01-04 22:45:07,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:07,495 INFO:     Epoch: 10
2023-01-04 22:45:09,779 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.51995041569074, 'Total loss': 0.51995041569074} | train loss {'Reaction outcome loss': 0.3639502538509317, 'Total loss': 0.3639502538509317}
2023-01-04 22:45:09,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:09,780 INFO:     Epoch: 11
2023-01-04 22:45:12,057 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5303840061028798, 'Total loss': 0.5303840061028798} | train loss {'Reaction outcome loss': 0.3560250952893646, 'Total loss': 0.3560250952893646}
2023-01-04 22:45:12,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:12,058 INFO:     Epoch: 12
2023-01-04 22:45:14,316 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5434487919012706, 'Total loss': 0.5434487919012706} | train loss {'Reaction outcome loss': 0.344125077908435, 'Total loss': 0.344125077908435}
2023-01-04 22:45:14,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:14,317 INFO:     Epoch: 13
2023-01-04 22:45:16,633 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5329368511835734, 'Total loss': 0.5329368511835734} | train loss {'Reaction outcome loss': 0.3376187163300893, 'Total loss': 0.3376187163300893}
2023-01-04 22:45:16,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:16,634 INFO:     Epoch: 14
2023-01-04 22:45:18,956 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5369359831015269, 'Total loss': 0.5369359831015269} | train loss {'Reaction outcome loss': 0.33112321339466944, 'Total loss': 0.33112321339466944}
2023-01-04 22:45:18,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:18,957 INFO:     Epoch: 15
2023-01-04 22:45:21,299 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5120666136344274, 'Total loss': 0.5120666136344274} | train loss {'Reaction outcome loss': 0.32209203031842026, 'Total loss': 0.32209203031842026}
2023-01-04 22:45:21,299 INFO:     Found new best model at epoch 15
2023-01-04 22:45:21,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:21,300 INFO:     Epoch: 16
2023-01-04 22:45:23,641 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5417871097723643, 'Total loss': 0.5417871097723643} | train loss {'Reaction outcome loss': 0.31298120058938483, 'Total loss': 0.31298120058938483}
2023-01-04 22:45:23,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:23,642 INFO:     Epoch: 17
2023-01-04 22:45:25,972 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5421178221702576, 'Total loss': 0.5421178221702576} | train loss {'Reaction outcome loss': 0.30377050737988215, 'Total loss': 0.30377050737988215}
2023-01-04 22:45:25,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:25,973 INFO:     Epoch: 18
2023-01-04 22:45:28,292 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5572103023529053, 'Total loss': 0.5572103023529053} | train loss {'Reaction outcome loss': 0.2978633173240436, 'Total loss': 0.2978633173240436}
2023-01-04 22:45:28,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:28,294 INFO:     Epoch: 19
2023-01-04 22:45:30,588 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5333965683976809, 'Total loss': 0.5333965683976809} | train loss {'Reaction outcome loss': 0.2917691077028371, 'Total loss': 0.2917691077028371}
2023-01-04 22:45:30,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:30,588 INFO:     Epoch: 20
2023-01-04 22:45:32,883 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5533024668693542, 'Total loss': 0.5533024668693542} | train loss {'Reaction outcome loss': 0.2838851595398321, 'Total loss': 0.2838851595398321}
2023-01-04 22:45:32,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:32,884 INFO:     Epoch: 21
2023-01-04 22:45:35,164 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5448363701502482, 'Total loss': 0.5448363701502482} | train loss {'Reaction outcome loss': 0.2784293085968774, 'Total loss': 0.2784293085968774}
2023-01-04 22:45:35,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:35,164 INFO:     Epoch: 22
2023-01-04 22:45:37,430 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.539190740386645, 'Total loss': 0.539190740386645} | train loss {'Reaction outcome loss': 0.27498863692587033, 'Total loss': 0.27498863692587033}
2023-01-04 22:45:37,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:37,431 INFO:     Epoch: 23
2023-01-04 22:45:39,702 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5449613531430563, 'Total loss': 0.5449613531430563} | train loss {'Reaction outcome loss': 0.2641539913787093, 'Total loss': 0.2641539913787093}
2023-01-04 22:45:39,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:39,704 INFO:     Epoch: 24
2023-01-04 22:45:42,002 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5368525547906756, 'Total loss': 0.5368525547906756} | train loss {'Reaction outcome loss': 0.2640890735420079, 'Total loss': 0.2640890735420079}
2023-01-04 22:45:42,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:42,002 INFO:     Epoch: 25
2023-01-04 22:45:44,287 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5320586482683818, 'Total loss': 0.5320586482683818} | train loss {'Reaction outcome loss': 0.260802198873853, 'Total loss': 0.260802198873853}
2023-01-04 22:45:44,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:44,287 INFO:     Epoch: 26
2023-01-04 22:45:46,588 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5462408026059469, 'Total loss': 0.5462408026059469} | train loss {'Reaction outcome loss': 0.25442217559375485, 'Total loss': 0.25442217559375485}
2023-01-04 22:45:46,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:46,590 INFO:     Epoch: 27
2023-01-04 22:45:48,678 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5347523192564646, 'Total loss': 0.5347523192564646} | train loss {'Reaction outcome loss': 0.25214931724545975, 'Total loss': 0.25214931724545975}
2023-01-04 22:45:48,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:48,678 INFO:     Epoch: 28
2023-01-04 22:45:50,942 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5225429544846217, 'Total loss': 0.5225429544846217} | train loss {'Reaction outcome loss': 0.24775073408327378, 'Total loss': 0.24775073408327378}
2023-01-04 22:45:50,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:50,942 INFO:     Epoch: 29
2023-01-04 22:45:53,222 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5215831955273946, 'Total loss': 0.5215831955273946} | train loss {'Reaction outcome loss': 0.24551753517549607, 'Total loss': 0.24551753517549607}
2023-01-04 22:45:53,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:53,223 INFO:     Epoch: 30
2023-01-04 22:45:55,507 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.538542628288269, 'Total loss': 0.538542628288269} | train loss {'Reaction outcome loss': 0.23751829855735768, 'Total loss': 0.23751829855735768}
2023-01-04 22:45:55,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:55,507 INFO:     Epoch: 31
2023-01-04 22:45:57,777 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5214058895905812, 'Total loss': 0.5214058895905812} | train loss {'Reaction outcome loss': 0.23661646392156072, 'Total loss': 0.23661646392156072}
2023-01-04 22:45:57,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:45:57,777 INFO:     Epoch: 32
2023-01-04 22:46:00,043 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5356640815734863, 'Total loss': 0.5356640815734863} | train loss {'Reaction outcome loss': 0.23244298600494215, 'Total loss': 0.23244298600494215}
2023-01-04 22:46:00,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:00,044 INFO:     Epoch: 33
2023-01-04 22:46:02,227 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5488427643974622, 'Total loss': 0.5488427643974622} | train loss {'Reaction outcome loss': 0.2270878880059461, 'Total loss': 0.2270878880059461}
2023-01-04 22:46:02,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:02,228 INFO:     Epoch: 34
2023-01-04 22:46:04,487 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5411935836076737, 'Total loss': 0.5411935836076737} | train loss {'Reaction outcome loss': 0.2307232268497563, 'Total loss': 0.2307232268497563}
2023-01-04 22:46:04,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:04,487 INFO:     Epoch: 35
2023-01-04 22:46:06,771 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.50947488596042, 'Total loss': 0.50947488596042} | train loss {'Reaction outcome loss': 0.22521489253771973, 'Total loss': 0.22521489253771973}
2023-01-04 22:46:06,773 INFO:     Found new best model at epoch 35
2023-01-04 22:46:06,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:06,774 INFO:     Epoch: 36
2023-01-04 22:46:09,061 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5545781175295512, 'Total loss': 0.5545781175295512} | train loss {'Reaction outcome loss': 0.22403297516171036, 'Total loss': 0.22403297516171036}
2023-01-04 22:46:09,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:09,061 INFO:     Epoch: 37
2023-01-04 22:46:11,351 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5410053541262945, 'Total loss': 0.5410053541262945} | train loss {'Reaction outcome loss': 0.21440510695887602, 'Total loss': 0.21440510695887602}
2023-01-04 22:46:11,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:11,352 INFO:     Epoch: 38
2023-01-04 22:46:13,620 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5273689190546672, 'Total loss': 0.5273689190546672} | train loss {'Reaction outcome loss': 0.216147518323378, 'Total loss': 0.216147518323378}
2023-01-04 22:46:13,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:13,620 INFO:     Epoch: 39
2023-01-04 22:46:15,893 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.517290864388148, 'Total loss': 0.517290864388148} | train loss {'Reaction outcome loss': 0.21379980594188727, 'Total loss': 0.21379980594188727}
2023-01-04 22:46:15,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:15,893 INFO:     Epoch: 40
2023-01-04 22:46:18,165 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5409972449143727, 'Total loss': 0.5409972449143727} | train loss {'Reaction outcome loss': 0.20846605280057834, 'Total loss': 0.20846605280057834}
2023-01-04 22:46:18,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:18,167 INFO:     Epoch: 41
2023-01-04 22:46:20,464 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5260635619362195, 'Total loss': 0.5260635619362195} | train loss {'Reaction outcome loss': 0.21120492395161505, 'Total loss': 0.21120492395161505}
2023-01-04 22:46:20,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:20,464 INFO:     Epoch: 42
2023-01-04 22:46:22,769 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.537264168759187, 'Total loss': 0.537264168759187} | train loss {'Reaction outcome loss': 0.20723091318719222, 'Total loss': 0.20723091318719222}
2023-01-04 22:46:22,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:22,771 INFO:     Epoch: 43
2023-01-04 22:46:25,036 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5326972623666127, 'Total loss': 0.5326972623666127} | train loss {'Reaction outcome loss': 0.2037006398992418, 'Total loss': 0.2037006398992418}
2023-01-04 22:46:25,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:25,037 INFO:     Epoch: 44
2023-01-04 22:46:27,306 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5301166286071142, 'Total loss': 0.5301166286071142} | train loss {'Reaction outcome loss': 0.19986235676165198, 'Total loss': 0.19986235676165198}
2023-01-04 22:46:27,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:27,307 INFO:     Epoch: 45
2023-01-04 22:46:29,557 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5078969021638234, 'Total loss': 0.5078969021638234} | train loss {'Reaction outcome loss': 0.19986899874916145, 'Total loss': 0.19986899874916145}
2023-01-04 22:46:29,558 INFO:     Found new best model at epoch 45
2023-01-04 22:46:29,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:29,560 INFO:     Epoch: 46
2023-01-04 22:46:31,846 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5180874228477478, 'Total loss': 0.5180874228477478} | train loss {'Reaction outcome loss': 0.19629081221976544, 'Total loss': 0.19629081221976544}
2023-01-04 22:46:31,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:31,846 INFO:     Epoch: 47
2023-01-04 22:46:34,124 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.513649903734525, 'Total loss': 0.513649903734525} | train loss {'Reaction outcome loss': 0.19821159239683556, 'Total loss': 0.19821159239683556}
2023-01-04 22:46:34,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:34,124 INFO:     Epoch: 48
2023-01-04 22:46:36,387 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5393732259670894, 'Total loss': 0.5393732259670894} | train loss {'Reaction outcome loss': 0.1932384184433907, 'Total loss': 0.1932384184433907}
2023-01-04 22:46:36,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:36,388 INFO:     Epoch: 49
2023-01-04 22:46:38,672 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5324386099974314, 'Total loss': 0.5324386099974314} | train loss {'Reaction outcome loss': 0.19224013559795944, 'Total loss': 0.19224013559795944}
2023-01-04 22:46:38,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:38,672 INFO:     Epoch: 50
2023-01-04 22:46:40,989 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5148467888434728, 'Total loss': 0.5148467888434728} | train loss {'Reaction outcome loss': 0.19013768524630836, 'Total loss': 0.19013768524630836}
2023-01-04 22:46:40,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:40,990 INFO:     Epoch: 51
2023-01-04 22:46:43,283 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5308389067649841, 'Total loss': 0.5308389067649841} | train loss {'Reaction outcome loss': 0.18654034365076128, 'Total loss': 0.18654034365076128}
2023-01-04 22:46:43,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:43,283 INFO:     Epoch: 52
2023-01-04 22:46:45,577 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5478412369887035, 'Total loss': 0.5478412369887035} | train loss {'Reaction outcome loss': 0.1840679873023115, 'Total loss': 0.1840679873023115}
2023-01-04 22:46:45,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:45,578 INFO:     Epoch: 53
2023-01-04 22:46:47,845 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5232820570468902, 'Total loss': 0.5232820570468902} | train loss {'Reaction outcome loss': 0.18350321419002483, 'Total loss': 0.18350321419002483}
2023-01-04 22:46:47,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:47,847 INFO:     Epoch: 54
2023-01-04 22:46:50,105 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.537221971154213, 'Total loss': 0.537221971154213} | train loss {'Reaction outcome loss': 0.18396555074904156, 'Total loss': 0.18396555074904156}
2023-01-04 22:46:50,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:50,105 INFO:     Epoch: 55
2023-01-04 22:46:52,391 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5024695525566737, 'Total loss': 0.5024695525566737} | train loss {'Reaction outcome loss': 0.18370637651667376, 'Total loss': 0.18370637651667376}
2023-01-04 22:46:52,392 INFO:     Found new best model at epoch 55
2023-01-04 22:46:52,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:52,393 INFO:     Epoch: 56
2023-01-04 22:46:54,687 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5045752624670664, 'Total loss': 0.5045752624670664} | train loss {'Reaction outcome loss': 0.18219230513320395, 'Total loss': 0.18219230513320395}
2023-01-04 22:46:54,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:54,687 INFO:     Epoch: 57
2023-01-04 22:46:56,989 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5176038404305776, 'Total loss': 0.5176038404305776} | train loss {'Reaction outcome loss': 0.18144023825249733, 'Total loss': 0.18144023825249733}
2023-01-04 22:46:56,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:56,989 INFO:     Epoch: 58
2023-01-04 22:46:59,271 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.508694181839625, 'Total loss': 0.508694181839625} | train loss {'Reaction outcome loss': 0.17692759144876408, 'Total loss': 0.17692759144876408}
2023-01-04 22:46:59,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:46:59,272 INFO:     Epoch: 59
2023-01-04 22:47:01,525 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.546677361552914, 'Total loss': 0.546677361552914} | train loss {'Reaction outcome loss': 0.17782457329884224, 'Total loss': 0.17782457329884224}
2023-01-04 22:47:01,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:01,526 INFO:     Epoch: 60
2023-01-04 22:47:03,815 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5437042037645976, 'Total loss': 0.5437042037645976} | train loss {'Reaction outcome loss': 0.17636478717509482, 'Total loss': 0.17636478717509482}
2023-01-04 22:47:03,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:03,816 INFO:     Epoch: 61
2023-01-04 22:47:06,115 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49474989672501885, 'Total loss': 0.49474989672501885} | train loss {'Reaction outcome loss': 0.1778613976791286, 'Total loss': 0.1778613976791286}
2023-01-04 22:47:06,115 INFO:     Found new best model at epoch 61
2023-01-04 22:47:06,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:06,117 INFO:     Epoch: 62
2023-01-04 22:47:08,419 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5260746975739797, 'Total loss': 0.5260746975739797} | train loss {'Reaction outcome loss': 0.17377466747254833, 'Total loss': 0.17377466747254833}
2023-01-04 22:47:08,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:08,419 INFO:     Epoch: 63
2023-01-04 22:47:10,705 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4906029899915059, 'Total loss': 0.4906029899915059} | train loss {'Reaction outcome loss': 0.17022835111433796, 'Total loss': 0.17022835111433796}
2023-01-04 22:47:10,706 INFO:     Found new best model at epoch 63
2023-01-04 22:47:10,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:10,707 INFO:     Epoch: 64
2023-01-04 22:47:13,003 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5250910699367524, 'Total loss': 0.5250910699367524} | train loss {'Reaction outcome loss': 0.17274208280294864, 'Total loss': 0.17274208280294864}
2023-01-04 22:47:13,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:13,003 INFO:     Epoch: 65
2023-01-04 22:47:15,257 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5335083882013957, 'Total loss': 0.5335083882013957} | train loss {'Reaction outcome loss': 0.1695988154617081, 'Total loss': 0.1695988154617081}
2023-01-04 22:47:15,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:15,258 INFO:     Epoch: 66
2023-01-04 22:47:17,546 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5225364675124486, 'Total loss': 0.5225364675124486} | train loss {'Reaction outcome loss': 0.167305094364775, 'Total loss': 0.167305094364775}
2023-01-04 22:47:17,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:17,548 INFO:     Epoch: 67
2023-01-04 22:47:19,815 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5092369129260381, 'Total loss': 0.5092369129260381} | train loss {'Reaction outcome loss': 0.1690745993150862, 'Total loss': 0.1690745993150862}
2023-01-04 22:47:19,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:19,815 INFO:     Epoch: 68
2023-01-04 22:47:22,069 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.519765720764796, 'Total loss': 0.519765720764796} | train loss {'Reaction outcome loss': 0.169890004879247, 'Total loss': 0.169890004879247}
2023-01-04 22:47:22,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:22,071 INFO:     Epoch: 69
2023-01-04 22:47:24,323 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5248601059118907, 'Total loss': 0.5248601059118907} | train loss {'Reaction outcome loss': 0.16933559731072628, 'Total loss': 0.16933559731072628}
2023-01-04 22:47:24,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:24,323 INFO:     Epoch: 70
2023-01-04 22:47:26,584 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5329468801617623, 'Total loss': 0.5329468801617623} | train loss {'Reaction outcome loss': 0.1684201534447472, 'Total loss': 0.1684201534447472}
2023-01-04 22:47:26,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:26,584 INFO:     Epoch: 71
2023-01-04 22:47:28,880 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5094449341297149, 'Total loss': 0.5094449341297149} | train loss {'Reaction outcome loss': 0.16164772628070215, 'Total loss': 0.16164772628070215}
2023-01-04 22:47:28,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:28,881 INFO:     Epoch: 72
2023-01-04 22:47:31,080 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5179206609725953, 'Total loss': 0.5179206609725953} | train loss {'Reaction outcome loss': 0.16296432470055533, 'Total loss': 0.16296432470055533}
2023-01-04 22:47:31,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:31,081 INFO:     Epoch: 73
2023-01-04 22:47:33,354 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5158621648947398, 'Total loss': 0.5158621648947398} | train loss {'Reaction outcome loss': 0.16508311147562862, 'Total loss': 0.16508311147562862}
2023-01-04 22:47:33,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:33,355 INFO:     Epoch: 74
2023-01-04 22:47:35,610 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.525026050209999, 'Total loss': 0.525026050209999} | train loss {'Reaction outcome loss': 0.16321601634441676, 'Total loss': 0.16321601634441676}
2023-01-04 22:47:35,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:35,611 INFO:     Epoch: 75
2023-01-04 22:47:37,825 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5353670765956243, 'Total loss': 0.5353670765956243} | train loss {'Reaction outcome loss': 0.1610759769142723, 'Total loss': 0.1610759769142723}
2023-01-04 22:47:37,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:37,826 INFO:     Epoch: 76
2023-01-04 22:47:40,104 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5075900852680206, 'Total loss': 0.5075900852680206} | train loss {'Reaction outcome loss': 0.16078753433264253, 'Total loss': 0.16078753433264253}
2023-01-04 22:47:40,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:40,105 INFO:     Epoch: 77
2023-01-04 22:47:42,380 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4904496595263481, 'Total loss': 0.4904496595263481} | train loss {'Reaction outcome loss': 0.16589224934645186, 'Total loss': 0.16589224934645186}
2023-01-04 22:47:42,380 INFO:     Found new best model at epoch 77
2023-01-04 22:47:42,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:42,381 INFO:     Epoch: 78
2023-01-04 22:47:44,659 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49900014102458956, 'Total loss': 0.49900014102458956} | train loss {'Reaction outcome loss': 0.1662207891129038, 'Total loss': 0.1662207891129038}
2023-01-04 22:47:44,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:44,660 INFO:     Epoch: 79
2023-01-04 22:47:46,912 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5138899127642313, 'Total loss': 0.5138899127642313} | train loss {'Reaction outcome loss': 0.16430524866422808, 'Total loss': 0.16430524866422808}
2023-01-04 22:47:46,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:46,912 INFO:     Epoch: 80
2023-01-04 22:47:49,164 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5214980532725652, 'Total loss': 0.5214980532725652} | train loss {'Reaction outcome loss': 0.15806854952678137, 'Total loss': 0.15806854952678137}
2023-01-04 22:47:49,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:49,164 INFO:     Epoch: 81
2023-01-04 22:47:51,415 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5564660201470057, 'Total loss': 0.5564660201470057} | train loss {'Reaction outcome loss': 0.16109603901632427, 'Total loss': 0.16109603901632427}
2023-01-04 22:47:51,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:51,416 INFO:     Epoch: 82
2023-01-04 22:47:53,696 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4945249527692795, 'Total loss': 0.4945249527692795} | train loss {'Reaction outcome loss': 0.15949952144542245, 'Total loss': 0.15949952144542245}
2023-01-04 22:47:53,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:53,696 INFO:     Epoch: 83
2023-01-04 22:47:55,948 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5021174068252245, 'Total loss': 0.5021174068252245} | train loss {'Reaction outcome loss': 0.15873524937728278, 'Total loss': 0.15873524937728278}
2023-01-04 22:47:55,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:55,950 INFO:     Epoch: 84
2023-01-04 22:47:58,218 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.534875613451004, 'Total loss': 0.534875613451004} | train loss {'Reaction outcome loss': 0.15982727111327305, 'Total loss': 0.15982727111327305}
2023-01-04 22:47:58,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:47:58,218 INFO:     Epoch: 85
2023-01-04 22:48:00,519 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5168014248212178, 'Total loss': 0.5168014248212178} | train loss {'Reaction outcome loss': 0.16244550245656003, 'Total loss': 0.16244550245656003}
2023-01-04 22:48:00,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:00,519 INFO:     Epoch: 86
2023-01-04 22:48:02,804 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5210790356000264, 'Total loss': 0.5210790356000264} | train loss {'Reaction outcome loss': 0.15616632289243088, 'Total loss': 0.15616632289243088}
2023-01-04 22:48:02,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:02,805 INFO:     Epoch: 87
2023-01-04 22:48:05,097 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4967095563809077, 'Total loss': 0.4967095563809077} | train loss {'Reaction outcome loss': 0.15581385547544013, 'Total loss': 0.15581385547544013}
2023-01-04 22:48:05,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:05,097 INFO:     Epoch: 88
2023-01-04 22:48:07,396 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5013032068808874, 'Total loss': 0.5013032068808874} | train loss {'Reaction outcome loss': 0.1591776916605928, 'Total loss': 0.1591776916605928}
2023-01-04 22:48:07,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:07,396 INFO:     Epoch: 89
2023-01-04 22:48:09,628 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.492143655816714, 'Total loss': 0.492143655816714} | train loss {'Reaction outcome loss': 0.1546286521395433, 'Total loss': 0.1546286521395433}
2023-01-04 22:48:09,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:09,629 INFO:     Epoch: 90
2023-01-04 22:48:11,873 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.508708597222964, 'Total loss': 0.508708597222964} | train loss {'Reaction outcome loss': 0.15593489506601318, 'Total loss': 0.15593489506601318}
2023-01-04 22:48:11,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:11,873 INFO:     Epoch: 91
2023-01-04 22:48:14,146 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.514569119612376, 'Total loss': 0.514569119612376} | train loss {'Reaction outcome loss': 0.15840687292933947, 'Total loss': 0.15840687292933947}
2023-01-04 22:48:14,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:14,147 INFO:     Epoch: 92
2023-01-04 22:48:16,395 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5063684364159902, 'Total loss': 0.5063684364159902} | train loss {'Reaction outcome loss': 0.15031145316454506, 'Total loss': 0.15031145316454506}
2023-01-04 22:48:16,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:16,396 INFO:     Epoch: 93
2023-01-04 22:48:18,641 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.542146748304367, 'Total loss': 0.542146748304367} | train loss {'Reaction outcome loss': 0.14934249864790305, 'Total loss': 0.14934249864790305}
2023-01-04 22:48:18,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:18,641 INFO:     Epoch: 94
2023-01-04 22:48:20,911 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5364800800879796, 'Total loss': 0.5364800800879796} | train loss {'Reaction outcome loss': 0.15197903643083163, 'Total loss': 0.15197903643083163}
2023-01-04 22:48:20,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:20,912 INFO:     Epoch: 95
2023-01-04 22:48:23,275 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4907307634751002, 'Total loss': 0.4907307634751002} | train loss {'Reaction outcome loss': 0.15198319827606532, 'Total loss': 0.15198319827606532}
2023-01-04 22:48:23,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:23,276 INFO:     Epoch: 96
2023-01-04 22:48:25,601 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5253418823083241, 'Total loss': 0.5253418823083241} | train loss {'Reaction outcome loss': 0.15524483642403022, 'Total loss': 0.15524483642403022}
2023-01-04 22:48:25,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:25,601 INFO:     Epoch: 97
2023-01-04 22:48:27,947 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5473548223574957, 'Total loss': 0.5473548223574957} | train loss {'Reaction outcome loss': 0.1516729095002589, 'Total loss': 0.1516729095002589}
2023-01-04 22:48:27,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:27,948 INFO:     Epoch: 98
2023-01-04 22:48:30,307 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5113317211469014, 'Total loss': 0.5113317211469014} | train loss {'Reaction outcome loss': 0.15370721718303132, 'Total loss': 0.15370721718303132}
2023-01-04 22:48:30,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:30,307 INFO:     Epoch: 99
2023-01-04 22:48:32,647 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49622803976138435, 'Total loss': 0.49622803976138435} | train loss {'Reaction outcome loss': 0.15253217761751117, 'Total loss': 0.15253217761751117}
2023-01-04 22:48:32,648 INFO:     Best model found after epoch 78 of 100.
2023-01-04 22:48:32,648 INFO:   Done with stage: TRAINING
2023-01-04 22:48:32,648 INFO:   Starting stage: EVALUATION
2023-01-04 22:48:32,799 INFO:   Done with stage: EVALUATION
2023-01-04 22:48:32,799 INFO:   Leaving out SEQ value Fold_7
2023-01-04 22:48:32,813 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 22:48:32,814 INFO:   Starting stage: FEATURE SCALING
2023-01-04 22:48:33,533 INFO:   Done with stage: FEATURE SCALING
2023-01-04 22:48:33,534 INFO:   Starting stage: SCALING TARGETS
2023-01-04 22:48:33,617 INFO:   Done with stage: SCALING TARGETS
2023-01-04 22:48:33,617 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:48:33,617 INFO:     No hyperparam tuning for this model
2023-01-04 22:48:33,617 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:48:33,617 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 22:48:33,618 INFO:     None feature selector for col prot
2023-01-04 22:48:33,618 INFO:     None feature selector for col prot
2023-01-04 22:48:33,619 INFO:     None feature selector for col prot
2023-01-04 22:48:33,620 INFO:     None feature selector for col chem
2023-01-04 22:48:33,620 INFO:     None feature selector for col chem
2023-01-04 22:48:33,620 INFO:     None feature selector for col chem
2023-01-04 22:48:33,620 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 22:48:33,620 INFO:   Starting stage: BUILD MODEL
2023-01-04 22:48:33,622 INFO:     Number of params in model 72931
2023-01-04 22:48:33,625 INFO:   Done with stage: BUILD MODEL
2023-01-04 22:48:33,625 INFO:   Starting stage: TRAINING
2023-01-04 22:48:33,689 INFO:     Val loss before train {'Reaction outcome loss': 1.0697319189707437, 'Total loss': 1.0697319189707437}
2023-01-04 22:48:33,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:33,690 INFO:     Epoch: 0
2023-01-04 22:48:36,043 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7633037249247233, 'Total loss': 0.7633037249247233} | train loss {'Reaction outcome loss': 0.9255712346479781, 'Total loss': 0.9255712346479781}
2023-01-04 22:48:36,043 INFO:     Found new best model at epoch 0
2023-01-04 22:48:36,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:36,044 INFO:     Epoch: 1
2023-01-04 22:48:38,379 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6211335291465123, 'Total loss': 0.6211335291465123} | train loss {'Reaction outcome loss': 0.5976227868334911, 'Total loss': 0.5976227868334911}
2023-01-04 22:48:38,380 INFO:     Found new best model at epoch 1
2023-01-04 22:48:38,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:38,382 INFO:     Epoch: 2
2023-01-04 22:48:40,735 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5887069175640742, 'Total loss': 0.5887069175640742} | train loss {'Reaction outcome loss': 0.5255503681377384, 'Total loss': 0.5255503681377384}
2023-01-04 22:48:40,735 INFO:     Found new best model at epoch 2
2023-01-04 22:48:40,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:40,737 INFO:     Epoch: 3
2023-01-04 22:48:43,079 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5797403494517008, 'Total loss': 0.5797403494517008} | train loss {'Reaction outcome loss': 0.48402321158440964, 'Total loss': 0.48402321158440964}
2023-01-04 22:48:43,079 INFO:     Found new best model at epoch 3
2023-01-04 22:48:43,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:43,080 INFO:     Epoch: 4
2023-01-04 22:48:45,408 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5395348280668258, 'Total loss': 0.5395348280668258} | train loss {'Reaction outcome loss': 0.4616251898263766, 'Total loss': 0.4616251898263766}
2023-01-04 22:48:45,409 INFO:     Found new best model at epoch 4
2023-01-04 22:48:45,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:45,411 INFO:     Epoch: 5
2023-01-04 22:48:47,695 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5356907943884531, 'Total loss': 0.5356907943884531} | train loss {'Reaction outcome loss': 0.4399228469344253, 'Total loss': 0.4399228469344253}
2023-01-04 22:48:47,696 INFO:     Found new best model at epoch 5
2023-01-04 22:48:47,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:47,697 INFO:     Epoch: 6
2023-01-04 22:48:49,977 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5534440497557322, 'Total loss': 0.5534440497557322} | train loss {'Reaction outcome loss': 0.4212786589449924, 'Total loss': 0.4212786589449924}
2023-01-04 22:48:49,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:49,977 INFO:     Epoch: 7
2023-01-04 22:48:52,259 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5429424385229746, 'Total loss': 0.5429424385229746} | train loss {'Reaction outcome loss': 0.4045994586516373, 'Total loss': 0.4045994586516373}
2023-01-04 22:48:52,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:52,260 INFO:     Epoch: 8
2023-01-04 22:48:54,536 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5492204914490382, 'Total loss': 0.5492204914490382} | train loss {'Reaction outcome loss': 0.391483686057454, 'Total loss': 0.391483686057454}
2023-01-04 22:48:54,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:54,536 INFO:     Epoch: 9
2023-01-04 22:48:56,840 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.531038882335027, 'Total loss': 0.531038882335027} | train loss {'Reaction outcome loss': 0.382920043616949, 'Total loss': 0.382920043616949}
2023-01-04 22:48:56,841 INFO:     Found new best model at epoch 9
2023-01-04 22:48:56,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:56,842 INFO:     Epoch: 10
2023-01-04 22:48:59,129 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5347069799900055, 'Total loss': 0.5347069799900055} | train loss {'Reaction outcome loss': 0.36936372488952285, 'Total loss': 0.36936372488952285}
2023-01-04 22:48:59,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:48:59,129 INFO:     Epoch: 11
2023-01-04 22:49:01,404 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5239914615948995, 'Total loss': 0.5239914615948995} | train loss {'Reaction outcome loss': 0.3613882176174584, 'Total loss': 0.3613882176174584}
2023-01-04 22:49:01,404 INFO:     Found new best model at epoch 11
2023-01-04 22:49:01,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:01,405 INFO:     Epoch: 12
2023-01-04 22:49:03,674 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5456174314022064, 'Total loss': 0.5456174314022064} | train loss {'Reaction outcome loss': 0.3492168349210536, 'Total loss': 0.3492168349210536}
2023-01-04 22:49:03,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:03,675 INFO:     Epoch: 13
2023-01-04 22:49:05,935 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5321477562189102, 'Total loss': 0.5321477562189102} | train loss {'Reaction outcome loss': 0.34191017635570103, 'Total loss': 0.34191017635570103}
2023-01-04 22:49:05,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:05,935 INFO:     Epoch: 14
2023-01-04 22:49:08,222 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5433011472225189, 'Total loss': 0.5433011472225189} | train loss {'Reaction outcome loss': 0.3350679026883001, 'Total loss': 0.3350679026883001}
2023-01-04 22:49:08,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:08,223 INFO:     Epoch: 15
2023-01-04 22:49:10,497 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.541954043507576, 'Total loss': 0.541954043507576} | train loss {'Reaction outcome loss': 0.3242205160565755, 'Total loss': 0.3242205160565755}
2023-01-04 22:49:10,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:10,498 INFO:     Epoch: 16
2023-01-04 22:49:12,736 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5168884019056956, 'Total loss': 0.5168884019056956} | train loss {'Reaction outcome loss': 0.31828011916647747, 'Total loss': 0.31828011916647747}
2023-01-04 22:49:12,736 INFO:     Found new best model at epoch 16
2023-01-04 22:49:12,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:12,737 INFO:     Epoch: 17
2023-01-04 22:49:15,005 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5372578759988149, 'Total loss': 0.5372578759988149} | train loss {'Reaction outcome loss': 0.30623707487264695, 'Total loss': 0.30623707487264695}
2023-01-04 22:49:15,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:15,006 INFO:     Epoch: 18
2023-01-04 22:49:17,286 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5251686036586761, 'Total loss': 0.5251686036586761} | train loss {'Reaction outcome loss': 0.29714958092688654, 'Total loss': 0.29714958092688654}
2023-01-04 22:49:17,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:17,286 INFO:     Epoch: 19
2023-01-04 22:49:19,561 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4929299493630727, 'Total loss': 0.4929299493630727} | train loss {'Reaction outcome loss': 0.2902463845545527, 'Total loss': 0.2902463845545527}
2023-01-04 22:49:19,561 INFO:     Found new best model at epoch 19
2023-01-04 22:49:19,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:19,563 INFO:     Epoch: 20
2023-01-04 22:49:21,837 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5319060444831848, 'Total loss': 0.5319060444831848} | train loss {'Reaction outcome loss': 0.2848632396181998, 'Total loss': 0.2848632396181998}
2023-01-04 22:49:21,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:21,838 INFO:     Epoch: 21
2023-01-04 22:49:24,031 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5092901468276978, 'Total loss': 0.5092901468276978} | train loss {'Reaction outcome loss': 0.27860894834199107, 'Total loss': 0.27860894834199107}
2023-01-04 22:49:24,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:24,032 INFO:     Epoch: 22
2023-01-04 22:49:26,216 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5166705489158631, 'Total loss': 0.5166705489158631} | train loss {'Reaction outcome loss': 0.2766857825031349, 'Total loss': 0.2766857825031349}
2023-01-04 22:49:26,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:26,218 INFO:     Epoch: 23
2023-01-04 22:49:28,467 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5503877441088358, 'Total loss': 0.5503877441088358} | train loss {'Reaction outcome loss': 0.27136705671890976, 'Total loss': 0.27136705671890976}
2023-01-04 22:49:28,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:28,467 INFO:     Epoch: 24
2023-01-04 22:49:30,740 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.535029927889506, 'Total loss': 0.535029927889506} | train loss {'Reaction outcome loss': 0.26590246146390156, 'Total loss': 0.26590246146390156}
2023-01-04 22:49:30,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:30,740 INFO:     Epoch: 25
2023-01-04 22:49:32,986 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5210474073886872, 'Total loss': 0.5210474073886872} | train loss {'Reaction outcome loss': 0.2649520827383341, 'Total loss': 0.2649520827383341}
2023-01-04 22:49:32,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:32,987 INFO:     Epoch: 26
2023-01-04 22:49:35,258 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.543655268351237, 'Total loss': 0.543655268351237} | train loss {'Reaction outcome loss': 0.25998042834525936, 'Total loss': 0.25998042834525936}
2023-01-04 22:49:35,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:35,259 INFO:     Epoch: 27
2023-01-04 22:49:37,561 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5374702413876852, 'Total loss': 0.5374702413876852} | train loss {'Reaction outcome loss': 0.257062505217881, 'Total loss': 0.257062505217881}
2023-01-04 22:49:37,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:37,562 INFO:     Epoch: 28
2023-01-04 22:49:39,856 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.553564848502477, 'Total loss': 0.553564848502477} | train loss {'Reaction outcome loss': 0.25299051932533295, 'Total loss': 0.25299051932533295}
2023-01-04 22:49:39,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:39,857 INFO:     Epoch: 29
2023-01-04 22:49:42,134 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5382557372252147, 'Total loss': 0.5382557372252147} | train loss {'Reaction outcome loss': 0.24725119998201137, 'Total loss': 0.24725119998201137}
2023-01-04 22:49:42,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:42,135 INFO:     Epoch: 30
2023-01-04 22:49:44,425 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5443708817164103, 'Total loss': 0.5443708817164103} | train loss {'Reaction outcome loss': 0.2436196679444412, 'Total loss': 0.2436196679444412}
2023-01-04 22:49:44,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:44,426 INFO:     Epoch: 31
2023-01-04 22:49:46,723 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5227852796514829, 'Total loss': 0.5227852796514829} | train loss {'Reaction outcome loss': 0.23863814892886132, 'Total loss': 0.23863814892886132}
2023-01-04 22:49:46,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:46,724 INFO:     Epoch: 32
2023-01-04 22:49:49,012 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5415956487258275, 'Total loss': 0.5415956487258275} | train loss {'Reaction outcome loss': 0.23795781026355625, 'Total loss': 0.23795781026355625}
2023-01-04 22:49:49,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:49,012 INFO:     Epoch: 33
2023-01-04 22:49:51,309 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5406649470329284, 'Total loss': 0.5406649470329284} | train loss {'Reaction outcome loss': 0.23535124211158562, 'Total loss': 0.23535124211158562}
2023-01-04 22:49:51,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:51,311 INFO:     Epoch: 34
2023-01-04 22:49:53,597 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5629337867101033, 'Total loss': 0.5629337867101033} | train loss {'Reaction outcome loss': 0.22956815530757826, 'Total loss': 0.22956815530757826}
2023-01-04 22:49:53,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:53,597 INFO:     Epoch: 35
2023-01-04 22:49:55,897 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5453745245933532, 'Total loss': 0.5453745245933532} | train loss {'Reaction outcome loss': 0.22445880733968335, 'Total loss': 0.22445880733968335}
2023-01-04 22:49:55,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:55,899 INFO:     Epoch: 36
2023-01-04 22:49:58,002 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5486565411090851, 'Total loss': 0.5486565411090851} | train loss {'Reaction outcome loss': 0.22821563278872936, 'Total loss': 0.22821563278872936}
2023-01-04 22:49:58,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:49:58,003 INFO:     Epoch: 37
2023-01-04 22:50:00,289 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5700881699721019, 'Total loss': 0.5700881699721019} | train loss {'Reaction outcome loss': 0.22157316745699313, 'Total loss': 0.22157316745699313}
2023-01-04 22:50:00,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:00,291 INFO:     Epoch: 38
2023-01-04 22:50:02,523 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5402053018411, 'Total loss': 0.5402053018411} | train loss {'Reaction outcome loss': 0.22148221582241545, 'Total loss': 0.22148221582241545}
2023-01-04 22:50:02,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:02,524 INFO:     Epoch: 39
2023-01-04 22:50:04,803 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5454546054204304, 'Total loss': 0.5454546054204304} | train loss {'Reaction outcome loss': 0.2218661735419332, 'Total loss': 0.2218661735419332}
2023-01-04 22:50:04,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:04,804 INFO:     Epoch: 40
2023-01-04 22:50:07,088 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5651217410961787, 'Total loss': 0.5651217410961787} | train loss {'Reaction outcome loss': 0.218687499046245, 'Total loss': 0.218687499046245}
2023-01-04 22:50:07,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:07,089 INFO:     Epoch: 41
2023-01-04 22:50:09,353 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5478249390920004, 'Total loss': 0.5478249390920004} | train loss {'Reaction outcome loss': 0.21688701346220737, 'Total loss': 0.21688701346220737}
2023-01-04 22:50:09,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:09,353 INFO:     Epoch: 42
2023-01-04 22:50:11,616 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5427826635539532, 'Total loss': 0.5427826635539532} | train loss {'Reaction outcome loss': 0.21163731859492588, 'Total loss': 0.21163731859492588}
2023-01-04 22:50:11,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:11,617 INFO:     Epoch: 43
2023-01-04 22:50:13,915 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5676712056001028, 'Total loss': 0.5676712056001028} | train loss {'Reaction outcome loss': 0.20886363651240344, 'Total loss': 0.20886363651240344}
2023-01-04 22:50:13,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:13,916 INFO:     Epoch: 44
2023-01-04 22:50:16,167 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5588281512260437, 'Total loss': 0.5588281512260437} | train loss {'Reaction outcome loss': 0.2090852169407404, 'Total loss': 0.2090852169407404}
2023-01-04 22:50:16,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:16,167 INFO:     Epoch: 45
2023-01-04 22:50:18,446 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5508301854133606, 'Total loss': 0.5508301854133606} | train loss {'Reaction outcome loss': 0.20487810570464238, 'Total loss': 0.20487810570464238}
2023-01-04 22:50:18,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:18,448 INFO:     Epoch: 46
2023-01-04 22:50:20,682 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5386663099129995, 'Total loss': 0.5386663099129995} | train loss {'Reaction outcome loss': 0.20231277007098555, 'Total loss': 0.20231277007098555}
2023-01-04 22:50:20,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:20,682 INFO:     Epoch: 47
2023-01-04 22:50:22,948 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5634186138709386, 'Total loss': 0.5634186138709386} | train loss {'Reaction outcome loss': 0.20488279453219865, 'Total loss': 0.20488279453219865}
2023-01-04 22:50:22,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:22,948 INFO:     Epoch: 48
2023-01-04 22:50:25,248 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.567555163304011, 'Total loss': 0.567555163304011} | train loss {'Reaction outcome loss': 0.20559684415801768, 'Total loss': 0.20559684415801768}
2023-01-04 22:50:25,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:25,249 INFO:     Epoch: 49
2023-01-04 22:50:27,515 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.557621552546819, 'Total loss': 0.557621552546819} | train loss {'Reaction outcome loss': 0.20140266938249343, 'Total loss': 0.20140266938249343}
2023-01-04 22:50:27,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:27,515 INFO:     Epoch: 50
2023-01-04 22:50:29,758 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5554843366146087, 'Total loss': 0.5554843366146087} | train loss {'Reaction outcome loss': 0.2005875120544638, 'Total loss': 0.2005875120544638}
2023-01-04 22:50:29,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:29,759 INFO:     Epoch: 51
2023-01-04 22:50:32,036 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5749065160751343, 'Total loss': 0.5749065160751343} | train loss {'Reaction outcome loss': 0.19590062215682186, 'Total loss': 0.19590062215682186}
2023-01-04 22:50:32,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:32,037 INFO:     Epoch: 52
2023-01-04 22:50:34,295 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5685136308272679, 'Total loss': 0.5685136308272679} | train loss {'Reaction outcome loss': 0.20138662638620133, 'Total loss': 0.20138662638620133}
2023-01-04 22:50:34,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:34,295 INFO:     Epoch: 53
2023-01-04 22:50:36,558 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5408855815728505, 'Total loss': 0.5408855815728505} | train loss {'Reaction outcome loss': 0.18811978109934055, 'Total loss': 0.18811978109934055}
2023-01-04 22:50:36,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:36,560 INFO:     Epoch: 54
2023-01-04 22:50:38,822 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5859891494115194, 'Total loss': 0.5859891494115194} | train loss {'Reaction outcome loss': 0.1885952915532333, 'Total loss': 0.1885952915532333}
2023-01-04 22:50:38,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:38,822 INFO:     Epoch: 55
2023-01-04 22:50:41,071 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5518946627775828, 'Total loss': 0.5518946627775828} | train loss {'Reaction outcome loss': 0.1862428872156821, 'Total loss': 0.1862428872156821}
2023-01-04 22:50:41,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:41,072 INFO:     Epoch: 56
2023-01-04 22:50:43,348 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5617239236831665, 'Total loss': 0.5617239236831665} | train loss {'Reaction outcome loss': 0.1934439358536813, 'Total loss': 0.1934439358536813}
2023-01-04 22:50:43,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:43,348 INFO:     Epoch: 57
2023-01-04 22:50:45,605 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5374187156558037, 'Total loss': 0.5374187156558037} | train loss {'Reaction outcome loss': 0.18796598346776158, 'Total loss': 0.18796598346776158}
2023-01-04 22:50:45,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:45,605 INFO:     Epoch: 58
2023-01-04 22:50:47,880 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5690591712792714, 'Total loss': 0.5690591712792714} | train loss {'Reaction outcome loss': 0.19163842356195573, 'Total loss': 0.19163842356195573}
2023-01-04 22:50:47,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:47,881 INFO:     Epoch: 59
2023-01-04 22:50:50,154 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5882290442784627, 'Total loss': 0.5882290442784627} | train loss {'Reaction outcome loss': 0.18393774562606097, 'Total loss': 0.18393774562606097}
2023-01-04 22:50:50,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:50,154 INFO:     Epoch: 60
2023-01-04 22:50:52,404 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5660446306069692, 'Total loss': 0.5660446306069692} | train loss {'Reaction outcome loss': 0.18583184657517537, 'Total loss': 0.18583184657517537}
2023-01-04 22:50:52,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:52,404 INFO:     Epoch: 61
2023-01-04 22:50:54,686 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5189254534741242, 'Total loss': 0.5189254534741242} | train loss {'Reaction outcome loss': 0.1845188694115096, 'Total loss': 0.1845188694115096}
2023-01-04 22:50:54,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:54,687 INFO:     Epoch: 62
2023-01-04 22:50:56,940 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5898810108502706, 'Total loss': 0.5898810108502706} | train loss {'Reaction outcome loss': 0.18123946348474182, 'Total loss': 0.18123946348474182}
2023-01-04 22:50:56,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:56,940 INFO:     Epoch: 63
2023-01-04 22:50:59,196 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5599289268255234, 'Total loss': 0.5599289268255234} | train loss {'Reaction outcome loss': 0.18045678395535864, 'Total loss': 0.18045678395535864}
2023-01-04 22:50:59,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:50:59,197 INFO:     Epoch: 64
2023-01-04 22:51:01,485 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5466346184412638, 'Total loss': 0.5466346184412638} | train loss {'Reaction outcome loss': 0.17821726117733638, 'Total loss': 0.17821726117733638}
2023-01-04 22:51:01,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:01,485 INFO:     Epoch: 65
2023-01-04 22:51:03,725 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5624969144662221, 'Total loss': 0.5624969144662221} | train loss {'Reaction outcome loss': 0.17484352709422904, 'Total loss': 0.17484352709422904}
2023-01-04 22:51:03,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:03,726 INFO:     Epoch: 66
2023-01-04 22:51:06,002 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5801991353432338, 'Total loss': 0.5801991353432338} | train loss {'Reaction outcome loss': 0.17384451650930333, 'Total loss': 0.17384451650930333}
2023-01-04 22:51:06,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:06,004 INFO:     Epoch: 67
2023-01-04 22:51:08,251 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5769793043533961, 'Total loss': 0.5769793043533961} | train loss {'Reaction outcome loss': 0.1747542057129208, 'Total loss': 0.1747542057129208}
2023-01-04 22:51:08,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:08,252 INFO:     Epoch: 68
2023-01-04 22:51:10,514 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5482126166423161, 'Total loss': 0.5482126166423161} | train loss {'Reaction outcome loss': 0.17773789818657543, 'Total loss': 0.17773789818657543}
2023-01-04 22:51:10,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:10,516 INFO:     Epoch: 69
2023-01-04 22:51:12,791 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5561917533477148, 'Total loss': 0.5561917533477148} | train loss {'Reaction outcome loss': 0.17197026493236262, 'Total loss': 0.17197026493236262}
2023-01-04 22:51:12,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:12,791 INFO:     Epoch: 70
2023-01-04 22:51:15,021 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.6015317698319753, 'Total loss': 0.6015317698319753} | train loss {'Reaction outcome loss': 0.17317025079509574, 'Total loss': 0.17317025079509574}
2023-01-04 22:51:15,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:15,021 INFO:     Epoch: 71
2023-01-04 22:51:17,295 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5724119861920675, 'Total loss': 0.5724119861920675} | train loss {'Reaction outcome loss': 0.1742524673266249, 'Total loss': 0.1742524673266249}
2023-01-04 22:51:17,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:17,296 INFO:     Epoch: 72
2023-01-04 22:51:19,575 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5875139594078064, 'Total loss': 0.5875139594078064} | train loss {'Reaction outcome loss': 0.17879053079338225, 'Total loss': 0.17879053079338225}
2023-01-04 22:51:19,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:19,575 INFO:     Epoch: 73
2023-01-04 22:51:21,793 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5751283764839172, 'Total loss': 0.5751283764839172} | train loss {'Reaction outcome loss': 0.17370363654205676, 'Total loss': 0.17370363654205676}
2023-01-04 22:51:21,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:21,794 INFO:     Epoch: 74
2023-01-04 22:51:24,093 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.6000862816969553, 'Total loss': 0.6000862816969553} | train loss {'Reaction outcome loss': 0.17121118033096355, 'Total loss': 0.17121118033096355}
2023-01-04 22:51:24,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:24,094 INFO:     Epoch: 75
2023-01-04 22:51:26,393 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.600471842288971, 'Total loss': 0.600471842288971} | train loss {'Reaction outcome loss': 0.173286789981144, 'Total loss': 0.173286789981144}
2023-01-04 22:51:26,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:26,394 INFO:     Epoch: 76
2023-01-04 22:51:28,662 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.6102989395459493, 'Total loss': 0.6102989395459493} | train loss {'Reaction outcome loss': 0.17224553046875804, 'Total loss': 0.17224553046875804}
2023-01-04 22:51:28,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:28,663 INFO:     Epoch: 77
2023-01-04 22:51:30,859 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5980243821938832, 'Total loss': 0.5980243821938832} | train loss {'Reaction outcome loss': 0.16677716230159956, 'Total loss': 0.16677716230159956}
2023-01-04 22:51:30,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:30,859 INFO:     Epoch: 78
2023-01-04 22:51:33,132 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5638560781876246, 'Total loss': 0.5638560781876246} | train loss {'Reaction outcome loss': 0.16595420326250823, 'Total loss': 0.16595420326250823}
2023-01-04 22:51:33,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:33,132 INFO:     Epoch: 79
2023-01-04 22:51:35,396 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5712967564662298, 'Total loss': 0.5712967564662298} | train loss {'Reaction outcome loss': 0.17015379510604733, 'Total loss': 0.17015379510604733}
2023-01-04 22:51:35,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:35,397 INFO:     Epoch: 80
2023-01-04 22:51:37,636 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5554106116294861, 'Total loss': 0.5554106116294861} | train loss {'Reaction outcome loss': 0.16735470091540783, 'Total loss': 0.16735470091540783}
2023-01-04 22:51:37,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:37,636 INFO:     Epoch: 81
2023-01-04 22:51:39,904 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5950939575831096, 'Total loss': 0.5950939575831096} | train loss {'Reaction outcome loss': 0.1674552292677335, 'Total loss': 0.1674552292677335}
2023-01-04 22:51:39,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:39,906 INFO:     Epoch: 82
2023-01-04 22:51:42,178 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5594498902559281, 'Total loss': 0.5594498902559281} | train loss {'Reaction outcome loss': 0.16456380817998834, 'Total loss': 0.16456380817998834}
2023-01-04 22:51:42,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:42,179 INFO:     Epoch: 83
2023-01-04 22:51:44,455 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5828811128934225, 'Total loss': 0.5828811128934225} | train loss {'Reaction outcome loss': 0.16490372668931577, 'Total loss': 0.16490372668931577}
2023-01-04 22:51:44,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:44,455 INFO:     Epoch: 84
2023-01-04 22:51:46,724 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5863781491915385, 'Total loss': 0.5863781491915385} | train loss {'Reaction outcome loss': 0.1675686186989803, 'Total loss': 0.1675686186989803}
2023-01-04 22:51:46,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:46,726 INFO:     Epoch: 85
2023-01-04 22:51:48,983 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.6383429288864135, 'Total loss': 0.6383429288864135} | train loss {'Reaction outcome loss': 0.16724004049445856, 'Total loss': 0.16724004049445856}
2023-01-04 22:51:48,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:48,983 INFO:     Epoch: 86
2023-01-04 22:51:51,271 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5936897297700247, 'Total loss': 0.5936897297700247} | train loss {'Reaction outcome loss': 0.15949417653893683, 'Total loss': 0.15949417653893683}
2023-01-04 22:51:51,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:51,271 INFO:     Epoch: 87
2023-01-04 22:51:53,575 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.56593343714873, 'Total loss': 0.56593343714873} | train loss {'Reaction outcome loss': 0.16472849466195766, 'Total loss': 0.16472849466195766}
2023-01-04 22:51:53,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:53,576 INFO:     Epoch: 88
2023-01-04 22:51:55,840 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5744783222675324, 'Total loss': 0.5744783222675324} | train loss {'Reaction outcome loss': 0.15917646277793399, 'Total loss': 0.15917646277793399}
2023-01-04 22:51:55,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:55,841 INFO:     Epoch: 89
2023-01-04 22:51:58,091 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5651866475741069, 'Total loss': 0.5651866475741069} | train loss {'Reaction outcome loss': 0.16159532994489162, 'Total loss': 0.16159532994489162}
2023-01-04 22:51:58,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:51:58,093 INFO:     Epoch: 90
2023-01-04 22:52:00,352 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5704196035861969, 'Total loss': 0.5704196035861969} | train loss {'Reaction outcome loss': 0.15990341296722096, 'Total loss': 0.15990341296722096}
2023-01-04 22:52:00,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:00,352 INFO:     Epoch: 91
2023-01-04 22:52:02,638 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5707196791966757, 'Total loss': 0.5707196791966757} | train loss {'Reaction outcome loss': 0.1587108201431346, 'Total loss': 0.1587108201431346}
2023-01-04 22:52:02,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:02,638 INFO:     Epoch: 92
2023-01-04 22:52:04,930 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.6049461424350738, 'Total loss': 0.6049461424350738} | train loss {'Reaction outcome loss': 0.15803975270580273, 'Total loss': 0.15803975270580273}
2023-01-04 22:52:04,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:04,931 INFO:     Epoch: 93
2023-01-04 22:52:07,211 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5763922731081644, 'Total loss': 0.5763922731081644} | train loss {'Reaction outcome loss': 0.1544826383532667, 'Total loss': 0.1544826383532667}
2023-01-04 22:52:07,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:07,211 INFO:     Epoch: 94
2023-01-04 22:52:09,474 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5660268147786458, 'Total loss': 0.5660268147786458} | train loss {'Reaction outcome loss': 0.16041891197825275, 'Total loss': 0.16041891197825275}
2023-01-04 22:52:09,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:09,474 INFO:     Epoch: 95
2023-01-04 22:52:11,772 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5666393468777339, 'Total loss': 0.5666393468777339} | train loss {'Reaction outcome loss': 0.16012777353381394, 'Total loss': 0.16012777353381394}
2023-01-04 22:52:11,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:11,773 INFO:     Epoch: 96
2023-01-04 22:52:14,031 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5844302614529927, 'Total loss': 0.5844302614529927} | train loss {'Reaction outcome loss': 0.1558665173407308, 'Total loss': 0.1558665173407308}
2023-01-04 22:52:14,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:14,031 INFO:     Epoch: 97
2023-01-04 22:52:16,302 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.580122971534729, 'Total loss': 0.580122971534729} | train loss {'Reaction outcome loss': 0.15775103531845103, 'Total loss': 0.15775103531845103}
2023-01-04 22:52:16,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:16,303 INFO:     Epoch: 98
2023-01-04 22:52:18,548 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.547825135787328, 'Total loss': 0.547825135787328} | train loss {'Reaction outcome loss': 0.15632343747306762, 'Total loss': 0.15632343747306762}
2023-01-04 22:52:18,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:18,548 INFO:     Epoch: 99
2023-01-04 22:52:20,813 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.56039430697759, 'Total loss': 0.56039430697759} | train loss {'Reaction outcome loss': 0.15323368575935006, 'Total loss': 0.15323368575935006}
2023-01-04 22:52:20,813 INFO:     Best model found after epoch 20 of 100.
2023-01-04 22:52:20,813 INFO:   Done with stage: TRAINING
2023-01-04 22:52:20,813 INFO:   Starting stage: EVALUATION
2023-01-04 22:52:20,943 INFO:   Done with stage: EVALUATION
2023-01-04 22:52:20,943 INFO:   Leaving out SEQ value Fold_8
2023-01-04 22:52:20,955 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 22:52:20,956 INFO:   Starting stage: FEATURE SCALING
2023-01-04 22:52:21,616 INFO:   Done with stage: FEATURE SCALING
2023-01-04 22:52:21,616 INFO:   Starting stage: SCALING TARGETS
2023-01-04 22:52:21,688 INFO:   Done with stage: SCALING TARGETS
2023-01-04 22:52:21,688 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:52:21,689 INFO:     No hyperparam tuning for this model
2023-01-04 22:52:21,689 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:52:21,689 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 22:52:21,689 INFO:     None feature selector for col prot
2023-01-04 22:52:21,690 INFO:     None feature selector for col prot
2023-01-04 22:52:21,690 INFO:     None feature selector for col prot
2023-01-04 22:52:21,690 INFO:     None feature selector for col chem
2023-01-04 22:52:21,690 INFO:     None feature selector for col chem
2023-01-04 22:52:21,690 INFO:     None feature selector for col chem
2023-01-04 22:52:21,690 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 22:52:21,691 INFO:   Starting stage: BUILD MODEL
2023-01-04 22:52:21,693 INFO:     Number of params in model 72931
2023-01-04 22:52:21,696 INFO:   Done with stage: BUILD MODEL
2023-01-04 22:52:21,696 INFO:   Starting stage: TRAINING
2023-01-04 22:52:21,755 INFO:     Val loss before train {'Reaction outcome loss': 1.0752983649571737, 'Total loss': 1.0752983649571737}
2023-01-04 22:52:21,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:21,755 INFO:     Epoch: 0
2023-01-04 22:52:24,006 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8040139635403951, 'Total loss': 0.8040139635403951} | train loss {'Reaction outcome loss': 0.907841924092044, 'Total loss': 0.907841924092044}
2023-01-04 22:52:24,007 INFO:     Found new best model at epoch 0
2023-01-04 22:52:24,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:24,008 INFO:     Epoch: 1
2023-01-04 22:52:26,302 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6241881926854451, 'Total loss': 0.6241881926854451} | train loss {'Reaction outcome loss': 0.620889580876067, 'Total loss': 0.620889580876067}
2023-01-04 22:52:26,303 INFO:     Found new best model at epoch 1
2023-01-04 22:52:26,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:26,304 INFO:     Epoch: 2
2023-01-04 22:52:28,590 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5788901309172313, 'Total loss': 0.5788901309172313} | train loss {'Reaction outcome loss': 0.5234396206619947, 'Total loss': 0.5234396206619947}
2023-01-04 22:52:28,592 INFO:     Found new best model at epoch 2
2023-01-04 22:52:28,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:28,593 INFO:     Epoch: 3
2023-01-04 22:52:30,888 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5280397593975067, 'Total loss': 0.5280397593975067} | train loss {'Reaction outcome loss': 0.48008621035926585, 'Total loss': 0.48008621035926585}
2023-01-04 22:52:30,888 INFO:     Found new best model at epoch 3
2023-01-04 22:52:30,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:30,890 INFO:     Epoch: 4
2023-01-04 22:52:33,166 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5193960825602214, 'Total loss': 0.5193960825602214} | train loss {'Reaction outcome loss': 0.44615269355151965, 'Total loss': 0.44615269355151965}
2023-01-04 22:52:33,167 INFO:     Found new best model at epoch 4
2023-01-04 22:52:33,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:33,168 INFO:     Epoch: 5
2023-01-04 22:52:35,409 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4981333573659261, 'Total loss': 0.4981333573659261} | train loss {'Reaction outcome loss': 0.4217466117638717, 'Total loss': 0.4217466117638717}
2023-01-04 22:52:35,410 INFO:     Found new best model at epoch 5
2023-01-04 22:52:35,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:35,411 INFO:     Epoch: 6
2023-01-04 22:52:37,689 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5066332419713339, 'Total loss': 0.5066332419713339} | train loss {'Reaction outcome loss': 0.4031506439373977, 'Total loss': 0.4031506439373977}
2023-01-04 22:52:37,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:37,689 INFO:     Epoch: 7
2023-01-04 22:52:39,951 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4923038164774577, 'Total loss': 0.4923038164774577} | train loss {'Reaction outcome loss': 0.390133423352803, 'Total loss': 0.390133423352803}
2023-01-04 22:52:39,952 INFO:     Found new best model at epoch 7
2023-01-04 22:52:39,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:39,953 INFO:     Epoch: 8
2023-01-04 22:52:42,234 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49018436670303345, 'Total loss': 0.49018436670303345} | train loss {'Reaction outcome loss': 0.37427060318219924, 'Total loss': 0.37427060318219924}
2023-01-04 22:52:42,234 INFO:     Found new best model at epoch 8
2023-01-04 22:52:42,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:42,236 INFO:     Epoch: 9
2023-01-04 22:52:44,484 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4908384283383687, 'Total loss': 0.4908384283383687} | train loss {'Reaction outcome loss': 0.363588831720678, 'Total loss': 0.363588831720678}
2023-01-04 22:52:44,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:44,484 INFO:     Epoch: 10
2023-01-04 22:52:46,741 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4851394196351369, 'Total loss': 0.4851394196351369} | train loss {'Reaction outcome loss': 0.3538533294382775, 'Total loss': 0.3538533294382775}
2023-01-04 22:52:46,742 INFO:     Found new best model at epoch 10
2023-01-04 22:52:46,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:46,743 INFO:     Epoch: 11
2023-01-04 22:52:48,987 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4707319810986519, 'Total loss': 0.4707319810986519} | train loss {'Reaction outcome loss': 0.34453635329745064, 'Total loss': 0.34453635329745064}
2023-01-04 22:52:48,988 INFO:     Found new best model at epoch 11
2023-01-04 22:52:48,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:48,989 INFO:     Epoch: 12
2023-01-04 22:52:51,282 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48345561226209005, 'Total loss': 0.48345561226209005} | train loss {'Reaction outcome loss': 0.3370558417307726, 'Total loss': 0.3370558417307726}
2023-01-04 22:52:51,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:51,282 INFO:     Epoch: 13
2023-01-04 22:52:53,555 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49100895126660665, 'Total loss': 0.49100895126660665} | train loss {'Reaction outcome loss': 0.3229091958327563, 'Total loss': 0.3229091958327563}
2023-01-04 22:52:53,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:53,556 INFO:     Epoch: 14
2023-01-04 22:52:55,778 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4889042576154073, 'Total loss': 0.4889042576154073} | train loss {'Reaction outcome loss': 0.3184745736568626, 'Total loss': 0.3184745736568626}
2023-01-04 22:52:55,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:55,778 INFO:     Epoch: 15
2023-01-04 22:52:58,025 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4888712366422017, 'Total loss': 0.4888712366422017} | train loss {'Reaction outcome loss': 0.31460719365302636, 'Total loss': 0.31460719365302636}
2023-01-04 22:52:58,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:52:58,025 INFO:     Epoch: 16
2023-01-04 22:53:00,306 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4721357047557831, 'Total loss': 0.4721357047557831} | train loss {'Reaction outcome loss': 0.3089595775683478, 'Total loss': 0.3089595775683478}
2023-01-04 22:53:00,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:00,307 INFO:     Epoch: 17
2023-01-04 22:53:02,574 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47838368515173596, 'Total loss': 0.47838368515173596} | train loss {'Reaction outcome loss': 0.29815970067832404, 'Total loss': 0.29815970067832404}
2023-01-04 22:53:02,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:02,574 INFO:     Epoch: 18
2023-01-04 22:53:04,849 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4923887173334757, 'Total loss': 0.4923887173334757} | train loss {'Reaction outcome loss': 0.2929444506880827, 'Total loss': 0.2929444506880827}
2023-01-04 22:53:04,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:04,850 INFO:     Epoch: 19
2023-01-04 22:53:07,115 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47345375021298725, 'Total loss': 0.47345375021298725} | train loss {'Reaction outcome loss': 0.2857743111141473, 'Total loss': 0.2857743111141473}
2023-01-04 22:53:07,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:07,117 INFO:     Epoch: 20
2023-01-04 22:53:09,391 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4765781859556834, 'Total loss': 0.4765781859556834} | train loss {'Reaction outcome loss': 0.27916037804464827, 'Total loss': 0.27916037804464827}
2023-01-04 22:53:09,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:09,391 INFO:     Epoch: 21
2023-01-04 22:53:11,656 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48552613059679667, 'Total loss': 0.48552613059679667} | train loss {'Reaction outcome loss': 0.2805077416309412, 'Total loss': 0.2805077416309412}
2023-01-04 22:53:11,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:11,656 INFO:     Epoch: 22
2023-01-04 22:53:13,930 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4814498707652092, 'Total loss': 0.4814498707652092} | train loss {'Reaction outcome loss': 0.2930194236553465, 'Total loss': 0.2930194236553465}
2023-01-04 22:53:13,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:13,931 INFO:     Epoch: 23
2023-01-04 22:53:16,213 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4975246359904607, 'Total loss': 0.4975246359904607} | train loss {'Reaction outcome loss': 0.2702563966664931, 'Total loss': 0.2702563966664931}
2023-01-04 22:53:16,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:16,214 INFO:     Epoch: 24
2023-01-04 22:53:18,468 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5122705241044362, 'Total loss': 0.5122705241044362} | train loss {'Reaction outcome loss': 0.26800090062391496, 'Total loss': 0.26800090062391496}
2023-01-04 22:53:18,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:18,469 INFO:     Epoch: 25
2023-01-04 22:53:20,746 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4973948270082474, 'Total loss': 0.4973948270082474} | train loss {'Reaction outcome loss': 0.2825602915102575, 'Total loss': 0.2825602915102575}
2023-01-04 22:53:20,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:20,746 INFO:     Epoch: 26
2023-01-04 22:53:22,987 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4842612385749817, 'Total loss': 0.4842612385749817} | train loss {'Reaction outcome loss': 0.2615551599778553, 'Total loss': 0.2615551599778553}
2023-01-04 22:53:22,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:22,988 INFO:     Epoch: 27
2023-01-04 22:53:25,269 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4602286328872045, 'Total loss': 0.4602286328872045} | train loss {'Reaction outcome loss': 0.2493683044069811, 'Total loss': 0.2493683044069811}
2023-01-04 22:53:25,270 INFO:     Found new best model at epoch 27
2023-01-04 22:53:25,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:25,272 INFO:     Epoch: 28
2023-01-04 22:53:27,539 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48453323741753895, 'Total loss': 0.48453323741753895} | train loss {'Reaction outcome loss': 0.25109722754722746, 'Total loss': 0.25109722754722746}
2023-01-04 22:53:27,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:27,539 INFO:     Epoch: 29
2023-01-04 22:53:29,803 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47451735387245814, 'Total loss': 0.47451735387245814} | train loss {'Reaction outcome loss': 0.25087985062745627, 'Total loss': 0.25087985062745627}
2023-01-04 22:53:29,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:29,805 INFO:     Epoch: 30
2023-01-04 22:53:32,069 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4653335799773534, 'Total loss': 0.4653335799773534} | train loss {'Reaction outcome loss': 0.24238675724073022, 'Total loss': 0.24238675724073022}
2023-01-04 22:53:32,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:32,070 INFO:     Epoch: 31
2023-01-04 22:53:34,333 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4855042946835359, 'Total loss': 0.4855042946835359} | train loss {'Reaction outcome loss': 0.24266143475213778, 'Total loss': 0.24266143475213778}
2023-01-04 22:53:34,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:34,334 INFO:     Epoch: 32
2023-01-04 22:53:36,566 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49586562514305116, 'Total loss': 0.49586562514305116} | train loss {'Reaction outcome loss': 0.24078937398904152, 'Total loss': 0.24078937398904152}
2023-01-04 22:53:36,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:36,567 INFO:     Epoch: 33
2023-01-04 22:53:38,852 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4810205707947413, 'Total loss': 0.4810205707947413} | train loss {'Reaction outcome loss': 0.24435512058814798, 'Total loss': 0.24435512058814798}
2023-01-04 22:53:38,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:38,852 INFO:     Epoch: 34
2023-01-04 22:53:41,130 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4721542497475942, 'Total loss': 0.4721542497475942} | train loss {'Reaction outcome loss': 0.2542685438817463, 'Total loss': 0.2542685438817463}
2023-01-04 22:53:41,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:41,130 INFO:     Epoch: 35
2023-01-04 22:53:43,385 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4724347134431203, 'Total loss': 0.4724347134431203} | train loss {'Reaction outcome loss': 0.23401625103830104, 'Total loss': 0.23401625103830104}
2023-01-04 22:53:43,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:43,387 INFO:     Epoch: 36
2023-01-04 22:53:45,629 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.48698765436808267, 'Total loss': 0.48698765436808267} | train loss {'Reaction outcome loss': 0.2323827643008042, 'Total loss': 0.2323827643008042}
2023-01-04 22:53:45,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:45,629 INFO:     Epoch: 37
2023-01-04 22:53:47,871 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.473900314172109, 'Total loss': 0.473900314172109} | train loss {'Reaction outcome loss': 0.252680413370979, 'Total loss': 0.252680413370979}
2023-01-04 22:53:47,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:47,872 INFO:     Epoch: 38
2023-01-04 22:53:50,154 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4754155193765958, 'Total loss': 0.4754155193765958} | train loss {'Reaction outcome loss': 0.2637808107015123, 'Total loss': 0.2637808107015123}
2023-01-04 22:53:50,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:50,154 INFO:     Epoch: 39
2023-01-04 22:53:52,430 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49888647397359215, 'Total loss': 0.49888647397359215} | train loss {'Reaction outcome loss': 0.22384362387389917, 'Total loss': 0.22384362387389917}
2023-01-04 22:53:52,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:52,430 INFO:     Epoch: 40
2023-01-04 22:53:54,676 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44373902181784314, 'Total loss': 0.44373902181784314} | train loss {'Reaction outcome loss': 0.2237844935365686, 'Total loss': 0.2237844935365686}
2023-01-04 22:53:54,677 INFO:     Found new best model at epoch 40
2023-01-04 22:53:54,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:54,678 INFO:     Epoch: 41
2023-01-04 22:53:56,939 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4899013236165047, 'Total loss': 0.4899013236165047} | train loss {'Reaction outcome loss': 0.21916775464816726, 'Total loss': 0.21916775464816726}
2023-01-04 22:53:56,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:56,939 INFO:     Epoch: 42
2023-01-04 22:53:59,231 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48912430703639986, 'Total loss': 0.48912430703639986} | train loss {'Reaction outcome loss': 0.21611665183329445, 'Total loss': 0.21611665183329445}
2023-01-04 22:53:59,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:53:59,231 INFO:     Epoch: 43
2023-01-04 22:54:01,512 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4775549590587616, 'Total loss': 0.4775549590587616} | train loss {'Reaction outcome loss': 0.2135343156721741, 'Total loss': 0.2135343156721741}
2023-01-04 22:54:01,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:01,513 INFO:     Epoch: 44
2023-01-04 22:54:03,799 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4743343532085419, 'Total loss': 0.4743343532085419} | train loss {'Reaction outcome loss': 0.21326985757569597, 'Total loss': 0.21326985757569597}
2023-01-04 22:54:03,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:03,800 INFO:     Epoch: 45
2023-01-04 22:54:06,068 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4406398147344589, 'Total loss': 0.4406398147344589} | train loss {'Reaction outcome loss': 0.21312336415555194, 'Total loss': 0.21312336415555194}
2023-01-04 22:54:06,069 INFO:     Found new best model at epoch 45
2023-01-04 22:54:06,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:06,071 INFO:     Epoch: 46
2023-01-04 22:54:08,193 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4791775017976761, 'Total loss': 0.4791775017976761} | train loss {'Reaction outcome loss': 0.21068631372279437, 'Total loss': 0.21068631372279437}
2023-01-04 22:54:08,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:08,193 INFO:     Epoch: 47
2023-01-04 22:54:10,481 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4736358970403671, 'Total loss': 0.4736358970403671} | train loss {'Reaction outcome loss': 0.20489861128052048, 'Total loss': 0.20489861128052048}
2023-01-04 22:54:10,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:10,482 INFO:     Epoch: 48
2023-01-04 22:54:12,798 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45264769295851387, 'Total loss': 0.45264769295851387} | train loss {'Reaction outcome loss': 0.20783476260276626, 'Total loss': 0.20783476260276626}
2023-01-04 22:54:12,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:12,799 INFO:     Epoch: 49
2023-01-04 22:54:15,091 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4955791195233663, 'Total loss': 0.4955791195233663} | train loss {'Reaction outcome loss': 0.20552828753231248, 'Total loss': 0.20552828753231248}
2023-01-04 22:54:15,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:15,091 INFO:     Epoch: 50
2023-01-04 22:54:17,341 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4786220649878184, 'Total loss': 0.4786220649878184} | train loss {'Reaction outcome loss': 0.20163177264570867, 'Total loss': 0.20163177264570867}
2023-01-04 22:54:17,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:17,341 INFO:     Epoch: 51
2023-01-04 22:54:19,621 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4729392791787783, 'Total loss': 0.4729392791787783} | train loss {'Reaction outcome loss': 0.20020324428206432, 'Total loss': 0.20020324428206432}
2023-01-04 22:54:19,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:19,623 INFO:     Epoch: 52
2023-01-04 22:54:21,907 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4916824191808701, 'Total loss': 0.4916824191808701} | train loss {'Reaction outcome loss': 0.1966982905405398, 'Total loss': 0.1966982905405398}
2023-01-04 22:54:21,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:21,907 INFO:     Epoch: 53
2023-01-04 22:54:24,185 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48744043509165447, 'Total loss': 0.48744043509165447} | train loss {'Reaction outcome loss': 0.19964396368469234, 'Total loss': 0.19964396368469234}
2023-01-04 22:54:24,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:24,186 INFO:     Epoch: 54
2023-01-04 22:54:26,465 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48817370732625326, 'Total loss': 0.48817370732625326} | train loss {'Reaction outcome loss': 0.19946146426735906, 'Total loss': 0.19946146426735906}
2023-01-04 22:54:26,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:26,466 INFO:     Epoch: 55
2023-01-04 22:54:28,705 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45426657994588215, 'Total loss': 0.45426657994588215} | train loss {'Reaction outcome loss': 0.19975889553282195, 'Total loss': 0.19975889553282195}
2023-01-04 22:54:28,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:28,705 INFO:     Epoch: 56
2023-01-04 22:54:30,980 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48178790807724, 'Total loss': 0.48178790807724} | train loss {'Reaction outcome loss': 0.19810736959418823, 'Total loss': 0.19810736959418823}
2023-01-04 22:54:30,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:30,982 INFO:     Epoch: 57
2023-01-04 22:54:33,242 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48356427550315856, 'Total loss': 0.48356427550315856} | train loss {'Reaction outcome loss': 0.1948379080766218, 'Total loss': 0.1948379080766218}
2023-01-04 22:54:33,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:33,242 INFO:     Epoch: 58
2023-01-04 22:54:35,518 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4718595484892527, 'Total loss': 0.4718595484892527} | train loss {'Reaction outcome loss': 0.192321111869482, 'Total loss': 0.192321111869482}
2023-01-04 22:54:35,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:35,519 INFO:     Epoch: 59
2023-01-04 22:54:37,818 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48199008305867513, 'Total loss': 0.48199008305867513} | train loss {'Reaction outcome loss': 0.18841796638836336, 'Total loss': 0.18841796638836336}
2023-01-04 22:54:37,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:37,818 INFO:     Epoch: 60
2023-01-04 22:54:40,125 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4815413991610209, 'Total loss': 0.4815413991610209} | train loss {'Reaction outcome loss': 0.1924751918438984, 'Total loss': 0.1924751918438984}
2023-01-04 22:54:40,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:40,125 INFO:     Epoch: 61
2023-01-04 22:54:42,448 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4470160742600759, 'Total loss': 0.4470160742600759} | train loss {'Reaction outcome loss': 0.18369201540653246, 'Total loss': 0.18369201540653246}
2023-01-04 22:54:42,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:42,449 INFO:     Epoch: 62
2023-01-04 22:54:44,720 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.517919905980428, 'Total loss': 0.517919905980428} | train loss {'Reaction outcome loss': 0.19024791218251505, 'Total loss': 0.19024791218251505}
2023-01-04 22:54:44,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:44,720 INFO:     Epoch: 63
2023-01-04 22:54:46,921 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4811276584863663, 'Total loss': 0.4811276584863663} | train loss {'Reaction outcome loss': 0.18958884741468995, 'Total loss': 0.18958884741468995}
2023-01-04 22:54:46,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:46,921 INFO:     Epoch: 64
2023-01-04 22:54:49,196 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.48924266795317334, 'Total loss': 0.48924266795317334} | train loss {'Reaction outcome loss': 0.19075290684628746, 'Total loss': 0.19075290684628746}
2023-01-04 22:54:49,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:49,197 INFO:     Epoch: 65
2023-01-04 22:54:51,384 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5168392479419708, 'Total loss': 0.5168392479419708} | train loss {'Reaction outcome loss': 0.22970121577584549, 'Total loss': 0.22970121577584549}
2023-01-04 22:54:51,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:51,385 INFO:     Epoch: 66
2023-01-04 22:54:53,337 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4786793768405914, 'Total loss': 0.4786793768405914} | train loss {'Reaction outcome loss': 0.19412021300809432, 'Total loss': 0.19412021300809432}
2023-01-04 22:54:53,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:53,337 INFO:     Epoch: 67
2023-01-04 22:54:55,185 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47884493072827655, 'Total loss': 0.47884493072827655} | train loss {'Reaction outcome loss': 0.18547063856048213, 'Total loss': 0.18547063856048213}
2023-01-04 22:54:55,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:55,187 INFO:     Epoch: 68
2023-01-04 22:54:57,235 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46251903772354125, 'Total loss': 0.46251903772354125} | train loss {'Reaction outcome loss': 0.18239558925763272, 'Total loss': 0.18239558925763272}
2023-01-04 22:54:57,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:57,235 INFO:     Epoch: 69
2023-01-04 22:54:59,478 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46986329754193623, 'Total loss': 0.46986329754193623} | train loss {'Reaction outcome loss': 0.1849821807172966, 'Total loss': 0.1849821807172966}
2023-01-04 22:54:59,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:54:59,478 INFO:     Epoch: 70
2023-01-04 22:55:01,734 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.49339683800935746, 'Total loss': 0.49339683800935746} | train loss {'Reaction outcome loss': 0.1828196166653483, 'Total loss': 0.1828196166653483}
2023-01-04 22:55:01,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:01,735 INFO:     Epoch: 71
2023-01-04 22:55:04,021 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4677511458595594, 'Total loss': 0.4677511458595594} | train loss {'Reaction outcome loss': 0.18031307343482986, 'Total loss': 0.18031307343482986}
2023-01-04 22:55:04,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:04,021 INFO:     Epoch: 72
2023-01-04 22:55:06,298 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47367735719308257, 'Total loss': 0.47367735719308257} | train loss {'Reaction outcome loss': 0.17704472714356836, 'Total loss': 0.17704472714356836}
2023-01-04 22:55:06,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:06,299 INFO:     Epoch: 73
2023-01-04 22:55:08,559 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47046745717525484, 'Total loss': 0.47046745717525484} | train loss {'Reaction outcome loss': 0.17756019157834246, 'Total loss': 0.17756019157834246}
2023-01-04 22:55:08,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:08,559 INFO:     Epoch: 74
2023-01-04 22:55:10,840 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49511123100916543, 'Total loss': 0.49511123100916543} | train loss {'Reaction outcome loss': 0.18126826944922947, 'Total loss': 0.18126826944922947}
2023-01-04 22:55:10,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:10,840 INFO:     Epoch: 75
2023-01-04 22:55:13,132 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48318399786949157, 'Total loss': 0.48318399786949157} | train loss {'Reaction outcome loss': 0.1836618024845729, 'Total loss': 0.1836618024845729}
2023-01-04 22:55:13,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:13,133 INFO:     Epoch: 76
2023-01-04 22:55:15,419 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48467785914738976, 'Total loss': 0.48467785914738976} | train loss {'Reaction outcome loss': 0.17329548037958084, 'Total loss': 0.17329548037958084}
2023-01-04 22:55:15,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:15,419 INFO:     Epoch: 77
2023-01-04 22:55:17,683 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4963747670253118, 'Total loss': 0.4963747670253118} | train loss {'Reaction outcome loss': 0.1796915227415688, 'Total loss': 0.1796915227415688}
2023-01-04 22:55:17,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:17,683 INFO:     Epoch: 78
2023-01-04 22:55:19,943 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47715527017911274, 'Total loss': 0.47715527017911274} | train loss {'Reaction outcome loss': 0.17762042454146929, 'Total loss': 0.17762042454146929}
2023-01-04 22:55:19,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:19,944 INFO:     Epoch: 79
2023-01-04 22:55:22,157 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4921603431304296, 'Total loss': 0.4921603431304296} | train loss {'Reaction outcome loss': 0.17627194267582957, 'Total loss': 0.17627194267582957}
2023-01-04 22:55:22,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:22,158 INFO:     Epoch: 80
2023-01-04 22:55:24,437 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4884779055913289, 'Total loss': 0.4884779055913289} | train loss {'Reaction outcome loss': 0.1712651646129139, 'Total loss': 0.1712651646129139}
2023-01-04 22:55:24,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:24,438 INFO:     Epoch: 81
2023-01-04 22:55:26,713 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.521283874909083, 'Total loss': 0.521283874909083} | train loss {'Reaction outcome loss': 0.17069777084821064, 'Total loss': 0.17069777084821064}
2023-01-04 22:55:26,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:26,713 INFO:     Epoch: 82
2023-01-04 22:55:28,936 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4809119671583176, 'Total loss': 0.4809119671583176} | train loss {'Reaction outcome loss': 0.17609201645498854, 'Total loss': 0.17609201645498854}
2023-01-04 22:55:28,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:28,936 INFO:     Epoch: 83
2023-01-04 22:55:31,113 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4825952450434367, 'Total loss': 0.4825952450434367} | train loss {'Reaction outcome loss': 0.17046158235663258, 'Total loss': 0.17046158235663258}
2023-01-04 22:55:31,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:31,114 INFO:     Epoch: 84
2023-01-04 22:55:33,306 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4959264963554839, 'Total loss': 0.4959264963554839} | train loss {'Reaction outcome loss': 0.1741745163673076, 'Total loss': 0.1741745163673076}
2023-01-04 22:55:33,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:33,307 INFO:     Epoch: 85
2023-01-04 22:55:35,502 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5077716449896494, 'Total loss': 0.5077716449896494} | train loss {'Reaction outcome loss': 0.17501908841697275, 'Total loss': 0.17501908841697275}
2023-01-04 22:55:35,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:35,502 INFO:     Epoch: 86
2023-01-04 22:55:37,770 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4805658181508382, 'Total loss': 0.4805658181508382} | train loss {'Reaction outcome loss': 0.1716638131655982, 'Total loss': 0.1716638131655982}
2023-01-04 22:55:37,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:37,771 INFO:     Epoch: 87
2023-01-04 22:55:40,039 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4875587490697702, 'Total loss': 0.4875587490697702} | train loss {'Reaction outcome loss': 0.17018190762652355, 'Total loss': 0.17018190762652355}
2023-01-04 22:55:40,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:40,040 INFO:     Epoch: 88
2023-01-04 22:55:42,233 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5146464884281159, 'Total loss': 0.5146464884281159} | train loss {'Reaction outcome loss': 0.17317851897889236, 'Total loss': 0.17317851897889236}
2023-01-04 22:55:42,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:42,233 INFO:     Epoch: 89
2023-01-04 22:55:44,510 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4919261078039805, 'Total loss': 0.4919261078039805} | train loss {'Reaction outcome loss': 0.172323643174014, 'Total loss': 0.172323643174014}
2023-01-04 22:55:44,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:44,511 INFO:     Epoch: 90
2023-01-04 22:55:46,814 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48252567648887634, 'Total loss': 0.48252567648887634} | train loss {'Reaction outcome loss': 0.17194111008633417, 'Total loss': 0.17194111008633417}
2023-01-04 22:55:46,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:46,814 INFO:     Epoch: 91
2023-01-04 22:55:49,108 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5099513779083887, 'Total loss': 0.5099513779083887} | train loss {'Reaction outcome loss': 0.16988508711854566, 'Total loss': 0.16988508711854566}
2023-01-04 22:55:49,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:49,110 INFO:     Epoch: 92
2023-01-04 22:55:51,412 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5197860757509868, 'Total loss': 0.5197860757509868} | train loss {'Reaction outcome loss': 0.17108819814208234, 'Total loss': 0.17108819814208234}
2023-01-04 22:55:51,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:51,412 INFO:     Epoch: 93
2023-01-04 22:55:53,587 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49976565341154733, 'Total loss': 0.49976565341154733} | train loss {'Reaction outcome loss': 0.16738375054294433, 'Total loss': 0.16738375054294433}
2023-01-04 22:55:53,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:53,587 INFO:     Epoch: 94
2023-01-04 22:55:55,839 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.49573976596196495, 'Total loss': 0.49573976596196495} | train loss {'Reaction outcome loss': 0.16727170823614343, 'Total loss': 0.16727170823614343}
2023-01-04 22:55:55,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:55,840 INFO:     Epoch: 95
2023-01-04 22:55:58,134 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4838869422674179, 'Total loss': 0.4838869422674179} | train loss {'Reaction outcome loss': 0.1659983128796001, 'Total loss': 0.1659983128796001}
2023-01-04 22:55:58,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:55:58,134 INFO:     Epoch: 96
2023-01-04 22:56:00,414 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.518419498205185, 'Total loss': 0.518419498205185} | train loss {'Reaction outcome loss': 0.16406742721353995, 'Total loss': 0.16406742721353995}
2023-01-04 22:56:00,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:00,415 INFO:     Epoch: 97
2023-01-04 22:56:02,706 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48219716747601826, 'Total loss': 0.48219716747601826} | train loss {'Reaction outcome loss': 0.16288035469588594, 'Total loss': 0.16288035469588594}
2023-01-04 22:56:02,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:02,707 INFO:     Epoch: 98
2023-01-04 22:56:04,961 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4866662154595057, 'Total loss': 0.4866662154595057} | train loss {'Reaction outcome loss': 0.16569400077645222, 'Total loss': 0.16569400077645222}
2023-01-04 22:56:04,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:04,961 INFO:     Epoch: 99
2023-01-04 22:56:07,234 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4775019735097885, 'Total loss': 0.4775019735097885} | train loss {'Reaction outcome loss': 0.16409872391913255, 'Total loss': 0.16409872391913255}
2023-01-04 22:56:07,234 INFO:     Best model found after epoch 46 of 100.
2023-01-04 22:56:07,234 INFO:   Done with stage: TRAINING
2023-01-04 22:56:07,234 INFO:   Starting stage: EVALUATION
2023-01-04 22:56:07,371 INFO:   Done with stage: EVALUATION
2023-01-04 22:56:07,372 INFO:   Leaving out SEQ value Fold_9
2023-01-04 22:56:07,384 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 22:56:07,384 INFO:   Starting stage: FEATURE SCALING
2023-01-04 22:56:08,047 INFO:   Done with stage: FEATURE SCALING
2023-01-04 22:56:08,047 INFO:   Starting stage: SCALING TARGETS
2023-01-04 22:56:08,118 INFO:   Done with stage: SCALING TARGETS
2023-01-04 22:56:08,118 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:56:08,118 INFO:     No hyperparam tuning for this model
2023-01-04 22:56:08,118 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:56:08,118 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 22:56:08,119 INFO:     None feature selector for col prot
2023-01-04 22:56:08,119 INFO:     None feature selector for col prot
2023-01-04 22:56:08,119 INFO:     None feature selector for col prot
2023-01-04 22:56:08,120 INFO:     None feature selector for col chem
2023-01-04 22:56:08,120 INFO:     None feature selector for col chem
2023-01-04 22:56:08,120 INFO:     None feature selector for col chem
2023-01-04 22:56:08,120 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 22:56:08,120 INFO:   Starting stage: BUILD MODEL
2023-01-04 22:56:08,122 INFO:     Number of params in model 72931
2023-01-04 22:56:08,125 INFO:   Done with stage: BUILD MODEL
2023-01-04 22:56:08,125 INFO:   Starting stage: TRAINING
2023-01-04 22:56:08,186 INFO:     Val loss before train {'Reaction outcome loss': 0.9835253675778707, 'Total loss': 0.9835253675778707}
2023-01-04 22:56:08,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:08,187 INFO:     Epoch: 0
2023-01-04 22:56:10,496 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7387048244476319, 'Total loss': 0.7387048244476319} | train loss {'Reaction outcome loss': 0.9462795775074391, 'Total loss': 0.9462795775074391}
2023-01-04 22:56:10,497 INFO:     Found new best model at epoch 0
2023-01-04 22:56:10,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:10,498 INFO:     Epoch: 1
2023-01-04 22:56:12,797 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5700938403606415, 'Total loss': 0.5700938403606415} | train loss {'Reaction outcome loss': 0.6395516412783185, 'Total loss': 0.6395516412783185}
2023-01-04 22:56:12,797 INFO:     Found new best model at epoch 1
2023-01-04 22:56:12,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:12,799 INFO:     Epoch: 2
2023-01-04 22:56:15,066 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5130373716354371, 'Total loss': 0.5130373716354371} | train loss {'Reaction outcome loss': 0.5486961637055401, 'Total loss': 0.5486961637055401}
2023-01-04 22:56:15,068 INFO:     Found new best model at epoch 2
2023-01-04 22:56:15,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:15,069 INFO:     Epoch: 3
2023-01-04 22:56:17,323 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49591492811838783, 'Total loss': 0.49591492811838783} | train loss {'Reaction outcome loss': 0.505914209713144, 'Total loss': 0.505914209713144}
2023-01-04 22:56:17,323 INFO:     Found new best model at epoch 3
2023-01-04 22:56:17,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:17,325 INFO:     Epoch: 4
2023-01-04 22:56:19,546 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.467172513405482, 'Total loss': 0.467172513405482} | train loss {'Reaction outcome loss': 0.47203414787669473, 'Total loss': 0.47203414787669473}
2023-01-04 22:56:19,546 INFO:     Found new best model at epoch 4
2023-01-04 22:56:19,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:19,547 INFO:     Epoch: 5
2023-01-04 22:56:21,839 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4387440592050552, 'Total loss': 0.4387440592050552} | train loss {'Reaction outcome loss': 0.45486253811994615, 'Total loss': 0.45486253811994615}
2023-01-04 22:56:21,840 INFO:     Found new best model at epoch 5
2023-01-04 22:56:21,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:21,841 INFO:     Epoch: 6
2023-01-04 22:56:24,126 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.41830509901046753, 'Total loss': 0.41830509901046753} | train loss {'Reaction outcome loss': 0.4297710216002344, 'Total loss': 0.4297710216002344}
2023-01-04 22:56:24,126 INFO:     Found new best model at epoch 6
2023-01-04 22:56:24,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:24,127 INFO:     Epoch: 7
2023-01-04 22:56:26,411 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4082747538884481, 'Total loss': 0.4082747538884481} | train loss {'Reaction outcome loss': 0.4138475542733385, 'Total loss': 0.4138475542733385}
2023-01-04 22:56:26,413 INFO:     Found new best model at epoch 7
2023-01-04 22:56:26,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:26,414 INFO:     Epoch: 8
2023-01-04 22:56:28,708 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4185022960106532, 'Total loss': 0.4185022960106532} | train loss {'Reaction outcome loss': 0.40155124051045854, 'Total loss': 0.40155124051045854}
2023-01-04 22:56:28,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:28,708 INFO:     Epoch: 9
2023-01-04 22:56:30,950 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4104697744051615, 'Total loss': 0.4104697744051615} | train loss {'Reaction outcome loss': 0.3892488978964542, 'Total loss': 0.3892488978964542}
2023-01-04 22:56:30,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:30,951 INFO:     Epoch: 10
2023-01-04 22:56:33,229 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3988907968004545, 'Total loss': 0.3988907968004545} | train loss {'Reaction outcome loss': 0.3777538127255784, 'Total loss': 0.3777538127255784}
2023-01-04 22:56:33,230 INFO:     Found new best model at epoch 10
2023-01-04 22:56:33,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:33,231 INFO:     Epoch: 11
2023-01-04 22:56:35,487 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4030952344338099, 'Total loss': 0.4030952344338099} | train loss {'Reaction outcome loss': 0.36934591484145135, 'Total loss': 0.36934591484145135}
2023-01-04 22:56:35,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:35,487 INFO:     Epoch: 12
2023-01-04 22:56:37,773 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3928818615774314, 'Total loss': 0.3928818615774314} | train loss {'Reaction outcome loss': 0.3600010663432335, 'Total loss': 0.3600010663432335}
2023-01-04 22:56:37,773 INFO:     Found new best model at epoch 12
2023-01-04 22:56:37,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:37,775 INFO:     Epoch: 13
2023-01-04 22:56:40,045 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4109608332316081, 'Total loss': 0.4109608332316081} | train loss {'Reaction outcome loss': 0.35213417075708886, 'Total loss': 0.35213417075708886}
2023-01-04 22:56:40,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:40,046 INFO:     Epoch: 14
2023-01-04 22:56:42,286 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4123014112313588, 'Total loss': 0.4123014112313588} | train loss {'Reaction outcome loss': 0.3439219487084594, 'Total loss': 0.3439219487084594}
2023-01-04 22:56:42,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:42,286 INFO:     Epoch: 15
2023-01-04 22:56:44,566 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4239676892757416, 'Total loss': 0.4239676892757416} | train loss {'Reaction outcome loss': 0.3333458216988653, 'Total loss': 0.3333458216988653}
2023-01-04 22:56:44,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:44,568 INFO:     Epoch: 16
2023-01-04 22:56:46,844 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.402409029006958, 'Total loss': 0.402409029006958} | train loss {'Reaction outcome loss': 0.33092847746201803, 'Total loss': 0.33092847746201803}
2023-01-04 22:56:46,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:46,844 INFO:     Epoch: 17
2023-01-04 22:56:49,089 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3930389225482941, 'Total loss': 0.3930389225482941} | train loss {'Reaction outcome loss': 0.31678378803904306, 'Total loss': 0.31678378803904306}
2023-01-04 22:56:49,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:49,090 INFO:     Epoch: 18
2023-01-04 22:56:51,341 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4079935948053996, 'Total loss': 0.4079935948053996} | train loss {'Reaction outcome loss': 0.3194216873886783, 'Total loss': 0.3194216873886783}
2023-01-04 22:56:51,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:51,343 INFO:     Epoch: 19
2023-01-04 22:56:53,595 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4004051168759664, 'Total loss': 0.4004051168759664} | train loss {'Reaction outcome loss': 0.3090302646698074, 'Total loss': 0.3090302646698074}
2023-01-04 22:56:53,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:53,596 INFO:     Epoch: 20
2023-01-04 22:56:55,901 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41700620353221896, 'Total loss': 0.41700620353221896} | train loss {'Reaction outcome loss': 0.2990688099139219, 'Total loss': 0.2990688099139219}
2023-01-04 22:56:55,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:55,901 INFO:     Epoch: 21
2023-01-04 22:56:58,210 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.37955992768208185, 'Total loss': 0.37955992768208185} | train loss {'Reaction outcome loss': 0.29681104190297936, 'Total loss': 0.29681104190297936}
2023-01-04 22:56:58,211 INFO:     Found new best model at epoch 21
2023-01-04 22:56:58,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:56:58,213 INFO:     Epoch: 22
2023-01-04 22:57:00,524 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39804467856884, 'Total loss': 0.39804467856884} | train loss {'Reaction outcome loss': 0.28968900829446015, 'Total loss': 0.28968900829446015}
2023-01-04 22:57:00,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:00,524 INFO:     Epoch: 23
2023-01-04 22:57:02,808 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.38989486296971637, 'Total loss': 0.38989486296971637} | train loss {'Reaction outcome loss': 0.2842811335295116, 'Total loss': 0.2842811335295116}
2023-01-04 22:57:02,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:02,810 INFO:     Epoch: 24
2023-01-04 22:57:05,018 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39066399236520133, 'Total loss': 0.39066399236520133} | train loss {'Reaction outcome loss': 0.28270669187341785, 'Total loss': 0.28270669187341785}
2023-01-04 22:57:05,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:05,018 INFO:     Epoch: 25
2023-01-04 22:57:07,306 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4086955567200979, 'Total loss': 0.4086955567200979} | train loss {'Reaction outcome loss': 0.27529692859641053, 'Total loss': 0.27529692859641053}
2023-01-04 22:57:07,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:07,306 INFO:     Epoch: 26
2023-01-04 22:57:09,529 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39409331580003104, 'Total loss': 0.39409331580003104} | train loss {'Reaction outcome loss': 0.27610848783532205, 'Total loss': 0.27610848783532205}
2023-01-04 22:57:09,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:09,530 INFO:     Epoch: 27
2023-01-04 22:57:11,823 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41363580028216046, 'Total loss': 0.41363580028216046} | train loss {'Reaction outcome loss': 0.26393120075552473, 'Total loss': 0.26393120075552473}
2023-01-04 22:57:11,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:11,823 INFO:     Epoch: 28
2023-01-04 22:57:14,094 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4081984301408132, 'Total loss': 0.4081984301408132} | train loss {'Reaction outcome loss': 0.2658725840910355, 'Total loss': 0.2658725840910355}
2023-01-04 22:57:14,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:14,094 INFO:     Epoch: 29
2023-01-04 22:57:16,398 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4168532222509384, 'Total loss': 0.4168532222509384} | train loss {'Reaction outcome loss': 0.26059574991572204, 'Total loss': 0.26059574991572204}
2023-01-04 22:57:16,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:16,399 INFO:     Epoch: 30
2023-01-04 22:57:18,607 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39817753036816916, 'Total loss': 0.39817753036816916} | train loss {'Reaction outcome loss': 0.26052888351011794, 'Total loss': 0.26052888351011794}
2023-01-04 22:57:18,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:18,607 INFO:     Epoch: 31
2023-01-04 22:57:20,892 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38998759984970094, 'Total loss': 0.38998759984970094} | train loss {'Reaction outcome loss': 0.2547579884246691, 'Total loss': 0.2547579884246691}
2023-01-04 22:57:20,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:20,893 INFO:     Epoch: 32
2023-01-04 22:57:23,196 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3926489050189654, 'Total loss': 0.3926489050189654} | train loss {'Reaction outcome loss': 0.2503057504509868, 'Total loss': 0.2503057504509868}
2023-01-04 22:57:23,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:23,196 INFO:     Epoch: 33
2023-01-04 22:57:25,447 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41557107369105023, 'Total loss': 0.41557107369105023} | train loss {'Reaction outcome loss': 0.24238163435878737, 'Total loss': 0.24238163435878737}
2023-01-04 22:57:25,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:25,447 INFO:     Epoch: 34
2023-01-04 22:57:27,748 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.389621106783549, 'Total loss': 0.389621106783549} | train loss {'Reaction outcome loss': 0.2369521242778224, 'Total loss': 0.2369521242778224}
2023-01-04 22:57:27,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:27,749 INFO:     Epoch: 35
2023-01-04 22:57:30,024 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4414207587639491, 'Total loss': 0.4414207587639491} | train loss {'Reaction outcome loss': 0.24107098089874007, 'Total loss': 0.24107098089874007}
2023-01-04 22:57:30,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:30,024 INFO:     Epoch: 36
2023-01-04 22:57:32,317 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42963138471047085, 'Total loss': 0.42963138471047085} | train loss {'Reaction outcome loss': 0.2373730728557394, 'Total loss': 0.2373730728557394}
2023-01-04 22:57:32,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:32,318 INFO:     Epoch: 37
2023-01-04 22:57:34,585 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43663109714786213, 'Total loss': 0.43663109714786213} | train loss {'Reaction outcome loss': 0.23352330093295565, 'Total loss': 0.23352330093295565}
2023-01-04 22:57:34,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:34,586 INFO:     Epoch: 38
2023-01-04 22:57:36,860 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4387992332379023, 'Total loss': 0.4387992332379023} | train loss {'Reaction outcome loss': 0.2320149026488354, 'Total loss': 0.2320149026488354}
2023-01-04 22:57:36,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:36,860 INFO:     Epoch: 39
2023-01-04 22:57:39,156 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4452825476725896, 'Total loss': 0.4452825476725896} | train loss {'Reaction outcome loss': 0.22912393780324325, 'Total loss': 0.22912393780324325}
2023-01-04 22:57:39,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:39,157 INFO:     Epoch: 40
2023-01-04 22:57:41,433 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4275238484144211, 'Total loss': 0.4275238484144211} | train loss {'Reaction outcome loss': 0.2282105086283886, 'Total loss': 0.2282105086283886}
2023-01-04 22:57:41,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:41,434 INFO:     Epoch: 41
2023-01-04 22:57:43,711 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4237036257982254, 'Total loss': 0.4237036257982254} | train loss {'Reaction outcome loss': 0.22329584305386466, 'Total loss': 0.22329584305386466}
2023-01-04 22:57:43,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:43,712 INFO:     Epoch: 42
2023-01-04 22:57:46,005 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42851589222749076, 'Total loss': 0.42851589222749076} | train loss {'Reaction outcome loss': 0.22625519448911455, 'Total loss': 0.22625519448911455}
2023-01-04 22:57:46,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:46,006 INFO:     Epoch: 43
2023-01-04 22:57:48,298 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4333049605290095, 'Total loss': 0.4333049605290095} | train loss {'Reaction outcome loss': 0.2127540614657669, 'Total loss': 0.2127540614657669}
2023-01-04 22:57:48,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:48,298 INFO:     Epoch: 44
2023-01-04 22:57:50,590 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4212460597356161, 'Total loss': 0.4212460597356161} | train loss {'Reaction outcome loss': 0.21581779920667518, 'Total loss': 0.21581779920667518}
2023-01-04 22:57:50,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:50,592 INFO:     Epoch: 45
2023-01-04 22:57:52,871 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4207200070222219, 'Total loss': 0.4207200070222219} | train loss {'Reaction outcome loss': 0.21636153518857723, 'Total loss': 0.21636153518857723}
2023-01-04 22:57:52,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:52,872 INFO:     Epoch: 46
2023-01-04 22:57:55,140 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4518126040697098, 'Total loss': 0.4518126040697098} | train loss {'Reaction outcome loss': 0.21110587249365417, 'Total loss': 0.21110587249365417}
2023-01-04 22:57:55,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:55,140 INFO:     Epoch: 47
2023-01-04 22:57:57,449 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4449806034564972, 'Total loss': 0.4449806034564972} | train loss {'Reaction outcome loss': 0.2175619596622158, 'Total loss': 0.2175619596622158}
2023-01-04 22:57:57,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:57,450 INFO:     Epoch: 48
2023-01-04 22:57:59,703 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43467632234096526, 'Total loss': 0.43467632234096526} | train loss {'Reaction outcome loss': 0.21031966439317173, 'Total loss': 0.21031966439317173}
2023-01-04 22:57:59,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:57:59,703 INFO:     Epoch: 49
2023-01-04 22:58:01,922 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.422758013010025, 'Total loss': 0.422758013010025} | train loss {'Reaction outcome loss': 0.21088241002545943, 'Total loss': 0.21088241002545943}
2023-01-04 22:58:01,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:01,923 INFO:     Epoch: 50
2023-01-04 22:58:04,165 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43919260061035553, 'Total loss': 0.43919260061035553} | train loss {'Reaction outcome loss': 0.20761919337987148, 'Total loss': 0.20761919337987148}
2023-01-04 22:58:04,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:04,165 INFO:     Epoch: 51
2023-01-04 22:58:06,464 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4473050504922867, 'Total loss': 0.4473050504922867} | train loss {'Reaction outcome loss': 0.20243550613791503, 'Total loss': 0.20243550613791503}
2023-01-04 22:58:06,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:06,464 INFO:     Epoch: 52
2023-01-04 22:58:08,767 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4433781901995341, 'Total loss': 0.4433781901995341} | train loss {'Reaction outcome loss': 0.2046615051825124, 'Total loss': 0.2046615051825124}
2023-01-04 22:58:08,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:08,767 INFO:     Epoch: 53
2023-01-04 22:58:11,020 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4384594947099686, 'Total loss': 0.4384594947099686} | train loss {'Reaction outcome loss': 0.2007569526322186, 'Total loss': 0.2007569526322186}
2023-01-04 22:58:11,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:11,021 INFO:     Epoch: 54
2023-01-04 22:58:13,300 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4268389870723089, 'Total loss': 0.4268389870723089} | train loss {'Reaction outcome loss': 0.2043201336031948, 'Total loss': 0.2043201336031948}
2023-01-04 22:58:13,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:13,301 INFO:     Epoch: 55
2023-01-04 22:58:15,506 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4386083791653315, 'Total loss': 0.4386083791653315} | train loss {'Reaction outcome loss': 0.19975473838337168, 'Total loss': 0.19975473838337168}
2023-01-04 22:58:15,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:15,507 INFO:     Epoch: 56
2023-01-04 22:58:17,678 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48027640382448833, 'Total loss': 0.48027640382448833} | train loss {'Reaction outcome loss': 0.19838723371524888, 'Total loss': 0.19838723371524888}
2023-01-04 22:58:17,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:17,678 INFO:     Epoch: 57
2023-01-04 22:58:19,982 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45187345842520393, 'Total loss': 0.45187345842520393} | train loss {'Reaction outcome loss': 0.19728360768905184, 'Total loss': 0.19728360768905184}
2023-01-04 22:58:19,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:19,984 INFO:     Epoch: 58
2023-01-04 22:58:22,238 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42983382592598596, 'Total loss': 0.42983382592598596} | train loss {'Reaction outcome loss': 0.1943349158055139, 'Total loss': 0.1943349158055139}
2023-01-04 22:58:22,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:22,238 INFO:     Epoch: 59
2023-01-04 22:58:24,538 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4332283059755961, 'Total loss': 0.4332283059755961} | train loss {'Reaction outcome loss': 0.1934486072819801, 'Total loss': 0.1934486072819801}
2023-01-04 22:58:24,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:24,538 INFO:     Epoch: 60
2023-01-04 22:58:26,822 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4287444308400154, 'Total loss': 0.4287444308400154} | train loss {'Reaction outcome loss': 0.1899153391497768, 'Total loss': 0.1899153391497768}
2023-01-04 22:58:26,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:26,823 INFO:     Epoch: 61
2023-01-04 22:58:29,035 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43923896153767905, 'Total loss': 0.43923896153767905} | train loss {'Reaction outcome loss': 0.19057032309257382, 'Total loss': 0.19057032309257382}
2023-01-04 22:58:29,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:29,035 INFO:     Epoch: 62
2023-01-04 22:58:31,315 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4261276771624883, 'Total loss': 0.4261276771624883} | train loss {'Reaction outcome loss': 0.1844156006324216, 'Total loss': 0.1844156006324216}
2023-01-04 22:58:31,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:31,316 INFO:     Epoch: 63
2023-01-04 22:58:33,601 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4266882260640462, 'Total loss': 0.4266882260640462} | train loss {'Reaction outcome loss': 0.19240401151324438, 'Total loss': 0.19240401151324438}
2023-01-04 22:58:33,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:33,601 INFO:     Epoch: 64
2023-01-04 22:58:35,898 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4153573582569758, 'Total loss': 0.4153573582569758} | train loss {'Reaction outcome loss': 0.18897382984280803, 'Total loss': 0.18897382984280803}
2023-01-04 22:58:35,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:35,899 INFO:     Epoch: 65
2023-01-04 22:58:38,167 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4276713649431864, 'Total loss': 0.4276713649431864} | train loss {'Reaction outcome loss': 0.18834998525194957, 'Total loss': 0.18834998525194957}
2023-01-04 22:58:38,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:38,168 INFO:     Epoch: 66
2023-01-04 22:58:40,458 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4444634656111399, 'Total loss': 0.4444634656111399} | train loss {'Reaction outcome loss': 0.18449570565393686, 'Total loss': 0.18449570565393686}
2023-01-04 22:58:40,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:40,459 INFO:     Epoch: 67
2023-01-04 22:58:42,750 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4303218603134155, 'Total loss': 0.4303218603134155} | train loss {'Reaction outcome loss': 0.18150980380239362, 'Total loss': 0.18150980380239362}
2023-01-04 22:58:42,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:42,750 INFO:     Epoch: 68
2023-01-04 22:58:45,027 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42839138209819794, 'Total loss': 0.42839138209819794} | train loss {'Reaction outcome loss': 0.17756671816554417, 'Total loss': 0.17756671816554417}
2023-01-04 22:58:45,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:45,027 INFO:     Epoch: 69
2023-01-04 22:58:47,284 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43902567637463413, 'Total loss': 0.43902567637463413} | train loss {'Reaction outcome loss': 0.1862619651501682, 'Total loss': 0.1862619651501682}
2023-01-04 22:58:47,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:47,284 INFO:     Epoch: 70
2023-01-04 22:58:49,551 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4302254448334376, 'Total loss': 0.4302254448334376} | train loss {'Reaction outcome loss': 0.17974794119435097, 'Total loss': 0.17974794119435097}
2023-01-04 22:58:49,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:49,551 INFO:     Epoch: 71
2023-01-04 22:58:51,811 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4260128994782766, 'Total loss': 0.4260128994782766} | train loss {'Reaction outcome loss': 0.18011834397777537, 'Total loss': 0.18011834397777537}
2023-01-04 22:58:51,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:51,811 INFO:     Epoch: 72
2023-01-04 22:58:54,108 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4454786280790965, 'Total loss': 0.4454786280790965} | train loss {'Reaction outcome loss': 0.17738499761044657, 'Total loss': 0.17738499761044657}
2023-01-04 22:58:54,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:54,108 INFO:     Epoch: 73
2023-01-04 22:58:56,406 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41573306918144226, 'Total loss': 0.41573306918144226} | train loss {'Reaction outcome loss': 0.17516186909366815, 'Total loss': 0.17516186909366815}
2023-01-04 22:58:56,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:56,407 INFO:     Epoch: 74
2023-01-04 22:58:58,655 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4498079518477122, 'Total loss': 0.4498079518477122} | train loss {'Reaction outcome loss': 0.18103381249690528, 'Total loss': 0.18103381249690528}
2023-01-04 22:58:58,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:58:58,655 INFO:     Epoch: 75
2023-01-04 22:59:00,952 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45548471212387087, 'Total loss': 0.45548471212387087} | train loss {'Reaction outcome loss': 0.17478346129852457, 'Total loss': 0.17478346129852457}
2023-01-04 22:59:00,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:00,952 INFO:     Epoch: 76
2023-01-04 22:59:03,229 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43793928225835166, 'Total loss': 0.43793928225835166} | train loss {'Reaction outcome loss': 0.1766610004004454, 'Total loss': 0.1766610004004454}
2023-01-04 22:59:03,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:03,230 INFO:     Epoch: 77
2023-01-04 22:59:05,518 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4313187410434087, 'Total loss': 0.4313187410434087} | train loss {'Reaction outcome loss': 0.17590336836302914, 'Total loss': 0.17590336836302914}
2023-01-04 22:59:05,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:05,519 INFO:     Epoch: 78
2023-01-04 22:59:07,798 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41171034673849743, 'Total loss': 0.41171034673849743} | train loss {'Reaction outcome loss': 0.17122803993913133, 'Total loss': 0.17122803993913133}
2023-01-04 22:59:07,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:07,798 INFO:     Epoch: 79
2023-01-04 22:59:10,071 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4284946988026301, 'Total loss': 0.4284946988026301} | train loss {'Reaction outcome loss': 0.1754600193136328, 'Total loss': 0.1754600193136328}
2023-01-04 22:59:10,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:10,071 INFO:     Epoch: 80
2023-01-04 22:59:12,362 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4457289109627406, 'Total loss': 0.4457289109627406} | train loss {'Reaction outcome loss': 0.16897118301382993, 'Total loss': 0.16897118301382993}
2023-01-04 22:59:12,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:12,362 INFO:     Epoch: 81
2023-01-04 22:59:14,617 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4413319249947866, 'Total loss': 0.4413319249947866} | train loss {'Reaction outcome loss': 0.17824390506882906, 'Total loss': 0.17824390506882906}
2023-01-04 22:59:14,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:14,617 INFO:     Epoch: 82
2023-01-04 22:59:16,846 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4437381366888682, 'Total loss': 0.4437381366888682} | train loss {'Reaction outcome loss': 0.1701861375536003, 'Total loss': 0.1701861375536003}
2023-01-04 22:59:16,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:16,847 INFO:     Epoch: 83
2023-01-04 22:59:19,132 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43299641211827594, 'Total loss': 0.43299641211827594} | train loss {'Reaction outcome loss': 0.17124814032123084, 'Total loss': 0.17124814032123084}
2023-01-04 22:59:19,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:19,133 INFO:     Epoch: 84
2023-01-04 22:59:21,379 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44497226625680925, 'Total loss': 0.44497226625680925} | train loss {'Reaction outcome loss': 0.1704915023613923, 'Total loss': 0.1704915023613923}
2023-01-04 22:59:21,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:21,379 INFO:     Epoch: 85
2023-01-04 22:59:23,648 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4334070732196172, 'Total loss': 0.4334070732196172} | train loss {'Reaction outcome loss': 0.16581069066488463, 'Total loss': 0.16581069066488463}
2023-01-04 22:59:23,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:23,648 INFO:     Epoch: 86
2023-01-04 22:59:25,954 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4063406301041444, 'Total loss': 0.4063406301041444} | train loss {'Reaction outcome loss': 0.16864453215616004, 'Total loss': 0.16864453215616004}
2023-01-04 22:59:25,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:25,954 INFO:     Epoch: 87
2023-01-04 22:59:28,269 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43361648519833884, 'Total loss': 0.43361648519833884} | train loss {'Reaction outcome loss': 0.17074552163421194, 'Total loss': 0.17074552163421194}
2023-01-04 22:59:28,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:28,269 INFO:     Epoch: 88
2023-01-04 22:59:30,544 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42672400871912636, 'Total loss': 0.42672400871912636} | train loss {'Reaction outcome loss': 0.16771698724276754, 'Total loss': 0.16771698724276754}
2023-01-04 22:59:30,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:30,544 INFO:     Epoch: 89
2023-01-04 22:59:32,799 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4282772327462832, 'Total loss': 0.4282772327462832} | train loss {'Reaction outcome loss': 0.16656630943253609, 'Total loss': 0.16656630943253609}
2023-01-04 22:59:32,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:32,801 INFO:     Epoch: 90
2023-01-04 22:59:35,073 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4431600570678711, 'Total loss': 0.4431600570678711} | train loss {'Reaction outcome loss': 0.16710280149919568, 'Total loss': 0.16710280149919568}
2023-01-04 22:59:35,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:35,073 INFO:     Epoch: 91
2023-01-04 22:59:37,356 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39560621281464897, 'Total loss': 0.39560621281464897} | train loss {'Reaction outcome loss': 0.16793821272120849, 'Total loss': 0.16793821272120849}
2023-01-04 22:59:37,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:37,356 INFO:     Epoch: 92
2023-01-04 22:59:39,600 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42628948340813316, 'Total loss': 0.42628948340813316} | train loss {'Reaction outcome loss': 0.16573063438818772, 'Total loss': 0.16573063438818772}
2023-01-04 22:59:39,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:39,601 INFO:     Epoch: 93
2023-01-04 22:59:41,868 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4618141184250514, 'Total loss': 0.4618141184250514} | train loss {'Reaction outcome loss': 0.1682138483675486, 'Total loss': 0.1682138483675486}
2023-01-04 22:59:41,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:41,868 INFO:     Epoch: 94
2023-01-04 22:59:44,122 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4311528027057648, 'Total loss': 0.4311528027057648} | train loss {'Reaction outcome loss': 0.17021651706567525, 'Total loss': 0.17021651706567525}
2023-01-04 22:59:44,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:44,122 INFO:     Epoch: 95
2023-01-04 22:59:46,406 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47015890876452127, 'Total loss': 0.47015890876452127} | train loss {'Reaction outcome loss': 0.15968930600244646, 'Total loss': 0.15968930600244646}
2023-01-04 22:59:46,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:46,406 INFO:     Epoch: 96
2023-01-04 22:59:48,659 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4561025050158302, 'Total loss': 0.4561025050158302} | train loss {'Reaction outcome loss': 0.16461448876661272, 'Total loss': 0.16461448876661272}
2023-01-04 22:59:48,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:48,660 INFO:     Epoch: 97
2023-01-04 22:59:50,897 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44649466971556345, 'Total loss': 0.44649466971556345} | train loss {'Reaction outcome loss': 0.1607450104893491, 'Total loss': 0.1607450104893491}
2023-01-04 22:59:50,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:50,897 INFO:     Epoch: 98
2023-01-04 22:59:53,176 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4318931634227435, 'Total loss': 0.4318931634227435} | train loss {'Reaction outcome loss': 0.1626040663079288, 'Total loss': 0.1626040663079288}
2023-01-04 22:59:53,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:53,177 INFO:     Epoch: 99
2023-01-04 22:59:55,444 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43788812557856244, 'Total loss': 0.43788812557856244} | train loss {'Reaction outcome loss': 0.15942804588236936, 'Total loss': 0.15942804588236936}
2023-01-04 22:59:55,444 INFO:     Best model found after epoch 22 of 100.
2023-01-04 22:59:55,444 INFO:   Done with stage: TRAINING
2023-01-04 22:59:55,444 INFO:   Starting stage: EVALUATION
2023-01-04 22:59:55,573 INFO:   Done with stage: EVALUATION
2023-01-04 22:59:55,582 INFO:   Leaving out SEQ value Fold_0
2023-01-04 22:59:55,595 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 22:59:55,595 INFO:   Starting stage: FEATURE SCALING
2023-01-04 22:59:56,241 INFO:   Done with stage: FEATURE SCALING
2023-01-04 22:59:56,242 INFO:   Starting stage: SCALING TARGETS
2023-01-04 22:59:56,312 INFO:   Done with stage: SCALING TARGETS
2023-01-04 22:59:56,312 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:59:56,313 INFO:     No hyperparam tuning for this model
2023-01-04 22:59:56,313 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 22:59:56,313 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 22:59:56,313 INFO:     None feature selector for col prot
2023-01-04 22:59:56,314 INFO:     None feature selector for col prot
2023-01-04 22:59:56,314 INFO:     None feature selector for col prot
2023-01-04 22:59:56,314 INFO:     None feature selector for col chem
2023-01-04 22:59:56,314 INFO:     None feature selector for col chem
2023-01-04 22:59:56,314 INFO:     None feature selector for col chem
2023-01-04 22:59:56,314 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 22:59:56,314 INFO:   Starting stage: BUILD MODEL
2023-01-04 22:59:56,316 INFO:     Number of params in model 72931
2023-01-04 22:59:56,319 INFO:   Done with stage: BUILD MODEL
2023-01-04 22:59:56,319 INFO:   Starting stage: TRAINING
2023-01-04 22:59:56,381 INFO:     Val loss before train {'Reaction outcome loss': 0.97593621412913, 'Total loss': 0.97593621412913}
2023-01-04 22:59:56,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:56,381 INFO:     Epoch: 0
2023-01-04 22:59:58,639 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7721365412076314, 'Total loss': 0.7721365412076314} | train loss {'Reaction outcome loss': 0.9508104071999989, 'Total loss': 0.9508104071999989}
2023-01-04 22:59:58,639 INFO:     Found new best model at epoch 0
2023-01-04 22:59:58,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 22:59:58,641 INFO:     Epoch: 1
2023-01-04 23:00:00,876 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5339162091414134, 'Total loss': 0.5339162091414134} | train loss {'Reaction outcome loss': 0.6459220213285328, 'Total loss': 0.6459220213285328}
2023-01-04 23:00:00,876 INFO:     Found new best model at epoch 1
2023-01-04 23:00:00,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:00,878 INFO:     Epoch: 2
2023-01-04 23:00:03,132 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4927454928557078, 'Total loss': 0.4927454928557078} | train loss {'Reaction outcome loss': 0.5230588890666509, 'Total loss': 0.5230588890666509}
2023-01-04 23:00:03,132 INFO:     Found new best model at epoch 2
2023-01-04 23:00:03,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:03,133 INFO:     Epoch: 3
2023-01-04 23:00:05,384 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4777742177248001, 'Total loss': 0.4777742177248001} | train loss {'Reaction outcome loss': 0.4742849369662522, 'Total loss': 0.4742849369662522}
2023-01-04 23:00:05,384 INFO:     Found new best model at epoch 3
2023-01-04 23:00:05,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:05,385 INFO:     Epoch: 4
2023-01-04 23:00:07,619 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4623370627562205, 'Total loss': 0.4623370627562205} | train loss {'Reaction outcome loss': 0.4504888340776419, 'Total loss': 0.4504888340776419}
2023-01-04 23:00:07,620 INFO:     Found new best model at epoch 4
2023-01-04 23:00:07,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:07,622 INFO:     Epoch: 5
2023-01-04 23:00:09,860 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4833112428585688, 'Total loss': 0.4833112428585688} | train loss {'Reaction outcome loss': 0.43363019601054437, 'Total loss': 0.43363019601054437}
2023-01-04 23:00:09,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:09,860 INFO:     Epoch: 6
2023-01-04 23:00:12,106 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47570237616697947, 'Total loss': 0.47570237616697947} | train loss {'Reaction outcome loss': 0.4128608498586355, 'Total loss': 0.4128608498586355}
2023-01-04 23:00:12,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:12,106 INFO:     Epoch: 7
2023-01-04 23:00:14,336 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48929787675539654, 'Total loss': 0.48929787675539654} | train loss {'Reaction outcome loss': 0.3936358323715029, 'Total loss': 0.3936358323715029}
2023-01-04 23:00:14,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:14,337 INFO:     Epoch: 8
2023-01-04 23:00:16,526 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4702543338139852, 'Total loss': 0.4702543338139852} | train loss {'Reaction outcome loss': 0.3813032014771317, 'Total loss': 0.3813032014771317}
2023-01-04 23:00:16,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:16,526 INFO:     Epoch: 9
2023-01-04 23:00:18,728 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4364648848772049, 'Total loss': 0.4364648848772049} | train loss {'Reaction outcome loss': 0.37077760973768514, 'Total loss': 0.37077760973768514}
2023-01-04 23:00:18,728 INFO:     Found new best model at epoch 9
2023-01-04 23:00:18,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:18,729 INFO:     Epoch: 10
2023-01-04 23:00:21,015 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46052430272102357, 'Total loss': 0.46052430272102357} | train loss {'Reaction outcome loss': 0.3623764109219948, 'Total loss': 0.3623764109219948}
2023-01-04 23:00:21,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:21,016 INFO:     Epoch: 11
2023-01-04 23:00:23,305 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4594222158193588, 'Total loss': 0.4594222158193588} | train loss {'Reaction outcome loss': 0.35329818290515536, 'Total loss': 0.35329818290515536}
2023-01-04 23:00:23,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:23,305 INFO:     Epoch: 12
2023-01-04 23:00:25,539 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4435069923599561, 'Total loss': 0.4435069923599561} | train loss {'Reaction outcome loss': 0.3451572329512913, 'Total loss': 0.3451572329512913}
2023-01-04 23:00:25,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:25,539 INFO:     Epoch: 13
2023-01-04 23:00:27,774 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42853864779074985, 'Total loss': 0.42853864779074985} | train loss {'Reaction outcome loss': 0.339867035348485, 'Total loss': 0.339867035348485}
2023-01-04 23:00:27,775 INFO:     Found new best model at epoch 13
2023-01-04 23:00:27,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:27,776 INFO:     Epoch: 14
2023-01-04 23:00:30,024 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45467570225397747, 'Total loss': 0.45467570225397747} | train loss {'Reaction outcome loss': 0.32859206052809736, 'Total loss': 0.32859206052809736}
2023-01-04 23:00:30,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:30,024 INFO:     Epoch: 15
2023-01-04 23:00:32,273 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44597567518552145, 'Total loss': 0.44597567518552145} | train loss {'Reaction outcome loss': 0.3255312926727381, 'Total loss': 0.3255312926727381}
2023-01-04 23:00:32,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:32,273 INFO:     Epoch: 16
2023-01-04 23:00:34,503 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4533344070116679, 'Total loss': 0.4533344070116679} | train loss {'Reaction outcome loss': 0.31621894277088397, 'Total loss': 0.31621894277088397}
2023-01-04 23:00:34,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:34,503 INFO:     Epoch: 17
2023-01-04 23:00:36,742 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4332868864138921, 'Total loss': 0.4332868864138921} | train loss {'Reaction outcome loss': 0.30884655510639625, 'Total loss': 0.30884655510639625}
2023-01-04 23:00:36,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:36,742 INFO:     Epoch: 18
2023-01-04 23:00:38,982 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4418485055367152, 'Total loss': 0.4418485055367152} | train loss {'Reaction outcome loss': 0.3031889487085116, 'Total loss': 0.3031889487085116}
2023-01-04 23:00:38,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:38,982 INFO:     Epoch: 19
2023-01-04 23:00:41,238 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4199445406595866, 'Total loss': 0.4199445406595866} | train loss {'Reaction outcome loss': 0.29094046592902745, 'Total loss': 0.29094046592902745}
2023-01-04 23:00:41,238 INFO:     Found new best model at epoch 19
2023-01-04 23:00:41,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:41,239 INFO:     Epoch: 20
2023-01-04 23:00:43,424 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4078683545192083, 'Total loss': 0.4078683545192083} | train loss {'Reaction outcome loss': 0.290028989301437, 'Total loss': 0.290028989301437}
2023-01-04 23:00:43,425 INFO:     Found new best model at epoch 20
2023-01-04 23:00:43,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:43,427 INFO:     Epoch: 21
2023-01-04 23:00:45,697 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4153132398923238, 'Total loss': 0.4153132398923238} | train loss {'Reaction outcome loss': 0.28190336048766207, 'Total loss': 0.28190336048766207}
2023-01-04 23:00:45,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:45,697 INFO:     Epoch: 22
2023-01-04 23:00:47,892 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41918244361877444, 'Total loss': 0.41918244361877444} | train loss {'Reaction outcome loss': 0.27811893015882394, 'Total loss': 0.27811893015882394}
2023-01-04 23:00:47,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:47,892 INFO:     Epoch: 23
2023-01-04 23:00:50,156 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3982450067996979, 'Total loss': 0.3982450067996979} | train loss {'Reaction outcome loss': 0.274484774709618, 'Total loss': 0.274484774709618}
2023-01-04 23:00:50,157 INFO:     Found new best model at epoch 23
2023-01-04 23:00:50,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:50,158 INFO:     Epoch: 24
2023-01-04 23:00:52,395 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4223664879798889, 'Total loss': 0.4223664879798889} | train loss {'Reaction outcome loss': 0.26895989165607376, 'Total loss': 0.26895989165607376}
2023-01-04 23:00:52,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:52,395 INFO:     Epoch: 25
2023-01-04 23:00:54,616 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3889925921956698, 'Total loss': 0.3889925921956698} | train loss {'Reaction outcome loss': 0.26369308533459684, 'Total loss': 0.26369308533459684}
2023-01-04 23:00:54,616 INFO:     Found new best model at epoch 25
2023-01-04 23:00:54,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:54,617 INFO:     Epoch: 26
2023-01-04 23:00:56,863 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42812011341253914, 'Total loss': 0.42812011341253914} | train loss {'Reaction outcome loss': 0.2632713471981187, 'Total loss': 0.2632713471981187}
2023-01-04 23:00:56,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:56,863 INFO:     Epoch: 27
2023-01-04 23:00:59,121 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4229141136010488, 'Total loss': 0.4229141136010488} | train loss {'Reaction outcome loss': 0.2563990393150462, 'Total loss': 0.2563990393150462}
2023-01-04 23:00:59,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:00:59,121 INFO:     Epoch: 28
2023-01-04 23:01:01,366 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40033102085193, 'Total loss': 0.40033102085193} | train loss {'Reaction outcome loss': 0.2532783452231083, 'Total loss': 0.2532783452231083}
2023-01-04 23:01:01,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:01,366 INFO:     Epoch: 29
2023-01-04 23:01:03,588 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38597987542549766, 'Total loss': 0.38597987542549766} | train loss {'Reaction outcome loss': 0.24963179253803117, 'Total loss': 0.24963179253803117}
2023-01-04 23:01:03,589 INFO:     Found new best model at epoch 29
2023-01-04 23:01:03,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:03,590 INFO:     Epoch: 30
2023-01-04 23:01:05,786 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40893372843662895, 'Total loss': 0.40893372843662895} | train loss {'Reaction outcome loss': 0.24556569846850024, 'Total loss': 0.24556569846850024}
2023-01-04 23:01:05,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:05,786 INFO:     Epoch: 31
2023-01-04 23:01:07,938 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43426240781943004, 'Total loss': 0.43426240781943004} | train loss {'Reaction outcome loss': 0.24340595331478077, 'Total loss': 0.24340595331478077}
2023-01-04 23:01:07,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:07,939 INFO:     Epoch: 32
2023-01-04 23:01:10,194 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3927120044827461, 'Total loss': 0.3927120044827461} | train loss {'Reaction outcome loss': 0.23975865734591537, 'Total loss': 0.23975865734591537}
2023-01-04 23:01:10,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:10,194 INFO:     Epoch: 33
2023-01-04 23:01:12,445 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43291534582773844, 'Total loss': 0.43291534582773844} | train loss {'Reaction outcome loss': 0.24010543733916795, 'Total loss': 0.24010543733916795}
2023-01-04 23:01:12,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:12,445 INFO:     Epoch: 34
2023-01-04 23:01:14,713 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41249193251132965, 'Total loss': 0.41249193251132965} | train loss {'Reaction outcome loss': 0.23577706577650603, 'Total loss': 0.23577706577650603}
2023-01-04 23:01:14,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:14,713 INFO:     Epoch: 35
2023-01-04 23:01:16,952 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40978000660737357, 'Total loss': 0.40978000660737357} | train loss {'Reaction outcome loss': 0.23244386363815325, 'Total loss': 0.23244386363815325}
2023-01-04 23:01:16,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:16,952 INFO:     Epoch: 36
2023-01-04 23:01:19,173 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38210400740305583, 'Total loss': 0.38210400740305583} | train loss {'Reaction outcome loss': 0.22786299919328876, 'Total loss': 0.22786299919328876}
2023-01-04 23:01:19,175 INFO:     Found new best model at epoch 36
2023-01-04 23:01:19,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:19,176 INFO:     Epoch: 37
2023-01-04 23:01:21,459 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40333084330583613, 'Total loss': 0.40333084330583613} | train loss {'Reaction outcome loss': 0.22470679069549715, 'Total loss': 0.22470679069549715}
2023-01-04 23:01:21,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:21,459 INFO:     Epoch: 38
2023-01-04 23:01:23,706 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.417261665686965, 'Total loss': 0.417261665686965} | train loss {'Reaction outcome loss': 0.22707660599564114, 'Total loss': 0.22707660599564114}
2023-01-04 23:01:23,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:23,707 INFO:     Epoch: 39
2023-01-04 23:01:25,927 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41258739233016967, 'Total loss': 0.41258739233016967} | train loss {'Reaction outcome loss': 0.2244175799517301, 'Total loss': 0.2244175799517301}
2023-01-04 23:01:25,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:25,928 INFO:     Epoch: 40
2023-01-04 23:01:28,167 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4018625125288963, 'Total loss': 0.4018625125288963} | train loss {'Reaction outcome loss': 0.21750568248073224, 'Total loss': 0.21750568248073224}
2023-01-04 23:01:28,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:28,167 INFO:     Epoch: 41
2023-01-04 23:01:30,414 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41914332906405133, 'Total loss': 0.41914332906405133} | train loss {'Reaction outcome loss': 0.21970391307148512, 'Total loss': 0.21970391307148512}
2023-01-04 23:01:30,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:30,415 INFO:     Epoch: 42
2023-01-04 23:01:32,686 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41234642267227173, 'Total loss': 0.41234642267227173} | train loss {'Reaction outcome loss': 0.2172708112481356, 'Total loss': 0.2172708112481356}
2023-01-04 23:01:32,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:32,687 INFO:     Epoch: 43
2023-01-04 23:01:34,960 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42933252453804016, 'Total loss': 0.42933252453804016} | train loss {'Reaction outcome loss': 0.21003955903796168, 'Total loss': 0.21003955903796168}
2023-01-04 23:01:34,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:34,960 INFO:     Epoch: 44
2023-01-04 23:01:37,135 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4291049361228943, 'Total loss': 0.4291049361228943} | train loss {'Reaction outcome loss': 0.21294810273854511, 'Total loss': 0.21294810273854511}
2023-01-04 23:01:37,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:37,135 INFO:     Epoch: 45
2023-01-04 23:01:39,384 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4119873841603597, 'Total loss': 0.4119873841603597} | train loss {'Reaction outcome loss': 0.20978235291575428, 'Total loss': 0.20978235291575428}
2023-01-04 23:01:39,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:39,385 INFO:     Epoch: 46
2023-01-04 23:01:41,632 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.397777230789264, 'Total loss': 0.397777230789264} | train loss {'Reaction outcome loss': 0.2077438941354571, 'Total loss': 0.2077438941354571}
2023-01-04 23:01:41,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:41,632 INFO:     Epoch: 47
2023-01-04 23:01:43,858 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42998449206352235, 'Total loss': 0.42998449206352235} | train loss {'Reaction outcome loss': 0.20402914559958082, 'Total loss': 0.20402914559958082}
2023-01-04 23:01:43,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:43,858 INFO:     Epoch: 48
2023-01-04 23:01:46,115 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44579776624838513, 'Total loss': 0.44579776624838513} | train loss {'Reaction outcome loss': 0.2019268440143851, 'Total loss': 0.2019268440143851}
2023-01-04 23:01:46,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:46,115 INFO:     Epoch: 49
2023-01-04 23:01:48,336 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40053206980228423, 'Total loss': 0.40053206980228423} | train loss {'Reaction outcome loss': 0.20396772878801953, 'Total loss': 0.20396772878801953}
2023-01-04 23:01:48,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:48,336 INFO:     Epoch: 50
2023-01-04 23:01:50,568 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38627725541591645, 'Total loss': 0.38627725541591645} | train loss {'Reaction outcome loss': 0.20035638353603819, 'Total loss': 0.20035638353603819}
2023-01-04 23:01:50,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:50,568 INFO:     Epoch: 51
2023-01-04 23:01:52,749 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3999833971261978, 'Total loss': 0.3999833971261978} | train loss {'Reaction outcome loss': 0.2005790382722243, 'Total loss': 0.2005790382722243}
2023-01-04 23:01:52,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:52,749 INFO:     Epoch: 52
2023-01-04 23:01:55,009 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.440338317801555, 'Total loss': 0.440338317801555} | train loss {'Reaction outcome loss': 0.1981412781552024, 'Total loss': 0.1981412781552024}
2023-01-04 23:01:55,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:55,010 INFO:     Epoch: 53
2023-01-04 23:01:57,278 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42328756550947827, 'Total loss': 0.42328756550947827} | train loss {'Reaction outcome loss': 0.2007501406822843, 'Total loss': 0.2007501406822843}
2023-01-04 23:01:57,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:57,278 INFO:     Epoch: 54
2023-01-04 23:01:59,523 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43955589334170025, 'Total loss': 0.43955589334170025} | train loss {'Reaction outcome loss': 0.18955959586161494, 'Total loss': 0.18955959586161494}
2023-01-04 23:01:59,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:01:59,524 INFO:     Epoch: 55
2023-01-04 23:02:01,755 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42729925910631816, 'Total loss': 0.42729925910631816} | train loss {'Reaction outcome loss': 0.19228618747697476, 'Total loss': 0.19228618747697476}
2023-01-04 23:02:01,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:01,756 INFO:     Epoch: 56
2023-01-04 23:02:03,984 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40313936620950697, 'Total loss': 0.40313936620950697} | train loss {'Reaction outcome loss': 0.18934236145510344, 'Total loss': 0.18934236145510344}
2023-01-04 23:02:03,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:03,984 INFO:     Epoch: 57
2023-01-04 23:02:06,243 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4011061971386274, 'Total loss': 0.4011061971386274} | train loss {'Reaction outcome loss': 0.1884509395437492, 'Total loss': 0.1884509395437492}
2023-01-04 23:02:06,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:06,243 INFO:     Epoch: 58
2023-01-04 23:02:08,498 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4371929903825124, 'Total loss': 0.4371929903825124} | train loss {'Reaction outcome loss': 0.1916501454628297, 'Total loss': 0.1916501454628297}
2023-01-04 23:02:08,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:08,498 INFO:     Epoch: 59
2023-01-04 23:02:10,735 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4155506521463394, 'Total loss': 0.4155506521463394} | train loss {'Reaction outcome loss': 0.18945420913425456, 'Total loss': 0.18945420913425456}
2023-01-04 23:02:10,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:10,736 INFO:     Epoch: 60
2023-01-04 23:02:12,885 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3923733098121981, 'Total loss': 0.3923733098121981} | train loss {'Reaction outcome loss': 0.18940446455113208, 'Total loss': 0.18940446455113208}
2023-01-04 23:02:12,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:12,886 INFO:     Epoch: 61
2023-01-04 23:02:15,115 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4083314408858617, 'Total loss': 0.4083314408858617} | train loss {'Reaction outcome loss': 0.1858538013107966, 'Total loss': 0.1858538013107966}
2023-01-04 23:02:15,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:15,116 INFO:     Epoch: 62
2023-01-04 23:02:17,366 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43343779345353445, 'Total loss': 0.43343779345353445} | train loss {'Reaction outcome loss': 0.1836597644129129, 'Total loss': 0.1836597644129129}
2023-01-04 23:02:17,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:17,366 INFO:     Epoch: 63
2023-01-04 23:02:19,613 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4521301746368408, 'Total loss': 0.4521301746368408} | train loss {'Reaction outcome loss': 0.18461549379964814, 'Total loss': 0.18461549379964814}
2023-01-04 23:02:19,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:19,613 INFO:     Epoch: 64
2023-01-04 23:02:21,872 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4221627642711004, 'Total loss': 0.4221627642711004} | train loss {'Reaction outcome loss': 0.18022744654997314, 'Total loss': 0.18022744654997314}
2023-01-04 23:02:21,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:21,872 INFO:     Epoch: 65
2023-01-04 23:02:24,099 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41654679030179975, 'Total loss': 0.41654679030179975} | train loss {'Reaction outcome loss': 0.178044605456347, 'Total loss': 0.178044605456347}
2023-01-04 23:02:24,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:24,099 INFO:     Epoch: 66
2023-01-04 23:02:26,146 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4249470094839732, 'Total loss': 0.4249470094839732} | train loss {'Reaction outcome loss': 0.1841910380808922, 'Total loss': 0.1841910380808922}
2023-01-04 23:02:26,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:26,147 INFO:     Epoch: 67
2023-01-04 23:02:28,384 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43245667616526284, 'Total loss': 0.43245667616526284} | train loss {'Reaction outcome loss': 0.17827765087862193, 'Total loss': 0.17827765087862193}
2023-01-04 23:02:28,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:28,385 INFO:     Epoch: 68
2023-01-04 23:02:30,609 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4190462949996193, 'Total loss': 0.4190462949996193} | train loss {'Reaction outcome loss': 0.17683677271647502, 'Total loss': 0.17683677271647502}
2023-01-04 23:02:30,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:30,609 INFO:     Epoch: 69
2023-01-04 23:02:32,855 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4189691433217376, 'Total loss': 0.4189691433217376} | train loss {'Reaction outcome loss': 0.17366773623252546, 'Total loss': 0.17366773623252546}
2023-01-04 23:02:32,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:32,856 INFO:     Epoch: 70
2023-01-04 23:02:35,092 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43730806559324265, 'Total loss': 0.43730806559324265} | train loss {'Reaction outcome loss': 0.17710218352544374, 'Total loss': 0.17710218352544374}
2023-01-04 23:02:35,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:35,093 INFO:     Epoch: 71
2023-01-04 23:02:37,297 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4573415398597717, 'Total loss': 0.4573415398597717} | train loss {'Reaction outcome loss': 0.17473441684604996, 'Total loss': 0.17473441684604996}
2023-01-04 23:02:37,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:37,298 INFO:     Epoch: 72
2023-01-04 23:02:39,513 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45623487581809363, 'Total loss': 0.45623487581809363} | train loss {'Reaction outcome loss': 0.16935494810302001, 'Total loss': 0.16935494810302001}
2023-01-04 23:02:39,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:39,513 INFO:     Epoch: 73
2023-01-04 23:02:41,774 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40784498111655315, 'Total loss': 0.40784498111655315} | train loss {'Reaction outcome loss': 0.17074702391366944, 'Total loss': 0.17074702391366944}
2023-01-04 23:02:41,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:41,775 INFO:     Epoch: 74
2023-01-04 23:02:44,023 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.427214519182841, 'Total loss': 0.427214519182841} | train loss {'Reaction outcome loss': 0.1709994330856079, 'Total loss': 0.1709994330856079}
2023-01-04 23:02:44,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:44,023 INFO:     Epoch: 75
2023-01-04 23:02:46,233 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4042658374955257, 'Total loss': 0.4042658374955257} | train loss {'Reaction outcome loss': 0.1754975970205681, 'Total loss': 0.1754975970205681}
2023-01-04 23:02:46,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:46,233 INFO:     Epoch: 76
2023-01-04 23:02:48,492 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4126419210030387, 'Total loss': 0.4126419210030387} | train loss {'Reaction outcome loss': 0.16799778262166865, 'Total loss': 0.16799778262166865}
2023-01-04 23:02:48,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:48,492 INFO:     Epoch: 77
2023-01-04 23:02:50,720 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42861268619696297, 'Total loss': 0.42861268619696297} | train loss {'Reaction outcome loss': 0.1709129826070564, 'Total loss': 0.1709129826070564}
2023-01-04 23:02:50,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:50,720 INFO:     Epoch: 78
2023-01-04 23:02:52,990 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4435086637735367, 'Total loss': 0.4435086637735367} | train loss {'Reaction outcome loss': 0.17458095698597004, 'Total loss': 0.17458095698597004}
2023-01-04 23:02:52,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:52,991 INFO:     Epoch: 79
2023-01-04 23:02:55,247 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4307523330052694, 'Total loss': 0.4307523330052694} | train loss {'Reaction outcome loss': 0.1706551943215657, 'Total loss': 0.1706551943215657}
2023-01-04 23:02:55,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:55,248 INFO:     Epoch: 80
2023-01-04 23:02:57,471 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4167550871769587, 'Total loss': 0.4167550871769587} | train loss {'Reaction outcome loss': 0.16943672956579303, 'Total loss': 0.16943672956579303}
2023-01-04 23:02:57,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:57,472 INFO:     Epoch: 81
2023-01-04 23:02:59,814 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46990808298190434, 'Total loss': 0.46990808298190434} | train loss {'Reaction outcome loss': 0.16845535587886498, 'Total loss': 0.16845535587886498}
2023-01-04 23:02:59,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:02:59,814 INFO:     Epoch: 82
2023-01-04 23:03:02,119 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4335854634642601, 'Total loss': 0.4335854634642601} | train loss {'Reaction outcome loss': 0.16948824081175629, 'Total loss': 0.16948824081175629}
2023-01-04 23:03:02,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:02,119 INFO:     Epoch: 83
2023-01-04 23:03:04,391 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42105310757954917, 'Total loss': 0.42105310757954917} | train loss {'Reaction outcome loss': 0.1669110234582076, 'Total loss': 0.1669110234582076}
2023-01-04 23:03:04,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:04,392 INFO:     Epoch: 84
2023-01-04 23:03:06,605 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44765649139881136, 'Total loss': 0.44765649139881136} | train loss {'Reaction outcome loss': 0.16227155679116284, 'Total loss': 0.16227155679116284}
2023-01-04 23:03:06,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:06,606 INFO:     Epoch: 85
2023-01-04 23:03:08,851 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43983558217684426, 'Total loss': 0.43983558217684426} | train loss {'Reaction outcome loss': 0.17058909168283382, 'Total loss': 0.17058909168283382}
2023-01-04 23:03:08,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:08,851 INFO:     Epoch: 86
2023-01-04 23:03:11,088 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47076100260019305, 'Total loss': 0.47076100260019305} | train loss {'Reaction outcome loss': 0.16366494265401968, 'Total loss': 0.16366494265401968}
2023-01-04 23:03:11,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:11,088 INFO:     Epoch: 87
2023-01-04 23:03:13,343 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4249932954708735, 'Total loss': 0.4249932954708735} | train loss {'Reaction outcome loss': 0.1628621631458293, 'Total loss': 0.1628621631458293}
2023-01-04 23:03:13,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:13,344 INFO:     Epoch: 88
2023-01-04 23:03:15,590 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4209671176970005, 'Total loss': 0.4209671176970005} | train loss {'Reaction outcome loss': 0.16167684167752683, 'Total loss': 0.16167684167752683}
2023-01-04 23:03:15,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:15,591 INFO:     Epoch: 89
2023-01-04 23:03:17,841 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4324098295842608, 'Total loss': 0.4324098295842608} | train loss {'Reaction outcome loss': 0.1616846251668558, 'Total loss': 0.1616846251668558}
2023-01-04 23:03:17,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:17,841 INFO:     Epoch: 90
2023-01-04 23:03:20,103 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4605087826649348, 'Total loss': 0.4605087826649348} | train loss {'Reaction outcome loss': 0.16323422176940164, 'Total loss': 0.16323422176940164}
2023-01-04 23:03:20,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:20,104 INFO:     Epoch: 91
2023-01-04 23:03:22,340 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46319325764973956, 'Total loss': 0.46319325764973956} | train loss {'Reaction outcome loss': 0.1590027654251206, 'Total loss': 0.1590027654251206}
2023-01-04 23:03:22,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:22,340 INFO:     Epoch: 92
2023-01-04 23:03:24,567 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39498039583365124, 'Total loss': 0.39498039583365124} | train loss {'Reaction outcome loss': 0.16537465075078508, 'Total loss': 0.16537465075078508}
2023-01-04 23:03:24,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:24,567 INFO:     Epoch: 93
2023-01-04 23:03:26,828 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44497455333669983, 'Total loss': 0.44497455333669983} | train loss {'Reaction outcome loss': 0.15741561761594983, 'Total loss': 0.15741561761594983}
2023-01-04 23:03:26,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:26,829 INFO:     Epoch: 94
2023-01-04 23:03:29,097 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4103377590576808, 'Total loss': 0.4103377590576808} | train loss {'Reaction outcome loss': 0.16077140682499286, 'Total loss': 0.16077140682499286}
2023-01-04 23:03:29,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:29,097 INFO:     Epoch: 95
2023-01-04 23:03:31,325 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4595201214154561, 'Total loss': 0.4595201214154561} | train loss {'Reaction outcome loss': 0.1582924836981416, 'Total loss': 0.1582924836981416}
2023-01-04 23:03:31,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:31,325 INFO:     Epoch: 96
2023-01-04 23:03:33,571 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4082592914501826, 'Total loss': 0.4082592914501826} | train loss {'Reaction outcome loss': 0.15795907280645774, 'Total loss': 0.15795907280645774}
2023-01-04 23:03:33,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:33,571 INFO:     Epoch: 97
2023-01-04 23:03:35,830 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40657544406907015, 'Total loss': 0.40657544406907015} | train loss {'Reaction outcome loss': 0.164698877135618, 'Total loss': 0.164698877135618}
2023-01-04 23:03:35,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:35,830 INFO:     Epoch: 98
2023-01-04 23:03:37,736 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45846806665261586, 'Total loss': 0.45846806665261586} | train loss {'Reaction outcome loss': 0.15629264498877266, 'Total loss': 0.15629264498877266}
2023-01-04 23:03:37,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:37,736 INFO:     Epoch: 99
2023-01-04 23:03:39,611 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4395524670680364, 'Total loss': 0.4395524670680364} | train loss {'Reaction outcome loss': 0.15527710148446044, 'Total loss': 0.15527710148446044}
2023-01-04 23:03:39,612 INFO:     Best model found after epoch 37 of 100.
2023-01-04 23:03:39,612 INFO:   Done with stage: TRAINING
2023-01-04 23:03:39,612 INFO:   Starting stage: EVALUATION
2023-01-04 23:03:39,751 INFO:   Done with stage: EVALUATION
2023-01-04 23:03:39,751 INFO:   Leaving out SEQ value Fold_1
2023-01-04 23:03:39,764 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-04 23:03:39,764 INFO:   Starting stage: FEATURE SCALING
2023-01-04 23:03:40,409 INFO:   Done with stage: FEATURE SCALING
2023-01-04 23:03:40,409 INFO:   Starting stage: SCALING TARGETS
2023-01-04 23:03:40,480 INFO:   Done with stage: SCALING TARGETS
2023-01-04 23:03:40,480 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:03:40,480 INFO:     No hyperparam tuning for this model
2023-01-04 23:03:40,481 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:03:40,481 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 23:03:40,481 INFO:     None feature selector for col prot
2023-01-04 23:03:40,482 INFO:     None feature selector for col prot
2023-01-04 23:03:40,482 INFO:     None feature selector for col prot
2023-01-04 23:03:40,482 INFO:     None feature selector for col chem
2023-01-04 23:03:40,482 INFO:     None feature selector for col chem
2023-01-04 23:03:40,482 INFO:     None feature selector for col chem
2023-01-04 23:03:40,482 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 23:03:40,482 INFO:   Starting stage: BUILD MODEL
2023-01-04 23:03:40,484 INFO:     Number of params in model 72931
2023-01-04 23:03:40,487 INFO:   Done with stage: BUILD MODEL
2023-01-04 23:03:40,487 INFO:   Starting stage: TRAINING
2023-01-04 23:03:40,547 INFO:     Val loss before train {'Reaction outcome loss': 1.093928591410319, 'Total loss': 1.093928591410319}
2023-01-04 23:03:40,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:40,548 INFO:     Epoch: 0
2023-01-04 23:03:42,788 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.831491349140803, 'Total loss': 0.831491349140803} | train loss {'Reaction outcome loss': 0.9613736072809493, 'Total loss': 0.9613736072809493}
2023-01-04 23:03:42,789 INFO:     Found new best model at epoch 0
2023-01-04 23:03:42,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:42,790 INFO:     Epoch: 1
2023-01-04 23:03:45,002 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5596617410580317, 'Total loss': 0.5596617410580317} | train loss {'Reaction outcome loss': 0.6481281813660231, 'Total loss': 0.6481281813660231}
2023-01-04 23:03:45,002 INFO:     Found new best model at epoch 1
2023-01-04 23:03:45,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:45,004 INFO:     Epoch: 2
2023-01-04 23:03:47,242 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5242635488510132, 'Total loss': 0.5242635488510132} | train loss {'Reaction outcome loss': 0.5370375314981735, 'Total loss': 0.5370375314981735}
2023-01-04 23:03:47,243 INFO:     Found new best model at epoch 2
2023-01-04 23:03:47,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:47,244 INFO:     Epoch: 3
2023-01-04 23:03:49,465 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.523780204852422, 'Total loss': 0.523780204852422} | train loss {'Reaction outcome loss': 0.4901593194456558, 'Total loss': 0.4901593194456558}
2023-01-04 23:03:49,466 INFO:     Found new best model at epoch 3
2023-01-04 23:03:49,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:49,468 INFO:     Epoch: 4
2023-01-04 23:03:51,698 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5088283975919088, 'Total loss': 0.5088283975919088} | train loss {'Reaction outcome loss': 0.46204211769068815, 'Total loss': 0.46204211769068815}
2023-01-04 23:03:51,698 INFO:     Found new best model at epoch 4
2023-01-04 23:03:51,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:51,699 INFO:     Epoch: 5
2023-01-04 23:03:53,901 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47072718540827435, 'Total loss': 0.47072718540827435} | train loss {'Reaction outcome loss': 0.4384112842518465, 'Total loss': 0.4384112842518465}
2023-01-04 23:03:53,901 INFO:     Found new best model at epoch 5
2023-01-04 23:03:53,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:53,903 INFO:     Epoch: 6
2023-01-04 23:03:56,065 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47608742912610374, 'Total loss': 0.47608742912610374} | train loss {'Reaction outcome loss': 0.42127786543756396, 'Total loss': 0.42127786543756396}
2023-01-04 23:03:56,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:56,065 INFO:     Epoch: 7
2023-01-04 23:03:58,290 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4989663322766622, 'Total loss': 0.4989663322766622} | train loss {'Reaction outcome loss': 0.40506949204250453, 'Total loss': 0.40506949204250453}
2023-01-04 23:03:58,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:03:58,290 INFO:     Epoch: 8
2023-01-04 23:04:00,432 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45595700840155284, 'Total loss': 0.45595700840155284} | train loss {'Reaction outcome loss': 0.39339744071458976, 'Total loss': 0.39339744071458976}
2023-01-04 23:04:00,432 INFO:     Found new best model at epoch 8
2023-01-04 23:04:00,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:00,433 INFO:     Epoch: 9
2023-01-04 23:04:02,650 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44288676728804904, 'Total loss': 0.44288676728804904} | train loss {'Reaction outcome loss': 0.3843504846975812, 'Total loss': 0.3843504846975812}
2023-01-04 23:04:02,651 INFO:     Found new best model at epoch 9
2023-01-04 23:04:02,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:02,652 INFO:     Epoch: 10
2023-01-04 23:04:04,825 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45375694433848063, 'Total loss': 0.45375694433848063} | train loss {'Reaction outcome loss': 0.3736054743897871, 'Total loss': 0.3736054743897871}
2023-01-04 23:04:04,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:04,825 INFO:     Epoch: 11
2023-01-04 23:04:07,036 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46090291639169056, 'Total loss': 0.46090291639169056} | train loss {'Reaction outcome loss': 0.3664405218487076, 'Total loss': 0.3664405218487076}
2023-01-04 23:04:07,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:07,036 INFO:     Epoch: 12
2023-01-04 23:04:09,263 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44173918962478637, 'Total loss': 0.44173918962478637} | train loss {'Reaction outcome loss': 0.3536398033044435, 'Total loss': 0.3536398033044435}
2023-01-04 23:04:09,263 INFO:     Found new best model at epoch 12
2023-01-04 23:04:09,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:09,264 INFO:     Epoch: 13
2023-01-04 23:04:11,499 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45637798607349395, 'Total loss': 0.45637798607349395} | train loss {'Reaction outcome loss': 0.34285393670696174, 'Total loss': 0.34285393670696174}
2023-01-04 23:04:11,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:11,499 INFO:     Epoch: 14
2023-01-04 23:04:13,696 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44344544808069863, 'Total loss': 0.44344544808069863} | train loss {'Reaction outcome loss': 0.33386012708348983, 'Total loss': 0.33386012708348983}
2023-01-04 23:04:13,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:13,697 INFO:     Epoch: 15
2023-01-04 23:04:15,869 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47894535064697263, 'Total loss': 0.47894535064697263} | train loss {'Reaction outcome loss': 0.331826773626778, 'Total loss': 0.331826773626778}
2023-01-04 23:04:15,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:15,869 INFO:     Epoch: 16
2023-01-04 23:04:18,113 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.474629541238149, 'Total loss': 0.474629541238149} | train loss {'Reaction outcome loss': 0.31990530234641257, 'Total loss': 0.31990530234641257}
2023-01-04 23:04:18,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:18,114 INFO:     Epoch: 17
2023-01-04 23:04:20,315 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4536403000354767, 'Total loss': 0.4536403000354767} | train loss {'Reaction outcome loss': 0.3124369211439937, 'Total loss': 0.3124369211439937}
2023-01-04 23:04:20,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:20,316 INFO:     Epoch: 18
2023-01-04 23:04:22,500 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4397276888291041, 'Total loss': 0.4397276888291041} | train loss {'Reaction outcome loss': 0.3090474971353568, 'Total loss': 0.3090474971353568}
2023-01-04 23:04:22,501 INFO:     Found new best model at epoch 18
2023-01-04 23:04:22,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:22,502 INFO:     Epoch: 19
2023-01-04 23:04:24,734 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45551846822102865, 'Total loss': 0.45551846822102865} | train loss {'Reaction outcome loss': 0.30044872569422, 'Total loss': 0.30044872569422}
2023-01-04 23:04:24,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:24,735 INFO:     Epoch: 20
2023-01-04 23:04:26,920 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47140495479106903, 'Total loss': 0.47140495479106903} | train loss {'Reaction outcome loss': 0.29301946762798015, 'Total loss': 0.29301946762798015}
2023-01-04 23:04:26,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:26,920 INFO:     Epoch: 21
2023-01-04 23:04:29,057 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44934682846069335, 'Total loss': 0.44934682846069335} | train loss {'Reaction outcome loss': 0.28932670413128125, 'Total loss': 0.28932670413128125}
2023-01-04 23:04:29,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:29,057 INFO:     Epoch: 22
2023-01-04 23:04:31,190 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4724338173866272, 'Total loss': 0.4724338173866272} | train loss {'Reaction outcome loss': 0.2852492623608491, 'Total loss': 0.2852492623608491}
2023-01-04 23:04:31,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:31,191 INFO:     Epoch: 23
2023-01-04 23:04:33,371 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42819744348526, 'Total loss': 0.42819744348526} | train loss {'Reaction outcome loss': 0.2753228374595352, 'Total loss': 0.2753228374595352}
2023-01-04 23:04:33,372 INFO:     Found new best model at epoch 23
2023-01-04 23:04:33,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:33,374 INFO:     Epoch: 24
2023-01-04 23:04:35,593 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4466332147518794, 'Total loss': 0.4466332147518794} | train loss {'Reaction outcome loss': 0.27005018645766915, 'Total loss': 0.27005018645766915}
2023-01-04 23:04:35,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:35,593 INFO:     Epoch: 25
2023-01-04 23:04:37,820 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4784377902746201, 'Total loss': 0.4784377902746201} | train loss {'Reaction outcome loss': 0.26979018585598336, 'Total loss': 0.26979018585598336}
2023-01-04 23:04:37,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:37,820 INFO:     Epoch: 26
2023-01-04 23:04:40,027 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44905565281709037, 'Total loss': 0.44905565281709037} | train loss {'Reaction outcome loss': 0.26520926327997907, 'Total loss': 0.26520926327997907}
2023-01-04 23:04:40,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:40,027 INFO:     Epoch: 27
2023-01-04 23:04:42,253 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49553322394688926, 'Total loss': 0.49553322394688926} | train loss {'Reaction outcome loss': 0.26150568621404935, 'Total loss': 0.26150568621404935}
2023-01-04 23:04:42,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:42,254 INFO:     Epoch: 28
2023-01-04 23:04:44,489 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47844197948773703, 'Total loss': 0.47844197948773703} | train loss {'Reaction outcome loss': 0.2578488638507704, 'Total loss': 0.2578488638507704}
2023-01-04 23:04:44,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:44,490 INFO:     Epoch: 29
2023-01-04 23:04:46,732 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43679684201876323, 'Total loss': 0.43679684201876323} | train loss {'Reaction outcome loss': 0.251748044841074, 'Total loss': 0.251748044841074}
2023-01-04 23:04:46,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:46,732 INFO:     Epoch: 30
2023-01-04 23:04:48,958 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4763004740079244, 'Total loss': 0.4763004740079244} | train loss {'Reaction outcome loss': 0.24300802731371013, 'Total loss': 0.24300802731371013}
2023-01-04 23:04:48,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:48,959 INFO:     Epoch: 31
2023-01-04 23:04:51,173 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42229174772898354, 'Total loss': 0.42229174772898354} | train loss {'Reaction outcome loss': 0.24114540950618546, 'Total loss': 0.24114540950618546}
2023-01-04 23:04:51,174 INFO:     Found new best model at epoch 31
2023-01-04 23:04:51,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:51,175 INFO:     Epoch: 32
2023-01-04 23:04:53,417 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.446030596892039, 'Total loss': 0.446030596892039} | train loss {'Reaction outcome loss': 0.24495346367881526, 'Total loss': 0.24495346367881526}
2023-01-04 23:04:53,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:53,418 INFO:     Epoch: 33
2023-01-04 23:04:55,633 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4662610967954, 'Total loss': 0.4662610967954} | train loss {'Reaction outcome loss': 0.23662731453528923, 'Total loss': 0.23662731453528923}
2023-01-04 23:04:55,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:55,634 INFO:     Epoch: 34
2023-01-04 23:04:57,787 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47790746092796327, 'Total loss': 0.47790746092796327} | train loss {'Reaction outcome loss': 0.2297926441701026, 'Total loss': 0.2297926441701026}
2023-01-04 23:04:57,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:57,787 INFO:     Epoch: 35
2023-01-04 23:04:59,943 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45310092667738594, 'Total loss': 0.45310092667738594} | train loss {'Reaction outcome loss': 0.23071399357898428, 'Total loss': 0.23071399357898428}
2023-01-04 23:04:59,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:04:59,943 INFO:     Epoch: 36
2023-01-04 23:05:02,085 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5038841406504313, 'Total loss': 0.5038841406504313} | train loss {'Reaction outcome loss': 0.22990401675477898, 'Total loss': 0.22990401675477898}
2023-01-04 23:05:02,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:02,085 INFO:     Epoch: 37
2023-01-04 23:05:04,320 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4558065523703893, 'Total loss': 0.4558065523703893} | train loss {'Reaction outcome loss': 0.2273339240217231, 'Total loss': 0.2273339240217231}
2023-01-04 23:05:04,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:04,320 INFO:     Epoch: 38
2023-01-04 23:05:06,526 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4903379023075104, 'Total loss': 0.4903379023075104} | train loss {'Reaction outcome loss': 0.22803784154932877, 'Total loss': 0.22803784154932877}
2023-01-04 23:05:06,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:06,526 INFO:     Epoch: 39
2023-01-04 23:05:08,754 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5091683705647786, 'Total loss': 0.5091683705647786} | train loss {'Reaction outcome loss': 0.22051689539420868, 'Total loss': 0.22051689539420868}
2023-01-04 23:05:08,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:08,755 INFO:     Epoch: 40
2023-01-04 23:05:10,899 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46189215083916985, 'Total loss': 0.46189215083916985} | train loss {'Reaction outcome loss': 0.21792786829585958, 'Total loss': 0.21792786829585958}
2023-01-04 23:05:10,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:10,899 INFO:     Epoch: 41
2023-01-04 23:05:13,036 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5096294999122619, 'Total loss': 0.5096294999122619} | train loss {'Reaction outcome loss': 0.2131037033262673, 'Total loss': 0.2131037033262673}
2023-01-04 23:05:13,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:13,036 INFO:     Epoch: 42
2023-01-04 23:05:15,264 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46629161238670347, 'Total loss': 0.46629161238670347} | train loss {'Reaction outcome loss': 0.2106166244707864, 'Total loss': 0.2106166244707864}
2023-01-04 23:05:15,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:15,264 INFO:     Epoch: 43
2023-01-04 23:05:17,440 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4656816989183426, 'Total loss': 0.4656816989183426} | train loss {'Reaction outcome loss': 0.21271109562435933, 'Total loss': 0.21271109562435933}
2023-01-04 23:05:17,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:17,441 INFO:     Epoch: 44
2023-01-04 23:05:19,589 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5194317320982615, 'Total loss': 0.5194317320982615} | train loss {'Reaction outcome loss': 0.20776149519887577, 'Total loss': 0.20776149519887577}
2023-01-04 23:05:19,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:19,589 INFO:     Epoch: 45
2023-01-04 23:05:21,794 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49564898014068604, 'Total loss': 0.49564898014068604} | train loss {'Reaction outcome loss': 0.2024734576930364, 'Total loss': 0.2024734576930364}
2023-01-04 23:05:21,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:21,794 INFO:     Epoch: 46
2023-01-04 23:05:24,024 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49903510411580404, 'Total loss': 0.49903510411580404} | train loss {'Reaction outcome loss': 0.20926657266832366, 'Total loss': 0.20926657266832366}
2023-01-04 23:05:24,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:24,025 INFO:     Epoch: 47
2023-01-04 23:05:26,234 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4810130923986435, 'Total loss': 0.4810130923986435} | train loss {'Reaction outcome loss': 0.20365719106117078, 'Total loss': 0.20365719106117078}
2023-01-04 23:05:26,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:26,236 INFO:     Epoch: 48
2023-01-04 23:05:28,454 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4492954753960172, 'Total loss': 0.4492954753960172} | train loss {'Reaction outcome loss': 0.19979865193312019, 'Total loss': 0.19979865193312019}
2023-01-04 23:05:28,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:28,454 INFO:     Epoch: 49
2023-01-04 23:05:30,626 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45952478448549905, 'Total loss': 0.45952478448549905} | train loss {'Reaction outcome loss': 0.19097280463829253, 'Total loss': 0.19097280463829253}
2023-01-04 23:05:30,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:30,627 INFO:     Epoch: 50
2023-01-04 23:05:32,853 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48852068185806274, 'Total loss': 0.48852068185806274} | train loss {'Reaction outcome loss': 0.19609149706264703, 'Total loss': 0.19609149706264703}
2023-01-04 23:05:32,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:32,854 INFO:     Epoch: 51
2023-01-04 23:05:35,048 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.486243932445844, 'Total loss': 0.486243932445844} | train loss {'Reaction outcome loss': 0.20089388476526604, 'Total loss': 0.20089388476526604}
2023-01-04 23:05:35,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:35,048 INFO:     Epoch: 52
2023-01-04 23:05:37,261 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48507586419582366, 'Total loss': 0.48507586419582366} | train loss {'Reaction outcome loss': 0.19323296611956783, 'Total loss': 0.19323296611956783}
2023-01-04 23:05:37,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:37,262 INFO:     Epoch: 53
2023-01-04 23:05:39,409 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.49396963069836297, 'Total loss': 0.49396963069836297} | train loss {'Reaction outcome loss': 0.201273929616402, 'Total loss': 0.201273929616402}
2023-01-04 23:05:39,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:39,409 INFO:     Epoch: 54
2023-01-04 23:05:41,652 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4975141242146492, 'Total loss': 0.4975141242146492} | train loss {'Reaction outcome loss': 0.1925693467170055, 'Total loss': 0.1925693467170055}
2023-01-04 23:05:41,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:41,652 INFO:     Epoch: 55
2023-01-04 23:05:43,905 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4518470505873362, 'Total loss': 0.4518470505873362} | train loss {'Reaction outcome loss': 0.1863981459317282, 'Total loss': 0.1863981459317282}
2023-01-04 23:05:43,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:43,905 INFO:     Epoch: 56
2023-01-04 23:05:46,142 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4974871943394343, 'Total loss': 0.4974871943394343} | train loss {'Reaction outcome loss': 0.18778332888846358, 'Total loss': 0.18778332888846358}
2023-01-04 23:05:46,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:46,143 INFO:     Epoch: 57
2023-01-04 23:05:48,378 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4449745977918307, 'Total loss': 0.4449745977918307} | train loss {'Reaction outcome loss': 0.191468291266433, 'Total loss': 0.191468291266433}
2023-01-04 23:05:48,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:48,379 INFO:     Epoch: 58
2023-01-04 23:05:50,607 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5080086380243302, 'Total loss': 0.5080086380243302} | train loss {'Reaction outcome loss': 0.18547339005760052, 'Total loss': 0.18547339005760052}
2023-01-04 23:05:50,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:50,607 INFO:     Epoch: 59
2023-01-04 23:05:52,834 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47044441203276316, 'Total loss': 0.47044441203276316} | train loss {'Reaction outcome loss': 0.1907160684974981, 'Total loss': 0.1907160684974981}
2023-01-04 23:05:52,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:52,834 INFO:     Epoch: 60
2023-01-04 23:05:55,066 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4732558101415634, 'Total loss': 0.4732558101415634} | train loss {'Reaction outcome loss': 0.1897033141802213, 'Total loss': 0.1897033141802213}
2023-01-04 23:05:55,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:55,066 INFO:     Epoch: 61
2023-01-04 23:05:57,300 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5191257516543071, 'Total loss': 0.5191257516543071} | train loss {'Reaction outcome loss': 0.1824283016969302, 'Total loss': 0.1824283016969302}
2023-01-04 23:05:57,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:57,302 INFO:     Epoch: 62
2023-01-04 23:05:59,526 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5486579259236654, 'Total loss': 0.5486579259236654} | train loss {'Reaction outcome loss': 0.18084827262729516, 'Total loss': 0.18084827262729516}
2023-01-04 23:05:59,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:05:59,526 INFO:     Epoch: 63
2023-01-04 23:06:01,785 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49096909587581955, 'Total loss': 0.49096909587581955} | train loss {'Reaction outcome loss': 0.18153878315472186, 'Total loss': 0.18153878315472186}
2023-01-04 23:06:01,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:01,785 INFO:     Epoch: 64
2023-01-04 23:06:04,009 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49976858297983806, 'Total loss': 0.49976858297983806} | train loss {'Reaction outcome loss': 0.18083775129918409, 'Total loss': 0.18083775129918409}
2023-01-04 23:06:04,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:04,010 INFO:     Epoch: 65
2023-01-04 23:06:06,217 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4674285252888997, 'Total loss': 0.4674285252888997} | train loss {'Reaction outcome loss': 0.1810265697669444, 'Total loss': 0.1810265697669444}
2023-01-04 23:06:06,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:06,218 INFO:     Epoch: 66
2023-01-04 23:06:08,462 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5496967524290085, 'Total loss': 0.5496967524290085} | train loss {'Reaction outcome loss': 0.17667513277821545, 'Total loss': 0.17667513277821545}
2023-01-04 23:06:08,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:08,462 INFO:     Epoch: 67
2023-01-04 23:06:10,673 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48992016216119133, 'Total loss': 0.48992016216119133} | train loss {'Reaction outcome loss': 0.1727512467281405, 'Total loss': 0.1727512467281405}
2023-01-04 23:06:10,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:10,673 INFO:     Epoch: 68
2023-01-04 23:06:12,912 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49508923043807346, 'Total loss': 0.49508923043807346} | train loss {'Reaction outcome loss': 0.17149082431913357, 'Total loss': 0.17149082431913357}
2023-01-04 23:06:12,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:12,912 INFO:     Epoch: 69
2023-01-04 23:06:15,158 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5037112921476364, 'Total loss': 0.5037112921476364} | train loss {'Reaction outcome loss': 0.17493139315960152, 'Total loss': 0.17493139315960152}
2023-01-04 23:06:15,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:15,159 INFO:     Epoch: 70
2023-01-04 23:06:17,382 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.49980739057064055, 'Total loss': 0.49980739057064055} | train loss {'Reaction outcome loss': 0.17446653850589677, 'Total loss': 0.17446653850589677}
2023-01-04 23:06:17,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:17,383 INFO:     Epoch: 71
2023-01-04 23:06:19,622 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.497955189148585, 'Total loss': 0.497955189148585} | train loss {'Reaction outcome loss': 0.17667059437457705, 'Total loss': 0.17667059437457705}
2023-01-04 23:06:19,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:19,622 INFO:     Epoch: 72
2023-01-04 23:06:21,858 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.592695434888204, 'Total loss': 0.592695434888204} | train loss {'Reaction outcome loss': 0.17530519602737799, 'Total loss': 0.17530519602737799}
2023-01-04 23:06:21,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:21,858 INFO:     Epoch: 73
2023-01-04 23:06:24,007 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4826424211263657, 'Total loss': 0.4826424211263657} | train loss {'Reaction outcome loss': 0.1666440454112345, 'Total loss': 0.1666440454112345}
2023-01-04 23:06:24,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:24,007 INFO:     Epoch: 74
2023-01-04 23:06:26,237 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49063853969176613, 'Total loss': 0.49063853969176613} | train loss {'Reaction outcome loss': 0.1689041999196187, 'Total loss': 0.1689041999196187}
2023-01-04 23:06:26,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:26,238 INFO:     Epoch: 75
2023-01-04 23:06:28,398 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4362263639767965, 'Total loss': 0.4362263639767965} | train loss {'Reaction outcome loss': 0.1732318013772451, 'Total loss': 0.1732318013772451}
2023-01-04 23:06:28,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:28,398 INFO:     Epoch: 76
2023-01-04 23:06:30,639 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49520231982072194, 'Total loss': 0.49520231982072194} | train loss {'Reaction outcome loss': 0.16908138013372673, 'Total loss': 0.16908138013372673}
2023-01-04 23:06:30,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:30,639 INFO:     Epoch: 77
2023-01-04 23:06:32,802 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4941550135612488, 'Total loss': 0.4941550135612488} | train loss {'Reaction outcome loss': 0.16872339797759517, 'Total loss': 0.16872339797759517}
2023-01-04 23:06:32,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:32,803 INFO:     Epoch: 78
2023-01-04 23:06:34,831 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4707920422156652, 'Total loss': 0.4707920422156652} | train loss {'Reaction outcome loss': 0.16344820557856363, 'Total loss': 0.16344820557856363}
2023-01-04 23:06:34,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:34,831 INFO:     Epoch: 79
2023-01-04 23:06:37,135 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5310999482870102, 'Total loss': 0.5310999482870102} | train loss {'Reaction outcome loss': 0.1663971015018483, 'Total loss': 0.1663971015018483}
2023-01-04 23:06:37,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:37,135 INFO:     Epoch: 80
2023-01-04 23:06:39,389 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5128038316965103, 'Total loss': 0.5128038316965103} | train loss {'Reaction outcome loss': 0.16748624537964918, 'Total loss': 0.16748624537964918}
2023-01-04 23:06:39,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:39,390 INFO:     Epoch: 81
2023-01-04 23:06:41,566 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4396171653022369, 'Total loss': 0.4396171653022369} | train loss {'Reaction outcome loss': 0.16662079438470936, 'Total loss': 0.16662079438470936}
2023-01-04 23:06:41,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:41,567 INFO:     Epoch: 82
2023-01-04 23:06:43,724 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4953752875328064, 'Total loss': 0.4953752875328064} | train loss {'Reaction outcome loss': 0.17059049110282282, 'Total loss': 0.17059049110282282}
2023-01-04 23:06:43,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:43,724 INFO:     Epoch: 83
2023-01-04 23:06:45,962 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48252080132563907, 'Total loss': 0.48252080132563907} | train loss {'Reaction outcome loss': 0.16626894497914013, 'Total loss': 0.16626894497914013}
2023-01-04 23:06:45,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:45,963 INFO:     Epoch: 84
2023-01-04 23:06:48,170 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5215693900982539, 'Total loss': 0.5215693900982539} | train loss {'Reaction outcome loss': 0.16477972712897013, 'Total loss': 0.16477972712897013}
2023-01-04 23:06:48,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:48,171 INFO:     Epoch: 85
2023-01-04 23:06:50,380 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.489311021566391, 'Total loss': 0.489311021566391} | train loss {'Reaction outcome loss': 0.16413349485389092, 'Total loss': 0.16413349485389092}
2023-01-04 23:06:50,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:50,381 INFO:     Epoch: 86
2023-01-04 23:06:52,597 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5059827317794164, 'Total loss': 0.5059827317794164} | train loss {'Reaction outcome loss': 0.16324616415852275, 'Total loss': 0.16324616415852275}
2023-01-04 23:06:52,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:52,597 INFO:     Epoch: 87
2023-01-04 23:06:54,833 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.558528459072113, 'Total loss': 0.558528459072113} | train loss {'Reaction outcome loss': 0.16262326110498052, 'Total loss': 0.16262326110498052}
2023-01-04 23:06:54,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:54,833 INFO:     Epoch: 88
2023-01-04 23:06:57,069 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5028084009885788, 'Total loss': 0.5028084009885788} | train loss {'Reaction outcome loss': 0.16266191691311413, 'Total loss': 0.16266191691311413}
2023-01-04 23:06:57,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:57,070 INFO:     Epoch: 89
2023-01-04 23:06:59,296 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5389121860265732, 'Total loss': 0.5389121860265732} | train loss {'Reaction outcome loss': 0.1596847472959834, 'Total loss': 0.1596847472959834}
2023-01-04 23:06:59,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:06:59,296 INFO:     Epoch: 90
2023-01-04 23:07:01,546 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5228053996960322, 'Total loss': 0.5228053996960322} | train loss {'Reaction outcome loss': 0.1611953515549125, 'Total loss': 0.1611953515549125}
2023-01-04 23:07:01,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:01,546 INFO:     Epoch: 91
2023-01-04 23:07:03,773 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5181620651235183, 'Total loss': 0.5181620651235183} | train loss {'Reaction outcome loss': 0.16514447502400106, 'Total loss': 0.16514447502400106}
2023-01-04 23:07:03,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:03,774 INFO:     Epoch: 92
2023-01-04 23:07:06,014 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48095198074976603, 'Total loss': 0.48095198074976603} | train loss {'Reaction outcome loss': 0.1589824163055948, 'Total loss': 0.1589824163055948}
2023-01-04 23:07:06,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:06,015 INFO:     Epoch: 93
2023-01-04 23:07:08,247 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5022638832529386, 'Total loss': 0.5022638832529386} | train loss {'Reaction outcome loss': 0.1606174281977007, 'Total loss': 0.1606174281977007}
2023-01-04 23:07:08,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:08,247 INFO:     Epoch: 94
2023-01-04 23:07:10,460 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5686753928661347, 'Total loss': 0.5686753928661347} | train loss {'Reaction outcome loss': 0.15839996951291976, 'Total loss': 0.15839996951291976}
2023-01-04 23:07:10,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:10,461 INFO:     Epoch: 95
2023-01-04 23:07:12,697 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47513227760791776, 'Total loss': 0.47513227760791776} | train loss {'Reaction outcome loss': 0.1537649972378053, 'Total loss': 0.1537649972378053}
2023-01-04 23:07:12,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:12,697 INFO:     Epoch: 96
2023-01-04 23:07:14,937 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5367182202637195, 'Total loss': 0.5367182202637195} | train loss {'Reaction outcome loss': 0.155188713294911, 'Total loss': 0.155188713294911}
2023-01-04 23:07:14,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:14,938 INFO:     Epoch: 97
2023-01-04 23:07:17,137 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5176049947738648, 'Total loss': 0.5176049947738648} | train loss {'Reaction outcome loss': 0.15182883446826514, 'Total loss': 0.15182883446826514}
2023-01-04 23:07:17,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:17,137 INFO:     Epoch: 98
2023-01-04 23:07:19,380 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47373811503251395, 'Total loss': 0.47373811503251395} | train loss {'Reaction outcome loss': 0.15230033388859643, 'Total loss': 0.15230033388859643}
2023-01-04 23:07:19,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:19,380 INFO:     Epoch: 99
2023-01-04 23:07:21,603 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5355183084805807, 'Total loss': 0.5355183084805807} | train loss {'Reaction outcome loss': 0.15943546761411528, 'Total loss': 0.15943546761411528}
2023-01-04 23:07:21,603 INFO:     Best model found after epoch 32 of 100.
2023-01-04 23:07:21,603 INFO:   Done with stage: TRAINING
2023-01-04 23:07:21,603 INFO:   Starting stage: EVALUATION
2023-01-04 23:07:21,758 INFO:   Done with stage: EVALUATION
2023-01-04 23:07:21,759 INFO:   Leaving out SEQ value Fold_2
2023-01-04 23:07:21,772 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 23:07:21,772 INFO:   Starting stage: FEATURE SCALING
2023-01-04 23:07:22,420 INFO:   Done with stage: FEATURE SCALING
2023-01-04 23:07:22,420 INFO:   Starting stage: SCALING TARGETS
2023-01-04 23:07:22,492 INFO:   Done with stage: SCALING TARGETS
2023-01-04 23:07:22,493 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:07:22,493 INFO:     No hyperparam tuning for this model
2023-01-04 23:07:22,493 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:07:22,493 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 23:07:22,494 INFO:     None feature selector for col prot
2023-01-04 23:07:22,494 INFO:     None feature selector for col prot
2023-01-04 23:07:22,494 INFO:     None feature selector for col prot
2023-01-04 23:07:22,495 INFO:     None feature selector for col chem
2023-01-04 23:07:22,495 INFO:     None feature selector for col chem
2023-01-04 23:07:22,495 INFO:     None feature selector for col chem
2023-01-04 23:07:22,495 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 23:07:22,495 INFO:   Starting stage: BUILD MODEL
2023-01-04 23:07:22,497 INFO:     Number of params in model 72931
2023-01-04 23:07:22,500 INFO:   Done with stage: BUILD MODEL
2023-01-04 23:07:22,500 INFO:   Starting stage: TRAINING
2023-01-04 23:07:22,561 INFO:     Val loss before train {'Reaction outcome loss': 1.0027346849441527, 'Total loss': 1.0027346849441527}
2023-01-04 23:07:22,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:22,561 INFO:     Epoch: 0
2023-01-04 23:07:24,822 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6895147760709127, 'Total loss': 0.6895147760709127} | train loss {'Reaction outcome loss': 0.9290985624049453, 'Total loss': 0.9290985624049453}
2023-01-04 23:07:24,822 INFO:     Found new best model at epoch 0
2023-01-04 23:07:24,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:24,823 INFO:     Epoch: 1
2023-01-04 23:07:27,078 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4803318381309509, 'Total loss': 0.4803318381309509} | train loss {'Reaction outcome loss': 0.6178640231922052, 'Total loss': 0.6178640231922052}
2023-01-04 23:07:27,078 INFO:     Found new best model at epoch 1
2023-01-04 23:07:27,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:27,079 INFO:     Epoch: 2
2023-01-04 23:07:29,356 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4580019364754359, 'Total loss': 0.4580019364754359} | train loss {'Reaction outcome loss': 0.5172150963647426, 'Total loss': 0.5172150963647426}
2023-01-04 23:07:29,356 INFO:     Found new best model at epoch 2
2023-01-04 23:07:29,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:29,357 INFO:     Epoch: 3
2023-01-04 23:07:31,638 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.43858763178189597, 'Total loss': 0.43858763178189597} | train loss {'Reaction outcome loss': 0.4833416197502959, 'Total loss': 0.4833416197502959}
2023-01-04 23:07:31,638 INFO:     Found new best model at epoch 3
2023-01-04 23:07:31,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:31,640 INFO:     Epoch: 4
2023-01-04 23:07:33,899 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4481622556845347, 'Total loss': 0.4481622556845347} | train loss {'Reaction outcome loss': 0.4537859154406233, 'Total loss': 0.4537859154406233}
2023-01-04 23:07:33,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:33,901 INFO:     Epoch: 5
2023-01-04 23:07:36,167 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43150551517804464, 'Total loss': 0.43150551517804464} | train loss {'Reaction outcome loss': 0.44892646404712094, 'Total loss': 0.44892646404712094}
2023-01-04 23:07:36,168 INFO:     Found new best model at epoch 5
2023-01-04 23:07:36,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:36,169 INFO:     Epoch: 6
2023-01-04 23:07:38,402 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42106285840272906, 'Total loss': 0.42106285840272906} | train loss {'Reaction outcome loss': 0.4281062895661571, 'Total loss': 0.4281062895661571}
2023-01-04 23:07:38,402 INFO:     Found new best model at epoch 6
2023-01-04 23:07:38,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:38,404 INFO:     Epoch: 7
2023-01-04 23:07:40,638 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42697646220525104, 'Total loss': 0.42697646220525104} | train loss {'Reaction outcome loss': 0.3968882561556698, 'Total loss': 0.3968882561556698}
2023-01-04 23:07:40,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:40,639 INFO:     Epoch: 8
2023-01-04 23:07:42,920 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42249574363231657, 'Total loss': 0.42249574363231657} | train loss {'Reaction outcome loss': 0.38017022402609524, 'Total loss': 0.38017022402609524}
2023-01-04 23:07:42,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:42,920 INFO:     Epoch: 9
2023-01-04 23:07:45,098 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.38648763100306194, 'Total loss': 0.38648763100306194} | train loss {'Reaction outcome loss': 0.3718299174097542, 'Total loss': 0.3718299174097542}
2023-01-04 23:07:45,098 INFO:     Found new best model at epoch 9
2023-01-04 23:07:45,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:45,099 INFO:     Epoch: 10
2023-01-04 23:07:47,386 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4115360274910927, 'Total loss': 0.4115360274910927} | train loss {'Reaction outcome loss': 0.36129362246298324, 'Total loss': 0.36129362246298324}
2023-01-04 23:07:47,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:47,386 INFO:     Epoch: 11
2023-01-04 23:07:49,662 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3896181578437487, 'Total loss': 0.3896181578437487} | train loss {'Reaction outcome loss': 0.34954572902600944, 'Total loss': 0.34954572902600944}
2023-01-04 23:07:49,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:49,662 INFO:     Epoch: 12
2023-01-04 23:07:51,921 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40207693179448445, 'Total loss': 0.40207693179448445} | train loss {'Reaction outcome loss': 0.33992328152458684, 'Total loss': 0.33992328152458684}
2023-01-04 23:07:51,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:51,921 INFO:     Epoch: 13
2023-01-04 23:07:54,228 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3981658548116684, 'Total loss': 0.3981658548116684} | train loss {'Reaction outcome loss': 0.33002229390122934, 'Total loss': 0.33002229390122934}
2023-01-04 23:07:54,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:54,229 INFO:     Epoch: 14
2023-01-04 23:07:56,514 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3969292938709259, 'Total loss': 0.3969292938709259} | train loss {'Reaction outcome loss': 0.32364735339322814, 'Total loss': 0.32364735339322814}
2023-01-04 23:07:56,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:56,514 INFO:     Epoch: 15
2023-01-04 23:07:58,853 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4072243998448054, 'Total loss': 0.4072243998448054} | train loss {'Reaction outcome loss': 0.31525572642103594, 'Total loss': 0.31525572642103594}
2023-01-04 23:07:58,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:07:58,853 INFO:     Epoch: 16
2023-01-04 23:08:01,104 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.407903246084849, 'Total loss': 0.407903246084849} | train loss {'Reaction outcome loss': 0.3040853899066755, 'Total loss': 0.3040853899066755}
2023-01-04 23:08:01,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:01,104 INFO:     Epoch: 17
2023-01-04 23:08:03,360 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.37176061421632767, 'Total loss': 0.37176061421632767} | train loss {'Reaction outcome loss': 0.3029914635631755, 'Total loss': 0.3029914635631755}
2023-01-04 23:08:03,360 INFO:     Found new best model at epoch 17
2023-01-04 23:08:03,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:03,362 INFO:     Epoch: 18
2023-01-04 23:08:05,637 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3857260763645172, 'Total loss': 0.3857260763645172} | train loss {'Reaction outcome loss': 0.2899652523531889, 'Total loss': 0.2899652523531889}
2023-01-04 23:08:05,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:05,637 INFO:     Epoch: 19
2023-01-04 23:08:07,896 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3874445075790087, 'Total loss': 0.3874445075790087} | train loss {'Reaction outcome loss': 0.2853251006184281, 'Total loss': 0.2853251006184281}
2023-01-04 23:08:07,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:07,896 INFO:     Epoch: 20
2023-01-04 23:08:10,134 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38606420159339905, 'Total loss': 0.38606420159339905} | train loss {'Reaction outcome loss': 0.28111405902925163, 'Total loss': 0.28111405902925163}
2023-01-04 23:08:10,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:10,135 INFO:     Epoch: 21
2023-01-04 23:08:12,416 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4090987871090571, 'Total loss': 0.4090987871090571} | train loss {'Reaction outcome loss': 0.2739070083475616, 'Total loss': 0.2739070083475616}
2023-01-04 23:08:12,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:12,416 INFO:     Epoch: 22
2023-01-04 23:08:14,674 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38745068858067194, 'Total loss': 0.38745068858067194} | train loss {'Reaction outcome loss': 0.26665622000312567, 'Total loss': 0.26665622000312567}
2023-01-04 23:08:14,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:14,674 INFO:     Epoch: 23
2023-01-04 23:08:16,955 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39814793268839516, 'Total loss': 0.39814793268839516} | train loss {'Reaction outcome loss': 0.27473017630045826, 'Total loss': 0.27473017630045826}
2023-01-04 23:08:16,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:16,956 INFO:     Epoch: 24
2023-01-04 23:08:19,217 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.37779061297575633, 'Total loss': 0.37779061297575633} | train loss {'Reaction outcome loss': 0.2897166365224436, 'Total loss': 0.2897166365224436}
2023-01-04 23:08:19,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:19,217 INFO:     Epoch: 25
2023-01-04 23:08:21,489 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41712616632382077, 'Total loss': 0.41712616632382077} | train loss {'Reaction outcome loss': 0.26023736804642755, 'Total loss': 0.26023736804642755}
2023-01-04 23:08:21,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:21,489 INFO:     Epoch: 26
2023-01-04 23:08:23,771 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4110137909650803, 'Total loss': 0.4110137909650803} | train loss {'Reaction outcome loss': 0.2517664590513037, 'Total loss': 0.2517664590513037}
2023-01-04 23:08:23,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:23,771 INFO:     Epoch: 27
2023-01-04 23:08:26,029 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39743179380893706, 'Total loss': 0.39743179380893706} | train loss {'Reaction outcome loss': 0.25119894921469194, 'Total loss': 0.25119894921469194}
2023-01-04 23:08:26,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:26,029 INFO:     Epoch: 28
2023-01-04 23:08:28,313 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38463334888219836, 'Total loss': 0.38463334888219836} | train loss {'Reaction outcome loss': 0.24516433531054013, 'Total loss': 0.24516433531054013}
2023-01-04 23:08:28,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:28,313 INFO:     Epoch: 29
2023-01-04 23:08:30,545 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40563995043436685, 'Total loss': 0.40563995043436685} | train loss {'Reaction outcome loss': 0.2407168365906978, 'Total loss': 0.2407168365906978}
2023-01-04 23:08:30,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:30,545 INFO:     Epoch: 30
2023-01-04 23:08:32,812 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41348368922869366, 'Total loss': 0.41348368922869366} | train loss {'Reaction outcome loss': 0.23845768641141427, 'Total loss': 0.23845768641141427}
2023-01-04 23:08:32,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:32,813 INFO:     Epoch: 31
2023-01-04 23:08:35,090 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3954228460788727, 'Total loss': 0.3954228460788727} | train loss {'Reaction outcome loss': 0.23679275364206726, 'Total loss': 0.23679275364206726}
2023-01-04 23:08:35,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:35,091 INFO:     Epoch: 32
2023-01-04 23:08:37,356 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4157760411500931, 'Total loss': 0.4157760411500931} | train loss {'Reaction outcome loss': 0.23037967734052328, 'Total loss': 0.23037967734052328}
2023-01-04 23:08:37,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:37,357 INFO:     Epoch: 33
2023-01-04 23:08:39,631 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4413958306113879, 'Total loss': 0.4413958306113879} | train loss {'Reaction outcome loss': 0.22530172753613442, 'Total loss': 0.22530172753613442}
2023-01-04 23:08:39,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:39,632 INFO:     Epoch: 34
2023-01-04 23:08:41,915 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42287447055180866, 'Total loss': 0.42287447055180866} | train loss {'Reaction outcome loss': 0.2304612673798819, 'Total loss': 0.2304612673798819}
2023-01-04 23:08:41,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:41,915 INFO:     Epoch: 35
2023-01-04 23:08:44,185 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42266472776730857, 'Total loss': 0.42266472776730857} | train loss {'Reaction outcome loss': 0.22863196635254376, 'Total loss': 0.22863196635254376}
2023-01-04 23:08:44,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:44,185 INFO:     Epoch: 36
2023-01-04 23:08:46,441 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3928883713980516, 'Total loss': 0.3928883713980516} | train loss {'Reaction outcome loss': 0.22879006868174326, 'Total loss': 0.22879006868174326}
2023-01-04 23:08:46,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:46,442 INFO:     Epoch: 37
2023-01-04 23:08:48,692 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39845311144987744, 'Total loss': 0.39845311144987744} | train loss {'Reaction outcome loss': 0.21735271093422087, 'Total loss': 0.21735271093422087}
2023-01-04 23:08:48,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:48,692 INFO:     Epoch: 38
2023-01-04 23:08:50,985 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4237007220586141, 'Total loss': 0.4237007220586141} | train loss {'Reaction outcome loss': 0.21731888492713156, 'Total loss': 0.21731888492713156}
2023-01-04 23:08:50,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:50,985 INFO:     Epoch: 39
2023-01-04 23:08:53,227 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4220890089869499, 'Total loss': 0.4220890089869499} | train loss {'Reaction outcome loss': 0.2174152970771462, 'Total loss': 0.2174152970771462}
2023-01-04 23:08:53,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:53,227 INFO:     Epoch: 40
2023-01-04 23:08:55,482 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4522861401240031, 'Total loss': 0.4522861401240031} | train loss {'Reaction outcome loss': 0.21526628849434032, 'Total loss': 0.21526628849434032}
2023-01-04 23:08:55,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:55,482 INFO:     Epoch: 41
2023-01-04 23:08:57,757 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4418231358130773, 'Total loss': 0.4418231358130773} | train loss {'Reaction outcome loss': 0.21642250412791644, 'Total loss': 0.21642250412791644}
2023-01-04 23:08:57,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:08:57,757 INFO:     Epoch: 42
2023-01-04 23:09:00,011 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45326775312423706, 'Total loss': 0.45326775312423706} | train loss {'Reaction outcome loss': 0.21117429165642007, 'Total loss': 0.21117429165642007}
2023-01-04 23:09:00,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:00,012 INFO:     Epoch: 43
2023-01-04 23:09:02,260 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42859416802724204, 'Total loss': 0.42859416802724204} | train loss {'Reaction outcome loss': 0.20874519780298453, 'Total loss': 0.20874519780298453}
2023-01-04 23:09:02,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:02,260 INFO:     Epoch: 44
2023-01-04 23:09:04,540 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4428001304467519, 'Total loss': 0.4428001304467519} | train loss {'Reaction outcome loss': 0.20507907542481046, 'Total loss': 0.20507907542481046}
2023-01-04 23:09:04,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:04,540 INFO:     Epoch: 45
2023-01-04 23:09:06,803 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44403369625409445, 'Total loss': 0.44403369625409445} | train loss {'Reaction outcome loss': 0.20216537077668245, 'Total loss': 0.20216537077668245}
2023-01-04 23:09:06,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:06,803 INFO:     Epoch: 46
2023-01-04 23:09:09,073 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4402440309524536, 'Total loss': 0.4402440309524536} | train loss {'Reaction outcome loss': 0.20472230972507902, 'Total loss': 0.20472230972507902}
2023-01-04 23:09:09,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:09,073 INFO:     Epoch: 47
2023-01-04 23:09:11,359 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45365475714206693, 'Total loss': 0.45365475714206693} | train loss {'Reaction outcome loss': 0.20534676560150136, 'Total loss': 0.20534676560150136}
2023-01-04 23:09:11,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:11,359 INFO:     Epoch: 48
2023-01-04 23:09:13,610 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4523834817111492, 'Total loss': 0.4523834817111492} | train loss {'Reaction outcome loss': 0.19418031987742576, 'Total loss': 0.19418031987742576}
2023-01-04 23:09:13,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:13,610 INFO:     Epoch: 49
2023-01-04 23:09:15,888 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4210240483283997, 'Total loss': 0.4210240483283997} | train loss {'Reaction outcome loss': 0.19319731695298065, 'Total loss': 0.19319731695298065}
2023-01-04 23:09:15,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:15,889 INFO:     Epoch: 50
2023-01-04 23:09:18,152 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4186194181442261, 'Total loss': 0.4186194181442261} | train loss {'Reaction outcome loss': 0.195936672685907, 'Total loss': 0.195936672685907}
2023-01-04 23:09:18,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:18,152 INFO:     Epoch: 51
2023-01-04 23:09:20,410 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43718496362368264, 'Total loss': 0.43718496362368264} | train loss {'Reaction outcome loss': 0.1925643183912262, 'Total loss': 0.1925643183912262}
2023-01-04 23:09:20,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:20,410 INFO:     Epoch: 52
2023-01-04 23:09:22,677 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4464335968097051, 'Total loss': 0.4464335968097051} | train loss {'Reaction outcome loss': 0.19425520687482145, 'Total loss': 0.19425520687482145}
2023-01-04 23:09:22,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:22,678 INFO:     Epoch: 53
2023-01-04 23:09:24,929 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4517076482375463, 'Total loss': 0.4517076482375463} | train loss {'Reaction outcome loss': 0.19342873980562805, 'Total loss': 0.19342873980562805}
2023-01-04 23:09:24,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:24,929 INFO:     Epoch: 54
2023-01-04 23:09:27,207 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4316319525241852, 'Total loss': 0.4316319525241852} | train loss {'Reaction outcome loss': 0.19249547135708997, 'Total loss': 0.19249547135708997}
2023-01-04 23:09:27,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:27,207 INFO:     Epoch: 55
2023-01-04 23:09:29,447 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4579405774672826, 'Total loss': 0.4579405774672826} | train loss {'Reaction outcome loss': 0.19314821167221374, 'Total loss': 0.19314821167221374}
2023-01-04 23:09:29,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:29,447 INFO:     Epoch: 56
2023-01-04 23:09:31,730 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43652844230333965, 'Total loss': 0.43652844230333965} | train loss {'Reaction outcome loss': 0.18933828077127185, 'Total loss': 0.18933828077127185}
2023-01-04 23:09:31,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:31,731 INFO:     Epoch: 57
2023-01-04 23:09:33,941 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44976813197135923, 'Total loss': 0.44976813197135923} | train loss {'Reaction outcome loss': 0.1912906325061171, 'Total loss': 0.1912906325061171}
2023-01-04 23:09:33,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:33,941 INFO:     Epoch: 58
2023-01-04 23:09:36,092 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4448911408583323, 'Total loss': 0.4448911408583323} | train loss {'Reaction outcome loss': 0.18699556445378973, 'Total loss': 0.18699556445378973}
2023-01-04 23:09:36,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:36,093 INFO:     Epoch: 59
2023-01-04 23:09:38,357 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4573423077662786, 'Total loss': 0.4573423077662786} | train loss {'Reaction outcome loss': 0.20297763560750132, 'Total loss': 0.20297763560750132}
2023-01-04 23:09:38,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:38,358 INFO:     Epoch: 60
2023-01-04 23:09:40,589 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44842349489529926, 'Total loss': 0.44842349489529926} | train loss {'Reaction outcome loss': 0.23237191783804176, 'Total loss': 0.23237191783804176}
2023-01-04 23:09:40,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:40,589 INFO:     Epoch: 61
2023-01-04 23:09:42,856 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4793724060058594, 'Total loss': 0.4793724060058594} | train loss {'Reaction outcome loss': 0.19212771753341817, 'Total loss': 0.19212771753341817}
2023-01-04 23:09:42,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:42,856 INFO:     Epoch: 62
2023-01-04 23:09:45,120 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4803530106941859, 'Total loss': 0.4803530106941859} | train loss {'Reaction outcome loss': 0.18389654040520723, 'Total loss': 0.18389654040520723}
2023-01-04 23:09:45,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:45,120 INFO:     Epoch: 63
2023-01-04 23:09:47,373 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4398758860925833, 'Total loss': 0.4398758860925833} | train loss {'Reaction outcome loss': 0.18662465961677008, 'Total loss': 0.18662465961677008}
2023-01-04 23:09:47,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:47,373 INFO:     Epoch: 64
2023-01-04 23:09:49,606 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46525485490759216, 'Total loss': 0.46525485490759216} | train loss {'Reaction outcome loss': 0.19026069077865584, 'Total loss': 0.19026069077865584}
2023-01-04 23:09:49,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:49,606 INFO:     Epoch: 65
2023-01-04 23:09:51,870 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4622727811336517, 'Total loss': 0.4622727811336517} | train loss {'Reaction outcome loss': 0.18108639703026763, 'Total loss': 0.18108639703026763}
2023-01-04 23:09:51,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:51,871 INFO:     Epoch: 66
2023-01-04 23:09:54,083 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48550613621870675, 'Total loss': 0.48550613621870675} | train loss {'Reaction outcome loss': 0.17890304028085244, 'Total loss': 0.17890304028085244}
2023-01-04 23:09:54,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:54,083 INFO:     Epoch: 67
2023-01-04 23:09:56,356 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4609255741039912, 'Total loss': 0.4609255741039912} | train loss {'Reaction outcome loss': 0.18113095139552318, 'Total loss': 0.18113095139552318}
2023-01-04 23:09:56,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:56,357 INFO:     Epoch: 68
2023-01-04 23:09:58,619 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4640326937039693, 'Total loss': 0.4640326937039693} | train loss {'Reaction outcome loss': 0.17604531389359024, 'Total loss': 0.17604531389359024}
2023-01-04 23:09:58,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:09:58,620 INFO:     Epoch: 69
2023-01-04 23:10:00,886 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45269510000944135, 'Total loss': 0.45269510000944135} | train loss {'Reaction outcome loss': 0.17504129698500037, 'Total loss': 0.17504129698500037}
2023-01-04 23:10:00,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:00,886 INFO:     Epoch: 70
2023-01-04 23:10:03,157 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4380248417456945, 'Total loss': 0.4380248417456945} | train loss {'Reaction outcome loss': 0.1718090372396282, 'Total loss': 0.1718090372396282}
2023-01-04 23:10:03,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:03,157 INFO:     Epoch: 71
2023-01-04 23:10:05,433 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4542306890090307, 'Total loss': 0.4542306890090307} | train loss {'Reaction outcome loss': 0.1777464447853466, 'Total loss': 0.1777464447853466}
2023-01-04 23:10:05,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:05,433 INFO:     Epoch: 72
2023-01-04 23:10:07,707 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4543784221013387, 'Total loss': 0.4543784221013387} | train loss {'Reaction outcome loss': 0.17530828184048322, 'Total loss': 0.17530828184048322}
2023-01-04 23:10:07,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:07,707 INFO:     Epoch: 73
2023-01-04 23:10:09,958 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4895060251156489, 'Total loss': 0.4895060251156489} | train loss {'Reaction outcome loss': 0.17714748426890542, 'Total loss': 0.17714748426890542}
2023-01-04 23:10:09,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:09,958 INFO:     Epoch: 74
2023-01-04 23:10:12,206 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4640013371904691, 'Total loss': 0.4640013371904691} | train loss {'Reaction outcome loss': 0.1725399100438496, 'Total loss': 0.1725399100438496}
2023-01-04 23:10:12,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:12,207 INFO:     Epoch: 75
2023-01-04 23:10:14,417 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46875369747479756, 'Total loss': 0.46875369747479756} | train loss {'Reaction outcome loss': 0.17113323263280714, 'Total loss': 0.17113323263280714}
2023-01-04 23:10:14,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:14,417 INFO:     Epoch: 76
2023-01-04 23:10:16,649 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5013247927029928, 'Total loss': 0.5013247927029928} | train loss {'Reaction outcome loss': 0.17389924052944136, 'Total loss': 0.17389924052944136}
2023-01-04 23:10:16,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:16,649 INFO:     Epoch: 77
2023-01-04 23:10:18,933 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45682883461316426, 'Total loss': 0.45682883461316426} | train loss {'Reaction outcome loss': 0.17103710974249448, 'Total loss': 0.17103710974249448}
2023-01-04 23:10:18,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:18,933 INFO:     Epoch: 78
2023-01-04 23:10:21,211 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4662534733613332, 'Total loss': 0.4662534733613332} | train loss {'Reaction outcome loss': 0.17215578032904677, 'Total loss': 0.17215578032904677}
2023-01-04 23:10:21,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:21,211 INFO:     Epoch: 79
2023-01-04 23:10:23,435 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4717848678429922, 'Total loss': 0.4717848678429922} | train loss {'Reaction outcome loss': 0.17180570880895096, 'Total loss': 0.17180570880895096}
2023-01-04 23:10:23,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:23,435 INFO:     Epoch: 80
2023-01-04 23:10:25,715 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4834986979762713, 'Total loss': 0.4834986979762713} | train loss {'Reaction outcome loss': 0.17638744529276795, 'Total loss': 0.17638744529276795}
2023-01-04 23:10:25,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:25,715 INFO:     Epoch: 81
2023-01-04 23:10:27,987 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4596873660882314, 'Total loss': 0.4596873660882314} | train loss {'Reaction outcome loss': 0.1716358307478557, 'Total loss': 0.1716358307478557}
2023-01-04 23:10:27,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:27,989 INFO:     Epoch: 82
2023-01-04 23:10:30,277 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44999164827167987, 'Total loss': 0.44999164827167987} | train loss {'Reaction outcome loss': 0.16744214836601884, 'Total loss': 0.16744214836601884}
2023-01-04 23:10:30,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:30,277 INFO:     Epoch: 83
2023-01-04 23:10:32,524 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4763963041206201, 'Total loss': 0.4763963041206201} | train loss {'Reaction outcome loss': 0.16909669389766033, 'Total loss': 0.16909669389766033}
2023-01-04 23:10:32,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:32,524 INFO:     Epoch: 84
2023-01-04 23:10:34,777 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47326672573884326, 'Total loss': 0.47326672573884326} | train loss {'Reaction outcome loss': 0.1687239729579997, 'Total loss': 0.1687239729579997}
2023-01-04 23:10:34,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:34,778 INFO:     Epoch: 85
2023-01-04 23:10:37,037 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47283487816651665, 'Total loss': 0.47283487816651665} | train loss {'Reaction outcome loss': 0.16542510558047466, 'Total loss': 0.16542510558047466}
2023-01-04 23:10:37,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:37,037 INFO:     Epoch: 86
2023-01-04 23:10:39,257 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48510177731513976, 'Total loss': 0.48510177731513976} | train loss {'Reaction outcome loss': 0.1668289033426107, 'Total loss': 0.1668289033426107}
2023-01-04 23:10:39,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:39,257 INFO:     Epoch: 87
2023-01-04 23:10:41,430 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46533615589141847, 'Total loss': 0.46533615589141847} | train loss {'Reaction outcome loss': 0.17635289467659238, 'Total loss': 0.17635289467659238}
2023-01-04 23:10:41,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:41,430 INFO:     Epoch: 88
2023-01-04 23:10:43,585 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48060145825147627, 'Total loss': 0.48060145825147627} | train loss {'Reaction outcome loss': 0.16403701494910175, 'Total loss': 0.16403701494910175}
2023-01-04 23:10:43,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:43,585 INFO:     Epoch: 89
2023-01-04 23:10:45,816 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4583289941151937, 'Total loss': 0.4583289941151937} | train loss {'Reaction outcome loss': 0.1615396052767882, 'Total loss': 0.1615396052767882}
2023-01-04 23:10:45,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:45,817 INFO:     Epoch: 90
2023-01-04 23:10:48,067 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46528915911912916, 'Total loss': 0.46528915911912916} | train loss {'Reaction outcome loss': 0.15962549520359523, 'Total loss': 0.15962549520359523}
2023-01-04 23:10:48,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:48,068 INFO:     Epoch: 91
2023-01-04 23:10:50,335 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4633664737145106, 'Total loss': 0.4633664737145106} | train loss {'Reaction outcome loss': 0.16656512348824923, 'Total loss': 0.16656512348824923}
2023-01-04 23:10:50,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:50,336 INFO:     Epoch: 92
2023-01-04 23:10:52,583 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.474672931432724, 'Total loss': 0.474672931432724} | train loss {'Reaction outcome loss': 0.16129211169174887, 'Total loss': 0.16129211169174887}
2023-01-04 23:10:52,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:52,584 INFO:     Epoch: 93
2023-01-04 23:10:54,828 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45518546203772225, 'Total loss': 0.45518546203772225} | train loss {'Reaction outcome loss': 0.16228668237412078, 'Total loss': 0.16228668237412078}
2023-01-04 23:10:54,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:54,828 INFO:     Epoch: 94
2023-01-04 23:10:57,092 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4716008722782135, 'Total loss': 0.4716008722782135} | train loss {'Reaction outcome loss': 0.16444236914411295, 'Total loss': 0.16444236914411295}
2023-01-04 23:10:57,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:57,092 INFO:     Epoch: 95
2023-01-04 23:10:59,322 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46189482013384503, 'Total loss': 0.46189482013384503} | train loss {'Reaction outcome loss': 0.16068326850232761, 'Total loss': 0.16068326850232761}
2023-01-04 23:10:59,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:10:59,322 INFO:     Epoch: 96
2023-01-04 23:11:01,574 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48149001598358154, 'Total loss': 0.48149001598358154} | train loss {'Reaction outcome loss': 0.1609416775425653, 'Total loss': 0.1609416775425653}
2023-01-04 23:11:01,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:01,575 INFO:     Epoch: 97
2023-01-04 23:11:03,833 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4594624360402425, 'Total loss': 0.4594624360402425} | train loss {'Reaction outcome loss': 0.16248998829489236, 'Total loss': 0.16248998829489236}
2023-01-04 23:11:03,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:03,834 INFO:     Epoch: 98
2023-01-04 23:11:06,098 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4599656224250793, 'Total loss': 0.4599656224250793} | train loss {'Reaction outcome loss': 0.1581696234289152, 'Total loss': 0.1581696234289152}
2023-01-04 23:11:06,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:06,099 INFO:     Epoch: 99
2023-01-04 23:11:08,329 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4727440387010574, 'Total loss': 0.4727440387010574} | train loss {'Reaction outcome loss': 0.1602017667778916, 'Total loss': 0.1602017667778916}
2023-01-04 23:11:08,329 INFO:     Best model found after epoch 18 of 100.
2023-01-04 23:11:08,329 INFO:   Done with stage: TRAINING
2023-01-04 23:11:08,329 INFO:   Starting stage: EVALUATION
2023-01-04 23:11:08,464 INFO:   Done with stage: EVALUATION
2023-01-04 23:11:08,464 INFO:   Leaving out SEQ value Fold_3
2023-01-04 23:11:08,477 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 23:11:08,477 INFO:   Starting stage: FEATURE SCALING
2023-01-04 23:11:09,134 INFO:   Done with stage: FEATURE SCALING
2023-01-04 23:11:09,134 INFO:   Starting stage: SCALING TARGETS
2023-01-04 23:11:09,206 INFO:   Done with stage: SCALING TARGETS
2023-01-04 23:11:09,206 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:11:09,206 INFO:     No hyperparam tuning for this model
2023-01-04 23:11:09,206 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:11:09,206 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 23:11:09,207 INFO:     None feature selector for col prot
2023-01-04 23:11:09,207 INFO:     None feature selector for col prot
2023-01-04 23:11:09,207 INFO:     None feature selector for col prot
2023-01-04 23:11:09,208 INFO:     None feature selector for col chem
2023-01-04 23:11:09,208 INFO:     None feature selector for col chem
2023-01-04 23:11:09,208 INFO:     None feature selector for col chem
2023-01-04 23:11:09,208 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 23:11:09,208 INFO:   Starting stage: BUILD MODEL
2023-01-04 23:11:09,209 INFO:     Number of params in model 72931
2023-01-04 23:11:09,213 INFO:   Done with stage: BUILD MODEL
2023-01-04 23:11:09,213 INFO:   Starting stage: TRAINING
2023-01-04 23:11:09,273 INFO:     Val loss before train {'Reaction outcome loss': 1.095068621635437, 'Total loss': 1.095068621635437}
2023-01-04 23:11:09,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:09,273 INFO:     Epoch: 0
2023-01-04 23:11:11,493 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7703462302684784, 'Total loss': 0.7703462302684784} | train loss {'Reaction outcome loss': 0.9295076566301422, 'Total loss': 0.9295076566301422}
2023-01-04 23:11:11,494 INFO:     Found new best model at epoch 0
2023-01-04 23:11:11,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:11,495 INFO:     Epoch: 1
2023-01-04 23:11:13,732 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5423811237017314, 'Total loss': 0.5423811237017314} | train loss {'Reaction outcome loss': 0.6095410114897913, 'Total loss': 0.6095410114897913}
2023-01-04 23:11:13,732 INFO:     Found new best model at epoch 1
2023-01-04 23:11:13,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:13,733 INFO:     Epoch: 2
2023-01-04 23:11:15,991 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5139554659525554, 'Total loss': 0.5139554659525554} | train loss {'Reaction outcome loss': 0.5201021376110259, 'Total loss': 0.5201021376110259}
2023-01-04 23:11:15,991 INFO:     Found new best model at epoch 2
2023-01-04 23:11:15,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:15,992 INFO:     Epoch: 3
2023-01-04 23:11:18,264 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4960729012886683, 'Total loss': 0.4960729012886683} | train loss {'Reaction outcome loss': 0.4773553667160181, 'Total loss': 0.4773553667160181}
2023-01-04 23:11:18,264 INFO:     Found new best model at epoch 3
2023-01-04 23:11:18,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:18,266 INFO:     Epoch: 4
2023-01-04 23:11:20,491 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46853497525056204, 'Total loss': 0.46853497525056204} | train loss {'Reaction outcome loss': 0.44288977838697885, 'Total loss': 0.44288977838697885}
2023-01-04 23:11:20,491 INFO:     Found new best model at epoch 4
2023-01-04 23:11:20,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:20,493 INFO:     Epoch: 5
2023-01-04 23:11:22,700 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4696069290240606, 'Total loss': 0.4696069290240606} | train loss {'Reaction outcome loss': 0.42221911049587824, 'Total loss': 0.42221911049587824}
2023-01-04 23:11:22,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:22,701 INFO:     Epoch: 6
2023-01-04 23:11:24,952 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45266509453455606, 'Total loss': 0.45266509453455606} | train loss {'Reaction outcome loss': 0.4032116249039933, 'Total loss': 0.4032116249039933}
2023-01-04 23:11:24,953 INFO:     Found new best model at epoch 6
2023-01-04 23:11:24,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:24,954 INFO:     Epoch: 7
2023-01-04 23:11:27,210 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45916943848133085, 'Total loss': 0.45916943848133085} | train loss {'Reaction outcome loss': 0.3843354829501756, 'Total loss': 0.3843354829501756}
2023-01-04 23:11:27,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:27,210 INFO:     Epoch: 8
2023-01-04 23:11:29,454 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4289192060629527, 'Total loss': 0.4289192060629527} | train loss {'Reaction outcome loss': 0.36997319206650003, 'Total loss': 0.36997319206650003}
2023-01-04 23:11:29,454 INFO:     Found new best model at epoch 8
2023-01-04 23:11:29,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:29,456 INFO:     Epoch: 9
2023-01-04 23:11:31,717 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4105008880297343, 'Total loss': 0.4105008880297343} | train loss {'Reaction outcome loss': 0.3604309536489375, 'Total loss': 0.3604309536489375}
2023-01-04 23:11:31,717 INFO:     Found new best model at epoch 9
2023-01-04 23:11:31,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:31,719 INFO:     Epoch: 10
2023-01-04 23:11:33,960 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4213465889294942, 'Total loss': 0.4213465889294942} | train loss {'Reaction outcome loss': 0.3529121310010061, 'Total loss': 0.3529121310010061}
2023-01-04 23:11:33,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:33,960 INFO:     Epoch: 11
2023-01-04 23:11:36,202 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4266537566979726, 'Total loss': 0.4266537566979726} | train loss {'Reaction outcome loss': 0.3438779622616567, 'Total loss': 0.3438779622616567}
2023-01-04 23:11:36,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:36,202 INFO:     Epoch: 12
2023-01-04 23:11:38,434 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41588822901248934, 'Total loss': 0.41588822901248934} | train loss {'Reaction outcome loss': 0.3354091303416224, 'Total loss': 0.3354091303416224}
2023-01-04 23:11:38,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:38,434 INFO:     Epoch: 13
2023-01-04 23:11:40,644 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3888574500878652, 'Total loss': 0.3888574500878652} | train loss {'Reaction outcome loss': 0.3241326725963271, 'Total loss': 0.3241326725963271}
2023-01-04 23:11:40,645 INFO:     Found new best model at epoch 13
2023-01-04 23:11:40,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:40,647 INFO:     Epoch: 14
2023-01-04 23:11:42,891 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3965654800335566, 'Total loss': 0.3965654800335566} | train loss {'Reaction outcome loss': 0.31888658060750247, 'Total loss': 0.31888658060750247}
2023-01-04 23:11:42,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:42,891 INFO:     Epoch: 15
2023-01-04 23:11:45,123 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42035029927889506, 'Total loss': 0.42035029927889506} | train loss {'Reaction outcome loss': 0.31086816696020275, 'Total loss': 0.31086816696020275}
2023-01-04 23:11:45,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:45,123 INFO:     Epoch: 16
2023-01-04 23:11:47,376 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44248408476511636, 'Total loss': 0.44248408476511636} | train loss {'Reaction outcome loss': 0.3091599776003605, 'Total loss': 0.3091599776003605}
2023-01-04 23:11:47,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:47,377 INFO:     Epoch: 17
2023-01-04 23:11:49,597 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3922197158137957, 'Total loss': 0.3922197158137957} | train loss {'Reaction outcome loss': 0.29985344671941067, 'Total loss': 0.29985344671941067}
2023-01-04 23:11:49,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:49,597 INFO:     Epoch: 18
2023-01-04 23:11:51,813 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39146954913934073, 'Total loss': 0.39146954913934073} | train loss {'Reaction outcome loss': 0.29382626458511246, 'Total loss': 0.29382626458511246}
2023-01-04 23:11:51,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:51,814 INFO:     Epoch: 19
2023-01-04 23:11:54,064 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41755209465821586, 'Total loss': 0.41755209465821586} | train loss {'Reaction outcome loss': 0.28952735122088546, 'Total loss': 0.28952735122088546}
2023-01-04 23:11:54,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:54,065 INFO:     Epoch: 20
2023-01-04 23:11:56,269 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38801904718081154, 'Total loss': 0.38801904718081154} | train loss {'Reaction outcome loss': 0.2859647113133918, 'Total loss': 0.2859647113133918}
2023-01-04 23:11:56,269 INFO:     Found new best model at epoch 20
2023-01-04 23:11:56,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:56,270 INFO:     Epoch: 21
2023-01-04 23:11:58,540 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39878568053245544, 'Total loss': 0.39878568053245544} | train loss {'Reaction outcome loss': 0.2779285692116894, 'Total loss': 0.2779285692116894}
2023-01-04 23:11:58,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:11:58,540 INFO:     Epoch: 22
2023-01-04 23:12:00,803 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4076957955956459, 'Total loss': 0.4076957955956459} | train loss {'Reaction outcome loss': 0.27264628054458145, 'Total loss': 0.27264628054458145}
2023-01-04 23:12:00,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:00,804 INFO:     Epoch: 23
2023-01-04 23:12:03,056 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40808407465616864, 'Total loss': 0.40808407465616864} | train loss {'Reaction outcome loss': 0.27260177336878827, 'Total loss': 0.27260177336878827}
2023-01-04 23:12:03,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:03,056 INFO:     Epoch: 24
2023-01-04 23:12:05,307 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41156186163425446, 'Total loss': 0.41156186163425446} | train loss {'Reaction outcome loss': 0.2661514292597334, 'Total loss': 0.2661514292597334}
2023-01-04 23:12:05,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:05,307 INFO:     Epoch: 25
2023-01-04 23:12:07,540 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4019012356797854, 'Total loss': 0.4019012356797854} | train loss {'Reaction outcome loss': 0.257819944194385, 'Total loss': 0.257819944194385}
2023-01-04 23:12:07,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:07,540 INFO:     Epoch: 26
2023-01-04 23:12:09,781 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40833547711372375, 'Total loss': 0.40833547711372375} | train loss {'Reaction outcome loss': 0.2549202007279073, 'Total loss': 0.2549202007279073}
2023-01-04 23:12:09,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:09,781 INFO:     Epoch: 27
2023-01-04 23:12:12,016 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3624825544655323, 'Total loss': 0.3624825544655323} | train loss {'Reaction outcome loss': 0.2512760950736838, 'Total loss': 0.2512760950736838}
2023-01-04 23:12:12,016 INFO:     Found new best model at epoch 27
2023-01-04 23:12:12,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:12,017 INFO:     Epoch: 28
2023-01-04 23:12:14,281 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41787810226281485, 'Total loss': 0.41787810226281485} | train loss {'Reaction outcome loss': 0.25740552707251174, 'Total loss': 0.25740552707251174}
2023-01-04 23:12:14,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:14,281 INFO:     Epoch: 29
2023-01-04 23:12:16,541 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3917653371890386, 'Total loss': 0.3917653371890386} | train loss {'Reaction outcome loss': 0.2539142872592359, 'Total loss': 0.2539142872592359}
2023-01-04 23:12:16,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:16,542 INFO:     Epoch: 30
2023-01-04 23:12:18,746 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4208377838134766, 'Total loss': 0.4208377838134766} | train loss {'Reaction outcome loss': 0.24835915710681525, 'Total loss': 0.24835915710681525}
2023-01-04 23:12:18,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:18,746 INFO:     Epoch: 31
2023-01-04 23:12:20,985 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.37598603665828706, 'Total loss': 0.37598603665828706} | train loss {'Reaction outcome loss': 0.23825254573080784, 'Total loss': 0.23825254573080784}
2023-01-04 23:12:20,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:20,985 INFO:     Epoch: 32
2023-01-04 23:12:23,196 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39859311481316884, 'Total loss': 0.39859311481316884} | train loss {'Reaction outcome loss': 0.2388733080946482, 'Total loss': 0.2388733080946482}
2023-01-04 23:12:23,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:23,197 INFO:     Epoch: 33
2023-01-04 23:12:25,454 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3850537930925687, 'Total loss': 0.3850537930925687} | train loss {'Reaction outcome loss': 0.23634983145464689, 'Total loss': 0.23634983145464689}
2023-01-04 23:12:25,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:25,454 INFO:     Epoch: 34
2023-01-04 23:12:27,694 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40227851271629333, 'Total loss': 0.40227851271629333} | train loss {'Reaction outcome loss': 0.2339801920011585, 'Total loss': 0.2339801920011585}
2023-01-04 23:12:27,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:27,695 INFO:     Epoch: 35
2023-01-04 23:12:29,959 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3930477872490883, 'Total loss': 0.3930477872490883} | train loss {'Reaction outcome loss': 0.23099905312497973, 'Total loss': 0.23099905312497973}
2023-01-04 23:12:29,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:29,959 INFO:     Epoch: 36
2023-01-04 23:12:32,204 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4273046299815178, 'Total loss': 0.4273046299815178} | train loss {'Reaction outcome loss': 0.22978626322956422, 'Total loss': 0.22978626322956422}
2023-01-04 23:12:32,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:32,204 INFO:     Epoch: 37
2023-01-04 23:12:34,436 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39065930744012195, 'Total loss': 0.39065930744012195} | train loss {'Reaction outcome loss': 0.22462979211188824, 'Total loss': 0.22462979211188824}
2023-01-04 23:12:34,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:34,436 INFO:     Epoch: 38
2023-01-04 23:12:36,688 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.412170738975207, 'Total loss': 0.412170738975207} | train loss {'Reaction outcome loss': 0.22545708371360443, 'Total loss': 0.22545708371360443}
2023-01-04 23:12:36,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:36,689 INFO:     Epoch: 39
2023-01-04 23:12:38,935 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4371458053588867, 'Total loss': 0.4371458053588867} | train loss {'Reaction outcome loss': 0.2269045164870037, 'Total loss': 0.2269045164870037}
2023-01-04 23:12:38,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:38,935 INFO:     Epoch: 40
2023-01-04 23:12:41,172 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3802482103308042, 'Total loss': 0.3802482103308042} | train loss {'Reaction outcome loss': 0.21965652470555388, 'Total loss': 0.21965652470555388}
2023-01-04 23:12:41,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:41,172 INFO:     Epoch: 41
2023-01-04 23:12:43,420 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.422475336988767, 'Total loss': 0.422475336988767} | train loss {'Reaction outcome loss': 0.222713892151953, 'Total loss': 0.222713892151953}
2023-01-04 23:12:43,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:43,420 INFO:     Epoch: 42
2023-01-04 23:12:45,682 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3919455736875534, 'Total loss': 0.3919455736875534} | train loss {'Reaction outcome loss': 0.2176927790223133, 'Total loss': 0.2176927790223133}
2023-01-04 23:12:45,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:45,683 INFO:     Epoch: 43
2023-01-04 23:12:47,938 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41028763707727195, 'Total loss': 0.41028763707727195} | train loss {'Reaction outcome loss': 0.21868361884748544, 'Total loss': 0.21868361884748544}
2023-01-04 23:12:47,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:47,938 INFO:     Epoch: 44
2023-01-04 23:12:50,199 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41532410979270934, 'Total loss': 0.41532410979270934} | train loss {'Reaction outcome loss': 0.21464113021208034, 'Total loss': 0.21464113021208034}
2023-01-04 23:12:50,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:50,199 INFO:     Epoch: 45
2023-01-04 23:12:52,471 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42325721979141234, 'Total loss': 0.42325721979141234} | train loss {'Reaction outcome loss': 0.21537761664488814, 'Total loss': 0.21537761664488814}
2023-01-04 23:12:52,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:52,471 INFO:     Epoch: 46
2023-01-04 23:12:54,712 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39421516756216685, 'Total loss': 0.39421516756216685} | train loss {'Reaction outcome loss': 0.21154073562435532, 'Total loss': 0.21154073562435532}
2023-01-04 23:12:54,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:54,713 INFO:     Epoch: 47
2023-01-04 23:12:56,976 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3885634401192268, 'Total loss': 0.3885634401192268} | train loss {'Reaction outcome loss': 0.20807992598048716, 'Total loss': 0.20807992598048716}
2023-01-04 23:12:56,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:56,976 INFO:     Epoch: 48
2023-01-04 23:12:59,229 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4111766134699186, 'Total loss': 0.4111766134699186} | train loss {'Reaction outcome loss': 0.2096514643780587, 'Total loss': 0.2096514643780587}
2023-01-04 23:12:59,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:12:59,229 INFO:     Epoch: 49
2023-01-04 23:13:01,477 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3866050439576308, 'Total loss': 0.3866050439576308} | train loss {'Reaction outcome loss': 0.20688004531443882, 'Total loss': 0.20688004531443882}
2023-01-04 23:13:01,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:01,477 INFO:     Epoch: 50
2023-01-04 23:13:03,742 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3974408835172653, 'Total loss': 0.3974408835172653} | train loss {'Reaction outcome loss': 0.21282727070725882, 'Total loss': 0.21282727070725882}
2023-01-04 23:13:03,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:03,742 INFO:     Epoch: 51
2023-01-04 23:13:06,007 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40094768901666006, 'Total loss': 0.40094768901666006} | train loss {'Reaction outcome loss': 0.20573128001498325, 'Total loss': 0.20573128001498325}
2023-01-04 23:13:06,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:06,008 INFO:     Epoch: 52
2023-01-04 23:13:08,262 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4009658465782801, 'Total loss': 0.4009658465782801} | train loss {'Reaction outcome loss': 0.20687310318479607, 'Total loss': 0.20687310318479607}
2023-01-04 23:13:08,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:08,263 INFO:     Epoch: 53
2023-01-04 23:13:10,513 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3914291386802991, 'Total loss': 0.3914291386802991} | train loss {'Reaction outcome loss': 0.20199332185875923, 'Total loss': 0.20199332185875923}
2023-01-04 23:13:10,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:10,513 INFO:     Epoch: 54
2023-01-04 23:13:12,763 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41116901536782585, 'Total loss': 0.41116901536782585} | train loss {'Reaction outcome loss': 0.19934263950275197, 'Total loss': 0.19934263950275197}
2023-01-04 23:13:12,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:12,763 INFO:     Epoch: 55
2023-01-04 23:13:15,024 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40212076813913883, 'Total loss': 0.40212076813913883} | train loss {'Reaction outcome loss': 0.19974016470172795, 'Total loss': 0.19974016470172795}
2023-01-04 23:13:15,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:15,024 INFO:     Epoch: 56
2023-01-04 23:13:17,247 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38008238275845846, 'Total loss': 0.38008238275845846} | train loss {'Reaction outcome loss': 0.19954028885279382, 'Total loss': 0.19954028885279382}
2023-01-04 23:13:17,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:17,247 INFO:     Epoch: 57
2023-01-04 23:13:19,504 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3852272907892863, 'Total loss': 0.3852272907892863} | train loss {'Reaction outcome loss': 0.19747324940158334, 'Total loss': 0.19747324940158334}
2023-01-04 23:13:19,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:19,505 INFO:     Epoch: 58
2023-01-04 23:13:21,728 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3770130082964897, 'Total loss': 0.3770130082964897} | train loss {'Reaction outcome loss': 0.19798690054033483, 'Total loss': 0.19798690054033483}
2023-01-04 23:13:21,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:21,730 INFO:     Epoch: 59
2023-01-04 23:13:23,999 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3783280928929647, 'Total loss': 0.3783280928929647} | train loss {'Reaction outcome loss': 0.19725268990510986, 'Total loss': 0.19725268990510986}
2023-01-04 23:13:24,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:24,000 INFO:     Epoch: 60
2023-01-04 23:13:26,281 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4017729640007019, 'Total loss': 0.4017729640007019} | train loss {'Reaction outcome loss': 0.19889837493540058, 'Total loss': 0.19889837493540058}
2023-01-04 23:13:26,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:26,281 INFO:     Epoch: 61
2023-01-04 23:13:28,546 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38162838518619535, 'Total loss': 0.38162838518619535} | train loss {'Reaction outcome loss': 0.18911094857113703, 'Total loss': 0.18911094857113703}
2023-01-04 23:13:28,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:28,546 INFO:     Epoch: 62
2023-01-04 23:13:30,790 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.410517023007075, 'Total loss': 0.410517023007075} | train loss {'Reaction outcome loss': 0.18909873648618275, 'Total loss': 0.18909873648618275}
2023-01-04 23:13:30,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:30,791 INFO:     Epoch: 63
2023-01-04 23:13:33,018 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4331672762831052, 'Total loss': 0.4331672762831052} | train loss {'Reaction outcome loss': 0.1937294216662809, 'Total loss': 0.1937294216662809}
2023-01-04 23:13:33,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:33,018 INFO:     Epoch: 64
2023-01-04 23:13:35,258 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4304860333601634, 'Total loss': 0.4304860333601634} | train loss {'Reaction outcome loss': 0.1877131877141244, 'Total loss': 0.1877131877141244}
2023-01-04 23:13:35,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:35,259 INFO:     Epoch: 65
2023-01-04 23:13:37,492 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42201876143614453, 'Total loss': 0.42201876143614453} | train loss {'Reaction outcome loss': 0.1886704727263623, 'Total loss': 0.1886704727263623}
2023-01-04 23:13:37,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:37,493 INFO:     Epoch: 66
2023-01-04 23:13:39,748 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3840272843837738, 'Total loss': 0.3840272843837738} | train loss {'Reaction outcome loss': 0.19432684328857358, 'Total loss': 0.19432684328857358}
2023-01-04 23:13:39,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:39,749 INFO:     Epoch: 67
2023-01-04 23:13:41,983 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40422842899958294, 'Total loss': 0.40422842899958294} | train loss {'Reaction outcome loss': 0.18981868924143222, 'Total loss': 0.18981868924143222}
2023-01-04 23:13:41,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:41,984 INFO:     Epoch: 68
2023-01-04 23:13:44,252 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39457823634147643, 'Total loss': 0.39457823634147643} | train loss {'Reaction outcome loss': 0.1837787845584772, 'Total loss': 0.1837787845584772}
2023-01-04 23:13:44,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:44,253 INFO:     Epoch: 69
2023-01-04 23:13:46,513 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.413611830274264, 'Total loss': 0.413611830274264} | train loss {'Reaction outcome loss': 0.18432707150531558, 'Total loss': 0.18432707150531558}
2023-01-04 23:13:46,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:46,513 INFO:     Epoch: 70
2023-01-04 23:13:48,739 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44333781202634176, 'Total loss': 0.44333781202634176} | train loss {'Reaction outcome loss': 0.18916035542305518, 'Total loss': 0.18916035542305518}
2023-01-04 23:13:48,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:48,739 INFO:     Epoch: 71
2023-01-04 23:13:50,973 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40301244854927065, 'Total loss': 0.40301244854927065} | train loss {'Reaction outcome loss': 0.18519448618585374, 'Total loss': 0.18519448618585374}
2023-01-04 23:13:50,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:50,973 INFO:     Epoch: 72
2023-01-04 23:13:53,189 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40940502683321633, 'Total loss': 0.40940502683321633} | train loss {'Reaction outcome loss': 0.18179719481317005, 'Total loss': 0.18179719481317005}
2023-01-04 23:13:53,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:53,189 INFO:     Epoch: 73
2023-01-04 23:13:55,408 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40216429630915324, 'Total loss': 0.40216429630915324} | train loss {'Reaction outcome loss': 0.17904122587593593, 'Total loss': 0.17904122587593593}
2023-01-04 23:13:55,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:55,409 INFO:     Epoch: 74
2023-01-04 23:13:57,645 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41002860565980276, 'Total loss': 0.41002860565980276} | train loss {'Reaction outcome loss': 0.18017709144133556, 'Total loss': 0.18017709144133556}
2023-01-04 23:13:57,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:57,646 INFO:     Epoch: 75
2023-01-04 23:13:59,886 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3772053201993307, 'Total loss': 0.3772053201993307} | train loss {'Reaction outcome loss': 0.17777037979427712, 'Total loss': 0.17777037979427712}
2023-01-04 23:13:59,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:13:59,886 INFO:     Epoch: 76
2023-01-04 23:14:02,133 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3991678113738696, 'Total loss': 0.3991678113738696} | train loss {'Reaction outcome loss': 0.17534589337273723, 'Total loss': 0.17534589337273723}
2023-01-04 23:14:02,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:02,133 INFO:     Epoch: 77
2023-01-04 23:14:04,337 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3979134033123652, 'Total loss': 0.3979134033123652} | train loss {'Reaction outcome loss': 0.1738304750142694, 'Total loss': 0.1738304750142694}
2023-01-04 23:14:04,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:04,338 INFO:     Epoch: 78
2023-01-04 23:14:06,566 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41822865704695383, 'Total loss': 0.41822865704695383} | train loss {'Reaction outcome loss': 0.17824452148661726, 'Total loss': 0.17824452148661726}
2023-01-04 23:14:06,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:06,567 INFO:     Epoch: 79
2023-01-04 23:14:08,742 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4069660916924477, 'Total loss': 0.4069660916924477} | train loss {'Reaction outcome loss': 0.1750416952959729, 'Total loss': 0.1750416952959729}
2023-01-04 23:14:08,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:08,742 INFO:     Epoch: 80
2023-01-04 23:14:10,991 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3617840027514224, 'Total loss': 0.3617840027514224} | train loss {'Reaction outcome loss': 0.17331294039769213, 'Total loss': 0.17331294039769213}
2023-01-04 23:14:10,992 INFO:     Found new best model at epoch 80
2023-01-04 23:14:10,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:10,993 INFO:     Epoch: 81
2023-01-04 23:14:13,254 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40807516624530155, 'Total loss': 0.40807516624530155} | train loss {'Reaction outcome loss': 0.17639573722320434, 'Total loss': 0.17639573722320434}
2023-01-04 23:14:13,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:13,254 INFO:     Epoch: 82
2023-01-04 23:14:15,489 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4289471964041392, 'Total loss': 0.4289471964041392} | train loss {'Reaction outcome loss': 0.17470099446926635, 'Total loss': 0.17470099446926635}
2023-01-04 23:14:15,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:15,489 INFO:     Epoch: 83
2023-01-04 23:14:17,732 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4315343198676904, 'Total loss': 0.4315343198676904} | train loss {'Reaction outcome loss': 0.17269675444040597, 'Total loss': 0.17269675444040597}
2023-01-04 23:14:17,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:17,733 INFO:     Epoch: 84
2023-01-04 23:14:19,940 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37656214870512483, 'Total loss': 0.37656214870512483} | train loss {'Reaction outcome loss': 0.173158159994626, 'Total loss': 0.173158159994626}
2023-01-04 23:14:19,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:19,940 INFO:     Epoch: 85
2023-01-04 23:14:22,172 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3989791760842005, 'Total loss': 0.3989791760842005} | train loss {'Reaction outcome loss': 0.17786326133151412, 'Total loss': 0.17786326133151412}
2023-01-04 23:14:22,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:22,172 INFO:     Epoch: 86
2023-01-04 23:14:24,380 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41761735721180837, 'Total loss': 0.41761735721180837} | train loss {'Reaction outcome loss': 0.17050485047017097, 'Total loss': 0.17050485047017097}
2023-01-04 23:14:24,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:24,380 INFO:     Epoch: 87
2023-01-04 23:14:26,623 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4024262587229411, 'Total loss': 0.4024262587229411} | train loss {'Reaction outcome loss': 0.16895006681645747, 'Total loss': 0.16895006681645747}
2023-01-04 23:14:26,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:26,624 INFO:     Epoch: 88
2023-01-04 23:14:28,824 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40923832456270853, 'Total loss': 0.40923832456270853} | train loss {'Reaction outcome loss': 0.17069375300234108, 'Total loss': 0.17069375300234108}
2023-01-04 23:14:28,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:28,824 INFO:     Epoch: 89
2023-01-04 23:14:30,649 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38940222760041554, 'Total loss': 0.38940222760041554} | train loss {'Reaction outcome loss': 0.17124451826336784, 'Total loss': 0.17124451826336784}
2023-01-04 23:14:30,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:30,650 INFO:     Epoch: 90
2023-01-04 23:14:32,504 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4259500702222188, 'Total loss': 0.4259500702222188} | train loss {'Reaction outcome loss': 0.17574731148813508, 'Total loss': 0.17574731148813508}
2023-01-04 23:14:32,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:32,505 INFO:     Epoch: 91
2023-01-04 23:14:34,638 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4646007567644119, 'Total loss': 0.4646007567644119} | train loss {'Reaction outcome loss': 0.17185599418125036, 'Total loss': 0.17185599418125036}
2023-01-04 23:14:34,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:34,639 INFO:     Epoch: 92
2023-01-04 23:14:36,866 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3902238880594571, 'Total loss': 0.3902238880594571} | train loss {'Reaction outcome loss': 0.17268649836483618, 'Total loss': 0.17268649836483618}
2023-01-04 23:14:36,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:36,866 INFO:     Epoch: 93
2023-01-04 23:14:39,090 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.35859544333070514, 'Total loss': 0.35859544333070514} | train loss {'Reaction outcome loss': 0.16811614518732707, 'Total loss': 0.16811614518732707}
2023-01-04 23:14:39,091 INFO:     Found new best model at epoch 93
2023-01-04 23:14:39,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:39,092 INFO:     Epoch: 94
2023-01-04 23:14:41,301 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40706898272037506, 'Total loss': 0.40706898272037506} | train loss {'Reaction outcome loss': 0.16860403237530056, 'Total loss': 0.16860403237530056}
2023-01-04 23:14:41,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:41,302 INFO:     Epoch: 95
2023-01-04 23:14:43,534 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4127066959937414, 'Total loss': 0.4127066959937414} | train loss {'Reaction outcome loss': 0.1634482561240498, 'Total loss': 0.1634482561240498}
2023-01-04 23:14:43,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:43,534 INFO:     Epoch: 96
2023-01-04 23:14:45,756 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40750562647978467, 'Total loss': 0.40750562647978467} | train loss {'Reaction outcome loss': 0.16637171942215317, 'Total loss': 0.16637171942215317}
2023-01-04 23:14:45,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:45,756 INFO:     Epoch: 97
2023-01-04 23:14:47,905 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4128993809223175, 'Total loss': 0.4128993809223175} | train loss {'Reaction outcome loss': 0.16728001022745512, 'Total loss': 0.16728001022745512}
2023-01-04 23:14:47,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:47,906 INFO:     Epoch: 98
2023-01-04 23:14:50,132 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41054114947716397, 'Total loss': 0.41054114947716397} | train loss {'Reaction outcome loss': 0.16859773923080046, 'Total loss': 0.16859773923080046}
2023-01-04 23:14:50,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:50,133 INFO:     Epoch: 99
2023-01-04 23:14:52,205 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43770716786384584, 'Total loss': 0.43770716786384584} | train loss {'Reaction outcome loss': 0.1647292444663252, 'Total loss': 0.1647292444663252}
2023-01-04 23:14:52,205 INFO:     Best model found after epoch 94 of 100.
2023-01-04 23:14:52,206 INFO:   Done with stage: TRAINING
2023-01-04 23:14:52,206 INFO:   Starting stage: EVALUATION
2023-01-04 23:14:52,353 INFO:   Done with stage: EVALUATION
2023-01-04 23:14:52,353 INFO:   Leaving out SEQ value Fold_4
2023-01-04 23:14:52,366 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 23:14:52,366 INFO:   Starting stage: FEATURE SCALING
2023-01-04 23:14:53,025 INFO:   Done with stage: FEATURE SCALING
2023-01-04 23:14:53,025 INFO:   Starting stage: SCALING TARGETS
2023-01-04 23:14:53,097 INFO:   Done with stage: SCALING TARGETS
2023-01-04 23:14:53,097 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:14:53,097 INFO:     No hyperparam tuning for this model
2023-01-04 23:14:53,097 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:14:53,097 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 23:14:53,098 INFO:     None feature selector for col prot
2023-01-04 23:14:53,098 INFO:     None feature selector for col prot
2023-01-04 23:14:53,098 INFO:     None feature selector for col prot
2023-01-04 23:14:53,099 INFO:     None feature selector for col chem
2023-01-04 23:14:53,099 INFO:     None feature selector for col chem
2023-01-04 23:14:53,099 INFO:     None feature selector for col chem
2023-01-04 23:14:53,099 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 23:14:53,099 INFO:   Starting stage: BUILD MODEL
2023-01-04 23:14:53,101 INFO:     Number of params in model 72931
2023-01-04 23:14:53,104 INFO:   Done with stage: BUILD MODEL
2023-01-04 23:14:53,104 INFO:   Starting stage: TRAINING
2023-01-04 23:14:53,164 INFO:     Val loss before train {'Reaction outcome loss': 1.044503629207611, 'Total loss': 1.044503629207611}
2023-01-04 23:14:53,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:53,165 INFO:     Epoch: 0
2023-01-04 23:14:55,357 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8062486608823141, 'Total loss': 0.8062486608823141} | train loss {'Reaction outcome loss': 0.9298715017978034, 'Total loss': 0.9298715017978034}
2023-01-04 23:14:55,358 INFO:     Found new best model at epoch 0
2023-01-04 23:14:55,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:55,359 INFO:     Epoch: 1
2023-01-04 23:14:57,581 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6205380260944366, 'Total loss': 0.6205380260944366} | train loss {'Reaction outcome loss': 0.635142643851924, 'Total loss': 0.635142643851924}
2023-01-04 23:14:57,581 INFO:     Found new best model at epoch 1
2023-01-04 23:14:57,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:57,583 INFO:     Epoch: 2
2023-01-04 23:14:59,882 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5922768553098042, 'Total loss': 0.5922768553098042} | train loss {'Reaction outcome loss': 0.5403293419077939, 'Total loss': 0.5403293419077939}
2023-01-04 23:14:59,882 INFO:     Found new best model at epoch 2
2023-01-04 23:14:59,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:14:59,884 INFO:     Epoch: 3
2023-01-04 23:15:02,130 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5604237973690033, 'Total loss': 0.5604237973690033} | train loss {'Reaction outcome loss': 0.5064472167715699, 'Total loss': 0.5064472167715699}
2023-01-04 23:15:02,131 INFO:     Found new best model at epoch 3
2023-01-04 23:15:02,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:02,132 INFO:     Epoch: 4
2023-01-04 23:15:04,402 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5216160217920939, 'Total loss': 0.5216160217920939} | train loss {'Reaction outcome loss': 0.48049525556151185, 'Total loss': 0.48049525556151185}
2023-01-04 23:15:04,403 INFO:     Found new best model at epoch 4
2023-01-04 23:15:04,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:04,404 INFO:     Epoch: 5
2023-01-04 23:15:06,698 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5175475001335144, 'Total loss': 0.5175475001335144} | train loss {'Reaction outcome loss': 0.45569260854153, 'Total loss': 0.45569260854153}
2023-01-04 23:15:06,698 INFO:     Found new best model at epoch 5
2023-01-04 23:15:06,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:06,699 INFO:     Epoch: 6
2023-01-04 23:15:08,960 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49130779107411704, 'Total loss': 0.49130779107411704} | train loss {'Reaction outcome loss': 0.43842434382825984, 'Total loss': 0.43842434382825984}
2023-01-04 23:15:08,961 INFO:     Found new best model at epoch 6
2023-01-04 23:15:08,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:08,963 INFO:     Epoch: 7
2023-01-04 23:15:11,208 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4928750137488047, 'Total loss': 0.4928750137488047} | train loss {'Reaction outcome loss': 0.4197077078724596, 'Total loss': 0.4197077078724596}
2023-01-04 23:15:11,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:11,209 INFO:     Epoch: 8
2023-01-04 23:15:13,496 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4787618617216746, 'Total loss': 0.4787618617216746} | train loss {'Reaction outcome loss': 0.4003593767270284, 'Total loss': 0.4003593767270284}
2023-01-04 23:15:13,496 INFO:     Found new best model at epoch 8
2023-01-04 23:15:13,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:13,497 INFO:     Epoch: 9
2023-01-04 23:15:15,756 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4854173759619395, 'Total loss': 0.4854173759619395} | train loss {'Reaction outcome loss': 0.3911412547641713, 'Total loss': 0.3911412547641713}
2023-01-04 23:15:15,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:15,757 INFO:     Epoch: 10
2023-01-04 23:15:18,013 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4471145351727804, 'Total loss': 0.4471145351727804} | train loss {'Reaction outcome loss': 0.37728271972293886, 'Total loss': 0.37728271972293886}
2023-01-04 23:15:18,013 INFO:     Found new best model at epoch 10
2023-01-04 23:15:18,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:18,015 INFO:     Epoch: 11
2023-01-04 23:15:20,263 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45051018595695497, 'Total loss': 0.45051018595695497} | train loss {'Reaction outcome loss': 0.36280995289986745, 'Total loss': 0.36280995289986745}
2023-01-04 23:15:20,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:20,264 INFO:     Epoch: 12
2023-01-04 23:15:22,458 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4562072068452835, 'Total loss': 0.4562072068452835} | train loss {'Reaction outcome loss': 0.3535961659107398, 'Total loss': 0.3535961659107398}
2023-01-04 23:15:22,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:22,458 INFO:     Epoch: 13
2023-01-04 23:15:24,718 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45260481238365174, 'Total loss': 0.45260481238365174} | train loss {'Reaction outcome loss': 0.3473790463880511, 'Total loss': 0.3473790463880511}
2023-01-04 23:15:24,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:24,719 INFO:     Epoch: 14
2023-01-04 23:15:26,956 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45931612253189086, 'Total loss': 0.45931612253189086} | train loss {'Reaction outcome loss': 0.338594056907974, 'Total loss': 0.338594056907974}
2023-01-04 23:15:26,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:26,957 INFO:     Epoch: 15
2023-01-04 23:15:29,211 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44442553917566935, 'Total loss': 0.44442553917566935} | train loss {'Reaction outcome loss': 0.33368293148892453, 'Total loss': 0.33368293148892453}
2023-01-04 23:15:29,212 INFO:     Found new best model at epoch 15
2023-01-04 23:15:29,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:29,214 INFO:     Epoch: 16
2023-01-04 23:15:31,497 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44962590336799624, 'Total loss': 0.44962590336799624} | train loss {'Reaction outcome loss': 0.32294617066099324, 'Total loss': 0.32294617066099324}
2023-01-04 23:15:31,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:31,498 INFO:     Epoch: 17
2023-01-04 23:15:33,758 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44881681402524315, 'Total loss': 0.44881681402524315} | train loss {'Reaction outcome loss': 0.31637132746110325, 'Total loss': 0.31637132746110325}
2023-01-04 23:15:33,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:33,759 INFO:     Epoch: 18
2023-01-04 23:15:35,981 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4236640771230062, 'Total loss': 0.4236640771230062} | train loss {'Reaction outcome loss': 0.30508381352904473, 'Total loss': 0.30508381352904473}
2023-01-04 23:15:35,981 INFO:     Found new best model at epoch 18
2023-01-04 23:15:35,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:35,982 INFO:     Epoch: 19
2023-01-04 23:15:38,258 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43217650999625523, 'Total loss': 0.43217650999625523} | train loss {'Reaction outcome loss': 0.2998223423097108, 'Total loss': 0.2998223423097108}
2023-01-04 23:15:38,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:38,258 INFO:     Epoch: 20
2023-01-04 23:15:40,491 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4521546204884847, 'Total loss': 0.4521546204884847} | train loss {'Reaction outcome loss': 0.2914555132765632, 'Total loss': 0.2914555132765632}
2023-01-04 23:15:40,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:40,491 INFO:     Epoch: 21
2023-01-04 23:15:42,748 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4275312483310699, 'Total loss': 0.4275312483310699} | train loss {'Reaction outcome loss': 0.2911133027773364, 'Total loss': 0.2911133027773364}
2023-01-04 23:15:42,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:42,748 INFO:     Epoch: 22
2023-01-04 23:15:45,029 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.418938136100769, 'Total loss': 0.418938136100769} | train loss {'Reaction outcome loss': 0.28466583577250315, 'Total loss': 0.28466583577250315}
2023-01-04 23:15:45,030 INFO:     Found new best model at epoch 22
2023-01-04 23:15:45,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:45,032 INFO:     Epoch: 23
2023-01-04 23:15:47,303 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42143595616022744, 'Total loss': 0.42143595616022744} | train loss {'Reaction outcome loss': 0.278003626553483, 'Total loss': 0.278003626553483}
2023-01-04 23:15:47,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:47,303 INFO:     Epoch: 24
2023-01-04 23:15:49,591 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40626984735329946, 'Total loss': 0.40626984735329946} | train loss {'Reaction outcome loss': 0.2757852098060644, 'Total loss': 0.2757852098060644}
2023-01-04 23:15:49,591 INFO:     Found new best model at epoch 24
2023-01-04 23:15:49,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:49,592 INFO:     Epoch: 25
2023-01-04 23:15:51,875 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4237457732359568, 'Total loss': 0.4237457732359568} | train loss {'Reaction outcome loss': 0.2685718302504035, 'Total loss': 0.2685718302504035}
2023-01-04 23:15:51,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:51,876 INFO:     Epoch: 26
2023-01-04 23:15:54,180 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.396666227777799, 'Total loss': 0.396666227777799} | train loss {'Reaction outcome loss': 0.2700513885205188, 'Total loss': 0.2700513885205188}
2023-01-04 23:15:54,180 INFO:     Found new best model at epoch 26
2023-01-04 23:15:54,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:54,182 INFO:     Epoch: 27
2023-01-04 23:15:56,442 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41622244715690615, 'Total loss': 0.41622244715690615} | train loss {'Reaction outcome loss': 0.263518785082799, 'Total loss': 0.263518785082799}
2023-01-04 23:15:56,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:56,443 INFO:     Epoch: 28
2023-01-04 23:15:58,693 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41805574893951414, 'Total loss': 0.41805574893951414} | train loss {'Reaction outcome loss': 0.26456954374586633, 'Total loss': 0.26456954374586633}
2023-01-04 23:15:58,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:15:58,693 INFO:     Epoch: 29
2023-01-04 23:16:00,942 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4180381417274475, 'Total loss': 0.4180381417274475} | train loss {'Reaction outcome loss': 0.26054903845359917, 'Total loss': 0.26054903845359917}
2023-01-04 23:16:00,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:00,942 INFO:     Epoch: 30
2023-01-04 23:16:03,199 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4308200110991796, 'Total loss': 0.4308200110991796} | train loss {'Reaction outcome loss': 0.25230647059365946, 'Total loss': 0.25230647059365946}
2023-01-04 23:16:03,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:03,200 INFO:     Epoch: 31
2023-01-04 23:16:05,501 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4162840823332469, 'Total loss': 0.4162840823332469} | train loss {'Reaction outcome loss': 0.24897253626305274, 'Total loss': 0.24897253626305274}
2023-01-04 23:16:05,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:05,502 INFO:     Epoch: 32
2023-01-04 23:16:07,779 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41186395386854807, 'Total loss': 0.41186395386854807} | train loss {'Reaction outcome loss': 0.2475303037004673, 'Total loss': 0.2475303037004673}
2023-01-04 23:16:07,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:07,780 INFO:     Epoch: 33
2023-01-04 23:16:10,066 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42358678380648296, 'Total loss': 0.42358678380648296} | train loss {'Reaction outcome loss': 0.24132778156642878, 'Total loss': 0.24132778156642878}
2023-01-04 23:16:10,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:10,067 INFO:     Epoch: 34
2023-01-04 23:16:12,360 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45275183071692787, 'Total loss': 0.45275183071692787} | train loss {'Reaction outcome loss': 0.24680198242195248, 'Total loss': 0.24680198242195248}
2023-01-04 23:16:12,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:12,360 INFO:     Epoch: 35
2023-01-04 23:16:14,647 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41936249534289044, 'Total loss': 0.41936249534289044} | train loss {'Reaction outcome loss': 0.240384173118896, 'Total loss': 0.240384173118896}
2023-01-04 23:16:14,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:14,647 INFO:     Epoch: 36
2023-01-04 23:16:16,935 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40693603654702504, 'Total loss': 0.40693603654702504} | train loss {'Reaction outcome loss': 0.2389719079648706, 'Total loss': 0.2389719079648706}
2023-01-04 23:16:16,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:16,935 INFO:     Epoch: 37
2023-01-04 23:16:19,225 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4339184800783793, 'Total loss': 0.4339184800783793} | train loss {'Reaction outcome loss': 0.23461661078977242, 'Total loss': 0.23461661078977242}
2023-01-04 23:16:19,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:19,225 INFO:     Epoch: 38
2023-01-04 23:16:21,499 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4328018615643183, 'Total loss': 0.4328018615643183} | train loss {'Reaction outcome loss': 0.2308829319243074, 'Total loss': 0.2308829319243074}
2023-01-04 23:16:21,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:21,500 INFO:     Epoch: 39
2023-01-04 23:16:23,786 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4267858813206355, 'Total loss': 0.4267858813206355} | train loss {'Reaction outcome loss': 0.22905373974074525, 'Total loss': 0.22905373974074525}
2023-01-04 23:16:23,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:23,786 INFO:     Epoch: 40
2023-01-04 23:16:26,058 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42525238494078316, 'Total loss': 0.42525238494078316} | train loss {'Reaction outcome loss': 0.22486175515349377, 'Total loss': 0.22486175515349377}
2023-01-04 23:16:26,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:26,058 INFO:     Epoch: 41
2023-01-04 23:16:28,344 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41952802836894987, 'Total loss': 0.41952802836894987} | train loss {'Reaction outcome loss': 0.22316027273985453, 'Total loss': 0.22316027273985453}
2023-01-04 23:16:28,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:28,345 INFO:     Epoch: 42
2023-01-04 23:16:30,617 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42326015879710516, 'Total loss': 0.42326015879710516} | train loss {'Reaction outcome loss': 0.2203099694210592, 'Total loss': 0.2203099694210592}
2023-01-04 23:16:30,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:30,617 INFO:     Epoch: 43
2023-01-04 23:16:32,894 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43787912229696907, 'Total loss': 0.43787912229696907} | train loss {'Reaction outcome loss': 0.21646547966404728, 'Total loss': 0.21646547966404728}
2023-01-04 23:16:32,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:32,894 INFO:     Epoch: 44
2023-01-04 23:16:35,170 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43441434303919474, 'Total loss': 0.43441434303919474} | train loss {'Reaction outcome loss': 0.21980375416630657, 'Total loss': 0.21980375416630657}
2023-01-04 23:16:35,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:35,170 INFO:     Epoch: 45
2023-01-04 23:16:37,413 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4261878624558449, 'Total loss': 0.4261878624558449} | train loss {'Reaction outcome loss': 0.21452667958200625, 'Total loss': 0.21452667958200625}
2023-01-04 23:16:37,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:37,413 INFO:     Epoch: 46
2023-01-04 23:16:39,697 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4230264241496722, 'Total loss': 0.4230264241496722} | train loss {'Reaction outcome loss': 0.21512918220664834, 'Total loss': 0.21512918220664834}
2023-01-04 23:16:39,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:39,698 INFO:     Epoch: 47
2023-01-04 23:16:41,965 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44067783852418263, 'Total loss': 0.44067783852418263} | train loss {'Reaction outcome loss': 0.21360500038530852, 'Total loss': 0.21360500038530852}
2023-01-04 23:16:41,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:41,965 INFO:     Epoch: 48
2023-01-04 23:16:44,235 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43278379340966544, 'Total loss': 0.43278379340966544} | train loss {'Reaction outcome loss': 0.21119911203476927, 'Total loss': 0.21119911203476927}
2023-01-04 23:16:44,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:44,235 INFO:     Epoch: 49
2023-01-04 23:16:46,490 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4177343229452769, 'Total loss': 0.4177343229452769} | train loss {'Reaction outcome loss': 0.21461010477858652, 'Total loss': 0.21461010477858652}
2023-01-04 23:16:46,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:46,491 INFO:     Epoch: 50
2023-01-04 23:16:48,722 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4263424078623454, 'Total loss': 0.4263424078623454} | train loss {'Reaction outcome loss': 0.21019560434025064, 'Total loss': 0.21019560434025064}
2023-01-04 23:16:48,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:48,722 INFO:     Epoch: 51
2023-01-04 23:16:50,983 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42368564307689666, 'Total loss': 0.42368564307689666} | train loss {'Reaction outcome loss': 0.20457287949412414, 'Total loss': 0.20457287949412414}
2023-01-04 23:16:50,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:50,984 INFO:     Epoch: 52
2023-01-04 23:16:53,268 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4253718376159668, 'Total loss': 0.4253718376159668} | train loss {'Reaction outcome loss': 0.20173651981587767, 'Total loss': 0.20173651981587767}
2023-01-04 23:16:53,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:53,268 INFO:     Epoch: 53
2023-01-04 23:16:55,533 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42845732271671294, 'Total loss': 0.42845732271671294} | train loss {'Reaction outcome loss': 0.2022894605160405, 'Total loss': 0.2022894605160405}
2023-01-04 23:16:55,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:55,533 INFO:     Epoch: 54
2023-01-04 23:16:57,828 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4282342622677485, 'Total loss': 0.4282342622677485} | train loss {'Reaction outcome loss': 0.19901884879768972, 'Total loss': 0.19901884879768972}
2023-01-04 23:16:57,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:16:57,829 INFO:     Epoch: 55
2023-01-04 23:17:00,063 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44400243163108827, 'Total loss': 0.44400243163108827} | train loss {'Reaction outcome loss': 0.19611831262223556, 'Total loss': 0.19611831262223556}
2023-01-04 23:17:00,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:00,063 INFO:     Epoch: 56
2023-01-04 23:17:02,270 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4386986069381237, 'Total loss': 0.4386986069381237} | train loss {'Reaction outcome loss': 0.200713031982418, 'Total loss': 0.200713031982418}
2023-01-04 23:17:02,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:02,270 INFO:     Epoch: 57
2023-01-04 23:17:04,553 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42825817366441093, 'Total loss': 0.42825817366441093} | train loss {'Reaction outcome loss': 0.19652760234604244, 'Total loss': 0.19652760234604244}
2023-01-04 23:17:04,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:04,554 INFO:     Epoch: 58
2023-01-04 23:17:06,751 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4368289391199748, 'Total loss': 0.4368289391199748} | train loss {'Reaction outcome loss': 0.19303249843109277, 'Total loss': 0.19303249843109277}
2023-01-04 23:17:06,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:06,751 INFO:     Epoch: 59
2023-01-04 23:17:09,033 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44122707719604176, 'Total loss': 0.44122707719604176} | train loss {'Reaction outcome loss': 0.18804949511931907, 'Total loss': 0.18804949511931907}
2023-01-04 23:17:09,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:09,034 INFO:     Epoch: 60
2023-01-04 23:17:11,372 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4561503310998281, 'Total loss': 0.4561503310998281} | train loss {'Reaction outcome loss': 0.19935344423029558, 'Total loss': 0.19935344423029558}
2023-01-04 23:17:11,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:11,372 INFO:     Epoch: 61
2023-01-04 23:17:13,672 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4169443229834239, 'Total loss': 0.4169443229834239} | train loss {'Reaction outcome loss': 0.1929812714649156, 'Total loss': 0.1929812714649156}
2023-01-04 23:17:13,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:13,673 INFO:     Epoch: 62
2023-01-04 23:17:15,953 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4300903638203939, 'Total loss': 0.4300903638203939} | train loss {'Reaction outcome loss': 0.18360406275004795, 'Total loss': 0.18360406275004795}
2023-01-04 23:17:15,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:15,954 INFO:     Epoch: 63
2023-01-04 23:17:18,231 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42138471429546676, 'Total loss': 0.42138471429546676} | train loss {'Reaction outcome loss': 0.18613688397264974, 'Total loss': 0.18613688397264974}
2023-01-04 23:17:18,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:18,231 INFO:     Epoch: 64
2023-01-04 23:17:20,494 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4479653924703598, 'Total loss': 0.4479653924703598} | train loss {'Reaction outcome loss': 0.19436869300592569, 'Total loss': 0.19436869300592569}
2023-01-04 23:17:20,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:20,494 INFO:     Epoch: 65
2023-01-04 23:17:22,786 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4491720030705134, 'Total loss': 0.4491720030705134} | train loss {'Reaction outcome loss': 0.18586834741668903, 'Total loss': 0.18586834741668903}
2023-01-04 23:17:22,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:22,787 INFO:     Epoch: 66
2023-01-04 23:17:25,050 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43313976923624675, 'Total loss': 0.43313976923624675} | train loss {'Reaction outcome loss': 0.18727871543973254, 'Total loss': 0.18727871543973254}
2023-01-04 23:17:25,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:25,051 INFO:     Epoch: 67
2023-01-04 23:17:27,345 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4306109011173248, 'Total loss': 0.4306109011173248} | train loss {'Reaction outcome loss': 0.18140392001240854, 'Total loss': 0.18140392001240854}
2023-01-04 23:17:27,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:27,346 INFO:     Epoch: 68
2023-01-04 23:17:29,644 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.431281316280365, 'Total loss': 0.431281316280365} | train loss {'Reaction outcome loss': 0.18286847409082826, 'Total loss': 0.18286847409082826}
2023-01-04 23:17:29,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:29,644 INFO:     Epoch: 69
2023-01-04 23:17:31,894 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43834288269281385, 'Total loss': 0.43834288269281385} | train loss {'Reaction outcome loss': 0.1849562101728461, 'Total loss': 0.1849562101728461}
2023-01-04 23:17:31,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:31,894 INFO:     Epoch: 70
2023-01-04 23:17:34,133 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4199057032664617, 'Total loss': 0.4199057032664617} | train loss {'Reaction outcome loss': 0.1798493473888089, 'Total loss': 0.1798493473888089}
2023-01-04 23:17:34,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:34,134 INFO:     Epoch: 71
2023-01-04 23:17:36,412 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4571575830380122, 'Total loss': 0.4571575830380122} | train loss {'Reaction outcome loss': 0.17917137053401785, 'Total loss': 0.17917137053401785}
2023-01-04 23:17:36,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:36,412 INFO:     Epoch: 72
2023-01-04 23:17:38,691 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4591319978237152, 'Total loss': 0.4591319978237152} | train loss {'Reaction outcome loss': 0.18048444226895213, 'Total loss': 0.18048444226895213}
2023-01-04 23:17:38,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:38,691 INFO:     Epoch: 73
2023-01-04 23:17:40,975 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4611434092124303, 'Total loss': 0.4611434092124303} | train loss {'Reaction outcome loss': 0.1768859820507655, 'Total loss': 0.1768859820507655}
2023-01-04 23:17:40,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:40,975 INFO:     Epoch: 74
2023-01-04 23:17:43,236 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4553232048948606, 'Total loss': 0.4553232048948606} | train loss {'Reaction outcome loss': 0.18215946239563854, 'Total loss': 0.18215946239563854}
2023-01-04 23:17:43,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:43,236 INFO:     Epoch: 75
2023-01-04 23:17:45,503 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45246309638023374, 'Total loss': 0.45246309638023374} | train loss {'Reaction outcome loss': 0.17727977922774635, 'Total loss': 0.17727977922774635}
2023-01-04 23:17:45,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:45,504 INFO:     Epoch: 76
2023-01-04 23:17:47,767 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4322269695500533, 'Total loss': 0.4322269695500533} | train loss {'Reaction outcome loss': 0.18055694026448882, 'Total loss': 0.18055694026448882}
2023-01-04 23:17:47,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:47,768 INFO:     Epoch: 77
2023-01-04 23:17:50,062 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4517064074675242, 'Total loss': 0.4517064074675242} | train loss {'Reaction outcome loss': 0.1778361583885061, 'Total loss': 0.1778361583885061}
2023-01-04 23:17:50,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:50,063 INFO:     Epoch: 78
2023-01-04 23:17:52,353 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4226316894094149, 'Total loss': 0.4226316894094149} | train loss {'Reaction outcome loss': 0.17440477779995825, 'Total loss': 0.17440477779995825}
2023-01-04 23:17:52,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:52,353 INFO:     Epoch: 79
2023-01-04 23:17:54,641 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46286069800456364, 'Total loss': 0.46286069800456364} | train loss {'Reaction outcome loss': 0.17355440701408453, 'Total loss': 0.17355440701408453}
2023-01-04 23:17:54,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:54,642 INFO:     Epoch: 80
2023-01-04 23:17:56,934 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45522169172763827, 'Total loss': 0.45522169172763827} | train loss {'Reaction outcome loss': 0.17043157864617528, 'Total loss': 0.17043157864617528}
2023-01-04 23:17:56,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:56,934 INFO:     Epoch: 81
2023-01-04 23:17:59,173 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4329306920369466, 'Total loss': 0.4329306920369466} | train loss {'Reaction outcome loss': 0.17144454427446754, 'Total loss': 0.17144454427446754}
2023-01-04 23:17:59,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:17:59,173 INFO:     Epoch: 82
2023-01-04 23:18:01,392 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4455465793609619, 'Total loss': 0.4455465793609619} | train loss {'Reaction outcome loss': 0.17213821307577812, 'Total loss': 0.17213821307577812}
2023-01-04 23:18:01,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:01,392 INFO:     Epoch: 83
2023-01-04 23:18:03,637 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42806649804115293, 'Total loss': 0.42806649804115293} | train loss {'Reaction outcome loss': 0.17395277670248402, 'Total loss': 0.17395277670248402}
2023-01-04 23:18:03,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:03,638 INFO:     Epoch: 84
2023-01-04 23:18:05,909 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4303830881913503, 'Total loss': 0.4303830881913503} | train loss {'Reaction outcome loss': 0.17674202824999924, 'Total loss': 0.17674202824999924}
2023-01-04 23:18:05,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:05,909 INFO:     Epoch: 85
2023-01-04 23:18:08,181 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.446844611565272, 'Total loss': 0.446844611565272} | train loss {'Reaction outcome loss': 0.16903517034832752, 'Total loss': 0.16903517034832752}
2023-01-04 23:18:08,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:08,182 INFO:     Epoch: 86
2023-01-04 23:18:10,441 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4562847137451172, 'Total loss': 0.4562847137451172} | train loss {'Reaction outcome loss': 0.16977040840830612, 'Total loss': 0.16977040840830612}
2023-01-04 23:18:10,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:10,441 INFO:     Epoch: 87
2023-01-04 23:18:12,719 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4552081048488617, 'Total loss': 0.4552081048488617} | train loss {'Reaction outcome loss': 0.1667568003388949, 'Total loss': 0.1667568003388949}
2023-01-04 23:18:12,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:12,719 INFO:     Epoch: 88
2023-01-04 23:18:14,959 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45050180355707803, 'Total loss': 0.45050180355707803} | train loss {'Reaction outcome loss': 0.17453428191075687, 'Total loss': 0.17453428191075687}
2023-01-04 23:18:14,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:14,959 INFO:     Epoch: 89
2023-01-04 23:18:17,228 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42648040056228637, 'Total loss': 0.42648040056228637} | train loss {'Reaction outcome loss': 0.16902000168405662, 'Total loss': 0.16902000168405662}
2023-01-04 23:18:17,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:17,229 INFO:     Epoch: 90
2023-01-04 23:18:19,471 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41591627995173136, 'Total loss': 0.41591627995173136} | train loss {'Reaction outcome loss': 0.16925438837608867, 'Total loss': 0.16925438837608867}
2023-01-04 23:18:19,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:19,471 INFO:     Epoch: 91
2023-01-04 23:18:21,706 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4301391194264094, 'Total loss': 0.4301391194264094} | train loss {'Reaction outcome loss': 0.16527754070896267, 'Total loss': 0.16527754070896267}
2023-01-04 23:18:21,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:21,706 INFO:     Epoch: 92
2023-01-04 23:18:24,034 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4102546046177546, 'Total loss': 0.4102546046177546} | train loss {'Reaction outcome loss': 0.16546434032249968, 'Total loss': 0.16546434032249968}
2023-01-04 23:18:24,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:24,034 INFO:     Epoch: 93
2023-01-04 23:18:26,398 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46338038245836893, 'Total loss': 0.46338038245836893} | train loss {'Reaction outcome loss': 0.1623527616470891, 'Total loss': 0.1623527616470891}
2023-01-04 23:18:26,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:26,398 INFO:     Epoch: 94
2023-01-04 23:18:28,759 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43866504430770875, 'Total loss': 0.43866504430770875} | train loss {'Reaction outcome loss': 0.16534568713086956, 'Total loss': 0.16534568713086956}
2023-01-04 23:18:28,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:28,759 INFO:     Epoch: 95
2023-01-04 23:18:31,025 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.436258206764857, 'Total loss': 0.436258206764857} | train loss {'Reaction outcome loss': 0.16172850465516322, 'Total loss': 0.16172850465516322}
2023-01-04 23:18:31,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:31,025 INFO:     Epoch: 96
2023-01-04 23:18:33,223 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41286092897256216, 'Total loss': 0.41286092897256216} | train loss {'Reaction outcome loss': 0.16196694085878802, 'Total loss': 0.16196694085878802}
2023-01-04 23:18:33,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:33,223 INFO:     Epoch: 97
2023-01-04 23:18:35,469 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.439941343665123, 'Total loss': 0.439941343665123} | train loss {'Reaction outcome loss': 0.16385044351334446, 'Total loss': 0.16385044351334446}
2023-01-04 23:18:35,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:35,470 INFO:     Epoch: 98
2023-01-04 23:18:37,755 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40388526221116383, 'Total loss': 0.40388526221116383} | train loss {'Reaction outcome loss': 0.164956665290217, 'Total loss': 0.164956665290217}
2023-01-04 23:18:37,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:37,756 INFO:     Epoch: 99
2023-01-04 23:18:40,039 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3783925801515579, 'Total loss': 0.3783925801515579} | train loss {'Reaction outcome loss': 0.1621485093830402, 'Total loss': 0.1621485093830402}
2023-01-04 23:18:40,040 INFO:     Found new best model at epoch 99
2023-01-04 23:18:40,041 INFO:     Best model found after epoch 100 of 100.
2023-01-04 23:18:40,042 INFO:   Done with stage: TRAINING
2023-01-04 23:18:40,042 INFO:   Starting stage: EVALUATION
2023-01-04 23:18:40,172 INFO:   Done with stage: EVALUATION
2023-01-04 23:18:40,172 INFO:   Leaving out SEQ value Fold_5
2023-01-04 23:18:40,185 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 23:18:40,185 INFO:   Starting stage: FEATURE SCALING
2023-01-04 23:18:40,845 INFO:   Done with stage: FEATURE SCALING
2023-01-04 23:18:40,845 INFO:   Starting stage: SCALING TARGETS
2023-01-04 23:18:40,917 INFO:   Done with stage: SCALING TARGETS
2023-01-04 23:18:40,918 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:18:40,918 INFO:     No hyperparam tuning for this model
2023-01-04 23:18:40,918 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:18:40,918 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 23:18:40,919 INFO:     None feature selector for col prot
2023-01-04 23:18:40,919 INFO:     None feature selector for col prot
2023-01-04 23:18:40,919 INFO:     None feature selector for col prot
2023-01-04 23:18:40,919 INFO:     None feature selector for col chem
2023-01-04 23:18:40,919 INFO:     None feature selector for col chem
2023-01-04 23:18:40,919 INFO:     None feature selector for col chem
2023-01-04 23:18:40,920 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 23:18:40,920 INFO:   Starting stage: BUILD MODEL
2023-01-04 23:18:40,921 INFO:     Number of params in model 72931
2023-01-04 23:18:40,925 INFO:   Done with stage: BUILD MODEL
2023-01-04 23:18:40,925 INFO:   Starting stage: TRAINING
2023-01-04 23:18:40,983 INFO:     Val loss before train {'Reaction outcome loss': 1.0405542333920796, 'Total loss': 1.0405542333920796}
2023-01-04 23:18:40,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:40,983 INFO:     Epoch: 0
2023-01-04 23:18:43,254 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.817188702027003, 'Total loss': 0.817188702027003} | train loss {'Reaction outcome loss': 0.9479570395542659, 'Total loss': 0.9479570395542659}
2023-01-04 23:18:43,254 INFO:     Found new best model at epoch 0
2023-01-04 23:18:43,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:43,255 INFO:     Epoch: 1
2023-01-04 23:18:45,506 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6040984233220418, 'Total loss': 0.6040984233220418} | train loss {'Reaction outcome loss': 0.6761306189000607, 'Total loss': 0.6761306189000607}
2023-01-04 23:18:45,506 INFO:     Found new best model at epoch 1
2023-01-04 23:18:45,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:45,508 INFO:     Epoch: 2
2023-01-04 23:18:47,768 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5184903959433238, 'Total loss': 0.5184903959433238} | train loss {'Reaction outcome loss': 0.5654187096633773, 'Total loss': 0.5654187096633773}
2023-01-04 23:18:47,769 INFO:     Found new best model at epoch 2
2023-01-04 23:18:47,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:47,770 INFO:     Epoch: 3
2023-01-04 23:18:50,018 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4775463799635569, 'Total loss': 0.4775463799635569} | train loss {'Reaction outcome loss': 0.5147318539709069, 'Total loss': 0.5147318539709069}
2023-01-04 23:18:50,018 INFO:     Found new best model at epoch 3
2023-01-04 23:18:50,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:50,020 INFO:     Epoch: 4
2023-01-04 23:18:52,268 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49854002793629965, 'Total loss': 0.49854002793629965} | train loss {'Reaction outcome loss': 0.5009707933210809, 'Total loss': 0.5009707933210809}
2023-01-04 23:18:52,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:52,269 INFO:     Epoch: 5
2023-01-04 23:18:54,501 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4759785453478495, 'Total loss': 0.4759785453478495} | train loss {'Reaction outcome loss': 0.47193328123809636, 'Total loss': 0.47193328123809636}
2023-01-04 23:18:54,502 INFO:     Found new best model at epoch 5
2023-01-04 23:18:54,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:54,503 INFO:     Epoch: 6
2023-01-04 23:18:56,718 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45619294345378875, 'Total loss': 0.45619294345378875} | train loss {'Reaction outcome loss': 0.4445442304932985, 'Total loss': 0.4445442304932985}
2023-01-04 23:18:56,718 INFO:     Found new best model at epoch 6
2023-01-04 23:18:56,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:56,719 INFO:     Epoch: 7
2023-01-04 23:18:58,998 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4417164425055186, 'Total loss': 0.4417164425055186} | train loss {'Reaction outcome loss': 0.431836552797324, 'Total loss': 0.431836552797324}
2023-01-04 23:18:58,998 INFO:     Found new best model at epoch 7
2023-01-04 23:18:59,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:18:59,000 INFO:     Epoch: 8
2023-01-04 23:19:01,084 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47054130434989927, 'Total loss': 0.47054130434989927} | train loss {'Reaction outcome loss': 0.42266055903957644, 'Total loss': 0.42266055903957644}
2023-01-04 23:19:01,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:01,085 INFO:     Epoch: 9
2023-01-04 23:19:03,355 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44051680763562523, 'Total loss': 0.44051680763562523} | train loss {'Reaction outcome loss': 0.40616098673933226, 'Total loss': 0.40616098673933226}
2023-01-04 23:19:03,355 INFO:     Found new best model at epoch 9
2023-01-04 23:19:03,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:03,357 INFO:     Epoch: 10
2023-01-04 23:19:05,587 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43142411013444265, 'Total loss': 0.43142411013444265} | train loss {'Reaction outcome loss': 0.3898382040037625, 'Total loss': 0.3898382040037625}
2023-01-04 23:19:05,588 INFO:     Found new best model at epoch 10
2023-01-04 23:19:05,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:05,589 INFO:     Epoch: 11
2023-01-04 23:19:07,816 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4317188084125519, 'Total loss': 0.4317188084125519} | train loss {'Reaction outcome loss': 0.3833951426878564, 'Total loss': 0.3833951426878564}
2023-01-04 23:19:07,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:07,816 INFO:     Epoch: 12
2023-01-04 23:19:10,077 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44833494822184244, 'Total loss': 0.44833494822184244} | train loss {'Reaction outcome loss': 0.3734758446343999, 'Total loss': 0.3734758446343999}
2023-01-04 23:19:10,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:10,078 INFO:     Epoch: 13
2023-01-04 23:19:12,336 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.426348348458608, 'Total loss': 0.426348348458608} | train loss {'Reaction outcome loss': 0.3629194287850228, 'Total loss': 0.3629194287850228}
2023-01-04 23:19:12,336 INFO:     Found new best model at epoch 13
2023-01-04 23:19:12,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:12,338 INFO:     Epoch: 14
2023-01-04 23:19:14,629 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4337006131807963, 'Total loss': 0.4337006131807963} | train loss {'Reaction outcome loss': 0.3533559770659085, 'Total loss': 0.3533559770659085}
2023-01-04 23:19:14,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:14,629 INFO:     Epoch: 15
2023-01-04 23:19:16,893 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4312754233678182, 'Total loss': 0.4312754233678182} | train loss {'Reaction outcome loss': 0.3442528175217086, 'Total loss': 0.3442528175217086}
2023-01-04 23:19:16,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:16,894 INFO:     Epoch: 16
2023-01-04 23:19:19,159 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42785220046838124, 'Total loss': 0.42785220046838124} | train loss {'Reaction outcome loss': 0.33663947418993473, 'Total loss': 0.33663947418993473}
2023-01-04 23:19:19,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:19,159 INFO:     Epoch: 17
2023-01-04 23:19:21,393 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43355787396430967, 'Total loss': 0.43355787396430967} | train loss {'Reaction outcome loss': 0.32774327123753616, 'Total loss': 0.32774327123753616}
2023-01-04 23:19:21,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:21,393 INFO:     Epoch: 18
2023-01-04 23:19:23,665 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42284738421440127, 'Total loss': 0.42284738421440127} | train loss {'Reaction outcome loss': 0.3151965708053414, 'Total loss': 0.3151965708053414}
2023-01-04 23:19:23,665 INFO:     Found new best model at epoch 18
2023-01-04 23:19:23,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:23,666 INFO:     Epoch: 19
2023-01-04 23:19:25,914 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4348675891757011, 'Total loss': 0.4348675891757011} | train loss {'Reaction outcome loss': 0.3107997255182177, 'Total loss': 0.3107997255182177}
2023-01-04 23:19:25,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:25,915 INFO:     Epoch: 20
2023-01-04 23:19:28,157 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44283474882443746, 'Total loss': 0.44283474882443746} | train loss {'Reaction outcome loss': 0.30498913249027904, 'Total loss': 0.30498913249027904}
2023-01-04 23:19:28,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:28,157 INFO:     Epoch: 21
2023-01-04 23:19:30,413 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41320655047893523, 'Total loss': 0.41320655047893523} | train loss {'Reaction outcome loss': 0.30009591661476315, 'Total loss': 0.30009591661476315}
2023-01-04 23:19:30,413 INFO:     Found new best model at epoch 21
2023-01-04 23:19:30,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:30,415 INFO:     Epoch: 22
2023-01-04 23:19:32,696 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4380081901947657, 'Total loss': 0.4380081901947657} | train loss {'Reaction outcome loss': 0.2904663345493052, 'Total loss': 0.2904663345493052}
2023-01-04 23:19:32,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:32,696 INFO:     Epoch: 23
2023-01-04 23:19:34,971 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4138913561900457, 'Total loss': 0.4138913561900457} | train loss {'Reaction outcome loss': 0.2851209147020068, 'Total loss': 0.2851209147020068}
2023-01-04 23:19:34,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:34,971 INFO:     Epoch: 24
2023-01-04 23:19:37,219 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4191707193851471, 'Total loss': 0.4191707193851471} | train loss {'Reaction outcome loss': 0.2830696015891221, 'Total loss': 0.2830696015891221}
2023-01-04 23:19:37,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:37,220 INFO:     Epoch: 25
2023-01-04 23:19:39,463 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43951541384061177, 'Total loss': 0.43951541384061177} | train loss {'Reaction outcome loss': 0.27337308254124987, 'Total loss': 0.27337308254124987}
2023-01-04 23:19:39,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:39,463 INFO:     Epoch: 26
2023-01-04 23:19:41,657 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43831991255283353, 'Total loss': 0.43831991255283353} | train loss {'Reaction outcome loss': 0.2743018334326537, 'Total loss': 0.2743018334326537}
2023-01-04 23:19:41,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:41,657 INFO:     Epoch: 27
2023-01-04 23:19:43,905 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4183842251698176, 'Total loss': 0.4183842251698176} | train loss {'Reaction outcome loss': 0.26893268766677164, 'Total loss': 0.26893268766677164}
2023-01-04 23:19:43,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:43,905 INFO:     Epoch: 28
2023-01-04 23:19:46,194 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42358576456705727, 'Total loss': 0.42358576456705727} | train loss {'Reaction outcome loss': 0.2627377194863663, 'Total loss': 0.2627377194863663}
2023-01-04 23:19:46,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:46,196 INFO:     Epoch: 29
2023-01-04 23:19:48,455 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47182472348213195, 'Total loss': 0.47182472348213195} | train loss {'Reaction outcome loss': 0.25912892265056353, 'Total loss': 0.25912892265056353}
2023-01-04 23:19:48,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:48,455 INFO:     Epoch: 30
2023-01-04 23:19:50,711 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4339047541220983, 'Total loss': 0.4339047541220983} | train loss {'Reaction outcome loss': 0.2611887453805547, 'Total loss': 0.2611887453805547}
2023-01-04 23:19:50,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:50,711 INFO:     Epoch: 31
2023-01-04 23:19:52,964 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44246899684270224, 'Total loss': 0.44246899684270224} | train loss {'Reaction outcome loss': 0.25246748308753647, 'Total loss': 0.25246748308753647}
2023-01-04 23:19:52,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:52,965 INFO:     Epoch: 32
2023-01-04 23:19:55,227 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4203487515449524, 'Total loss': 0.4203487515449524} | train loss {'Reaction outcome loss': 0.24898246926634296, 'Total loss': 0.24898246926634296}
2023-01-04 23:19:55,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:55,227 INFO:     Epoch: 33
2023-01-04 23:19:57,509 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44567069311936697, 'Total loss': 0.44567069311936697} | train loss {'Reaction outcome loss': 0.24529963320094175, 'Total loss': 0.24529963320094175}
2023-01-04 23:19:57,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:57,509 INFO:     Epoch: 34
2023-01-04 23:19:59,736 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41819846332073213, 'Total loss': 0.41819846332073213} | train loss {'Reaction outcome loss': 0.2422762695848402, 'Total loss': 0.2422762695848402}
2023-01-04 23:19:59,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:19:59,736 INFO:     Epoch: 35
2023-01-04 23:20:01,973 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4469686562816302, 'Total loss': 0.4469686562816302} | train loss {'Reaction outcome loss': 0.2384973988443127, 'Total loss': 0.2384973988443127}
2023-01-04 23:20:01,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:01,973 INFO:     Epoch: 36
2023-01-04 23:20:04,196 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4563373148441315, 'Total loss': 0.4563373148441315} | train loss {'Reaction outcome loss': 0.24349721522336645, 'Total loss': 0.24349721522336645}
2023-01-04 23:20:04,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:04,197 INFO:     Epoch: 37
2023-01-04 23:20:06,457 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43830639322598774, 'Total loss': 0.43830639322598774} | train loss {'Reaction outcome loss': 0.23954162412606503, 'Total loss': 0.23954162412606503}
2023-01-04 23:20:06,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:06,458 INFO:     Epoch: 38
2023-01-04 23:20:08,650 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4461434088647366, 'Total loss': 0.4461434088647366} | train loss {'Reaction outcome loss': 0.23140208706984372, 'Total loss': 0.23140208706984372}
2023-01-04 23:20:08,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:08,650 INFO:     Epoch: 39
2023-01-04 23:20:10,883 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4454640671610832, 'Total loss': 0.4454640671610832} | train loss {'Reaction outcome loss': 0.22441026069007922, 'Total loss': 0.22441026069007922}
2023-01-04 23:20:10,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:10,883 INFO:     Epoch: 40
2023-01-04 23:20:13,146 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47051354149977365, 'Total loss': 0.47051354149977365} | train loss {'Reaction outcome loss': 0.22517291045284987, 'Total loss': 0.22517291045284987}
2023-01-04 23:20:13,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:13,147 INFO:     Epoch: 41
2023-01-04 23:20:15,396 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4304872781038284, 'Total loss': 0.4304872781038284} | train loss {'Reaction outcome loss': 0.22083910748293367, 'Total loss': 0.22083910748293367}
2023-01-04 23:20:15,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:15,397 INFO:     Epoch: 42
2023-01-04 23:20:17,637 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47328803141911824, 'Total loss': 0.47328803141911824} | train loss {'Reaction outcome loss': 0.22063845426387194, 'Total loss': 0.22063845426387194}
2023-01-04 23:20:17,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:17,638 INFO:     Epoch: 43
2023-01-04 23:20:19,904 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44551642599205177, 'Total loss': 0.44551642599205177} | train loss {'Reaction outcome loss': 0.21802827178254264, 'Total loss': 0.21802827178254264}
2023-01-04 23:20:19,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:19,904 INFO:     Epoch: 44
2023-01-04 23:20:22,190 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4555651624997457, 'Total loss': 0.4555651624997457} | train loss {'Reaction outcome loss': 0.2180131436201971, 'Total loss': 0.2180131436201971}
2023-01-04 23:20:22,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:22,192 INFO:     Epoch: 45
2023-01-04 23:20:24,457 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4610251983006795, 'Total loss': 0.4610251983006795} | train loss {'Reaction outcome loss': 0.21586485473644512, 'Total loss': 0.21586485473644512}
2023-01-04 23:20:24,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:24,458 INFO:     Epoch: 46
2023-01-04 23:20:26,741 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45559522608915964, 'Total loss': 0.45559522608915964} | train loss {'Reaction outcome loss': 0.212839528452605, 'Total loss': 0.212839528452605}
2023-01-04 23:20:26,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:26,741 INFO:     Epoch: 47
2023-01-04 23:20:29,002 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4416104351480802, 'Total loss': 0.4416104351480802} | train loss {'Reaction outcome loss': 0.21291680841713442, 'Total loss': 0.21291680841713442}
2023-01-04 23:20:29,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:29,003 INFO:     Epoch: 48
2023-01-04 23:20:31,290 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44172254105408987, 'Total loss': 0.44172254105408987} | train loss {'Reaction outcome loss': 0.21118645290034296, 'Total loss': 0.21118645290034296}
2023-01-04 23:20:31,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:31,291 INFO:     Epoch: 49
2023-01-04 23:20:33,558 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45669230322043103, 'Total loss': 0.45669230322043103} | train loss {'Reaction outcome loss': 0.2373508247681826, 'Total loss': 0.2373508247681826}
2023-01-04 23:20:33,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:33,558 INFO:     Epoch: 50
2023-01-04 23:20:35,797 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44364270369211833, 'Total loss': 0.44364270369211833} | train loss {'Reaction outcome loss': 0.2083308004025046, 'Total loss': 0.2083308004025046}
2023-01-04 23:20:35,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:35,797 INFO:     Epoch: 51
2023-01-04 23:20:38,048 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46400029460589093, 'Total loss': 0.46400029460589093} | train loss {'Reaction outcome loss': 0.2060967381314739, 'Total loss': 0.2060967381314739}
2023-01-04 23:20:38,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:38,049 INFO:     Epoch: 52
2023-01-04 23:20:40,303 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4334633986155192, 'Total loss': 0.4334633986155192} | train loss {'Reaction outcome loss': 0.20561599401854977, 'Total loss': 0.20561599401854977}
2023-01-04 23:20:40,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:40,303 INFO:     Epoch: 53
2023-01-04 23:20:42,569 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46989498237768806, 'Total loss': 0.46989498237768806} | train loss {'Reaction outcome loss': 0.20216090804192852, 'Total loss': 0.20216090804192852}
2023-01-04 23:20:42,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:42,570 INFO:     Epoch: 54
2023-01-04 23:20:44,841 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42844275732835135, 'Total loss': 0.42844275732835135} | train loss {'Reaction outcome loss': 0.20282225842938584, 'Total loss': 0.20282225842938584}
2023-01-04 23:20:44,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:44,841 INFO:     Epoch: 55
2023-01-04 23:20:47,033 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45844690402348837, 'Total loss': 0.45844690402348837} | train loss {'Reaction outcome loss': 0.19398145552680734, 'Total loss': 0.19398145552680734}
2023-01-04 23:20:47,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:47,034 INFO:     Epoch: 56
2023-01-04 23:20:49,267 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4490600903828939, 'Total loss': 0.4490600903828939} | train loss {'Reaction outcome loss': 0.1928313479571308, 'Total loss': 0.1928313479571308}
2023-01-04 23:20:49,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:49,267 INFO:     Epoch: 57
2023-01-04 23:20:51,476 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4700438479582469, 'Total loss': 0.4700438479582469} | train loss {'Reaction outcome loss': 0.19712865510518895, 'Total loss': 0.19712865510518895}
2023-01-04 23:20:51,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:51,476 INFO:     Epoch: 58
2023-01-04 23:20:53,749 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45856092845400176, 'Total loss': 0.45856092845400176} | train loss {'Reaction outcome loss': 0.1981024675626321, 'Total loss': 0.1981024675626321}
2023-01-04 23:20:53,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:53,750 INFO:     Epoch: 59
2023-01-04 23:20:56,038 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4460971992462873, 'Total loss': 0.4460971992462873} | train loss {'Reaction outcome loss': 0.19508546368097482, 'Total loss': 0.19508546368097482}
2023-01-04 23:20:56,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:56,038 INFO:     Epoch: 60
2023-01-04 23:20:58,324 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4529411395390828, 'Total loss': 0.4529411395390828} | train loss {'Reaction outcome loss': 0.206277533441436, 'Total loss': 0.206277533441436}
2023-01-04 23:20:58,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:20:58,325 INFO:     Epoch: 61
2023-01-04 23:21:00,623 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42043623278538383, 'Total loss': 0.42043623278538383} | train loss {'Reaction outcome loss': 0.1931787466755191, 'Total loss': 0.1931787466755191}
2023-01-04 23:21:00,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:00,623 INFO:     Epoch: 62
2023-01-04 23:21:02,809 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4284371480345726, 'Total loss': 0.4284371480345726} | train loss {'Reaction outcome loss': 0.19832144188968823, 'Total loss': 0.19832144188968823}
2023-01-04 23:21:02,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:02,809 INFO:     Epoch: 63
2023-01-04 23:21:05,085 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47871648569901787, 'Total loss': 0.47871648569901787} | train loss {'Reaction outcome loss': 0.19167608784029153, 'Total loss': 0.19167608784029153}
2023-01-04 23:21:05,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:05,086 INFO:     Epoch: 64
2023-01-04 23:21:07,352 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4381563772757848, 'Total loss': 0.4381563772757848} | train loss {'Reaction outcome loss': 0.18562383543821456, 'Total loss': 0.18562383543821456}
2023-01-04 23:21:07,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:07,352 INFO:     Epoch: 65
2023-01-04 23:21:09,672 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47821881572405495, 'Total loss': 0.47821881572405495} | train loss {'Reaction outcome loss': 0.1854839720054651, 'Total loss': 0.1854839720054651}
2023-01-04 23:21:09,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:09,672 INFO:     Epoch: 66
2023-01-04 23:21:11,967 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4740815301736196, 'Total loss': 0.4740815301736196} | train loss {'Reaction outcome loss': 0.21252370650198418, 'Total loss': 0.21252370650198418}
2023-01-04 23:21:11,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:11,967 INFO:     Epoch: 67
2023-01-04 23:21:14,210 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4452872266372045, 'Total loss': 0.4452872266372045} | train loss {'Reaction outcome loss': 0.18270320069469576, 'Total loss': 0.18270320069469576}
2023-01-04 23:21:14,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:14,211 INFO:     Epoch: 68
2023-01-04 23:21:16,432 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42089602748552957, 'Total loss': 0.42089602748552957} | train loss {'Reaction outcome loss': 0.1817423997386156, 'Total loss': 0.1817423997386156}
2023-01-04 23:21:16,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:16,433 INFO:     Epoch: 69
2023-01-04 23:21:18,694 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4849596361319224, 'Total loss': 0.4849596361319224} | train loss {'Reaction outcome loss': 0.184348321509669, 'Total loss': 0.184348321509669}
2023-01-04 23:21:18,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:18,694 INFO:     Epoch: 70
2023-01-04 23:21:20,957 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4358313341935476, 'Total loss': 0.4358313341935476} | train loss {'Reaction outcome loss': 0.17897534919451363, 'Total loss': 0.17897534919451363}
2023-01-04 23:21:20,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:20,957 INFO:     Epoch: 71
2023-01-04 23:21:23,233 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4474111020565033, 'Total loss': 0.4474111020565033} | train loss {'Reaction outcome loss': 0.17597490621973638, 'Total loss': 0.17597490621973638}
2023-01-04 23:21:23,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:23,234 INFO:     Epoch: 72
2023-01-04 23:21:25,462 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45203529198964437, 'Total loss': 0.45203529198964437} | train loss {'Reaction outcome loss': 0.1778110305954149, 'Total loss': 0.1778110305954149}
2023-01-04 23:21:25,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:25,462 INFO:     Epoch: 73
2023-01-04 23:21:27,700 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4409239838520686, 'Total loss': 0.4409239838520686} | train loss {'Reaction outcome loss': 0.19249025989067403, 'Total loss': 0.19249025989067403}
2023-01-04 23:21:27,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:27,702 INFO:     Epoch: 74
2023-01-04 23:21:30,003 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4581326901912689, 'Total loss': 0.4581326901912689} | train loss {'Reaction outcome loss': 0.19313956719201666, 'Total loss': 0.19313956719201666}
2023-01-04 23:21:30,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:30,003 INFO:     Epoch: 75
2023-01-04 23:21:32,222 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46819797723243634, 'Total loss': 0.46819797723243634} | train loss {'Reaction outcome loss': 0.1789318379045574, 'Total loss': 0.1789318379045574}
2023-01-04 23:21:32,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:32,222 INFO:     Epoch: 76
2023-01-04 23:21:34,491 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45893299480279287, 'Total loss': 0.45893299480279287} | train loss {'Reaction outcome loss': 0.1831941465826948, 'Total loss': 0.1831941465826948}
2023-01-04 23:21:34,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:34,492 INFO:     Epoch: 77
2023-01-04 23:21:36,774 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46237714737653735, 'Total loss': 0.46237714737653735} | train loss {'Reaction outcome loss': 0.18128094697744201, 'Total loss': 0.18128094697744201}
2023-01-04 23:21:36,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:36,774 INFO:     Epoch: 78
2023-01-04 23:21:39,023 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44169559329748154, 'Total loss': 0.44169559329748154} | train loss {'Reaction outcome loss': 0.17110552606797116, 'Total loss': 0.17110552606797116}
2023-01-04 23:21:39,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:39,023 INFO:     Epoch: 79
2023-01-04 23:21:41,307 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4737611452738444, 'Total loss': 0.4737611452738444} | train loss {'Reaction outcome loss': 0.1735845933806664, 'Total loss': 0.1735845933806664}
2023-01-04 23:21:41,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:41,308 INFO:     Epoch: 80
2023-01-04 23:21:43,578 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4654288227359454, 'Total loss': 0.4654288227359454} | train loss {'Reaction outcome loss': 0.17492409808258252, 'Total loss': 0.17492409808258252}
2023-01-04 23:21:43,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:43,579 INFO:     Epoch: 81
2023-01-04 23:21:45,831 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4359214693307877, 'Total loss': 0.4359214693307877} | train loss {'Reaction outcome loss': 0.17755206899913162, 'Total loss': 0.17755206899913162}
2023-01-04 23:21:45,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:45,831 INFO:     Epoch: 82
2023-01-04 23:21:48,125 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4647865017255147, 'Total loss': 0.4647865017255147} | train loss {'Reaction outcome loss': 0.178176177559299, 'Total loss': 0.178176177559299}
2023-01-04 23:21:48,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:48,126 INFO:     Epoch: 83
2023-01-04 23:21:50,371 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4517250252266725, 'Total loss': 0.4517250252266725} | train loss {'Reaction outcome loss': 0.17996209808726513, 'Total loss': 0.17996209808726513}
2023-01-04 23:21:50,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:50,372 INFO:     Epoch: 84
2023-01-04 23:21:52,658 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4640514406065146, 'Total loss': 0.4640514406065146} | train loss {'Reaction outcome loss': 0.17033931564715138, 'Total loss': 0.17033931564715138}
2023-01-04 23:21:52,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:52,658 INFO:     Epoch: 85
2023-01-04 23:21:54,941 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4370908205707868, 'Total loss': 0.4370908205707868} | train loss {'Reaction outcome loss': 0.16981472164479783, 'Total loss': 0.16981472164479783}
2023-01-04 23:21:54,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:54,941 INFO:     Epoch: 86
2023-01-04 23:21:57,221 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.447391664981842, 'Total loss': 0.447391664981842} | train loss {'Reaction outcome loss': 0.17443150771430446, 'Total loss': 0.17443150771430446}
2023-01-04 23:21:57,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:57,222 INFO:     Epoch: 87
2023-01-04 23:21:59,504 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4420529325803121, 'Total loss': 0.4420529325803121} | train loss {'Reaction outcome loss': 0.17112342444538692, 'Total loss': 0.17112342444538692}
2023-01-04 23:21:59,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:21:59,505 INFO:     Epoch: 88
2023-01-04 23:22:01,746 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49957818587621056, 'Total loss': 0.49957818587621056} | train loss {'Reaction outcome loss': 0.17283753045173228, 'Total loss': 0.17283753045173228}
2023-01-04 23:22:01,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:01,746 INFO:     Epoch: 89
2023-01-04 23:22:03,990 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.498464593787988, 'Total loss': 0.498464593787988} | train loss {'Reaction outcome loss': 0.17058649325770311, 'Total loss': 0.17058649325770311}
2023-01-04 23:22:03,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:03,991 INFO:     Epoch: 90
2023-01-04 23:22:06,260 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4838379554450512, 'Total loss': 0.4838379554450512} | train loss {'Reaction outcome loss': 0.16856397697162154, 'Total loss': 0.16856397697162154}
2023-01-04 23:22:06,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:06,260 INFO:     Epoch: 91
2023-01-04 23:22:08,530 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5006386863688628, 'Total loss': 0.5006386863688628} | train loss {'Reaction outcome loss': 0.16948062724058863, 'Total loss': 0.16948062724058863}
2023-01-04 23:22:08,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:08,531 INFO:     Epoch: 92
2023-01-04 23:22:10,801 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46268286208311715, 'Total loss': 0.46268286208311715} | train loss {'Reaction outcome loss': 0.17200925386387625, 'Total loss': 0.17200925386387625}
2023-01-04 23:22:10,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:10,802 INFO:     Epoch: 93
2023-01-04 23:22:13,037 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46848679383595787, 'Total loss': 0.46848679383595787} | train loss {'Reaction outcome loss': 0.16633506114822408, 'Total loss': 0.16633506114822408}
2023-01-04 23:22:13,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:13,038 INFO:     Epoch: 94
2023-01-04 23:22:15,307 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5089978729685147, 'Total loss': 0.5089978729685147} | train loss {'Reaction outcome loss': 0.16760901065182238, 'Total loss': 0.16760901065182238}
2023-01-04 23:22:15,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:15,308 INFO:     Epoch: 95
2023-01-04 23:22:17,570 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4867755780617396, 'Total loss': 0.4867755780617396} | train loss {'Reaction outcome loss': 0.1682203583127441, 'Total loss': 0.1682203583127441}
2023-01-04 23:22:17,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:17,571 INFO:     Epoch: 96
2023-01-04 23:22:19,829 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4704374442497889, 'Total loss': 0.4704374442497889} | train loss {'Reaction outcome loss': 0.16744652986992573, 'Total loss': 0.16744652986992573}
2023-01-04 23:22:19,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:19,829 INFO:     Epoch: 97
2023-01-04 23:22:22,110 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5061319331328075, 'Total loss': 0.5061319331328075} | train loss {'Reaction outcome loss': 0.1639550709472699, 'Total loss': 0.1639550709472699}
2023-01-04 23:22:22,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:22,110 INFO:     Epoch: 98
2023-01-04 23:22:24,367 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45809954504172007, 'Total loss': 0.45809954504172007} | train loss {'Reaction outcome loss': 0.16391743313790005, 'Total loss': 0.16391743313790005}
2023-01-04 23:22:24,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:24,368 INFO:     Epoch: 99
2023-01-04 23:22:26,616 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4883331795533498, 'Total loss': 0.4883331795533498} | train loss {'Reaction outcome loss': 0.18289721929771907, 'Total loss': 0.18289721929771907}
2023-01-04 23:22:26,617 INFO:     Best model found after epoch 22 of 100.
2023-01-04 23:22:26,617 INFO:   Done with stage: TRAINING
2023-01-04 23:22:26,617 INFO:   Starting stage: EVALUATION
2023-01-04 23:22:26,753 INFO:   Done with stage: EVALUATION
2023-01-04 23:22:26,753 INFO:   Leaving out SEQ value Fold_6
2023-01-04 23:22:26,766 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 23:22:26,766 INFO:   Starting stage: FEATURE SCALING
2023-01-04 23:22:27,423 INFO:   Done with stage: FEATURE SCALING
2023-01-04 23:22:27,423 INFO:   Starting stage: SCALING TARGETS
2023-01-04 23:22:27,495 INFO:   Done with stage: SCALING TARGETS
2023-01-04 23:22:27,496 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:22:27,496 INFO:     No hyperparam tuning for this model
2023-01-04 23:22:27,496 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:22:27,496 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 23:22:27,496 INFO:     None feature selector for col prot
2023-01-04 23:22:27,497 INFO:     None feature selector for col prot
2023-01-04 23:22:27,497 INFO:     None feature selector for col prot
2023-01-04 23:22:27,497 INFO:     None feature selector for col chem
2023-01-04 23:22:27,497 INFO:     None feature selector for col chem
2023-01-04 23:22:27,497 INFO:     None feature selector for col chem
2023-01-04 23:22:27,497 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 23:22:27,497 INFO:   Starting stage: BUILD MODEL
2023-01-04 23:22:27,499 INFO:     Number of params in model 72931
2023-01-04 23:22:27,502 INFO:   Done with stage: BUILD MODEL
2023-01-04 23:22:27,502 INFO:   Starting stage: TRAINING
2023-01-04 23:22:27,564 INFO:     Val loss before train {'Reaction outcome loss': 1.0212197780609131, 'Total loss': 1.0212197780609131}
2023-01-04 23:22:27,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:27,565 INFO:     Epoch: 0
2023-01-04 23:22:29,847 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7947020173072815, 'Total loss': 0.7947020173072815} | train loss {'Reaction outcome loss': 0.9224593207939437, 'Total loss': 0.9224593207939437}
2023-01-04 23:22:29,847 INFO:     Found new best model at epoch 0
2023-01-04 23:22:29,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:29,849 INFO:     Epoch: 1
2023-01-04 23:22:32,131 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5736074527104695, 'Total loss': 0.5736074527104695} | train loss {'Reaction outcome loss': 0.6211304184762149, 'Total loss': 0.6211304184762149}
2023-01-04 23:22:32,132 INFO:     Found new best model at epoch 1
2023-01-04 23:22:32,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:32,133 INFO:     Epoch: 2
2023-01-04 23:22:34,406 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5404145936171214, 'Total loss': 0.5404145936171214} | train loss {'Reaction outcome loss': 0.533242852571639, 'Total loss': 0.533242852571639}
2023-01-04 23:22:34,407 INFO:     Found new best model at epoch 2
2023-01-04 23:22:34,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:34,408 INFO:     Epoch: 3
2023-01-04 23:22:36,648 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.522036341826121, 'Total loss': 0.522036341826121} | train loss {'Reaction outcome loss': 0.4948745240534686, 'Total loss': 0.4948745240534686}
2023-01-04 23:22:36,648 INFO:     Found new best model at epoch 3
2023-01-04 23:22:36,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:36,650 INFO:     Epoch: 4
2023-01-04 23:22:38,879 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4976820210615794, 'Total loss': 0.4976820210615794} | train loss {'Reaction outcome loss': 0.4661566155966008, 'Total loss': 0.4661566155966008}
2023-01-04 23:22:38,879 INFO:     Found new best model at epoch 4
2023-01-04 23:22:38,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:38,880 INFO:     Epoch: 5
2023-01-04 23:22:41,150 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4745092213153839, 'Total loss': 0.4745092213153839} | train loss {'Reaction outcome loss': 0.4436579193879551, 'Total loss': 0.4436579193879551}
2023-01-04 23:22:41,151 INFO:     Found new best model at epoch 5
2023-01-04 23:22:41,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:41,153 INFO:     Epoch: 6
2023-01-04 23:22:43,448 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4637647171815236, 'Total loss': 0.4637647171815236} | train loss {'Reaction outcome loss': 0.4310676519782535, 'Total loss': 0.4310676519782535}
2023-01-04 23:22:43,448 INFO:     Found new best model at epoch 6
2023-01-04 23:22:43,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:43,449 INFO:     Epoch: 7
2023-01-04 23:22:45,720 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4702505807081858, 'Total loss': 0.4702505807081858} | train loss {'Reaction outcome loss': 0.4180228780376782, 'Total loss': 0.4180228780376782}
2023-01-04 23:22:45,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:45,721 INFO:     Epoch: 8
2023-01-04 23:22:47,971 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4793957183758418, 'Total loss': 0.4793957183758418} | train loss {'Reaction outcome loss': 0.4080614534203326, 'Total loss': 0.4080614534203326}
2023-01-04 23:22:47,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:47,972 INFO:     Epoch: 9
2023-01-04 23:22:50,166 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46112950245539347, 'Total loss': 0.46112950245539347} | train loss {'Reaction outcome loss': 0.3946379043619125, 'Total loss': 0.3946379043619125}
2023-01-04 23:22:50,167 INFO:     Found new best model at epoch 9
2023-01-04 23:22:50,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:50,168 INFO:     Epoch: 10
2023-01-04 23:22:52,410 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4632437249024709, 'Total loss': 0.4632437249024709} | train loss {'Reaction outcome loss': 0.385352276319416, 'Total loss': 0.385352276319416}
2023-01-04 23:22:52,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:52,410 INFO:     Epoch: 11
2023-01-04 23:22:54,676 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48058943351109823, 'Total loss': 0.48058943351109823} | train loss {'Reaction outcome loss': 0.37386596116778653, 'Total loss': 0.37386596116778653}
2023-01-04 23:22:54,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:54,677 INFO:     Epoch: 12
2023-01-04 23:22:56,961 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4536199529965719, 'Total loss': 0.4536199529965719} | train loss {'Reaction outcome loss': 0.37005090490252535, 'Total loss': 0.37005090490252535}
2023-01-04 23:22:56,961 INFO:     Found new best model at epoch 12
2023-01-04 23:22:56,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:56,962 INFO:     Epoch: 13
2023-01-04 23:22:59,245 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4535158594449361, 'Total loss': 0.4535158594449361} | train loss {'Reaction outcome loss': 0.3617034049617254, 'Total loss': 0.3617034049617254}
2023-01-04 23:22:59,245 INFO:     Found new best model at epoch 13
2023-01-04 23:22:59,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:22:59,246 INFO:     Epoch: 14
2023-01-04 23:23:01,164 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4612702906131744, 'Total loss': 0.4612702906131744} | train loss {'Reaction outcome loss': 0.3522791123347162, 'Total loss': 0.3522791123347162}
2023-01-04 23:23:01,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:01,165 INFO:     Epoch: 15
2023-01-04 23:23:02,999 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4417919099330902, 'Total loss': 0.4417919099330902} | train loss {'Reaction outcome loss': 0.34285910575506057, 'Total loss': 0.34285910575506057}
2023-01-04 23:23:02,999 INFO:     Found new best model at epoch 15
2023-01-04 23:23:03,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:03,001 INFO:     Epoch: 16
2023-01-04 23:23:05,083 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45301098624865216, 'Total loss': 0.45301098624865216} | train loss {'Reaction outcome loss': 0.3357761788050836, 'Total loss': 0.3357761788050836}
2023-01-04 23:23:05,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:05,083 INFO:     Epoch: 17
2023-01-04 23:23:07,367 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45655840039253237, 'Total loss': 0.45655840039253237} | train loss {'Reaction outcome loss': 0.33252068734072177, 'Total loss': 0.33252068734072177}
2023-01-04 23:23:07,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:07,368 INFO:     Epoch: 18
2023-01-04 23:23:09,472 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4626710375150045, 'Total loss': 0.4626710375150045} | train loss {'Reaction outcome loss': 0.3234563807449186, 'Total loss': 0.3234563807449186}
2023-01-04 23:23:09,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:09,473 INFO:     Epoch: 19
2023-01-04 23:23:11,756 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4511885593334834, 'Total loss': 0.4511885593334834} | train loss {'Reaction outcome loss': 0.3218368883732209, 'Total loss': 0.3218368883732209}
2023-01-04 23:23:11,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:11,758 INFO:     Epoch: 20
2023-01-04 23:23:14,044 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4567002922296524, 'Total loss': 0.4567002922296524} | train loss {'Reaction outcome loss': 0.31358771790020734, 'Total loss': 0.31358771790020734}
2023-01-04 23:23:14,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:14,044 INFO:     Epoch: 21
2023-01-04 23:23:16,339 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4388556458055973, 'Total loss': 0.4388556458055973} | train loss {'Reaction outcome loss': 0.30922540785603575, 'Total loss': 0.30922540785603575}
2023-01-04 23:23:16,339 INFO:     Found new best model at epoch 21
2023-01-04 23:23:16,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:16,340 INFO:     Epoch: 22
2023-01-04 23:23:18,629 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4620469331741333, 'Total loss': 0.4620469331741333} | train loss {'Reaction outcome loss': 0.3077090944328248, 'Total loss': 0.3077090944328248}
2023-01-04 23:23:18,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:18,630 INFO:     Epoch: 23
2023-01-04 23:23:20,914 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.457573601603508, 'Total loss': 0.457573601603508} | train loss {'Reaction outcome loss': 0.29619125067004226, 'Total loss': 0.29619125067004226}
2023-01-04 23:23:20,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:20,914 INFO:     Epoch: 24
2023-01-04 23:23:23,159 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4540125966072083, 'Total loss': 0.4540125966072083} | train loss {'Reaction outcome loss': 0.2953243460035496, 'Total loss': 0.2953243460035496}
2023-01-04 23:23:23,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:23,159 INFO:     Epoch: 25
2023-01-04 23:23:25,433 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4454214036464691, 'Total loss': 0.4454214036464691} | train loss {'Reaction outcome loss': 0.2921796561713038, 'Total loss': 0.2921796561713038}
2023-01-04 23:23:25,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:25,434 INFO:     Epoch: 26
2023-01-04 23:23:27,694 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4307391494512558, 'Total loss': 0.4307391494512558} | train loss {'Reaction outcome loss': 0.2843414535107165, 'Total loss': 0.2843414535107165}
2023-01-04 23:23:27,694 INFO:     Found new best model at epoch 26
2023-01-04 23:23:27,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:27,695 INFO:     Epoch: 27
2023-01-04 23:23:29,937 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4468964099884033, 'Total loss': 0.4468964099884033} | train loss {'Reaction outcome loss': 0.28110087872735, 'Total loss': 0.28110087872735}
2023-01-04 23:23:29,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:29,938 INFO:     Epoch: 28
2023-01-04 23:23:32,225 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4299878383676211, 'Total loss': 0.4299878383676211} | train loss {'Reaction outcome loss': 0.2805155026272531, 'Total loss': 0.2805155026272531}
2023-01-04 23:23:32,225 INFO:     Found new best model at epoch 28
2023-01-04 23:23:32,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:32,227 INFO:     Epoch: 29
2023-01-04 23:23:34,507 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4271841983000437, 'Total loss': 0.4271841983000437} | train loss {'Reaction outcome loss': 0.26968277649221006, 'Total loss': 0.26968277649221006}
2023-01-04 23:23:34,507 INFO:     Found new best model at epoch 29
2023-01-04 23:23:34,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:34,508 INFO:     Epoch: 30
2023-01-04 23:23:36,796 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.446649702390035, 'Total loss': 0.446649702390035} | train loss {'Reaction outcome loss': 0.269892814814614, 'Total loss': 0.269892814814614}
2023-01-04 23:23:36,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:36,796 INFO:     Epoch: 31
2023-01-04 23:23:39,072 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4507912307977676, 'Total loss': 0.4507912307977676} | train loss {'Reaction outcome loss': 0.26632841004710983, 'Total loss': 0.26632841004710983}
2023-01-04 23:23:39,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:39,072 INFO:     Epoch: 32
2023-01-04 23:23:41,358 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4443579614162445, 'Total loss': 0.4443579614162445} | train loss {'Reaction outcome loss': 0.26459094577398323, 'Total loss': 0.26459094577398323}
2023-01-04 23:23:41,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:41,359 INFO:     Epoch: 33
2023-01-04 23:23:43,628 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45160075823465984, 'Total loss': 0.45160075823465984} | train loss {'Reaction outcome loss': 0.2629250333466254, 'Total loss': 0.2629250333466254}
2023-01-04 23:23:43,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:43,628 INFO:     Epoch: 34
2023-01-04 23:23:45,839 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44380613366762794, 'Total loss': 0.44380613366762794} | train loss {'Reaction outcome loss': 0.24855063081002837, 'Total loss': 0.24855063081002837}
2023-01-04 23:23:45,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:45,839 INFO:     Epoch: 35
2023-01-04 23:23:48,102 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46692178497711817, 'Total loss': 0.46692178497711817} | train loss {'Reaction outcome loss': 0.25188012235539053, 'Total loss': 0.25188012235539053}
2023-01-04 23:23:48,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:48,103 INFO:     Epoch: 36
2023-01-04 23:23:50,370 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4845903366804123, 'Total loss': 0.4845903366804123} | train loss {'Reaction outcome loss': 0.251975240898638, 'Total loss': 0.251975240898638}
2023-01-04 23:23:50,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:50,370 INFO:     Epoch: 37
2023-01-04 23:23:52,614 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44528324802716573, 'Total loss': 0.44528324802716573} | train loss {'Reaction outcome loss': 0.2500262818423634, 'Total loss': 0.2500262818423634}
2023-01-04 23:23:52,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:52,614 INFO:     Epoch: 38
2023-01-04 23:23:54,854 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4520709792772929, 'Total loss': 0.4520709792772929} | train loss {'Reaction outcome loss': 0.24511940755447648, 'Total loss': 0.24511940755447648}
2023-01-04 23:23:54,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:54,855 INFO:     Epoch: 39
2023-01-04 23:23:57,095 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4320538346966108, 'Total loss': 0.4320538346966108} | train loss {'Reaction outcome loss': 0.24361515895123947, 'Total loss': 0.24361515895123947}
2023-01-04 23:23:57,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:57,096 INFO:     Epoch: 40
2023-01-04 23:23:59,327 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44649996757507326, 'Total loss': 0.44649996757507326} | train loss {'Reaction outcome loss': 0.23604883170864857, 'Total loss': 0.23604883170864857}
2023-01-04 23:23:59,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:23:59,327 INFO:     Epoch: 41
2023-01-04 23:24:01,614 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4467045346895854, 'Total loss': 0.4467045346895854} | train loss {'Reaction outcome loss': 0.23529105289882915, 'Total loss': 0.23529105289882915}
2023-01-04 23:24:01,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:01,615 INFO:     Epoch: 42
2023-01-04 23:24:03,917 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45494600931803386, 'Total loss': 0.45494600931803386} | train loss {'Reaction outcome loss': 0.23843737328525916, 'Total loss': 0.23843737328525916}
2023-01-04 23:24:03,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:03,917 INFO:     Epoch: 43
2023-01-04 23:24:06,233 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4622491767009099, 'Total loss': 0.4622491767009099} | train loss {'Reaction outcome loss': 0.23540922468158312, 'Total loss': 0.23540922468158312}
2023-01-04 23:24:06,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:06,233 INFO:     Epoch: 44
2023-01-04 23:24:08,484 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47684189875920613, 'Total loss': 0.47684189875920613} | train loss {'Reaction outcome loss': 0.23053681149083569, 'Total loss': 0.23053681149083569}
2023-01-04 23:24:08,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:08,484 INFO:     Epoch: 45
2023-01-04 23:24:10,699 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4498711923758189, 'Total loss': 0.4498711923758189} | train loss {'Reaction outcome loss': 0.22733349282469345, 'Total loss': 0.22733349282469345}
2023-01-04 23:24:10,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:10,700 INFO:     Epoch: 46
2023-01-04 23:24:12,939 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4486814608176549, 'Total loss': 0.4486814608176549} | train loss {'Reaction outcome loss': 0.22185167323273441, 'Total loss': 0.22185167323273441}
2023-01-04 23:24:12,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:12,940 INFO:     Epoch: 47
2023-01-04 23:24:15,169 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4741340190172195, 'Total loss': 0.4741340190172195} | train loss {'Reaction outcome loss': 0.21928046301800744, 'Total loss': 0.21928046301800744}
2023-01-04 23:24:15,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:15,169 INFO:     Epoch: 48
2023-01-04 23:24:17,440 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4542632708946864, 'Total loss': 0.4542632708946864} | train loss {'Reaction outcome loss': 0.21994279427218524, 'Total loss': 0.21994279427218524}
2023-01-04 23:24:17,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:17,442 INFO:     Epoch: 49
2023-01-04 23:24:19,769 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44759315152963003, 'Total loss': 0.44759315152963003} | train loss {'Reaction outcome loss': 0.2233553215430962, 'Total loss': 0.2233553215430962}
2023-01-04 23:24:19,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:19,770 INFO:     Epoch: 50
2023-01-04 23:24:22,078 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4658466021219889, 'Total loss': 0.4658466021219889} | train loss {'Reaction outcome loss': 0.21405946475450313, 'Total loss': 0.21405946475450313}
2023-01-04 23:24:22,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:22,079 INFO:     Epoch: 51
2023-01-04 23:24:24,366 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4499913493792216, 'Total loss': 0.4499913493792216} | train loss {'Reaction outcome loss': 0.2163711877788555, 'Total loss': 0.2163711877788555}
2023-01-04 23:24:24,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:24,367 INFO:     Epoch: 52
2023-01-04 23:24:26,635 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46377118676900864, 'Total loss': 0.46377118676900864} | train loss {'Reaction outcome loss': 0.21495801246714935, 'Total loss': 0.21495801246714935}
2023-01-04 23:24:26,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:26,635 INFO:     Epoch: 53
2023-01-04 23:24:28,906 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44069421887397764, 'Total loss': 0.44069421887397764} | train loss {'Reaction outcome loss': 0.2110788507255917, 'Total loss': 0.2110788507255917}
2023-01-04 23:24:28,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:28,906 INFO:     Epoch: 54
2023-01-04 23:24:31,122 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4624218148489793, 'Total loss': 0.4624218148489793} | train loss {'Reaction outcome loss': 0.2053270746654552, 'Total loss': 0.2053270746654552}
2023-01-04 23:24:31,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:31,122 INFO:     Epoch: 55
2023-01-04 23:24:33,391 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45008739332358044, 'Total loss': 0.45008739332358044} | train loss {'Reaction outcome loss': 0.20130008541296374, 'Total loss': 0.20130008541296374}
2023-01-04 23:24:33,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:33,391 INFO:     Epoch: 56
2023-01-04 23:24:35,618 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4477332999308904, 'Total loss': 0.4477332999308904} | train loss {'Reaction outcome loss': 0.20655223020496996, 'Total loss': 0.20655223020496996}
2023-01-04 23:24:35,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:35,618 INFO:     Epoch: 57
2023-01-04 23:24:37,881 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.49527015884717307, 'Total loss': 0.49527015884717307} | train loss {'Reaction outcome loss': 0.20311887853103103, 'Total loss': 0.20311887853103103}
2023-01-04 23:24:37,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:37,882 INFO:     Epoch: 58
2023-01-04 23:24:40,178 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4704579214255015, 'Total loss': 0.4704579214255015} | train loss {'Reaction outcome loss': 0.20492903005654522, 'Total loss': 0.20492903005654522}
2023-01-04 23:24:40,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:40,179 INFO:     Epoch: 59
2023-01-04 23:24:42,497 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4561981012423833, 'Total loss': 0.4561981012423833} | train loss {'Reaction outcome loss': 0.2027586187851289, 'Total loss': 0.2027586187851289}
2023-01-04 23:24:42,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:42,497 INFO:     Epoch: 60
2023-01-04 23:24:44,769 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4539203445116679, 'Total loss': 0.4539203445116679} | train loss {'Reaction outcome loss': 0.19849333817320824, 'Total loss': 0.19849333817320824}
2023-01-04 23:24:44,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:44,770 INFO:     Epoch: 61
2023-01-04 23:24:47,045 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47152416308720907, 'Total loss': 0.47152416308720907} | train loss {'Reaction outcome loss': 0.2017349033189487, 'Total loss': 0.2017349033189487}
2023-01-04 23:24:47,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:47,046 INFO:     Epoch: 62
2023-01-04 23:24:49,313 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4791700889666875, 'Total loss': 0.4791700889666875} | train loss {'Reaction outcome loss': 0.1989275666293335, 'Total loss': 0.1989275666293335}
2023-01-04 23:24:49,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:49,314 INFO:     Epoch: 63
2023-01-04 23:24:51,582 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47311321695645653, 'Total loss': 0.47311321695645653} | train loss {'Reaction outcome loss': 0.20691469690967554, 'Total loss': 0.20691469690967554}
2023-01-04 23:24:51,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:51,582 INFO:     Epoch: 64
2023-01-04 23:24:53,827 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47240935961405434, 'Total loss': 0.47240935961405434} | train loss {'Reaction outcome loss': 0.19524063400601438, 'Total loss': 0.19524063400601438}
2023-01-04 23:24:53,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:53,829 INFO:     Epoch: 65
2023-01-04 23:24:56,117 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4400781810283661, 'Total loss': 0.4400781810283661} | train loss {'Reaction outcome loss': 0.19648715897735597, 'Total loss': 0.19648715897735597}
2023-01-04 23:24:56,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:56,117 INFO:     Epoch: 66
2023-01-04 23:24:58,395 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4695383807023366, 'Total loss': 0.4695383807023366} | train loss {'Reaction outcome loss': 0.19975765587237498, 'Total loss': 0.19975765587237498}
2023-01-04 23:24:58,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:24:58,395 INFO:     Epoch: 67
2023-01-04 23:25:00,624 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4812110106150309, 'Total loss': 0.4812110106150309} | train loss {'Reaction outcome loss': 0.19357142958030213, 'Total loss': 0.19357142958030213}
2023-01-04 23:25:00,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:00,625 INFO:     Epoch: 68
2023-01-04 23:25:02,931 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46707086463769276, 'Total loss': 0.46707086463769276} | train loss {'Reaction outcome loss': 0.1927678274925435, 'Total loss': 0.1927678274925435}
2023-01-04 23:25:02,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:02,931 INFO:     Epoch: 69
2023-01-04 23:25:05,234 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4544309268395106, 'Total loss': 0.4544309268395106} | train loss {'Reaction outcome loss': 0.1909713379766402, 'Total loss': 0.1909713379766402}
2023-01-04 23:25:05,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:05,234 INFO:     Epoch: 70
2023-01-04 23:25:07,546 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4946425716082255, 'Total loss': 0.4946425716082255} | train loss {'Reaction outcome loss': 0.19003604975149088, 'Total loss': 0.19003604975149088}
2023-01-04 23:25:07,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:07,546 INFO:     Epoch: 71
2023-01-04 23:25:09,818 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45368781785170237, 'Total loss': 0.45368781785170237} | train loss {'Reaction outcome loss': 0.1883500635032189, 'Total loss': 0.1883500635032189}
2023-01-04 23:25:09,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:09,819 INFO:     Epoch: 72
2023-01-04 23:25:12,099 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4656770666440328, 'Total loss': 0.4656770666440328} | train loss {'Reaction outcome loss': 0.18623040737382504, 'Total loss': 0.18623040737382504}
2023-01-04 23:25:12,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:12,099 INFO:     Epoch: 73
2023-01-04 23:25:14,382 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46822360120713713, 'Total loss': 0.46822360120713713} | train loss {'Reaction outcome loss': 0.18853345014733205, 'Total loss': 0.18853345014733205}
2023-01-04 23:25:14,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:14,383 INFO:     Epoch: 74
2023-01-04 23:25:16,683 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4677694261074066, 'Total loss': 0.4677694261074066} | train loss {'Reaction outcome loss': 0.18958461927149162, 'Total loss': 0.18958461927149162}
2023-01-04 23:25:16,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:16,683 INFO:     Epoch: 75
2023-01-04 23:25:18,986 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4928350955247879, 'Total loss': 0.4928350955247879} | train loss {'Reaction outcome loss': 0.18192952885779987, 'Total loss': 0.18192952885779987}
2023-01-04 23:25:18,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:18,986 INFO:     Epoch: 76
2023-01-04 23:25:21,162 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48651241610447565, 'Total loss': 0.48651241610447565} | train loss {'Reaction outcome loss': 0.18654909157715335, 'Total loss': 0.18654909157715335}
2023-01-04 23:25:21,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:21,163 INFO:     Epoch: 77
2023-01-04 23:25:23,442 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4750005801518758, 'Total loss': 0.4750005801518758} | train loss {'Reaction outcome loss': 0.18655283000347095, 'Total loss': 0.18655283000347095}
2023-01-04 23:25:23,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:23,444 INFO:     Epoch: 78
2023-01-04 23:25:25,735 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5054896006981532, 'Total loss': 0.5054896006981532} | train loss {'Reaction outcome loss': 0.1820026783218829, 'Total loss': 0.1820026783218829}
2023-01-04 23:25:25,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:25,736 INFO:     Epoch: 79
2023-01-04 23:25:28,032 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4741297155618668, 'Total loss': 0.4741297155618668} | train loss {'Reaction outcome loss': 0.18185702122122532, 'Total loss': 0.18185702122122532}
2023-01-04 23:25:28,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:28,032 INFO:     Epoch: 80
2023-01-04 23:25:30,328 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4578692038853963, 'Total loss': 0.4578692038853963} | train loss {'Reaction outcome loss': 0.18348717345899837, 'Total loss': 0.18348717345899837}
2023-01-04 23:25:30,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:30,329 INFO:     Epoch: 81
2023-01-04 23:25:32,621 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47783849388360977, 'Total loss': 0.47783849388360977} | train loss {'Reaction outcome loss': 0.1847997863376883, 'Total loss': 0.1847997863376883}
2023-01-04 23:25:32,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:32,621 INFO:     Epoch: 82
2023-01-04 23:25:34,908 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5163602670033772, 'Total loss': 0.5163602670033772} | train loss {'Reaction outcome loss': 0.17917116663825533, 'Total loss': 0.17917116663825533}
2023-01-04 23:25:34,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:34,909 INFO:     Epoch: 83
2023-01-04 23:25:37,166 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4819430703918139, 'Total loss': 0.4819430703918139} | train loss {'Reaction outcome loss': 0.1807140000265374, 'Total loss': 0.1807140000265374}
2023-01-04 23:25:37,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:37,166 INFO:     Epoch: 84
2023-01-04 23:25:39,471 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4919595390558243, 'Total loss': 0.4919595390558243} | train loss {'Reaction outcome loss': 0.1799379102230099, 'Total loss': 0.1799379102230099}
2023-01-04 23:25:39,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:39,471 INFO:     Epoch: 85
2023-01-04 23:25:41,764 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4664676475028197, 'Total loss': 0.4664676475028197} | train loss {'Reaction outcome loss': 0.18350644011238745, 'Total loss': 0.18350644011238745}
2023-01-04 23:25:41,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:41,764 INFO:     Epoch: 86
2023-01-04 23:25:44,054 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46861465722322465, 'Total loss': 0.46861465722322465} | train loss {'Reaction outcome loss': 0.1785588967613876, 'Total loss': 0.1785588967613876}
2023-01-04 23:25:44,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:44,055 INFO:     Epoch: 87
2023-01-04 23:25:46,333 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4634279568990072, 'Total loss': 0.4634279568990072} | train loss {'Reaction outcome loss': 0.17483070987740712, 'Total loss': 0.17483070987740712}
2023-01-04 23:25:46,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:46,333 INFO:     Epoch: 88
2023-01-04 23:25:48,628 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4767390032609304, 'Total loss': 0.4767390032609304} | train loss {'Reaction outcome loss': 0.17877939161558767, 'Total loss': 0.17877939161558767}
2023-01-04 23:25:48,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:48,629 INFO:     Epoch: 89
2023-01-04 23:25:50,925 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49935654997825624, 'Total loss': 0.49935654997825624} | train loss {'Reaction outcome loss': 0.1764233386066712, 'Total loss': 0.1764233386066712}
2023-01-04 23:25:50,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:50,925 INFO:     Epoch: 90
2023-01-04 23:25:53,216 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49523348808288575, 'Total loss': 0.49523348808288575} | train loss {'Reaction outcome loss': 0.17508022971148687, 'Total loss': 0.17508022971148687}
2023-01-04 23:25:53,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:53,216 INFO:     Epoch: 91
2023-01-04 23:25:55,434 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.494657364487648, 'Total loss': 0.494657364487648} | train loss {'Reaction outcome loss': 0.1784573913844376, 'Total loss': 0.1784573913844376}
2023-01-04 23:25:55,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:55,434 INFO:     Epoch: 92
2023-01-04 23:25:57,712 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4819457213083903, 'Total loss': 0.4819457213083903} | train loss {'Reaction outcome loss': 0.17288152848467878, 'Total loss': 0.17288152848467878}
2023-01-04 23:25:57,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:57,713 INFO:     Epoch: 93
2023-01-04 23:25:59,944 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4853885809580485, 'Total loss': 0.4853885809580485} | train loss {'Reaction outcome loss': 0.1738440290762495, 'Total loss': 0.1738440290762495}
2023-01-04 23:25:59,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:25:59,945 INFO:     Epoch: 94
2023-01-04 23:26:02,195 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48729101022084553, 'Total loss': 0.48729101022084553} | train loss {'Reaction outcome loss': 0.1733321810430353, 'Total loss': 0.1733321810430353}
2023-01-04 23:26:02,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:02,196 INFO:     Epoch: 95
2023-01-04 23:26:04,474 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48687800069650017, 'Total loss': 0.48687800069650017} | train loss {'Reaction outcome loss': 0.1739110426711665, 'Total loss': 0.1739110426711665}
2023-01-04 23:26:04,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:04,474 INFO:     Epoch: 96
2023-01-04 23:26:06,729 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4640991985797882, 'Total loss': 0.4640991985797882} | train loss {'Reaction outcome loss': 0.17377810443781774, 'Total loss': 0.17377810443781774}
2023-01-04 23:26:06,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:06,730 INFO:     Epoch: 97
2023-01-04 23:26:09,007 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48407886624336244, 'Total loss': 0.48407886624336244} | train loss {'Reaction outcome loss': 0.17356330189275612, 'Total loss': 0.17356330189275612}
2023-01-04 23:26:09,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:09,007 INFO:     Epoch: 98
2023-01-04 23:26:11,359 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4916790227095286, 'Total loss': 0.4916790227095286} | train loss {'Reaction outcome loss': 0.17628741012516327, 'Total loss': 0.17628741012516327}
2023-01-04 23:26:11,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:11,359 INFO:     Epoch: 99
2023-01-04 23:26:13,666 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4858250518639882, 'Total loss': 0.4858250518639882} | train loss {'Reaction outcome loss': 0.17733308217666424, 'Total loss': 0.17733308217666424}
2023-01-04 23:26:13,666 INFO:     Best model found after epoch 30 of 100.
2023-01-04 23:26:13,666 INFO:   Done with stage: TRAINING
2023-01-04 23:26:13,666 INFO:   Starting stage: EVALUATION
2023-01-04 23:26:13,795 INFO:   Done with stage: EVALUATION
2023-01-04 23:26:13,795 INFO:   Leaving out SEQ value Fold_7
2023-01-04 23:26:13,808 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 23:26:13,808 INFO:   Starting stage: FEATURE SCALING
2023-01-04 23:26:14,457 INFO:   Done with stage: FEATURE SCALING
2023-01-04 23:26:14,457 INFO:   Starting stage: SCALING TARGETS
2023-01-04 23:26:14,527 INFO:   Done with stage: SCALING TARGETS
2023-01-04 23:26:14,528 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:26:14,528 INFO:     No hyperparam tuning for this model
2023-01-04 23:26:14,528 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:26:14,528 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 23:26:14,528 INFO:     None feature selector for col prot
2023-01-04 23:26:14,529 INFO:     None feature selector for col prot
2023-01-04 23:26:14,529 INFO:     None feature selector for col prot
2023-01-04 23:26:14,529 INFO:     None feature selector for col chem
2023-01-04 23:26:14,529 INFO:     None feature selector for col chem
2023-01-04 23:26:14,529 INFO:     None feature selector for col chem
2023-01-04 23:26:14,529 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 23:26:14,529 INFO:   Starting stage: BUILD MODEL
2023-01-04 23:26:14,532 INFO:     Number of params in model 72931
2023-01-04 23:26:14,535 INFO:   Done with stage: BUILD MODEL
2023-01-04 23:26:14,535 INFO:   Starting stage: TRAINING
2023-01-04 23:26:14,596 INFO:     Val loss before train {'Reaction outcome loss': 1.0874489863713583, 'Total loss': 1.0874489863713583}
2023-01-04 23:26:14,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:14,596 INFO:     Epoch: 0
2023-01-04 23:26:16,854 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9077630996704101, 'Total loss': 0.9077630996704101} | train loss {'Reaction outcome loss': 0.9795123275614133, 'Total loss': 0.9795123275614133}
2023-01-04 23:26:16,854 INFO:     Found new best model at epoch 0
2023-01-04 23:26:16,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:16,856 INFO:     Epoch: 1
2023-01-04 23:26:19,114 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5618566473325094, 'Total loss': 0.5618566473325094} | train loss {'Reaction outcome loss': 0.6896498458881448, 'Total loss': 0.6896498458881448}
2023-01-04 23:26:19,115 INFO:     Found new best model at epoch 1
2023-01-04 23:26:19,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:19,116 INFO:     Epoch: 2
2023-01-04 23:26:21,341 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49725107848644257, 'Total loss': 0.49725107848644257} | train loss {'Reaction outcome loss': 0.552354519330237, 'Total loss': 0.552354519330237}
2023-01-04 23:26:21,341 INFO:     Found new best model at epoch 2
2023-01-04 23:26:21,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:21,342 INFO:     Epoch: 3
2023-01-04 23:26:23,601 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4707077443599701, 'Total loss': 0.4707077443599701} | train loss {'Reaction outcome loss': 0.5077916202645232, 'Total loss': 0.5077916202645232}
2023-01-04 23:26:23,601 INFO:     Found new best model at epoch 3
2023-01-04 23:26:23,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:23,603 INFO:     Epoch: 4
2023-01-04 23:26:25,856 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4557168687383334, 'Total loss': 0.4557168687383334} | train loss {'Reaction outcome loss': 0.47740866635402623, 'Total loss': 0.47740866635402623}
2023-01-04 23:26:25,856 INFO:     Found new best model at epoch 4
2023-01-04 23:26:25,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:25,857 INFO:     Epoch: 5
2023-01-04 23:26:28,121 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4352245231469472, 'Total loss': 0.4352245231469472} | train loss {'Reaction outcome loss': 0.4630532144521275, 'Total loss': 0.4630532144521275}
2023-01-04 23:26:28,121 INFO:     Found new best model at epoch 5
2023-01-04 23:26:28,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:28,123 INFO:     Epoch: 6
2023-01-04 23:26:30,366 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42533968985080717, 'Total loss': 0.42533968985080717} | train loss {'Reaction outcome loss': 0.4456353271855925, 'Total loss': 0.4456353271855925}
2023-01-04 23:26:30,367 INFO:     Found new best model at epoch 6
2023-01-04 23:26:30,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:30,368 INFO:     Epoch: 7
2023-01-04 23:26:32,611 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4209741443395615, 'Total loss': 0.4209741443395615} | train loss {'Reaction outcome loss': 0.4321100772732366, 'Total loss': 0.4321100772732366}
2023-01-04 23:26:32,611 INFO:     Found new best model at epoch 7
2023-01-04 23:26:32,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:32,612 INFO:     Epoch: 8
2023-01-04 23:26:34,855 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4247999956210454, 'Total loss': 0.4247999956210454} | train loss {'Reaction outcome loss': 0.4196011823785566, 'Total loss': 0.4196011823785566}
2023-01-04 23:26:34,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:34,856 INFO:     Epoch: 9
2023-01-04 23:26:37,035 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4166963736216227, 'Total loss': 0.4166963736216227} | train loss {'Reaction outcome loss': 0.4101668593004672, 'Total loss': 0.4101668593004672}
2023-01-04 23:26:37,035 INFO:     Found new best model at epoch 9
2023-01-04 23:26:37,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:37,037 INFO:     Epoch: 10
2023-01-04 23:26:39,292 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4101716369390488, 'Total loss': 0.4101716369390488} | train loss {'Reaction outcome loss': 0.4027373101698221, 'Total loss': 0.4027373101698221}
2023-01-04 23:26:39,293 INFO:     Found new best model at epoch 10
2023-01-04 23:26:39,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:39,294 INFO:     Epoch: 11
2023-01-04 23:26:41,556 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4203737547000249, 'Total loss': 0.4203737547000249} | train loss {'Reaction outcome loss': 0.39225318905537143, 'Total loss': 0.39225318905537143}
2023-01-04 23:26:41,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:41,557 INFO:     Epoch: 12
2023-01-04 23:26:43,805 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3843912015358607, 'Total loss': 0.3843912015358607} | train loss {'Reaction outcome loss': 0.3851288515449005, 'Total loss': 0.3851288515449005}
2023-01-04 23:26:43,806 INFO:     Found new best model at epoch 12
2023-01-04 23:26:43,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:43,807 INFO:     Epoch: 13
2023-01-04 23:26:46,068 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.38834849148988726, 'Total loss': 0.38834849148988726} | train loss {'Reaction outcome loss': 0.3731716257540414, 'Total loss': 0.3731716257540414}
2023-01-04 23:26:46,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:46,068 INFO:     Epoch: 14
2023-01-04 23:26:48,308 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4079307953516642, 'Total loss': 0.4079307953516642} | train loss {'Reaction outcome loss': 0.3672121202260473, 'Total loss': 0.3672121202260473}
2023-01-04 23:26:48,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:48,308 INFO:     Epoch: 15
2023-01-04 23:26:50,547 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4211643854777018, 'Total loss': 0.4211643854777018} | train loss {'Reaction outcome loss': 0.3580012795970823, 'Total loss': 0.3580012795970823}
2023-01-04 23:26:50,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:50,548 INFO:     Epoch: 16
2023-01-04 23:26:52,774 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40934446156024934, 'Total loss': 0.40934446156024934} | train loss {'Reaction outcome loss': 0.35446637262501857, 'Total loss': 0.35446637262501857}
2023-01-04 23:26:52,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:52,775 INFO:     Epoch: 17
2023-01-04 23:26:54,995 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3879961669445038, 'Total loss': 0.3879961669445038} | train loss {'Reaction outcome loss': 0.34616480573304814, 'Total loss': 0.34616480573304814}
2023-01-04 23:26:54,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:54,996 INFO:     Epoch: 18
2023-01-04 23:26:57,213 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3907658219337463, 'Total loss': 0.3907658219337463} | train loss {'Reaction outcome loss': 0.34102218723210104, 'Total loss': 0.34102218723210104}
2023-01-04 23:26:57,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:57,213 INFO:     Epoch: 19
2023-01-04 23:26:59,468 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3950527548789978, 'Total loss': 0.3950527548789978} | train loss {'Reaction outcome loss': 0.3347522577468007, 'Total loss': 0.3347522577468007}
2023-01-04 23:26:59,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:26:59,469 INFO:     Epoch: 20
2023-01-04 23:27:01,706 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40044650534788767, 'Total loss': 0.40044650534788767} | train loss {'Reaction outcome loss': 0.3241014748295076, 'Total loss': 0.3241014748295076}
2023-01-04 23:27:01,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:01,706 INFO:     Epoch: 21
2023-01-04 23:27:03,977 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.412690731883049, 'Total loss': 0.412690731883049} | train loss {'Reaction outcome loss': 0.31615597994005595, 'Total loss': 0.31615597994005595}
2023-01-04 23:27:03,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:03,977 INFO:     Epoch: 22
2023-01-04 23:27:06,231 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40527440905570983, 'Total loss': 0.40527440905570983} | train loss {'Reaction outcome loss': 0.3165292114590424, 'Total loss': 0.3165292114590424}
2023-01-04 23:27:06,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:06,231 INFO:     Epoch: 23
2023-01-04 23:27:08,453 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4084653774897257, 'Total loss': 0.4084653774897257} | train loss {'Reaction outcome loss': 0.3060964469247273, 'Total loss': 0.3060964469247273}
2023-01-04 23:27:08,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:08,453 INFO:     Epoch: 24
2023-01-04 23:27:10,676 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3885718961556753, 'Total loss': 0.3885718961556753} | train loss {'Reaction outcome loss': 0.30270522729541266, 'Total loss': 0.30270522729541266}
2023-01-04 23:27:10,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:10,678 INFO:     Epoch: 25
2023-01-04 23:27:12,907 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4127322264015675, 'Total loss': 0.4127322264015675} | train loss {'Reaction outcome loss': 0.29540913644498284, 'Total loss': 0.29540913644498284}
2023-01-04 23:27:12,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:12,907 INFO:     Epoch: 26
2023-01-04 23:27:15,156 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4255029777685801, 'Total loss': 0.4255029777685801} | train loss {'Reaction outcome loss': 0.28981707468085044, 'Total loss': 0.28981707468085044}
2023-01-04 23:27:15,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:15,156 INFO:     Epoch: 27
2023-01-04 23:27:17,390 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4074034800132116, 'Total loss': 0.4074034800132116} | train loss {'Reaction outcome loss': 0.28525092044886013, 'Total loss': 0.28525092044886013}
2023-01-04 23:27:17,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:17,391 INFO:     Epoch: 28
2023-01-04 23:27:19,529 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4109666089216868, 'Total loss': 0.4109666089216868} | train loss {'Reaction outcome loss': 0.28143623014436153, 'Total loss': 0.28143623014436153}
2023-01-04 23:27:19,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:19,529 INFO:     Epoch: 29
2023-01-04 23:27:21,671 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41588741143544516, 'Total loss': 0.41588741143544516} | train loss {'Reaction outcome loss': 0.28204004965505025, 'Total loss': 0.28204004965505025}
2023-01-04 23:27:21,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:21,671 INFO:     Epoch: 30
2023-01-04 23:27:23,851 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45695608059565224, 'Total loss': 0.45695608059565224} | train loss {'Reaction outcome loss': 0.27434252649817586, 'Total loss': 0.27434252649817586}
2023-01-04 23:27:23,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:23,851 INFO:     Epoch: 31
2023-01-04 23:27:26,107 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4028755242625872, 'Total loss': 0.4028755242625872} | train loss {'Reaction outcome loss': 0.2730633595237767, 'Total loss': 0.2730633595237767}
2023-01-04 23:27:26,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:26,107 INFO:     Epoch: 32
2023-01-04 23:27:28,364 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4153526842594147, 'Total loss': 0.4153526842594147} | train loss {'Reaction outcome loss': 0.26601532955456825, 'Total loss': 0.26601532955456825}
2023-01-04 23:27:28,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:28,364 INFO:     Epoch: 33
2023-01-04 23:27:30,546 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41914859612782795, 'Total loss': 0.41914859612782795} | train loss {'Reaction outcome loss': 0.2623225992994152, 'Total loss': 0.2623225992994152}
2023-01-04 23:27:30,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:30,547 INFO:     Epoch: 34
2023-01-04 23:27:32,778 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4029160941640536, 'Total loss': 0.4029160941640536} | train loss {'Reaction outcome loss': 0.2574713164260679, 'Total loss': 0.2574713164260679}
2023-01-04 23:27:32,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:32,779 INFO:     Epoch: 35
2023-01-04 23:27:35,019 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42534574270248415, 'Total loss': 0.42534574270248415} | train loss {'Reaction outcome loss': 0.2585656786351091, 'Total loss': 0.2585656786351091}
2023-01-04 23:27:35,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:35,019 INFO:     Epoch: 36
2023-01-04 23:27:37,295 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38766595820585886, 'Total loss': 0.38766595820585886} | train loss {'Reaction outcome loss': 0.25271735371627513, 'Total loss': 0.25271735371627513}
2023-01-04 23:27:37,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:37,296 INFO:     Epoch: 37
2023-01-04 23:27:39,555 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4752561906973521, 'Total loss': 0.4752561906973521} | train loss {'Reaction outcome loss': 0.25050270356183507, 'Total loss': 0.25050270356183507}
2023-01-04 23:27:39,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:39,555 INFO:     Epoch: 38
2023-01-04 23:27:41,795 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3991461033622424, 'Total loss': 0.3991461033622424} | train loss {'Reaction outcome loss': 0.24457950986595484, 'Total loss': 0.24457950986595484}
2023-01-04 23:27:41,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:41,796 INFO:     Epoch: 39
2023-01-04 23:27:44,004 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4019680107633273, 'Total loss': 0.4019680107633273} | train loss {'Reaction outcome loss': 0.24724053587411007, 'Total loss': 0.24724053587411007}
2023-01-04 23:27:44,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:44,004 INFO:     Epoch: 40
2023-01-04 23:27:46,244 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40973959267139437, 'Total loss': 0.40973959267139437} | train loss {'Reaction outcome loss': 0.2389842492195159, 'Total loss': 0.2389842492195159}
2023-01-04 23:27:46,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:46,245 INFO:     Epoch: 41
2023-01-04 23:27:48,500 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3972070515155792, 'Total loss': 0.3972070515155792} | train loss {'Reaction outcome loss': 0.24034317477137176, 'Total loss': 0.24034317477137176}
2023-01-04 23:27:48,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:48,500 INFO:     Epoch: 42
2023-01-04 23:27:50,752 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42792488634586334, 'Total loss': 0.42792488634586334} | train loss {'Reaction outcome loss': 0.2349990311139909, 'Total loss': 0.2349990311139909}
2023-01-04 23:27:50,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:50,753 INFO:     Epoch: 43
2023-01-04 23:27:52,998 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4134790221850077, 'Total loss': 0.4134790221850077} | train loss {'Reaction outcome loss': 0.2343629608899491, 'Total loss': 0.2343629608899491}
2023-01-04 23:27:52,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:52,999 INFO:     Epoch: 44
2023-01-04 23:27:55,201 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4243868221839269, 'Total loss': 0.4243868221839269} | train loss {'Reaction outcome loss': 0.22887521749022452, 'Total loss': 0.22887521749022452}
2023-01-04 23:27:55,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:55,201 INFO:     Epoch: 45
2023-01-04 23:27:57,462 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40260813816760976, 'Total loss': 0.40260813816760976} | train loss {'Reaction outcome loss': 0.23067429069647172, 'Total loss': 0.23067429069647172}
2023-01-04 23:27:57,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:57,462 INFO:     Epoch: 46
2023-01-04 23:27:59,732 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45139425893624624, 'Total loss': 0.45139425893624624} | train loss {'Reaction outcome loss': 0.22469365967260876, 'Total loss': 0.22469365967260876}
2023-01-04 23:27:59,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:27:59,732 INFO:     Epoch: 47
2023-01-04 23:28:01,969 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44773715535799663, 'Total loss': 0.44773715535799663} | train loss {'Reaction outcome loss': 0.21933378025984568, 'Total loss': 0.21933378025984568}
2023-01-04 23:28:01,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:01,969 INFO:     Epoch: 48
2023-01-04 23:28:04,206 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4443453053633372, 'Total loss': 0.4443453053633372} | train loss {'Reaction outcome loss': 0.2292060327858929, 'Total loss': 0.2292060327858929}
2023-01-04 23:28:04,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:04,206 INFO:     Epoch: 49
2023-01-04 23:28:06,400 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41664061645666756, 'Total loss': 0.41664061645666756} | train loss {'Reaction outcome loss': 0.21959105381116706, 'Total loss': 0.21959105381116706}
2023-01-04 23:28:06,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:06,401 INFO:     Epoch: 50
2023-01-04 23:28:08,665 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44732149243354796, 'Total loss': 0.44732149243354796} | train loss {'Reaction outcome loss': 0.2184506860310144, 'Total loss': 0.2184506860310144}
2023-01-04 23:28:08,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:08,666 INFO:     Epoch: 51
2023-01-04 23:28:10,924 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42371123532454175, 'Total loss': 0.42371123532454175} | train loss {'Reaction outcome loss': 0.21537399383424952, 'Total loss': 0.21537399383424952}
2023-01-04 23:28:10,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:10,924 INFO:     Epoch: 52
2023-01-04 23:28:13,183 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42755562042196593, 'Total loss': 0.42755562042196593} | train loss {'Reaction outcome loss': 0.2178766650970291, 'Total loss': 0.2178766650970291}
2023-01-04 23:28:13,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:13,183 INFO:     Epoch: 53
2023-01-04 23:28:15,426 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4379542301098506, 'Total loss': 0.4379542301098506} | train loss {'Reaction outcome loss': 0.2147068112245659, 'Total loss': 0.2147068112245659}
2023-01-04 23:28:15,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:15,426 INFO:     Epoch: 54
2023-01-04 23:28:17,606 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46826276381810505, 'Total loss': 0.46826276381810505} | train loss {'Reaction outcome loss': 0.21145031785415688, 'Total loss': 0.21145031785415688}
2023-01-04 23:28:17,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:17,606 INFO:     Epoch: 55
2023-01-04 23:28:19,833 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4651321589946747, 'Total loss': 0.4651321589946747} | train loss {'Reaction outcome loss': 0.21512392330506858, 'Total loss': 0.21512392330506858}
2023-01-04 23:28:19,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:19,833 INFO:     Epoch: 56
2023-01-04 23:28:22,077 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46168641448020936, 'Total loss': 0.46168641448020936} | train loss {'Reaction outcome loss': 0.20747698305079537, 'Total loss': 0.20747698305079537}
2023-01-04 23:28:22,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:22,078 INFO:     Epoch: 57
2023-01-04 23:28:24,300 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42861494024594626, 'Total loss': 0.42861494024594626} | train loss {'Reaction outcome loss': 0.20970629509810332, 'Total loss': 0.20970629509810332}
2023-01-04 23:28:24,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:24,300 INFO:     Epoch: 58
2023-01-04 23:28:26,528 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43730166951815286, 'Total loss': 0.43730166951815286} | train loss {'Reaction outcome loss': 0.2046491493688502, 'Total loss': 0.2046491493688502}
2023-01-04 23:28:26,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:26,528 INFO:     Epoch: 59
2023-01-04 23:28:28,794 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4176193714141846, 'Total loss': 0.4176193714141846} | train loss {'Reaction outcome loss': 0.20591722709215143, 'Total loss': 0.20591722709215143}
2023-01-04 23:28:28,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:28,795 INFO:     Epoch: 60
2023-01-04 23:28:31,016 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4047904888788859, 'Total loss': 0.4047904888788859} | train loss {'Reaction outcome loss': 0.2036960206409223, 'Total loss': 0.2036960206409223}
2023-01-04 23:28:31,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:31,016 INFO:     Epoch: 61
2023-01-04 23:28:33,281 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42801931500434875, 'Total loss': 0.42801931500434875} | train loss {'Reaction outcome loss': 0.20306777984012653, 'Total loss': 0.20306777984012653}
2023-01-04 23:28:33,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:33,282 INFO:     Epoch: 62
2023-01-04 23:28:35,488 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4230846703052521, 'Total loss': 0.4230846703052521} | train loss {'Reaction outcome loss': 0.20374753503944643, 'Total loss': 0.20374753503944643}
2023-01-04 23:28:35,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:35,488 INFO:     Epoch: 63
2023-01-04 23:28:37,739 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47396882573763527, 'Total loss': 0.47396882573763527} | train loss {'Reaction outcome loss': 0.19827141294283043, 'Total loss': 0.19827141294283043}
2023-01-04 23:28:37,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:37,739 INFO:     Epoch: 64
2023-01-04 23:28:40,001 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45970698396364845, 'Total loss': 0.45970698396364845} | train loss {'Reaction outcome loss': 0.2016752819245151, 'Total loss': 0.2016752819245151}
2023-01-04 23:28:40,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:40,002 INFO:     Epoch: 65
2023-01-04 23:28:42,237 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4304639607667923, 'Total loss': 0.4304639607667923} | train loss {'Reaction outcome loss': 0.2004193882763821, 'Total loss': 0.2004193882763821}
2023-01-04 23:28:42,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:42,238 INFO:     Epoch: 66
2023-01-04 23:28:44,501 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44908128182093304, 'Total loss': 0.44908128182093304} | train loss {'Reaction outcome loss': 0.19447646101420052, 'Total loss': 0.19447646101420052}
2023-01-04 23:28:44,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:44,502 INFO:     Epoch: 67
2023-01-04 23:28:46,779 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43343774129947027, 'Total loss': 0.43343774129947027} | train loss {'Reaction outcome loss': 0.198359258598682, 'Total loss': 0.198359258598682}
2023-01-04 23:28:46,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:46,779 INFO:     Epoch: 68
2023-01-04 23:28:49,025 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4404189815123876, 'Total loss': 0.4404189815123876} | train loss {'Reaction outcome loss': 0.2003068995804791, 'Total loss': 0.2003068995804791}
2023-01-04 23:28:49,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:49,025 INFO:     Epoch: 69
2023-01-04 23:28:51,279 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42613408863544466, 'Total loss': 0.42613408863544466} | train loss {'Reaction outcome loss': 0.1921233156403649, 'Total loss': 0.1921233156403649}
2023-01-04 23:28:51,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:51,280 INFO:     Epoch: 70
2023-01-04 23:28:53,510 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4382269084453583, 'Total loss': 0.4382269084453583} | train loss {'Reaction outcome loss': 0.19194271631307736, 'Total loss': 0.19194271631307736}
2023-01-04 23:28:53,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:53,511 INFO:     Epoch: 71
2023-01-04 23:28:55,764 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46712138255437213, 'Total loss': 0.46712138255437213} | train loss {'Reaction outcome loss': 0.1900816938234833, 'Total loss': 0.1900816938234833}
2023-01-04 23:28:55,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:55,765 INFO:     Epoch: 72
2023-01-04 23:28:58,012 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4461130981643995, 'Total loss': 0.4461130981643995} | train loss {'Reaction outcome loss': 0.19030700069614245, 'Total loss': 0.19030700069614245}
2023-01-04 23:28:58,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:28:58,013 INFO:     Epoch: 73
2023-01-04 23:29:00,180 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46883926590283714, 'Total loss': 0.46883926590283714} | train loss {'Reaction outcome loss': 0.19414519789513118, 'Total loss': 0.19414519789513118}
2023-01-04 23:29:00,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:00,180 INFO:     Epoch: 74
2023-01-04 23:29:02,445 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.459068954984347, 'Total loss': 0.459068954984347} | train loss {'Reaction outcome loss': 0.18883055290139286, 'Total loss': 0.18883055290139286}
2023-01-04 23:29:02,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:02,445 INFO:     Epoch: 75
2023-01-04 23:29:04,675 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40978765760858854, 'Total loss': 0.40978765760858854} | train loss {'Reaction outcome loss': 0.18795598673559452, 'Total loss': 0.18795598673559452}
2023-01-04 23:29:04,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:04,676 INFO:     Epoch: 76
2023-01-04 23:29:06,937 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4797350307305654, 'Total loss': 0.4797350307305654} | train loss {'Reaction outcome loss': 0.18351423425130872, 'Total loss': 0.18351423425130872}
2023-01-04 23:29:06,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:06,937 INFO:     Epoch: 77
2023-01-04 23:29:09,201 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4437447081009547, 'Total loss': 0.4437447081009547} | train loss {'Reaction outcome loss': 0.18874287973226042, 'Total loss': 0.18874287973226042}
2023-01-04 23:29:09,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:09,201 INFO:     Epoch: 78
2023-01-04 23:29:11,437 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4509861746802926, 'Total loss': 0.4509861746802926} | train loss {'Reaction outcome loss': 0.1866332879298482, 'Total loss': 0.1866332879298482}
2023-01-04 23:29:11,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:11,437 INFO:     Epoch: 79
2023-01-04 23:29:13,706 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45594608883063, 'Total loss': 0.45594608883063} | train loss {'Reaction outcome loss': 0.18930100379035855, 'Total loss': 0.18930100379035855}
2023-01-04 23:29:13,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:13,706 INFO:     Epoch: 80
2023-01-04 23:29:15,968 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4412034342686335, 'Total loss': 0.4412034342686335} | train loss {'Reaction outcome loss': 0.18522155899418533, 'Total loss': 0.18522155899418533}
2023-01-04 23:29:15,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:15,969 INFO:     Epoch: 81
2023-01-04 23:29:18,226 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47282064507404964, 'Total loss': 0.47282064507404964} | train loss {'Reaction outcome loss': 0.18462841567603777, 'Total loss': 0.18462841567603777}
2023-01-04 23:29:18,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:18,227 INFO:     Epoch: 82
2023-01-04 23:29:20,472 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4794378399848938, 'Total loss': 0.4794378399848938} | train loss {'Reaction outcome loss': 0.18070931980950608, 'Total loss': 0.18070931980950608}
2023-01-04 23:29:20,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:20,473 INFO:     Epoch: 83
2023-01-04 23:29:22,744 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4868078996737798, 'Total loss': 0.4868078996737798} | train loss {'Reaction outcome loss': 0.18630840912474878, 'Total loss': 0.18630840912474878}
2023-01-04 23:29:22,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:22,745 INFO:     Epoch: 84
2023-01-04 23:29:24,927 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4869863480329514, 'Total loss': 0.4869863480329514} | train loss {'Reaction outcome loss': 0.17991035173640307, 'Total loss': 0.17991035173640307}
2023-01-04 23:29:24,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:24,927 INFO:     Epoch: 85
2023-01-04 23:29:27,184 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42240533034006755, 'Total loss': 0.42240533034006755} | train loss {'Reaction outcome loss': 0.17921464243839175, 'Total loss': 0.17921464243839175}
2023-01-04 23:29:27,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:27,184 INFO:     Epoch: 86
2023-01-04 23:29:29,402 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4375506092173358, 'Total loss': 0.4375506092173358} | train loss {'Reaction outcome loss': 0.17450245446865412, 'Total loss': 0.17450245446865412}
2023-01-04 23:29:29,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:29,403 INFO:     Epoch: 87
2023-01-04 23:29:31,670 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44577717582384746, 'Total loss': 0.44577717582384746} | train loss {'Reaction outcome loss': 0.1822648536682428, 'Total loss': 0.1822648536682428}
2023-01-04 23:29:31,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:31,671 INFO:     Epoch: 88
2023-01-04 23:29:33,944 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4486651251713435, 'Total loss': 0.4486651251713435} | train loss {'Reaction outcome loss': 0.176327010375332, 'Total loss': 0.176327010375332}
2023-01-04 23:29:33,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:33,945 INFO:     Epoch: 89
2023-01-04 23:29:36,196 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4250309516986211, 'Total loss': 0.4250309516986211} | train loss {'Reaction outcome loss': 0.1814563382573317, 'Total loss': 0.1814563382573317}
2023-01-04 23:29:36,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:36,197 INFO:     Epoch: 90
2023-01-04 23:29:38,446 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5134589264790217, 'Total loss': 0.5134589264790217} | train loss {'Reaction outcome loss': 0.18460215247630474, 'Total loss': 0.18460215247630474}
2023-01-04 23:29:38,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:38,446 INFO:     Epoch: 91
2023-01-04 23:29:40,670 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44437433977921803, 'Total loss': 0.44437433977921803} | train loss {'Reaction outcome loss': 0.1785060999571706, 'Total loss': 0.1785060999571706}
2023-01-04 23:29:40,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:40,671 INFO:     Epoch: 92
2023-01-04 23:29:42,904 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4259549130996068, 'Total loss': 0.4259549130996068} | train loss {'Reaction outcome loss': 0.17501730730852288, 'Total loss': 0.17501730730852288}
2023-01-04 23:29:42,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:42,904 INFO:     Epoch: 93
2023-01-04 23:29:45,168 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43556834806998573, 'Total loss': 0.43556834806998573} | train loss {'Reaction outcome loss': 0.17371957352126602, 'Total loss': 0.17371957352126602}
2023-01-04 23:29:45,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:45,169 INFO:     Epoch: 94
2023-01-04 23:29:47,429 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.456241167585055, 'Total loss': 0.456241167585055} | train loss {'Reaction outcome loss': 0.17480009253796217, 'Total loss': 0.17480009253796217}
2023-01-04 23:29:47,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:47,429 INFO:     Epoch: 95
2023-01-04 23:29:49,622 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47087718496719994, 'Total loss': 0.47087718496719994} | train loss {'Reaction outcome loss': 0.17415983185858677, 'Total loss': 0.17415983185858677}
2023-01-04 23:29:49,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:49,622 INFO:     Epoch: 96
2023-01-04 23:29:51,868 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45715296069780986, 'Total loss': 0.45715296069780986} | train loss {'Reaction outcome loss': 0.17346885360022804, 'Total loss': 0.17346885360022804}
2023-01-04 23:29:51,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:51,869 INFO:     Epoch: 97
2023-01-04 23:29:54,153 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46404386858145397, 'Total loss': 0.46404386858145397} | train loss {'Reaction outcome loss': 0.17263106336089762, 'Total loss': 0.17263106336089762}
2023-01-04 23:29:54,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:54,154 INFO:     Epoch: 98
2023-01-04 23:29:56,444 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5031283418337504, 'Total loss': 0.5031283418337504} | train loss {'Reaction outcome loss': 0.17409009106345066, 'Total loss': 0.17409009106345066}
2023-01-04 23:29:56,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:56,444 INFO:     Epoch: 99
2023-01-04 23:29:58,732 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4642688790957133, 'Total loss': 0.4642688790957133} | train loss {'Reaction outcome loss': 0.1718143150839193, 'Total loss': 0.1718143150839193}
2023-01-04 23:29:58,732 INFO:     Best model found after epoch 13 of 100.
2023-01-04 23:29:58,732 INFO:   Done with stage: TRAINING
2023-01-04 23:29:58,732 INFO:   Starting stage: EVALUATION
2023-01-04 23:29:58,875 INFO:   Done with stage: EVALUATION
2023-01-04 23:29:58,875 INFO:   Leaving out SEQ value Fold_8
2023-01-04 23:29:58,888 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 23:29:58,888 INFO:   Starting stage: FEATURE SCALING
2023-01-04 23:29:59,555 INFO:   Done with stage: FEATURE SCALING
2023-01-04 23:29:59,555 INFO:   Starting stage: SCALING TARGETS
2023-01-04 23:29:59,627 INFO:   Done with stage: SCALING TARGETS
2023-01-04 23:29:59,627 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:29:59,627 INFO:     No hyperparam tuning for this model
2023-01-04 23:29:59,627 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:29:59,627 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 23:29:59,628 INFO:     None feature selector for col prot
2023-01-04 23:29:59,628 INFO:     None feature selector for col prot
2023-01-04 23:29:59,628 INFO:     None feature selector for col prot
2023-01-04 23:29:59,629 INFO:     None feature selector for col chem
2023-01-04 23:29:59,629 INFO:     None feature selector for col chem
2023-01-04 23:29:59,629 INFO:     None feature selector for col chem
2023-01-04 23:29:59,629 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 23:29:59,629 INFO:   Starting stage: BUILD MODEL
2023-01-04 23:29:59,630 INFO:     Number of params in model 72931
2023-01-04 23:29:59,634 INFO:   Done with stage: BUILD MODEL
2023-01-04 23:29:59,634 INFO:   Starting stage: TRAINING
2023-01-04 23:29:59,694 INFO:     Val loss before train {'Reaction outcome loss': 0.9286420424779256, 'Total loss': 0.9286420424779256}
2023-01-04 23:29:59,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:29:59,694 INFO:     Epoch: 0
2023-01-04 23:30:01,998 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.771179711818695, 'Total loss': 0.771179711818695} | train loss {'Reaction outcome loss': 0.9644227182822107, 'Total loss': 0.9644227182822107}
2023-01-04 23:30:01,998 INFO:     Found new best model at epoch 0
2023-01-04 23:30:01,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:01,999 INFO:     Epoch: 1
2023-01-04 23:30:04,261 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4993348260720571, 'Total loss': 0.4993348260720571} | train loss {'Reaction outcome loss': 0.6809445113911956, 'Total loss': 0.6809445113911956}
2023-01-04 23:30:04,261 INFO:     Found new best model at epoch 1
2023-01-04 23:30:04,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:04,262 INFO:     Epoch: 2
2023-01-04 23:30:06,557 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4664145747820536, 'Total loss': 0.4664145747820536} | train loss {'Reaction outcome loss': 0.5566571442013614, 'Total loss': 0.5566571442013614}
2023-01-04 23:30:06,558 INFO:     Found new best model at epoch 2
2023-01-04 23:30:06,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:06,559 INFO:     Epoch: 3
2023-01-04 23:30:08,856 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4377902994553248, 'Total loss': 0.4377902994553248} | train loss {'Reaction outcome loss': 0.5189633466276451, 'Total loss': 0.5189633466276451}
2023-01-04 23:30:08,856 INFO:     Found new best model at epoch 3
2023-01-04 23:30:08,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:08,857 INFO:     Epoch: 4
2023-01-04 23:30:11,125 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43684360682964324, 'Total loss': 0.43684360682964324} | train loss {'Reaction outcome loss': 0.48618047009306264, 'Total loss': 0.48618047009306264}
2023-01-04 23:30:11,127 INFO:     Found new best model at epoch 4
2023-01-04 23:30:11,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:11,128 INFO:     Epoch: 5
2023-01-04 23:30:13,398 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4120178093512853, 'Total loss': 0.4120178093512853} | train loss {'Reaction outcome loss': 0.46391224277471377, 'Total loss': 0.46391224277471377}
2023-01-04 23:30:13,398 INFO:     Found new best model at epoch 5
2023-01-04 23:30:13,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:13,400 INFO:     Epoch: 6
2023-01-04 23:30:15,634 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4116581012805303, 'Total loss': 0.4116581012805303} | train loss {'Reaction outcome loss': 0.44071440850569454, 'Total loss': 0.44071440850569454}
2023-01-04 23:30:15,634 INFO:     Found new best model at epoch 6
2023-01-04 23:30:15,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:15,635 INFO:     Epoch: 7
2023-01-04 23:30:17,834 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4001247058312098, 'Total loss': 0.4001247058312098} | train loss {'Reaction outcome loss': 0.42675448464572646, 'Total loss': 0.42675448464572646}
2023-01-04 23:30:17,835 INFO:     Found new best model at epoch 7
2023-01-04 23:30:17,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:17,836 INFO:     Epoch: 8
2023-01-04 23:30:20,100 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.39323177735010784, 'Total loss': 0.39323177735010784} | train loss {'Reaction outcome loss': 0.4105751001232368, 'Total loss': 0.4105751001232368}
2023-01-04 23:30:20,100 INFO:     Found new best model at epoch 8
2023-01-04 23:30:20,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:20,102 INFO:     Epoch: 9
2023-01-04 23:30:22,390 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3962304453055064, 'Total loss': 0.3962304453055064} | train loss {'Reaction outcome loss': 0.3954215982007636, 'Total loss': 0.3954215982007636}
2023-01-04 23:30:22,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:22,390 INFO:     Epoch: 10
2023-01-04 23:30:24,673 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39409133394559226, 'Total loss': 0.39409133394559226} | train loss {'Reaction outcome loss': 0.3871230366320386, 'Total loss': 0.3871230366320386}
2023-01-04 23:30:24,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:24,673 INFO:     Epoch: 11
2023-01-04 23:30:26,832 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4000294228394826, 'Total loss': 0.4000294228394826} | train loss {'Reaction outcome loss': 0.3715846353489569, 'Total loss': 0.3715846353489569}
2023-01-04 23:30:26,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:26,833 INFO:     Epoch: 12
2023-01-04 23:30:29,093 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4122663597265879, 'Total loss': 0.4122663597265879} | train loss {'Reaction outcome loss': 0.361216422829387, 'Total loss': 0.361216422829387}
2023-01-04 23:30:29,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:29,093 INFO:     Epoch: 13
2023-01-04 23:30:31,380 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41950943171977995, 'Total loss': 0.41950943171977995} | train loss {'Reaction outcome loss': 0.3583265888077688, 'Total loss': 0.3583265888077688}
2023-01-04 23:30:31,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:31,381 INFO:     Epoch: 14
2023-01-04 23:30:33,657 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40897912879784903, 'Total loss': 0.40897912879784903} | train loss {'Reaction outcome loss': 0.34714270670921793, 'Total loss': 0.34714270670921793}
2023-01-04 23:30:33,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:33,657 INFO:     Epoch: 15
2023-01-04 23:30:35,922 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4027097980181376, 'Total loss': 0.4027097980181376} | train loss {'Reaction outcome loss': 0.3330391479743517, 'Total loss': 0.3330391479743517}
2023-01-04 23:30:35,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:35,922 INFO:     Epoch: 16
2023-01-04 23:30:38,181 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4213121031721433, 'Total loss': 0.4213121031721433} | train loss {'Reaction outcome loss': 0.3350252206655831, 'Total loss': 0.3350252206655831}
2023-01-04 23:30:38,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:38,181 INFO:     Epoch: 17
2023-01-04 23:30:40,451 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42177408238252007, 'Total loss': 0.42177408238252007} | train loss {'Reaction outcome loss': 0.32350079994984915, 'Total loss': 0.32350079994984915}
2023-01-04 23:30:40,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:40,453 INFO:     Epoch: 18
2023-01-04 23:30:42,722 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4013698404033979, 'Total loss': 0.4013698404033979} | train loss {'Reaction outcome loss': 0.3182764148964994, 'Total loss': 0.3182764148964994}
2023-01-04 23:30:42,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:42,722 INFO:     Epoch: 19
2023-01-04 23:30:44,997 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4123350024223328, 'Total loss': 0.4123350024223328} | train loss {'Reaction outcome loss': 0.3109836417522671, 'Total loss': 0.3109836417522671}
2023-01-04 23:30:44,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:44,997 INFO:     Epoch: 20
2023-01-04 23:30:47,274 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4255721390247345, 'Total loss': 0.4255721390247345} | train loss {'Reaction outcome loss': 0.3086602197630526, 'Total loss': 0.3086602197630526}
2023-01-04 23:30:47,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:47,276 INFO:     Epoch: 21
2023-01-04 23:30:49,515 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4187788585821787, 'Total loss': 0.4187788585821787} | train loss {'Reaction outcome loss': 0.3039008331105167, 'Total loss': 0.3039008331105167}
2023-01-04 23:30:49,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:49,515 INFO:     Epoch: 22
2023-01-04 23:30:51,772 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4068668733040492, 'Total loss': 0.4068668733040492} | train loss {'Reaction outcome loss': 0.29849327707979223, 'Total loss': 0.29849327707979223}
2023-01-04 23:30:51,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:51,772 INFO:     Epoch: 23
2023-01-04 23:30:54,056 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44245516856511435, 'Total loss': 0.44245516856511435} | train loss {'Reaction outcome loss': 0.29242271190300745, 'Total loss': 0.29242271190300745}
2023-01-04 23:30:54,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:54,056 INFO:     Epoch: 24
2023-01-04 23:30:56,326 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.421622164050738, 'Total loss': 0.421622164050738} | train loss {'Reaction outcome loss': 0.28996213899407575, 'Total loss': 0.28996213899407575}
2023-01-04 23:30:56,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:56,326 INFO:     Epoch: 25
2023-01-04 23:30:58,579 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43637654185295105, 'Total loss': 0.43637654185295105} | train loss {'Reaction outcome loss': 0.2849652489600199, 'Total loss': 0.2849652489600199}
2023-01-04 23:30:58,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:30:58,580 INFO:     Epoch: 26
2023-01-04 23:31:00,838 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42217131753762566, 'Total loss': 0.42217131753762566} | train loss {'Reaction outcome loss': 0.28016281952335087, 'Total loss': 0.28016281952335087}
2023-01-04 23:31:00,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:00,840 INFO:     Epoch: 27
2023-01-04 23:31:03,101 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4112072149912516, 'Total loss': 0.4112072149912516} | train loss {'Reaction outcome loss': 0.27432630249443685, 'Total loss': 0.27432630249443685}
2023-01-04 23:31:03,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:03,101 INFO:     Epoch: 28
2023-01-04 23:31:05,383 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4525955359141032, 'Total loss': 0.4525955359141032} | train loss {'Reaction outcome loss': 0.26954728477241113, 'Total loss': 0.26954728477241113}
2023-01-04 23:31:05,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:05,384 INFO:     Epoch: 29
2023-01-04 23:31:07,654 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4189618428548177, 'Total loss': 0.4189618428548177} | train loss {'Reaction outcome loss': 0.2656238339168931, 'Total loss': 0.2656238339168931}
2023-01-04 23:31:07,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:07,654 INFO:     Epoch: 30
2023-01-04 23:31:09,938 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.427454266945521, 'Total loss': 0.427454266945521} | train loss {'Reaction outcome loss': 0.2694560270554753, 'Total loss': 0.2694560270554753}
2023-01-04 23:31:09,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:09,938 INFO:     Epoch: 31
2023-01-04 23:31:12,212 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42946228583653767, 'Total loss': 0.42946228583653767} | train loss {'Reaction outcome loss': 0.2556090514488276, 'Total loss': 0.2556090514488276}
2023-01-04 23:31:12,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:12,212 INFO:     Epoch: 32
2023-01-04 23:31:14,466 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4129423846801122, 'Total loss': 0.4129423846801122} | train loss {'Reaction outcome loss': 0.2561743093876417, 'Total loss': 0.2561743093876417}
2023-01-04 23:31:14,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:14,466 INFO:     Epoch: 33
2023-01-04 23:31:16,761 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4306349277496338, 'Total loss': 0.4306349277496338} | train loss {'Reaction outcome loss': 0.25133810849988075, 'Total loss': 0.25133810849988075}
2023-01-04 23:31:16,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:16,762 INFO:     Epoch: 34
2023-01-04 23:31:19,039 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41887307465076445, 'Total loss': 0.41887307465076445} | train loss {'Reaction outcome loss': 0.24897570606818697, 'Total loss': 0.24897570606818697}
2023-01-04 23:31:19,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:19,039 INFO:     Epoch: 35
2023-01-04 23:31:21,280 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4088935315608978, 'Total loss': 0.4088935315608978} | train loss {'Reaction outcome loss': 0.24901275549231883, 'Total loss': 0.24901275549231883}
2023-01-04 23:31:21,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:21,280 INFO:     Epoch: 36
2023-01-04 23:31:23,575 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42159107426802317, 'Total loss': 0.42159107426802317} | train loss {'Reaction outcome loss': 0.24631948014620408, 'Total loss': 0.24631948014620408}
2023-01-04 23:31:23,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:23,576 INFO:     Epoch: 37
2023-01-04 23:31:25,778 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41386279265085857, 'Total loss': 0.41386279265085857} | train loss {'Reaction outcome loss': 0.24039914251207659, 'Total loss': 0.24039914251207659}
2023-01-04 23:31:25,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:25,778 INFO:     Epoch: 38
2023-01-04 23:31:28,068 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42483429511388143, 'Total loss': 0.42483429511388143} | train loss {'Reaction outcome loss': 0.2402916415207868, 'Total loss': 0.2402916415207868}
2023-01-04 23:31:28,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:28,068 INFO:     Epoch: 39
2023-01-04 23:31:30,121 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4381862560908, 'Total loss': 0.4381862560908} | train loss {'Reaction outcome loss': 0.23156516354141038, 'Total loss': 0.23156516354141038}
2023-01-04 23:31:30,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:30,121 INFO:     Epoch: 40
2023-01-04 23:31:32,416 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4509492794672648, 'Total loss': 0.4509492794672648} | train loss {'Reaction outcome loss': 0.2301674102456561, 'Total loss': 0.2301674102456561}
2023-01-04 23:31:32,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:32,416 INFO:     Epoch: 41
2023-01-04 23:31:34,702 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4386195421218872, 'Total loss': 0.4386195421218872} | train loss {'Reaction outcome loss': 0.23183627091079198, 'Total loss': 0.23183627091079198}
2023-01-04 23:31:34,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:34,703 INFO:     Epoch: 42
2023-01-04 23:31:36,956 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44227377076943714, 'Total loss': 0.44227377076943714} | train loss {'Reaction outcome loss': 0.2253476158187923, 'Total loss': 0.2253476158187923}
2023-01-04 23:31:36,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:36,957 INFO:     Epoch: 43
2023-01-04 23:31:39,143 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4224743644396464, 'Total loss': 0.4224743644396464} | train loss {'Reaction outcome loss': 0.22475332597990114, 'Total loss': 0.22475332597990114}
2023-01-04 23:31:39,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:39,143 INFO:     Epoch: 44
2023-01-04 23:31:41,382 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4427175571521123, 'Total loss': 0.4427175571521123} | train loss {'Reaction outcome loss': 0.22112744344593385, 'Total loss': 0.22112744344593385}
2023-01-04 23:31:41,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:41,383 INFO:     Epoch: 45
2023-01-04 23:31:43,691 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42764368851979573, 'Total loss': 0.42764368851979573} | train loss {'Reaction outcome loss': 0.22156799357680315, 'Total loss': 0.22156799357680315}
2023-01-04 23:31:43,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:43,692 INFO:     Epoch: 46
2023-01-04 23:31:45,937 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42596299449602765, 'Total loss': 0.42596299449602765} | train loss {'Reaction outcome loss': 0.22347529054642906, 'Total loss': 0.22347529054642906}
2023-01-04 23:31:45,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:45,937 INFO:     Epoch: 47
2023-01-04 23:31:48,216 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44359906713167824, 'Total loss': 0.44359906713167824} | train loss {'Reaction outcome loss': 0.21420038691536936, 'Total loss': 0.21420038691536936}
2023-01-04 23:31:48,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:48,217 INFO:     Epoch: 48
2023-01-04 23:31:50,495 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41838558415571847, 'Total loss': 0.41838558415571847} | train loss {'Reaction outcome loss': 0.21823349106209589, 'Total loss': 0.21823349106209589}
2023-01-04 23:31:50,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:50,495 INFO:     Epoch: 49
2023-01-04 23:31:52,794 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4430042246977488, 'Total loss': 0.4430042246977488} | train loss {'Reaction outcome loss': 0.2113501549822813, 'Total loss': 0.2113501549822813}
2023-01-04 23:31:52,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:52,795 INFO:     Epoch: 50
2023-01-04 23:31:55,082 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4367491553227107, 'Total loss': 0.4367491553227107} | train loss {'Reaction outcome loss': 0.21509602188136065, 'Total loss': 0.21509602188136065}
2023-01-04 23:31:55,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:55,082 INFO:     Epoch: 51
2023-01-04 23:31:57,382 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4452757020791372, 'Total loss': 0.4452757020791372} | train loss {'Reaction outcome loss': 0.2065747574657632, 'Total loss': 0.2065747574657632}
2023-01-04 23:31:57,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:57,382 INFO:     Epoch: 52
2023-01-04 23:31:59,663 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42331402798493706, 'Total loss': 0.42331402798493706} | train loss {'Reaction outcome loss': 0.2024966230622698, 'Total loss': 0.2024966230622698}
2023-01-04 23:31:59,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:31:59,664 INFO:     Epoch: 53
2023-01-04 23:32:01,939 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4675237168868383, 'Total loss': 0.4675237168868383} | train loss {'Reaction outcome loss': 0.20761035546989917, 'Total loss': 0.20761035546989917}
2023-01-04 23:32:01,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:01,939 INFO:     Epoch: 54
2023-01-04 23:32:04,201 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42830393811066947, 'Total loss': 0.42830393811066947} | train loss {'Reaction outcome loss': 0.20667322773809144, 'Total loss': 0.20667322773809144}
2023-01-04 23:32:04,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:04,202 INFO:     Epoch: 55
2023-01-04 23:32:06,499 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4424260174234708, 'Total loss': 0.4424260174234708} | train loss {'Reaction outcome loss': 0.2022708803617029, 'Total loss': 0.2022708803617029}
2023-01-04 23:32:06,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:06,499 INFO:     Epoch: 56
2023-01-04 23:32:08,791 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4445684323708216, 'Total loss': 0.4445684323708216} | train loss {'Reaction outcome loss': 0.20293625353395078, 'Total loss': 0.20293625353395078}
2023-01-04 23:32:08,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:08,791 INFO:     Epoch: 57
2023-01-04 23:32:11,079 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4453226675589879, 'Total loss': 0.4453226675589879} | train loss {'Reaction outcome loss': 0.1989311925959286, 'Total loss': 0.1989311925959286}
2023-01-04 23:32:11,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:11,079 INFO:     Epoch: 58
2023-01-04 23:32:13,323 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44815719276666643, 'Total loss': 0.44815719276666643} | train loss {'Reaction outcome loss': 0.1976928847912524, 'Total loss': 0.1976928847912524}
2023-01-04 23:32:13,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:13,324 INFO:     Epoch: 59
2023-01-04 23:32:15,572 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45969968537489575, 'Total loss': 0.45969968537489575} | train loss {'Reaction outcome loss': 0.19788028400337546, 'Total loss': 0.19788028400337546}
2023-01-04 23:32:15,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:15,572 INFO:     Epoch: 60
2023-01-04 23:32:17,818 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4531656374533971, 'Total loss': 0.4531656374533971} | train loss {'Reaction outcome loss': 0.19134070943126502, 'Total loss': 0.19134070943126502}
2023-01-04 23:32:17,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:17,819 INFO:     Epoch: 61
2023-01-04 23:32:20,108 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4337951252857844, 'Total loss': 0.4337951252857844} | train loss {'Reaction outcome loss': 0.19317055008767528, 'Total loss': 0.19317055008767528}
2023-01-04 23:32:20,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:20,108 INFO:     Epoch: 62
2023-01-04 23:32:22,327 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4402519812186559, 'Total loss': 0.4402519812186559} | train loss {'Reaction outcome loss': 0.18857876708250265, 'Total loss': 0.18857876708250265}
2023-01-04 23:32:22,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:22,327 INFO:     Epoch: 63
2023-01-04 23:32:24,539 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45375174582004546, 'Total loss': 0.45375174582004546} | train loss {'Reaction outcome loss': 0.19149052639851608, 'Total loss': 0.19149052639851608}
2023-01-04 23:32:24,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:24,540 INFO:     Epoch: 64
2023-01-04 23:32:26,831 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43189971645673114, 'Total loss': 0.43189971645673114} | train loss {'Reaction outcome loss': 0.19052607620585482, 'Total loss': 0.19052607620585482}
2023-01-04 23:32:26,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:26,832 INFO:     Epoch: 65
2023-01-04 23:32:29,134 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41150530576705935, 'Total loss': 0.41150530576705935} | train loss {'Reaction outcome loss': 0.18748428862515015, 'Total loss': 0.18748428862515015}
2023-01-04 23:32:29,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:29,135 INFO:     Epoch: 66
2023-01-04 23:32:31,385 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44848055243492124, 'Total loss': 0.44848055243492124} | train loss {'Reaction outcome loss': 0.19064761339165673, 'Total loss': 0.19064761339165673}
2023-01-04 23:32:31,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:31,385 INFO:     Epoch: 67
2023-01-04 23:32:33,616 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4346641167998314, 'Total loss': 0.4346641167998314} | train loss {'Reaction outcome loss': 0.1823990633408623, 'Total loss': 0.1823990633408623}
2023-01-04 23:32:33,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:33,616 INFO:     Epoch: 68
2023-01-04 23:32:35,861 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4466608812411626, 'Total loss': 0.4466608812411626} | train loss {'Reaction outcome loss': 0.18520889171678237, 'Total loss': 0.18520889171678237}
2023-01-04 23:32:35,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:35,862 INFO:     Epoch: 69
2023-01-04 23:32:38,146 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4185851444800695, 'Total loss': 0.4185851444800695} | train loss {'Reaction outcome loss': 0.18009626789569907, 'Total loss': 0.18009626789569907}
2023-01-04 23:32:38,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:38,147 INFO:     Epoch: 70
2023-01-04 23:32:40,417 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4601764718691508, 'Total loss': 0.4601764718691508} | train loss {'Reaction outcome loss': 0.18302268648540285, 'Total loss': 0.18302268648540285}
2023-01-04 23:32:40,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:40,417 INFO:     Epoch: 71
2023-01-04 23:32:42,608 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4511838396390279, 'Total loss': 0.4511838396390279} | train loss {'Reaction outcome loss': 0.18481509039003657, 'Total loss': 0.18481509039003657}
2023-01-04 23:32:42,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:42,608 INFO:     Epoch: 72
2023-01-04 23:32:44,875 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43054593404134117, 'Total loss': 0.43054593404134117} | train loss {'Reaction outcome loss': 0.17680428949409982, 'Total loss': 0.17680428949409982}
2023-01-04 23:32:44,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:44,875 INFO:     Epoch: 73
2023-01-04 23:32:47,146 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44377549091974894, 'Total loss': 0.44377549091974894} | train loss {'Reaction outcome loss': 0.17715070758263718, 'Total loss': 0.17715070758263718}
2023-01-04 23:32:47,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:47,146 INFO:     Epoch: 74
2023-01-04 23:32:49,317 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4322692359487216, 'Total loss': 0.4322692359487216} | train loss {'Reaction outcome loss': 0.17907290965560757, 'Total loss': 0.17907290965560757}
2023-01-04 23:32:49,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:49,318 INFO:     Epoch: 75
2023-01-04 23:32:51,605 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41735878586769104, 'Total loss': 0.41735878586769104} | train loss {'Reaction outcome loss': 0.17724721263152704, 'Total loss': 0.17724721263152704}
2023-01-04 23:32:51,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:51,605 INFO:     Epoch: 76
2023-01-04 23:32:53,890 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4482588847478231, 'Total loss': 0.4482588847478231} | train loss {'Reaction outcome loss': 0.17392049121606543, 'Total loss': 0.17392049121606543}
2023-01-04 23:32:53,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:53,891 INFO:     Epoch: 77
2023-01-04 23:32:56,180 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4494068215290705, 'Total loss': 0.4494068215290705} | train loss {'Reaction outcome loss': 0.1743316048527614, 'Total loss': 0.1743316048527614}
2023-01-04 23:32:56,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:56,180 INFO:     Epoch: 78
2023-01-04 23:32:58,432 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41633730890850223, 'Total loss': 0.41633730890850223} | train loss {'Reaction outcome loss': 0.17373484807821926, 'Total loss': 0.17373484807821926}
2023-01-04 23:32:58,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:32:58,432 INFO:     Epoch: 79
2023-01-04 23:33:00,668 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46229682366053265, 'Total loss': 0.46229682366053265} | train loss {'Reaction outcome loss': 0.17983798204924548, 'Total loss': 0.17983798204924548}
2023-01-04 23:33:00,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:00,668 INFO:     Epoch: 80
2023-01-04 23:33:02,956 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43986955682436624, 'Total loss': 0.43986955682436624} | train loss {'Reaction outcome loss': 0.17075729315649946, 'Total loss': 0.17075729315649946}
2023-01-04 23:33:02,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:02,956 INFO:     Epoch: 81
2023-01-04 23:33:05,252 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4299020995696386, 'Total loss': 0.4299020995696386} | train loss {'Reaction outcome loss': 0.17367124548753463, 'Total loss': 0.17367124548753463}
2023-01-04 23:33:05,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:05,254 INFO:     Epoch: 82
2023-01-04 23:33:07,543 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.439093225200971, 'Total loss': 0.439093225200971} | train loss {'Reaction outcome loss': 0.17077299676136204, 'Total loss': 0.17077299676136204}
2023-01-04 23:33:07,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:07,543 INFO:     Epoch: 83
2023-01-04 23:33:09,816 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.441228977839152, 'Total loss': 0.441228977839152} | train loss {'Reaction outcome loss': 0.17188670614478765, 'Total loss': 0.17188670614478765}
2023-01-04 23:33:09,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:09,816 INFO:     Epoch: 84
2023-01-04 23:33:12,079 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45067488054434457, 'Total loss': 0.45067488054434457} | train loss {'Reaction outcome loss': 0.1696975368078435, 'Total loss': 0.1696975368078435}
2023-01-04 23:33:12,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:12,080 INFO:     Epoch: 85
2023-01-04 23:33:14,359 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46681420703728993, 'Total loss': 0.46681420703728993} | train loss {'Reaction outcome loss': 0.1710188994385867, 'Total loss': 0.1710188994385867}
2023-01-04 23:33:14,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:14,360 INFO:     Epoch: 86
2023-01-04 23:33:16,643 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44780363937218987, 'Total loss': 0.44780363937218987} | train loss {'Reaction outcome loss': 0.1675213262075659, 'Total loss': 0.1675213262075659}
2023-01-04 23:33:16,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:16,643 INFO:     Epoch: 87
2023-01-04 23:33:18,866 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4541920244693756, 'Total loss': 0.4541920244693756} | train loss {'Reaction outcome loss': 0.16430248765590927, 'Total loss': 0.16430248765590927}
2023-01-04 23:33:18,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:18,866 INFO:     Epoch: 88
2023-01-04 23:33:21,109 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45253178626298907, 'Total loss': 0.45253178626298907} | train loss {'Reaction outcome loss': 0.16906078693386342, 'Total loss': 0.16906078693386342}
2023-01-04 23:33:21,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:21,109 INFO:     Epoch: 89
2023-01-04 23:33:23,388 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4411977991461754, 'Total loss': 0.4411977991461754} | train loss {'Reaction outcome loss': 0.16416497108953523, 'Total loss': 0.16416497108953523}
2023-01-04 23:33:23,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:23,388 INFO:     Epoch: 90
2023-01-04 23:33:25,674 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45441068559885023, 'Total loss': 0.45441068559885023} | train loss {'Reaction outcome loss': 0.16599229487610664, 'Total loss': 0.16599229487610664}
2023-01-04 23:33:25,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:25,675 INFO:     Epoch: 91
2023-01-04 23:33:27,928 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41941918184359867, 'Total loss': 0.41941918184359867} | train loss {'Reaction outcome loss': 0.1635678319684112, 'Total loss': 0.1635678319684112}
2023-01-04 23:33:27,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:27,929 INFO:     Epoch: 92
2023-01-04 23:33:30,218 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4262709190448125, 'Total loss': 0.4262709190448125} | train loss {'Reaction outcome loss': 0.16811516033888993, 'Total loss': 0.16811516033888993}
2023-01-04 23:33:30,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:30,218 INFO:     Epoch: 93
2023-01-04 23:33:32,396 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4726357618967692, 'Total loss': 0.4726357618967692} | train loss {'Reaction outcome loss': 0.16466980722114202, 'Total loss': 0.16466980722114202}
2023-01-04 23:33:32,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:32,396 INFO:     Epoch: 94
2023-01-04 23:33:34,680 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4251916453242302, 'Total loss': 0.4251916453242302} | train loss {'Reaction outcome loss': 0.1642099259007682, 'Total loss': 0.1642099259007682}
2023-01-04 23:33:34,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:34,681 INFO:     Epoch: 95
2023-01-04 23:33:36,963 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4240863045056661, 'Total loss': 0.4240863045056661} | train loss {'Reaction outcome loss': 0.16427463499176911, 'Total loss': 0.16427463499176911}
2023-01-04 23:33:36,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:36,964 INFO:     Epoch: 96
2023-01-04 23:33:39,265 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45988230804602304, 'Total loss': 0.45988230804602304} | train loss {'Reaction outcome loss': 0.16540613431577647, 'Total loss': 0.16540613431577647}
2023-01-04 23:33:39,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:39,265 INFO:     Epoch: 97
2023-01-04 23:33:41,570 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4237541069587072, 'Total loss': 0.4237541069587072} | train loss {'Reaction outcome loss': 0.16116594911354598, 'Total loss': 0.16116594911354598}
2023-01-04 23:33:41,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:41,571 INFO:     Epoch: 98
2023-01-04 23:33:43,820 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4463736802339554, 'Total loss': 0.4463736802339554} | train loss {'Reaction outcome loss': 0.16319138728525986, 'Total loss': 0.16319138728525986}
2023-01-04 23:33:43,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:43,820 INFO:     Epoch: 99
2023-01-04 23:33:46,032 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4449940323829651, 'Total loss': 0.4449940323829651} | train loss {'Reaction outcome loss': 0.15847233370020447, 'Total loss': 0.15847233370020447}
2023-01-04 23:33:46,032 INFO:     Best model found after epoch 9 of 100.
2023-01-04 23:33:46,032 INFO:   Done with stage: TRAINING
2023-01-04 23:33:46,032 INFO:   Starting stage: EVALUATION
2023-01-04 23:33:46,161 INFO:   Done with stage: EVALUATION
2023-01-04 23:33:46,161 INFO:   Leaving out SEQ value Fold_9
2023-01-04 23:33:46,174 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 23:33:46,174 INFO:   Starting stage: FEATURE SCALING
2023-01-04 23:33:46,830 INFO:   Done with stage: FEATURE SCALING
2023-01-04 23:33:46,830 INFO:   Starting stage: SCALING TARGETS
2023-01-04 23:33:46,901 INFO:   Done with stage: SCALING TARGETS
2023-01-04 23:33:46,901 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:33:46,901 INFO:     No hyperparam tuning for this model
2023-01-04 23:33:46,901 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:33:46,901 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 23:33:46,902 INFO:     None feature selector for col prot
2023-01-04 23:33:46,902 INFO:     None feature selector for col prot
2023-01-04 23:33:46,902 INFO:     None feature selector for col prot
2023-01-04 23:33:46,903 INFO:     None feature selector for col chem
2023-01-04 23:33:46,903 INFO:     None feature selector for col chem
2023-01-04 23:33:46,903 INFO:     None feature selector for col chem
2023-01-04 23:33:46,903 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 23:33:46,903 INFO:   Starting stage: BUILD MODEL
2023-01-04 23:33:46,905 INFO:     Number of params in model 72931
2023-01-04 23:33:46,908 INFO:   Done with stage: BUILD MODEL
2023-01-04 23:33:46,908 INFO:   Starting stage: TRAINING
2023-01-04 23:33:46,968 INFO:     Val loss before train {'Reaction outcome loss': 0.9583163817723592, 'Total loss': 0.9583163817723592}
2023-01-04 23:33:46,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:46,968 INFO:     Epoch: 0
2023-01-04 23:33:49,245 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7582942883173625, 'Total loss': 0.7582942883173625} | train loss {'Reaction outcome loss': 0.9386268245677153, 'Total loss': 0.9386268245677153}
2023-01-04 23:33:49,245 INFO:     Found new best model at epoch 0
2023-01-04 23:33:49,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:49,247 INFO:     Epoch: 1
2023-01-04 23:33:51,534 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5869200348854064, 'Total loss': 0.5869200348854064} | train loss {'Reaction outcome loss': 0.6378595675198375, 'Total loss': 0.6378595675198375}
2023-01-04 23:33:51,534 INFO:     Found new best model at epoch 1
2023-01-04 23:33:51,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:51,536 INFO:     Epoch: 2
2023-01-04 23:33:53,823 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5323188602924347, 'Total loss': 0.5323188602924347} | train loss {'Reaction outcome loss': 0.5359954432638335, 'Total loss': 0.5359954432638335}
2023-01-04 23:33:53,824 INFO:     Found new best model at epoch 2
2023-01-04 23:33:53,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:53,826 INFO:     Epoch: 3
2023-01-04 23:33:56,102 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5007496108611424, 'Total loss': 0.5007496108611424} | train loss {'Reaction outcome loss': 0.49864841495519097, 'Total loss': 0.49864841495519097}
2023-01-04 23:33:56,102 INFO:     Found new best model at epoch 3
2023-01-04 23:33:56,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:56,104 INFO:     Epoch: 4
2023-01-04 23:33:58,383 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5061591496070226, 'Total loss': 0.5061591496070226} | train loss {'Reaction outcome loss': 0.4810121679514903, 'Total loss': 0.4810121679514903}
2023-01-04 23:33:58,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:33:58,383 INFO:     Epoch: 5
2023-01-04 23:34:00,617 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46858772039413454, 'Total loss': 0.46858772039413454} | train loss {'Reaction outcome loss': 0.4490773398699104, 'Total loss': 0.4490773398699104}
2023-01-04 23:34:00,617 INFO:     Found new best model at epoch 5
2023-01-04 23:34:00,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:00,619 INFO:     Epoch: 6
2023-01-04 23:34:02,905 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48741256693998974, 'Total loss': 0.48741256693998974} | train loss {'Reaction outcome loss': 0.43416356734013645, 'Total loss': 0.43416356734013645}
2023-01-04 23:34:02,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:02,906 INFO:     Epoch: 7
2023-01-04 23:34:05,198 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45883668859799703, 'Total loss': 0.45883668859799703} | train loss {'Reaction outcome loss': 0.4166834569684621, 'Total loss': 0.4166834569684621}
2023-01-04 23:34:05,198 INFO:     Found new best model at epoch 7
2023-01-04 23:34:05,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:05,199 INFO:     Epoch: 8
2023-01-04 23:34:07,465 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48399085402488706, 'Total loss': 0.48399085402488706} | train loss {'Reaction outcome loss': 0.4073140904985611, 'Total loss': 0.4073140904985611}
2023-01-04 23:34:07,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:07,465 INFO:     Epoch: 9
2023-01-04 23:34:09,609 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46419962545235954, 'Total loss': 0.46419962545235954} | train loss {'Reaction outcome loss': 0.4117472656071186, 'Total loss': 0.4117472656071186}
2023-01-04 23:34:09,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:09,609 INFO:     Epoch: 10
2023-01-04 23:34:11,474 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4686232328414917, 'Total loss': 0.4686232328414917} | train loss {'Reaction outcome loss': 0.4055965652662343, 'Total loss': 0.4055965652662343}
2023-01-04 23:34:11,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:11,476 INFO:     Epoch: 11
2023-01-04 23:34:13,375 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46263665755589806, 'Total loss': 0.46263665755589806} | train loss {'Reaction outcome loss': 0.3873015304190525, 'Total loss': 0.3873015304190525}
2023-01-04 23:34:13,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:13,376 INFO:     Epoch: 12
2023-01-04 23:34:15,650 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4574810047944387, 'Total loss': 0.4574810047944387} | train loss {'Reaction outcome loss': 0.37265482557837537, 'Total loss': 0.37265482557837537}
2023-01-04 23:34:15,651 INFO:     Found new best model at epoch 12
2023-01-04 23:34:15,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:15,652 INFO:     Epoch: 13
2023-01-04 23:34:17,933 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46756666600704194, 'Total loss': 0.46756666600704194} | train loss {'Reaction outcome loss': 0.36296918876199186, 'Total loss': 0.36296918876199186}
2023-01-04 23:34:17,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:17,934 INFO:     Epoch: 14
2023-01-04 23:34:20,227 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45859734565019605, 'Total loss': 0.45859734565019605} | train loss {'Reaction outcome loss': 0.3571715130018529, 'Total loss': 0.3571715130018529}
2023-01-04 23:34:20,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:20,227 INFO:     Epoch: 15
2023-01-04 23:34:22,516 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4588403048614661, 'Total loss': 0.4588403048614661} | train loss {'Reaction outcome loss': 0.34962828179730265, 'Total loss': 0.34962828179730265}
2023-01-04 23:34:22,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:22,516 INFO:     Epoch: 16
2023-01-04 23:34:24,808 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4483586053053538, 'Total loss': 0.4483586053053538} | train loss {'Reaction outcome loss': 0.34743566190250486, 'Total loss': 0.34743566190250486}
2023-01-04 23:34:24,809 INFO:     Found new best model at epoch 16
2023-01-04 23:34:24,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:24,810 INFO:     Epoch: 17
2023-01-04 23:34:27,086 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45988148351510366, 'Total loss': 0.45988148351510366} | train loss {'Reaction outcome loss': 0.3391696682193087, 'Total loss': 0.3391696682193087}
2023-01-04 23:34:27,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:27,086 INFO:     Epoch: 18
2023-01-04 23:34:29,379 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4621363952755928, 'Total loss': 0.4621363952755928} | train loss {'Reaction outcome loss': 0.3297863092907853, 'Total loss': 0.3297863092907853}
2023-01-04 23:34:29,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:29,380 INFO:     Epoch: 19
2023-01-04 23:34:31,683 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46957170267899834, 'Total loss': 0.46957170267899834} | train loss {'Reaction outcome loss': 0.3239163178410585, 'Total loss': 0.3239163178410585}
2023-01-04 23:34:31,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:31,684 INFO:     Epoch: 20
2023-01-04 23:34:33,943 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4479148477315903, 'Total loss': 0.4479148477315903} | train loss {'Reaction outcome loss': 0.32298550805400894, 'Total loss': 0.32298550805400894}
2023-01-04 23:34:33,944 INFO:     Found new best model at epoch 20
2023-01-04 23:34:33,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:33,945 INFO:     Epoch: 21
2023-01-04 23:34:36,168 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47329431573549907, 'Total loss': 0.47329431573549907} | train loss {'Reaction outcome loss': 0.3142991050456961, 'Total loss': 0.3142991050456961}
2023-01-04 23:34:36,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:36,168 INFO:     Epoch: 22
2023-01-04 23:34:38,451 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48841333389282227, 'Total loss': 0.48841333389282227} | train loss {'Reaction outcome loss': 0.3080229774873326, 'Total loss': 0.3080229774873326}
2023-01-04 23:34:38,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:38,452 INFO:     Epoch: 23
2023-01-04 23:34:40,737 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.470183914899826, 'Total loss': 0.470183914899826} | train loss {'Reaction outcome loss': 0.31206077993029147, 'Total loss': 0.31206077993029147}
2023-01-04 23:34:40,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:40,737 INFO:     Epoch: 24
2023-01-04 23:34:43,013 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48490631182988486, 'Total loss': 0.48490631182988486} | train loss {'Reaction outcome loss': 0.29202309447667346, 'Total loss': 0.29202309447667346}
2023-01-04 23:34:43,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:43,015 INFO:     Epoch: 25
2023-01-04 23:34:45,308 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48615813851356504, 'Total loss': 0.48615813851356504} | train loss {'Reaction outcome loss': 0.2905283013183246, 'Total loss': 0.2905283013183246}
2023-01-04 23:34:45,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:45,308 INFO:     Epoch: 26
2023-01-04 23:34:47,573 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48608358601729074, 'Total loss': 0.48608358601729074} | train loss {'Reaction outcome loss': 0.28528856290875515, 'Total loss': 0.28528856290875515}
2023-01-04 23:34:47,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:47,574 INFO:     Epoch: 27
2023-01-04 23:34:49,849 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5086135963598887, 'Total loss': 0.5086135963598887} | train loss {'Reaction outcome loss': 0.2803641576691112, 'Total loss': 0.2803641576691112}
2023-01-04 23:34:49,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:49,850 INFO:     Epoch: 28
2023-01-04 23:34:52,122 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5065648436546326, 'Total loss': 0.5065648436546326} | train loss {'Reaction outcome loss': 0.2792024786320036, 'Total loss': 0.2792024786320036}
2023-01-04 23:34:52,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:52,123 INFO:     Epoch: 29
2023-01-04 23:34:54,402 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46385056587557, 'Total loss': 0.46385056587557} | train loss {'Reaction outcome loss': 0.2773509484749332, 'Total loss': 0.2773509484749332}
2023-01-04 23:34:54,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:54,402 INFO:     Epoch: 30
2023-01-04 23:34:56,695 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4791241243481636, 'Total loss': 0.4791241243481636} | train loss {'Reaction outcome loss': 0.2907634478440319, 'Total loss': 0.2907634478440319}
2023-01-04 23:34:56,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:56,695 INFO:     Epoch: 31
2023-01-04 23:34:58,929 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5075248261292775, 'Total loss': 0.5075248261292775} | train loss {'Reaction outcome loss': 0.27001597097926383, 'Total loss': 0.27001597097926383}
2023-01-04 23:34:58,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:34:58,929 INFO:     Epoch: 32
2023-01-04 23:35:01,199 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5285200317700703, 'Total loss': 0.5285200317700703} | train loss {'Reaction outcome loss': 0.2623285891258738, 'Total loss': 0.2623285891258738}
2023-01-04 23:35:01,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:01,200 INFO:     Epoch: 33
2023-01-04 23:35:03,474 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47237347265084584, 'Total loss': 0.47237347265084584} | train loss {'Reaction outcome loss': 0.26010955109571415, 'Total loss': 0.26010955109571415}
2023-01-04 23:35:03,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:03,475 INFO:     Epoch: 34
2023-01-04 23:35:05,734 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48649964729944867, 'Total loss': 0.48649964729944867} | train loss {'Reaction outcome loss': 0.26086324186273513, 'Total loss': 0.26086324186273513}
2023-01-04 23:35:05,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:05,735 INFO:     Epoch: 35
2023-01-04 23:35:08,015 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4864043802022934, 'Total loss': 0.4864043802022934} | train loss {'Reaction outcome loss': 0.25491004927164834, 'Total loss': 0.25491004927164834}
2023-01-04 23:35:08,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:08,015 INFO:     Epoch: 36
2023-01-04 23:35:10,233 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.495879386862119, 'Total loss': 0.495879386862119} | train loss {'Reaction outcome loss': 0.24788211199346985, 'Total loss': 0.24788211199346985}
2023-01-04 23:35:10,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:10,233 INFO:     Epoch: 37
2023-01-04 23:35:12,489 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4739253719647725, 'Total loss': 0.4739253719647725} | train loss {'Reaction outcome loss': 0.2487531761551087, 'Total loss': 0.2487531761551087}
2023-01-04 23:35:12,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:12,490 INFO:     Epoch: 38
2023-01-04 23:35:14,752 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4847751408815384, 'Total loss': 0.4847751408815384} | train loss {'Reaction outcome loss': 0.2494559608029427, 'Total loss': 0.2494559608029427}
2023-01-04 23:35:14,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:14,752 INFO:     Epoch: 39
2023-01-04 23:35:17,018 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.487234565615654, 'Total loss': 0.487234565615654} | train loss {'Reaction outcome loss': 0.24491156597893374, 'Total loss': 0.24491156597893374}
2023-01-04 23:35:17,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:17,018 INFO:     Epoch: 40
2023-01-04 23:35:19,290 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5415857652823131, 'Total loss': 0.5415857652823131} | train loss {'Reaction outcome loss': 0.24104541243286803, 'Total loss': 0.24104541243286803}
2023-01-04 23:35:19,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:19,291 INFO:     Epoch: 41
2023-01-04 23:35:21,519 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5172340750694275, 'Total loss': 0.5172340750694275} | train loss {'Reaction outcome loss': 0.23894134073086298, 'Total loss': 0.23894134073086298}
2023-01-04 23:35:21,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:21,520 INFO:     Epoch: 42
2023-01-04 23:35:23,775 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5296960055828095, 'Total loss': 0.5296960055828095} | train loss {'Reaction outcome loss': 0.2340947308639179, 'Total loss': 0.2340947308639179}
2023-01-04 23:35:23,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:23,775 INFO:     Epoch: 43
2023-01-04 23:35:26,015 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5149666567643484, 'Total loss': 0.5149666567643484} | train loss {'Reaction outcome loss': 0.23051532030281058, 'Total loss': 0.23051532030281058}
2023-01-04 23:35:26,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:26,016 INFO:     Epoch: 44
2023-01-04 23:35:28,264 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5170956949392954, 'Total loss': 0.5170956949392954} | train loss {'Reaction outcome loss': 0.23056824999335018, 'Total loss': 0.23056824999335018}
2023-01-04 23:35:28,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:28,264 INFO:     Epoch: 45
2023-01-04 23:35:30,531 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5323998788992564, 'Total loss': 0.5323998788992564} | train loss {'Reaction outcome loss': 0.23049926042617502, 'Total loss': 0.23049926042617502}
2023-01-04 23:35:30,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:30,531 INFO:     Epoch: 46
2023-01-04 23:35:32,804 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5282387132445971, 'Total loss': 0.5282387132445971} | train loss {'Reaction outcome loss': 0.23203828825574854, 'Total loss': 0.23203828825574854}
2023-01-04 23:35:32,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:32,805 INFO:     Epoch: 47
2023-01-04 23:35:35,073 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5343774845202763, 'Total loss': 0.5343774845202763} | train loss {'Reaction outcome loss': 0.23537712041929743, 'Total loss': 0.23537712041929743}
2023-01-04 23:35:35,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:35,074 INFO:     Epoch: 48
2023-01-04 23:35:37,320 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5198804219563802, 'Total loss': 0.5198804219563802} | train loss {'Reaction outcome loss': 0.22202620799720718, 'Total loss': 0.22202620799720718}
2023-01-04 23:35:37,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:37,321 INFO:     Epoch: 49
2023-01-04 23:35:39,360 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5228587128221989, 'Total loss': 0.5228587128221989} | train loss {'Reaction outcome loss': 0.22285839535291324, 'Total loss': 0.22285839535291324}
2023-01-04 23:35:39,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:39,361 INFO:     Epoch: 50
2023-01-04 23:35:41,498 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5275814344485601, 'Total loss': 0.5275814344485601} | train loss {'Reaction outcome loss': 0.2200620245201972, 'Total loss': 0.2200620245201972}
2023-01-04 23:35:41,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:41,498 INFO:     Epoch: 51
2023-01-04 23:35:43,740 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5222861468791962, 'Total loss': 0.5222861468791962} | train loss {'Reaction outcome loss': 0.22033827026388136, 'Total loss': 0.22033827026388136}
2023-01-04 23:35:43,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:43,740 INFO:     Epoch: 52
2023-01-04 23:35:46,015 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5020395477612813, 'Total loss': 0.5020395477612813} | train loss {'Reaction outcome loss': 0.2166012486238775, 'Total loss': 0.2166012486238775}
2023-01-04 23:35:46,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:46,016 INFO:     Epoch: 53
2023-01-04 23:35:48,255 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5212796757618586, 'Total loss': 0.5212796757618586} | train loss {'Reaction outcome loss': 0.23928381430417084, 'Total loss': 0.23928381430417084}
2023-01-04 23:35:48,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:48,256 INFO:     Epoch: 54
2023-01-04 23:35:50,512 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5245970358451207, 'Total loss': 0.5245970358451207} | train loss {'Reaction outcome loss': 0.21262202703012695, 'Total loss': 0.21262202703012695}
2023-01-04 23:35:50,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:50,513 INFO:     Epoch: 55
2023-01-04 23:35:52,792 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5188308407862982, 'Total loss': 0.5188308407862982} | train loss {'Reaction outcome loss': 0.21284605356487335, 'Total loss': 0.21284605356487335}
2023-01-04 23:35:52,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:52,792 INFO:     Epoch: 56
2023-01-04 23:35:55,046 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5010630269845326, 'Total loss': 0.5010630269845326} | train loss {'Reaction outcome loss': 0.2097520203246793, 'Total loss': 0.2097520203246793}
2023-01-04 23:35:55,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:55,047 INFO:     Epoch: 57
2023-01-04 23:35:57,326 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5233207784593106, 'Total loss': 0.5233207784593106} | train loss {'Reaction outcome loss': 0.20895923298793723, 'Total loss': 0.20895923298793723}
2023-01-04 23:35:57,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:57,327 INFO:     Epoch: 58
2023-01-04 23:35:59,605 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5124661445617675, 'Total loss': 0.5124661445617675} | train loss {'Reaction outcome loss': 0.2037759873783216, 'Total loss': 0.2037759873783216}
2023-01-04 23:35:59,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:35:59,606 INFO:     Epoch: 59
2023-01-04 23:36:01,861 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.516489772995313, 'Total loss': 0.516489772995313} | train loss {'Reaction outcome loss': 0.20642054034578905, 'Total loss': 0.20642054034578905}
2023-01-04 23:36:01,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:01,861 INFO:     Epoch: 60
2023-01-04 23:36:04,138 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5334136486053467, 'Total loss': 0.5334136486053467} | train loss {'Reaction outcome loss': 0.2023261889451111, 'Total loss': 0.2023261889451111}
2023-01-04 23:36:04,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:04,139 INFO:     Epoch: 61
2023-01-04 23:36:06,411 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.539526425053676, 'Total loss': 0.539526425053676} | train loss {'Reaction outcome loss': 0.22067736641949284, 'Total loss': 0.22067736641949284}
2023-01-04 23:36:06,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:06,411 INFO:     Epoch: 62
2023-01-04 23:36:08,688 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5091526021560033, 'Total loss': 0.5091526021560033} | train loss {'Reaction outcome loss': 0.20429524502453758, 'Total loss': 0.20429524502453758}
2023-01-04 23:36:08,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:08,689 INFO:     Epoch: 63
2023-01-04 23:36:10,889 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5081739286581676, 'Total loss': 0.5081739286581676} | train loss {'Reaction outcome loss': 0.20071276807246488, 'Total loss': 0.20071276807246488}
2023-01-04 23:36:10,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:10,889 INFO:     Epoch: 64
2023-01-04 23:36:13,131 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5195429762204488, 'Total loss': 0.5195429762204488} | train loss {'Reaction outcome loss': 0.19999945863231045, 'Total loss': 0.19999945863231045}
2023-01-04 23:36:13,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:13,131 INFO:     Epoch: 65
2023-01-04 23:36:15,429 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5385262896617253, 'Total loss': 0.5385262896617253} | train loss {'Reaction outcome loss': 0.1991577206560802, 'Total loss': 0.1991577206560802}
2023-01-04 23:36:15,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:15,430 INFO:     Epoch: 66
2023-01-04 23:36:17,726 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5276089032491048, 'Total loss': 0.5276089032491048} | train loss {'Reaction outcome loss': 0.19733934549435947, 'Total loss': 0.19733934549435947}
2023-01-04 23:36:17,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:17,727 INFO:     Epoch: 67
2023-01-04 23:36:20,040 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5112081785996755, 'Total loss': 0.5112081785996755} | train loss {'Reaction outcome loss': 0.19284440656158858, 'Total loss': 0.19284440656158858}
2023-01-04 23:36:20,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:20,041 INFO:     Epoch: 68
2023-01-04 23:36:22,324 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5314501245816549, 'Total loss': 0.5314501245816549} | train loss {'Reaction outcome loss': 0.1965471122859289, 'Total loss': 0.1965471122859289}
2023-01-04 23:36:22,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:22,324 INFO:     Epoch: 69
2023-01-04 23:36:24,616 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5104845046997071, 'Total loss': 0.5104845046997071} | train loss {'Reaction outcome loss': 0.19594868400710527, 'Total loss': 0.19594868400710527}
2023-01-04 23:36:24,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:24,617 INFO:     Epoch: 70
2023-01-04 23:36:26,921 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5547051921486854, 'Total loss': 0.5547051921486854} | train loss {'Reaction outcome loss': 0.19621731280821605, 'Total loss': 0.19621731280821605}
2023-01-04 23:36:26,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:26,921 INFO:     Epoch: 71
2023-01-04 23:36:29,225 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5362233757972718, 'Total loss': 0.5362233757972718} | train loss {'Reaction outcome loss': 0.19015711909868632, 'Total loss': 0.19015711909868632}
2023-01-04 23:36:29,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:29,225 INFO:     Epoch: 72
2023-01-04 23:36:31,522 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.545696880420049, 'Total loss': 0.545696880420049} | train loss {'Reaction outcome loss': 0.18705392503318802, 'Total loss': 0.18705392503318802}
2023-01-04 23:36:31,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:31,524 INFO:     Epoch: 73
2023-01-04 23:36:33,805 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5619516809781392, 'Total loss': 0.5619516809781392} | train loss {'Reaction outcome loss': 0.18931716906271226, 'Total loss': 0.18931716906271226}
2023-01-04 23:36:33,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:33,805 INFO:     Epoch: 74
2023-01-04 23:36:36,049 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5181147237618764, 'Total loss': 0.5181147237618764} | train loss {'Reaction outcome loss': 0.18931523481001353, 'Total loss': 0.18931523481001353}
2023-01-04 23:36:36,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:36,049 INFO:     Epoch: 75
2023-01-04 23:36:38,318 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.508353304117918, 'Total loss': 0.508353304117918} | train loss {'Reaction outcome loss': 0.18471565363385403, 'Total loss': 0.18471565363385403}
2023-01-04 23:36:38,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:38,318 INFO:     Epoch: 76
2023-01-04 23:36:40,616 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5425301384801666, 'Total loss': 0.5425301384801666} | train loss {'Reaction outcome loss': 0.18511004311092594, 'Total loss': 0.18511004311092594}
2023-01-04 23:36:40,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:40,617 INFO:     Epoch: 77
2023-01-04 23:36:42,896 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5030082414547602, 'Total loss': 0.5030082414547602} | train loss {'Reaction outcome loss': 0.18212373587469471, 'Total loss': 0.18212373587469471}
2023-01-04 23:36:42,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:42,896 INFO:     Epoch: 78
2023-01-04 23:36:45,103 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5151549438635509, 'Total loss': 0.5151549438635509} | train loss {'Reaction outcome loss': 0.18454297811012363, 'Total loss': 0.18454297811012363}
2023-01-04 23:36:45,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:45,104 INFO:     Epoch: 79
2023-01-04 23:36:47,304 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5566826686263084, 'Total loss': 0.5566826686263084} | train loss {'Reaction outcome loss': 0.18636520211314916, 'Total loss': 0.18636520211314916}
2023-01-04 23:36:47,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:47,304 INFO:     Epoch: 80
2023-01-04 23:36:49,582 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5135545939207077, 'Total loss': 0.5135545939207077} | train loss {'Reaction outcome loss': 0.18371809545931392, 'Total loss': 0.18371809545931392}
2023-01-04 23:36:49,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:49,582 INFO:     Epoch: 81
2023-01-04 23:36:51,858 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.531638573606809, 'Total loss': 0.531638573606809} | train loss {'Reaction outcome loss': 0.18173244259154328, 'Total loss': 0.18173244259154328}
2023-01-04 23:36:51,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:51,858 INFO:     Epoch: 82
2023-01-04 23:36:54,100 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4961458245913188, 'Total loss': 0.4961458245913188} | train loss {'Reaction outcome loss': 0.17793440536352928, 'Total loss': 0.17793440536352928}
2023-01-04 23:36:54,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:54,100 INFO:     Epoch: 83
2023-01-04 23:36:56,322 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5181507207453251, 'Total loss': 0.5181507207453251} | train loss {'Reaction outcome loss': 0.1785253330561555, 'Total loss': 0.1785253330561555}
2023-01-04 23:36:56,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:56,323 INFO:     Epoch: 84
2023-01-04 23:36:58,578 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5099933882554372, 'Total loss': 0.5099933882554372} | train loss {'Reaction outcome loss': 0.18131576310775743, 'Total loss': 0.18131576310775743}
2023-01-04 23:36:58,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:36:58,578 INFO:     Epoch: 85
2023-01-04 23:37:00,786 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49760274291038514, 'Total loss': 0.49760274291038514} | train loss {'Reaction outcome loss': 0.17902443356528555, 'Total loss': 0.17902443356528555}
2023-01-04 23:37:00,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:00,787 INFO:     Epoch: 86
2023-01-04 23:37:03,066 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.501702410976092, 'Total loss': 0.501702410976092} | train loss {'Reaction outcome loss': 0.1765816628188907, 'Total loss': 0.1765816628188907}
2023-01-04 23:37:03,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:03,066 INFO:     Epoch: 87
2023-01-04 23:37:05,300 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5110211282968521, 'Total loss': 0.5110211282968521} | train loss {'Reaction outcome loss': 0.1798890467017781, 'Total loss': 0.1798890467017781}
2023-01-04 23:37:05,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:05,300 INFO:     Epoch: 88
2023-01-04 23:37:07,584 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5448820134003957, 'Total loss': 0.5448820134003957} | train loss {'Reaction outcome loss': 0.17815532391904382, 'Total loss': 0.17815532391904382}
2023-01-04 23:37:07,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:07,585 INFO:     Epoch: 89
2023-01-04 23:37:09,850 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4689823627471924, 'Total loss': 0.4689823627471924} | train loss {'Reaction outcome loss': 0.17500232577710279, 'Total loss': 0.17500232577710279}
2023-01-04 23:37:09,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:09,851 INFO:     Epoch: 90
2023-01-04 23:37:12,081 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.500858994325002, 'Total loss': 0.500858994325002} | train loss {'Reaction outcome loss': 0.17419945634477094, 'Total loss': 0.17419945634477094}
2023-01-04 23:37:12,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:12,081 INFO:     Epoch: 91
2023-01-04 23:37:14,330 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5051342894633611, 'Total loss': 0.5051342894633611} | train loss {'Reaction outcome loss': 0.17390383256829606, 'Total loss': 0.17390383256829606}
2023-01-04 23:37:14,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:14,330 INFO:     Epoch: 92
2023-01-04 23:37:16,586 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5035882890224457, 'Total loss': 0.5035882890224457} | train loss {'Reaction outcome loss': 0.17327837399004595, 'Total loss': 0.17327837399004595}
2023-01-04 23:37:16,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:16,586 INFO:     Epoch: 93
2023-01-04 23:37:18,849 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5138630559047063, 'Total loss': 0.5138630559047063} | train loss {'Reaction outcome loss': 0.17333368558531115, 'Total loss': 0.17333368558531115}
2023-01-04 23:37:18,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:18,849 INFO:     Epoch: 94
2023-01-04 23:37:21,107 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5301068007946015, 'Total loss': 0.5301068007946015} | train loss {'Reaction outcome loss': 0.17341143857692773, 'Total loss': 0.17341143857692773}
2023-01-04 23:37:21,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:21,108 INFO:     Epoch: 95
2023-01-04 23:37:23,328 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.525421533981959, 'Total loss': 0.525421533981959} | train loss {'Reaction outcome loss': 0.16562396838022667, 'Total loss': 0.16562396838022667}
2023-01-04 23:37:23,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:23,328 INFO:     Epoch: 96
2023-01-04 23:37:25,598 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.524609328309695, 'Total loss': 0.524609328309695} | train loss {'Reaction outcome loss': 0.17104570284414955, 'Total loss': 0.17104570284414955}
2023-01-04 23:37:25,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:25,598 INFO:     Epoch: 97
2023-01-04 23:37:27,863 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5192808032035827, 'Total loss': 0.5192808032035827} | train loss {'Reaction outcome loss': 0.17488838185048391, 'Total loss': 0.17488838185048391}
2023-01-04 23:37:27,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:27,863 INFO:     Epoch: 98
2023-01-04 23:37:30,125 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5152280320723851, 'Total loss': 0.5152280320723851} | train loss {'Reaction outcome loss': 0.16864951592583236, 'Total loss': 0.16864951592583236}
2023-01-04 23:37:30,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:30,127 INFO:     Epoch: 99
2023-01-04 23:37:32,357 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5183681885401408, 'Total loss': 0.5183681885401408} | train loss {'Reaction outcome loss': 0.1655024828836811, 'Total loss': 0.1655024828836811}
2023-01-04 23:37:32,357 INFO:     Best model found after epoch 21 of 100.
2023-01-04 23:37:32,358 INFO:   Done with stage: TRAINING
2023-01-04 23:37:32,358 INFO:   Starting stage: EVALUATION
2023-01-04 23:37:32,494 INFO:   Done with stage: EVALUATION
2023-01-04 23:37:32,502 INFO:   Leaving out SEQ value Fold_0
2023-01-04 23:37:32,515 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 23:37:32,515 INFO:   Starting stage: FEATURE SCALING
2023-01-04 23:37:33,161 INFO:   Done with stage: FEATURE SCALING
2023-01-04 23:37:33,161 INFO:   Starting stage: SCALING TARGETS
2023-01-04 23:37:33,233 INFO:   Done with stage: SCALING TARGETS
2023-01-04 23:37:33,233 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:37:33,233 INFO:     No hyperparam tuning for this model
2023-01-04 23:37:33,233 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:37:33,233 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 23:37:33,234 INFO:     None feature selector for col prot
2023-01-04 23:37:33,234 INFO:     None feature selector for col prot
2023-01-04 23:37:33,234 INFO:     None feature selector for col prot
2023-01-04 23:37:33,235 INFO:     None feature selector for col chem
2023-01-04 23:37:33,235 INFO:     None feature selector for col chem
2023-01-04 23:37:33,235 INFO:     None feature selector for col chem
2023-01-04 23:37:33,235 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 23:37:33,235 INFO:   Starting stage: BUILD MODEL
2023-01-04 23:37:33,237 INFO:     Number of params in model 72931
2023-01-04 23:37:33,240 INFO:   Done with stage: BUILD MODEL
2023-01-04 23:37:33,240 INFO:   Starting stage: TRAINING
2023-01-04 23:37:33,300 INFO:     Val loss before train {'Reaction outcome loss': 1.0338389913241068, 'Total loss': 1.0338389913241068}
2023-01-04 23:37:33,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:33,301 INFO:     Epoch: 0
2023-01-04 23:37:35,538 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.841604495048523, 'Total loss': 0.841604495048523} | train loss {'Reaction outcome loss': 0.9584539342318138, 'Total loss': 0.9584539342318138}
2023-01-04 23:37:35,538 INFO:     Found new best model at epoch 0
2023-01-04 23:37:35,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:35,539 INFO:     Epoch: 1
2023-01-04 23:37:37,789 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5930841585000356, 'Total loss': 0.5930841585000356} | train loss {'Reaction outcome loss': 0.6591871656531835, 'Total loss': 0.6591871656531835}
2023-01-04 23:37:37,790 INFO:     Found new best model at epoch 1
2023-01-04 23:37:37,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:37,791 INFO:     Epoch: 2
2023-01-04 23:37:40,057 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5170001705487569, 'Total loss': 0.5170001705487569} | train loss {'Reaction outcome loss': 0.5444788790858575, 'Total loss': 0.5444788790858575}
2023-01-04 23:37:40,057 INFO:     Found new best model at epoch 2
2023-01-04 23:37:40,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:40,058 INFO:     Epoch: 3
2023-01-04 23:37:42,329 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4798579732577006, 'Total loss': 0.4798579732577006} | train loss {'Reaction outcome loss': 0.5099392407131891, 'Total loss': 0.5099392407131891}
2023-01-04 23:37:42,329 INFO:     Found new best model at epoch 3
2023-01-04 23:37:42,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:42,330 INFO:     Epoch: 4
2023-01-04 23:37:44,575 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4720882793267568, 'Total loss': 0.4720882793267568} | train loss {'Reaction outcome loss': 0.48268842512238636, 'Total loss': 0.48268842512238636}
2023-01-04 23:37:44,575 INFO:     Found new best model at epoch 4
2023-01-04 23:37:44,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:44,576 INFO:     Epoch: 5
2023-01-04 23:37:46,831 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46362417489290236, 'Total loss': 0.46362417489290236} | train loss {'Reaction outcome loss': 0.4540741712833843, 'Total loss': 0.4540741712833843}
2023-01-04 23:37:46,831 INFO:     Found new best model at epoch 5
2023-01-04 23:37:46,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:46,833 INFO:     Epoch: 6
2023-01-04 23:37:49,107 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46146967907746633, 'Total loss': 0.46146967907746633} | train loss {'Reaction outcome loss': 0.4399535211115858, 'Total loss': 0.4399535211115858}
2023-01-04 23:37:49,107 INFO:     Found new best model at epoch 6
2023-01-04 23:37:49,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:49,108 INFO:     Epoch: 7
2023-01-04 23:37:51,394 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4469772443175316, 'Total loss': 0.4469772443175316} | train loss {'Reaction outcome loss': 0.42851500940529536, 'Total loss': 0.42851500940529536}
2023-01-04 23:37:51,395 INFO:     Found new best model at epoch 7
2023-01-04 23:37:51,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:51,396 INFO:     Epoch: 8
2023-01-04 23:37:53,664 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45840796530246736, 'Total loss': 0.45840796530246736} | train loss {'Reaction outcome loss': 0.40896015967765864, 'Total loss': 0.40896015967765864}
2023-01-04 23:37:53,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:53,664 INFO:     Epoch: 9
2023-01-04 23:37:55,882 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44732517500718433, 'Total loss': 0.44732517500718433} | train loss {'Reaction outcome loss': 0.40133777366828743, 'Total loss': 0.40133777366828743}
2023-01-04 23:37:55,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:55,883 INFO:     Epoch: 10
2023-01-04 23:37:58,117 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4515327711900075, 'Total loss': 0.4515327711900075} | train loss {'Reaction outcome loss': 0.38652694192681, 'Total loss': 0.38652694192681}
2023-01-04 23:37:58,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:37:58,117 INFO:     Epoch: 11
2023-01-04 23:38:00,394 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44972979724407197, 'Total loss': 0.44972979724407197} | train loss {'Reaction outcome loss': 0.3731885507539676, 'Total loss': 0.3731885507539676}
2023-01-04 23:38:00,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:00,394 INFO:     Epoch: 12
2023-01-04 23:38:02,691 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4405726472536723, 'Total loss': 0.4405726472536723} | train loss {'Reaction outcome loss': 0.366090554798389, 'Total loss': 0.366090554798389}
2023-01-04 23:38:02,691 INFO:     Found new best model at epoch 12
2023-01-04 23:38:02,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:02,692 INFO:     Epoch: 13
2023-01-04 23:38:04,938 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44829969604810077, 'Total loss': 0.44829969604810077} | train loss {'Reaction outcome loss': 0.35881119501525466, 'Total loss': 0.35881119501525466}
2023-01-04 23:38:04,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:04,939 INFO:     Epoch: 14
2023-01-04 23:38:07,204 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4423205425341924, 'Total loss': 0.4423205425341924} | train loss {'Reaction outcome loss': 0.34876542747782097, 'Total loss': 0.34876542747782097}
2023-01-04 23:38:07,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:07,205 INFO:     Epoch: 15
2023-01-04 23:38:09,438 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4393530706564585, 'Total loss': 0.4393530706564585} | train loss {'Reaction outcome loss': 0.3425466866116889, 'Total loss': 0.3425466866116889}
2023-01-04 23:38:09,438 INFO:     Found new best model at epoch 15
2023-01-04 23:38:09,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:09,440 INFO:     Epoch: 16
2023-01-04 23:38:11,685 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.434079110622406, 'Total loss': 0.434079110622406} | train loss {'Reaction outcome loss': 0.3311120789688434, 'Total loss': 0.3311120789688434}
2023-01-04 23:38:11,686 INFO:     Found new best model at epoch 16
2023-01-04 23:38:11,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:11,687 INFO:     Epoch: 17
2023-01-04 23:38:13,910 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4495584160089493, 'Total loss': 0.4495584160089493} | train loss {'Reaction outcome loss': 0.3210434992491764, 'Total loss': 0.3210434992491764}
2023-01-04 23:38:13,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:13,911 INFO:     Epoch: 18
2023-01-04 23:38:16,130 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42536674936612445, 'Total loss': 0.42536674936612445} | train loss {'Reaction outcome loss': 0.3182460212685766, 'Total loss': 0.3182460212685766}
2023-01-04 23:38:16,130 INFO:     Found new best model at epoch 18
2023-01-04 23:38:16,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:16,131 INFO:     Epoch: 19
2023-01-04 23:38:18,349 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4466086874405543, 'Total loss': 0.4466086874405543} | train loss {'Reaction outcome loss': 0.3131661173771985, 'Total loss': 0.3131661173771985}
2023-01-04 23:38:18,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:18,349 INFO:     Epoch: 20
2023-01-04 23:38:20,543 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4247960865497589, 'Total loss': 0.4247960865497589} | train loss {'Reaction outcome loss': 0.3094631444703597, 'Total loss': 0.3094631444703597}
2023-01-04 23:38:20,543 INFO:     Found new best model at epoch 20
2023-01-04 23:38:20,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:20,544 INFO:     Epoch: 21
2023-01-04 23:38:22,766 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40600682720541953, 'Total loss': 0.40600682720541953} | train loss {'Reaction outcome loss': 0.3086065648082834, 'Total loss': 0.3086065648082834}
2023-01-04 23:38:22,766 INFO:     Found new best model at epoch 21
2023-01-04 23:38:22,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:22,768 INFO:     Epoch: 22
2023-01-04 23:38:25,025 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40305139049887656, 'Total loss': 0.40305139049887656} | train loss {'Reaction outcome loss': 0.2942335094413618, 'Total loss': 0.2942335094413618}
2023-01-04 23:38:25,025 INFO:     Found new best model at epoch 22
2023-01-04 23:38:25,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:25,027 INFO:     Epoch: 23
2023-01-04 23:38:27,292 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4295890301465988, 'Total loss': 0.4295890301465988} | train loss {'Reaction outcome loss': 0.29377759313278823, 'Total loss': 0.29377759313278823}
2023-01-04 23:38:27,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:27,293 INFO:     Epoch: 24
2023-01-04 23:38:29,535 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4144504725933075, 'Total loss': 0.4144504725933075} | train loss {'Reaction outcome loss': 0.28561608757089524, 'Total loss': 0.28561608757089524}
2023-01-04 23:38:29,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:29,536 INFO:     Epoch: 25
2023-01-04 23:38:31,782 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4178619911273321, 'Total loss': 0.4178619911273321} | train loss {'Reaction outcome loss': 0.2824609231230986, 'Total loss': 0.2824609231230986}
2023-01-04 23:38:31,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:31,782 INFO:     Epoch: 26
2023-01-04 23:38:34,050 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4322110195954641, 'Total loss': 0.4322110195954641} | train loss {'Reaction outcome loss': 0.2761990246736873, 'Total loss': 0.2761990246736873}
2023-01-04 23:38:34,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:34,051 INFO:     Epoch: 27
2023-01-04 23:38:36,328 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4154211978117625, 'Total loss': 0.4154211978117625} | train loss {'Reaction outcome loss': 0.2689641259583461, 'Total loss': 0.2689641259583461}
2023-01-04 23:38:36,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:36,328 INFO:     Epoch: 28
2023-01-04 23:38:38,568 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44247169345617293, 'Total loss': 0.44247169345617293} | train loss {'Reaction outcome loss': 0.2673774898378518, 'Total loss': 0.2673774898378518}
2023-01-04 23:38:38,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:38,570 INFO:     Epoch: 29
2023-01-04 23:38:40,847 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43049131631851195, 'Total loss': 0.43049131631851195} | train loss {'Reaction outcome loss': 0.26353314639932485, 'Total loss': 0.26353314639932485}
2023-01-04 23:38:40,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:40,847 INFO:     Epoch: 30
2023-01-04 23:38:43,112 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4324937139948209, 'Total loss': 0.4324937139948209} | train loss {'Reaction outcome loss': 0.2602155861873044, 'Total loss': 0.2602155861873044}
2023-01-04 23:38:43,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:43,112 INFO:     Epoch: 31
2023-01-04 23:38:45,349 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45572404166062674, 'Total loss': 0.45572404166062674} | train loss {'Reaction outcome loss': 0.2575550097564276, 'Total loss': 0.2575550097564276}
2023-01-04 23:38:45,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:45,350 INFO:     Epoch: 32
2023-01-04 23:38:47,615 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43589661916097006, 'Total loss': 0.43589661916097006} | train loss {'Reaction outcome loss': 0.2542700185474471, 'Total loss': 0.2542700185474471}
2023-01-04 23:38:47,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:47,616 INFO:     Epoch: 33
2023-01-04 23:38:49,853 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4608107497294744, 'Total loss': 0.4608107497294744} | train loss {'Reaction outcome loss': 0.24792722834913183, 'Total loss': 0.24792722834913183}
2023-01-04 23:38:49,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:49,854 INFO:     Epoch: 34
2023-01-04 23:38:52,095 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48012219766775766, 'Total loss': 0.48012219766775766} | train loss {'Reaction outcome loss': 0.24695603448190612, 'Total loss': 0.24695603448190612}
2023-01-04 23:38:52,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:52,095 INFO:     Epoch: 35
2023-01-04 23:38:54,355 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44611580669879913, 'Total loss': 0.44611580669879913} | train loss {'Reaction outcome loss': 0.24359989598271076, 'Total loss': 0.24359989598271076}
2023-01-04 23:38:54,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:54,355 INFO:     Epoch: 36
2023-01-04 23:38:56,528 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45179210404555004, 'Total loss': 0.45179210404555004} | train loss {'Reaction outcome loss': 0.24296000146436214, 'Total loss': 0.24296000146436214}
2023-01-04 23:38:56,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:56,529 INFO:     Epoch: 37
2023-01-04 23:38:58,803 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46977799385786057, 'Total loss': 0.46977799385786057} | train loss {'Reaction outcome loss': 0.24105162112327821, 'Total loss': 0.24105162112327821}
2023-01-04 23:38:58,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:38:58,804 INFO:     Epoch: 38
2023-01-04 23:39:01,060 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46981575787067414, 'Total loss': 0.46981575787067414} | train loss {'Reaction outcome loss': 0.23394397126653496, 'Total loss': 0.23394397126653496}
2023-01-04 23:39:01,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:01,061 INFO:     Epoch: 39
2023-01-04 23:39:03,310 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42214406927426656, 'Total loss': 0.42214406927426656} | train loss {'Reaction outcome loss': 0.23249626149810906, 'Total loss': 0.23249626149810906}
2023-01-04 23:39:03,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:03,310 INFO:     Epoch: 40
2023-01-04 23:39:05,566 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44431467056274415, 'Total loss': 0.44431467056274415} | train loss {'Reaction outcome loss': 0.23104357094007688, 'Total loss': 0.23104357094007688}
2023-01-04 23:39:05,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:05,567 INFO:     Epoch: 41
2023-01-04 23:39:07,808 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4525803883870443, 'Total loss': 0.4525803883870443} | train loss {'Reaction outcome loss': 0.23301219106074014, 'Total loss': 0.23301219106074014}
2023-01-04 23:39:07,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:07,809 INFO:     Epoch: 42
2023-01-04 23:39:10,084 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4686071902513504, 'Total loss': 0.4686071902513504} | train loss {'Reaction outcome loss': 0.22619902531371663, 'Total loss': 0.22619902531371663}
2023-01-04 23:39:10,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:10,084 INFO:     Epoch: 43
2023-01-04 23:39:12,358 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4422118922074636, 'Total loss': 0.4422118922074636} | train loss {'Reaction outcome loss': 0.22743853822649612, 'Total loss': 0.22743853822649612}
2023-01-04 23:39:12,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:12,359 INFO:     Epoch: 44
2023-01-04 23:39:14,676 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46370653808116913, 'Total loss': 0.46370653808116913} | train loss {'Reaction outcome loss': 0.22051061787744508, 'Total loss': 0.22051061787744508}
2023-01-04 23:39:14,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:14,677 INFO:     Epoch: 45
2023-01-04 23:39:16,975 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46134478052457173, 'Total loss': 0.46134478052457173} | train loss {'Reaction outcome loss': 0.21869476619822376, 'Total loss': 0.21869476619822376}
2023-01-04 23:39:16,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:16,975 INFO:     Epoch: 46
2023-01-04 23:39:19,228 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4331145574649175, 'Total loss': 0.4331145574649175} | train loss {'Reaction outcome loss': 0.22378766664514577, 'Total loss': 0.22378766664514577}
2023-01-04 23:39:19,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:19,229 INFO:     Epoch: 47
2023-01-04 23:39:21,512 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46384376486142476, 'Total loss': 0.46384376486142476} | train loss {'Reaction outcome loss': 0.2171714695333673, 'Total loss': 0.2171714695333673}
2023-01-04 23:39:21,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:21,512 INFO:     Epoch: 48
2023-01-04 23:39:23,758 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44017497499783836, 'Total loss': 0.44017497499783836} | train loss {'Reaction outcome loss': 0.2172965968238448, 'Total loss': 0.2172965968238448}
2023-01-04 23:39:23,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:23,758 INFO:     Epoch: 49
2023-01-04 23:39:26,024 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4609064032634099, 'Total loss': 0.4609064032634099} | train loss {'Reaction outcome loss': 0.21398264513330628, 'Total loss': 0.21398264513330628}
2023-01-04 23:39:26,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:26,025 INFO:     Epoch: 50
2023-01-04 23:39:28,244 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46267790496349337, 'Total loss': 0.46267790496349337} | train loss {'Reaction outcome loss': 0.21691387850981558, 'Total loss': 0.21691387850981558}
2023-01-04 23:39:28,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:28,245 INFO:     Epoch: 51
2023-01-04 23:39:30,483 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4629790226618449, 'Total loss': 0.4629790226618449} | train loss {'Reaction outcome loss': 0.21133135059460942, 'Total loss': 0.21133135059460942}
2023-01-04 23:39:30,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:30,483 INFO:     Epoch: 52
2023-01-04 23:39:32,675 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.472410515944163, 'Total loss': 0.472410515944163} | train loss {'Reaction outcome loss': 0.20841992112814728, 'Total loss': 0.20841992112814728}
2023-01-04 23:39:32,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:32,675 INFO:     Epoch: 53
2023-01-04 23:39:34,883 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4674253503481547, 'Total loss': 0.4674253503481547} | train loss {'Reaction outcome loss': 0.20906221067165806, 'Total loss': 0.20906221067165806}
2023-01-04 23:39:34,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:34,883 INFO:     Epoch: 54
2023-01-04 23:39:37,120 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46196115712324776, 'Total loss': 0.46196115712324776} | train loss {'Reaction outcome loss': 0.2100660978972803, 'Total loss': 0.2100660978972803}
2023-01-04 23:39:37,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:37,121 INFO:     Epoch: 55
2023-01-04 23:39:39,399 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4504115303357442, 'Total loss': 0.4504115303357442} | train loss {'Reaction outcome loss': 0.20703963589018387, 'Total loss': 0.20703963589018387}
2023-01-04 23:39:39,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:39,399 INFO:     Epoch: 56
2023-01-04 23:39:41,660 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4687514126300812, 'Total loss': 0.4687514126300812} | train loss {'Reaction outcome loss': 0.20245221763319016, 'Total loss': 0.20245221763319016}
2023-01-04 23:39:41,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:41,660 INFO:     Epoch: 57
2023-01-04 23:39:43,893 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4591159005959829, 'Total loss': 0.4591159005959829} | train loss {'Reaction outcome loss': 0.2020956610166298, 'Total loss': 0.2020956610166298}
2023-01-04 23:39:43,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:43,894 INFO:     Epoch: 58
2023-01-04 23:39:46,161 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49698454042275747, 'Total loss': 0.49698454042275747} | train loss {'Reaction outcome loss': 0.19996949307022305, 'Total loss': 0.19996949307022305}
2023-01-04 23:39:46,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:46,161 INFO:     Epoch: 59
2023-01-04 23:39:48,296 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5008164425690969, 'Total loss': 0.5008164425690969} | train loss {'Reaction outcome loss': 0.20385557815201416, 'Total loss': 0.20385557815201416}
2023-01-04 23:39:48,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:48,297 INFO:     Epoch: 60
2023-01-04 23:39:50,482 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4914004107316335, 'Total loss': 0.4914004107316335} | train loss {'Reaction outcome loss': 0.19927530181696163, 'Total loss': 0.19927530181696163}
2023-01-04 23:39:50,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:50,483 INFO:     Epoch: 61
2023-01-04 23:39:52,712 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4384738266468048, 'Total loss': 0.4384738266468048} | train loss {'Reaction outcome loss': 0.1987439322074617, 'Total loss': 0.1987439322074617}
2023-01-04 23:39:52,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:52,712 INFO:     Epoch: 62
2023-01-04 23:39:54,984 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4816471546888351, 'Total loss': 0.4816471546888351} | train loss {'Reaction outcome loss': 0.19438292297201543, 'Total loss': 0.19438292297201543}
2023-01-04 23:39:54,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:54,985 INFO:     Epoch: 63
2023-01-04 23:39:57,277 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4570605898896853, 'Total loss': 0.4570605898896853} | train loss {'Reaction outcome loss': 0.19802145505269622, 'Total loss': 0.19802145505269622}
2023-01-04 23:39:57,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:57,277 INFO:     Epoch: 64
2023-01-04 23:39:59,566 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44983149667580924, 'Total loss': 0.44983149667580924} | train loss {'Reaction outcome loss': 0.19465324215346227, 'Total loss': 0.19465324215346227}
2023-01-04 23:39:59,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:39:59,566 INFO:     Epoch: 65
2023-01-04 23:40:01,860 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44006408751010895, 'Total loss': 0.44006408751010895} | train loss {'Reaction outcome loss': 0.1926222163130169, 'Total loss': 0.1926222163130169}
2023-01-04 23:40:01,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:01,860 INFO:     Epoch: 66
2023-01-04 23:40:04,100 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47218848864237467, 'Total loss': 0.47218848864237467} | train loss {'Reaction outcome loss': 0.19399532105393, 'Total loss': 0.19399532105393}
2023-01-04 23:40:04,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:04,101 INFO:     Epoch: 67
2023-01-04 23:40:06,287 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47736869504054386, 'Total loss': 0.47736869504054386} | train loss {'Reaction outcome loss': 0.1969467348684251, 'Total loss': 0.1969467348684251}
2023-01-04 23:40:06,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:06,287 INFO:     Epoch: 68
2023-01-04 23:40:08,547 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49448702683051426, 'Total loss': 0.49448702683051426} | train loss {'Reaction outcome loss': 0.190959238843231, 'Total loss': 0.190959238843231}
2023-01-04 23:40:08,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:08,548 INFO:     Epoch: 69
2023-01-04 23:40:10,750 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4662666340668996, 'Total loss': 0.4662666340668996} | train loss {'Reaction outcome loss': 0.19004335935587865, 'Total loss': 0.19004335935587865}
2023-01-04 23:40:10,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:10,751 INFO:     Epoch: 70
2023-01-04 23:40:13,011 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5054358343283335, 'Total loss': 0.5054358343283335} | train loss {'Reaction outcome loss': 0.19061794352928435, 'Total loss': 0.19061794352928435}
2023-01-04 23:40:13,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:13,011 INFO:     Epoch: 71
2023-01-04 23:40:15,241 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47284294466177623, 'Total loss': 0.47284294466177623} | train loss {'Reaction outcome loss': 0.19391541386254296, 'Total loss': 0.19391541386254296}
2023-01-04 23:40:15,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:15,241 INFO:     Epoch: 72
2023-01-04 23:40:17,452 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44387420018513996, 'Total loss': 0.44387420018513996} | train loss {'Reaction outcome loss': 0.18831954553322255, 'Total loss': 0.18831954553322255}
2023-01-04 23:40:17,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:17,452 INFO:     Epoch: 73
2023-01-04 23:40:19,704 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4450283065438271, 'Total loss': 0.4450283065438271} | train loss {'Reaction outcome loss': 0.18571523942196075, 'Total loss': 0.18571523942196075}
2023-01-04 23:40:19,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:19,706 INFO:     Epoch: 74
2023-01-04 23:40:21,973 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4538739403088888, 'Total loss': 0.4538739403088888} | train loss {'Reaction outcome loss': 0.1823428552138898, 'Total loss': 0.1823428552138898}
2023-01-04 23:40:21,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:21,973 INFO:     Epoch: 75
2023-01-04 23:40:24,239 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45903068681557974, 'Total loss': 0.45903068681557974} | train loss {'Reaction outcome loss': 0.18349448605406568, 'Total loss': 0.18349448605406568}
2023-01-04 23:40:24,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:24,240 INFO:     Epoch: 76
2023-01-04 23:40:26,501 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47807862361272174, 'Total loss': 0.47807862361272174} | train loss {'Reaction outcome loss': 0.18426632980924834, 'Total loss': 0.18426632980924834}
2023-01-04 23:40:26,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:26,502 INFO:     Epoch: 77
2023-01-04 23:40:28,759 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47187339067459105, 'Total loss': 0.47187339067459105} | train loss {'Reaction outcome loss': 0.18200702523391177, 'Total loss': 0.18200702523391177}
2023-01-04 23:40:28,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:28,760 INFO:     Epoch: 78
2023-01-04 23:40:31,027 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46389084580975276, 'Total loss': 0.46389084580975276} | train loss {'Reaction outcome loss': 0.185822035651654, 'Total loss': 0.185822035651654}
2023-01-04 23:40:31,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:31,027 INFO:     Epoch: 79
2023-01-04 23:40:33,275 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49315503537654876, 'Total loss': 0.49315503537654876} | train loss {'Reaction outcome loss': 0.17987679635398907, 'Total loss': 0.17987679635398907}
2023-01-04 23:40:33,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:33,276 INFO:     Epoch: 80
2023-01-04 23:40:35,557 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46306188305219015, 'Total loss': 0.46306188305219015} | train loss {'Reaction outcome loss': 0.18199178673680463, 'Total loss': 0.18199178673680463}
2023-01-04 23:40:35,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:35,557 INFO:     Epoch: 81
2023-01-04 23:40:37,801 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48304536640644075, 'Total loss': 0.48304536640644075} | train loss {'Reaction outcome loss': 0.18167892713983455, 'Total loss': 0.18167892713983455}
2023-01-04 23:40:37,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:37,801 INFO:     Epoch: 82
2023-01-04 23:40:40,051 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4639707251141469, 'Total loss': 0.4639707251141469} | train loss {'Reaction outcome loss': 0.178906285285569, 'Total loss': 0.178906285285569}
2023-01-04 23:40:40,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:40,052 INFO:     Epoch: 83
2023-01-04 23:40:42,314 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46810746043920515, 'Total loss': 0.46810746043920515} | train loss {'Reaction outcome loss': 0.17812698829687967, 'Total loss': 0.17812698829687967}
2023-01-04 23:40:42,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:42,314 INFO:     Epoch: 84
2023-01-04 23:40:44,561 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47643048564593, 'Total loss': 0.47643048564593} | train loss {'Reaction outcome loss': 0.17757739212166818, 'Total loss': 0.17757739212166818}
2023-01-04 23:40:44,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:44,562 INFO:     Epoch: 85
2023-01-04 23:40:46,816 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45355566740036013, 'Total loss': 0.45355566740036013} | train loss {'Reaction outcome loss': 0.17809598239811722, 'Total loss': 0.17809598239811722}
2023-01-04 23:40:46,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:46,817 INFO:     Epoch: 86
2023-01-04 23:40:49,129 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4634303083022436, 'Total loss': 0.4634303083022436} | train loss {'Reaction outcome loss': 0.17736710997614466, 'Total loss': 0.17736710997614466}
2023-01-04 23:40:49,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:49,129 INFO:     Epoch: 87
2023-01-04 23:40:51,458 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4569712201754252, 'Total loss': 0.4569712201754252} | train loss {'Reaction outcome loss': 0.17524272058903492, 'Total loss': 0.17524272058903492}
2023-01-04 23:40:51,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:51,458 INFO:     Epoch: 88
2023-01-04 23:40:53,787 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4836030478278796, 'Total loss': 0.4836030478278796} | train loss {'Reaction outcome loss': 0.17864393256094824, 'Total loss': 0.17864393256094824}
2023-01-04 23:40:53,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:53,787 INFO:     Epoch: 89
2023-01-04 23:40:56,108 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4327601276648541, 'Total loss': 0.4327601276648541} | train loss {'Reaction outcome loss': 0.177400812428499, 'Total loss': 0.177400812428499}
2023-01-04 23:40:56,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:56,109 INFO:     Epoch: 90
2023-01-04 23:40:58,366 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4454160918792089, 'Total loss': 0.4454160918792089} | train loss {'Reaction outcome loss': 0.17829740145005776, 'Total loss': 0.17829740145005776}
2023-01-04 23:40:58,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:40:58,366 INFO:     Epoch: 91
2023-01-04 23:41:00,622 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44070998827616376, 'Total loss': 0.44070998827616376} | train loss {'Reaction outcome loss': 0.17096077781646465, 'Total loss': 0.17096077781646465}
2023-01-04 23:41:00,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:00,623 INFO:     Epoch: 92
2023-01-04 23:41:02,863 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4652334928512573, 'Total loss': 0.4652334928512573} | train loss {'Reaction outcome loss': 0.1721946128718827, 'Total loss': 0.1721946128718827}
2023-01-04 23:41:02,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:02,864 INFO:     Epoch: 93
2023-01-04 23:41:05,083 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4470998670284947, 'Total loss': 0.4470998670284947} | train loss {'Reaction outcome loss': 0.17080408840841294, 'Total loss': 0.17080408840841294}
2023-01-04 23:41:05,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:05,083 INFO:     Epoch: 94
2023-01-04 23:41:07,323 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.464188510676225, 'Total loss': 0.464188510676225} | train loss {'Reaction outcome loss': 0.17665686195947394, 'Total loss': 0.17665686195947394}
2023-01-04 23:41:07,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:07,324 INFO:     Epoch: 95
2023-01-04 23:41:09,515 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4808165262142817, 'Total loss': 0.4808165262142817} | train loss {'Reaction outcome loss': 0.17493380212401768, 'Total loss': 0.17493380212401768}
2023-01-04 23:41:09,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:09,515 INFO:     Epoch: 96
2023-01-04 23:41:11,707 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46818851480881374, 'Total loss': 0.46818851480881374} | train loss {'Reaction outcome loss': 0.1750766617155899, 'Total loss': 0.1750766617155899}
2023-01-04 23:41:11,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:11,707 INFO:     Epoch: 97
2023-01-04 23:41:13,910 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4350438540180524, 'Total loss': 0.4350438540180524} | train loss {'Reaction outcome loss': 0.1734099389890032, 'Total loss': 0.1734099389890032}
2023-01-04 23:41:13,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:13,910 INFO:     Epoch: 98
2023-01-04 23:41:16,139 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.49083272417386375, 'Total loss': 0.49083272417386375} | train loss {'Reaction outcome loss': 0.16536301798799014, 'Total loss': 0.16536301798799014}
2023-01-04 23:41:16,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:16,140 INFO:     Epoch: 99
2023-01-04 23:41:18,357 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46414656440416974, 'Total loss': 0.46414656440416974} | train loss {'Reaction outcome loss': 0.17076187996690018, 'Total loss': 0.17076187996690018}
2023-01-04 23:41:18,357 INFO:     Best model found after epoch 23 of 100.
2023-01-04 23:41:18,358 INFO:   Done with stage: TRAINING
2023-01-04 23:41:18,358 INFO:   Starting stage: EVALUATION
2023-01-04 23:41:18,500 INFO:   Done with stage: EVALUATION
2023-01-04 23:41:18,500 INFO:   Leaving out SEQ value Fold_1
2023-01-04 23:41:18,513 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 23:41:18,513 INFO:   Starting stage: FEATURE SCALING
2023-01-04 23:41:19,172 INFO:   Done with stage: FEATURE SCALING
2023-01-04 23:41:19,173 INFO:   Starting stage: SCALING TARGETS
2023-01-04 23:41:19,244 INFO:   Done with stage: SCALING TARGETS
2023-01-04 23:41:19,245 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:41:19,245 INFO:     No hyperparam tuning for this model
2023-01-04 23:41:19,245 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:41:19,245 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 23:41:19,246 INFO:     None feature selector for col prot
2023-01-04 23:41:19,246 INFO:     None feature selector for col prot
2023-01-04 23:41:19,246 INFO:     None feature selector for col prot
2023-01-04 23:41:19,247 INFO:     None feature selector for col chem
2023-01-04 23:41:19,247 INFO:     None feature selector for col chem
2023-01-04 23:41:19,247 INFO:     None feature selector for col chem
2023-01-04 23:41:19,247 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 23:41:19,247 INFO:   Starting stage: BUILD MODEL
2023-01-04 23:41:19,248 INFO:     Number of params in model 72931
2023-01-04 23:41:19,252 INFO:   Done with stage: BUILD MODEL
2023-01-04 23:41:19,252 INFO:   Starting stage: TRAINING
2023-01-04 23:41:19,313 INFO:     Val loss before train {'Reaction outcome loss': 0.9737777948379517, 'Total loss': 0.9737777948379517}
2023-01-04 23:41:19,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:19,314 INFO:     Epoch: 0
2023-01-04 23:41:21,530 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7811341901620229, 'Total loss': 0.7811341901620229} | train loss {'Reaction outcome loss': 0.9560716717782682, 'Total loss': 0.9560716717782682}
2023-01-04 23:41:21,530 INFO:     Found new best model at epoch 0
2023-01-04 23:41:21,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:21,531 INFO:     Epoch: 1
2023-01-04 23:41:23,790 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5497677286465963, 'Total loss': 0.5497677286465963} | train loss {'Reaction outcome loss': 0.626783703691768, 'Total loss': 0.626783703691768}
2023-01-04 23:41:23,790 INFO:     Found new best model at epoch 1
2023-01-04 23:41:23,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:23,792 INFO:     Epoch: 2
2023-01-04 23:41:26,043 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.525937416156133, 'Total loss': 0.525937416156133} | train loss {'Reaction outcome loss': 0.5259276298384596, 'Total loss': 0.5259276298384596}
2023-01-04 23:41:26,043 INFO:     Found new best model at epoch 2
2023-01-04 23:41:26,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:26,045 INFO:     Epoch: 3
2023-01-04 23:41:28,305 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4991176744302114, 'Total loss': 0.4991176744302114} | train loss {'Reaction outcome loss': 0.48160514757581, 'Total loss': 0.48160514757581}
2023-01-04 23:41:28,305 INFO:     Found new best model at epoch 3
2023-01-04 23:41:28,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:28,307 INFO:     Epoch: 4
2023-01-04 23:41:30,531 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5020540535449982, 'Total loss': 0.5020540535449982} | train loss {'Reaction outcome loss': 0.4546187415610265, 'Total loss': 0.4546187415610265}
2023-01-04 23:41:30,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:30,533 INFO:     Epoch: 5
2023-01-04 23:41:32,681 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4864335089921951, 'Total loss': 0.4864335089921951} | train loss {'Reaction outcome loss': 0.4341969999219597, 'Total loss': 0.4341969999219597}
2023-01-04 23:41:32,681 INFO:     Found new best model at epoch 5
2023-01-04 23:41:32,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:32,682 INFO:     Epoch: 6
2023-01-04 23:41:34,953 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4662762920061747, 'Total loss': 0.4662762920061747} | train loss {'Reaction outcome loss': 0.41314846568190267, 'Total loss': 0.41314846568190267}
2023-01-04 23:41:34,953 INFO:     Found new best model at epoch 6
2023-01-04 23:41:34,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:34,954 INFO:     Epoch: 7
2023-01-04 23:41:37,213 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4392217993736267, 'Total loss': 0.4392217993736267} | train loss {'Reaction outcome loss': 0.4006982361150049, 'Total loss': 0.4006982361150049}
2023-01-04 23:41:37,213 INFO:     Found new best model at epoch 7
2023-01-04 23:41:37,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:37,215 INFO:     Epoch: 8
2023-01-04 23:41:39,454 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46433427234490715, 'Total loss': 0.46433427234490715} | train loss {'Reaction outcome loss': 0.38576900548417203, 'Total loss': 0.38576900548417203}
2023-01-04 23:41:39,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:39,454 INFO:     Epoch: 9
2023-01-04 23:41:41,692 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4287569691737493, 'Total loss': 0.4287569691737493} | train loss {'Reaction outcome loss': 0.37897346609265264, 'Total loss': 0.37897346609265264}
2023-01-04 23:41:41,693 INFO:     Found new best model at epoch 9
2023-01-04 23:41:41,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:41,694 INFO:     Epoch: 10
2023-01-04 23:41:43,952 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4476779083410899, 'Total loss': 0.4476779083410899} | train loss {'Reaction outcome loss': 0.36381867866500883, 'Total loss': 0.36381867866500883}
2023-01-04 23:41:43,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:43,952 INFO:     Epoch: 11
2023-01-04 23:41:46,228 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4378049269318581, 'Total loss': 0.4378049269318581} | train loss {'Reaction outcome loss': 0.35277513458128396, 'Total loss': 0.35277513458128396}
2023-01-04 23:41:46,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:46,229 INFO:     Epoch: 12
2023-01-04 23:41:48,483 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.462272780140241, 'Total loss': 0.462272780140241} | train loss {'Reaction outcome loss': 0.34194092947418675, 'Total loss': 0.34194092947418675}
2023-01-04 23:41:48,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:48,484 INFO:     Epoch: 13
2023-01-04 23:41:50,736 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43900379439195, 'Total loss': 0.43900379439195} | train loss {'Reaction outcome loss': 0.33090756732943283, 'Total loss': 0.33090756732943283}
2023-01-04 23:41:50,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:50,737 INFO:     Epoch: 14
2023-01-04 23:41:52,978 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4387201895316442, 'Total loss': 0.4387201895316442} | train loss {'Reaction outcome loss': 0.32555977208199943, 'Total loss': 0.32555977208199943}
2023-01-04 23:41:52,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:52,978 INFO:     Epoch: 15
2023-01-04 23:41:55,224 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4446246246496836, 'Total loss': 0.4446246246496836} | train loss {'Reaction outcome loss': 0.31934700736327326, 'Total loss': 0.31934700736327326}
2023-01-04 23:41:55,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:55,224 INFO:     Epoch: 16
2023-01-04 23:41:57,467 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4457578738530477, 'Total loss': 0.4457578738530477} | train loss {'Reaction outcome loss': 0.3096387684889083, 'Total loss': 0.3096387684889083}
2023-01-04 23:41:57,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:57,467 INFO:     Epoch: 17
2023-01-04 23:41:59,736 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42957329054673515, 'Total loss': 0.42957329054673515} | train loss {'Reaction outcome loss': 0.3048743853739796, 'Total loss': 0.3048743853739796}
2023-01-04 23:41:59,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:41:59,736 INFO:     Epoch: 18
2023-01-04 23:42:01,984 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4300606966018677, 'Total loss': 0.4300606966018677} | train loss {'Reaction outcome loss': 0.2990408931199434, 'Total loss': 0.2990408931199434}
2023-01-04 23:42:01,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:01,985 INFO:     Epoch: 19
2023-01-04 23:42:04,248 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.442283042271932, 'Total loss': 0.442283042271932} | train loss {'Reaction outcome loss': 0.29162188764851893, 'Total loss': 0.29162188764851893}
2023-01-04 23:42:04,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:04,248 INFO:     Epoch: 20
2023-01-04 23:42:06,520 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45576708565155666, 'Total loss': 0.45576708565155666} | train loss {'Reaction outcome loss': 0.2854271503097385, 'Total loss': 0.2854271503097385}
2023-01-04 23:42:06,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:06,521 INFO:     Epoch: 21
2023-01-04 23:42:08,759 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4429449637730916, 'Total loss': 0.4429449637730916} | train loss {'Reaction outcome loss': 0.28314491774696504, 'Total loss': 0.28314491774696504}
2023-01-04 23:42:08,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:08,760 INFO:     Epoch: 22
2023-01-04 23:42:11,015 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47753472526868185, 'Total loss': 0.47753472526868185} | train loss {'Reaction outcome loss': 0.28243820578621254, 'Total loss': 0.28243820578621254}
2023-01-04 23:42:11,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:11,015 INFO:     Epoch: 23
2023-01-04 23:42:13,248 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43993250677982965, 'Total loss': 0.43993250677982965} | train loss {'Reaction outcome loss': 0.2761602871473471, 'Total loss': 0.2761602871473471}
2023-01-04 23:42:13,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:13,249 INFO:     Epoch: 24
2023-01-04 23:42:15,519 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42022371689478555, 'Total loss': 0.42022371689478555} | train loss {'Reaction outcome loss': 0.26839518750997354, 'Total loss': 0.26839518750997354}
2023-01-04 23:42:15,520 INFO:     Found new best model at epoch 24
2023-01-04 23:42:15,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:15,521 INFO:     Epoch: 25
2023-01-04 23:42:17,768 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4406920137504737, 'Total loss': 0.4406920137504737} | train loss {'Reaction outcome loss': 0.26594334063086195, 'Total loss': 0.26594334063086195}
2023-01-04 23:42:17,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:17,768 INFO:     Epoch: 26
2023-01-04 23:42:19,953 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47731601893901826, 'Total loss': 0.47731601893901826} | train loss {'Reaction outcome loss': 0.2568910159238607, 'Total loss': 0.2568910159238607}
2023-01-04 23:42:19,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:19,953 INFO:     Epoch: 27
2023-01-04 23:42:22,202 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45258706212043764, 'Total loss': 0.45258706212043764} | train loss {'Reaction outcome loss': 0.2557720308783498, 'Total loss': 0.2557720308783498}
2023-01-04 23:42:22,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:22,202 INFO:     Epoch: 28
2023-01-04 23:42:24,420 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4284656981627146, 'Total loss': 0.4284656981627146} | train loss {'Reaction outcome loss': 0.2529887363015518, 'Total loss': 0.2529887363015518}
2023-01-04 23:42:24,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:24,420 INFO:     Epoch: 29
2023-01-04 23:42:26,299 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45445094754298526, 'Total loss': 0.45445094754298526} | train loss {'Reaction outcome loss': 0.24639766822385528, 'Total loss': 0.24639766822385528}
2023-01-04 23:42:26,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:26,300 INFO:     Epoch: 30
2023-01-04 23:42:28,136 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43819369971752165, 'Total loss': 0.43819369971752165} | train loss {'Reaction outcome loss': 0.24666527933339133, 'Total loss': 0.24666527933339133}
2023-01-04 23:42:28,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:28,136 INFO:     Epoch: 31
2023-01-04 23:42:30,302 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4777034988005956, 'Total loss': 0.4777034988005956} | train loss {'Reaction outcome loss': 0.2420398683905819, 'Total loss': 0.2420398683905819}
2023-01-04 23:42:30,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:30,302 INFO:     Epoch: 32
2023-01-04 23:42:32,562 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45543358524640404, 'Total loss': 0.45543358524640404} | train loss {'Reaction outcome loss': 0.24336213583167451, 'Total loss': 0.24336213583167451}
2023-01-04 23:42:32,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:32,563 INFO:     Epoch: 33
2023-01-04 23:42:34,813 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5113673528035482, 'Total loss': 0.5113673528035482} | train loss {'Reaction outcome loss': 0.23842099559812868, 'Total loss': 0.23842099559812868}
2023-01-04 23:42:34,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:34,813 INFO:     Epoch: 34
2023-01-04 23:42:37,076 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4473801483710607, 'Total loss': 0.4473801483710607} | train loss {'Reaction outcome loss': 0.23129334487700767, 'Total loss': 0.23129334487700767}
2023-01-04 23:42:37,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:37,076 INFO:     Epoch: 35
2023-01-04 23:42:39,318 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44434939275185265, 'Total loss': 0.44434939275185265} | train loss {'Reaction outcome loss': 0.23002536864067516, 'Total loss': 0.23002536864067516}
2023-01-04 23:42:39,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:39,318 INFO:     Epoch: 36
2023-01-04 23:42:41,535 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4338392600417137, 'Total loss': 0.4338392600417137} | train loss {'Reaction outcome loss': 0.2271172285392663, 'Total loss': 0.2271172285392663}
2023-01-04 23:42:41,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:41,535 INFO:     Epoch: 37
2023-01-04 23:42:43,779 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4533039698998133, 'Total loss': 0.4533039698998133} | train loss {'Reaction outcome loss': 0.2272006362527065, 'Total loss': 0.2272006362527065}
2023-01-04 23:42:43,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:43,780 INFO:     Epoch: 38
2023-01-04 23:42:45,977 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47743182480335233, 'Total loss': 0.47743182480335233} | train loss {'Reaction outcome loss': 0.22272973760527415, 'Total loss': 0.22272973760527415}
2023-01-04 23:42:45,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:45,978 INFO:     Epoch: 39
2023-01-04 23:42:48,214 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5079465597867966, 'Total loss': 0.5079465597867966} | train loss {'Reaction outcome loss': 0.22496232202779637, 'Total loss': 0.22496232202779637}
2023-01-04 23:42:48,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:48,214 INFO:     Epoch: 40
2023-01-04 23:42:50,462 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4565857062737147, 'Total loss': 0.4565857062737147} | train loss {'Reaction outcome loss': 0.22251845821806224, 'Total loss': 0.22251845821806224}
2023-01-04 23:42:50,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:50,463 INFO:     Epoch: 41
2023-01-04 23:42:52,710 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43889073431491854, 'Total loss': 0.43889073431491854} | train loss {'Reaction outcome loss': 0.22144720663595266, 'Total loss': 0.22144720663595266}
2023-01-04 23:42:52,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:52,711 INFO:     Epoch: 42
2023-01-04 23:42:54,972 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4534559448560079, 'Total loss': 0.4534559448560079} | train loss {'Reaction outcome loss': 0.21610363435516827, 'Total loss': 0.21610363435516827}
2023-01-04 23:42:54,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:54,972 INFO:     Epoch: 43
2023-01-04 23:42:57,213 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45634978314240776, 'Total loss': 0.45634978314240776} | train loss {'Reaction outcome loss': 0.2156301363214959, 'Total loss': 0.2156301363214959}
2023-01-04 23:42:57,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:57,214 INFO:     Epoch: 44
2023-01-04 23:42:59,442 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46175636251767477, 'Total loss': 0.46175636251767477} | train loss {'Reaction outcome loss': 0.21102947536278108, 'Total loss': 0.21102947536278108}
2023-01-04 23:42:59,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:42:59,442 INFO:     Epoch: 45
2023-01-04 23:43:01,711 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5032496114571889, 'Total loss': 0.5032496114571889} | train loss {'Reaction outcome loss': 0.2131691496703692, 'Total loss': 0.2131691496703692}
2023-01-04 23:43:01,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:01,711 INFO:     Epoch: 46
2023-01-04 23:43:03,934 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47324629028638204, 'Total loss': 0.47324629028638204} | train loss {'Reaction outcome loss': 0.21419877337332624, 'Total loss': 0.21419877337332624}
2023-01-04 23:43:03,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:03,935 INFO:     Epoch: 47
2023-01-04 23:43:06,195 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45543173849582674, 'Total loss': 0.45543173849582674} | train loss {'Reaction outcome loss': 0.21230056650773452, 'Total loss': 0.21230056650773452}
2023-01-04 23:43:06,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:06,196 INFO:     Epoch: 48
2023-01-04 23:43:08,458 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5016645739475886, 'Total loss': 0.5016645739475886} | train loss {'Reaction outcome loss': 0.20908852640614187, 'Total loss': 0.20908852640614187}
2023-01-04 23:43:08,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:08,458 INFO:     Epoch: 49
2023-01-04 23:43:10,698 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4721095333496729, 'Total loss': 0.4721095333496729} | train loss {'Reaction outcome loss': 0.20804377359399287, 'Total loss': 0.20804377359399287}
2023-01-04 23:43:10,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:10,698 INFO:     Epoch: 50
2023-01-04 23:43:12,970 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48150656521320345, 'Total loss': 0.48150656521320345} | train loss {'Reaction outcome loss': 0.2025418095001747, 'Total loss': 0.2025418095001747}
2023-01-04 23:43:12,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:12,971 INFO:     Epoch: 51
2023-01-04 23:43:15,218 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5193244844675065, 'Total loss': 0.5193244844675065} | train loss {'Reaction outcome loss': 0.20345032490436396, 'Total loss': 0.20345032490436396}
2023-01-04 23:43:15,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:15,218 INFO:     Epoch: 52
2023-01-04 23:43:17,445 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48095625241597495, 'Total loss': 0.48095625241597495} | train loss {'Reaction outcome loss': 0.20187429608573226, 'Total loss': 0.20187429608573226}
2023-01-04 23:43:17,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:17,445 INFO:     Epoch: 53
2023-01-04 23:43:19,705 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46711336920658747, 'Total loss': 0.46711336920658747} | train loss {'Reaction outcome loss': 0.20177784978826768, 'Total loss': 0.20177784978826768}
2023-01-04 23:43:19,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:19,706 INFO:     Epoch: 54
2023-01-04 23:43:21,966 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5029439662893613, 'Total loss': 0.5029439662893613} | train loss {'Reaction outcome loss': 0.2007360240736854, 'Total loss': 0.2007360240736854}
2023-01-04 23:43:21,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:21,967 INFO:     Epoch: 55
2023-01-04 23:43:24,229 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4479743013779322, 'Total loss': 0.4479743013779322} | train loss {'Reaction outcome loss': 0.19481900578405517, 'Total loss': 0.19481900578405517}
2023-01-04 23:43:24,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:24,229 INFO:     Epoch: 56
2023-01-04 23:43:26,421 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5097883492708206, 'Total loss': 0.5097883492708206} | train loss {'Reaction outcome loss': 0.19465152156559656, 'Total loss': 0.19465152156559656}
2023-01-04 23:43:26,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:26,421 INFO:     Epoch: 57
2023-01-04 23:43:28,644 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5144589215517044, 'Total loss': 0.5144589215517044} | train loss {'Reaction outcome loss': 0.19847023331757335, 'Total loss': 0.19847023331757335}
2023-01-04 23:43:28,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:28,644 INFO:     Epoch: 58
2023-01-04 23:43:30,854 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.53448409785827, 'Total loss': 0.53448409785827} | train loss {'Reaction outcome loss': 0.19483326016721336, 'Total loss': 0.19483326016721336}
2023-01-04 23:43:30,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:30,855 INFO:     Epoch: 59
2023-01-04 23:43:33,121 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46626895864804585, 'Total loss': 0.46626895864804585} | train loss {'Reaction outcome loss': 0.19534885851040917, 'Total loss': 0.19534885851040917}
2023-01-04 23:43:33,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:33,122 INFO:     Epoch: 60
2023-01-04 23:43:35,384 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5013277540604274, 'Total loss': 0.5013277540604274} | train loss {'Reaction outcome loss': 0.19468531118753454, 'Total loss': 0.19468531118753454}
2023-01-04 23:43:35,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:35,384 INFO:     Epoch: 61
2023-01-04 23:43:37,569 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48483634342749915, 'Total loss': 0.48483634342749915} | train loss {'Reaction outcome loss': 0.18992958844972463, 'Total loss': 0.18992958844972463}
2023-01-04 23:43:37,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:37,569 INFO:     Epoch: 62
2023-01-04 23:43:39,777 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4782804590960344, 'Total loss': 0.4782804590960344} | train loss {'Reaction outcome loss': 0.1905052326891544, 'Total loss': 0.1905052326891544}
2023-01-04 23:43:39,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:39,777 INFO:     Epoch: 63
2023-01-04 23:43:42,012 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49185728828112285, 'Total loss': 0.49185728828112285} | train loss {'Reaction outcome loss': 0.18452865783682595, 'Total loss': 0.18452865783682595}
2023-01-04 23:43:42,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:42,012 INFO:     Epoch: 64
2023-01-04 23:43:44,234 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47424757679303486, 'Total loss': 0.47424757679303486} | train loss {'Reaction outcome loss': 0.1869241828370812, 'Total loss': 0.1869241828370812}
2023-01-04 23:43:44,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:44,234 INFO:     Epoch: 65
2023-01-04 23:43:46,508 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4577862641463677, 'Total loss': 0.4577862641463677} | train loss {'Reaction outcome loss': 0.18709175989548438, 'Total loss': 0.18709175989548438}
2023-01-04 23:43:46,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:46,508 INFO:     Epoch: 66
2023-01-04 23:43:48,763 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4716121663649877, 'Total loss': 0.4716121663649877} | train loss {'Reaction outcome loss': 0.1893264306012378, 'Total loss': 0.1893264306012378}
2023-01-04 23:43:48,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:48,765 INFO:     Epoch: 67
2023-01-04 23:43:50,958 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49374218185742696, 'Total loss': 0.49374218185742696} | train loss {'Reaction outcome loss': 0.18608865628603602, 'Total loss': 0.18608865628603602}
2023-01-04 23:43:50,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:50,958 INFO:     Epoch: 68
2023-01-04 23:43:53,315 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46150919099648796, 'Total loss': 0.46150919099648796} | train loss {'Reaction outcome loss': 0.1831142153815251, 'Total loss': 0.1831142153815251}
2023-01-04 23:43:53,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:53,315 INFO:     Epoch: 69
2023-01-04 23:43:55,641 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45844930211702983, 'Total loss': 0.45844930211702983} | train loss {'Reaction outcome loss': 0.18582884023768187, 'Total loss': 0.18582884023768187}
2023-01-04 23:43:55,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:55,642 INFO:     Epoch: 70
2023-01-04 23:43:57,814 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45946590006351473, 'Total loss': 0.45946590006351473} | train loss {'Reaction outcome loss': 0.1880639102139993, 'Total loss': 0.1880639102139993}
2023-01-04 23:43:57,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:43:57,814 INFO:     Epoch: 71
2023-01-04 23:44:00,157 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4537879844196141, 'Total loss': 0.4537879844196141} | train loss {'Reaction outcome loss': 0.18048964200854084, 'Total loss': 0.18048964200854084}
2023-01-04 23:44:00,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:00,158 INFO:     Epoch: 72
2023-01-04 23:44:02,435 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4777099033196767, 'Total loss': 0.4777099033196767} | train loss {'Reaction outcome loss': 0.18204472316802908, 'Total loss': 0.18204472316802908}
2023-01-04 23:44:02,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:02,435 INFO:     Epoch: 73
2023-01-04 23:44:04,709 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48513738966236514, 'Total loss': 0.48513738966236514} | train loss {'Reaction outcome loss': 0.17480579664655382, 'Total loss': 0.17480579664655382}
2023-01-04 23:44:04,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:04,710 INFO:     Epoch: 74
2023-01-04 23:44:06,997 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5322330504655838, 'Total loss': 0.5322330504655838} | train loss {'Reaction outcome loss': 0.17893189039543597, 'Total loss': 0.17893189039543597}
2023-01-04 23:44:06,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:06,997 INFO:     Epoch: 75
2023-01-04 23:44:09,285 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4628814918299516, 'Total loss': 0.4628814918299516} | train loss {'Reaction outcome loss': 0.17802196099715184, 'Total loss': 0.17802196099715184}
2023-01-04 23:44:09,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:09,286 INFO:     Epoch: 76
2023-01-04 23:44:11,562 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4714727262655894, 'Total loss': 0.4714727262655894} | train loss {'Reaction outcome loss': 0.17662224647024796, 'Total loss': 0.17662224647024796}
2023-01-04 23:44:11,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:11,562 INFO:     Epoch: 77
2023-01-04 23:44:13,809 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4757506231466929, 'Total loss': 0.4757506231466929} | train loss {'Reaction outcome loss': 0.17834837754243427, 'Total loss': 0.17834837754243427}
2023-01-04 23:44:13,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:13,809 INFO:     Epoch: 78
2023-01-04 23:44:16,081 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48458487366636593, 'Total loss': 0.48458487366636593} | train loss {'Reaction outcome loss': 0.17715499021561584, 'Total loss': 0.17715499021561584}
2023-01-04 23:44:16,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:16,082 INFO:     Epoch: 79
2023-01-04 23:44:18,351 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47875453730424244, 'Total loss': 0.47875453730424244} | train loss {'Reaction outcome loss': 0.18215785468554627, 'Total loss': 0.18215785468554627}
2023-01-04 23:44:18,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:18,351 INFO:     Epoch: 80
2023-01-04 23:44:20,620 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45189577837785083, 'Total loss': 0.45189577837785083} | train loss {'Reaction outcome loss': 0.1716829714769783, 'Total loss': 0.1716829714769783}
2023-01-04 23:44:20,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:20,620 INFO:     Epoch: 81
2023-01-04 23:44:22,894 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5023720860481262, 'Total loss': 0.5023720860481262} | train loss {'Reaction outcome loss': 0.17323803283906386, 'Total loss': 0.17323803283906386}
2023-01-04 23:44:22,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:22,894 INFO:     Epoch: 82
2023-01-04 23:44:25,142 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46239872922499975, 'Total loss': 0.46239872922499975} | train loss {'Reaction outcome loss': 0.17372247089468704, 'Total loss': 0.17372247089468704}
2023-01-04 23:44:25,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:25,143 INFO:     Epoch: 83
2023-01-04 23:44:27,439 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4922619491815567, 'Total loss': 0.4922619491815567} | train loss {'Reaction outcome loss': 0.17452178317645606, 'Total loss': 0.17452178317645606}
2023-01-04 23:44:27,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:27,439 INFO:     Epoch: 84
2023-01-04 23:44:29,692 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4740186060468356, 'Total loss': 0.4740186060468356} | train loss {'Reaction outcome loss': 0.1734659833660227, 'Total loss': 0.1734659833660227}
2023-01-04 23:44:29,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:29,692 INFO:     Epoch: 85
2023-01-04 23:44:31,953 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47034037709236143, 'Total loss': 0.47034037709236143} | train loss {'Reaction outcome loss': 0.17548407288778056, 'Total loss': 0.17548407288778056}
2023-01-04 23:44:31,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:31,954 INFO:     Epoch: 86
2023-01-04 23:44:34,203 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4768421232700348, 'Total loss': 0.4768421232700348} | train loss {'Reaction outcome loss': 0.17619094426614523, 'Total loss': 0.17619094426614523}
2023-01-04 23:44:34,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:34,204 INFO:     Epoch: 87
2023-01-04 23:44:36,445 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4268424580960224, 'Total loss': 0.4268424580960224} | train loss {'Reaction outcome loss': 0.1730863985870659, 'Total loss': 0.1730863985870659}
2023-01-04 23:44:36,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:36,445 INFO:     Epoch: 88
2023-01-04 23:44:38,709 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4556130533417066, 'Total loss': 0.4556130533417066} | train loss {'Reaction outcome loss': 0.17653889376602142, 'Total loss': 0.17653889376602142}
2023-01-04 23:44:38,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:38,710 INFO:     Epoch: 89
2023-01-04 23:44:40,910 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.428107554713885, 'Total loss': 0.428107554713885} | train loss {'Reaction outcome loss': 0.17203258083161158, 'Total loss': 0.17203258083161158}
2023-01-04 23:44:40,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:40,910 INFO:     Epoch: 90
2023-01-04 23:44:43,181 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4803683171669642, 'Total loss': 0.4803683171669642} | train loss {'Reaction outcome loss': 0.16799460149227377, 'Total loss': 0.16799460149227377}
2023-01-04 23:44:43,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:43,181 INFO:     Epoch: 91
2023-01-04 23:44:45,419 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4337308555841446, 'Total loss': 0.4337308555841446} | train loss {'Reaction outcome loss': 0.17108843788117115, 'Total loss': 0.17108843788117115}
2023-01-04 23:44:45,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:45,420 INFO:     Epoch: 92
2023-01-04 23:44:47,681 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49315956731637317, 'Total loss': 0.49315956731637317} | train loss {'Reaction outcome loss': 0.1709179351901649, 'Total loss': 0.1709179351901649}
2023-01-04 23:44:47,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:47,682 INFO:     Epoch: 93
2023-01-04 23:44:49,933 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5016045441230138, 'Total loss': 0.5016045441230138} | train loss {'Reaction outcome loss': 0.17043354224590382, 'Total loss': 0.17043354224590382}
2023-01-04 23:44:49,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:49,933 INFO:     Epoch: 94
2023-01-04 23:44:52,289 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48409116665522256, 'Total loss': 0.48409116665522256} | train loss {'Reaction outcome loss': 0.1681184592745165, 'Total loss': 0.1681184592745165}
2023-01-04 23:44:52,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:52,289 INFO:     Epoch: 95
2023-01-04 23:44:54,636 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46107350938643016, 'Total loss': 0.46107350938643016} | train loss {'Reaction outcome loss': 0.16261524578597206, 'Total loss': 0.16261524578597206}
2023-01-04 23:44:54,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:54,637 INFO:     Epoch: 96
2023-01-04 23:44:56,997 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47855566491683327, 'Total loss': 0.47855566491683327} | train loss {'Reaction outcome loss': 0.1680628922835917, 'Total loss': 0.1680628922835917}
2023-01-04 23:44:56,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:56,997 INFO:     Epoch: 97
2023-01-04 23:44:59,362 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45162343482176465, 'Total loss': 0.45162343482176465} | train loss {'Reaction outcome loss': 0.1712047180660531, 'Total loss': 0.1712047180660531}
2023-01-04 23:44:59,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:44:59,362 INFO:     Epoch: 98
2023-01-04 23:45:01,654 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4927952826023102, 'Total loss': 0.4927952826023102} | train loss {'Reaction outcome loss': 0.16973165635284662, 'Total loss': 0.16973165635284662}
2023-01-04 23:45:01,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:01,656 INFO:     Epoch: 99
2023-01-04 23:45:03,939 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4648821592330933, 'Total loss': 0.4648821592330933} | train loss {'Reaction outcome loss': 0.16926649233061195, 'Total loss': 0.16926649233061195}
2023-01-04 23:45:03,940 INFO:     Best model found after epoch 25 of 100.
2023-01-04 23:45:03,940 INFO:   Done with stage: TRAINING
2023-01-04 23:45:03,940 INFO:   Starting stage: EVALUATION
2023-01-04 23:45:04,082 INFO:   Done with stage: EVALUATION
2023-01-04 23:45:04,082 INFO:   Leaving out SEQ value Fold_2
2023-01-04 23:45:04,095 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 23:45:04,096 INFO:   Starting stage: FEATURE SCALING
2023-01-04 23:45:04,757 INFO:   Done with stage: FEATURE SCALING
2023-01-04 23:45:04,757 INFO:   Starting stage: SCALING TARGETS
2023-01-04 23:45:04,828 INFO:   Done with stage: SCALING TARGETS
2023-01-04 23:45:04,828 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:45:04,829 INFO:     No hyperparam tuning for this model
2023-01-04 23:45:04,829 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:45:04,829 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 23:45:04,829 INFO:     None feature selector for col prot
2023-01-04 23:45:04,830 INFO:     None feature selector for col prot
2023-01-04 23:45:04,830 INFO:     None feature selector for col prot
2023-01-04 23:45:04,830 INFO:     None feature selector for col chem
2023-01-04 23:45:04,830 INFO:     None feature selector for col chem
2023-01-04 23:45:04,830 INFO:     None feature selector for col chem
2023-01-04 23:45:04,830 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 23:45:04,830 INFO:   Starting stage: BUILD MODEL
2023-01-04 23:45:04,832 INFO:     Number of params in model 72931
2023-01-04 23:45:04,835 INFO:   Done with stage: BUILD MODEL
2023-01-04 23:45:04,835 INFO:   Starting stage: TRAINING
2023-01-04 23:45:04,896 INFO:     Val loss before train {'Reaction outcome loss': 0.9914558927218119, 'Total loss': 0.9914558927218119}
2023-01-04 23:45:04,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:04,897 INFO:     Epoch: 0
2023-01-04 23:45:07,185 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7970847884813944, 'Total loss': 0.7970847884813944} | train loss {'Reaction outcome loss': 0.9779440685026888, 'Total loss': 0.9779440685026888}
2023-01-04 23:45:07,185 INFO:     Found new best model at epoch 0
2023-01-04 23:45:07,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:07,186 INFO:     Epoch: 1
2023-01-04 23:45:09,463 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5651018261909485, 'Total loss': 0.5651018261909485} | train loss {'Reaction outcome loss': 0.6908199198112108, 'Total loss': 0.6908199198112108}
2023-01-04 23:45:09,464 INFO:     Found new best model at epoch 1
2023-01-04 23:45:09,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:09,466 INFO:     Epoch: 2
2023-01-04 23:45:11,710 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5271602272987366, 'Total loss': 0.5271602272987366} | train loss {'Reaction outcome loss': 0.5549407285710702, 'Total loss': 0.5549407285710702}
2023-01-04 23:45:11,710 INFO:     Found new best model at epoch 2
2023-01-04 23:45:11,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:11,711 INFO:     Epoch: 3
2023-01-04 23:45:13,972 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49927955865859985, 'Total loss': 0.49927955865859985} | train loss {'Reaction outcome loss': 0.5237344515820345, 'Total loss': 0.5237344515820345}
2023-01-04 23:45:13,972 INFO:     Found new best model at epoch 3
2023-01-04 23:45:13,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:13,973 INFO:     Epoch: 4
2023-01-04 23:45:16,254 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4903413017590841, 'Total loss': 0.4903413017590841} | train loss {'Reaction outcome loss': 0.4887266204877169, 'Total loss': 0.4887266204877169}
2023-01-04 23:45:16,254 INFO:     Found new best model at epoch 4
2023-01-04 23:45:16,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:16,256 INFO:     Epoch: 5
2023-01-04 23:45:18,499 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47642123500506084, 'Total loss': 0.47642123500506084} | train loss {'Reaction outcome loss': 0.4628801834103111, 'Total loss': 0.4628801834103111}
2023-01-04 23:45:18,499 INFO:     Found new best model at epoch 5
2023-01-04 23:45:18,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:18,500 INFO:     Epoch: 6
2023-01-04 23:45:20,768 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48150406281153363, 'Total loss': 0.48150406281153363} | train loss {'Reaction outcome loss': 0.4463777368356366, 'Total loss': 0.4463777368356366}
2023-01-04 23:45:20,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:20,768 INFO:     Epoch: 7
2023-01-04 23:45:23,025 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48067312240600585, 'Total loss': 0.48067312240600585} | train loss {'Reaction outcome loss': 0.42851517497362784, 'Total loss': 0.42851517497362784}
2023-01-04 23:45:23,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:23,026 INFO:     Epoch: 8
2023-01-04 23:45:25,286 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45928342243035636, 'Total loss': 0.45928342243035636} | train loss {'Reaction outcome loss': 0.415335725567749, 'Total loss': 0.415335725567749}
2023-01-04 23:45:25,286 INFO:     Found new best model at epoch 8
2023-01-04 23:45:25,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:25,287 INFO:     Epoch: 9
2023-01-04 23:45:27,564 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46468401153882344, 'Total loss': 0.46468401153882344} | train loss {'Reaction outcome loss': 0.40420465437073355, 'Total loss': 0.40420465437073355}
2023-01-04 23:45:27,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:27,564 INFO:     Epoch: 10
2023-01-04 23:45:29,824 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4775461971759796, 'Total loss': 0.4775461971759796} | train loss {'Reaction outcome loss': 0.3938431313850953, 'Total loss': 0.3938431313850953}
2023-01-04 23:45:29,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:29,824 INFO:     Epoch: 11
2023-01-04 23:45:32,050 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4790122846762339, 'Total loss': 0.4790122846762339} | train loss {'Reaction outcome loss': 0.3845077630240416, 'Total loss': 0.3845077630240416}
2023-01-04 23:45:32,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:32,050 INFO:     Epoch: 12
2023-01-04 23:45:34,329 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45804612735907235, 'Total loss': 0.45804612735907235} | train loss {'Reaction outcome loss': 0.3796852747558045, 'Total loss': 0.3796852747558045}
2023-01-04 23:45:34,329 INFO:     Found new best model at epoch 12
2023-01-04 23:45:34,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:34,330 INFO:     Epoch: 13
2023-01-04 23:45:36,602 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47423698703447975, 'Total loss': 0.47423698703447975} | train loss {'Reaction outcome loss': 0.3600305980948758, 'Total loss': 0.3600305980948758}
2023-01-04 23:45:36,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:36,603 INFO:     Epoch: 14
2023-01-04 23:45:38,880 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4600866953531901, 'Total loss': 0.4600866953531901} | train loss {'Reaction outcome loss': 0.3565619872761485, 'Total loss': 0.3565619872761485}
2023-01-04 23:45:38,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:38,880 INFO:     Epoch: 15
2023-01-04 23:45:41,164 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47548688600460687, 'Total loss': 0.47548688600460687} | train loss {'Reaction outcome loss': 0.34678921233052795, 'Total loss': 0.34678921233052795}
2023-01-04 23:45:41,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:41,164 INFO:     Epoch: 16
2023-01-04 23:45:43,424 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46473768750826516, 'Total loss': 0.46473768750826516} | train loss {'Reaction outcome loss': 0.3387340068516821, 'Total loss': 0.3387340068516821}
2023-01-04 23:45:43,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:43,425 INFO:     Epoch: 17
2023-01-04 23:45:45,653 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45034511387348175, 'Total loss': 0.45034511387348175} | train loss {'Reaction outcome loss': 0.33527311591888725, 'Total loss': 0.33527311591888725}
2023-01-04 23:45:45,653 INFO:     Found new best model at epoch 17
2023-01-04 23:45:45,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:45,654 INFO:     Epoch: 18
2023-01-04 23:45:47,886 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.503364677230517, 'Total loss': 0.503364677230517} | train loss {'Reaction outcome loss': 0.3297287638289044, 'Total loss': 0.3297287638289044}
2023-01-04 23:45:47,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:47,887 INFO:     Epoch: 19
2023-01-04 23:45:50,141 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4645137578248978, 'Total loss': 0.4645137578248978} | train loss {'Reaction outcome loss': 0.32561856031120906, 'Total loss': 0.32561856031120906}
2023-01-04 23:45:50,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:50,141 INFO:     Epoch: 20
2023-01-04 23:45:52,392 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46836619414389136, 'Total loss': 0.46836619414389136} | train loss {'Reaction outcome loss': 0.3197761447965235, 'Total loss': 0.3197761447965235}
2023-01-04 23:45:52,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:52,393 INFO:     Epoch: 21
2023-01-04 23:45:54,661 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48165928224722543, 'Total loss': 0.48165928224722543} | train loss {'Reaction outcome loss': 0.32755563947864796, 'Total loss': 0.32755563947864796}
2023-01-04 23:45:54,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:54,661 INFO:     Epoch: 22
2023-01-04 23:45:56,914 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46785190105438235, 'Total loss': 0.46785190105438235} | train loss {'Reaction outcome loss': 0.3091563105311555, 'Total loss': 0.3091563105311555}
2023-01-04 23:45:56,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:56,915 INFO:     Epoch: 23
2023-01-04 23:45:59,174 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48283477425575255, 'Total loss': 0.48283477425575255} | train loss {'Reaction outcome loss': 0.3023615322561692, 'Total loss': 0.3023615322561692}
2023-01-04 23:45:59,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:45:59,175 INFO:     Epoch: 24
2023-01-04 23:46:01,449 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.468368673324585, 'Total loss': 0.468368673324585} | train loss {'Reaction outcome loss': 0.3012528337451353, 'Total loss': 0.3012528337451353}
2023-01-04 23:46:01,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:01,449 INFO:     Epoch: 25
2023-01-04 23:46:03,698 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4892745703458786, 'Total loss': 0.4892745703458786} | train loss {'Reaction outcome loss': 0.2888887668533784, 'Total loss': 0.2888887668533784}
2023-01-04 23:46:03,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:03,698 INFO:     Epoch: 26
2023-01-04 23:46:05,970 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.462367981672287, 'Total loss': 0.462367981672287} | train loss {'Reaction outcome loss': 0.289970488216647, 'Total loss': 0.289970488216647}
2023-01-04 23:46:05,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:05,970 INFO:     Epoch: 27
2023-01-04 23:46:08,202 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49816582202911375, 'Total loss': 0.49816582202911375} | train loss {'Reaction outcome loss': 0.2881335734129897, 'Total loss': 0.2881335734129897}
2023-01-04 23:46:08,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:08,202 INFO:     Epoch: 28
2023-01-04 23:46:10,472 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4449886580308278, 'Total loss': 0.4449886580308278} | train loss {'Reaction outcome loss': 0.2809284744491932, 'Total loss': 0.2809284744491932}
2023-01-04 23:46:10,472 INFO:     Found new best model at epoch 28
2023-01-04 23:46:10,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:10,473 INFO:     Epoch: 29
2023-01-04 23:46:12,738 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5033376316229502, 'Total loss': 0.5033376316229502} | train loss {'Reaction outcome loss': 0.27953129841615376, 'Total loss': 0.27953129841615376}
2023-01-04 23:46:12,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:12,739 INFO:     Epoch: 30
2023-01-04 23:46:15,018 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48753818273544314, 'Total loss': 0.48753818273544314} | train loss {'Reaction outcome loss': 0.2738302671054887, 'Total loss': 0.2738302671054887}
2023-01-04 23:46:15,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:15,018 INFO:     Epoch: 31
2023-01-04 23:46:17,288 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4937461644411087, 'Total loss': 0.4937461644411087} | train loss {'Reaction outcome loss': 0.2741525142227529, 'Total loss': 0.2741525142227529}
2023-01-04 23:46:17,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:17,288 INFO:     Epoch: 32
2023-01-04 23:46:19,542 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5067995607852935, 'Total loss': 0.5067995607852935} | train loss {'Reaction outcome loss': 0.26773828030327684, 'Total loss': 0.26773828030327684}
2023-01-04 23:46:19,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:19,543 INFO:     Epoch: 33
2023-01-04 23:46:21,794 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4853404499590397, 'Total loss': 0.4853404499590397} | train loss {'Reaction outcome loss': 0.2648854601547878, 'Total loss': 0.2648854601547878}
2023-01-04 23:46:21,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:21,794 INFO:     Epoch: 34
2023-01-04 23:46:24,073 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5324135224024454, 'Total loss': 0.5324135224024454} | train loss {'Reaction outcome loss': 0.25955773827086703, 'Total loss': 0.25955773827086703}
2023-01-04 23:46:24,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:24,074 INFO:     Epoch: 35
2023-01-04 23:46:26,371 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5084812780221303, 'Total loss': 0.5084812780221303} | train loss {'Reaction outcome loss': 0.2581957690569613, 'Total loss': 0.2581957690569613}
2023-01-04 23:46:26,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:26,371 INFO:     Epoch: 36
2023-01-04 23:46:28,730 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5040630002816519, 'Total loss': 0.5040630002816519} | train loss {'Reaction outcome loss': 0.26028013346291595, 'Total loss': 0.26028013346291595}
2023-01-04 23:46:28,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:28,731 INFO:     Epoch: 37
2023-01-04 23:46:30,961 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5283194919427235, 'Total loss': 0.5283194919427235} | train loss {'Reaction outcome loss': 0.2538554881289399, 'Total loss': 0.2538554881289399}
2023-01-04 23:46:30,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:30,961 INFO:     Epoch: 38
2023-01-04 23:46:33,228 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5204759289820989, 'Total loss': 0.5204759289820989} | train loss {'Reaction outcome loss': 0.2517981272173094, 'Total loss': 0.2517981272173094}
2023-01-04 23:46:33,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:33,229 INFO:     Epoch: 39
2023-01-04 23:46:35,509 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5006028852115075, 'Total loss': 0.5006028852115075} | train loss {'Reaction outcome loss': 0.26992745562524034, 'Total loss': 0.26992745562524034}
2023-01-04 23:46:35,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:35,509 INFO:     Epoch: 40
2023-01-04 23:46:37,786 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5300140698750814, 'Total loss': 0.5300140698750814} | train loss {'Reaction outcome loss': 0.24454807473681495, 'Total loss': 0.24454807473681495}
2023-01-04 23:46:37,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:37,787 INFO:     Epoch: 41
2023-01-04 23:46:40,065 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5320227603117625, 'Total loss': 0.5320227603117625} | train loss {'Reaction outcome loss': 0.24954040021892043, 'Total loss': 0.24954040021892043}
2023-01-04 23:46:40,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:40,065 INFO:     Epoch: 42
2023-01-04 23:46:42,354 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5045566558837891, 'Total loss': 0.5045566558837891} | train loss {'Reaction outcome loss': 0.24323806390579641, 'Total loss': 0.24323806390579641}
2023-01-04 23:46:42,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:42,354 INFO:     Epoch: 43
2023-01-04 23:46:44,627 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5365841130415598, 'Total loss': 0.5365841130415598} | train loss {'Reaction outcome loss': 0.24221466188454002, 'Total loss': 0.24221466188454002}
2023-01-04 23:46:44,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:44,628 INFO:     Epoch: 44
2023-01-04 23:46:46,896 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5058241923650105, 'Total loss': 0.5058241923650105} | train loss {'Reaction outcome loss': 0.23368169640636313, 'Total loss': 0.23368169640636313}
2023-01-04 23:46:46,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:46,896 INFO:     Epoch: 45
2023-01-04 23:46:49,159 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5297623574733734, 'Total loss': 0.5297623574733734} | train loss {'Reaction outcome loss': 0.23542300405561167, 'Total loss': 0.23542300405561167}
2023-01-04 23:46:49,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:49,161 INFO:     Epoch: 46
2023-01-04 23:46:51,385 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5361855695645015, 'Total loss': 0.5361855695645015} | train loss {'Reaction outcome loss': 0.25216595458956703, 'Total loss': 0.25216595458956703}
2023-01-04 23:46:51,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:51,385 INFO:     Epoch: 47
2023-01-04 23:46:53,585 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5273865560690562, 'Total loss': 0.5273865560690562} | train loss {'Reaction outcome loss': 0.2363741740203071, 'Total loss': 0.2363741740203071}
2023-01-04 23:46:53,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:53,585 INFO:     Epoch: 48
2023-01-04 23:46:55,789 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5245217770338059, 'Total loss': 0.5245217770338059} | train loss {'Reaction outcome loss': 0.22999988720023437, 'Total loss': 0.22999988720023437}
2023-01-04 23:46:55,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:55,790 INFO:     Epoch: 49
2023-01-04 23:46:58,075 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5560407350460689, 'Total loss': 0.5560407350460689} | train loss {'Reaction outcome loss': 0.22443090257761272, 'Total loss': 0.22443090257761272}
2023-01-04 23:46:58,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:46:58,075 INFO:     Epoch: 50
2023-01-04 23:47:00,333 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5613882740338644, 'Total loss': 0.5613882740338644} | train loss {'Reaction outcome loss': 0.24168202052501525, 'Total loss': 0.24168202052501525}
2023-01-04 23:47:00,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:00,333 INFO:     Epoch: 51
2023-01-04 23:47:02,596 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5211858153343201, 'Total loss': 0.5211858153343201} | train loss {'Reaction outcome loss': 0.22343363343279107, 'Total loss': 0.22343363343279107}
2023-01-04 23:47:02,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:02,596 INFO:     Epoch: 52
2023-01-04 23:47:04,798 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5332948525746664, 'Total loss': 0.5332948525746664} | train loss {'Reaction outcome loss': 0.24793948013119507, 'Total loss': 0.24793948013119507}
2023-01-04 23:47:04,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:04,798 INFO:     Epoch: 53
2023-01-04 23:47:07,057 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5276003549496333, 'Total loss': 0.5276003549496333} | train loss {'Reaction outcome loss': 0.22486175682591408, 'Total loss': 0.22486175682591408}
2023-01-04 23:47:07,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:07,057 INFO:     Epoch: 54
2023-01-04 23:47:09,333 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5157660365104675, 'Total loss': 0.5157660365104675} | train loss {'Reaction outcome loss': 0.21774462226797672, 'Total loss': 0.21774462226797672}
2023-01-04 23:47:09,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:09,334 INFO:     Epoch: 55
2023-01-04 23:47:11,544 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5402480681737264, 'Total loss': 0.5402480681737264} | train loss {'Reaction outcome loss': 0.22172864742469098, 'Total loss': 0.22172864742469098}
2023-01-04 23:47:11,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:11,545 INFO:     Epoch: 56
2023-01-04 23:47:13,817 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5406239420175553, 'Total loss': 0.5406239420175553} | train loss {'Reaction outcome loss': 0.21845772175077835, 'Total loss': 0.21845772175077835}
2023-01-04 23:47:13,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:13,818 INFO:     Epoch: 57
2023-01-04 23:47:16,089 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5654125074545543, 'Total loss': 0.5654125074545543} | train loss {'Reaction outcome loss': 0.21743760676295293, 'Total loss': 0.21743760676295293}
2023-01-04 23:47:16,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:16,089 INFO:     Epoch: 58
2023-01-04 23:47:18,347 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.521072926123937, 'Total loss': 0.521072926123937} | train loss {'Reaction outcome loss': 0.2251981748672931, 'Total loss': 0.2251981748672931}
2023-01-04 23:47:18,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:18,347 INFO:     Epoch: 59
2023-01-04 23:47:20,618 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5329797367254893, 'Total loss': 0.5329797367254893} | train loss {'Reaction outcome loss': 0.23444168101591262, 'Total loss': 0.23444168101591262}
2023-01-04 23:47:20,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:20,619 INFO:     Epoch: 60
2023-01-04 23:47:22,869 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5257306357224782, 'Total loss': 0.5257306357224782} | train loss {'Reaction outcome loss': 0.22464288698266383, 'Total loss': 0.22464288698266383}
2023-01-04 23:47:22,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:22,869 INFO:     Epoch: 61
2023-01-04 23:47:25,058 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5341202239195506, 'Total loss': 0.5341202239195506} | train loss {'Reaction outcome loss': 0.22278437727009473, 'Total loss': 0.22278437727009473}
2023-01-04 23:47:25,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:25,059 INFO:     Epoch: 62
2023-01-04 23:47:27,334 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5378718574841818, 'Total loss': 0.5378718574841818} | train loss {'Reaction outcome loss': 0.2235032492485977, 'Total loss': 0.2235032492485977}
2023-01-04 23:47:27,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:27,334 INFO:     Epoch: 63
2023-01-04 23:47:29,596 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5525396843751271, 'Total loss': 0.5525396843751271} | train loss {'Reaction outcome loss': 0.2276453107588695, 'Total loss': 0.2276453107588695}
2023-01-04 23:47:29,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:29,596 INFO:     Epoch: 64
2023-01-04 23:47:31,829 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5523265928030014, 'Total loss': 0.5523265928030014} | train loss {'Reaction outcome loss': 0.21670347622737451, 'Total loss': 0.21670347622737451}
2023-01-04 23:47:31,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:31,830 INFO:     Epoch: 65
2023-01-04 23:47:34,082 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5401892244815827, 'Total loss': 0.5401892244815827} | train loss {'Reaction outcome loss': 0.21754942704970692, 'Total loss': 0.21754942704970692}
2023-01-04 23:47:34,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:34,082 INFO:     Epoch: 66
2023-01-04 23:47:36,349 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5285018811623255, 'Total loss': 0.5285018811623255} | train loss {'Reaction outcome loss': 0.2116342601916783, 'Total loss': 0.2116342601916783}
2023-01-04 23:47:36,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:36,349 INFO:     Epoch: 67
2023-01-04 23:47:38,619 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.523341896229734, 'Total loss': 0.523341896229734} | train loss {'Reaction outcome loss': 0.21435761804056802, 'Total loss': 0.21435761804056802}
2023-01-04 23:47:38,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:38,619 INFO:     Epoch: 68
2023-01-04 23:47:40,897 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5449159642060598, 'Total loss': 0.5449159642060598} | train loss {'Reaction outcome loss': 0.21606316761302669, 'Total loss': 0.21606316761302669}
2023-01-04 23:47:40,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:40,897 INFO:     Epoch: 69
2023-01-04 23:47:43,162 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5423350056012471, 'Total loss': 0.5423350056012471} | train loss {'Reaction outcome loss': 0.21542637670147774, 'Total loss': 0.21542637670147774}
2023-01-04 23:47:43,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:43,163 INFO:     Epoch: 70
2023-01-04 23:47:45,411 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5483079175154368, 'Total loss': 0.5483079175154368} | train loss {'Reaction outcome loss': 0.21905910073563564, 'Total loss': 0.21905910073563564}
2023-01-04 23:47:45,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:45,412 INFO:     Epoch: 71
2023-01-04 23:47:47,689 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5414686322212219, 'Total loss': 0.5414686322212219} | train loss {'Reaction outcome loss': 0.21620802799873712, 'Total loss': 0.21620802799873712}
2023-01-04 23:47:47,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:47,689 INFO:     Epoch: 72
2023-01-04 23:47:49,964 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5334558725357056, 'Total loss': 0.5334558725357056} | train loss {'Reaction outcome loss': 0.210293437877292, 'Total loss': 0.210293437877292}
2023-01-04 23:47:49,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:49,964 INFO:     Epoch: 73
2023-01-04 23:47:52,241 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5440146694580714, 'Total loss': 0.5440146694580714} | train loss {'Reaction outcome loss': 0.2073702093882763, 'Total loss': 0.2073702093882763}
2023-01-04 23:47:52,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:52,241 INFO:     Epoch: 74
2023-01-04 23:47:54,499 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5033476014931997, 'Total loss': 0.5033476014931997} | train loss {'Reaction outcome loss': 0.23543967456772816, 'Total loss': 0.23543967456772816}
2023-01-04 23:47:54,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:54,500 INFO:     Epoch: 75
2023-01-04 23:47:56,765 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5243670026461283, 'Total loss': 0.5243670026461283} | train loss {'Reaction outcome loss': 0.21211841644844096, 'Total loss': 0.21211841644844096}
2023-01-04 23:47:56,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:56,765 INFO:     Epoch: 76
2023-01-04 23:47:59,049 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5562352403998375, 'Total loss': 0.5562352403998375} | train loss {'Reaction outcome loss': 0.20680058878117605, 'Total loss': 0.20680058878117605}
2023-01-04 23:47:59,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:47:59,049 INFO:     Epoch: 77
2023-01-04 23:48:01,359 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5227079570293427, 'Total loss': 0.5227079570293427} | train loss {'Reaction outcome loss': 0.2056120102499625, 'Total loss': 0.2056120102499625}
2023-01-04 23:48:01,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:01,361 INFO:     Epoch: 78
2023-01-04 23:48:03,705 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5573826829592387, 'Total loss': 0.5573826829592387} | train loss {'Reaction outcome loss': 0.20459083407658382, 'Total loss': 0.20459083407658382}
2023-01-04 23:48:03,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:03,705 INFO:     Epoch: 79
2023-01-04 23:48:06,008 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5551271855831146, 'Total loss': 0.5551271855831146} | train loss {'Reaction outcome loss': 0.22587046902533958, 'Total loss': 0.22587046902533958}
2023-01-04 23:48:06,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:06,008 INFO:     Epoch: 80
2023-01-04 23:48:08,096 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.537881824374199, 'Total loss': 0.537881824374199} | train loss {'Reaction outcome loss': 0.20384806414317017, 'Total loss': 0.20384806414317017}
2023-01-04 23:48:08,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:08,097 INFO:     Epoch: 81
2023-01-04 23:48:10,373 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5548674921194713, 'Total loss': 0.5548674921194713} | train loss {'Reaction outcome loss': 0.19629463564648386, 'Total loss': 0.19629463564648386}
2023-01-04 23:48:10,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:10,374 INFO:     Epoch: 82
2023-01-04 23:48:12,655 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5680103401343027, 'Total loss': 0.5680103401343027} | train loss {'Reaction outcome loss': 0.19861507403940146, 'Total loss': 0.19861507403940146}
2023-01-04 23:48:12,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:12,655 INFO:     Epoch: 83
2023-01-04 23:48:14,904 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.540154763062795, 'Total loss': 0.540154763062795} | train loss {'Reaction outcome loss': 0.19945087044792, 'Total loss': 0.19945087044792}
2023-01-04 23:48:14,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:14,904 INFO:     Epoch: 84
2023-01-04 23:48:17,133 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5161734438656519, 'Total loss': 0.5161734438656519} | train loss {'Reaction outcome loss': 0.19389326227457682, 'Total loss': 0.19389326227457682}
2023-01-04 23:48:17,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:17,133 INFO:     Epoch: 85
2023-01-04 23:48:19,410 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5372719029585521, 'Total loss': 0.5372719029585521} | train loss {'Reaction outcome loss': 0.1945325559683387, 'Total loss': 0.1945325559683387}
2023-01-04 23:48:19,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:19,410 INFO:     Epoch: 86
2023-01-04 23:48:21,685 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5654333353042602, 'Total loss': 0.5654333353042602} | train loss {'Reaction outcome loss': 0.19282647143320544, 'Total loss': 0.19282647143320544}
2023-01-04 23:48:21,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:21,686 INFO:     Epoch: 87
2023-01-04 23:48:23,970 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5222475528717041, 'Total loss': 0.5222475528717041} | train loss {'Reaction outcome loss': 0.19932256385758249, 'Total loss': 0.19932256385758249}
2023-01-04 23:48:23,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:23,970 INFO:     Epoch: 88
2023-01-04 23:48:26,266 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5245446364084879, 'Total loss': 0.5245446364084879} | train loss {'Reaction outcome loss': 0.19405157377680196, 'Total loss': 0.19405157377680196}
2023-01-04 23:48:26,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:26,267 INFO:     Epoch: 89
2023-01-04 23:48:28,544 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5450669089953105, 'Total loss': 0.5450669089953105} | train loss {'Reaction outcome loss': 0.18722663910391377, 'Total loss': 0.18722663910391377}
2023-01-04 23:48:28,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:28,545 INFO:     Epoch: 90
2023-01-04 23:48:30,841 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5357362866401673, 'Total loss': 0.5357362866401673} | train loss {'Reaction outcome loss': 0.19040421459285953, 'Total loss': 0.19040421459285953}
2023-01-04 23:48:30,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:30,843 INFO:     Epoch: 91
2023-01-04 23:48:33,115 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5261727790037791, 'Total loss': 0.5261727790037791} | train loss {'Reaction outcome loss': 0.18914961419490073, 'Total loss': 0.18914961419490073}
2023-01-04 23:48:33,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:33,115 INFO:     Epoch: 92
2023-01-04 23:48:35,410 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5289069732030233, 'Total loss': 0.5289069732030233} | train loss {'Reaction outcome loss': 0.18876560815781399, 'Total loss': 0.18876560815781399}
2023-01-04 23:48:35,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:35,410 INFO:     Epoch: 93
2023-01-04 23:48:37,689 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5261803224682808, 'Total loss': 0.5261803224682808} | train loss {'Reaction outcome loss': 0.19190558320617024, 'Total loss': 0.19190558320617024}
2023-01-04 23:48:37,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:37,690 INFO:     Epoch: 94
2023-01-04 23:48:39,951 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5455436487992604, 'Total loss': 0.5455436487992604} | train loss {'Reaction outcome loss': 0.19261884763904347, 'Total loss': 0.19261884763904347}
2023-01-04 23:48:39,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:39,952 INFO:     Epoch: 95
2023-01-04 23:48:42,233 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5575632234414418, 'Total loss': 0.5575632234414418} | train loss {'Reaction outcome loss': 0.19727866987565337, 'Total loss': 0.19727866987565337}
2023-01-04 23:48:42,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:42,233 INFO:     Epoch: 96
2023-01-04 23:48:44,486 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5307739506165187, 'Total loss': 0.5307739506165187} | train loss {'Reaction outcome loss': 0.18950710747099103, 'Total loss': 0.18950710747099103}
2023-01-04 23:48:44,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:44,486 INFO:     Epoch: 97
2023-01-04 23:48:46,768 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5394448320070903, 'Total loss': 0.5394448320070903} | train loss {'Reaction outcome loss': 0.18557611331546112, 'Total loss': 0.18557611331546112}
2023-01-04 23:48:46,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:46,769 INFO:     Epoch: 98
2023-01-04 23:48:48,945 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5263794971474757, 'Total loss': 0.5263794971474757} | train loss {'Reaction outcome loss': 0.18557383047036213, 'Total loss': 0.18557383047036213}
2023-01-04 23:48:48,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:48,946 INFO:     Epoch: 99
2023-01-04 23:48:51,197 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5254899144172669, 'Total loss': 0.5254899144172669} | train loss {'Reaction outcome loss': 0.189078079756734, 'Total loss': 0.189078079756734}
2023-01-04 23:48:51,197 INFO:     Best model found after epoch 29 of 100.
2023-01-04 23:48:51,198 INFO:   Done with stage: TRAINING
2023-01-04 23:48:51,198 INFO:   Starting stage: EVALUATION
2023-01-04 23:48:51,335 INFO:   Done with stage: EVALUATION
2023-01-04 23:48:51,335 INFO:   Leaving out SEQ value Fold_3
2023-01-04 23:48:51,348 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 23:48:51,348 INFO:   Starting stage: FEATURE SCALING
2023-01-04 23:48:52,008 INFO:   Done with stage: FEATURE SCALING
2023-01-04 23:48:52,008 INFO:   Starting stage: SCALING TARGETS
2023-01-04 23:48:52,080 INFO:   Done with stage: SCALING TARGETS
2023-01-04 23:48:52,080 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:48:52,080 INFO:     No hyperparam tuning for this model
2023-01-04 23:48:52,080 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:48:52,080 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 23:48:52,081 INFO:     None feature selector for col prot
2023-01-04 23:48:52,081 INFO:     None feature selector for col prot
2023-01-04 23:48:52,081 INFO:     None feature selector for col prot
2023-01-04 23:48:52,082 INFO:     None feature selector for col chem
2023-01-04 23:48:52,082 INFO:     None feature selector for col chem
2023-01-04 23:48:52,082 INFO:     None feature selector for col chem
2023-01-04 23:48:52,082 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 23:48:52,082 INFO:   Starting stage: BUILD MODEL
2023-01-04 23:48:52,083 INFO:     Number of params in model 72931
2023-01-04 23:48:52,087 INFO:   Done with stage: BUILD MODEL
2023-01-04 23:48:52,087 INFO:   Starting stage: TRAINING
2023-01-04 23:48:52,147 INFO:     Val loss before train {'Reaction outcome loss': 1.047098845243454, 'Total loss': 1.047098845243454}
2023-01-04 23:48:52,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:52,147 INFO:     Epoch: 0
2023-01-04 23:48:54,390 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8378578106562297, 'Total loss': 0.8378578106562297} | train loss {'Reaction outcome loss': 0.9721889347925673, 'Total loss': 0.9721889347925673}
2023-01-04 23:48:54,391 INFO:     Found new best model at epoch 0
2023-01-04 23:48:54,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:54,392 INFO:     Epoch: 1
2023-01-04 23:48:56,628 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.603476220369339, 'Total loss': 0.603476220369339} | train loss {'Reaction outcome loss': 0.6594194794332024, 'Total loss': 0.6594194794332024}
2023-01-04 23:48:56,628 INFO:     Found new best model at epoch 1
2023-01-04 23:48:56,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:56,630 INFO:     Epoch: 2
2023-01-04 23:48:58,895 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5898932655652364, 'Total loss': 0.5898932655652364} | train loss {'Reaction outcome loss': 0.5407773160042554, 'Total loss': 0.5407773160042554}
2023-01-04 23:48:58,895 INFO:     Found new best model at epoch 2
2023-01-04 23:48:58,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:48:58,897 INFO:     Epoch: 3
2023-01-04 23:49:01,145 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5792493879795074, 'Total loss': 0.5792493879795074} | train loss {'Reaction outcome loss': 0.5027251146788144, 'Total loss': 0.5027251146788144}
2023-01-04 23:49:01,145 INFO:     Found new best model at epoch 3
2023-01-04 23:49:01,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:01,147 INFO:     Epoch: 4
2023-01-04 23:49:03,372 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5567256867885589, 'Total loss': 0.5567256867885589} | train loss {'Reaction outcome loss': 0.47643354763514806, 'Total loss': 0.47643354763514806}
2023-01-04 23:49:03,372 INFO:     Found new best model at epoch 4
2023-01-04 23:49:03,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:03,374 INFO:     Epoch: 5
2023-01-04 23:49:05,641 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5481572687625885, 'Total loss': 0.5481572687625885} | train loss {'Reaction outcome loss': 0.45817971517787365, 'Total loss': 0.45817971517787365}
2023-01-04 23:49:05,641 INFO:     Found new best model at epoch 5
2023-01-04 23:49:05,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:05,642 INFO:     Epoch: 6
2023-01-04 23:49:07,881 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5271367132663727, 'Total loss': 0.5271367132663727} | train loss {'Reaction outcome loss': 0.44158172066303064, 'Total loss': 0.44158172066303064}
2023-01-04 23:49:07,882 INFO:     Found new best model at epoch 6
2023-01-04 23:49:07,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:07,884 INFO:     Epoch: 7
2023-01-04 23:49:10,149 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5425630748271942, 'Total loss': 0.5425630748271942} | train loss {'Reaction outcome loss': 0.43078397249762157, 'Total loss': 0.43078397249762157}
2023-01-04 23:49:10,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:10,149 INFO:     Epoch: 8
2023-01-04 23:49:12,411 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4951227128505707, 'Total loss': 0.4951227128505707} | train loss {'Reaction outcome loss': 0.4167705686749333, 'Total loss': 0.4167705686749333}
2023-01-04 23:49:12,411 INFO:     Found new best model at epoch 8
2023-01-04 23:49:12,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:12,412 INFO:     Epoch: 9
2023-01-04 23:49:14,649 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49601803421974183, 'Total loss': 0.49601803421974183} | train loss {'Reaction outcome loss': 0.40825752179770575, 'Total loss': 0.40825752179770575}
2023-01-04 23:49:14,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:14,650 INFO:     Epoch: 10
2023-01-04 23:49:16,906 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4945923924446106, 'Total loss': 0.4945923924446106} | train loss {'Reaction outcome loss': 0.3998570819895198, 'Total loss': 0.3998570819895198}
2023-01-04 23:49:16,906 INFO:     Found new best model at epoch 10
2023-01-04 23:49:16,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:16,908 INFO:     Epoch: 11
2023-01-04 23:49:19,151 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5018963734308879, 'Total loss': 0.5018963734308879} | train loss {'Reaction outcome loss': 0.39222419302720224, 'Total loss': 0.39222419302720224}
2023-01-04 23:49:19,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:19,151 INFO:     Epoch: 12
2023-01-04 23:49:21,414 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4986438949902852, 'Total loss': 0.4986438949902852} | train loss {'Reaction outcome loss': 0.38050463039727106, 'Total loss': 0.38050463039727106}
2023-01-04 23:49:21,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:21,414 INFO:     Epoch: 13
2023-01-04 23:49:23,674 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4969775160153707, 'Total loss': 0.4969775160153707} | train loss {'Reaction outcome loss': 0.37681832036724056, 'Total loss': 0.37681832036724056}
2023-01-04 23:49:23,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:23,674 INFO:     Epoch: 14
2023-01-04 23:49:25,901 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5072121620178223, 'Total loss': 0.5072121620178223} | train loss {'Reaction outcome loss': 0.3672598888349794, 'Total loss': 0.3672598888349794}
2023-01-04 23:49:25,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:25,901 INFO:     Epoch: 15
2023-01-04 23:49:28,145 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4887740602095922, 'Total loss': 0.4887740602095922} | train loss {'Reaction outcome loss': 0.3613777529366695, 'Total loss': 0.3613777529366695}
2023-01-04 23:49:28,146 INFO:     Found new best model at epoch 15
2023-01-04 23:49:28,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:28,147 INFO:     Epoch: 16
2023-01-04 23:49:30,310 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47941765089829763, 'Total loss': 0.47941765089829763} | train loss {'Reaction outcome loss': 0.35111916652561104, 'Total loss': 0.35111916652561104}
2023-01-04 23:49:30,310 INFO:     Found new best model at epoch 16
2023-01-04 23:49:30,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:30,312 INFO:     Epoch: 17
2023-01-04 23:49:32,564 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4599467049042384, 'Total loss': 0.4599467049042384} | train loss {'Reaction outcome loss': 0.34387095791906336, 'Total loss': 0.34387095791906336}
2023-01-04 23:49:32,564 INFO:     Found new best model at epoch 17
2023-01-04 23:49:32,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:32,565 INFO:     Epoch: 18
2023-01-04 23:49:34,821 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47649478117624916, 'Total loss': 0.47649478117624916} | train loss {'Reaction outcome loss': 0.34016278781758175, 'Total loss': 0.34016278781758175}
2023-01-04 23:49:34,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:34,822 INFO:     Epoch: 19
2023-01-04 23:49:36,955 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45524922410647073, 'Total loss': 0.45524922410647073} | train loss {'Reaction outcome loss': 0.33341989674381095, 'Total loss': 0.33341989674381095}
2023-01-04 23:49:36,956 INFO:     Found new best model at epoch 19
2023-01-04 23:49:36,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:36,957 INFO:     Epoch: 20
2023-01-04 23:49:39,204 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49099629918734233, 'Total loss': 0.49099629918734233} | train loss {'Reaction outcome loss': 0.32712694216709937, 'Total loss': 0.32712694216709937}
2023-01-04 23:49:39,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:39,204 INFO:     Epoch: 21
2023-01-04 23:49:41,429 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4905530909697215, 'Total loss': 0.4905530909697215} | train loss {'Reaction outcome loss': 0.3194863145803883, 'Total loss': 0.3194863145803883}
2023-01-04 23:49:41,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:41,429 INFO:     Epoch: 22
2023-01-04 23:49:43,661 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4635069360335668, 'Total loss': 0.4635069360335668} | train loss {'Reaction outcome loss': 0.3156134765187319, 'Total loss': 0.3156134765187319}
2023-01-04 23:49:43,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:43,662 INFO:     Epoch: 23
2023-01-04 23:49:45,920 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48779605428377787, 'Total loss': 0.48779605428377787} | train loss {'Reaction outcome loss': 0.3124159740107338, 'Total loss': 0.3124159740107338}
2023-01-04 23:49:45,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:45,920 INFO:     Epoch: 24
2023-01-04 23:49:48,183 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5192339807748795, 'Total loss': 0.5192339807748795} | train loss {'Reaction outcome loss': 0.30380216833666296, 'Total loss': 0.30380216833666296}
2023-01-04 23:49:48,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:48,183 INFO:     Epoch: 25
2023-01-04 23:49:50,313 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48480913241704304, 'Total loss': 0.48480913241704304} | train loss {'Reaction outcome loss': 0.3001149553452095, 'Total loss': 0.3001149553452095}
2023-01-04 23:49:50,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:50,313 INFO:     Epoch: 26
2023-01-04 23:49:52,554 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4648581047852834, 'Total loss': 0.4648581047852834} | train loss {'Reaction outcome loss': 0.29466425967368765, 'Total loss': 0.29466425967368765}
2023-01-04 23:49:52,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:52,554 INFO:     Epoch: 27
2023-01-04 23:49:54,736 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49989821910858157, 'Total loss': 0.49989821910858157} | train loss {'Reaction outcome loss': 0.291302034495412, 'Total loss': 0.291302034495412}
2023-01-04 23:49:54,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:54,737 INFO:     Epoch: 28
2023-01-04 23:49:56,987 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46275305449962617, 'Total loss': 0.46275305449962617} | train loss {'Reaction outcome loss': 0.2858519850122015, 'Total loss': 0.2858519850122015}
2023-01-04 23:49:56,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:56,988 INFO:     Epoch: 29
2023-01-04 23:49:59,226 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49879588683446247, 'Total loss': 0.49879588683446247} | train loss {'Reaction outcome loss': 0.2786929071439009, 'Total loss': 0.2786929071439009}
2023-01-04 23:49:59,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:49:59,226 INFO:     Epoch: 30
2023-01-04 23:50:01,468 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4747347245613734, 'Total loss': 0.4747347245613734} | train loss {'Reaction outcome loss': 0.27766717993484363, 'Total loss': 0.27766717993484363}
2023-01-04 23:50:01,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:01,468 INFO:     Epoch: 31
2023-01-04 23:50:03,893 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4604618782798449, 'Total loss': 0.4604618782798449} | train loss {'Reaction outcome loss': 0.27375085301099034, 'Total loss': 0.27375085301099034}
2023-01-04 23:50:03,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:03,893 INFO:     Epoch: 32
2023-01-04 23:50:06,188 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4893864813571175, 'Total loss': 0.4893864813571175} | train loss {'Reaction outcome loss': 0.26514868846122364, 'Total loss': 0.26514868846122364}
2023-01-04 23:50:06,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:06,188 INFO:     Epoch: 33
2023-01-04 23:50:08,490 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5130183259646098, 'Total loss': 0.5130183259646098} | train loss {'Reaction outcome loss': 0.2635941378377976, 'Total loss': 0.2635941378377976}
2023-01-04 23:50:08,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:08,490 INFO:     Epoch: 34
2023-01-04 23:50:10,723 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5063373039166132, 'Total loss': 0.5063373039166132} | train loss {'Reaction outcome loss': 0.25953809517252185, 'Total loss': 0.25953809517252185}
2023-01-04 23:50:10,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:10,723 INFO:     Epoch: 35
2023-01-04 23:50:12,923 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48682942409068347, 'Total loss': 0.48682942409068347} | train loss {'Reaction outcome loss': 0.25749514063643497, 'Total loss': 0.25749514063643497}
2023-01-04 23:50:12,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:12,924 INFO:     Epoch: 36
2023-01-04 23:50:15,164 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.48554211258888247, 'Total loss': 0.48554211258888247} | train loss {'Reaction outcome loss': 0.2535851913415929, 'Total loss': 0.2535851913415929}
2023-01-04 23:50:15,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:15,165 INFO:     Epoch: 37
2023-01-04 23:50:17,382 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.523426067829132, 'Total loss': 0.523426067829132} | train loss {'Reaction outcome loss': 0.24933185313495188, 'Total loss': 0.24933185313495188}
2023-01-04 23:50:17,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:17,382 INFO:     Epoch: 38
2023-01-04 23:50:19,629 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46236011385917664, 'Total loss': 0.46236011385917664} | train loss {'Reaction outcome loss': 0.2469477490419998, 'Total loss': 0.2469477490419998}
2023-01-04 23:50:19,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:19,630 INFO:     Epoch: 39
2023-01-04 23:50:21,856 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5208446264266968, 'Total loss': 0.5208446264266968} | train loss {'Reaction outcome loss': 0.24545399113864141, 'Total loss': 0.24545399113864141}
2023-01-04 23:50:21,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:21,856 INFO:     Epoch: 40
2023-01-04 23:50:24,061 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5226737707853317, 'Total loss': 0.5226737707853317} | train loss {'Reaction outcome loss': 0.23914959021320525, 'Total loss': 0.23914959021320525}
2023-01-04 23:50:24,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:24,061 INFO:     Epoch: 41
2023-01-04 23:50:26,307 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5297216693560283, 'Total loss': 0.5297216693560283} | train loss {'Reaction outcome loss': 0.23813704386639006, 'Total loss': 0.23813704386639006}
2023-01-04 23:50:26,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:26,307 INFO:     Epoch: 42
2023-01-04 23:50:28,480 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4868026912212372, 'Total loss': 0.4868026912212372} | train loss {'Reaction outcome loss': 0.23090266882965382, 'Total loss': 0.23090266882965382}
2023-01-04 23:50:28,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:28,480 INFO:     Epoch: 43
2023-01-04 23:50:30,711 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5152912100156148, 'Total loss': 0.5152912100156148} | train loss {'Reaction outcome loss': 0.2341675160887794, 'Total loss': 0.2341675160887794}
2023-01-04 23:50:30,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:30,712 INFO:     Epoch: 44
2023-01-04 23:50:32,966 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5154247025648753, 'Total loss': 0.5154247025648753} | train loss {'Reaction outcome loss': 0.22860854217633061, 'Total loss': 0.22860854217633061}
2023-01-04 23:50:32,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:32,967 INFO:     Epoch: 45
2023-01-04 23:50:35,093 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5099954674641292, 'Total loss': 0.5099954674641292} | train loss {'Reaction outcome loss': 0.22912122991724607, 'Total loss': 0.22912122991724607}
2023-01-04 23:50:35,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:35,094 INFO:     Epoch: 46
2023-01-04 23:50:37,344 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48804236153761543, 'Total loss': 0.48804236153761543} | train loss {'Reaction outcome loss': 0.22693076720937108, 'Total loss': 0.22693076720937108}
2023-01-04 23:50:37,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:37,345 INFO:     Epoch: 47
2023-01-04 23:50:39,593 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47933231194814047, 'Total loss': 0.47933231194814047} | train loss {'Reaction outcome loss': 0.22399166189677958, 'Total loss': 0.22399166189677958}
2023-01-04 23:50:39,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:39,593 INFO:     Epoch: 48
2023-01-04 23:50:41,829 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47986327707767484, 'Total loss': 0.47986327707767484} | train loss {'Reaction outcome loss': 0.22051383671860625, 'Total loss': 0.22051383671860625}
2023-01-04 23:50:41,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:41,829 INFO:     Epoch: 49
2023-01-04 23:50:44,071 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.557126537958781, 'Total loss': 0.557126537958781} | train loss {'Reaction outcome loss': 0.2195991914766929, 'Total loss': 0.2195991914766929}
2023-01-04 23:50:44,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:44,071 INFO:     Epoch: 50
2023-01-04 23:50:46,318 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5244980365037918, 'Total loss': 0.5244980365037918} | train loss {'Reaction outcome loss': 0.22129029264659994, 'Total loss': 0.22129029264659994}
2023-01-04 23:50:46,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:46,318 INFO:     Epoch: 51
2023-01-04 23:50:48,549 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5366836229960124, 'Total loss': 0.5366836229960124} | train loss {'Reaction outcome loss': 0.21016404934968447, 'Total loss': 0.21016404934968447}
2023-01-04 23:50:48,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:48,550 INFO:     Epoch: 52
2023-01-04 23:50:50,805 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4833542168140411, 'Total loss': 0.4833542168140411} | train loss {'Reaction outcome loss': 0.2129885425084155, 'Total loss': 0.2129885425084155}
2023-01-04 23:50:50,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:50,805 INFO:     Epoch: 53
2023-01-04 23:50:53,046 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5094995588064194, 'Total loss': 0.5094995588064194} | train loss {'Reaction outcome loss': 0.2146250062289029, 'Total loss': 0.2146250062289029}
2023-01-04 23:50:53,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:53,047 INFO:     Epoch: 54
2023-01-04 23:50:55,228 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5307413925727208, 'Total loss': 0.5307413925727208} | train loss {'Reaction outcome loss': 0.21151118999836546, 'Total loss': 0.21151118999836546}
2023-01-04 23:50:55,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:55,229 INFO:     Epoch: 55
2023-01-04 23:50:57,483 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5355666697025299, 'Total loss': 0.5355666697025299} | train loss {'Reaction outcome loss': 0.2045198053046789, 'Total loss': 0.2045198053046789}
2023-01-04 23:50:57,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:57,483 INFO:     Epoch: 56
2023-01-04 23:50:59,696 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5301986664533616, 'Total loss': 0.5301986664533616} | train loss {'Reaction outcome loss': 0.20514332086024603, 'Total loss': 0.20514332086024603}
2023-01-04 23:50:59,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:50:59,697 INFO:     Epoch: 57
2023-01-04 23:51:01,877 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.557851501305898, 'Total loss': 0.557851501305898} | train loss {'Reaction outcome loss': 0.20954309156110143, 'Total loss': 0.20954309156110143}
2023-01-04 23:51:01,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:01,877 INFO:     Epoch: 58
2023-01-04 23:51:04,098 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4962292119860649, 'Total loss': 0.4962292119860649} | train loss {'Reaction outcome loss': 0.20205085409506068, 'Total loss': 0.20205085409506068}
2023-01-04 23:51:04,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:04,098 INFO:     Epoch: 59
2023-01-04 23:51:06,321 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5244253208239873, 'Total loss': 0.5244253208239873} | train loss {'Reaction outcome loss': 0.19866418827284318, 'Total loss': 0.19866418827284318}
2023-01-04 23:51:06,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:06,321 INFO:     Epoch: 60
2023-01-04 23:51:08,530 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5270448644955953, 'Total loss': 0.5270448644955953} | train loss {'Reaction outcome loss': 0.19834014496011457, 'Total loss': 0.19834014496011457}
2023-01-04 23:51:08,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:08,531 INFO:     Epoch: 61
2023-01-04 23:51:10,757 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.54606827100118, 'Total loss': 0.54606827100118} | train loss {'Reaction outcome loss': 0.20080877764381633, 'Total loss': 0.20080877764381633}
2023-01-04 23:51:10,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:10,757 INFO:     Epoch: 62
2023-01-04 23:51:12,995 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4873509929825862, 'Total loss': 0.4873509929825862} | train loss {'Reaction outcome loss': 0.2043324766211538, 'Total loss': 0.2043324766211538}
2023-01-04 23:51:12,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:12,995 INFO:     Epoch: 63
2023-01-04 23:51:15,219 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5459834476312001, 'Total loss': 0.5459834476312001} | train loss {'Reaction outcome loss': 0.1916064269650374, 'Total loss': 0.1916064269650374}
2023-01-04 23:51:15,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:15,219 INFO:     Epoch: 64
2023-01-04 23:51:17,500 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5170422633488972, 'Total loss': 0.5170422633488972} | train loss {'Reaction outcome loss': 0.19466442780664367, 'Total loss': 0.19466442780664367}
2023-01-04 23:51:17,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:17,500 INFO:     Epoch: 65
2023-01-04 23:51:19,770 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5178536812464396, 'Total loss': 0.5178536812464396} | train loss {'Reaction outcome loss': 0.188793108387286, 'Total loss': 0.188793108387286}
2023-01-04 23:51:19,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:19,770 INFO:     Epoch: 66
2023-01-04 23:51:22,010 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5277354826529821, 'Total loss': 0.5277354826529821} | train loss {'Reaction outcome loss': 0.19487162152250861, 'Total loss': 0.19487162152250861}
2023-01-04 23:51:22,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:22,010 INFO:     Epoch: 67
2023-01-04 23:51:24,290 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5566900213559468, 'Total loss': 0.5566900213559468} | train loss {'Reaction outcome loss': 0.1938562934647185, 'Total loss': 0.1938562934647185}
2023-01-04 23:51:24,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:24,290 INFO:     Epoch: 68
2023-01-04 23:51:26,571 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5432346244653066, 'Total loss': 0.5432346244653066} | train loss {'Reaction outcome loss': 0.19155752424313857, 'Total loss': 0.19155752424313857}
2023-01-04 23:51:26,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:26,572 INFO:     Epoch: 69
2023-01-04 23:51:28,850 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5527608275413514, 'Total loss': 0.5527608275413514} | train loss {'Reaction outcome loss': 0.18963352692938906, 'Total loss': 0.18963352692938906}
2023-01-04 23:51:28,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:28,850 INFO:     Epoch: 70
2023-01-04 23:51:31,128 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4864601289232572, 'Total loss': 0.4864601289232572} | train loss {'Reaction outcome loss': 0.18490656420765242, 'Total loss': 0.18490656420765242}
2023-01-04 23:51:31,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:31,129 INFO:     Epoch: 71
2023-01-04 23:51:33,414 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5816898743311564, 'Total loss': 0.5816898743311564} | train loss {'Reaction outcome loss': 0.18521843632992466, 'Total loss': 0.18521843632992466}
2023-01-04 23:51:33,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:33,415 INFO:     Epoch: 72
2023-01-04 23:51:35,695 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5359964201847712, 'Total loss': 0.5359964201847712} | train loss {'Reaction outcome loss': 0.18933053843908176, 'Total loss': 0.18933053843908176}
2023-01-04 23:51:35,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:35,696 INFO:     Epoch: 73
2023-01-04 23:51:37,969 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5678117454051972, 'Total loss': 0.5678117454051972} | train loss {'Reaction outcome loss': 0.18721356696999855, 'Total loss': 0.18721356696999855}
2023-01-04 23:51:37,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:37,969 INFO:     Epoch: 74
2023-01-04 23:51:40,217 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.576313816010952, 'Total loss': 0.576313816010952} | train loss {'Reaction outcome loss': 0.1862104650226551, 'Total loss': 0.1862104650226551}
2023-01-04 23:51:40,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:40,217 INFO:     Epoch: 75
2023-01-04 23:51:42,495 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5306295548876127, 'Total loss': 0.5306295548876127} | train loss {'Reaction outcome loss': 0.18279203859219043, 'Total loss': 0.18279203859219043}
2023-01-04 23:51:42,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:42,496 INFO:     Epoch: 76
2023-01-04 23:51:44,779 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5290163973967235, 'Total loss': 0.5290163973967235} | train loss {'Reaction outcome loss': 0.18169019892675817, 'Total loss': 0.18169019892675817}
2023-01-04 23:51:44,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:44,780 INFO:     Epoch: 77
2023-01-04 23:51:47,054 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.582229737440745, 'Total loss': 0.582229737440745} | train loss {'Reaction outcome loss': 0.1782723045568016, 'Total loss': 0.1782723045568016}
2023-01-04 23:51:47,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:47,056 INFO:     Epoch: 78
2023-01-04 23:51:49,344 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5606851637363434, 'Total loss': 0.5606851637363434} | train loss {'Reaction outcome loss': 0.17974166988130033, 'Total loss': 0.17974166988130033}
2023-01-04 23:51:49,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:49,344 INFO:     Epoch: 79
2023-01-04 23:51:51,616 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5722277541955312, 'Total loss': 0.5722277541955312} | train loss {'Reaction outcome loss': 0.1818508263031551, 'Total loss': 0.1818508263031551}
2023-01-04 23:51:51,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:51,617 INFO:     Epoch: 80
2023-01-04 23:51:53,878 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5581172188123067, 'Total loss': 0.5581172188123067} | train loss {'Reaction outcome loss': 0.17567040448002244, 'Total loss': 0.17567040448002244}
2023-01-04 23:51:53,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:53,879 INFO:     Epoch: 81
2023-01-04 23:51:56,132 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.51771306792895, 'Total loss': 0.51771306792895} | train loss {'Reaction outcome loss': 0.1766163468340507, 'Total loss': 0.1766163468340507}
2023-01-04 23:51:56,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:56,133 INFO:     Epoch: 82
2023-01-04 23:51:58,366 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5309004366397858, 'Total loss': 0.5309004366397858} | train loss {'Reaction outcome loss': 0.17231612098845142, 'Total loss': 0.17231612098845142}
2023-01-04 23:51:58,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:51:58,366 INFO:     Epoch: 83
2023-01-04 23:52:00,622 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.549549263715744, 'Total loss': 0.549549263715744} | train loss {'Reaction outcome loss': 0.17574707156958153, 'Total loss': 0.17574707156958153}
2023-01-04 23:52:00,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:00,622 INFO:     Epoch: 84
2023-01-04 23:52:02,852 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5899769107500712, 'Total loss': 0.5899769107500712} | train loss {'Reaction outcome loss': 0.17615802680910395, 'Total loss': 0.17615802680910395}
2023-01-04 23:52:02,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:02,853 INFO:     Epoch: 85
2023-01-04 23:52:05,077 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5674266959230105, 'Total loss': 0.5674266959230105} | train loss {'Reaction outcome loss': 0.17699987704722878, 'Total loss': 0.17699987704722878}
2023-01-04 23:52:05,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:05,077 INFO:     Epoch: 86
2023-01-04 23:52:07,328 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.6315868516763051, 'Total loss': 0.6315868516763051} | train loss {'Reaction outcome loss': 0.17817222250176826, 'Total loss': 0.17817222250176826}
2023-01-04 23:52:07,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:07,328 INFO:     Epoch: 87
2023-01-04 23:52:09,560 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5777571241060893, 'Total loss': 0.5777571241060893} | train loss {'Reaction outcome loss': 0.17717600132875744, 'Total loss': 0.17717600132875744}
2023-01-04 23:52:09,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:09,560 INFO:     Epoch: 88
2023-01-04 23:52:11,811 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5419788092374802, 'Total loss': 0.5419788092374802} | train loss {'Reaction outcome loss': 0.16846607358833898, 'Total loss': 0.16846607358833898}
2023-01-04 23:52:11,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:11,811 INFO:     Epoch: 89
2023-01-04 23:52:14,021 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5566815388699372, 'Total loss': 0.5566815388699372} | train loss {'Reaction outcome loss': 0.17016878267954083, 'Total loss': 0.17016878267954083}
2023-01-04 23:52:14,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:14,022 INFO:     Epoch: 90
2023-01-04 23:52:16,017 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5737570305665334, 'Total loss': 0.5737570305665334} | train loss {'Reaction outcome loss': 0.17544669189225257, 'Total loss': 0.17544669189225257}
2023-01-04 23:52:16,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:16,018 INFO:     Epoch: 91
2023-01-04 23:52:18,268 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5942029555638632, 'Total loss': 0.5942029555638632} | train loss {'Reaction outcome loss': 0.16957280146175602, 'Total loss': 0.16957280146175602}
2023-01-04 23:52:18,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:18,269 INFO:     Epoch: 92
2023-01-04 23:52:20,473 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.6034267087777455, 'Total loss': 0.6034267087777455} | train loss {'Reaction outcome loss': 0.17022713764067604, 'Total loss': 0.17022713764067604}
2023-01-04 23:52:20,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:20,474 INFO:     Epoch: 93
2023-01-04 23:52:22,726 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.541300630569458, 'Total loss': 0.541300630569458} | train loss {'Reaction outcome loss': 0.1736581277333363, 'Total loss': 0.1736581277333363}
2023-01-04 23:52:22,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:22,727 INFO:     Epoch: 94
2023-01-04 23:52:24,981 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5800573547681173, 'Total loss': 0.5800573547681173} | train loss {'Reaction outcome loss': 0.17105320053698536, 'Total loss': 0.17105320053698536}
2023-01-04 23:52:24,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:24,981 INFO:     Epoch: 95
2023-01-04 23:52:27,231 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5475822746753692, 'Total loss': 0.5475822746753692} | train loss {'Reaction outcome loss': 0.16556862071428421, 'Total loss': 0.16556862071428421}
2023-01-04 23:52:27,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:27,231 INFO:     Epoch: 96
2023-01-04 23:52:29,514 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5685553630193074, 'Total loss': 0.5685553630193074} | train loss {'Reaction outcome loss': 0.16437461667347456, 'Total loss': 0.16437461667347456}
2023-01-04 23:52:29,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:29,515 INFO:     Epoch: 97
2023-01-04 23:52:31,774 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5515896191199621, 'Total loss': 0.5515896191199621} | train loss {'Reaction outcome loss': 0.16619577344649736, 'Total loss': 0.16619577344649736}
2023-01-04 23:52:31,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:31,775 INFO:     Epoch: 98
2023-01-04 23:52:33,992 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5953309257825216, 'Total loss': 0.5953309257825216} | train loss {'Reaction outcome loss': 0.16708105194117248, 'Total loss': 0.16708105194117248}
2023-01-04 23:52:33,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:33,993 INFO:     Epoch: 99
2023-01-04 23:52:36,187 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.573319959640503, 'Total loss': 0.573319959640503} | train loss {'Reaction outcome loss': 0.16494580484539215, 'Total loss': 0.16494580484539215}
2023-01-04 23:52:36,187 INFO:     Best model found after epoch 20 of 100.
2023-01-04 23:52:36,187 INFO:   Done with stage: TRAINING
2023-01-04 23:52:36,187 INFO:   Starting stage: EVALUATION
2023-01-04 23:52:36,328 INFO:   Done with stage: EVALUATION
2023-01-04 23:52:36,328 INFO:   Leaving out SEQ value Fold_4
2023-01-04 23:52:36,341 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 23:52:36,341 INFO:   Starting stage: FEATURE SCALING
2023-01-04 23:52:36,985 INFO:   Done with stage: FEATURE SCALING
2023-01-04 23:52:36,985 INFO:   Starting stage: SCALING TARGETS
2023-01-04 23:52:37,056 INFO:   Done with stage: SCALING TARGETS
2023-01-04 23:52:37,056 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:52:37,056 INFO:     No hyperparam tuning for this model
2023-01-04 23:52:37,056 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:52:37,056 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 23:52:37,057 INFO:     None feature selector for col prot
2023-01-04 23:52:37,057 INFO:     None feature selector for col prot
2023-01-04 23:52:37,057 INFO:     None feature selector for col prot
2023-01-04 23:52:37,058 INFO:     None feature selector for col chem
2023-01-04 23:52:37,058 INFO:     None feature selector for col chem
2023-01-04 23:52:37,058 INFO:     None feature selector for col chem
2023-01-04 23:52:37,058 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 23:52:37,058 INFO:   Starting stage: BUILD MODEL
2023-01-04 23:52:37,059 INFO:     Number of params in model 72931
2023-01-04 23:52:37,063 INFO:   Done with stage: BUILD MODEL
2023-01-04 23:52:37,063 INFO:   Starting stage: TRAINING
2023-01-04 23:52:37,120 INFO:     Val loss before train {'Reaction outcome loss': 0.8425467729568481, 'Total loss': 0.8425467729568481}
2023-01-04 23:52:37,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:37,120 INFO:     Epoch: 0
2023-01-04 23:52:39,320 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7583137055238088, 'Total loss': 0.7583137055238088} | train loss {'Reaction outcome loss': 0.97540706946798, 'Total loss': 0.97540706946798}
2023-01-04 23:52:39,321 INFO:     Found new best model at epoch 0
2023-01-04 23:52:39,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:39,323 INFO:     Epoch: 1
2023-01-04 23:52:41,553 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.553416911760966, 'Total loss': 0.553416911760966} | train loss {'Reaction outcome loss': 0.6818383254449936, 'Total loss': 0.6818383254449936}
2023-01-04 23:52:41,553 INFO:     Found new best model at epoch 1
2023-01-04 23:52:41,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:41,555 INFO:     Epoch: 2
2023-01-04 23:52:43,754 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5133188505967458, 'Total loss': 0.5133188505967458} | train loss {'Reaction outcome loss': 0.5569764848299108, 'Total loss': 0.5569764848299108}
2023-01-04 23:52:43,754 INFO:     Found new best model at epoch 2
2023-01-04 23:52:43,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:43,755 INFO:     Epoch: 3
2023-01-04 23:52:45,983 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49034149944782257, 'Total loss': 0.49034149944782257} | train loss {'Reaction outcome loss': 0.5160047265410379, 'Total loss': 0.5160047265410379}
2023-01-04 23:52:45,984 INFO:     Found new best model at epoch 3
2023-01-04 23:52:45,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:45,985 INFO:     Epoch: 4
2023-01-04 23:52:48,189 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4688310424486796, 'Total loss': 0.4688310424486796} | train loss {'Reaction outcome loss': 0.48884141549609356, 'Total loss': 0.48884141549609356}
2023-01-04 23:52:48,189 INFO:     Found new best model at epoch 4
2023-01-04 23:52:48,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:48,191 INFO:     Epoch: 5
2023-01-04 23:52:50,408 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4462821086247762, 'Total loss': 0.4462821086247762} | train loss {'Reaction outcome loss': 0.46562501810578816, 'Total loss': 0.46562501810578816}
2023-01-04 23:52:50,408 INFO:     Found new best model at epoch 5
2023-01-04 23:52:50,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:50,410 INFO:     Epoch: 6
2023-01-04 23:52:52,637 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47599397599697113, 'Total loss': 0.47599397599697113} | train loss {'Reaction outcome loss': 0.44833342466449394, 'Total loss': 0.44833342466449394}
2023-01-04 23:52:52,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:52,638 INFO:     Epoch: 7
2023-01-04 23:52:54,856 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43397788926959036, 'Total loss': 0.43397788926959036} | train loss {'Reaction outcome loss': 0.43530917286440945, 'Total loss': 0.43530917286440945}
2023-01-04 23:52:54,856 INFO:     Found new best model at epoch 7
2023-01-04 23:52:54,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:54,857 INFO:     Epoch: 8
2023-01-04 23:52:57,081 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4091373682022095, 'Total loss': 0.4091373682022095} | train loss {'Reaction outcome loss': 0.4237515151068784, 'Total loss': 0.4237515151068784}
2023-01-04 23:52:57,082 INFO:     Found new best model at epoch 8
2023-01-04 23:52:57,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:57,083 INFO:     Epoch: 9
2023-01-04 23:52:59,303 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4361685504515966, 'Total loss': 0.4361685504515966} | train loss {'Reaction outcome loss': 0.41049108565167064, 'Total loss': 0.41049108565167064}
2023-01-04 23:52:59,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:52:59,303 INFO:     Epoch: 10
2023-01-04 23:53:01,527 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4416231115659078, 'Total loss': 0.4416231115659078} | train loss {'Reaction outcome loss': 0.3964923529183843, 'Total loss': 0.3964923529183843}
2023-01-04 23:53:01,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:01,527 INFO:     Epoch: 11
2023-01-04 23:53:03,742 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42248851458231607, 'Total loss': 0.42248851458231607} | train loss {'Reaction outcome loss': 0.3850311696752096, 'Total loss': 0.3850311696752096}
2023-01-04 23:53:03,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:03,742 INFO:     Epoch: 12
2023-01-04 23:53:05,983 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4525089313586553, 'Total loss': 0.4525089313586553} | train loss {'Reaction outcome loss': 0.37270991803160397, 'Total loss': 0.37270991803160397}
2023-01-04 23:53:05,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:05,983 INFO:     Epoch: 13
2023-01-04 23:53:08,200 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3967342346906662, 'Total loss': 0.3967342346906662} | train loss {'Reaction outcome loss': 0.3624638412544247, 'Total loss': 0.3624638412544247}
2023-01-04 23:53:08,201 INFO:     Found new best model at epoch 13
2023-01-04 23:53:08,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:08,202 INFO:     Epoch: 14
2023-01-04 23:53:10,403 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4050722002983093, 'Total loss': 0.4050722002983093} | train loss {'Reaction outcome loss': 0.3510436141370809, 'Total loss': 0.3510436141370809}
2023-01-04 23:53:10,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:10,404 INFO:     Epoch: 15
2023-01-04 23:53:12,674 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41004320879777273, 'Total loss': 0.41004320879777273} | train loss {'Reaction outcome loss': 0.3451524782188547, 'Total loss': 0.3451524782188547}
2023-01-04 23:53:12,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:12,674 INFO:     Epoch: 16
2023-01-04 23:53:14,928 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40127230683962506, 'Total loss': 0.40127230683962506} | train loss {'Reaction outcome loss': 0.3354158444560818, 'Total loss': 0.3354158444560818}
2023-01-04 23:53:14,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:14,929 INFO:     Epoch: 17
2023-01-04 23:53:17,169 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4193451801935832, 'Total loss': 0.4193451801935832} | train loss {'Reaction outcome loss': 0.32724464314895263, 'Total loss': 0.32724464314895263}
2023-01-04 23:53:17,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:17,170 INFO:     Epoch: 18
2023-01-04 23:53:19,429 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40442507664362587, 'Total loss': 0.40442507664362587} | train loss {'Reaction outcome loss': 0.3405704384372718, 'Total loss': 0.3405704384372718}
2023-01-04 23:53:19,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:19,430 INFO:     Epoch: 19
2023-01-04 23:53:21,698 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42500492135683693, 'Total loss': 0.42500492135683693} | train loss {'Reaction outcome loss': 0.322530399110806, 'Total loss': 0.322530399110806}
2023-01-04 23:53:21,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:21,699 INFO:     Epoch: 20
2023-01-04 23:53:23,956 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3894844263792038, 'Total loss': 0.3894844263792038} | train loss {'Reaction outcome loss': 0.31008892031926394, 'Total loss': 0.31008892031926394}
2023-01-04 23:53:23,957 INFO:     Found new best model at epoch 20
2023-01-04 23:53:23,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:23,958 INFO:     Epoch: 21
2023-01-04 23:53:26,174 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3867660194635391, 'Total loss': 0.3867660194635391} | train loss {'Reaction outcome loss': 0.322322272601119, 'Total loss': 0.322322272601119}
2023-01-04 23:53:26,174 INFO:     Found new best model at epoch 21
2023-01-04 23:53:26,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:26,176 INFO:     Epoch: 22
2023-01-04 23:53:28,312 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4038724313179652, 'Total loss': 0.4038724313179652} | train loss {'Reaction outcome loss': 0.31528082153881376, 'Total loss': 0.31528082153881376}
2023-01-04 23:53:28,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:28,313 INFO:     Epoch: 23
2023-01-04 23:53:30,546 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3811788866917292, 'Total loss': 0.3811788866917292} | train loss {'Reaction outcome loss': 0.29783378402192984, 'Total loss': 0.29783378402192984}
2023-01-04 23:53:30,547 INFO:     Found new best model at epoch 23
2023-01-04 23:53:30,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:30,548 INFO:     Epoch: 24
2023-01-04 23:53:32,795 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38905500968297324, 'Total loss': 0.38905500968297324} | train loss {'Reaction outcome loss': 0.2939027837777942, 'Total loss': 0.2939027837777942}
2023-01-04 23:53:32,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:32,795 INFO:     Epoch: 25
2023-01-04 23:53:35,043 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3979908992846807, 'Total loss': 0.3979908992846807} | train loss {'Reaction outcome loss': 0.2874158480461093, 'Total loss': 0.2874158480461093}
2023-01-04 23:53:35,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:35,043 INFO:     Epoch: 26
2023-01-04 23:53:37,228 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.37522191802660626, 'Total loss': 0.37522191802660626} | train loss {'Reaction outcome loss': 0.2831918413268294, 'Total loss': 0.2831918413268294}
2023-01-04 23:53:37,229 INFO:     Found new best model at epoch 26
2023-01-04 23:53:37,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:37,230 INFO:     Epoch: 27
2023-01-04 23:53:39,491 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40647286772727964, 'Total loss': 0.40647286772727964} | train loss {'Reaction outcome loss': 0.2761773989629507, 'Total loss': 0.2761773989629507}
2023-01-04 23:53:39,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:39,491 INFO:     Epoch: 28
2023-01-04 23:53:41,744 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3851882735888163, 'Total loss': 0.3851882735888163} | train loss {'Reaction outcome loss': 0.27078876470258745, 'Total loss': 0.27078876470258745}
2023-01-04 23:53:41,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:41,745 INFO:     Epoch: 29
2023-01-04 23:53:43,937 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3778636227051417, 'Total loss': 0.3778636227051417} | train loss {'Reaction outcome loss': 0.26894768716348166, 'Total loss': 0.26894768716348166}
2023-01-04 23:53:43,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:43,938 INFO:     Epoch: 30
2023-01-04 23:53:46,220 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38373771458864214, 'Total loss': 0.38373771458864214} | train loss {'Reaction outcome loss': 0.26550568160584354, 'Total loss': 0.26550568160584354}
2023-01-04 23:53:46,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:46,220 INFO:     Epoch: 31
2023-01-04 23:53:48,493 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3848226457834244, 'Total loss': 0.3848226457834244} | train loss {'Reaction outcome loss': 0.2635232213938582, 'Total loss': 0.2635232213938582}
2023-01-04 23:53:48,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:48,493 INFO:     Epoch: 32
2023-01-04 23:53:50,423 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.36915381749471027, 'Total loss': 0.36915381749471027} | train loss {'Reaction outcome loss': 0.26512424429149734, 'Total loss': 0.26512424429149734}
2023-01-04 23:53:50,424 INFO:     Found new best model at epoch 32
2023-01-04 23:53:50,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:50,425 INFO:     Epoch: 33
2023-01-04 23:53:52,274 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.36671892603238426, 'Total loss': 0.36671892603238426} | train loss {'Reaction outcome loss': 0.2548375185214209, 'Total loss': 0.2548375185214209}
2023-01-04 23:53:52,275 INFO:     Found new best model at epoch 33
2023-01-04 23:53:52,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:52,276 INFO:     Epoch: 34
2023-01-04 23:53:54,319 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38907424012819924, 'Total loss': 0.38907424012819924} | train loss {'Reaction outcome loss': 0.2535096616581238, 'Total loss': 0.2535096616581238}
2023-01-04 23:53:54,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:54,319 INFO:     Epoch: 35
2023-01-04 23:53:56,519 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3923224796851476, 'Total loss': 0.3923224796851476} | train loss {'Reaction outcome loss': 0.2553612561154085, 'Total loss': 0.2553612561154085}
2023-01-04 23:53:56,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:56,520 INFO:     Epoch: 36
2023-01-04 23:53:58,782 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.36982293526331583, 'Total loss': 0.36982293526331583} | train loss {'Reaction outcome loss': 0.25055769915975956, 'Total loss': 0.25055769915975956}
2023-01-04 23:53:58,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:53:58,783 INFO:     Epoch: 37
2023-01-04 23:54:01,036 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.35616773664951323, 'Total loss': 0.35616773664951323} | train loss {'Reaction outcome loss': 0.24772272161984196, 'Total loss': 0.24772272161984196}
2023-01-04 23:54:01,036 INFO:     Found new best model at epoch 37
2023-01-04 23:54:01,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:01,037 INFO:     Epoch: 38
2023-01-04 23:54:03,304 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4003124644358953, 'Total loss': 0.4003124644358953} | train loss {'Reaction outcome loss': 0.24541018657602262, 'Total loss': 0.24541018657602262}
2023-01-04 23:54:03,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:03,305 INFO:     Epoch: 39
2023-01-04 23:54:05,515 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3757530058423678, 'Total loss': 0.3757530058423678} | train loss {'Reaction outcome loss': 0.25703854207423993, 'Total loss': 0.25703854207423993}
2023-01-04 23:54:05,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:05,515 INFO:     Epoch: 40
2023-01-04 23:54:07,768 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37614858051141103, 'Total loss': 0.37614858051141103} | train loss {'Reaction outcome loss': 0.23988578378761094, 'Total loss': 0.23988578378761094}
2023-01-04 23:54:07,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:07,768 INFO:     Epoch: 41
2023-01-04 23:54:10,103 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3848269313573837, 'Total loss': 0.3848269313573837} | train loss {'Reaction outcome loss': 0.24028837563051586, 'Total loss': 0.24028837563051586}
2023-01-04 23:54:10,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:10,103 INFO:     Epoch: 42
2023-01-04 23:54:12,427 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38505731572707497, 'Total loss': 0.38505731572707497} | train loss {'Reaction outcome loss': 0.2378204021623115, 'Total loss': 0.2378204021623115}
2023-01-04 23:54:12,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:12,427 INFO:     Epoch: 43
2023-01-04 23:54:14,695 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4135201334953308, 'Total loss': 0.4135201334953308} | train loss {'Reaction outcome loss': 0.24890340959815227, 'Total loss': 0.24890340959815227}
2023-01-04 23:54:14,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:14,695 INFO:     Epoch: 44
2023-01-04 23:54:16,868 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3891863505045573, 'Total loss': 0.3891863505045573} | train loss {'Reaction outcome loss': 0.2607097075182853, 'Total loss': 0.2607097075182853}
2023-01-04 23:54:16,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:16,868 INFO:     Epoch: 45
2023-01-04 23:54:19,134 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3700267066558202, 'Total loss': 0.3700267066558202} | train loss {'Reaction outcome loss': 0.23833256887134496, 'Total loss': 0.23833256887134496}
2023-01-04 23:54:19,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:19,135 INFO:     Epoch: 46
2023-01-04 23:54:21,406 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3908942051231861, 'Total loss': 0.3908942051231861} | train loss {'Reaction outcome loss': 0.22731578266214364, 'Total loss': 0.22731578266214364}
2023-01-04 23:54:21,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:21,406 INFO:     Epoch: 47
2023-01-04 23:54:23,602 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.36308477570613223, 'Total loss': 0.36308477570613223} | train loss {'Reaction outcome loss': 0.22853269289497394, 'Total loss': 0.22853269289497394}
2023-01-04 23:54:23,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:23,602 INFO:     Epoch: 48
2023-01-04 23:54:25,835 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.36811977475881574, 'Total loss': 0.36811977475881574} | train loss {'Reaction outcome loss': 0.22677652879349847, 'Total loss': 0.22677652879349847}
2023-01-04 23:54:25,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:25,836 INFO:     Epoch: 49
2023-01-04 23:54:28,073 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3494767591357231, 'Total loss': 0.3494767591357231} | train loss {'Reaction outcome loss': 0.22166041355919425, 'Total loss': 0.22166041355919425}
2023-01-04 23:54:28,073 INFO:     Found new best model at epoch 49
2023-01-04 23:54:28,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:28,074 INFO:     Epoch: 50
2023-01-04 23:54:30,296 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3693430537978808, 'Total loss': 0.3693430537978808} | train loss {'Reaction outcome loss': 0.22062378692751974, 'Total loss': 0.22062378692751974}
2023-01-04 23:54:30,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:30,296 INFO:     Epoch: 51
2023-01-04 23:54:32,577 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3837107385198275, 'Total loss': 0.3837107385198275} | train loss {'Reaction outcome loss': 0.21933008332462745, 'Total loss': 0.21933008332462745}
2023-01-04 23:54:32,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:32,577 INFO:     Epoch: 52
2023-01-04 23:54:34,856 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3825577194492022, 'Total loss': 0.3825577194492022} | train loss {'Reaction outcome loss': 0.21591850939422738, 'Total loss': 0.21591850939422738}
2023-01-04 23:54:34,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:34,856 INFO:     Epoch: 53
2023-01-04 23:54:37,124 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38389792243639626, 'Total loss': 0.38389792243639626} | train loss {'Reaction outcome loss': 0.2195824436030175, 'Total loss': 0.2195824436030175}
2023-01-04 23:54:37,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:37,125 INFO:     Epoch: 54
2023-01-04 23:54:39,364 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42339865962664286, 'Total loss': 0.42339865962664286} | train loss {'Reaction outcome loss': 0.21533049330911666, 'Total loss': 0.21533049330911666}
2023-01-04 23:54:39,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:39,365 INFO:     Epoch: 55
2023-01-04 23:54:41,613 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40561774348219237, 'Total loss': 0.40561774348219237} | train loss {'Reaction outcome loss': 0.2123651593886451, 'Total loss': 0.2123651593886451}
2023-01-04 23:54:41,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:41,614 INFO:     Epoch: 56
2023-01-04 23:54:43,885 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.36051122297843297, 'Total loss': 0.36051122297843297} | train loss {'Reaction outcome loss': 0.21376650610002046, 'Total loss': 0.21376650610002046}
2023-01-04 23:54:43,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:43,885 INFO:     Epoch: 57
2023-01-04 23:54:46,150 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3826385577519735, 'Total loss': 0.3826385577519735} | train loss {'Reaction outcome loss': 0.2142499887736251, 'Total loss': 0.2142499887736251}
2023-01-04 23:54:46,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:46,150 INFO:     Epoch: 58
2023-01-04 23:54:48,406 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3947750426828861, 'Total loss': 0.3947750426828861} | train loss {'Reaction outcome loss': 0.210144418399727, 'Total loss': 0.210144418399727}
2023-01-04 23:54:48,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:48,407 INFO:     Epoch: 59
2023-01-04 23:54:50,637 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3585842505097389, 'Total loss': 0.3585842505097389} | train loss {'Reaction outcome loss': 0.20910067569702337, 'Total loss': 0.20910067569702337}
2023-01-04 23:54:50,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:50,638 INFO:     Epoch: 60
2023-01-04 23:54:52,901 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3714534819126129, 'Total loss': 0.3714534819126129} | train loss {'Reaction outcome loss': 0.20543301192388963, 'Total loss': 0.20543301192388963}
2023-01-04 23:54:52,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:52,901 INFO:     Epoch: 61
2023-01-04 23:54:55,184 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38138966461022694, 'Total loss': 0.38138966461022694} | train loss {'Reaction outcome loss': 0.2052264635996202, 'Total loss': 0.2052264635996202}
2023-01-04 23:54:55,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:55,185 INFO:     Epoch: 62
2023-01-04 23:54:57,449 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39036815563837685, 'Total loss': 0.39036815563837685} | train loss {'Reaction outcome loss': 0.20580394115919867, 'Total loss': 0.20580394115919867}
2023-01-04 23:54:57,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:57,449 INFO:     Epoch: 63
2023-01-04 23:54:59,690 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4119557539621989, 'Total loss': 0.4119557539621989} | train loss {'Reaction outcome loss': 0.20600538034763094, 'Total loss': 0.20600538034763094}
2023-01-04 23:54:59,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:54:59,690 INFO:     Epoch: 64
2023-01-04 23:55:01,941 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39732087751229606, 'Total loss': 0.39732087751229606} | train loss {'Reaction outcome loss': 0.2063102122890574, 'Total loss': 0.2063102122890574}
2023-01-04 23:55:01,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:01,942 INFO:     Epoch: 65
2023-01-04 23:55:04,155 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3803229739268621, 'Total loss': 0.3803229739268621} | train loss {'Reaction outcome loss': 0.20437710903327874, 'Total loss': 0.20437710903327874}
2023-01-04 23:55:04,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:04,156 INFO:     Epoch: 66
2023-01-04 23:55:06,426 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3758959899346034, 'Total loss': 0.3758959899346034} | train loss {'Reaction outcome loss': 0.19907285506243183, 'Total loss': 0.19907285506243183}
2023-01-04 23:55:06,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:06,427 INFO:     Epoch: 67
2023-01-04 23:55:08,681 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3935578445593516, 'Total loss': 0.3935578445593516} | train loss {'Reaction outcome loss': 0.1951800263992956, 'Total loss': 0.1951800263992956}
2023-01-04 23:55:08,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:08,681 INFO:     Epoch: 68
2023-01-04 23:55:10,939 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40223256926983597, 'Total loss': 0.40223256926983597} | train loss {'Reaction outcome loss': 0.2032751392907285, 'Total loss': 0.2032751392907285}
2023-01-04 23:55:10,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:10,940 INFO:     Epoch: 69
2023-01-04 23:55:13,177 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3913403739531835, 'Total loss': 0.3913403739531835} | train loss {'Reaction outcome loss': 0.199642389373854, 'Total loss': 0.199642389373854}
2023-01-04 23:55:13,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:13,177 INFO:     Epoch: 70
2023-01-04 23:55:15,433 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40317396223545077, 'Total loss': 0.40317396223545077} | train loss {'Reaction outcome loss': 0.1994190540778842, 'Total loss': 0.1994190540778842}
2023-01-04 23:55:15,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:15,434 INFO:     Epoch: 71
2023-01-04 23:55:17,678 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4069277952114741, 'Total loss': 0.4069277952114741} | train loss {'Reaction outcome loss': 0.19641698122976106, 'Total loss': 0.19641698122976106}
2023-01-04 23:55:17,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:17,678 INFO:     Epoch: 72
2023-01-04 23:55:19,933 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41333721776803334, 'Total loss': 0.41333721776803334} | train loss {'Reaction outcome loss': 0.19600108480738962, 'Total loss': 0.19600108480738962}
2023-01-04 23:55:19,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:19,934 INFO:     Epoch: 73
2023-01-04 23:55:22,162 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3690322846484681, 'Total loss': 0.3690322846484681} | train loss {'Reaction outcome loss': 0.1946720793536203, 'Total loss': 0.1946720793536203}
2023-01-04 23:55:22,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:22,163 INFO:     Epoch: 74
2023-01-04 23:55:24,405 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.418671811123689, 'Total loss': 0.418671811123689} | train loss {'Reaction outcome loss': 0.19112462678289824, 'Total loss': 0.19112462678289824}
2023-01-04 23:55:24,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:24,406 INFO:     Epoch: 75
2023-01-04 23:55:26,650 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.371556577583154, 'Total loss': 0.371556577583154} | train loss {'Reaction outcome loss': 0.19021899822989682, 'Total loss': 0.19021899822989682}
2023-01-04 23:55:26,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:26,650 INFO:     Epoch: 76
2023-01-04 23:55:28,898 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4154753778129816, 'Total loss': 0.4154753778129816} | train loss {'Reaction outcome loss': 0.18802469908900937, 'Total loss': 0.18802469908900937}
2023-01-04 23:55:28,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:28,898 INFO:     Epoch: 77
2023-01-04 23:55:31,151 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40741475820541384, 'Total loss': 0.40741475820541384} | train loss {'Reaction outcome loss': 0.18942982834150957, 'Total loss': 0.18942982834150957}
2023-01-04 23:55:31,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:31,152 INFO:     Epoch: 78
2023-01-04 23:55:33,390 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3809207543730736, 'Total loss': 0.3809207543730736} | train loss {'Reaction outcome loss': 0.18728976633910596, 'Total loss': 0.18728976633910596}
2023-01-04 23:55:33,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:33,390 INFO:     Epoch: 79
2023-01-04 23:55:35,606 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3902974516153336, 'Total loss': 0.3902974516153336} | train loss {'Reaction outcome loss': 0.18839110187790525, 'Total loss': 0.18839110187790525}
2023-01-04 23:55:35,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:35,606 INFO:     Epoch: 80
2023-01-04 23:55:37,848 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4279778659343719, 'Total loss': 0.4279778659343719} | train loss {'Reaction outcome loss': 0.18594068323727697, 'Total loss': 0.18594068323727697}
2023-01-04 23:55:37,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:37,849 INFO:     Epoch: 81
2023-01-04 23:55:40,067 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3964133941878875, 'Total loss': 0.3964133941878875} | train loss {'Reaction outcome loss': 0.1844243844085292, 'Total loss': 0.1844243844085292}
2023-01-04 23:55:40,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:40,067 INFO:     Epoch: 82
2023-01-04 23:55:42,336 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39470069895808896, 'Total loss': 0.39470069895808896} | train loss {'Reaction outcome loss': 0.18496675603582052, 'Total loss': 0.18496675603582052}
2023-01-04 23:55:42,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:42,336 INFO:     Epoch: 83
2023-01-04 23:55:44,547 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4337301254272461, 'Total loss': 0.4337301254272461} | train loss {'Reaction outcome loss': 0.1841942289206402, 'Total loss': 0.1841942289206402}
2023-01-04 23:55:44,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:44,548 INFO:     Epoch: 84
2023-01-04 23:55:46,714 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.39054615100224815, 'Total loss': 0.39054615100224815} | train loss {'Reaction outcome loss': 0.18756726954429262, 'Total loss': 0.18756726954429262}
2023-01-04 23:55:46,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:46,714 INFO:     Epoch: 85
2023-01-04 23:55:48,951 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3823824127515157, 'Total loss': 0.3823824127515157} | train loss {'Reaction outcome loss': 0.19354292114629693, 'Total loss': 0.19354292114629693}
2023-01-04 23:55:48,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:48,951 INFO:     Epoch: 86
2023-01-04 23:55:51,142 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3727162597080072, 'Total loss': 0.3727162597080072} | train loss {'Reaction outcome loss': 0.20087827727927463, 'Total loss': 0.20087827727927463}
2023-01-04 23:55:51,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:51,143 INFO:     Epoch: 87
2023-01-04 23:55:53,410 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39516473611195885, 'Total loss': 0.39516473611195885} | train loss {'Reaction outcome loss': 0.18682527358049006, 'Total loss': 0.18682527358049006}
2023-01-04 23:55:53,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:53,411 INFO:     Epoch: 88
2023-01-04 23:55:55,635 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39153035879135134, 'Total loss': 0.39153035879135134} | train loss {'Reaction outcome loss': 0.17494598348882087, 'Total loss': 0.17494598348882087}
2023-01-04 23:55:55,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:55,636 INFO:     Epoch: 89
2023-01-04 23:55:57,864 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38348423441251117, 'Total loss': 0.38348423441251117} | train loss {'Reaction outcome loss': 0.17700390929731194, 'Total loss': 0.17700390929731194}
2023-01-04 23:55:57,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:55:57,864 INFO:     Epoch: 90
2023-01-04 23:56:00,109 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3847905796021223, 'Total loss': 0.3847905796021223} | train loss {'Reaction outcome loss': 0.18040082768024202, 'Total loss': 0.18040082768024202}
2023-01-04 23:56:00,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:00,109 INFO:     Epoch: 91
2023-01-04 23:56:02,376 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41882082720597585, 'Total loss': 0.41882082720597585} | train loss {'Reaction outcome loss': 0.17730160285313817, 'Total loss': 0.17730160285313817}
2023-01-04 23:56:02,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:02,376 INFO:     Epoch: 92
2023-01-04 23:56:04,582 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4062778472900391, 'Total loss': 0.4062778472900391} | train loss {'Reaction outcome loss': 0.18246738703928186, 'Total loss': 0.18246738703928186}
2023-01-04 23:56:04,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:04,582 INFO:     Epoch: 93
2023-01-04 23:56:06,854 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3835999474550287, 'Total loss': 0.3835999474550287} | train loss {'Reaction outcome loss': 0.19520936184296483, 'Total loss': 0.19520936184296483}
2023-01-04 23:56:06,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:06,855 INFO:     Epoch: 94
2023-01-04 23:56:09,114 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40208435083429017, 'Total loss': 0.40208435083429017} | train loss {'Reaction outcome loss': 0.1759759105076175, 'Total loss': 0.1759759105076175}
2023-01-04 23:56:09,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:09,114 INFO:     Epoch: 95
2023-01-04 23:56:11,361 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.36600702852010725, 'Total loss': 0.36600702852010725} | train loss {'Reaction outcome loss': 0.17545075396555004, 'Total loss': 0.17545075396555004}
2023-01-04 23:56:11,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:11,361 INFO:     Epoch: 96
2023-01-04 23:56:13,600 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4108045836289724, 'Total loss': 0.4108045836289724} | train loss {'Reaction outcome loss': 0.17244086489612845, 'Total loss': 0.17244086489612845}
2023-01-04 23:56:13,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:13,601 INFO:     Epoch: 97
2023-01-04 23:56:15,841 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4192920590440432, 'Total loss': 0.4192920590440432} | train loss {'Reaction outcome loss': 0.17387290381273066, 'Total loss': 0.17387290381273066}
2023-01-04 23:56:15,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:15,841 INFO:     Epoch: 98
2023-01-04 23:56:18,124 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4009660392999649, 'Total loss': 0.4009660392999649} | train loss {'Reaction outcome loss': 0.17668423883741777, 'Total loss': 0.17668423883741777}
2023-01-04 23:56:18,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:18,124 INFO:     Epoch: 99
2023-01-04 23:56:20,352 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4270109216372172, 'Total loss': 0.4270109216372172} | train loss {'Reaction outcome loss': 0.16915392569669918, 'Total loss': 0.16915392569669918}
2023-01-04 23:56:20,352 INFO:     Best model found after epoch 50 of 100.
2023-01-04 23:56:20,352 INFO:   Done with stage: TRAINING
2023-01-04 23:56:20,352 INFO:   Starting stage: EVALUATION
2023-01-04 23:56:20,487 INFO:   Done with stage: EVALUATION
2023-01-04 23:56:20,487 INFO:   Leaving out SEQ value Fold_5
2023-01-04 23:56:20,500 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 23:56:20,500 INFO:   Starting stage: FEATURE SCALING
2023-01-04 23:56:21,162 INFO:   Done with stage: FEATURE SCALING
2023-01-04 23:56:21,162 INFO:   Starting stage: SCALING TARGETS
2023-01-04 23:56:21,233 INFO:   Done with stage: SCALING TARGETS
2023-01-04 23:56:21,233 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:56:21,233 INFO:     No hyperparam tuning for this model
2023-01-04 23:56:21,234 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 23:56:21,234 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 23:56:21,234 INFO:     None feature selector for col prot
2023-01-04 23:56:21,234 INFO:     None feature selector for col prot
2023-01-04 23:56:21,235 INFO:     None feature selector for col prot
2023-01-04 23:56:21,235 INFO:     None feature selector for col chem
2023-01-04 23:56:21,235 INFO:     None feature selector for col chem
2023-01-04 23:56:21,235 INFO:     None feature selector for col chem
2023-01-04 23:56:21,235 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 23:56:21,235 INFO:   Starting stage: BUILD MODEL
2023-01-04 23:56:21,237 INFO:     Number of params in model 72931
2023-01-04 23:56:21,240 INFO:   Done with stage: BUILD MODEL
2023-01-04 23:56:21,240 INFO:   Starting stage: TRAINING
2023-01-04 23:56:21,301 INFO:     Val loss before train {'Reaction outcome loss': 0.984640379746755, 'Total loss': 0.984640379746755}
2023-01-04 23:56:21,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:21,302 INFO:     Epoch: 0
2023-01-04 23:56:23,340 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7612481315930685, 'Total loss': 0.7612481315930685} | train loss {'Reaction outcome loss': 0.9609151607386042, 'Total loss': 0.9609151607386042}
2023-01-04 23:56:23,340 INFO:     Found new best model at epoch 0
2023-01-04 23:56:23,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:23,342 INFO:     Epoch: 1
2023-01-04 23:56:25,533 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5542404154936472, 'Total loss': 0.5542404154936472} | train loss {'Reaction outcome loss': 0.6291322273467852, 'Total loss': 0.6291322273467852}
2023-01-04 23:56:25,534 INFO:     Found new best model at epoch 1
2023-01-04 23:56:25,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:25,535 INFO:     Epoch: 2
2023-01-04 23:56:27,759 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4977973918120066, 'Total loss': 0.4977973918120066} | train loss {'Reaction outcome loss': 0.5316954043690478, 'Total loss': 0.5316954043690478}
2023-01-04 23:56:27,760 INFO:     Found new best model at epoch 2
2023-01-04 23:56:27,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:27,761 INFO:     Epoch: 3
2023-01-04 23:56:30,030 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.483561505873998, 'Total loss': 0.483561505873998} | train loss {'Reaction outcome loss': 0.49583337377985465, 'Total loss': 0.49583337377985465}
2023-01-04 23:56:30,030 INFO:     Found new best model at epoch 3
2023-01-04 23:56:30,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:30,031 INFO:     Epoch: 4
2023-01-04 23:56:32,226 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44958601097265877, 'Total loss': 0.44958601097265877} | train loss {'Reaction outcome loss': 0.46476289600349074, 'Total loss': 0.46476289600349074}
2023-01-04 23:56:32,226 INFO:     Found new best model at epoch 4
2023-01-04 23:56:32,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:32,227 INFO:     Epoch: 5
2023-01-04 23:56:34,483 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44988260765870414, 'Total loss': 0.44988260765870414} | train loss {'Reaction outcome loss': 0.43552838413831557, 'Total loss': 0.43552838413831557}
2023-01-04 23:56:34,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:34,483 INFO:     Epoch: 6
2023-01-04 23:56:36,706 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44672593077023826, 'Total loss': 0.44672593077023826} | train loss {'Reaction outcome loss': 0.42224466052941895, 'Total loss': 0.42224466052941895}
2023-01-04 23:56:36,706 INFO:     Found new best model at epoch 6
2023-01-04 23:56:36,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:36,708 INFO:     Epoch: 7
2023-01-04 23:56:38,936 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44140255252520244, 'Total loss': 0.44140255252520244} | train loss {'Reaction outcome loss': 0.3988643512398758, 'Total loss': 0.3988643512398758}
2023-01-04 23:56:38,936 INFO:     Found new best model at epoch 7
2023-01-04 23:56:38,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:38,937 INFO:     Epoch: 8
2023-01-04 23:56:41,215 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42089722156524656, 'Total loss': 0.42089722156524656} | train loss {'Reaction outcome loss': 0.3885465597041247, 'Total loss': 0.3885465597041247}
2023-01-04 23:56:41,215 INFO:     Found new best model at epoch 8
2023-01-04 23:56:41,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:41,217 INFO:     Epoch: 9
2023-01-04 23:56:43,490 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4157172014315923, 'Total loss': 0.4157172014315923} | train loss {'Reaction outcome loss': 0.3720982099079698, 'Total loss': 0.3720982099079698}
2023-01-04 23:56:43,491 INFO:     Found new best model at epoch 9
2023-01-04 23:56:43,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:43,493 INFO:     Epoch: 10
2023-01-04 23:56:45,731 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41318173011144005, 'Total loss': 0.41318173011144005} | train loss {'Reaction outcome loss': 0.3579094117298884, 'Total loss': 0.3579094117298884}
2023-01-04 23:56:45,731 INFO:     Found new best model at epoch 10
2023-01-04 23:56:45,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:45,732 INFO:     Epoch: 11
2023-01-04 23:56:47,995 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4232172012329102, 'Total loss': 0.4232172012329102} | train loss {'Reaction outcome loss': 0.3504862203548531, 'Total loss': 0.3504862203548531}
2023-01-04 23:56:47,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:47,995 INFO:     Epoch: 12
2023-01-04 23:56:50,188 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41829695999622346, 'Total loss': 0.41829695999622346} | train loss {'Reaction outcome loss': 0.3401455854734789, 'Total loss': 0.3401455854734789}
2023-01-04 23:56:50,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:50,189 INFO:     Epoch: 13
2023-01-04 23:56:52,457 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4246649185816447, 'Total loss': 0.4246649185816447} | train loss {'Reaction outcome loss': 0.33019139623060983, 'Total loss': 0.33019139623060983}
2023-01-04 23:56:52,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:52,457 INFO:     Epoch: 14
2023-01-04 23:56:54,736 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42336452305316924, 'Total loss': 0.42336452305316924} | train loss {'Reaction outcome loss': 0.3239963045242891, 'Total loss': 0.3239963045242891}
2023-01-04 23:56:54,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:54,737 INFO:     Epoch: 15
2023-01-04 23:56:57,011 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.38723326722780865, 'Total loss': 0.38723326722780865} | train loss {'Reaction outcome loss': 0.3194258203494635, 'Total loss': 0.3194258203494635}
2023-01-04 23:56:57,012 INFO:     Found new best model at epoch 15
2023-01-04 23:56:57,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:57,013 INFO:     Epoch: 16
2023-01-04 23:56:59,225 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41830634474754336, 'Total loss': 0.41830634474754336} | train loss {'Reaction outcome loss': 0.31388047480088277, 'Total loss': 0.31388047480088277}
2023-01-04 23:56:59,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:56:59,225 INFO:     Epoch: 17
2023-01-04 23:57:01,485 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4350847582022349, 'Total loss': 0.4350847582022349} | train loss {'Reaction outcome loss': 0.305195740010549, 'Total loss': 0.305195740010549}
2023-01-04 23:57:01,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:01,485 INFO:     Epoch: 18
2023-01-04 23:57:03,766 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41711738109588625, 'Total loss': 0.41711738109588625} | train loss {'Reaction outcome loss': 0.2981839595019602, 'Total loss': 0.2981839595019602}
2023-01-04 23:57:03,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:03,767 INFO:     Epoch: 19
2023-01-04 23:57:06,029 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41895791590213777, 'Total loss': 0.41895791590213777} | train loss {'Reaction outcome loss': 0.29138314500720064, 'Total loss': 0.29138314500720064}
2023-01-04 23:57:06,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:06,030 INFO:     Epoch: 20
2023-01-04 23:57:08,287 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4445763091246287, 'Total loss': 0.4445763091246287} | train loss {'Reaction outcome loss': 0.2856383459097857, 'Total loss': 0.2856383459097857}
2023-01-04 23:57:08,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:08,288 INFO:     Epoch: 21
2023-01-04 23:57:10,520 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4101696516076724, 'Total loss': 0.4101696516076724} | train loss {'Reaction outcome loss': 0.27802963878972864, 'Total loss': 0.27802963878972864}
2023-01-04 23:57:10,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:10,521 INFO:     Epoch: 22
2023-01-04 23:57:12,787 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4385555068651835, 'Total loss': 0.4385555068651835} | train loss {'Reaction outcome loss': 0.2755613504414739, 'Total loss': 0.2755613504414739}
2023-01-04 23:57:12,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:12,789 INFO:     Epoch: 23
2023-01-04 23:57:15,058 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4252647856871287, 'Total loss': 0.4252647856871287} | train loss {'Reaction outcome loss': 0.2733948599103341, 'Total loss': 0.2733948599103341}
2023-01-04 23:57:15,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:15,059 INFO:     Epoch: 24
2023-01-04 23:57:17,329 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4189214843014876, 'Total loss': 0.4189214843014876} | train loss {'Reaction outcome loss': 0.2704388963307392, 'Total loss': 0.2704388963307392}
2023-01-04 23:57:17,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:17,329 INFO:     Epoch: 25
2023-01-04 23:57:19,607 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43729130178689957, 'Total loss': 0.43729130178689957} | train loss {'Reaction outcome loss': 0.26965212777579733, 'Total loss': 0.26965212777579733}
2023-01-04 23:57:19,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:19,608 INFO:     Epoch: 26
2023-01-04 23:57:21,842 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4024528180559476, 'Total loss': 0.4024528180559476} | train loss {'Reaction outcome loss': 0.266632158591644, 'Total loss': 0.266632158591644}
2023-01-04 23:57:21,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:21,842 INFO:     Epoch: 27
2023-01-04 23:57:24,119 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43464786410331724, 'Total loss': 0.43464786410331724} | train loss {'Reaction outcome loss': 0.25706205342220484, 'Total loss': 0.25706205342220484}
2023-01-04 23:57:24,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:24,119 INFO:     Epoch: 28
2023-01-04 23:57:26,370 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42839920818805693, 'Total loss': 0.42839920818805693} | train loss {'Reaction outcome loss': 0.2563229647367547, 'Total loss': 0.2563229647367547}
2023-01-04 23:57:26,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:26,370 INFO:     Epoch: 29
2023-01-04 23:57:28,644 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.434267391761144, 'Total loss': 0.434267391761144} | train loss {'Reaction outcome loss': 0.2524807144440576, 'Total loss': 0.2524807144440576}
2023-01-04 23:57:28,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:28,644 INFO:     Epoch: 30
2023-01-04 23:57:30,905 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4231503556172053, 'Total loss': 0.4231503556172053} | train loss {'Reaction outcome loss': 0.2500334620670775, 'Total loss': 0.2500334620670775}
2023-01-04 23:57:30,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:30,906 INFO:     Epoch: 31
2023-01-04 23:57:33,133 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4319285417596499, 'Total loss': 0.4319285417596499} | train loss {'Reaction outcome loss': 0.25018440816376614, 'Total loss': 0.25018440816376614}
2023-01-04 23:57:33,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:33,134 INFO:     Epoch: 32
2023-01-04 23:57:35,378 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43574679692586266, 'Total loss': 0.43574679692586266} | train loss {'Reaction outcome loss': 0.24372586659710546, 'Total loss': 0.24372586659710546}
2023-01-04 23:57:35,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:35,378 INFO:     Epoch: 33
2023-01-04 23:57:37,681 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40682976245880126, 'Total loss': 0.40682976245880126} | train loss {'Reaction outcome loss': 0.23664313886274285, 'Total loss': 0.23664313886274285}
2023-01-04 23:57:37,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:37,682 INFO:     Epoch: 34
2023-01-04 23:57:39,886 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4345897614955902, 'Total loss': 0.4345897614955902} | train loss {'Reaction outcome loss': 0.23640179738321673, 'Total loss': 0.23640179738321673}
2023-01-04 23:57:39,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:39,886 INFO:     Epoch: 35
2023-01-04 23:57:42,087 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4383560756842295, 'Total loss': 0.4383560756842295} | train loss {'Reaction outcome loss': 0.2355630549363496, 'Total loss': 0.2355630549363496}
2023-01-04 23:57:42,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:42,088 INFO:     Epoch: 36
2023-01-04 23:57:44,294 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43681046764055886, 'Total loss': 0.43681046764055886} | train loss {'Reaction outcome loss': 0.2319544212092454, 'Total loss': 0.2319544212092454}
2023-01-04 23:57:44,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:44,294 INFO:     Epoch: 37
2023-01-04 23:57:46,503 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4531025449434916, 'Total loss': 0.4531025449434916} | train loss {'Reaction outcome loss': 0.23154318786565792, 'Total loss': 0.23154318786565792}
2023-01-04 23:57:46,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:46,503 INFO:     Epoch: 38
2023-01-04 23:57:48,792 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4616523345311483, 'Total loss': 0.4616523345311483} | train loss {'Reaction outcome loss': 0.22648951451929575, 'Total loss': 0.22648951451929575}
2023-01-04 23:57:48,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:48,793 INFO:     Epoch: 39
2023-01-04 23:57:51,097 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4091189031799634, 'Total loss': 0.4091189031799634} | train loss {'Reaction outcome loss': 0.22785151152726976, 'Total loss': 0.22785151152726976}
2023-01-04 23:57:51,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:51,098 INFO:     Epoch: 40
2023-01-04 23:57:53,400 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42118287086486816, 'Total loss': 0.42118287086486816} | train loss {'Reaction outcome loss': 0.22376376504771114, 'Total loss': 0.22376376504771114}
2023-01-04 23:57:53,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:53,400 INFO:     Epoch: 41
2023-01-04 23:57:55,654 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44245150685310364, 'Total loss': 0.44245150685310364} | train loss {'Reaction outcome loss': 0.21300826206238477, 'Total loss': 0.21300826206238477}
2023-01-04 23:57:55,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:55,655 INFO:     Epoch: 42
2023-01-04 23:57:57,921 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42233401040236157, 'Total loss': 0.42233401040236157} | train loss {'Reaction outcome loss': 0.21650266151418002, 'Total loss': 0.21650266151418002}
2023-01-04 23:57:57,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:57:57,921 INFO:     Epoch: 43
2023-01-04 23:58:00,176 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45764811635017394, 'Total loss': 0.45764811635017394} | train loss {'Reaction outcome loss': 0.2187851253116927, 'Total loss': 0.2187851253116927}
2023-01-04 23:58:00,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:00,176 INFO:     Epoch: 44
2023-01-04 23:58:02,448 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4409306267897288, 'Total loss': 0.4409306267897288} | train loss {'Reaction outcome loss': 0.21084587132753232, 'Total loss': 0.21084587132753232}
2023-01-04 23:58:02,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:02,448 INFO:     Epoch: 45
2023-01-04 23:58:04,682 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4348475714524587, 'Total loss': 0.4348475714524587} | train loss {'Reaction outcome loss': 0.20537259210143172, 'Total loss': 0.20537259210143172}
2023-01-04 23:58:04,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:04,682 INFO:     Epoch: 46
2023-01-04 23:58:06,901 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4503176249563694, 'Total loss': 0.4503176249563694} | train loss {'Reaction outcome loss': 0.2049364322588009, 'Total loss': 0.2049364322588009}
2023-01-04 23:58:06,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:06,901 INFO:     Epoch: 47
2023-01-04 23:58:09,141 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45013371606667835, 'Total loss': 0.45013371606667835} | train loss {'Reaction outcome loss': 0.20410813678338424, 'Total loss': 0.20410813678338424}
2023-01-04 23:58:09,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:09,142 INFO:     Epoch: 48
2023-01-04 23:58:11,311 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45175901651382444, 'Total loss': 0.45175901651382444} | train loss {'Reaction outcome loss': 0.20252229363089327, 'Total loss': 0.20252229363089327}
2023-01-04 23:58:11,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:11,311 INFO:     Epoch: 49
2023-01-04 23:58:13,561 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44178273230791093, 'Total loss': 0.44178273230791093} | train loss {'Reaction outcome loss': 0.2012579809430489, 'Total loss': 0.2012579809430489}
2023-01-04 23:58:13,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:13,561 INFO:     Epoch: 50
2023-01-04 23:58:15,748 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4330144961675008, 'Total loss': 0.4330144961675008} | train loss {'Reaction outcome loss': 0.19544629558974655, 'Total loss': 0.19544629558974655}
2023-01-04 23:58:15,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:15,748 INFO:     Epoch: 51
2023-01-04 23:58:18,015 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45370596945285796, 'Total loss': 0.45370596945285796} | train loss {'Reaction outcome loss': 0.19765645951462996, 'Total loss': 0.19765645951462996}
2023-01-04 23:58:18,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:18,015 INFO:     Epoch: 52
2023-01-04 23:58:20,281 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43794631560643515, 'Total loss': 0.43794631560643515} | train loss {'Reaction outcome loss': 0.19726789636463465, 'Total loss': 0.19726789636463465}
2023-01-04 23:58:20,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:20,281 INFO:     Epoch: 53
2023-01-04 23:58:22,505 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4646653840939204, 'Total loss': 0.4646653840939204} | train loss {'Reaction outcome loss': 0.1876028152619781, 'Total loss': 0.1876028152619781}
2023-01-04 23:58:22,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:22,506 INFO:     Epoch: 54
2023-01-04 23:58:24,755 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41638478140036267, 'Total loss': 0.41638478140036267} | train loss {'Reaction outcome loss': 0.1954757190756634, 'Total loss': 0.1954757190756634}
2023-01-04 23:58:24,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:24,756 INFO:     Epoch: 55
2023-01-04 23:58:27,015 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4502760450045268, 'Total loss': 0.4502760450045268} | train loss {'Reaction outcome loss': 0.19028646674424088, 'Total loss': 0.19028646674424088}
2023-01-04 23:58:27,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:27,015 INFO:     Epoch: 56
2023-01-04 23:58:29,265 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.441348934173584, 'Total loss': 0.441348934173584} | train loss {'Reaction outcome loss': 0.19122609366336668, 'Total loss': 0.19122609366336668}
2023-01-04 23:58:29,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:29,265 INFO:     Epoch: 57
2023-01-04 23:58:31,442 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44646308819452923, 'Total loss': 0.44646308819452923} | train loss {'Reaction outcome loss': 0.18834589856142173, 'Total loss': 0.18834589856142173}
2023-01-04 23:58:31,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:31,443 INFO:     Epoch: 58
2023-01-04 23:58:33,621 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4573146988948186, 'Total loss': 0.4573146988948186} | train loss {'Reaction outcome loss': 0.187716069947323, 'Total loss': 0.187716069947323}
2023-01-04 23:58:33,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:33,621 INFO:     Epoch: 59
2023-01-04 23:58:35,880 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45022302865982056, 'Total loss': 0.45022302865982056} | train loss {'Reaction outcome loss': 0.17829994397701876, 'Total loss': 0.17829994397701876}
2023-01-04 23:58:35,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:35,880 INFO:     Epoch: 60
2023-01-04 23:58:38,165 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4738044579823812, 'Total loss': 0.4738044579823812} | train loss {'Reaction outcome loss': 0.18073459877548503, 'Total loss': 0.18073459877548503}
2023-01-04 23:58:38,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:38,165 INFO:     Epoch: 61
2023-01-04 23:58:40,433 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45880507479111354, 'Total loss': 0.45880507479111354} | train loss {'Reaction outcome loss': 0.18152893200476355, 'Total loss': 0.18152893200476355}
2023-01-04 23:58:40,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:40,433 INFO:     Epoch: 62
2023-01-04 23:58:42,695 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4492860009272893, 'Total loss': 0.4492860009272893} | train loss {'Reaction outcome loss': 0.1890120712967946, 'Total loss': 0.1890120712967946}
2023-01-04 23:58:42,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:42,695 INFO:     Epoch: 63
2023-01-04 23:58:44,985 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43898998498916625, 'Total loss': 0.43898998498916625} | train loss {'Reaction outcome loss': 0.17615935312321793, 'Total loss': 0.17615935312321793}
2023-01-04 23:58:44,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:44,986 INFO:     Epoch: 64
2023-01-04 23:58:47,258 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4593590199947357, 'Total loss': 0.4593590199947357} | train loss {'Reaction outcome loss': 0.1785069333073357, 'Total loss': 0.1785069333073357}
2023-01-04 23:58:47,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:47,258 INFO:     Epoch: 65
2023-01-04 23:58:49,527 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4420925371348858, 'Total loss': 0.4420925371348858} | train loss {'Reaction outcome loss': 0.18073024313530417, 'Total loss': 0.18073024313530417}
2023-01-04 23:58:49,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:49,527 INFO:     Epoch: 66
2023-01-04 23:58:51,776 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44064992864926655, 'Total loss': 0.44064992864926655} | train loss {'Reaction outcome loss': 0.1770666359254707, 'Total loss': 0.1770666359254707}
2023-01-04 23:58:51,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:51,776 INFO:     Epoch: 67
2023-01-04 23:58:54,041 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4259736051162084, 'Total loss': 0.4259736051162084} | train loss {'Reaction outcome loss': 0.1786541988878151, 'Total loss': 0.1786541988878151}
2023-01-04 23:58:54,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:54,041 INFO:     Epoch: 68
2023-01-04 23:58:56,312 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44600558777650195, 'Total loss': 0.44600558777650195} | train loss {'Reaction outcome loss': 0.17396286717995949, 'Total loss': 0.17396286717995949}
2023-01-04 23:58:56,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:56,313 INFO:     Epoch: 69
2023-01-04 23:58:58,573 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4725694298744202, 'Total loss': 0.4725694298744202} | train loss {'Reaction outcome loss': 0.17249324685298847, 'Total loss': 0.17249324685298847}
2023-01-04 23:58:58,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:58:58,574 INFO:     Epoch: 70
2023-01-04 23:59:00,805 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4592456062634786, 'Total loss': 0.4592456062634786} | train loss {'Reaction outcome loss': 0.17562326502613052, 'Total loss': 0.17562326502613052}
2023-01-04 23:59:00,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:00,806 INFO:     Epoch: 71
2023-01-04 23:59:03,081 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4480633854866028, 'Total loss': 0.4480633854866028} | train loss {'Reaction outcome loss': 0.1722975481815959, 'Total loss': 0.1722975481815959}
2023-01-04 23:59:03,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:03,081 INFO:     Epoch: 72
2023-01-04 23:59:05,344 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4416413724422455, 'Total loss': 0.4416413724422455} | train loss {'Reaction outcome loss': 0.1760531234679347, 'Total loss': 0.1760531234679347}
2023-01-04 23:59:05,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:05,344 INFO:     Epoch: 73
2023-01-04 23:59:07,627 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45997280851006506, 'Total loss': 0.45997280851006506} | train loss {'Reaction outcome loss': 0.1713869200383955, 'Total loss': 0.1713869200383955}
2023-01-04 23:59:07,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:07,628 INFO:     Epoch: 74
2023-01-04 23:59:09,910 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47380075256029763, 'Total loss': 0.47380075256029763} | train loss {'Reaction outcome loss': 0.17115159669305982, 'Total loss': 0.17115159669305982}
2023-01-04 23:59:09,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:09,910 INFO:     Epoch: 75
2023-01-04 23:59:12,183 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48125124474366504, 'Total loss': 0.48125124474366504} | train loss {'Reaction outcome loss': 0.17117490833087248, 'Total loss': 0.17117490833087248}
2023-01-04 23:59:12,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:12,183 INFO:     Epoch: 76
2023-01-04 23:59:14,433 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43900107145309447, 'Total loss': 0.43900107145309447} | train loss {'Reaction outcome loss': 0.16373185959345382, 'Total loss': 0.16373185959345382}
2023-01-04 23:59:14,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:14,433 INFO:     Epoch: 77
2023-01-04 23:59:16,667 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4558419841031233, 'Total loss': 0.4558419841031233} | train loss {'Reaction outcome loss': 0.16898776730690623, 'Total loss': 0.16898776730690623}
2023-01-04 23:59:16,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:16,668 INFO:     Epoch: 78
2023-01-04 23:59:18,888 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43231927702824274, 'Total loss': 0.43231927702824274} | train loss {'Reaction outcome loss': 0.16831328540986626, 'Total loss': 0.16831328540986626}
2023-01-04 23:59:18,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:18,888 INFO:     Epoch: 79
2023-01-04 23:59:21,087 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4352393378814062, 'Total loss': 0.4352393378814062} | train loss {'Reaction outcome loss': 0.16426470828837705, 'Total loss': 0.16426470828837705}
2023-01-04 23:59:21,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:21,088 INFO:     Epoch: 80
2023-01-04 23:59:23,336 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45931327988704046, 'Total loss': 0.45931327988704046} | train loss {'Reaction outcome loss': 0.1750568476898952, 'Total loss': 0.1750568476898952}
2023-01-04 23:59:23,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:23,336 INFO:     Epoch: 81
2023-01-04 23:59:25,528 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.455532551308473, 'Total loss': 0.455532551308473} | train loss {'Reaction outcome loss': 0.1672310345009346, 'Total loss': 0.1672310345009346}
2023-01-04 23:59:25,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:25,528 INFO:     Epoch: 82
2023-01-04 23:59:27,798 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4567316708465417, 'Total loss': 0.4567316708465417} | train loss {'Reaction outcome loss': 0.1691633817783493, 'Total loss': 0.1691633817783493}
2023-01-04 23:59:27,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:27,798 INFO:     Epoch: 83
2023-01-04 23:59:30,022 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47746436993281044, 'Total loss': 0.47746436993281044} | train loss {'Reaction outcome loss': 0.16419796651861351, 'Total loss': 0.16419796651861351}
2023-01-04 23:59:30,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:30,023 INFO:     Epoch: 84
2023-01-04 23:59:32,294 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47689552704493204, 'Total loss': 0.47689552704493204} | train loss {'Reaction outcome loss': 0.16502611609411152, 'Total loss': 0.16502611609411152}
2023-01-04 23:59:32,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:32,294 INFO:     Epoch: 85
2023-01-04 23:59:34,508 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45684314767519635, 'Total loss': 0.45684314767519635} | train loss {'Reaction outcome loss': 0.1612881922620325, 'Total loss': 0.1612881922620325}
2023-01-04 23:59:34,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:34,509 INFO:     Epoch: 86
2023-01-04 23:59:36,695 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48041650305191674, 'Total loss': 0.48041650305191674} | train loss {'Reaction outcome loss': 0.16015560760596492, 'Total loss': 0.16015560760596492}
2023-01-04 23:59:36,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:36,696 INFO:     Epoch: 87
2023-01-04 23:59:38,961 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4672683914502462, 'Total loss': 0.4672683914502462} | train loss {'Reaction outcome loss': 0.16418808428503384, 'Total loss': 0.16418808428503384}
2023-01-04 23:59:38,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:38,962 INFO:     Epoch: 88
2023-01-04 23:59:41,200 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47498891353607176, 'Total loss': 0.47498891353607176} | train loss {'Reaction outcome loss': 0.1617940191603148, 'Total loss': 0.1617940191603148}
2023-01-04 23:59:41,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:41,201 INFO:     Epoch: 89
2023-01-04 23:59:43,477 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4339441508054733, 'Total loss': 0.4339441508054733} | train loss {'Reaction outcome loss': 0.16467883351968352, 'Total loss': 0.16467883351968352}
2023-01-04 23:59:43,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:43,478 INFO:     Epoch: 90
2023-01-04 23:59:45,690 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.467073467373848, 'Total loss': 0.467073467373848} | train loss {'Reaction outcome loss': 0.1608349314221729, 'Total loss': 0.1608349314221729}
2023-01-04 23:59:45,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:45,690 INFO:     Epoch: 91
2023-01-04 23:59:47,958 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46561845516165096, 'Total loss': 0.46561845516165096} | train loss {'Reaction outcome loss': 0.16031177719342202, 'Total loss': 0.16031177719342202}
2023-01-04 23:59:47,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:47,958 INFO:     Epoch: 92
2023-01-04 23:59:50,184 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47658339018623036, 'Total loss': 0.47658339018623036} | train loss {'Reaction outcome loss': 0.16242920671209746, 'Total loss': 0.16242920671209746}
2023-01-04 23:59:50,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:50,184 INFO:     Epoch: 93
2023-01-04 23:59:52,349 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45343192368745805, 'Total loss': 0.45343192368745805} | train loss {'Reaction outcome loss': 0.16167948031562654, 'Total loss': 0.16167948031562654}
2023-01-04 23:59:52,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:52,350 INFO:     Epoch: 94
2023-01-04 23:59:54,616 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46417841911315916, 'Total loss': 0.46417841911315916} | train loss {'Reaction outcome loss': 0.16224978231767778, 'Total loss': 0.16224978231767778}
2023-01-04 23:59:54,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:54,617 INFO:     Epoch: 95
2023-01-04 23:59:56,877 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.461062819759051, 'Total loss': 0.461062819759051} | train loss {'Reaction outcome loss': 0.1653881590403213, 'Total loss': 0.1653881590403213}
2023-01-04 23:59:56,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:56,878 INFO:     Epoch: 96
2023-01-04 23:59:59,139 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48910689453283945, 'Total loss': 0.48910689453283945} | train loss {'Reaction outcome loss': 0.157594933835218, 'Total loss': 0.157594933835218}
2023-01-04 23:59:59,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 23:59:59,139 INFO:     Epoch: 97
2023-01-05 00:00:01,415 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44698789765437447, 'Total loss': 0.44698789765437447} | train loss {'Reaction outcome loss': 0.15888816251718718, 'Total loss': 0.15888816251718718}
2023-01-05 00:00:01,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:01,415 INFO:     Epoch: 98
2023-01-05 00:00:03,622 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45744680166244506, 'Total loss': 0.45744680166244506} | train loss {'Reaction outcome loss': 0.15880468496817438, 'Total loss': 0.15880468496817438}
2023-01-05 00:00:03,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:03,623 INFO:     Epoch: 99
2023-01-05 00:00:05,903 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48301546374956766, 'Total loss': 0.48301546374956766} | train loss {'Reaction outcome loss': 0.15518417721782352, 'Total loss': 0.15518417721782352}
2023-01-05 00:00:05,903 INFO:     Best model found after epoch 16 of 100.
2023-01-05 00:00:05,903 INFO:   Done with stage: TRAINING
2023-01-05 00:00:05,903 INFO:   Starting stage: EVALUATION
2023-01-05 00:00:06,034 INFO:   Done with stage: EVALUATION
2023-01-05 00:00:06,034 INFO:   Leaving out SEQ value Fold_6
2023-01-05 00:00:06,047 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 00:00:06,047 INFO:   Starting stage: FEATURE SCALING
2023-01-05 00:00:06,701 INFO:   Done with stage: FEATURE SCALING
2023-01-05 00:00:06,702 INFO:   Starting stage: SCALING TARGETS
2023-01-05 00:00:06,774 INFO:   Done with stage: SCALING TARGETS
2023-01-05 00:00:06,774 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:00:06,774 INFO:     No hyperparam tuning for this model
2023-01-05 00:00:06,774 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:00:06,774 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 00:00:06,775 INFO:     None feature selector for col prot
2023-01-05 00:00:06,775 INFO:     None feature selector for col prot
2023-01-05 00:00:06,775 INFO:     None feature selector for col prot
2023-01-05 00:00:06,776 INFO:     None feature selector for col chem
2023-01-05 00:00:06,776 INFO:     None feature selector for col chem
2023-01-05 00:00:06,776 INFO:     None feature selector for col chem
2023-01-05 00:00:06,776 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 00:00:06,776 INFO:   Starting stage: BUILD MODEL
2023-01-05 00:00:06,778 INFO:     Number of params in model 72931
2023-01-05 00:00:06,781 INFO:   Done with stage: BUILD MODEL
2023-01-05 00:00:06,781 INFO:   Starting stage: TRAINING
2023-01-05 00:00:06,843 INFO:     Val loss before train {'Reaction outcome loss': 0.9436881879965464, 'Total loss': 0.9436881879965464}
2023-01-05 00:00:06,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:06,843 INFO:     Epoch: 0
2023-01-05 00:00:09,110 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7971830328305562, 'Total loss': 0.7971830328305562} | train loss {'Reaction outcome loss': 0.9671500811110372, 'Total loss': 0.9671500811110372}
2023-01-05 00:00:09,110 INFO:     Found new best model at epoch 0
2023-01-05 00:00:09,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:09,112 INFO:     Epoch: 1
2023-01-05 00:00:11,389 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5919151107470194, 'Total loss': 0.5919151107470194} | train loss {'Reaction outcome loss': 0.7041231208629366, 'Total loss': 0.7041231208629366}
2023-01-05 00:00:11,389 INFO:     Found new best model at epoch 1
2023-01-05 00:00:11,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:11,390 INFO:     Epoch: 2
2023-01-05 00:00:13,606 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5641207923491796, 'Total loss': 0.5641207923491796} | train loss {'Reaction outcome loss': 0.5570466958148323, 'Total loss': 0.5570466958148323}
2023-01-05 00:00:13,607 INFO:     Found new best model at epoch 2
2023-01-05 00:00:13,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:13,609 INFO:     Epoch: 3
2023-01-05 00:00:15,862 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5182463442285855, 'Total loss': 0.5182463442285855} | train loss {'Reaction outcome loss': 0.5116466452786024, 'Total loss': 0.5116466452786024}
2023-01-05 00:00:15,862 INFO:     Found new best model at epoch 3
2023-01-05 00:00:15,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:15,864 INFO:     Epoch: 4
2023-01-05 00:00:18,126 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.511760268608729, 'Total loss': 0.511760268608729} | train loss {'Reaction outcome loss': 0.4803186751686145, 'Total loss': 0.4803186751686145}
2023-01-05 00:00:18,126 INFO:     Found new best model at epoch 4
2023-01-05 00:00:18,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:18,128 INFO:     Epoch: 5
2023-01-05 00:00:20,381 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5081974307696024, 'Total loss': 0.5081974307696024} | train loss {'Reaction outcome loss': 0.4531457960281683, 'Total loss': 0.4531457960281683}
2023-01-05 00:00:20,382 INFO:     Found new best model at epoch 5
2023-01-05 00:00:20,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:20,383 INFO:     Epoch: 6
2023-01-05 00:00:22,626 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47560569246610007, 'Total loss': 0.47560569246610007} | train loss {'Reaction outcome loss': 0.4240136591580939, 'Total loss': 0.4240136591580939}
2023-01-05 00:00:22,626 INFO:     Found new best model at epoch 6
2023-01-05 00:00:22,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:22,628 INFO:     Epoch: 7
2023-01-05 00:00:24,864 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4692456761995951, 'Total loss': 0.4692456761995951} | train loss {'Reaction outcome loss': 0.4050069834355373, 'Total loss': 0.4050069834355373}
2023-01-05 00:00:24,864 INFO:     Found new best model at epoch 7
2023-01-05 00:00:24,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:24,866 INFO:     Epoch: 8
2023-01-05 00:00:27,103 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4710409084955851, 'Total loss': 0.4710409084955851} | train loss {'Reaction outcome loss': 0.38816440306043765, 'Total loss': 0.38816440306043765}
2023-01-05 00:00:27,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:27,103 INFO:     Epoch: 9
2023-01-05 00:00:29,241 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44622228344281517, 'Total loss': 0.44622228344281517} | train loss {'Reaction outcome loss': 0.3773275394839626, 'Total loss': 0.3773275394839626}
2023-01-05 00:00:29,241 INFO:     Found new best model at epoch 9
2023-01-05 00:00:29,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:29,242 INFO:     Epoch: 10
2023-01-05 00:00:31,402 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4432480792204539, 'Total loss': 0.4432480792204539} | train loss {'Reaction outcome loss': 0.36322085837415163, 'Total loss': 0.36322085837415163}
2023-01-05 00:00:31,402 INFO:     Found new best model at epoch 10
2023-01-05 00:00:31,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:31,404 INFO:     Epoch: 11
2023-01-05 00:00:33,654 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45509984095891315, 'Total loss': 0.45509984095891315} | train loss {'Reaction outcome loss': 0.35508111507621926, 'Total loss': 0.35508111507621926}
2023-01-05 00:00:33,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:33,655 INFO:     Epoch: 12
2023-01-05 00:00:35,892 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46954990228017174, 'Total loss': 0.46954990228017174} | train loss {'Reaction outcome loss': 0.3460848810981311, 'Total loss': 0.3460848810981311}
2023-01-05 00:00:35,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:35,892 INFO:     Epoch: 13
2023-01-05 00:00:38,124 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4524385472138723, 'Total loss': 0.4524385472138723} | train loss {'Reaction outcome loss': 0.3391684546958709, 'Total loss': 0.3391684546958709}
2023-01-05 00:00:38,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:38,124 INFO:     Epoch: 14
2023-01-05 00:00:40,335 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4461437940597534, 'Total loss': 0.4461437940597534} | train loss {'Reaction outcome loss': 0.3341149262867976, 'Total loss': 0.3341149262867976}
2023-01-05 00:00:40,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:40,336 INFO:     Epoch: 15
2023-01-05 00:00:42,588 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43710527817408246, 'Total loss': 0.43710527817408246} | train loss {'Reaction outcome loss': 0.32039235744868283, 'Total loss': 0.32039235744868283}
2023-01-05 00:00:42,589 INFO:     Found new best model at epoch 15
2023-01-05 00:00:42,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:42,591 INFO:     Epoch: 16
2023-01-05 00:00:44,815 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4266533464193344, 'Total loss': 0.4266533464193344} | train loss {'Reaction outcome loss': 0.3130808955301409, 'Total loss': 0.3130808955301409}
2023-01-05 00:00:44,816 INFO:     Found new best model at epoch 16
2023-01-05 00:00:44,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:44,817 INFO:     Epoch: 17
2023-01-05 00:00:47,081 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44123086134592693, 'Total loss': 0.44123086134592693} | train loss {'Reaction outcome loss': 0.30888980039921793, 'Total loss': 0.30888980039921793}
2023-01-05 00:00:47,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:47,081 INFO:     Epoch: 18
2023-01-05 00:00:49,280 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4243522753318151, 'Total loss': 0.4243522753318151} | train loss {'Reaction outcome loss': 0.2985608921406548, 'Total loss': 0.2985608921406548}
2023-01-05 00:00:49,280 INFO:     Found new best model at epoch 18
2023-01-05 00:00:49,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:49,282 INFO:     Epoch: 19
2023-01-05 00:00:51,468 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4470583001772563, 'Total loss': 0.4470583001772563} | train loss {'Reaction outcome loss': 0.2977979553806886, 'Total loss': 0.2977979553806886}
2023-01-05 00:00:51,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:51,468 INFO:     Epoch: 20
2023-01-05 00:00:53,740 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43489736517270405, 'Total loss': 0.43489736517270405} | train loss {'Reaction outcome loss': 0.29120300101467234, 'Total loss': 0.29120300101467234}
2023-01-05 00:00:53,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:53,741 INFO:     Epoch: 21
2023-01-05 00:00:55,993 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4166945884625117, 'Total loss': 0.4166945884625117} | train loss {'Reaction outcome loss': 0.2822403188497908, 'Total loss': 0.2822403188497908}
2023-01-05 00:00:55,993 INFO:     Found new best model at epoch 21
2023-01-05 00:00:55,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:55,994 INFO:     Epoch: 22
2023-01-05 00:00:58,232 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44171447356541954, 'Total loss': 0.44171447356541954} | train loss {'Reaction outcome loss': 0.27667402268675884, 'Total loss': 0.27667402268675884}
2023-01-05 00:00:58,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:00:58,233 INFO:     Epoch: 23
2023-01-05 00:01:00,494 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44766349395116173, 'Total loss': 0.44766349395116173} | train loss {'Reaction outcome loss': 0.27230465805927373, 'Total loss': 0.27230465805927373}
2023-01-05 00:01:00,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:00,494 INFO:     Epoch: 24
2023-01-05 00:01:02,766 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4371977965037028, 'Total loss': 0.4371977965037028} | train loss {'Reaction outcome loss': 0.26797895366027424, 'Total loss': 0.26797895366027424}
2023-01-05 00:01:02,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:02,767 INFO:     Epoch: 25
2023-01-05 00:01:05,017 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4194502572218577, 'Total loss': 0.4194502572218577} | train loss {'Reaction outcome loss': 0.2629426193218577, 'Total loss': 0.2629426193218577}
2023-01-05 00:01:05,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:05,017 INFO:     Epoch: 26
2023-01-05 00:01:07,239 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4536606967449188, 'Total loss': 0.4536606967449188} | train loss {'Reaction outcome loss': 0.2556357772808279, 'Total loss': 0.2556357772808279}
2023-01-05 00:01:07,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:07,239 INFO:     Epoch: 27
2023-01-05 00:01:09,496 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42395502626895903, 'Total loss': 0.42395502626895903} | train loss {'Reaction outcome loss': 0.25360498422473343, 'Total loss': 0.25360498422473343}
2023-01-05 00:01:09,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:09,496 INFO:     Epoch: 28
2023-01-05 00:01:11,751 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43800057570139567, 'Total loss': 0.43800057570139567} | train loss {'Reaction outcome loss': 0.25063791911634326, 'Total loss': 0.25063791911634326}
2023-01-05 00:01:11,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:11,752 INFO:     Epoch: 29
2023-01-05 00:01:14,005 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4468181143204371, 'Total loss': 0.4468181143204371} | train loss {'Reaction outcome loss': 0.24372370360441087, 'Total loss': 0.24372370360441087}
2023-01-05 00:01:14,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:14,005 INFO:     Epoch: 30
2023-01-05 00:01:16,197 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4321196878949801, 'Total loss': 0.4321196878949801} | train loss {'Reaction outcome loss': 0.24613908918041305, 'Total loss': 0.24613908918041305}
2023-01-05 00:01:16,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:16,197 INFO:     Epoch: 31
2023-01-05 00:01:18,443 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4474974026282628, 'Total loss': 0.4474974026282628} | train loss {'Reaction outcome loss': 0.24092792058144225, 'Total loss': 0.24092792058144225}
2023-01-05 00:01:18,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:18,445 INFO:     Epoch: 32
2023-01-05 00:01:20,705 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44072269399960834, 'Total loss': 0.44072269399960834} | train loss {'Reaction outcome loss': 0.23385234468741398, 'Total loss': 0.23385234468741398}
2023-01-05 00:01:20,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:20,705 INFO:     Epoch: 33
2023-01-05 00:01:22,960 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4186390529076258, 'Total loss': 0.4186390529076258} | train loss {'Reaction outcome loss': 0.23629077224857453, 'Total loss': 0.23629077224857453}
2023-01-05 00:01:22,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:22,960 INFO:     Epoch: 34
2023-01-05 00:01:25,162 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40840730965137484, 'Total loss': 0.40840730965137484} | train loss {'Reaction outcome loss': 0.2340541982114386, 'Total loss': 0.2340541982114386}
2023-01-05 00:01:25,163 INFO:     Found new best model at epoch 34
2023-01-05 00:01:25,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:25,164 INFO:     Epoch: 35
2023-01-05 00:01:27,428 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4096223540604115, 'Total loss': 0.4096223540604115} | train loss {'Reaction outcome loss': 0.22980907198683964, 'Total loss': 0.22980907198683964}
2023-01-05 00:01:27,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:27,428 INFO:     Epoch: 36
2023-01-05 00:01:29,703 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.443258876601855, 'Total loss': 0.443258876601855} | train loss {'Reaction outcome loss': 0.2489074410101318, 'Total loss': 0.2489074410101318}
2023-01-05 00:01:29,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:29,704 INFO:     Epoch: 37
2023-01-05 00:01:31,952 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42576943586270016, 'Total loss': 0.42576943586270016} | train loss {'Reaction outcome loss': 0.22595179211888192, 'Total loss': 0.22595179211888192}
2023-01-05 00:01:31,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:31,952 INFO:     Epoch: 38
2023-01-05 00:01:34,220 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4206340293089549, 'Total loss': 0.4206340293089549} | train loss {'Reaction outcome loss': 0.21929515480904072, 'Total loss': 0.21929515480904072}
2023-01-05 00:01:34,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:34,221 INFO:     Epoch: 39
2023-01-05 00:01:36,479 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4344710061947505, 'Total loss': 0.4344710061947505} | train loss {'Reaction outcome loss': 0.2229307603262461, 'Total loss': 0.2229307603262461}
2023-01-05 00:01:36,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:36,479 INFO:     Epoch: 40
2023-01-05 00:01:38,754 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45618801017602284, 'Total loss': 0.45618801017602284} | train loss {'Reaction outcome loss': 0.21863169379355604, 'Total loss': 0.21863169379355604}
2023-01-05 00:01:38,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:38,755 INFO:     Epoch: 41
2023-01-05 00:01:41,026 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.471074112256368, 'Total loss': 0.471074112256368} | train loss {'Reaction outcome loss': 0.22065536441463654, 'Total loss': 0.22065536441463654}
2023-01-05 00:01:41,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:41,026 INFO:     Epoch: 42
2023-01-05 00:01:43,281 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43964821100234985, 'Total loss': 0.43964821100234985} | train loss {'Reaction outcome loss': 0.213284355944252, 'Total loss': 0.213284355944252}
2023-01-05 00:01:43,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:43,281 INFO:     Epoch: 43
2023-01-05 00:01:45,547 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4534472405910492, 'Total loss': 0.4534472405910492} | train loss {'Reaction outcome loss': 0.21726201776334125, 'Total loss': 0.21726201776334125}
2023-01-05 00:01:45,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:45,548 INFO:     Epoch: 44
2023-01-05 00:01:47,657 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45752755204836526, 'Total loss': 0.45752755204836526} | train loss {'Reaction outcome loss': 0.21077819112890764, 'Total loss': 0.21077819112890764}
2023-01-05 00:01:47,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:47,657 INFO:     Epoch: 45
2023-01-05 00:01:49,532 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.443793644507726, 'Total loss': 0.443793644507726} | train loss {'Reaction outcome loss': 0.2128558330376214, 'Total loss': 0.2128558330376214}
2023-01-05 00:01:49,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:49,533 INFO:     Epoch: 46
2023-01-05 00:01:51,468 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45234659711519876, 'Total loss': 0.45234659711519876} | train loss {'Reaction outcome loss': 0.20689375054612552, 'Total loss': 0.20689375054612552}
2023-01-05 00:01:51,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:51,468 INFO:     Epoch: 47
2023-01-05 00:01:53,713 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4411799331506093, 'Total loss': 0.4411799331506093} | train loss {'Reaction outcome loss': 0.2013902157579677, 'Total loss': 0.2013902157579677}
2023-01-05 00:01:53,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:53,713 INFO:     Epoch: 48
2023-01-05 00:01:55,996 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43613175054391223, 'Total loss': 0.43613175054391223} | train loss {'Reaction outcome loss': 0.20908041669484362, 'Total loss': 0.20908041669484362}
2023-01-05 00:01:55,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:55,997 INFO:     Epoch: 49
2023-01-05 00:01:58,262 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44714422623316447, 'Total loss': 0.44714422623316447} | train loss {'Reaction outcome loss': 0.20225118424707983, 'Total loss': 0.20225118424707983}
2023-01-05 00:01:58,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:01:58,262 INFO:     Epoch: 50
2023-01-05 00:02:00,525 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4768710578481356, 'Total loss': 0.4768710578481356} | train loss {'Reaction outcome loss': 0.20429543824782054, 'Total loss': 0.20429543824782054}
2023-01-05 00:02:00,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:00,525 INFO:     Epoch: 51
2023-01-05 00:02:02,780 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47449960907300315, 'Total loss': 0.47449960907300315} | train loss {'Reaction outcome loss': 0.2069572478321669, 'Total loss': 0.2069572478321669}
2023-01-05 00:02:02,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:02,781 INFO:     Epoch: 52
2023-01-05 00:02:05,032 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44439967075983683, 'Total loss': 0.44439967075983683} | train loss {'Reaction outcome loss': 0.19944514496621749, 'Total loss': 0.19944514496621749}
2023-01-05 00:02:05,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:05,033 INFO:     Epoch: 53
2023-01-05 00:02:07,296 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4559796382983526, 'Total loss': 0.4559796382983526} | train loss {'Reaction outcome loss': 0.19663180768754723, 'Total loss': 0.19663180768754723}
2023-01-05 00:02:07,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:07,297 INFO:     Epoch: 54
2023-01-05 00:02:09,524 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4476819187402725, 'Total loss': 0.4476819187402725} | train loss {'Reaction outcome loss': 0.19334645370237422, 'Total loss': 0.19334645370237422}
2023-01-05 00:02:09,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:09,524 INFO:     Epoch: 55
2023-01-05 00:02:11,746 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4544929335514704, 'Total loss': 0.4544929335514704} | train loss {'Reaction outcome loss': 0.1969607295822757, 'Total loss': 0.1969607295822757}
2023-01-05 00:02:11,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:11,746 INFO:     Epoch: 56
2023-01-05 00:02:14,002 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.479407525062561, 'Total loss': 0.479407525062561} | train loss {'Reaction outcome loss': 0.19339979791413128, 'Total loss': 0.19339979791413128}
2023-01-05 00:02:14,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:14,002 INFO:     Epoch: 57
2023-01-05 00:02:16,159 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47951967318852745, 'Total loss': 0.47951967318852745} | train loss {'Reaction outcome loss': 0.18969389729021635, 'Total loss': 0.18969389729021635}
2023-01-05 00:02:16,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:16,160 INFO:     Epoch: 58
2023-01-05 00:02:18,354 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4627487167716026, 'Total loss': 0.4627487167716026} | train loss {'Reaction outcome loss': 0.1919482589941438, 'Total loss': 0.1919482589941438}
2023-01-05 00:02:18,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:18,354 INFO:     Epoch: 59
2023-01-05 00:02:20,604 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4806112915277481, 'Total loss': 0.4806112915277481} | train loss {'Reaction outcome loss': 0.18852780976474448, 'Total loss': 0.18852780976474448}
2023-01-05 00:02:20,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:20,604 INFO:     Epoch: 60
2023-01-05 00:02:22,872 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4423199832439423, 'Total loss': 0.4423199832439423} | train loss {'Reaction outcome loss': 0.18912527623652367, 'Total loss': 0.18912527623652367}
2023-01-05 00:02:22,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:22,872 INFO:     Epoch: 61
2023-01-05 00:02:25,072 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.460037632783254, 'Total loss': 0.460037632783254} | train loss {'Reaction outcome loss': 0.18517325760128017, 'Total loss': 0.18517325760128017}
2023-01-05 00:02:25,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:25,073 INFO:     Epoch: 62
2023-01-05 00:02:27,320 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43697588741779325, 'Total loss': 0.43697588741779325} | train loss {'Reaction outcome loss': 0.18640125711090808, 'Total loss': 0.18640125711090808}
2023-01-05 00:02:27,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:27,320 INFO:     Epoch: 63
2023-01-05 00:02:29,553 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45742232302824654, 'Total loss': 0.45742232302824654} | train loss {'Reaction outcome loss': 0.18232144604680006, 'Total loss': 0.18232144604680006}
2023-01-05 00:02:29,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:29,553 INFO:     Epoch: 64
2023-01-05 00:02:31,821 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46979623635609946, 'Total loss': 0.46979623635609946} | train loss {'Reaction outcome loss': 0.18688035616904256, 'Total loss': 0.18688035616904256}
2023-01-05 00:02:31,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:31,822 INFO:     Epoch: 65
2023-01-05 00:02:34,096 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4491148938735326, 'Total loss': 0.4491148938735326} | train loss {'Reaction outcome loss': 0.1867581111120566, 'Total loss': 0.1867581111120566}
2023-01-05 00:02:34,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:34,096 INFO:     Epoch: 66
2023-01-05 00:02:36,368 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4355118691921234, 'Total loss': 0.4355118691921234} | train loss {'Reaction outcome loss': 0.1829564356192587, 'Total loss': 0.1829564356192587}
2023-01-05 00:02:36,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:36,368 INFO:     Epoch: 67
2023-01-05 00:02:38,617 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44910924285650256, 'Total loss': 0.44910924285650256} | train loss {'Reaction outcome loss': 0.17901986824691066, 'Total loss': 0.17901986824691066}
2023-01-05 00:02:38,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:38,617 INFO:     Epoch: 68
2023-01-05 00:02:40,819 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4635798841714859, 'Total loss': 0.4635798841714859} | train loss {'Reaction outcome loss': 0.17889891014678194, 'Total loss': 0.17889891014678194}
2023-01-05 00:02:40,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:40,819 INFO:     Epoch: 69
2023-01-05 00:02:43,046 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45590984721978506, 'Total loss': 0.45590984721978506} | train loss {'Reaction outcome loss': 0.1830501418376841, 'Total loss': 0.1830501418376841}
2023-01-05 00:02:43,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:43,046 INFO:     Epoch: 70
2023-01-05 00:02:45,314 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4732014606396357, 'Total loss': 0.4732014606396357} | train loss {'Reaction outcome loss': 0.18014593493864886, 'Total loss': 0.18014593493864886}
2023-01-05 00:02:45,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:45,315 INFO:     Epoch: 71
2023-01-05 00:02:47,583 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4720511148373286, 'Total loss': 0.4720511148373286} | train loss {'Reaction outcome loss': 0.17467341010384532, 'Total loss': 0.17467341010384532}
2023-01-05 00:02:47,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:47,583 INFO:     Epoch: 72
2023-01-05 00:02:49,825 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45065163100759187, 'Total loss': 0.45065163100759187} | train loss {'Reaction outcome loss': 0.17274867675966918, 'Total loss': 0.17274867675966918}
2023-01-05 00:02:49,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:49,826 INFO:     Epoch: 73
2023-01-05 00:02:52,046 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4538480967283249, 'Total loss': 0.4538480967283249} | train loss {'Reaction outcome loss': 0.17844188112792544, 'Total loss': 0.17844188112792544}
2023-01-05 00:02:52,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:52,046 INFO:     Epoch: 74
2023-01-05 00:02:54,270 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44683375110228857, 'Total loss': 0.44683375110228857} | train loss {'Reaction outcome loss': 0.17343886619420262, 'Total loss': 0.17343886619420262}
2023-01-05 00:02:54,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:54,270 INFO:     Epoch: 75
2023-01-05 00:02:56,533 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45909021894137064, 'Total loss': 0.45909021894137064} | train loss {'Reaction outcome loss': 0.17436733936314788, 'Total loss': 0.17436733936314788}
2023-01-05 00:02:56,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:56,533 INFO:     Epoch: 76
2023-01-05 00:02:58,764 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4640794575214386, 'Total loss': 0.4640794575214386} | train loss {'Reaction outcome loss': 0.1720735075729296, 'Total loss': 0.1720735075729296}
2023-01-05 00:02:58,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:02:58,765 INFO:     Epoch: 77
2023-01-05 00:03:01,019 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5117986291646958, 'Total loss': 0.5117986291646958} | train loss {'Reaction outcome loss': 0.17303502740105614, 'Total loss': 0.17303502740105614}
2023-01-05 00:03:01,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:01,020 INFO:     Epoch: 78
2023-01-05 00:03:03,223 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46980421741803485, 'Total loss': 0.46980421741803485} | train loss {'Reaction outcome loss': 0.17130855973674983, 'Total loss': 0.17130855973674983}
2023-01-05 00:03:03,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:03,223 INFO:     Epoch: 79
2023-01-05 00:03:05,402 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4397138739625613, 'Total loss': 0.4397138739625613} | train loss {'Reaction outcome loss': 0.1727932464108681, 'Total loss': 0.1727932464108681}
2023-01-05 00:03:05,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:05,403 INFO:     Epoch: 80
2023-01-05 00:03:07,605 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4956873814264933, 'Total loss': 0.4956873814264933} | train loss {'Reaction outcome loss': 0.17389712540075972, 'Total loss': 0.17389712540075972}
2023-01-05 00:03:07,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:07,605 INFO:     Epoch: 81
2023-01-05 00:03:09,855 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.480513866742452, 'Total loss': 0.480513866742452} | train loss {'Reaction outcome loss': 0.17165238074992067, 'Total loss': 0.17165238074992067}
2023-01-05 00:03:09,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:09,856 INFO:     Epoch: 82
2023-01-05 00:03:12,133 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4642118642727534, 'Total loss': 0.4642118642727534} | train loss {'Reaction outcome loss': 0.16798071863478942, 'Total loss': 0.16798071863478942}
2023-01-05 00:03:12,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:12,134 INFO:     Epoch: 83
2023-01-05 00:03:14,361 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4745775202910105, 'Total loss': 0.4745775202910105} | train loss {'Reaction outcome loss': 0.16989022805659182, 'Total loss': 0.16989022805659182}
2023-01-05 00:03:14,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:14,361 INFO:     Epoch: 84
2023-01-05 00:03:16,577 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4654092133045197, 'Total loss': 0.4654092133045197} | train loss {'Reaction outcome loss': 0.16797920394067964, 'Total loss': 0.16797920394067964}
2023-01-05 00:03:16,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:16,578 INFO:     Epoch: 85
2023-01-05 00:03:18,832 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.470490703980128, 'Total loss': 0.470490703980128} | train loss {'Reaction outcome loss': 0.16460742180760976, 'Total loss': 0.16460742180760976}
2023-01-05 00:03:18,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:18,832 INFO:     Epoch: 86
2023-01-05 00:03:21,089 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4618647734324137, 'Total loss': 0.4618647734324137} | train loss {'Reaction outcome loss': 0.17166942251724718, 'Total loss': 0.17166942251724718}
2023-01-05 00:03:21,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:21,090 INFO:     Epoch: 87
2023-01-05 00:03:23,339 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45568973024686177, 'Total loss': 0.45568973024686177} | train loss {'Reaction outcome loss': 0.16872617772078494, 'Total loss': 0.16872617772078494}
2023-01-05 00:03:23,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:23,339 INFO:     Epoch: 88
2023-01-05 00:03:25,572 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4643489400545756, 'Total loss': 0.4643489400545756} | train loss {'Reaction outcome loss': 0.166738199759203, 'Total loss': 0.166738199759203}
2023-01-05 00:03:25,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:25,573 INFO:     Epoch: 89
2023-01-05 00:03:27,790 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45194864173730215, 'Total loss': 0.45194864173730215} | train loss {'Reaction outcome loss': 0.16873700112193837, 'Total loss': 0.16873700112193837}
2023-01-05 00:03:27,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:27,790 INFO:     Epoch: 90
2023-01-05 00:03:30,038 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.461978568136692, 'Total loss': 0.461978568136692} | train loss {'Reaction outcome loss': 0.1692658068881893, 'Total loss': 0.1692658068881893}
2023-01-05 00:03:30,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:30,038 INFO:     Epoch: 91
2023-01-05 00:03:32,292 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.487029692530632, 'Total loss': 0.487029692530632} | train loss {'Reaction outcome loss': 0.1674901605684958, 'Total loss': 0.1674901605684958}
2023-01-05 00:03:32,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:32,292 INFO:     Epoch: 92
2023-01-05 00:03:34,540 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44795599977175393, 'Total loss': 0.44795599977175393} | train loss {'Reaction outcome loss': 0.16623745209105528, 'Total loss': 0.16623745209105528}
2023-01-05 00:03:34,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:34,541 INFO:     Epoch: 93
2023-01-05 00:03:36,769 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4751881182193756, 'Total loss': 0.4751881182193756} | train loss {'Reaction outcome loss': 0.1640105044499132, 'Total loss': 0.1640105044499132}
2023-01-05 00:03:36,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:36,770 INFO:     Epoch: 94
2023-01-05 00:03:39,013 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4494563142458598, 'Total loss': 0.4494563142458598} | train loss {'Reaction outcome loss': 0.1646484849464084, 'Total loss': 0.1646484849464084}
2023-01-05 00:03:39,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:39,014 INFO:     Epoch: 95
2023-01-05 00:03:41,154 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.482789205511411, 'Total loss': 0.482789205511411} | train loss {'Reaction outcome loss': 0.16440385767151117, 'Total loss': 0.16440385767151117}
2023-01-05 00:03:41,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:41,155 INFO:     Epoch: 96
2023-01-05 00:03:43,389 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4630296180645625, 'Total loss': 0.4630296180645625} | train loss {'Reaction outcome loss': 0.1611837683881606, 'Total loss': 0.1611837683881606}
2023-01-05 00:03:43,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:43,390 INFO:     Epoch: 97
2023-01-05 00:03:45,638 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4667763071755568, 'Total loss': 0.4667763071755568} | train loss {'Reaction outcome loss': 0.16026246032434638, 'Total loss': 0.16026246032434638}
2023-01-05 00:03:45,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:45,638 INFO:     Epoch: 98
2023-01-05 00:03:47,874 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46428722540537515, 'Total loss': 0.46428722540537515} | train loss {'Reaction outcome loss': 0.16428793048508733, 'Total loss': 0.16428793048508733}
2023-01-05 00:03:47,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:47,874 INFO:     Epoch: 99
2023-01-05 00:03:50,114 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43743169655402503, 'Total loss': 0.43743169655402503} | train loss {'Reaction outcome loss': 0.16520913989296643, 'Total loss': 0.16520913989296643}
2023-01-05 00:03:50,114 INFO:     Best model found after epoch 35 of 100.
2023-01-05 00:03:50,114 INFO:   Done with stage: TRAINING
2023-01-05 00:03:50,114 INFO:   Starting stage: EVALUATION
2023-01-05 00:03:50,249 INFO:   Done with stage: EVALUATION
2023-01-05 00:03:50,249 INFO:   Leaving out SEQ value Fold_7
2023-01-05 00:03:50,262 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 00:03:50,262 INFO:   Starting stage: FEATURE SCALING
2023-01-05 00:03:50,913 INFO:   Done with stage: FEATURE SCALING
2023-01-05 00:03:50,913 INFO:   Starting stage: SCALING TARGETS
2023-01-05 00:03:50,984 INFO:   Done with stage: SCALING TARGETS
2023-01-05 00:03:50,984 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:03:50,984 INFO:     No hyperparam tuning for this model
2023-01-05 00:03:50,984 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:03:50,984 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 00:03:50,985 INFO:     None feature selector for col prot
2023-01-05 00:03:50,985 INFO:     None feature selector for col prot
2023-01-05 00:03:50,985 INFO:     None feature selector for col prot
2023-01-05 00:03:50,985 INFO:     None feature selector for col chem
2023-01-05 00:03:50,985 INFO:     None feature selector for col chem
2023-01-05 00:03:50,986 INFO:     None feature selector for col chem
2023-01-05 00:03:50,986 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 00:03:50,986 INFO:   Starting stage: BUILD MODEL
2023-01-05 00:03:50,987 INFO:     Number of params in model 72931
2023-01-05 00:03:50,990 INFO:   Done with stage: BUILD MODEL
2023-01-05 00:03:50,990 INFO:   Starting stage: TRAINING
2023-01-05 00:03:51,050 INFO:     Val loss before train {'Reaction outcome loss': 1.047385334968567, 'Total loss': 1.047385334968567}
2023-01-05 00:03:51,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:51,050 INFO:     Epoch: 0
2023-01-05 00:03:53,275 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8012117743492126, 'Total loss': 0.8012117743492126} | train loss {'Reaction outcome loss': 0.9406197681159213, 'Total loss': 0.9406197681159213}
2023-01-05 00:03:53,275 INFO:     Found new best model at epoch 0
2023-01-05 00:03:53,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:53,277 INFO:     Epoch: 1
2023-01-05 00:03:55,505 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6062492171923319, 'Total loss': 0.6062492171923319} | train loss {'Reaction outcome loss': 0.648737832714898, 'Total loss': 0.648737832714898}
2023-01-05 00:03:55,506 INFO:     Found new best model at epoch 1
2023-01-05 00:03:55,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:55,508 INFO:     Epoch: 2
2023-01-05 00:03:57,725 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5585258543491364, 'Total loss': 0.5585258543491364} | train loss {'Reaction outcome loss': 0.5568571501167964, 'Total loss': 0.5568571501167964}
2023-01-05 00:03:57,725 INFO:     Found new best model at epoch 2
2023-01-05 00:03:57,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:57,727 INFO:     Epoch: 3
2023-01-05 00:03:59,942 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5324652165174484, 'Total loss': 0.5324652165174484} | train loss {'Reaction outcome loss': 0.5318296040961707, 'Total loss': 0.5318296040961707}
2023-01-05 00:03:59,942 INFO:     Found new best model at epoch 3
2023-01-05 00:03:59,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:03:59,943 INFO:     Epoch: 4
2023-01-05 00:04:02,171 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.533372986316681, 'Total loss': 0.533372986316681} | train loss {'Reaction outcome loss': 0.49242146358406846, 'Total loss': 0.49242146358406846}
2023-01-05 00:04:02,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:02,171 INFO:     Epoch: 5
2023-01-05 00:04:04,432 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5044562002023061, 'Total loss': 0.5044562002023061} | train loss {'Reaction outcome loss': 0.4688627491502658, 'Total loss': 0.4688627491502658}
2023-01-05 00:04:04,432 INFO:     Found new best model at epoch 5
2023-01-05 00:04:04,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:04,434 INFO:     Epoch: 6
2023-01-05 00:04:06,666 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4970379094282786, 'Total loss': 0.4970379094282786} | train loss {'Reaction outcome loss': 0.4496548834739361, 'Total loss': 0.4496548834739361}
2023-01-05 00:04:06,666 INFO:     Found new best model at epoch 6
2023-01-05 00:04:06,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:06,667 INFO:     Epoch: 7
2023-01-05 00:04:08,921 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48411442240079244, 'Total loss': 0.48411442240079244} | train loss {'Reaction outcome loss': 0.4307413184070501, 'Total loss': 0.4307413184070501}
2023-01-05 00:04:08,921 INFO:     Found new best model at epoch 7
2023-01-05 00:04:08,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:08,923 INFO:     Epoch: 8
2023-01-05 00:04:11,171 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48821038405100503, 'Total loss': 0.48821038405100503} | train loss {'Reaction outcome loss': 0.4372969510816578, 'Total loss': 0.4372969510816578}
2023-01-05 00:04:11,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:11,171 INFO:     Epoch: 9
2023-01-05 00:04:13,382 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4769749681154887, 'Total loss': 0.4769749681154887} | train loss {'Reaction outcome loss': 0.41463795749713545, 'Total loss': 0.41463795749713545}
2023-01-05 00:04:13,384 INFO:     Found new best model at epoch 9
2023-01-05 00:04:13,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:13,385 INFO:     Epoch: 10
2023-01-05 00:04:15,645 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46863739291826884, 'Total loss': 0.46863739291826884} | train loss {'Reaction outcome loss': 0.42277855728415475, 'Total loss': 0.42277855728415475}
2023-01-05 00:04:15,645 INFO:     Found new best model at epoch 10
2023-01-05 00:04:15,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:15,647 INFO:     Epoch: 11
2023-01-05 00:04:17,905 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4869465887546539, 'Total loss': 0.4869465887546539} | train loss {'Reaction outcome loss': 0.39569461594025296, 'Total loss': 0.39569461594025296}
2023-01-05 00:04:17,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:17,905 INFO:     Epoch: 12
2023-01-05 00:04:20,172 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45106480121612547, 'Total loss': 0.45106480121612547} | train loss {'Reaction outcome loss': 0.39217877023569914, 'Total loss': 0.39217877023569914}
2023-01-05 00:04:20,173 INFO:     Found new best model at epoch 12
2023-01-05 00:04:20,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:20,175 INFO:     Epoch: 13
2023-01-05 00:04:22,410 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46734514087438583, 'Total loss': 0.46734514087438583} | train loss {'Reaction outcome loss': 0.3870601168550227, 'Total loss': 0.3870601168550227}
2023-01-05 00:04:22,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:22,410 INFO:     Epoch: 14
2023-01-05 00:04:24,673 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46040103435516355, 'Total loss': 0.46040103435516355} | train loss {'Reaction outcome loss': 0.37072771293637546, 'Total loss': 0.37072771293637546}
2023-01-05 00:04:24,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:24,674 INFO:     Epoch: 15
2023-01-05 00:04:26,905 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4518357346455256, 'Total loss': 0.4518357346455256} | train loss {'Reaction outcome loss': 0.3657706078939304, 'Total loss': 0.3657706078939304}
2023-01-05 00:04:26,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:26,906 INFO:     Epoch: 16
2023-01-05 00:04:29,129 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.456793882449468, 'Total loss': 0.456793882449468} | train loss {'Reaction outcome loss': 0.3531521425877303, 'Total loss': 0.3531521425877303}
2023-01-05 00:04:29,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:29,129 INFO:     Epoch: 17
2023-01-05 00:04:31,374 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44169972638289134, 'Total loss': 0.44169972638289134} | train loss {'Reaction outcome loss': 0.346645820983753, 'Total loss': 0.346645820983753}
2023-01-05 00:04:31,374 INFO:     Found new best model at epoch 17
2023-01-05 00:04:31,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:31,376 INFO:     Epoch: 18
2023-01-05 00:04:33,622 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44902216593424477, 'Total loss': 0.44902216593424477} | train loss {'Reaction outcome loss': 0.34100886948568665, 'Total loss': 0.34100886948568665}
2023-01-05 00:04:33,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:33,623 INFO:     Epoch: 19
2023-01-05 00:04:35,816 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45586488445599876, 'Total loss': 0.45586488445599876} | train loss {'Reaction outcome loss': 0.3406228910409508, 'Total loss': 0.3406228910409508}
2023-01-05 00:04:35,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:35,816 INFO:     Epoch: 20
2023-01-05 00:04:38,078 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43234205345312754, 'Total loss': 0.43234205345312754} | train loss {'Reaction outcome loss': 0.3314103970466101, 'Total loss': 0.3314103970466101}
2023-01-05 00:04:38,078 INFO:     Found new best model at epoch 20
2023-01-05 00:04:38,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:38,080 INFO:     Epoch: 21
2023-01-05 00:04:40,280 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46608807643254596, 'Total loss': 0.46608807643254596} | train loss {'Reaction outcome loss': 0.3403657663586563, 'Total loss': 0.3403657663586563}
2023-01-05 00:04:40,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:40,281 INFO:     Epoch: 22
2023-01-05 00:04:42,549 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.451986563205719, 'Total loss': 0.451986563205719} | train loss {'Reaction outcome loss': 0.3329051569360646, 'Total loss': 0.3329051569360646}
2023-01-05 00:04:42,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:42,549 INFO:     Epoch: 23
2023-01-05 00:04:44,709 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4337557117144267, 'Total loss': 0.4337557117144267} | train loss {'Reaction outcome loss': 0.31725264755685045, 'Total loss': 0.31725264755685045}
2023-01-05 00:04:44,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:44,710 INFO:     Epoch: 24
2023-01-05 00:04:46,935 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4178723643223445, 'Total loss': 0.4178723643223445} | train loss {'Reaction outcome loss': 0.3109741641927268, 'Total loss': 0.3109741641927268}
2023-01-05 00:04:46,936 INFO:     Found new best model at epoch 24
2023-01-05 00:04:46,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:46,937 INFO:     Epoch: 25
2023-01-05 00:04:49,147 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4398706098397573, 'Total loss': 0.4398706098397573} | train loss {'Reaction outcome loss': 0.30852746387160773, 'Total loss': 0.30852746387160773}
2023-01-05 00:04:49,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:49,149 INFO:     Epoch: 26
2023-01-05 00:04:51,392 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4251851965983709, 'Total loss': 0.4251851965983709} | train loss {'Reaction outcome loss': 0.30029386555964965, 'Total loss': 0.30029386555964965}
2023-01-05 00:04:51,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:51,392 INFO:     Epoch: 27
2023-01-05 00:04:53,659 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44755373696486156, 'Total loss': 0.44755373696486156} | train loss {'Reaction outcome loss': 0.30318923895206157, 'Total loss': 0.30318923895206157}
2023-01-05 00:04:53,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:53,659 INFO:     Epoch: 28
2023-01-05 00:04:55,936 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42100798785686494, 'Total loss': 0.42100798785686494} | train loss {'Reaction outcome loss': 0.29881941582467675, 'Total loss': 0.29881941582467675}
2023-01-05 00:04:55,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:55,937 INFO:     Epoch: 29
2023-01-05 00:04:58,157 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4514686703681946, 'Total loss': 0.4514686703681946} | train loss {'Reaction outcome loss': 0.2901360849863377, 'Total loss': 0.2901360849863377}
2023-01-05 00:04:58,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:04:58,157 INFO:     Epoch: 30
2023-01-05 00:05:00,394 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44234848817189537, 'Total loss': 0.44234848817189537} | train loss {'Reaction outcome loss': 0.2874194744238765, 'Total loss': 0.2874194744238765}
2023-01-05 00:05:00,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:00,395 INFO:     Epoch: 31
2023-01-05 00:05:02,647 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4182078589995702, 'Total loss': 0.4182078589995702} | train loss {'Reaction outcome loss': 0.286365082766692, 'Total loss': 0.286365082766692}
2023-01-05 00:05:02,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:02,648 INFO:     Epoch: 32
2023-01-05 00:05:04,894 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44866088032722473, 'Total loss': 0.44866088032722473} | train loss {'Reaction outcome loss': 0.28242651950500475, 'Total loss': 0.28242651950500475}
2023-01-05 00:05:04,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:04,895 INFO:     Epoch: 33
2023-01-05 00:05:07,141 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45254039267698926, 'Total loss': 0.45254039267698926} | train loss {'Reaction outcome loss': 0.2827238701292368, 'Total loss': 0.2827238701292368}
2023-01-05 00:05:07,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:07,141 INFO:     Epoch: 34
2023-01-05 00:05:09,369 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4316586414972941, 'Total loss': 0.4316586414972941} | train loss {'Reaction outcome loss': 0.2931598142815241, 'Total loss': 0.2931598142815241}
2023-01-05 00:05:09,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:09,370 INFO:     Epoch: 35
2023-01-05 00:05:11,617 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.439363557100296, 'Total loss': 0.439363557100296} | train loss {'Reaction outcome loss': 0.2822808607859348, 'Total loss': 0.2822808607859348}
2023-01-05 00:05:11,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:11,617 INFO:     Epoch: 36
2023-01-05 00:05:13,863 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42518821159998577, 'Total loss': 0.42518821159998577} | train loss {'Reaction outcome loss': 0.26888286078051815, 'Total loss': 0.26888286078051815}
2023-01-05 00:05:13,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:13,863 INFO:     Epoch: 37
2023-01-05 00:05:16,148 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4127689739068349, 'Total loss': 0.4127689739068349} | train loss {'Reaction outcome loss': 0.27107316409271426, 'Total loss': 0.27107316409271426}
2023-01-05 00:05:16,148 INFO:     Found new best model at epoch 37
2023-01-05 00:05:16,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:16,149 INFO:     Epoch: 38
2023-01-05 00:05:18,393 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42965511282285057, 'Total loss': 0.42965511282285057} | train loss {'Reaction outcome loss': 0.266784076500733, 'Total loss': 0.266784076500733}
2023-01-05 00:05:18,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:18,394 INFO:     Epoch: 39
2023-01-05 00:05:20,614 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44594690402348836, 'Total loss': 0.44594690402348836} | train loss {'Reaction outcome loss': 0.26203591088372946, 'Total loss': 0.26203591088372946}
2023-01-05 00:05:20,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:20,615 INFO:     Epoch: 40
2023-01-05 00:05:22,757 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4410285145044327, 'Total loss': 0.4410285145044327} | train loss {'Reaction outcome loss': 0.28511657475399366, 'Total loss': 0.28511657475399366}
2023-01-05 00:05:22,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:22,757 INFO:     Epoch: 41
2023-01-05 00:05:24,999 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4524594704310099, 'Total loss': 0.4524594704310099} | train loss {'Reaction outcome loss': 0.2552372723158982, 'Total loss': 0.2552372723158982}
2023-01-05 00:05:25,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:25,000 INFO:     Epoch: 42
2023-01-05 00:05:27,247 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44031033118565877, 'Total loss': 0.44031033118565877} | train loss {'Reaction outcome loss': 0.2545171901777697, 'Total loss': 0.2545171901777697}
2023-01-05 00:05:27,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:27,248 INFO:     Epoch: 43
2023-01-05 00:05:29,437 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4586570938428243, 'Total loss': 0.4586570938428243} | train loss {'Reaction outcome loss': 0.24844976368805635, 'Total loss': 0.24844976368805635}
2023-01-05 00:05:29,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:29,437 INFO:     Epoch: 44
2023-01-05 00:05:31,683 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4379181702931722, 'Total loss': 0.4379181702931722} | train loss {'Reaction outcome loss': 0.2453423127990918, 'Total loss': 0.2453423127990918}
2023-01-05 00:05:31,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:31,684 INFO:     Epoch: 45
2023-01-05 00:05:33,948 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45222591757774355, 'Total loss': 0.45222591757774355} | train loss {'Reaction outcome loss': 0.24663006069781462, 'Total loss': 0.24663006069781462}
2023-01-05 00:05:33,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:33,948 INFO:     Epoch: 46
2023-01-05 00:05:36,182 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47144096394379936, 'Total loss': 0.47144096394379936} | train loss {'Reaction outcome loss': 0.24191311155859233, 'Total loss': 0.24191311155859233}
2023-01-05 00:05:36,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:36,182 INFO:     Epoch: 47
2023-01-05 00:05:38,394 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44971350530783333, 'Total loss': 0.44971350530783333} | train loss {'Reaction outcome loss': 0.2392321777913004, 'Total loss': 0.2392321777913004}
2023-01-05 00:05:38,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:38,394 INFO:     Epoch: 48
2023-01-05 00:05:40,613 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4550149867932002, 'Total loss': 0.4550149867932002} | train loss {'Reaction outcome loss': 0.23678217787212064, 'Total loss': 0.23678217787212064}
2023-01-05 00:05:40,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:40,613 INFO:     Epoch: 49
2023-01-05 00:05:42,864 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44001362919807435, 'Total loss': 0.44001362919807435} | train loss {'Reaction outcome loss': 0.23720760965395882, 'Total loss': 0.23720760965395882}
2023-01-05 00:05:42,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:42,864 INFO:     Epoch: 50
2023-01-05 00:05:45,110 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4375250369310379, 'Total loss': 0.4375250369310379} | train loss {'Reaction outcome loss': 0.23584076953883978, 'Total loss': 0.23584076953883978}
2023-01-05 00:05:45,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:45,111 INFO:     Epoch: 51
2023-01-05 00:05:47,347 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4289255698521932, 'Total loss': 0.4289255698521932} | train loss {'Reaction outcome loss': 0.23349731954226297, 'Total loss': 0.23349731954226297}
2023-01-05 00:05:47,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:47,347 INFO:     Epoch: 52
2023-01-05 00:05:49,607 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46387777527173363, 'Total loss': 0.46387777527173363} | train loss {'Reaction outcome loss': 0.23537680229515978, 'Total loss': 0.23537680229515978}
2023-01-05 00:05:49,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:49,608 INFO:     Epoch: 53
2023-01-05 00:05:51,816 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44088952938715614, 'Total loss': 0.44088952938715614} | train loss {'Reaction outcome loss': 0.22698085674125215, 'Total loss': 0.22698085674125215}
2023-01-05 00:05:51,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:51,817 INFO:     Epoch: 54
2023-01-05 00:05:54,071 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4214256415764491, 'Total loss': 0.4214256415764491} | train loss {'Reaction outcome loss': 0.2231432293403381, 'Total loss': 0.2231432293403381}
2023-01-05 00:05:54,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:54,072 INFO:     Epoch: 55
2023-01-05 00:05:56,244 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4300574352343877, 'Total loss': 0.4300574352343877} | train loss {'Reaction outcome loss': 0.222328443998012, 'Total loss': 0.222328443998012}
2023-01-05 00:05:56,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:56,245 INFO:     Epoch: 56
2023-01-05 00:05:58,510 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43636052509148915, 'Total loss': 0.43636052509148915} | train loss {'Reaction outcome loss': 0.2239867737103402, 'Total loss': 0.2239867737103402}
2023-01-05 00:05:58,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:05:58,511 INFO:     Epoch: 57
2023-01-05 00:06:00,731 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4583093444506327, 'Total loss': 0.4583093444506327} | train loss {'Reaction outcome loss': 0.22307584229418062, 'Total loss': 0.22307584229418062}
2023-01-05 00:06:00,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:00,732 INFO:     Epoch: 58
2023-01-05 00:06:02,964 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42768517484267554, 'Total loss': 0.42768517484267554} | train loss {'Reaction outcome loss': 0.2233905052880932, 'Total loss': 0.2233905052880932}
2023-01-05 00:06:02,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:02,965 INFO:     Epoch: 59
2023-01-05 00:06:05,210 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4044009432196617, 'Total loss': 0.4044009432196617} | train loss {'Reaction outcome loss': 0.21361122847412078, 'Total loss': 0.21361122847412078}
2023-01-05 00:06:05,210 INFO:     Found new best model at epoch 59
2023-01-05 00:06:05,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:05,212 INFO:     Epoch: 60
2023-01-05 00:06:07,467 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4281558394432068, 'Total loss': 0.4281558394432068} | train loss {'Reaction outcome loss': 0.21154286596288, 'Total loss': 0.21154286596288}
2023-01-05 00:06:07,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:07,467 INFO:     Epoch: 61
2023-01-05 00:06:09,751 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4401737650235494, 'Total loss': 0.4401737650235494} | train loss {'Reaction outcome loss': 0.21700174055581886, 'Total loss': 0.21700174055581886}
2023-01-05 00:06:09,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:09,751 INFO:     Epoch: 62
2023-01-05 00:06:11,994 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4700807472070058, 'Total loss': 0.4700807472070058} | train loss {'Reaction outcome loss': 0.21321802437339193, 'Total loss': 0.21321802437339193}
2023-01-05 00:06:11,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:11,994 INFO:     Epoch: 63
2023-01-05 00:06:14,251 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4361720164616903, 'Total loss': 0.4361720164616903} | train loss {'Reaction outcome loss': 0.21208011510147565, 'Total loss': 0.21208011510147565}
2023-01-05 00:06:14,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:14,251 INFO:     Epoch: 64
2023-01-05 00:06:16,506 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46654940048853555, 'Total loss': 0.46654940048853555} | train loss {'Reaction outcome loss': 0.21859253833299855, 'Total loss': 0.21859253833299855}
2023-01-05 00:06:16,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:16,506 INFO:     Epoch: 65
2023-01-05 00:06:18,733 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44722873667875923, 'Total loss': 0.44722873667875923} | train loss {'Reaction outcome loss': 0.2455286621487281, 'Total loss': 0.2455286621487281}
2023-01-05 00:06:18,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:18,734 INFO:     Epoch: 66
2023-01-05 00:06:20,990 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4376092503468196, 'Total loss': 0.4376092503468196} | train loss {'Reaction outcome loss': 0.21302167077184372, 'Total loss': 0.21302167077184372}
2023-01-05 00:06:20,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:20,991 INFO:     Epoch: 67
2023-01-05 00:06:23,206 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4543656751513481, 'Total loss': 0.4543656751513481} | train loss {'Reaction outcome loss': 0.20742029117072758, 'Total loss': 0.20742029117072758}
2023-01-05 00:06:23,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:23,206 INFO:     Epoch: 68
2023-01-05 00:06:25,474 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42361808121204375, 'Total loss': 0.42361808121204375} | train loss {'Reaction outcome loss': 0.1986611618597543, 'Total loss': 0.1986611618597543}
2023-01-05 00:06:25,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:25,474 INFO:     Epoch: 69
2023-01-05 00:06:27,753 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43462446133295696, 'Total loss': 0.43462446133295696} | train loss {'Reaction outcome loss': 0.19981566118329522, 'Total loss': 0.19981566118329522}
2023-01-05 00:06:27,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:27,754 INFO:     Epoch: 70
2023-01-05 00:06:30,015 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47498664955298103, 'Total loss': 0.47498664955298103} | train loss {'Reaction outcome loss': 0.20337769489537016, 'Total loss': 0.20337769489537016}
2023-01-05 00:06:30,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:30,016 INFO:     Epoch: 71
2023-01-05 00:06:32,279 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44563652376333873, 'Total loss': 0.44563652376333873} | train loss {'Reaction outcome loss': 0.19804445699834183, 'Total loss': 0.19804445699834183}
2023-01-05 00:06:32,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:32,279 INFO:     Epoch: 72
2023-01-05 00:06:34,537 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4387614667415619, 'Total loss': 0.4387614667415619} | train loss {'Reaction outcome loss': 0.19871771206701364, 'Total loss': 0.19871771206701364}
2023-01-05 00:06:34,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:34,537 INFO:     Epoch: 73
2023-01-05 00:06:36,805 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44456330041090647, 'Total loss': 0.44456330041090647} | train loss {'Reaction outcome loss': 0.19995436627768737, 'Total loss': 0.19995436627768737}
2023-01-05 00:06:36,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:36,806 INFO:     Epoch: 74
2023-01-05 00:06:39,042 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4244736055533091, 'Total loss': 0.4244736055533091} | train loss {'Reaction outcome loss': 0.19226346173715117, 'Total loss': 0.19226346173715117}
2023-01-05 00:06:39,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:39,042 INFO:     Epoch: 75
2023-01-05 00:06:41,320 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4406981587409973, 'Total loss': 0.4406981587409973} | train loss {'Reaction outcome loss': 0.19266543051133445, 'Total loss': 0.19266543051133445}
2023-01-05 00:06:41,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:41,320 INFO:     Epoch: 76
2023-01-05 00:06:43,559 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4501791924238205, 'Total loss': 0.4501791924238205} | train loss {'Reaction outcome loss': 0.19423325341792236, 'Total loss': 0.19423325341792236}
2023-01-05 00:06:43,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:43,560 INFO:     Epoch: 77
2023-01-05 00:06:45,782 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4537459631760915, 'Total loss': 0.4537459631760915} | train loss {'Reaction outcome loss': 0.19343622585828585, 'Total loss': 0.19343622585828585}
2023-01-05 00:06:45,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:45,782 INFO:     Epoch: 78
2023-01-05 00:06:47,989 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43245387971401217, 'Total loss': 0.43245387971401217} | train loss {'Reaction outcome loss': 0.19343276520131453, 'Total loss': 0.19343276520131453}
2023-01-05 00:06:47,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:47,990 INFO:     Epoch: 79
2023-01-05 00:06:50,246 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4573186581333478, 'Total loss': 0.4573186581333478} | train loss {'Reaction outcome loss': 0.1893617701952926, 'Total loss': 0.1893617701952926}
2023-01-05 00:06:50,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:50,246 INFO:     Epoch: 80
2023-01-05 00:06:52,497 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4186314282317956, 'Total loss': 0.4186314282317956} | train loss {'Reaction outcome loss': 0.19027838348647227, 'Total loss': 0.19027838348647227}
2023-01-05 00:06:52,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:52,498 INFO:     Epoch: 81
2023-01-05 00:06:54,741 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4473796730240186, 'Total loss': 0.4473796730240186} | train loss {'Reaction outcome loss': 0.19321140034994838, 'Total loss': 0.19321140034994838}
2023-01-05 00:06:54,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:54,741 INFO:     Epoch: 82
2023-01-05 00:06:56,993 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42728019853432975, 'Total loss': 0.42728019853432975} | train loss {'Reaction outcome loss': 0.18956873852057735, 'Total loss': 0.18956873852057735}
2023-01-05 00:06:56,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:56,994 INFO:     Epoch: 83
2023-01-05 00:06:59,226 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4503797620534897, 'Total loss': 0.4503797620534897} | train loss {'Reaction outcome loss': 0.19077748031628763, 'Total loss': 0.19077748031628763}
2023-01-05 00:06:59,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:06:59,226 INFO:     Epoch: 84
2023-01-05 00:07:01,480 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41719502011934917, 'Total loss': 0.41719502011934917} | train loss {'Reaction outcome loss': 0.18454367599274585, 'Total loss': 0.18454367599274585}
2023-01-05 00:07:01,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:01,480 INFO:     Epoch: 85
2023-01-05 00:07:03,711 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45364575684070585, 'Total loss': 0.45364575684070585} | train loss {'Reaction outcome loss': 0.193295710456922, 'Total loss': 0.193295710456922}
2023-01-05 00:07:03,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:03,712 INFO:     Epoch: 86
2023-01-05 00:07:05,969 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4415258770187696, 'Total loss': 0.4415258770187696} | train loss {'Reaction outcome loss': 0.18709483268954183, 'Total loss': 0.18709483268954183}
2023-01-05 00:07:05,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:05,969 INFO:     Epoch: 87
2023-01-05 00:07:08,228 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45199362536271415, 'Total loss': 0.45199362536271415} | train loss {'Reaction outcome loss': 0.18252826160054267, 'Total loss': 0.18252826160054267}
2023-01-05 00:07:08,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:08,228 INFO:     Epoch: 88
2023-01-05 00:07:10,414 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4428795943657557, 'Total loss': 0.4428795943657557} | train loss {'Reaction outcome loss': 0.18025196220235334, 'Total loss': 0.18025196220235334}
2023-01-05 00:07:10,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:10,414 INFO:     Epoch: 89
2023-01-05 00:07:12,591 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44891521831353504, 'Total loss': 0.44891521831353504} | train loss {'Reaction outcome loss': 0.18727204485587895, 'Total loss': 0.18727204485587895}
2023-01-05 00:07:12,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:12,592 INFO:     Epoch: 90
2023-01-05 00:07:14,856 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45372176766395567, 'Total loss': 0.45372176766395567} | train loss {'Reaction outcome loss': 0.18229423461994831, 'Total loss': 0.18229423461994831}
2023-01-05 00:07:14,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:14,856 INFO:     Epoch: 91
2023-01-05 00:07:17,069 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45957555770874026, 'Total loss': 0.45957555770874026} | train loss {'Reaction outcome loss': 0.1821655151181166, 'Total loss': 0.1821655151181166}
2023-01-05 00:07:17,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:17,069 INFO:     Epoch: 92
2023-01-05 00:07:19,320 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46261069774627683, 'Total loss': 0.46261069774627683} | train loss {'Reaction outcome loss': 0.18278315281529195, 'Total loss': 0.18278315281529195}
2023-01-05 00:07:19,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:19,321 INFO:     Epoch: 93
2023-01-05 00:07:21,567 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44357968171437584, 'Total loss': 0.44357968171437584} | train loss {'Reaction outcome loss': 0.17583606074449432, 'Total loss': 0.17583606074449432}
2023-01-05 00:07:21,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:21,568 INFO:     Epoch: 94
2023-01-05 00:07:23,718 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47967264652252195, 'Total loss': 0.47967264652252195} | train loss {'Reaction outcome loss': 0.18371775453788755, 'Total loss': 0.18371775453788755}
2023-01-05 00:07:23,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:23,718 INFO:     Epoch: 95
2023-01-05 00:07:25,968 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4894762655099233, 'Total loss': 0.4894762655099233} | train loss {'Reaction outcome loss': 0.18167256139049245, 'Total loss': 0.18167256139049245}
2023-01-05 00:07:25,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:25,968 INFO:     Epoch: 96
2023-01-05 00:07:28,214 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44507817228635155, 'Total loss': 0.44507817228635155} | train loss {'Reaction outcome loss': 0.17649354708914144, 'Total loss': 0.17649354708914144}
2023-01-05 00:07:28,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:28,214 INFO:     Epoch: 97
2023-01-05 00:07:30,483 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47729192624489464, 'Total loss': 0.47729192624489464} | train loss {'Reaction outcome loss': 0.179227155675872, 'Total loss': 0.179227155675872}
2023-01-05 00:07:30,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:30,483 INFO:     Epoch: 98
2023-01-05 00:07:32,683 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.471889074643453, 'Total loss': 0.471889074643453} | train loss {'Reaction outcome loss': 0.1863655655634711, 'Total loss': 0.1863655655634711}
2023-01-05 00:07:32,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:32,684 INFO:     Epoch: 99
2023-01-05 00:07:34,885 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4315443217754364, 'Total loss': 0.4315443217754364} | train loss {'Reaction outcome loss': 0.1821538838477758, 'Total loss': 0.1821538838477758}
2023-01-05 00:07:34,886 INFO:     Best model found after epoch 60 of 100.
2023-01-05 00:07:34,886 INFO:   Done with stage: TRAINING
2023-01-05 00:07:34,886 INFO:   Starting stage: EVALUATION
2023-01-05 00:07:35,021 INFO:   Done with stage: EVALUATION
2023-01-05 00:07:35,021 INFO:   Leaving out SEQ value Fold_8
2023-01-05 00:07:35,033 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 00:07:35,033 INFO:   Starting stage: FEATURE SCALING
2023-01-05 00:07:35,675 INFO:   Done with stage: FEATURE SCALING
2023-01-05 00:07:35,675 INFO:   Starting stage: SCALING TARGETS
2023-01-05 00:07:35,746 INFO:   Done with stage: SCALING TARGETS
2023-01-05 00:07:35,746 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:07:35,746 INFO:     No hyperparam tuning for this model
2023-01-05 00:07:35,746 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:07:35,746 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 00:07:35,747 INFO:     None feature selector for col prot
2023-01-05 00:07:35,747 INFO:     None feature selector for col prot
2023-01-05 00:07:35,747 INFO:     None feature selector for col prot
2023-01-05 00:07:35,748 INFO:     None feature selector for col chem
2023-01-05 00:07:35,748 INFO:     None feature selector for col chem
2023-01-05 00:07:35,748 INFO:     None feature selector for col chem
2023-01-05 00:07:35,748 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 00:07:35,748 INFO:   Starting stage: BUILD MODEL
2023-01-05 00:07:35,750 INFO:     Number of params in model 72931
2023-01-05 00:07:35,753 INFO:   Done with stage: BUILD MODEL
2023-01-05 00:07:35,753 INFO:   Starting stage: TRAINING
2023-01-05 00:07:35,814 INFO:     Val loss before train {'Reaction outcome loss': 0.953829163312912, 'Total loss': 0.953829163312912}
2023-01-05 00:07:35,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:35,814 INFO:     Epoch: 0
2023-01-05 00:07:38,035 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7935573200384776, 'Total loss': 0.7935573200384776} | train loss {'Reaction outcome loss': 0.9233072426292922, 'Total loss': 0.9233072426292922}
2023-01-05 00:07:38,035 INFO:     Found new best model at epoch 0
2023-01-05 00:07:38,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:38,036 INFO:     Epoch: 1
2023-01-05 00:07:40,241 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5501870105663935, 'Total loss': 0.5501870105663935} | train loss {'Reaction outcome loss': 0.6263758374766989, 'Total loss': 0.6263758374766989}
2023-01-05 00:07:40,241 INFO:     Found new best model at epoch 1
2023-01-05 00:07:40,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:40,243 INFO:     Epoch: 2
2023-01-05 00:07:42,477 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5349990248680114, 'Total loss': 0.5349990248680114} | train loss {'Reaction outcome loss': 0.5375971492284384, 'Total loss': 0.5375971492284384}
2023-01-05 00:07:42,477 INFO:     Found new best model at epoch 2
2023-01-05 00:07:42,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:42,478 INFO:     Epoch: 3
2023-01-05 00:07:44,664 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5207913458347321, 'Total loss': 0.5207913458347321} | train loss {'Reaction outcome loss': 0.49886016635012714, 'Total loss': 0.49886016635012714}
2023-01-05 00:07:44,664 INFO:     Found new best model at epoch 3
2023-01-05 00:07:44,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:44,666 INFO:     Epoch: 4
2023-01-05 00:07:46,865 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4926121493180593, 'Total loss': 0.4926121493180593} | train loss {'Reaction outcome loss': 0.46642146649814786, 'Total loss': 0.46642146649814786}
2023-01-05 00:07:46,866 INFO:     Found new best model at epoch 4
2023-01-05 00:07:46,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:46,867 INFO:     Epoch: 5
2023-01-05 00:07:49,086 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5152072131633758, 'Total loss': 0.5152072131633758} | train loss {'Reaction outcome loss': 0.44688697969847985, 'Total loss': 0.44688697969847985}
2023-01-05 00:07:49,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:49,087 INFO:     Epoch: 6
2023-01-05 00:07:51,268 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5033248047033946, 'Total loss': 0.5033248047033946} | train loss {'Reaction outcome loss': 0.42718323803209995, 'Total loss': 0.42718323803209995}
2023-01-05 00:07:51,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:51,269 INFO:     Epoch: 7
2023-01-05 00:07:53,498 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5377165178457896, 'Total loss': 0.5377165178457896} | train loss {'Reaction outcome loss': 0.41485599196437517, 'Total loss': 0.41485599196437517}
2023-01-05 00:07:53,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:53,498 INFO:     Epoch: 8
2023-01-05 00:07:55,601 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5151287198066712, 'Total loss': 0.5151287198066712} | train loss {'Reaction outcome loss': 0.4022072485951714, 'Total loss': 0.4022072485951714}
2023-01-05 00:07:55,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:55,603 INFO:     Epoch: 9
2023-01-05 00:07:57,813 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5057874013980229, 'Total loss': 0.5057874013980229} | train loss {'Reaction outcome loss': 0.3927344533549997, 'Total loss': 0.3927344533549997}
2023-01-05 00:07:57,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:07:57,814 INFO:     Epoch: 10
2023-01-05 00:08:00,036 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5111664136250814, 'Total loss': 0.5111664136250814} | train loss {'Reaction outcome loss': 0.37789534141510833, 'Total loss': 0.37789534141510833}
2023-01-05 00:08:00,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:00,036 INFO:     Epoch: 11
2023-01-05 00:08:02,261 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5464877764383952, 'Total loss': 0.5464877764383952} | train loss {'Reaction outcome loss': 0.37042698411496133, 'Total loss': 0.37042698411496133}
2023-01-05 00:08:02,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:02,261 INFO:     Epoch: 12
2023-01-05 00:08:04,458 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4748556832472483, 'Total loss': 0.4748556832472483} | train loss {'Reaction outcome loss': 0.35860191719545115, 'Total loss': 0.35860191719545115}
2023-01-05 00:08:04,458 INFO:     Found new best model at epoch 12
2023-01-05 00:08:04,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:04,459 INFO:     Epoch: 13
2023-01-05 00:08:06,680 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47716636459032696, 'Total loss': 0.47716636459032696} | train loss {'Reaction outcome loss': 0.35152392254480513, 'Total loss': 0.35152392254480513}
2023-01-05 00:08:06,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:06,680 INFO:     Epoch: 14
2023-01-05 00:08:08,845 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49498087366422017, 'Total loss': 0.49498087366422017} | train loss {'Reaction outcome loss': 0.34445354049247534, 'Total loss': 0.34445354049247534}
2023-01-05 00:08:08,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:08,846 INFO:     Epoch: 15
2023-01-05 00:08:11,105 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5019640078147253, 'Total loss': 0.5019640078147253} | train loss {'Reaction outcome loss': 0.3335833992167707, 'Total loss': 0.3335833992167707}
2023-01-05 00:08:11,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:11,106 INFO:     Epoch: 16
2023-01-05 00:08:13,347 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5015753885110219, 'Total loss': 0.5015753885110219} | train loss {'Reaction outcome loss': 0.32804825436665025, 'Total loss': 0.32804825436665025}
2023-01-05 00:08:13,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:13,347 INFO:     Epoch: 17
2023-01-05 00:08:15,570 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4981040229399999, 'Total loss': 0.4981040229399999} | train loss {'Reaction outcome loss': 0.3202640765479633, 'Total loss': 0.3202640765479633}
2023-01-05 00:08:15,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:15,571 INFO:     Epoch: 18
2023-01-05 00:08:17,825 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49276965459187827, 'Total loss': 0.49276965459187827} | train loss {'Reaction outcome loss': 0.3112915149811423, 'Total loss': 0.3112915149811423}
2023-01-05 00:08:17,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:17,825 INFO:     Epoch: 19
2023-01-05 00:08:20,045 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.536747791369756, 'Total loss': 0.536747791369756} | train loss {'Reaction outcome loss': 0.3053035484592775, 'Total loss': 0.3053035484592775}
2023-01-05 00:08:20,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:20,047 INFO:     Epoch: 20
2023-01-05 00:08:22,314 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5257802128791809, 'Total loss': 0.5257802128791809} | train loss {'Reaction outcome loss': 0.2996703038476544, 'Total loss': 0.2996703038476544}
2023-01-05 00:08:22,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:22,314 INFO:     Epoch: 21
2023-01-05 00:08:24,553 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.511929652094841, 'Total loss': 0.511929652094841} | train loss {'Reaction outcome loss': 0.29424524900841187, 'Total loss': 0.29424524900841187}
2023-01-05 00:08:24,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:24,553 INFO:     Epoch: 22
2023-01-05 00:08:26,776 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4992553730805715, 'Total loss': 0.4992553730805715} | train loss {'Reaction outcome loss': 0.28781263401984297, 'Total loss': 0.28781263401984297}
2023-01-05 00:08:26,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:26,777 INFO:     Epoch: 23
2023-01-05 00:08:28,992 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4975045641263326, 'Total loss': 0.4975045641263326} | train loss {'Reaction outcome loss': 0.2817387276912456, 'Total loss': 0.2817387276912456}
2023-01-05 00:08:28,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:28,993 INFO:     Epoch: 24
2023-01-05 00:08:31,195 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48645906448364257, 'Total loss': 0.48645906448364257} | train loss {'Reaction outcome loss': 0.28238109439857056, 'Total loss': 0.28238109439857056}
2023-01-05 00:08:31,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:31,196 INFO:     Epoch: 25
2023-01-05 00:08:33,409 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49533768792947136, 'Total loss': 0.49533768792947136} | train loss {'Reaction outcome loss': 0.27421536119211287, 'Total loss': 0.27421536119211287}
2023-01-05 00:08:33,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:33,409 INFO:     Epoch: 26
2023-01-05 00:08:35,582 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.523361920317014, 'Total loss': 0.523361920317014} | train loss {'Reaction outcome loss': 0.26992654682379286, 'Total loss': 0.26992654682379286}
2023-01-05 00:08:35,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:35,582 INFO:     Epoch: 27
2023-01-05 00:08:37,804 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.499526979525884, 'Total loss': 0.499526979525884} | train loss {'Reaction outcome loss': 0.26325368748179506, 'Total loss': 0.26325368748179506}
2023-01-05 00:08:37,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:37,805 INFO:     Epoch: 28
2023-01-05 00:08:40,036 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5283203661441803, 'Total loss': 0.5283203661441803} | train loss {'Reaction outcome loss': 0.2644266268654621, 'Total loss': 0.2644266268654621}
2023-01-05 00:08:40,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:40,037 INFO:     Epoch: 29
2023-01-05 00:08:42,280 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.505181243022283, 'Total loss': 0.505181243022283} | train loss {'Reaction outcome loss': 0.2558596502757553, 'Total loss': 0.2558596502757553}
2023-01-05 00:08:42,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:42,280 INFO:     Epoch: 30
2023-01-05 00:08:44,291 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.533387557665507, 'Total loss': 0.533387557665507} | train loss {'Reaction outcome loss': 0.25440005043814906, 'Total loss': 0.25440005043814906}
2023-01-05 00:08:44,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:44,291 INFO:     Epoch: 31
2023-01-05 00:08:46,496 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49909206132094064, 'Total loss': 0.49909206132094064} | train loss {'Reaction outcome loss': 0.248518382755173, 'Total loss': 0.248518382755173}
2023-01-05 00:08:46,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:46,496 INFO:     Epoch: 32
2023-01-05 00:08:48,707 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.521302725871404, 'Total loss': 0.521302725871404} | train loss {'Reaction outcome loss': 0.25122283395693634, 'Total loss': 0.25122283395693634}
2023-01-05 00:08:48,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:48,707 INFO:     Epoch: 33
2023-01-05 00:08:50,861 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5442061066627503, 'Total loss': 0.5442061066627503} | train loss {'Reaction outcome loss': 0.2476779312959739, 'Total loss': 0.2476779312959739}
2023-01-05 00:08:50,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:50,863 INFO:     Epoch: 34
2023-01-05 00:08:53,083 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5463134566942851, 'Total loss': 0.5463134566942851} | train loss {'Reaction outcome loss': 0.24231226317202434, 'Total loss': 0.24231226317202434}
2023-01-05 00:08:53,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:53,083 INFO:     Epoch: 35
2023-01-05 00:08:55,293 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5120706001917521, 'Total loss': 0.5120706001917521} | train loss {'Reaction outcome loss': 0.23427755195279043, 'Total loss': 0.23427755195279043}
2023-01-05 00:08:55,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:55,294 INFO:     Epoch: 36
2023-01-05 00:08:57,490 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5450191875298818, 'Total loss': 0.5450191875298818} | train loss {'Reaction outcome loss': 0.23402290311624935, 'Total loss': 0.23402290311624935}
2023-01-05 00:08:57,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:57,491 INFO:     Epoch: 37
2023-01-05 00:08:59,741 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5243532796700795, 'Total loss': 0.5243532796700795} | train loss {'Reaction outcome loss': 0.23538570724864363, 'Total loss': 0.23538570724864363}
2023-01-05 00:08:59,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:08:59,741 INFO:     Epoch: 38
2023-01-05 00:09:01,970 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5472487464547158, 'Total loss': 0.5472487464547158} | train loss {'Reaction outcome loss': 0.23001019371120812, 'Total loss': 0.23001019371120812}
2023-01-05 00:09:01,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:01,970 INFO:     Epoch: 39
2023-01-05 00:09:04,200 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5333753605683644, 'Total loss': 0.5333753605683644} | train loss {'Reaction outcome loss': 0.22818871850877892, 'Total loss': 0.22818871850877892}
2023-01-05 00:09:04,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:04,200 INFO:     Epoch: 40
2023-01-05 00:09:06,444 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5249654566248257, 'Total loss': 0.5249654566248257} | train loss {'Reaction outcome loss': 0.22689963061099824, 'Total loss': 0.22689963061099824}
2023-01-05 00:09:06,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:06,444 INFO:     Epoch: 41
2023-01-05 00:09:08,553 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5031602462132772, 'Total loss': 0.5031602462132772} | train loss {'Reaction outcome loss': 0.223199301153667, 'Total loss': 0.223199301153667}
2023-01-05 00:09:08,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:08,553 INFO:     Epoch: 42
2023-01-05 00:09:10,735 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5276373296976089, 'Total loss': 0.5276373296976089} | train loss {'Reaction outcome loss': 0.22447195677803114, 'Total loss': 0.22447195677803114}
2023-01-05 00:09:10,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:10,736 INFO:     Epoch: 43
2023-01-05 00:09:12,850 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5157142301400502, 'Total loss': 0.5157142301400502} | train loss {'Reaction outcome loss': 0.22183825713224137, 'Total loss': 0.22183825713224137}
2023-01-05 00:09:12,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:12,850 INFO:     Epoch: 44
2023-01-05 00:09:14,977 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5267743209997813, 'Total loss': 0.5267743209997813} | train loss {'Reaction outcome loss': 0.21847171105116933, 'Total loss': 0.21847171105116933}
2023-01-05 00:09:14,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:14,977 INFO:     Epoch: 45
2023-01-05 00:09:17,196 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5278375089168549, 'Total loss': 0.5278375089168549} | train loss {'Reaction outcome loss': 0.21651940549222323, 'Total loss': 0.21651940549222323}
2023-01-05 00:09:17,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:17,196 INFO:     Epoch: 46
2023-01-05 00:09:19,394 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5223717272281647, 'Total loss': 0.5223717272281647} | train loss {'Reaction outcome loss': 0.21724034592359168, 'Total loss': 0.21724034592359168}
2023-01-05 00:09:19,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:19,394 INFO:     Epoch: 47
2023-01-05 00:09:21,561 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5299097071091334, 'Total loss': 0.5299097071091334} | train loss {'Reaction outcome loss': 0.21612494680416452, 'Total loss': 0.21612494680416452}
2023-01-05 00:09:21,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:21,562 INFO:     Epoch: 48
2023-01-05 00:09:23,748 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46825759842370945, 'Total loss': 0.46825759842370945} | train loss {'Reaction outcome loss': 0.20951492470371855, 'Total loss': 0.20951492470371855}
2023-01-05 00:09:23,749 INFO:     Found new best model at epoch 48
2023-01-05 00:09:23,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:23,750 INFO:     Epoch: 49
2023-01-05 00:09:25,985 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5524370650450389, 'Total loss': 0.5524370650450389} | train loss {'Reaction outcome loss': 0.21203597035299945, 'Total loss': 0.21203597035299945}
2023-01-05 00:09:25,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:25,986 INFO:     Epoch: 50
2023-01-05 00:09:28,210 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5505674322446187, 'Total loss': 0.5505674322446187} | train loss {'Reaction outcome loss': 0.20700667656944458, 'Total loss': 0.20700667656944458}
2023-01-05 00:09:28,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:28,211 INFO:     Epoch: 51
2023-01-05 00:09:30,442 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5699794183174769, 'Total loss': 0.5699794183174769} | train loss {'Reaction outcome loss': 0.20624434101930905, 'Total loss': 0.20624434101930905}
2023-01-05 00:09:30,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:30,442 INFO:     Epoch: 52
2023-01-05 00:09:32,673 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5206801027059555, 'Total loss': 0.5206801027059555} | train loss {'Reaction outcome loss': 0.2020617124305581, 'Total loss': 0.2020617124305581}
2023-01-05 00:09:32,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:32,674 INFO:     Epoch: 53
2023-01-05 00:09:34,904 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5486104786396027, 'Total loss': 0.5486104786396027} | train loss {'Reaction outcome loss': 0.20600074749344435, 'Total loss': 0.20600074749344435}
2023-01-05 00:09:34,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:34,904 INFO:     Epoch: 54
2023-01-05 00:09:37,123 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5596334596474966, 'Total loss': 0.5596334596474966} | train loss {'Reaction outcome loss': 0.20636356240240755, 'Total loss': 0.20636356240240755}
2023-01-05 00:09:37,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:37,124 INFO:     Epoch: 55
2023-01-05 00:09:39,356 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5078950971364975, 'Total loss': 0.5078950971364975} | train loss {'Reaction outcome loss': 0.1995357265772687, 'Total loss': 0.1995357265772687}
2023-01-05 00:09:39,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:39,357 INFO:     Epoch: 56
2023-01-05 00:09:41,599 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5211088662346204, 'Total loss': 0.5211088662346204} | train loss {'Reaction outcome loss': 0.2003754893242767, 'Total loss': 0.2003754893242767}
2023-01-05 00:09:41,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:41,600 INFO:     Epoch: 57
2023-01-05 00:09:43,825 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5217645545800527, 'Total loss': 0.5217645545800527} | train loss {'Reaction outcome loss': 0.19989598355675628, 'Total loss': 0.19989598355675628}
2023-01-05 00:09:43,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:43,825 INFO:     Epoch: 58
2023-01-05 00:09:46,032 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5132273445526759, 'Total loss': 0.5132273445526759} | train loss {'Reaction outcome loss': 0.20244497445585963, 'Total loss': 0.20244497445585963}
2023-01-05 00:09:46,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:46,032 INFO:     Epoch: 59
2023-01-05 00:09:48,182 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5335472295681636, 'Total loss': 0.5335472295681636} | train loss {'Reaction outcome loss': 0.19424905212452778, 'Total loss': 0.19424905212452778}
2023-01-05 00:09:48,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:48,182 INFO:     Epoch: 60
2023-01-05 00:09:50,389 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5653578524788221, 'Total loss': 0.5653578524788221} | train loss {'Reaction outcome loss': 0.19393340317402785, 'Total loss': 0.19393340317402785}
2023-01-05 00:09:50,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:50,390 INFO:     Epoch: 61
2023-01-05 00:09:52,603 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5789815485477448, 'Total loss': 0.5789815485477448} | train loss {'Reaction outcome loss': 0.19105205219238997, 'Total loss': 0.19105205219238997}
2023-01-05 00:09:52,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:52,603 INFO:     Epoch: 62
2023-01-05 00:09:54,758 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5148404101530711, 'Total loss': 0.5148404101530711} | train loss {'Reaction outcome loss': 0.19179736768942832, 'Total loss': 0.19179736768942832}
2023-01-05 00:09:54,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:54,758 INFO:     Epoch: 63
2023-01-05 00:09:57,011 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5282510651896397, 'Total loss': 0.5282510651896397} | train loss {'Reaction outcome loss': 0.1911482495074962, 'Total loss': 0.1911482495074962}
2023-01-05 00:09:57,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:57,012 INFO:     Epoch: 64
2023-01-05 00:09:59,197 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5596814592679341, 'Total loss': 0.5596814592679341} | train loss {'Reaction outcome loss': 0.1881359360545819, 'Total loss': 0.1881359360545819}
2023-01-05 00:09:59,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:09:59,198 INFO:     Epoch: 65
2023-01-05 00:10:01,398 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5627936859925587, 'Total loss': 0.5627936859925587} | train loss {'Reaction outcome loss': 0.18999096287257505, 'Total loss': 0.18999096287257505}
2023-01-05 00:10:01,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:01,398 INFO:     Epoch: 66
2023-01-05 00:10:03,623 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5352914780378342, 'Total loss': 0.5352914780378342} | train loss {'Reaction outcome loss': 0.18823269023918188, 'Total loss': 0.18823269023918188}
2023-01-05 00:10:03,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:03,623 INFO:     Epoch: 67
2023-01-05 00:10:05,816 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5214190850655238, 'Total loss': 0.5214190850655238} | train loss {'Reaction outcome loss': 0.1858193129454586, 'Total loss': 0.1858193129454586}
2023-01-05 00:10:05,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:05,817 INFO:     Epoch: 68
2023-01-05 00:10:07,983 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5014547298351923, 'Total loss': 0.5014547298351923} | train loss {'Reaction outcome loss': 0.18351908162024705, 'Total loss': 0.18351908162024705}
2023-01-05 00:10:07,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:07,983 INFO:     Epoch: 69
2023-01-05 00:10:10,190 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5621445784966151, 'Total loss': 0.5621445784966151} | train loss {'Reaction outcome loss': 0.18920760497539527, 'Total loss': 0.18920760497539527}
2023-01-05 00:10:10,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:10,191 INFO:     Epoch: 70
2023-01-05 00:10:12,425 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5337421973546346, 'Total loss': 0.5337421973546346} | train loss {'Reaction outcome loss': 0.18599488535015793, 'Total loss': 0.18599488535015793}
2023-01-05 00:10:12,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:12,426 INFO:     Epoch: 71
2023-01-05 00:10:14,619 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5338945845762889, 'Total loss': 0.5338945845762889} | train loss {'Reaction outcome loss': 0.1821157273294015, 'Total loss': 0.1821157273294015}
2023-01-05 00:10:14,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:14,619 INFO:     Epoch: 72
2023-01-05 00:10:16,830 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5362652083237965, 'Total loss': 0.5362652083237965} | train loss {'Reaction outcome loss': 0.18627224002807868, 'Total loss': 0.18627224002807868}
2023-01-05 00:10:16,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:16,830 INFO:     Epoch: 73
2023-01-05 00:10:19,065 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5265209600329399, 'Total loss': 0.5265209600329399} | train loss {'Reaction outcome loss': 0.18163336963211987, 'Total loss': 0.18163336963211987}
2023-01-05 00:10:19,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:19,065 INFO:     Epoch: 74
2023-01-05 00:10:21,312 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.527058822909991, 'Total loss': 0.527058822909991} | train loss {'Reaction outcome loss': 0.1833810818026818, 'Total loss': 0.1833810818026818}
2023-01-05 00:10:21,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:21,312 INFO:     Epoch: 75
2023-01-05 00:10:23,534 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5179989814758301, 'Total loss': 0.5179989814758301} | train loss {'Reaction outcome loss': 0.17673091966686122, 'Total loss': 0.17673091966686122}
2023-01-05 00:10:23,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:23,534 INFO:     Epoch: 76
2023-01-05 00:10:25,770 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5335779895385107, 'Total loss': 0.5335779895385107} | train loss {'Reaction outcome loss': 0.17901168806365803, 'Total loss': 0.17901168806365803}
2023-01-05 00:10:25,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:25,771 INFO:     Epoch: 77
2023-01-05 00:10:28,008 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5589156876007716, 'Total loss': 0.5589156876007716} | train loss {'Reaction outcome loss': 0.17572993518283161, 'Total loss': 0.17572993518283161}
2023-01-05 00:10:28,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:28,009 INFO:     Epoch: 78
2023-01-05 00:10:30,207 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5608287771542867, 'Total loss': 0.5608287771542867} | train loss {'Reaction outcome loss': 0.17584088138959647, 'Total loss': 0.17584088138959647}
2023-01-05 00:10:30,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:30,207 INFO:     Epoch: 79
2023-01-05 00:10:32,439 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5613767027854919, 'Total loss': 0.5613767027854919} | train loss {'Reaction outcome loss': 0.18005881759068576, 'Total loss': 0.18005881759068576}
2023-01-05 00:10:32,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:32,440 INFO:     Epoch: 80
2023-01-05 00:10:34,567 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5319924137710283, 'Total loss': 0.5319924137710283} | train loss {'Reaction outcome loss': 0.18312369532637543, 'Total loss': 0.18312369532637543}
2023-01-05 00:10:34,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:34,568 INFO:     Epoch: 81
2023-01-05 00:10:36,763 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5298691401878993, 'Total loss': 0.5298691401878993} | train loss {'Reaction outcome loss': 0.1743391657626809, 'Total loss': 0.1743391657626809}
2023-01-05 00:10:36,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:36,763 INFO:     Epoch: 82
2023-01-05 00:10:38,954 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5559138834476471, 'Total loss': 0.5559138834476471} | train loss {'Reaction outcome loss': 0.17498599341302945, 'Total loss': 0.17498599341302945}
2023-01-05 00:10:38,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:38,954 INFO:     Epoch: 83
2023-01-05 00:10:41,117 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5507906198501586, 'Total loss': 0.5507906198501586} | train loss {'Reaction outcome loss': 0.17302759934810327, 'Total loss': 0.17302759934810327}
2023-01-05 00:10:41,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:41,117 INFO:     Epoch: 84
2023-01-05 00:10:43,303 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5254940072695414, 'Total loss': 0.5254940072695414} | train loss {'Reaction outcome loss': 0.17437939579179, 'Total loss': 0.17437939579179}
2023-01-05 00:10:43,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:43,303 INFO:     Epoch: 85
2023-01-05 00:10:45,465 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4886846919854482, 'Total loss': 0.4886846919854482} | train loss {'Reaction outcome loss': 0.17552547900674817, 'Total loss': 0.17552547900674817}
2023-01-05 00:10:45,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:45,466 INFO:     Epoch: 86
2023-01-05 00:10:47,685 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5095752318700154, 'Total loss': 0.5095752318700154} | train loss {'Reaction outcome loss': 0.17448396912022007, 'Total loss': 0.17448396912022007}
2023-01-05 00:10:47,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:47,686 INFO:     Epoch: 87
2023-01-05 00:10:49,884 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5561983605225881, 'Total loss': 0.5561983605225881} | train loss {'Reaction outcome loss': 0.17886416392653307, 'Total loss': 0.17886416392653307}
2023-01-05 00:10:49,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:49,884 INFO:     Epoch: 88
2023-01-05 00:10:52,121 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5706553419431051, 'Total loss': 0.5706553419431051} | train loss {'Reaction outcome loss': 0.17020772279482402, 'Total loss': 0.17020772279482402}
2023-01-05 00:10:52,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:52,121 INFO:     Epoch: 89
2023-01-05 00:10:54,344 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5299298425515493, 'Total loss': 0.5299298425515493} | train loss {'Reaction outcome loss': 0.16609361491399738, 'Total loss': 0.16609361491399738}
2023-01-05 00:10:54,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:54,344 INFO:     Epoch: 90
2023-01-05 00:10:56,564 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5122037907441457, 'Total loss': 0.5122037907441457} | train loss {'Reaction outcome loss': 0.16650193775816388, 'Total loss': 0.16650193775816388}
2023-01-05 00:10:56,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:56,564 INFO:     Epoch: 91
2023-01-05 00:10:58,759 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.511794273982135, 'Total loss': 0.511794273982135} | train loss {'Reaction outcome loss': 0.17011245867517186, 'Total loss': 0.17011245867517186}
2023-01-05 00:10:58,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:10:58,760 INFO:     Epoch: 92
2023-01-05 00:11:00,987 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5384079347054164, 'Total loss': 0.5384079347054164} | train loss {'Reaction outcome loss': 0.1689611685030749, 'Total loss': 0.1689611685030749}
2023-01-05 00:11:00,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:00,987 INFO:     Epoch: 93
2023-01-05 00:11:03,129 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5623756180206935, 'Total loss': 0.5623756180206935} | train loss {'Reaction outcome loss': 0.1642214044580584, 'Total loss': 0.1642214044580584}
2023-01-05 00:11:03,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:03,129 INFO:     Epoch: 94
2023-01-05 00:11:05,320 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5061435769001643, 'Total loss': 0.5061435769001643} | train loss {'Reaction outcome loss': 0.17307196522042864, 'Total loss': 0.17307196522042864}
2023-01-05 00:11:05,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:05,321 INFO:     Epoch: 95
2023-01-05 00:11:07,563 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5661190470059713, 'Total loss': 0.5661190470059713} | train loss {'Reaction outcome loss': 0.16966457018499081, 'Total loss': 0.16966457018499081}
2023-01-05 00:11:07,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:07,563 INFO:     Epoch: 96
2023-01-05 00:11:09,736 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5518071472644805, 'Total loss': 0.5518071472644805} | train loss {'Reaction outcome loss': 0.16619128350171877, 'Total loss': 0.16619128350171877}
2023-01-05 00:11:09,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:09,737 INFO:     Epoch: 97
2023-01-05 00:11:11,972 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5242007195949554, 'Total loss': 0.5242007195949554} | train loss {'Reaction outcome loss': 0.16757444428934992, 'Total loss': 0.16757444428934992}
2023-01-05 00:11:11,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:11,972 INFO:     Epoch: 98
2023-01-05 00:11:14,136 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5310452282428741, 'Total loss': 0.5310452282428741} | train loss {'Reaction outcome loss': 0.17011779733855045, 'Total loss': 0.17011779733855045}
2023-01-05 00:11:14,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:14,136 INFO:     Epoch: 99
2023-01-05 00:11:16,335 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5254444340864818, 'Total loss': 0.5254444340864818} | train loss {'Reaction outcome loss': 0.16569333870966846, 'Total loss': 0.16569333870966846}
2023-01-05 00:11:16,335 INFO:     Best model found after epoch 49 of 100.
2023-01-05 00:11:16,335 INFO:   Done with stage: TRAINING
2023-01-05 00:11:16,335 INFO:   Starting stage: EVALUATION
2023-01-05 00:11:16,485 INFO:   Done with stage: EVALUATION
2023-01-05 00:11:16,485 INFO:   Leaving out SEQ value Fold_9
2023-01-05 00:11:16,498 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 00:11:16,498 INFO:   Starting stage: FEATURE SCALING
2023-01-05 00:11:17,142 INFO:   Done with stage: FEATURE SCALING
2023-01-05 00:11:17,142 INFO:   Starting stage: SCALING TARGETS
2023-01-05 00:11:17,212 INFO:   Done with stage: SCALING TARGETS
2023-01-05 00:11:17,212 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:11:17,212 INFO:     No hyperparam tuning for this model
2023-01-05 00:11:17,212 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:11:17,212 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 00:11:17,213 INFO:     None feature selector for col prot
2023-01-05 00:11:17,213 INFO:     None feature selector for col prot
2023-01-05 00:11:17,213 INFO:     None feature selector for col prot
2023-01-05 00:11:17,213 INFO:     None feature selector for col chem
2023-01-05 00:11:17,214 INFO:     None feature selector for col chem
2023-01-05 00:11:17,214 INFO:     None feature selector for col chem
2023-01-05 00:11:17,214 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 00:11:17,214 INFO:   Starting stage: BUILD MODEL
2023-01-05 00:11:17,215 INFO:     Number of params in model 72931
2023-01-05 00:11:17,218 INFO:   Done with stage: BUILD MODEL
2023-01-05 00:11:17,218 INFO:   Starting stage: TRAINING
2023-01-05 00:11:17,279 INFO:     Val loss before train {'Reaction outcome loss': 0.9718501885732015, 'Total loss': 0.9718501885732015}
2023-01-05 00:11:17,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:17,279 INFO:     Epoch: 0
2023-01-05 00:11:19,491 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6594067275524139, 'Total loss': 0.6594067275524139} | train loss {'Reaction outcome loss': 0.9156616223517103, 'Total loss': 0.9156616223517103}
2023-01-05 00:11:19,492 INFO:     Found new best model at epoch 0
2023-01-05 00:11:19,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:19,494 INFO:     Epoch: 1
2023-01-05 00:11:21,758 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4708498458067576, 'Total loss': 0.4708498458067576} | train loss {'Reaction outcome loss': 0.6026028780455607, 'Total loss': 0.6026028780455607}
2023-01-05 00:11:21,758 INFO:     Found new best model at epoch 1
2023-01-05 00:11:21,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:21,759 INFO:     Epoch: 2
2023-01-05 00:11:24,032 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4498984158039093, 'Total loss': 0.4498984158039093} | train loss {'Reaction outcome loss': 0.5285334246826993, 'Total loss': 0.5285334246826993}
2023-01-05 00:11:24,032 INFO:     Found new best model at epoch 2
2023-01-05 00:11:24,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:24,033 INFO:     Epoch: 3
2023-01-05 00:11:26,304 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.41539342800776163, 'Total loss': 0.41539342800776163} | train loss {'Reaction outcome loss': 0.4872471572879216, 'Total loss': 0.4872471572879216}
2023-01-05 00:11:26,304 INFO:     Found new best model at epoch 3
2023-01-05 00:11:26,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:26,305 INFO:     Epoch: 4
2023-01-05 00:11:28,565 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.411322025458018, 'Total loss': 0.411322025458018} | train loss {'Reaction outcome loss': 0.4617529601817006, 'Total loss': 0.4617529601817006}
2023-01-05 00:11:28,566 INFO:     Found new best model at epoch 4
2023-01-05 00:11:28,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:28,568 INFO:     Epoch: 5
2023-01-05 00:11:30,834 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.38527033030986785, 'Total loss': 0.38527033030986785} | train loss {'Reaction outcome loss': 0.44327874419732194, 'Total loss': 0.44327874419732194}
2023-01-05 00:11:30,834 INFO:     Found new best model at epoch 5
2023-01-05 00:11:30,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:30,835 INFO:     Epoch: 6
2023-01-05 00:11:33,083 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3862333714962006, 'Total loss': 0.3862333714962006} | train loss {'Reaction outcome loss': 0.42030177483557846, 'Total loss': 0.42030177483557846}
2023-01-05 00:11:33,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:33,083 INFO:     Epoch: 7
2023-01-05 00:11:35,334 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3956213116645813, 'Total loss': 0.3956213116645813} | train loss {'Reaction outcome loss': 0.40710056732564553, 'Total loss': 0.40710056732564553}
2023-01-05 00:11:35,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:35,335 INFO:     Epoch: 8
2023-01-05 00:11:37,484 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3979937881231308, 'Total loss': 0.3979937881231308} | train loss {'Reaction outcome loss': 0.38529873679162585, 'Total loss': 0.38529873679162585}
2023-01-05 00:11:37,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:37,484 INFO:     Epoch: 9
2023-01-05 00:11:39,724 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3881370037794113, 'Total loss': 0.3881370037794113} | train loss {'Reaction outcome loss': 0.3794353355938717, 'Total loss': 0.3794353355938717}
2023-01-05 00:11:39,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:39,724 INFO:     Epoch: 10
2023-01-05 00:11:42,031 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.38295198579629264, 'Total loss': 0.38295198579629264} | train loss {'Reaction outcome loss': 0.36261409345678514, 'Total loss': 0.36261409345678514}
2023-01-05 00:11:42,032 INFO:     Found new best model at epoch 10
2023-01-05 00:11:42,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:42,033 INFO:     Epoch: 11
2023-01-05 00:11:44,257 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39574796458085376, 'Total loss': 0.39574796458085376} | train loss {'Reaction outcome loss': 0.34874817765439337, 'Total loss': 0.34874817765439337}
2023-01-05 00:11:44,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:44,258 INFO:     Epoch: 12
2023-01-05 00:11:46,474 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3959062139193217, 'Total loss': 0.3959062139193217} | train loss {'Reaction outcome loss': 0.3494827778928954, 'Total loss': 0.3494827778928954}
2023-01-05 00:11:46,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:46,474 INFO:     Epoch: 13
2023-01-05 00:11:48,737 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.38721983730792997, 'Total loss': 0.38721983730792997} | train loss {'Reaction outcome loss': 0.3346162029886635, 'Total loss': 0.3346162029886635}
2023-01-05 00:11:48,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:48,738 INFO:     Epoch: 14
2023-01-05 00:11:51,001 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3887617290019989, 'Total loss': 0.3887617290019989} | train loss {'Reaction outcome loss': 0.3197075040885281, 'Total loss': 0.3197075040885281}
2023-01-05 00:11:51,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:51,001 INFO:     Epoch: 15
2023-01-05 00:11:53,185 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.382363182802995, 'Total loss': 0.382363182802995} | train loss {'Reaction outcome loss': 0.3127870795359595, 'Total loss': 0.3127870795359595}
2023-01-05 00:11:53,185 INFO:     Found new best model at epoch 15
2023-01-05 00:11:53,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:53,186 INFO:     Epoch: 16
2023-01-05 00:11:55,381 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39433495899041493, 'Total loss': 0.39433495899041493} | train loss {'Reaction outcome loss': 0.3070756819570965, 'Total loss': 0.3070756819570965}
2023-01-05 00:11:55,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:55,382 INFO:     Epoch: 17
2023-01-05 00:11:57,648 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4095224519570669, 'Total loss': 0.4095224519570669} | train loss {'Reaction outcome loss': 0.29683333020184893, 'Total loss': 0.29683333020184893}
2023-01-05 00:11:57,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:57,648 INFO:     Epoch: 18
2023-01-05 00:11:59,922 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4139423926671346, 'Total loss': 0.4139423926671346} | train loss {'Reaction outcome loss': 0.29315289295134234, 'Total loss': 0.29315289295134234}
2023-01-05 00:11:59,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:11:59,922 INFO:     Epoch: 19
2023-01-05 00:12:02,181 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4209120328227679, 'Total loss': 0.4209120328227679} | train loss {'Reaction outcome loss': 0.28281970305935195, 'Total loss': 0.28281970305935195}
2023-01-05 00:12:02,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:02,181 INFO:     Epoch: 20
2023-01-05 00:12:04,418 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39988010227680204, 'Total loss': 0.39988010227680204} | train loss {'Reaction outcome loss': 0.28367586583034066, 'Total loss': 0.28367586583034066}
2023-01-05 00:12:04,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:04,419 INFO:     Epoch: 21
2023-01-05 00:12:06,672 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40731717745463053, 'Total loss': 0.40731717745463053} | train loss {'Reaction outcome loss': 0.27358240988510457, 'Total loss': 0.27358240988510457}
2023-01-05 00:12:06,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:06,672 INFO:     Epoch: 22
2023-01-05 00:12:08,902 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43130144476890564, 'Total loss': 0.43130144476890564} | train loss {'Reaction outcome loss': 0.27253528951626754, 'Total loss': 0.27253528951626754}
2023-01-05 00:12:08,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:08,902 INFO:     Epoch: 23
2023-01-05 00:12:11,146 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41904007494449613, 'Total loss': 0.41904007494449613} | train loss {'Reaction outcome loss': 0.26422453112688044, 'Total loss': 0.26422453112688044}
2023-01-05 00:12:11,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:11,147 INFO:     Epoch: 24
2023-01-05 00:12:13,370 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43950793047746023, 'Total loss': 0.43950793047746023} | train loss {'Reaction outcome loss': 0.2620042396691766, 'Total loss': 0.2620042396691766}
2023-01-05 00:12:13,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:13,370 INFO:     Epoch: 25
2023-01-05 00:12:15,536 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41750296850999197, 'Total loss': 0.41750296850999197} | train loss {'Reaction outcome loss': 0.25895692480970983, 'Total loss': 0.25895692480970983}
2023-01-05 00:12:15,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:15,536 INFO:     Epoch: 26
2023-01-05 00:12:17,728 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42880346278349557, 'Total loss': 0.42880346278349557} | train loss {'Reaction outcome loss': 0.2559261374661456, 'Total loss': 0.2559261374661456}
2023-01-05 00:12:17,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:17,728 INFO:     Epoch: 27
2023-01-05 00:12:19,955 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4501617938280106, 'Total loss': 0.4501617938280106} | train loss {'Reaction outcome loss': 0.25036466908404953, 'Total loss': 0.25036466908404953}
2023-01-05 00:12:19,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:19,955 INFO:     Epoch: 28
2023-01-05 00:12:22,208 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41365313082933425, 'Total loss': 0.41365313082933425} | train loss {'Reaction outcome loss': 0.24626953448287037, 'Total loss': 0.24626953448287037}
2023-01-05 00:12:22,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:22,208 INFO:     Epoch: 29
2023-01-05 00:12:24,379 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41987336476643883, 'Total loss': 0.41987336476643883} | train loss {'Reaction outcome loss': 0.24787694379905378, 'Total loss': 0.24787694379905378}
2023-01-05 00:12:24,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:24,380 INFO:     Epoch: 30
2023-01-05 00:12:26,594 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4080008933941523, 'Total loss': 0.4080008933941523} | train loss {'Reaction outcome loss': 0.2541079825681189, 'Total loss': 0.2541079825681189}
2023-01-05 00:12:26,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:26,594 INFO:     Epoch: 31
2023-01-05 00:12:28,815 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43522436718146007, 'Total loss': 0.43522436718146007} | train loss {'Reaction outcome loss': 0.2550118292228022, 'Total loss': 0.2550118292228022}
2023-01-05 00:12:28,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:28,816 INFO:     Epoch: 32
2023-01-05 00:12:31,063 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4290326550602913, 'Total loss': 0.4290326550602913} | train loss {'Reaction outcome loss': 0.23460859623134203, 'Total loss': 0.23460859623134203}
2023-01-05 00:12:31,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:31,064 INFO:     Epoch: 33
2023-01-05 00:12:33,321 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4302335570255915, 'Total loss': 0.4302335570255915} | train loss {'Reaction outcome loss': 0.2335441664016126, 'Total loss': 0.2335441664016126}
2023-01-05 00:12:33,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:33,322 INFO:     Epoch: 34
2023-01-05 00:12:35,584 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3961505929629008, 'Total loss': 0.3961505929629008} | train loss {'Reaction outcome loss': 0.23077210755866912, 'Total loss': 0.23077210755866912}
2023-01-05 00:12:35,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:35,585 INFO:     Epoch: 35
2023-01-05 00:12:37,847 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4135551482439041, 'Total loss': 0.4135551482439041} | train loss {'Reaction outcome loss': 0.23343764908233847, 'Total loss': 0.23343764908233847}
2023-01-05 00:12:37,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:37,847 INFO:     Epoch: 36
2023-01-05 00:12:40,092 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4133426199977597, 'Total loss': 0.4133426199977597} | train loss {'Reaction outcome loss': 0.23211363205547864, 'Total loss': 0.23211363205547864}
2023-01-05 00:12:40,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:40,093 INFO:     Epoch: 37
2023-01-05 00:12:42,342 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4291185885667801, 'Total loss': 0.4291185885667801} | train loss {'Reaction outcome loss': 0.2279761250373786, 'Total loss': 0.2279761250373786}
2023-01-05 00:12:42,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:42,342 INFO:     Epoch: 38
2023-01-05 00:12:44,607 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40991709132989246, 'Total loss': 0.40991709132989246} | train loss {'Reaction outcome loss': 0.2216716403140774, 'Total loss': 0.2216716403140774}
2023-01-05 00:12:44,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:44,607 INFO:     Epoch: 39
2023-01-05 00:12:46,875 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42457288106282554, 'Total loss': 0.42457288106282554} | train loss {'Reaction outcome loss': 0.21844368105002618, 'Total loss': 0.21844368105002618}
2023-01-05 00:12:46,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:46,876 INFO:     Epoch: 40
2023-01-05 00:12:49,136 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44959480861822765, 'Total loss': 0.44959480861822765} | train loss {'Reaction outcome loss': 0.22064640849113357, 'Total loss': 0.22064640849113357}
2023-01-05 00:12:49,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:49,137 INFO:     Epoch: 41
2023-01-05 00:12:51,156 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43457960387070976, 'Total loss': 0.43457960387070976} | train loss {'Reaction outcome loss': 0.21626291273877132, 'Total loss': 0.21626291273877132}
2023-01-05 00:12:51,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:51,156 INFO:     Epoch: 42
2023-01-05 00:12:53,392 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43698568145434064, 'Total loss': 0.43698568145434064} | train loss {'Reaction outcome loss': 0.21634807050619545, 'Total loss': 0.21634807050619545}
2023-01-05 00:12:53,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:53,393 INFO:     Epoch: 43
2023-01-05 00:12:55,621 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4562978093822797, 'Total loss': 0.4562978093822797} | train loss {'Reaction outcome loss': 0.21655010296018334, 'Total loss': 0.21655010296018334}
2023-01-05 00:12:55,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:55,621 INFO:     Epoch: 44
2023-01-05 00:12:57,877 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4511389533678691, 'Total loss': 0.4511389533678691} | train loss {'Reaction outcome loss': 0.2099940420324118, 'Total loss': 0.2099940420324118}
2023-01-05 00:12:57,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:12:57,877 INFO:     Epoch: 45
2023-01-05 00:13:00,137 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4228694791595141, 'Total loss': 0.4228694791595141} | train loss {'Reaction outcome loss': 0.21129438882707147, 'Total loss': 0.21129438882707147}
2023-01-05 00:13:00,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:00,139 INFO:     Epoch: 46
2023-01-05 00:13:02,378 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42230084190766015, 'Total loss': 0.42230084190766015} | train loss {'Reaction outcome loss': 0.2077038052118661, 'Total loss': 0.2077038052118661}
2023-01-05 00:13:02,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:02,378 INFO:     Epoch: 47
2023-01-05 00:13:04,588 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4462429126103719, 'Total loss': 0.4462429126103719} | train loss {'Reaction outcome loss': 0.20736949852342124, 'Total loss': 0.20736949852342124}
2023-01-05 00:13:04,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:04,588 INFO:     Epoch: 48
2023-01-05 00:13:06,840 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4179627031087875, 'Total loss': 0.4179627031087875} | train loss {'Reaction outcome loss': 0.22656848822193948, 'Total loss': 0.22656848822193948}
2023-01-05 00:13:06,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:06,840 INFO:     Epoch: 49
2023-01-05 00:13:09,078 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4508913591504097, 'Total loss': 0.4508913591504097} | train loss {'Reaction outcome loss': 0.20063026172473378, 'Total loss': 0.20063026172473378}
2023-01-05 00:13:09,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:09,078 INFO:     Epoch: 50
2023-01-05 00:13:11,337 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46577816555897394, 'Total loss': 0.46577816555897394} | train loss {'Reaction outcome loss': 0.20381217068062352, 'Total loss': 0.20381217068062352}
2023-01-05 00:13:11,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:11,337 INFO:     Epoch: 51
2023-01-05 00:13:13,577 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4462990323702494, 'Total loss': 0.4462990323702494} | train loss {'Reaction outcome loss': 0.20411148234394944, 'Total loss': 0.20411148234394944}
2023-01-05 00:13:13,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:13,577 INFO:     Epoch: 52
2023-01-05 00:13:15,827 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4284331351518631, 'Total loss': 0.4284331351518631} | train loss {'Reaction outcome loss': 0.19832869051564214, 'Total loss': 0.19832869051564214}
2023-01-05 00:13:15,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:15,829 INFO:     Epoch: 53
2023-01-05 00:13:18,073 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4549973964691162, 'Total loss': 0.4549973964691162} | train loss {'Reaction outcome loss': 0.19208104290621544, 'Total loss': 0.19208104290621544}
2023-01-05 00:13:18,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:18,074 INFO:     Epoch: 54
2023-01-05 00:13:20,331 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4387581745783488, 'Total loss': 0.4387581745783488} | train loss {'Reaction outcome loss': 0.1978989710708223, 'Total loss': 0.1978989710708223}
2023-01-05 00:13:20,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:20,332 INFO:     Epoch: 55
2023-01-05 00:13:22,557 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4627342710892359, 'Total loss': 0.4627342710892359} | train loss {'Reaction outcome loss': 0.1973385095960744, 'Total loss': 0.1973385095960744}
2023-01-05 00:13:22,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:22,558 INFO:     Epoch: 56
2023-01-05 00:13:24,817 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4794304092725118, 'Total loss': 0.4794304092725118} | train loss {'Reaction outcome loss': 0.1936791532797793, 'Total loss': 0.1936791532797793}
2023-01-05 00:13:24,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:24,817 INFO:     Epoch: 57
2023-01-05 00:13:26,712 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43028223315874736, 'Total loss': 0.43028223315874736} | train loss {'Reaction outcome loss': 0.19660933669850542, 'Total loss': 0.19660933669850542}
2023-01-05 00:13:26,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:26,713 INFO:     Epoch: 58
2023-01-05 00:13:28,543 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4670236900448799, 'Total loss': 0.4670236900448799} | train loss {'Reaction outcome loss': 0.19136924164532515, 'Total loss': 0.19136924164532515}
2023-01-05 00:13:28,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:28,543 INFO:     Epoch: 59
2023-01-05 00:13:30,626 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42926248759031294, 'Total loss': 0.42926248759031294} | train loss {'Reaction outcome loss': 0.19083585737246103, 'Total loss': 0.19083585737246103}
2023-01-05 00:13:30,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:30,626 INFO:     Epoch: 60
2023-01-05 00:13:32,852 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4941259940465291, 'Total loss': 0.4941259940465291} | train loss {'Reaction outcome loss': 0.18789620124574657, 'Total loss': 0.18789620124574657}
2023-01-05 00:13:32,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:32,852 INFO:     Epoch: 61
2023-01-05 00:13:35,115 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4542561054229736, 'Total loss': 0.4542561054229736} | train loss {'Reaction outcome loss': 0.18701110151593897, 'Total loss': 0.18701110151593897}
2023-01-05 00:13:35,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:35,116 INFO:     Epoch: 62
2023-01-05 00:13:37,369 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4505567136531075, 'Total loss': 0.4505567136531075} | train loss {'Reaction outcome loss': 0.18484278442675545, 'Total loss': 0.18484278442675545}
2023-01-05 00:13:37,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:37,370 INFO:     Epoch: 63
2023-01-05 00:13:39,550 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46812449892361957, 'Total loss': 0.46812449892361957} | train loss {'Reaction outcome loss': 0.18284370685907322, 'Total loss': 0.18284370685907322}
2023-01-05 00:13:39,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:39,550 INFO:     Epoch: 64
2023-01-05 00:13:41,777 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.460956934094429, 'Total loss': 0.460956934094429} | train loss {'Reaction outcome loss': 0.18532408908873366, 'Total loss': 0.18532408908873366}
2023-01-05 00:13:41,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:41,777 INFO:     Epoch: 65
2023-01-05 00:13:44,016 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4658824195464452, 'Total loss': 0.4658824195464452} | train loss {'Reaction outcome loss': 0.20058587053453253, 'Total loss': 0.20058587053453253}
2023-01-05 00:13:44,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:44,016 INFO:     Epoch: 66
2023-01-05 00:13:46,276 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.49205576311796906, 'Total loss': 0.49205576311796906} | train loss {'Reaction outcome loss': 0.18397994782013036, 'Total loss': 0.18397994782013036}
2023-01-05 00:13:46,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:46,276 INFO:     Epoch: 67
2023-01-05 00:13:48,529 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48036103149255116, 'Total loss': 0.48036103149255116} | train loss {'Reaction outcome loss': 0.18042480814409023, 'Total loss': 0.18042480814409023}
2023-01-05 00:13:48,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:48,529 INFO:     Epoch: 68
2023-01-05 00:13:50,765 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4646985620260239, 'Total loss': 0.4646985620260239} | train loss {'Reaction outcome loss': 0.1860139204233048, 'Total loss': 0.1860139204233048}
2023-01-05 00:13:50,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:50,766 INFO:     Epoch: 69
2023-01-05 00:13:53,009 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5003634969393412, 'Total loss': 0.5003634969393412} | train loss {'Reaction outcome loss': 0.17877125863805818, 'Total loss': 0.17877125863805818}
2023-01-05 00:13:53,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:53,010 INFO:     Epoch: 70
2023-01-05 00:13:55,278 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4738544354836146, 'Total loss': 0.4738544354836146} | train loss {'Reaction outcome loss': 0.1757352602975173, 'Total loss': 0.1757352602975173}
2023-01-05 00:13:55,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:55,278 INFO:     Epoch: 71
2023-01-05 00:13:57,532 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4902091900507609, 'Total loss': 0.4902091900507609} | train loss {'Reaction outcome loss': 0.17690762613673924, 'Total loss': 0.17690762613673924}
2023-01-05 00:13:57,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:57,532 INFO:     Epoch: 72
2023-01-05 00:13:59,800 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4475208888451258, 'Total loss': 0.4475208888451258} | train loss {'Reaction outcome loss': 0.17507765383482404, 'Total loss': 0.17507765383482404}
2023-01-05 00:13:59,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:13:59,801 INFO:     Epoch: 73
2023-01-05 00:14:02,075 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4682478318611781, 'Total loss': 0.4682478318611781} | train loss {'Reaction outcome loss': 0.1800229175697904, 'Total loss': 0.1800229175697904}
2023-01-05 00:14:02,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:02,075 INFO:     Epoch: 74
2023-01-05 00:14:04,342 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4670768956343333, 'Total loss': 0.4670768956343333} | train loss {'Reaction outcome loss': 0.1832623345634193, 'Total loss': 0.1832623345634193}
2023-01-05 00:14:04,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:04,342 INFO:     Epoch: 75
2023-01-05 00:14:06,579 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46529424786567686, 'Total loss': 0.46529424786567686} | train loss {'Reaction outcome loss': 0.17908060617164534, 'Total loss': 0.17908060617164534}
2023-01-05 00:14:06,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:06,580 INFO:     Epoch: 76
2023-01-05 00:14:08,827 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4674387653668722, 'Total loss': 0.4674387653668722} | train loss {'Reaction outcome loss': 0.20130566555578128, 'Total loss': 0.20130566555578128}
2023-01-05 00:14:08,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:08,827 INFO:     Epoch: 77
2023-01-05 00:14:11,085 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44441391080617904, 'Total loss': 0.44441391080617904} | train loss {'Reaction outcome loss': 0.17777121291048414, 'Total loss': 0.17777121291048414}
2023-01-05 00:14:11,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:11,086 INFO:     Epoch: 78
2023-01-05 00:14:13,342 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4378819266955058, 'Total loss': 0.4378819266955058} | train loss {'Reaction outcome loss': 0.1749656703043028, 'Total loss': 0.1749656703043028}
2023-01-05 00:14:13,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:13,343 INFO:     Epoch: 79
2023-01-05 00:14:15,616 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46280078689257304, 'Total loss': 0.46280078689257304} | train loss {'Reaction outcome loss': 0.17109234157793463, 'Total loss': 0.17109234157793463}
2023-01-05 00:14:15,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:15,617 INFO:     Epoch: 80
2023-01-05 00:14:17,861 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4674792945384979, 'Total loss': 0.4674792945384979} | train loss {'Reaction outcome loss': 0.1676730223344234, 'Total loss': 0.1676730223344234}
2023-01-05 00:14:17,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:17,861 INFO:     Epoch: 81
2023-01-05 00:14:20,155 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42709179520606994, 'Total loss': 0.42709179520606994} | train loss {'Reaction outcome loss': 0.1697638960035545, 'Total loss': 0.1697638960035545}
2023-01-05 00:14:20,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:20,155 INFO:     Epoch: 82
2023-01-05 00:14:22,421 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43608226577440895, 'Total loss': 0.43608226577440895} | train loss {'Reaction outcome loss': 0.17355278299984764, 'Total loss': 0.17355278299984764}
2023-01-05 00:14:22,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:22,422 INFO:     Epoch: 83
2023-01-05 00:14:24,650 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4550007343292236, 'Total loss': 0.4550007343292236} | train loss {'Reaction outcome loss': 0.17108568243439431, 'Total loss': 0.17108568243439431}
2023-01-05 00:14:24,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:24,650 INFO:     Epoch: 84
2023-01-05 00:14:26,886 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4720416307449341, 'Total loss': 0.4720416307449341} | train loss {'Reaction outcome loss': 0.16679676915552683, 'Total loss': 0.16679676915552683}
2023-01-05 00:14:26,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:26,887 INFO:     Epoch: 85
2023-01-05 00:14:29,090 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4611866066853205, 'Total loss': 0.4611866066853205} | train loss {'Reaction outcome loss': 0.17214046231516555, 'Total loss': 0.17214046231516555}
2023-01-05 00:14:29,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:29,091 INFO:     Epoch: 86
2023-01-05 00:14:31,347 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46102205018202463, 'Total loss': 0.46102205018202463} | train loss {'Reaction outcome loss': 0.17036752096770424, 'Total loss': 0.17036752096770424}
2023-01-05 00:14:31,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:31,347 INFO:     Epoch: 87
2023-01-05 00:14:33,611 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4609478125969569, 'Total loss': 0.4609478125969569} | train loss {'Reaction outcome loss': 0.17107291555156987, 'Total loss': 0.17107291555156987}
2023-01-05 00:14:33,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:33,611 INFO:     Epoch: 88
2023-01-05 00:14:35,835 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46173903544743855, 'Total loss': 0.46173903544743855} | train loss {'Reaction outcome loss': 0.1637266251801929, 'Total loss': 0.1637266251801929}
2023-01-05 00:14:35,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:35,835 INFO:     Epoch: 89
2023-01-05 00:14:38,098 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49558199842770895, 'Total loss': 0.49558199842770895} | train loss {'Reaction outcome loss': 0.16854136809421977, 'Total loss': 0.16854136809421977}
2023-01-05 00:14:38,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:38,098 INFO:     Epoch: 90
2023-01-05 00:14:40,319 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4990150039394697, 'Total loss': 0.4990150039394697} | train loss {'Reaction outcome loss': 0.16605231036394968, 'Total loss': 0.16605231036394968}
2023-01-05 00:14:40,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:40,320 INFO:     Epoch: 91
2023-01-05 00:14:42,598 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4512264634172122, 'Total loss': 0.4512264634172122} | train loss {'Reaction outcome loss': 0.16883476240552417, 'Total loss': 0.16883476240552417}
2023-01-05 00:14:42,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:42,599 INFO:     Epoch: 92
2023-01-05 00:14:44,873 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4931013057629267, 'Total loss': 0.4931013057629267} | train loss {'Reaction outcome loss': 0.17114208634450115, 'Total loss': 0.17114208634450115}
2023-01-05 00:14:44,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:44,873 INFO:     Epoch: 93
2023-01-05 00:14:47,091 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4751795252164205, 'Total loss': 0.4751795252164205} | train loss {'Reaction outcome loss': 0.1650783371153301, 'Total loss': 0.1650783371153301}
2023-01-05 00:14:47,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:47,091 INFO:     Epoch: 94
2023-01-05 00:14:49,297 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41929353376229606, 'Total loss': 0.41929353376229606} | train loss {'Reaction outcome loss': 0.1653650965108418, 'Total loss': 0.1653650965108418}
2023-01-05 00:14:49,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:49,298 INFO:     Epoch: 95
2023-01-05 00:14:51,565 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48075507829586667, 'Total loss': 0.48075507829586667} | train loss {'Reaction outcome loss': 0.16704186619091965, 'Total loss': 0.16704186619091965}
2023-01-05 00:14:51,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:51,565 INFO:     Epoch: 96
2023-01-05 00:14:53,784 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.470696222782135, 'Total loss': 0.470696222782135} | train loss {'Reaction outcome loss': 0.1636996862033139, 'Total loss': 0.1636996862033139}
2023-01-05 00:14:53,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:53,784 INFO:     Epoch: 97
2023-01-05 00:14:56,031 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.443537615511256, 'Total loss': 0.443537615511256} | train loss {'Reaction outcome loss': 0.1606934455348233, 'Total loss': 0.1606934455348233}
2023-01-05 00:14:56,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:56,031 INFO:     Epoch: 98
2023-01-05 00:14:58,246 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47084730168183647, 'Total loss': 0.47084730168183647} | train loss {'Reaction outcome loss': 0.15859438315206004, 'Total loss': 0.15859438315206004}
2023-01-05 00:14:58,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:14:58,247 INFO:     Epoch: 99
2023-01-05 00:15:00,458 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.443647238612175, 'Total loss': 0.443647238612175} | train loss {'Reaction outcome loss': 0.16479386040325905, 'Total loss': 0.16479386040325905}
2023-01-05 00:15:00,458 INFO:     Best model found after epoch 16 of 100.
2023-01-05 00:15:00,458 INFO:   Done with stage: TRAINING
2023-01-05 00:15:00,458 INFO:   Starting stage: EVALUATION
2023-01-05 00:15:00,594 INFO:   Done with stage: EVALUATION
2023-01-05 00:15:00,602 INFO:   Leaving out SEQ value Fold_0
2023-01-05 00:15:00,615 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 00:15:00,615 INFO:   Starting stage: FEATURE SCALING
2023-01-05 00:15:01,273 INFO:   Done with stage: FEATURE SCALING
2023-01-05 00:15:01,273 INFO:   Starting stage: SCALING TARGETS
2023-01-05 00:15:01,344 INFO:   Done with stage: SCALING TARGETS
2023-01-05 00:15:01,344 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:15:01,344 INFO:     No hyperparam tuning for this model
2023-01-05 00:15:01,344 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:15:01,344 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 00:15:01,345 INFO:     None feature selector for col prot
2023-01-05 00:15:01,345 INFO:     None feature selector for col prot
2023-01-05 00:15:01,345 INFO:     None feature selector for col prot
2023-01-05 00:15:01,346 INFO:     None feature selector for col chem
2023-01-05 00:15:01,346 INFO:     None feature selector for col chem
2023-01-05 00:15:01,346 INFO:     None feature selector for col chem
2023-01-05 00:15:01,346 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 00:15:01,346 INFO:   Starting stage: BUILD MODEL
2023-01-05 00:15:01,347 INFO:     Number of params in model 72931
2023-01-05 00:15:01,351 INFO:   Done with stage: BUILD MODEL
2023-01-05 00:15:01,351 INFO:   Starting stage: TRAINING
2023-01-05 00:15:01,412 INFO:     Val loss before train {'Reaction outcome loss': 1.0306764940420787, 'Total loss': 1.0306764940420787}
2023-01-05 00:15:01,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:01,412 INFO:     Epoch: 0
2023-01-05 00:15:03,625 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.853472900390625, 'Total loss': 0.853472900390625} | train loss {'Reaction outcome loss': 0.9616274329415266, 'Total loss': 0.9616274329415266}
2023-01-05 00:15:03,625 INFO:     Found new best model at epoch 0
2023-01-05 00:15:03,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:03,626 INFO:     Epoch: 1
2023-01-05 00:15:05,888 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.591255517800649, 'Total loss': 0.591255517800649} | train loss {'Reaction outcome loss': 0.6520142830314412, 'Total loss': 0.6520142830314412}
2023-01-05 00:15:05,889 INFO:     Found new best model at epoch 1
2023-01-05 00:15:05,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:05,891 INFO:     Epoch: 2
2023-01-05 00:15:08,141 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.542370734612147, 'Total loss': 0.542370734612147} | train loss {'Reaction outcome loss': 0.543678943671799, 'Total loss': 0.543678943671799}
2023-01-05 00:15:08,142 INFO:     Found new best model at epoch 2
2023-01-05 00:15:08,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:08,143 INFO:     Epoch: 3
2023-01-05 00:15:10,377 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5222223599751791, 'Total loss': 0.5222223599751791} | train loss {'Reaction outcome loss': 0.5047944187038187, 'Total loss': 0.5047944187038187}
2023-01-05 00:15:10,377 INFO:     Found new best model at epoch 3
2023-01-05 00:15:10,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:10,379 INFO:     Epoch: 4
2023-01-05 00:15:12,609 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49955333570639293, 'Total loss': 0.49955333570639293} | train loss {'Reaction outcome loss': 0.4735412077195402, 'Total loss': 0.4735412077195402}
2023-01-05 00:15:12,609 INFO:     Found new best model at epoch 4
2023-01-05 00:15:12,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:12,610 INFO:     Epoch: 5
2023-01-05 00:15:14,847 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4638722946246465, 'Total loss': 0.4638722946246465} | train loss {'Reaction outcome loss': 0.4452614920429777, 'Total loss': 0.4452614920429777}
2023-01-05 00:15:14,847 INFO:     Found new best model at epoch 5
2023-01-05 00:15:14,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:14,849 INFO:     Epoch: 6
2023-01-05 00:15:17,055 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4859394907951355, 'Total loss': 0.4859394907951355} | train loss {'Reaction outcome loss': 0.4263572843772346, 'Total loss': 0.4263572843772346}
2023-01-05 00:15:17,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:17,056 INFO:     Epoch: 7
2023-01-05 00:15:19,307 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45888653794924417, 'Total loss': 0.45888653794924417} | train loss {'Reaction outcome loss': 0.42811410833636054, 'Total loss': 0.42811410833636054}
2023-01-05 00:15:19,308 INFO:     Found new best model at epoch 7
2023-01-05 00:15:19,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:19,309 INFO:     Epoch: 8
2023-01-05 00:15:21,469 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4658272176980972, 'Total loss': 0.4658272176980972} | train loss {'Reaction outcome loss': 0.4148529017351709, 'Total loss': 0.4148529017351709}
2023-01-05 00:15:21,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:21,470 INFO:     Epoch: 9
2023-01-05 00:15:23,612 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45556798378626506, 'Total loss': 0.45556798378626506} | train loss {'Reaction outcome loss': 0.38402205037351267, 'Total loss': 0.38402205037351267}
2023-01-05 00:15:23,612 INFO:     Found new best model at epoch 9
2023-01-05 00:15:23,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:23,614 INFO:     Epoch: 10
2023-01-05 00:15:25,818 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4373698264360428, 'Total loss': 0.4373698264360428} | train loss {'Reaction outcome loss': 0.37107273609633895, 'Total loss': 0.37107273609633895}
2023-01-05 00:15:25,818 INFO:     Found new best model at epoch 10
2023-01-05 00:15:25,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:25,819 INFO:     Epoch: 11
2023-01-05 00:15:28,065 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4497011492649714, 'Total loss': 0.4497011492649714} | train loss {'Reaction outcome loss': 0.3650582040254317, 'Total loss': 0.3650582040254317}
2023-01-05 00:15:28,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:28,065 INFO:     Epoch: 12
2023-01-05 00:15:30,350 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4360173843801022, 'Total loss': 0.4360173843801022} | train loss {'Reaction outcome loss': 0.35672676339983306, 'Total loss': 0.35672676339983306}
2023-01-05 00:15:30,350 INFO:     Found new best model at epoch 12
2023-01-05 00:15:30,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:30,352 INFO:     Epoch: 13
2023-01-05 00:15:32,650 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45904035965601603, 'Total loss': 0.45904035965601603} | train loss {'Reaction outcome loss': 0.34423271507578157, 'Total loss': 0.34423271507578157}
2023-01-05 00:15:32,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:32,651 INFO:     Epoch: 14
2023-01-05 00:15:34,937 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4483471473058065, 'Total loss': 0.4483471473058065} | train loss {'Reaction outcome loss': 0.3451247538129489, 'Total loss': 0.3451247538129489}
2023-01-05 00:15:34,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:34,938 INFO:     Epoch: 15
2023-01-05 00:15:37,244 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45759071558713915, 'Total loss': 0.45759071558713915} | train loss {'Reaction outcome loss': 0.33435219148869044, 'Total loss': 0.33435219148869044}
2023-01-05 00:15:37,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:37,244 INFO:     Epoch: 16
2023-01-05 00:15:39,468 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4417213122049967, 'Total loss': 0.4417213122049967} | train loss {'Reaction outcome loss': 0.3259384745112808, 'Total loss': 0.3259384745112808}
2023-01-05 00:15:39,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:39,468 INFO:     Epoch: 17
2023-01-05 00:15:41,703 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4430472542842229, 'Total loss': 0.4430472542842229} | train loss {'Reaction outcome loss': 0.3128377307995992, 'Total loss': 0.3128377307995992}
2023-01-05 00:15:41,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:41,704 INFO:     Epoch: 18
2023-01-05 00:15:43,897 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4511702487866084, 'Total loss': 0.4511702487866084} | train loss {'Reaction outcome loss': 0.3094075521875166, 'Total loss': 0.3094075521875166}
2023-01-05 00:15:43,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:43,897 INFO:     Epoch: 19
2023-01-05 00:15:46,067 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4532697781920433, 'Total loss': 0.4532697781920433} | train loss {'Reaction outcome loss': 0.30264596122382814, 'Total loss': 0.30264596122382814}
2023-01-05 00:15:46,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:46,068 INFO:     Epoch: 20
2023-01-05 00:15:48,289 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4699555575847626, 'Total loss': 0.4699555575847626} | train loss {'Reaction outcome loss': 0.2964474929792324, 'Total loss': 0.2964474929792324}
2023-01-05 00:15:48,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:48,289 INFO:     Epoch: 21
2023-01-05 00:15:50,495 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44944274524847666, 'Total loss': 0.44944274524847666} | train loss {'Reaction outcome loss': 0.2936973849149502, 'Total loss': 0.2936973849149502}
2023-01-05 00:15:50,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:50,496 INFO:     Epoch: 22
2023-01-05 00:15:52,779 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4540860901276271, 'Total loss': 0.4540860901276271} | train loss {'Reaction outcome loss': 0.2966929263658012, 'Total loss': 0.2966929263658012}
2023-01-05 00:15:52,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:52,779 INFO:     Epoch: 23
2023-01-05 00:15:55,059 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45965050856272377, 'Total loss': 0.45965050856272377} | train loss {'Reaction outcome loss': 0.27950048784765863, 'Total loss': 0.27950048784765863}
2023-01-05 00:15:55,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:55,060 INFO:     Epoch: 24
2023-01-05 00:15:57,331 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4730394870042801, 'Total loss': 0.4730394870042801} | train loss {'Reaction outcome loss': 0.27635210619874945, 'Total loss': 0.27635210619874945}
2023-01-05 00:15:57,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:57,332 INFO:     Epoch: 25
2023-01-05 00:15:59,628 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4336803011596203, 'Total loss': 0.4336803011596203} | train loss {'Reaction outcome loss': 0.2729752990754618, 'Total loss': 0.2729752990754618}
2023-01-05 00:15:59,628 INFO:     Found new best model at epoch 25
2023-01-05 00:15:59,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:15:59,629 INFO:     Epoch: 26
2023-01-05 00:16:01,898 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4785710419217745, 'Total loss': 0.4785710419217745} | train loss {'Reaction outcome loss': 0.27519839458788437, 'Total loss': 0.27519839458788437}
2023-01-05 00:16:01,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:01,898 INFO:     Epoch: 27
2023-01-05 00:16:04,147 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46378451585769653, 'Total loss': 0.46378451585769653} | train loss {'Reaction outcome loss': 0.2674940782902843, 'Total loss': 0.2674940782902843}
2023-01-05 00:16:04,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:04,148 INFO:     Epoch: 28
2023-01-05 00:16:06,402 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5122614403565725, 'Total loss': 0.5122614403565725} | train loss {'Reaction outcome loss': 0.2605377023251292, 'Total loss': 0.2605377023251292}
2023-01-05 00:16:06,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:06,403 INFO:     Epoch: 29
2023-01-05 00:16:08,652 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44861921221017836, 'Total loss': 0.44861921221017836} | train loss {'Reaction outcome loss': 0.2590531674643938, 'Total loss': 0.2590531674643938}
2023-01-05 00:16:08,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:08,652 INFO:     Epoch: 30
2023-01-05 00:16:10,900 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4702413519223531, 'Total loss': 0.4702413519223531} | train loss {'Reaction outcome loss': 0.2584062186259594, 'Total loss': 0.2584062186259594}
2023-01-05 00:16:10,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:10,901 INFO:     Epoch: 31
2023-01-05 00:16:13,181 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45387401928504306, 'Total loss': 0.45387401928504306} | train loss {'Reaction outcome loss': 0.2506009439984273, 'Total loss': 0.2506009439984273}
2023-01-05 00:16:13,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:13,181 INFO:     Epoch: 32
2023-01-05 00:16:15,422 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4901346802711487, 'Total loss': 0.4901346802711487} | train loss {'Reaction outcome loss': 0.2527443432756653, 'Total loss': 0.2527443432756653}
2023-01-05 00:16:15,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:15,422 INFO:     Epoch: 33
2023-01-05 00:16:17,693 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45217903032898904, 'Total loss': 0.45217903032898904} | train loss {'Reaction outcome loss': 0.24880648090618415, 'Total loss': 0.24880648090618415}
2023-01-05 00:16:17,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:17,693 INFO:     Epoch: 34
2023-01-05 00:16:19,940 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48276163736979166, 'Total loss': 0.48276163736979166} | train loss {'Reaction outcome loss': 0.24805987372562505, 'Total loss': 0.24805987372562505}
2023-01-05 00:16:19,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:19,940 INFO:     Epoch: 35
2023-01-05 00:16:22,121 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4904051343599955, 'Total loss': 0.4904051343599955} | train loss {'Reaction outcome loss': 0.26421923427910043, 'Total loss': 0.26421923427910043}
2023-01-05 00:16:22,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:22,121 INFO:     Epoch: 36
2023-01-05 00:16:24,384 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4681692600250244, 'Total loss': 0.4681692600250244} | train loss {'Reaction outcome loss': 0.24275746729066325, 'Total loss': 0.24275746729066325}
2023-01-05 00:16:24,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:24,385 INFO:     Epoch: 37
2023-01-05 00:16:26,630 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4763681600491206, 'Total loss': 0.4763681600491206} | train loss {'Reaction outcome loss': 0.23537072662612193, 'Total loss': 0.23537072662612193}
2023-01-05 00:16:26,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:26,630 INFO:     Epoch: 38
2023-01-05 00:16:28,869 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4933631718158722, 'Total loss': 0.4933631718158722} | train loss {'Reaction outcome loss': 0.23649185619053795, 'Total loss': 0.23649185619053795}
2023-01-05 00:16:28,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:28,869 INFO:     Epoch: 39
2023-01-05 00:16:31,069 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48692275484402975, 'Total loss': 0.48692275484402975} | train loss {'Reaction outcome loss': 0.23693630074410685, 'Total loss': 0.23693630074410685}
2023-01-05 00:16:31,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:31,069 INFO:     Epoch: 40
2023-01-05 00:16:33,253 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4661295707027117, 'Total loss': 0.4661295707027117} | train loss {'Reaction outcome loss': 0.2386133235278607, 'Total loss': 0.2386133235278607}
2023-01-05 00:16:33,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:33,254 INFO:     Epoch: 41
2023-01-05 00:16:35,465 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5217823694149654, 'Total loss': 0.5217823694149654} | train loss {'Reaction outcome loss': 0.24102107684761312, 'Total loss': 0.24102107684761312}
2023-01-05 00:16:35,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:35,466 INFO:     Epoch: 42
2023-01-05 00:16:37,703 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46446356025214, 'Total loss': 0.46446356025214} | train loss {'Reaction outcome loss': 0.23221168089482977, 'Total loss': 0.23221168089482977}
2023-01-05 00:16:37,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:37,703 INFO:     Epoch: 43
2023-01-05 00:16:39,958 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5012297868728638, 'Total loss': 0.5012297868728638} | train loss {'Reaction outcome loss': 0.22912239932549605, 'Total loss': 0.22912239932549605}
2023-01-05 00:16:39,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:39,960 INFO:     Epoch: 44
2023-01-05 00:16:42,148 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47048498690128326, 'Total loss': 0.47048498690128326} | train loss {'Reaction outcome loss': 0.2229579453073118, 'Total loss': 0.2229579453073118}
2023-01-05 00:16:42,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:42,148 INFO:     Epoch: 45
2023-01-05 00:16:44,319 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4729121963183085, 'Total loss': 0.4729121963183085} | train loss {'Reaction outcome loss': 0.22556571314867208, 'Total loss': 0.22556571314867208}
2023-01-05 00:16:44,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:44,320 INFO:     Epoch: 46
2023-01-05 00:16:46,599 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4690132935841878, 'Total loss': 0.4690132935841878} | train loss {'Reaction outcome loss': 0.22362733194672002, 'Total loss': 0.22362733194672002}
2023-01-05 00:16:46,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:46,600 INFO:     Epoch: 47
2023-01-05 00:16:48,871 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5111464222272237, 'Total loss': 0.5111464222272237} | train loss {'Reaction outcome loss': 0.21810878546017667, 'Total loss': 0.21810878546017667}
2023-01-05 00:16:48,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:48,871 INFO:     Epoch: 48
2023-01-05 00:16:51,076 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4746032973130544, 'Total loss': 0.4746032973130544} | train loss {'Reaction outcome loss': 0.22799181722212528, 'Total loss': 0.22799181722212528}
2023-01-05 00:16:51,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:51,076 INFO:     Epoch: 49
2023-01-05 00:16:53,340 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4607171597580115, 'Total loss': 0.4607171597580115} | train loss {'Reaction outcome loss': 0.23560647861829595, 'Total loss': 0.23560647861829595}
2023-01-05 00:16:53,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:53,341 INFO:     Epoch: 50
2023-01-05 00:16:55,579 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45214897096157075, 'Total loss': 0.45214897096157075} | train loss {'Reaction outcome loss': 0.21816635034317017, 'Total loss': 0.21816635034317017}
2023-01-05 00:16:55,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:55,580 INFO:     Epoch: 51
2023-01-05 00:16:57,661 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46531076629956564, 'Total loss': 0.46531076629956564} | train loss {'Reaction outcome loss': 0.2114521377193539, 'Total loss': 0.2114521377193539}
2023-01-05 00:16:57,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:57,661 INFO:     Epoch: 52
2023-01-05 00:16:59,913 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4499741706997156, 'Total loss': 0.4499741706997156} | train loss {'Reaction outcome loss': 0.21012713123290913, 'Total loss': 0.21012713123290913}
2023-01-05 00:16:59,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:16:59,913 INFO:     Epoch: 53
2023-01-05 00:17:02,178 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.478517551223437, 'Total loss': 0.478517551223437} | train loss {'Reaction outcome loss': 0.211379700655833, 'Total loss': 0.211379700655833}
2023-01-05 00:17:02,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:02,178 INFO:     Epoch: 54
2023-01-05 00:17:04,385 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47317573527495066, 'Total loss': 0.47317573527495066} | train loss {'Reaction outcome loss': 0.2128477524054925, 'Total loss': 0.2128477524054925}
2023-01-05 00:17:04,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:04,385 INFO:     Epoch: 55
2023-01-05 00:17:06,648 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4819389740626017, 'Total loss': 0.4819389740626017} | train loss {'Reaction outcome loss': 0.22935209309925203, 'Total loss': 0.22935209309925203}
2023-01-05 00:17:06,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:06,648 INFO:     Epoch: 56
2023-01-05 00:17:08,916 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4737304856379827, 'Total loss': 0.4737304856379827} | train loss {'Reaction outcome loss': 0.23039830233766764, 'Total loss': 0.23039830233766764}
2023-01-05 00:17:08,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:08,917 INFO:     Epoch: 57
2023-01-05 00:17:11,144 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47869203289349876, 'Total loss': 0.47869203289349876} | train loss {'Reaction outcome loss': 0.20968212558596017, 'Total loss': 0.20968212558596017}
2023-01-05 00:17:11,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:11,145 INFO:     Epoch: 58
2023-01-05 00:17:13,331 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46690796812375385, 'Total loss': 0.46690796812375385} | train loss {'Reaction outcome loss': 0.20366289154322736, 'Total loss': 0.20366289154322736}
2023-01-05 00:17:13,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:13,332 INFO:     Epoch: 59
2023-01-05 00:17:15,534 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4645007352034251, 'Total loss': 0.4645007352034251} | train loss {'Reaction outcome loss': 0.19781933746560462, 'Total loss': 0.19781933746560462}
2023-01-05 00:17:15,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:15,534 INFO:     Epoch: 60
2023-01-05 00:17:17,757 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5027185281117758, 'Total loss': 0.5027185281117758} | train loss {'Reaction outcome loss': 0.19934146976363304, 'Total loss': 0.19934146976363304}
2023-01-05 00:17:17,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:17,758 INFO:     Epoch: 61
2023-01-05 00:17:20,024 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47557472884655, 'Total loss': 0.47557472884655} | train loss {'Reaction outcome loss': 0.19803775807741802, 'Total loss': 0.19803775807741802}
2023-01-05 00:17:20,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:20,024 INFO:     Epoch: 62
2023-01-05 00:17:22,292 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4737372507651647, 'Total loss': 0.4737372507651647} | train loss {'Reaction outcome loss': 0.19620853945093256, 'Total loss': 0.19620853945093256}
2023-01-05 00:17:22,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:22,292 INFO:     Epoch: 63
2023-01-05 00:17:24,501 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47199954787890114, 'Total loss': 0.47199954787890114} | train loss {'Reaction outcome loss': 0.1909381425804526, 'Total loss': 0.1909381425804526}
2023-01-05 00:17:24,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:24,502 INFO:     Epoch: 64
2023-01-05 00:17:26,735 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4544900933901469, 'Total loss': 0.4544900933901469} | train loss {'Reaction outcome loss': 0.19854548082314094, 'Total loss': 0.19854548082314094}
2023-01-05 00:17:26,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:26,735 INFO:     Epoch: 65
2023-01-05 00:17:28,997 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4662377198537191, 'Total loss': 0.4662377198537191} | train loss {'Reaction outcome loss': 0.18968106149586147, 'Total loss': 0.18968106149586147}
2023-01-05 00:17:28,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:28,998 INFO:     Epoch: 66
2023-01-05 00:17:31,233 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4780358006556829, 'Total loss': 0.4780358006556829} | train loss {'Reaction outcome loss': 0.1896911915678504, 'Total loss': 0.1896911915678504}
2023-01-05 00:17:31,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:31,233 INFO:     Epoch: 67
2023-01-05 00:17:33,434 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49721509019533794, 'Total loss': 0.49721509019533794} | train loss {'Reaction outcome loss': 0.19366766749273823, 'Total loss': 0.19366766749273823}
2023-01-05 00:17:33,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:33,435 INFO:     Epoch: 68
2023-01-05 00:17:35,689 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4576440026362737, 'Total loss': 0.4576440026362737} | train loss {'Reaction outcome loss': 0.1937562620294267, 'Total loss': 0.1937562620294267}
2023-01-05 00:17:35,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:35,689 INFO:     Epoch: 69
2023-01-05 00:17:37,929 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4661236395438512, 'Total loss': 0.4661236395438512} | train loss {'Reaction outcome loss': 0.21727308656968028, 'Total loss': 0.21727308656968028}
2023-01-05 00:17:37,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:37,930 INFO:     Epoch: 70
2023-01-05 00:17:40,197 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4804481337467829, 'Total loss': 0.4804481337467829} | train loss {'Reaction outcome loss': 0.19484739344646357, 'Total loss': 0.19484739344646357}
2023-01-05 00:17:40,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:40,198 INFO:     Epoch: 71
2023-01-05 00:17:42,449 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4594970256090164, 'Total loss': 0.4594970256090164} | train loss {'Reaction outcome loss': 0.18573179797849793, 'Total loss': 0.18573179797849793}
2023-01-05 00:17:42,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:42,450 INFO:     Epoch: 72
2023-01-05 00:17:44,626 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46042341192563374, 'Total loss': 0.46042341192563374} | train loss {'Reaction outcome loss': 0.1938065241455384, 'Total loss': 0.1938065241455384}
2023-01-05 00:17:44,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:44,626 INFO:     Epoch: 73
2023-01-05 00:17:46,908 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45851726531982423, 'Total loss': 0.45851726531982423} | train loss {'Reaction outcome loss': 0.18590324297479854, 'Total loss': 0.18590324297479854}
2023-01-05 00:17:46,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:46,909 INFO:     Epoch: 74
2023-01-05 00:17:49,149 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46226092576980593, 'Total loss': 0.46226092576980593} | train loss {'Reaction outcome loss': 0.18222061494083575, 'Total loss': 0.18222061494083575}
2023-01-05 00:17:49,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:49,149 INFO:     Epoch: 75
2023-01-05 00:17:51,403 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47526222467422485, 'Total loss': 0.47526222467422485} | train loss {'Reaction outcome loss': 0.18052066915855824, 'Total loss': 0.18052066915855824}
2023-01-05 00:17:51,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:51,403 INFO:     Epoch: 76
2023-01-05 00:17:53,593 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4552731871604919, 'Total loss': 0.4552731871604919} | train loss {'Reaction outcome loss': 0.183593279447582, 'Total loss': 0.183593279447582}
2023-01-05 00:17:53,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:53,594 INFO:     Epoch: 77
2023-01-05 00:17:55,868 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49473299980163576, 'Total loss': 0.49473299980163576} | train loss {'Reaction outcome loss': 0.1809382454232326, 'Total loss': 0.1809382454232326}
2023-01-05 00:17:55,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:55,868 INFO:     Epoch: 78
2023-01-05 00:17:58,141 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4383953124284744, 'Total loss': 0.4383953124284744} | train loss {'Reaction outcome loss': 0.18079392857359472, 'Total loss': 0.18079392857359472}
2023-01-05 00:17:58,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:17:58,141 INFO:     Epoch: 79
2023-01-05 00:18:00,384 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49027304699023566, 'Total loss': 0.49027304699023566} | train loss {'Reaction outcome loss': 0.18015788475073033, 'Total loss': 0.18015788475073033}
2023-01-05 00:18:00,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:00,384 INFO:     Epoch: 80
2023-01-05 00:18:02,605 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4582995583613714, 'Total loss': 0.4582995583613714} | train loss {'Reaction outcome loss': 0.18190455472474729, 'Total loss': 0.18190455472474729}
2023-01-05 00:18:02,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:02,605 INFO:     Epoch: 81
2023-01-05 00:18:04,781 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4651456100245317, 'Total loss': 0.4651456100245317} | train loss {'Reaction outcome loss': 0.18299963880343822, 'Total loss': 0.18299963880343822}
2023-01-05 00:18:04,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:04,781 INFO:     Epoch: 82
2023-01-05 00:18:07,007 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4991508255402247, 'Total loss': 0.4991508255402247} | train loss {'Reaction outcome loss': 0.17670710412984708, 'Total loss': 0.17670710412984708}
2023-01-05 00:18:07,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:07,008 INFO:     Epoch: 83
2023-01-05 00:18:09,240 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5031546254952749, 'Total loss': 0.5031546254952749} | train loss {'Reaction outcome loss': 0.17303684587840099, 'Total loss': 0.17303684587840099}
2023-01-05 00:18:09,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:09,240 INFO:     Epoch: 84
2023-01-05 00:18:11,409 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49661736786365507, 'Total loss': 0.49661736786365507} | train loss {'Reaction outcome loss': 0.17606855535089289, 'Total loss': 0.17606855535089289}
2023-01-05 00:18:11,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:11,410 INFO:     Epoch: 85
2023-01-05 00:18:13,684 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4782408187786738, 'Total loss': 0.4782408187786738} | train loss {'Reaction outcome loss': 0.17662508024638385, 'Total loss': 0.17662508024638385}
2023-01-05 00:18:13,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:13,684 INFO:     Epoch: 86
2023-01-05 00:18:15,864 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4646249532699585, 'Total loss': 0.4646249532699585} | train loss {'Reaction outcome loss': 0.17134517793707293, 'Total loss': 0.17134517793707293}
2023-01-05 00:18:15,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:15,864 INFO:     Epoch: 87
2023-01-05 00:18:18,103 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4955592374006907, 'Total loss': 0.4955592374006907} | train loss {'Reaction outcome loss': 0.17697324340327253, 'Total loss': 0.17697324340327253}
2023-01-05 00:18:18,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:18,103 INFO:     Epoch: 88
2023-01-05 00:18:20,356 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49020350774129234, 'Total loss': 0.49020350774129234} | train loss {'Reaction outcome loss': 0.17541192293477556, 'Total loss': 0.17541192293477556}
2023-01-05 00:18:20,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:20,356 INFO:     Epoch: 89
2023-01-05 00:18:22,593 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49977170725663506, 'Total loss': 0.49977170725663506} | train loss {'Reaction outcome loss': 0.17100352913921993, 'Total loss': 0.17100352913921993}
2023-01-05 00:18:22,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:22,594 INFO:     Epoch: 90
2023-01-05 00:18:24,827 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48054503947496413, 'Total loss': 0.48054503947496413} | train loss {'Reaction outcome loss': 0.170626005561064, 'Total loss': 0.170626005561064}
2023-01-05 00:18:24,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:24,827 INFO:     Epoch: 91
2023-01-05 00:18:27,077 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4887581040461858, 'Total loss': 0.4887581040461858} | train loss {'Reaction outcome loss': 0.17490777482474357, 'Total loss': 0.17490777482474357}
2023-01-05 00:18:27,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:27,077 INFO:     Epoch: 92
2023-01-05 00:18:29,323 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46712115307648977, 'Total loss': 0.46712115307648977} | train loss {'Reaction outcome loss': 0.17199128169686181, 'Total loss': 0.17199128169686181}
2023-01-05 00:18:29,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:29,324 INFO:     Epoch: 93
2023-01-05 00:18:31,577 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43929588596026103, 'Total loss': 0.43929588596026103} | train loss {'Reaction outcome loss': 0.16980022062426028, 'Total loss': 0.16980022062426028}
2023-01-05 00:18:31,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:31,577 INFO:     Epoch: 94
2023-01-05 00:18:33,788 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47696126798788707, 'Total loss': 0.47696126798788707} | train loss {'Reaction outcome loss': 0.17320076135407705, 'Total loss': 0.17320076135407705}
2023-01-05 00:18:33,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:33,788 INFO:     Epoch: 95
2023-01-05 00:18:36,029 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4651116381088893, 'Total loss': 0.4651116381088893} | train loss {'Reaction outcome loss': 0.1681449177170483, 'Total loss': 0.1681449177170483}
2023-01-05 00:18:36,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:36,030 INFO:     Epoch: 96
2023-01-05 00:18:38,286 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48606275717417396, 'Total loss': 0.48606275717417396} | train loss {'Reaction outcome loss': 0.17108361206381864, 'Total loss': 0.17108361206381864}
2023-01-05 00:18:38,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:38,286 INFO:     Epoch: 97
2023-01-05 00:18:40,553 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5070431272188822, 'Total loss': 0.5070431272188822} | train loss {'Reaction outcome loss': 0.16527623661660482, 'Total loss': 0.16527623661660482}
2023-01-05 00:18:40,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:40,554 INFO:     Epoch: 98
2023-01-05 00:18:42,781 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.473565478126208, 'Total loss': 0.473565478126208} | train loss {'Reaction outcome loss': 0.16941224297245397, 'Total loss': 0.16941224297245397}
2023-01-05 00:18:42,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:42,782 INFO:     Epoch: 99
2023-01-05 00:18:45,032 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4716336806615194, 'Total loss': 0.4716336806615194} | train loss {'Reaction outcome loss': 0.1727014461502077, 'Total loss': 0.1727014461502077}
2023-01-05 00:18:45,032 INFO:     Best model found after epoch 26 of 100.
2023-01-05 00:18:45,033 INFO:   Done with stage: TRAINING
2023-01-05 00:18:45,033 INFO:   Starting stage: EVALUATION
2023-01-05 00:18:45,169 INFO:   Done with stage: EVALUATION
2023-01-05 00:18:45,169 INFO:   Leaving out SEQ value Fold_1
2023-01-05 00:18:45,182 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 00:18:45,182 INFO:   Starting stage: FEATURE SCALING
2023-01-05 00:18:45,821 INFO:   Done with stage: FEATURE SCALING
2023-01-05 00:18:45,821 INFO:   Starting stage: SCALING TARGETS
2023-01-05 00:18:45,892 INFO:   Done with stage: SCALING TARGETS
2023-01-05 00:18:45,892 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:18:45,892 INFO:     No hyperparam tuning for this model
2023-01-05 00:18:45,892 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:18:45,892 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 00:18:45,893 INFO:     None feature selector for col prot
2023-01-05 00:18:45,893 INFO:     None feature selector for col prot
2023-01-05 00:18:45,893 INFO:     None feature selector for col prot
2023-01-05 00:18:45,894 INFO:     None feature selector for col chem
2023-01-05 00:18:45,894 INFO:     None feature selector for col chem
2023-01-05 00:18:45,894 INFO:     None feature selector for col chem
2023-01-05 00:18:45,894 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 00:18:45,894 INFO:   Starting stage: BUILD MODEL
2023-01-05 00:18:45,896 INFO:     Number of params in model 72931
2023-01-05 00:18:45,899 INFO:   Done with stage: BUILD MODEL
2023-01-05 00:18:45,899 INFO:   Starting stage: TRAINING
2023-01-05 00:18:45,956 INFO:     Val loss before train {'Reaction outcome loss': 0.9757020155588786, 'Total loss': 0.9757020155588786}
2023-01-05 00:18:45,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:45,957 INFO:     Epoch: 0
2023-01-05 00:18:48,219 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7254244764645894, 'Total loss': 0.7254244764645894} | train loss {'Reaction outcome loss': 0.9053354432835476, 'Total loss': 0.9053354432835476}
2023-01-05 00:18:48,219 INFO:     Found new best model at epoch 0
2023-01-05 00:18:48,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:48,221 INFO:     Epoch: 1
2023-01-05 00:18:50,477 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5820553203423818, 'Total loss': 0.5820553203423818} | train loss {'Reaction outcome loss': 0.6259873066151488, 'Total loss': 0.6259873066151488}
2023-01-05 00:18:50,477 INFO:     Found new best model at epoch 1
2023-01-05 00:18:50,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:50,478 INFO:     Epoch: 2
2023-01-05 00:18:52,726 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5475859304269155, 'Total loss': 0.5475859304269155} | train loss {'Reaction outcome loss': 0.5221282200536866, 'Total loss': 0.5221282200536866}
2023-01-05 00:18:52,726 INFO:     Found new best model at epoch 2
2023-01-05 00:18:52,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:52,728 INFO:     Epoch: 3
2023-01-05 00:18:54,993 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.528060891230901, 'Total loss': 0.528060891230901} | train loss {'Reaction outcome loss': 0.4823985369943514, 'Total loss': 0.4823985369943514}
2023-01-05 00:18:54,993 INFO:     Found new best model at epoch 3
2023-01-05 00:18:54,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:54,995 INFO:     Epoch: 4
2023-01-05 00:18:57,253 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5043338418006897, 'Total loss': 0.5043338418006897} | train loss {'Reaction outcome loss': 0.4566785158400518, 'Total loss': 0.4566785158400518}
2023-01-05 00:18:57,253 INFO:     Found new best model at epoch 4
2023-01-05 00:18:57,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:57,255 INFO:     Epoch: 5
2023-01-05 00:18:59,514 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4995766431093216, 'Total loss': 0.4995766431093216} | train loss {'Reaction outcome loss': 0.44145797403947706, 'Total loss': 0.44145797403947706}
2023-01-05 00:18:59,515 INFO:     Found new best model at epoch 5
2023-01-05 00:18:59,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:18:59,516 INFO:     Epoch: 6
2023-01-05 00:19:01,756 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4837380180756251, 'Total loss': 0.4837380180756251} | train loss {'Reaction outcome loss': 0.41620546288828814, 'Total loss': 0.41620546288828814}
2023-01-05 00:19:01,756 INFO:     Found new best model at epoch 6
2023-01-05 00:19:01,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:01,758 INFO:     Epoch: 7
2023-01-05 00:19:03,961 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4837680141131083, 'Total loss': 0.4837680141131083} | train loss {'Reaction outcome loss': 0.4010428418042611, 'Total loss': 0.4010428418042611}
2023-01-05 00:19:03,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:03,961 INFO:     Epoch: 8
2023-01-05 00:19:06,167 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4896183371543884, 'Total loss': 0.4896183371543884} | train loss {'Reaction outcome loss': 0.38614797025271086, 'Total loss': 0.38614797025271086}
2023-01-05 00:19:06,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:06,168 INFO:     Epoch: 9
2023-01-05 00:19:08,388 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47458191215991974, 'Total loss': 0.47458191215991974} | train loss {'Reaction outcome loss': 0.3826632436244256, 'Total loss': 0.3826632436244256}
2023-01-05 00:19:08,389 INFO:     Found new best model at epoch 9
2023-01-05 00:19:08,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:08,390 INFO:     Epoch: 10
2023-01-05 00:19:10,595 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46746914386749266, 'Total loss': 0.46746914386749266} | train loss {'Reaction outcome loss': 0.36691753641850705, 'Total loss': 0.36691753641850705}
2023-01-05 00:19:10,595 INFO:     Found new best model at epoch 10
2023-01-05 00:19:10,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:10,596 INFO:     Epoch: 11
2023-01-05 00:19:12,798 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4759576459725698, 'Total loss': 0.4759576459725698} | train loss {'Reaction outcome loss': 0.3599107501947362, 'Total loss': 0.3599107501947362}
2023-01-05 00:19:12,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:12,798 INFO:     Epoch: 12
2023-01-05 00:19:15,000 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5017171382904053, 'Total loss': 0.5017171382904053} | train loss {'Reaction outcome loss': 0.35214869835940393, 'Total loss': 0.35214869835940393}
2023-01-05 00:19:15,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:15,000 INFO:     Epoch: 13
2023-01-05 00:19:17,167 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4714274346828461, 'Total loss': 0.4714274346828461} | train loss {'Reaction outcome loss': 0.3508277225267628, 'Total loss': 0.3508277225267628}
2023-01-05 00:19:17,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:17,167 INFO:     Epoch: 14
2023-01-05 00:19:19,399 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5005301187435786, 'Total loss': 0.5005301187435786} | train loss {'Reaction outcome loss': 0.3438672973979788, 'Total loss': 0.3438672973979788}
2023-01-05 00:19:19,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:19,400 INFO:     Epoch: 15
2023-01-05 00:19:21,638 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46856513420740764, 'Total loss': 0.46856513420740764} | train loss {'Reaction outcome loss': 0.3237195841123838, 'Total loss': 0.3237195841123838}
2023-01-05 00:19:21,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:21,639 INFO:     Epoch: 16
2023-01-05 00:19:23,897 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4516562928756078, 'Total loss': 0.4516562928756078} | train loss {'Reaction outcome loss': 0.31789536175547517, 'Total loss': 0.31789536175547517}
2023-01-05 00:19:23,897 INFO:     Found new best model at epoch 16
2023-01-05 00:19:23,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:23,899 INFO:     Epoch: 17
2023-01-05 00:19:26,123 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.455714484055837, 'Total loss': 0.455714484055837} | train loss {'Reaction outcome loss': 0.3163838501976621, 'Total loss': 0.3163838501976621}
2023-01-05 00:19:26,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:26,124 INFO:     Epoch: 18
2023-01-05 00:19:28,366 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4535189007719358, 'Total loss': 0.4535189007719358} | train loss {'Reaction outcome loss': 0.3069778824837145, 'Total loss': 0.3069778824837145}
2023-01-05 00:19:28,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:28,366 INFO:     Epoch: 19
2023-01-05 00:19:30,629 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46067262490590416, 'Total loss': 0.46067262490590416} | train loss {'Reaction outcome loss': 0.3049334821589055, 'Total loss': 0.3049334821589055}
2023-01-05 00:19:30,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:30,629 INFO:     Epoch: 20
2023-01-05 00:19:32,753 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4693307677904765, 'Total loss': 0.4693307677904765} | train loss {'Reaction outcome loss': 0.2995657477413129, 'Total loss': 0.2995657477413129}
2023-01-05 00:19:32,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:32,753 INFO:     Epoch: 21
2023-01-05 00:19:34,996 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47065542340278627, 'Total loss': 0.47065542340278627} | train loss {'Reaction outcome loss': 0.29757620767771226, 'Total loss': 0.29757620767771226}
2023-01-05 00:19:34,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:34,997 INFO:     Epoch: 22
2023-01-05 00:19:37,254 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4808810313542684, 'Total loss': 0.4808810313542684} | train loss {'Reaction outcome loss': 0.29015826027961855, 'Total loss': 0.29015826027961855}
2023-01-05 00:19:37,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:37,254 INFO:     Epoch: 23
2023-01-05 00:19:39,500 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4550306220849355, 'Total loss': 0.4550306220849355} | train loss {'Reaction outcome loss': 0.28398553488418543, 'Total loss': 0.28398553488418543}
2023-01-05 00:19:39,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:39,500 INFO:     Epoch: 24
2023-01-05 00:19:41,765 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.453493986527125, 'Total loss': 0.453493986527125} | train loss {'Reaction outcome loss': 0.279190984962886, 'Total loss': 0.279190984962886}
2023-01-05 00:19:41,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:41,765 INFO:     Epoch: 25
2023-01-05 00:19:44,008 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4852504114309947, 'Total loss': 0.4852504114309947} | train loss {'Reaction outcome loss': 0.27077673374256794, 'Total loss': 0.27077673374256794}
2023-01-05 00:19:44,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:44,008 INFO:     Epoch: 26
2023-01-05 00:19:46,233 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47450862179199854, 'Total loss': 0.47450862179199854} | train loss {'Reaction outcome loss': 0.27179626861344214, 'Total loss': 0.27179626861344214}
2023-01-05 00:19:46,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:46,234 INFO:     Epoch: 27
2023-01-05 00:19:48,446 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4920127997795741, 'Total loss': 0.4920127997795741} | train loss {'Reaction outcome loss': 0.2745479771570451, 'Total loss': 0.2745479771570451}
2023-01-05 00:19:48,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:48,446 INFO:     Epoch: 28
2023-01-05 00:19:50,702 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.49379889369010926, 'Total loss': 0.49379889369010926} | train loss {'Reaction outcome loss': 0.2658747721432229, 'Total loss': 0.2658747721432229}
2023-01-05 00:19:50,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:50,702 INFO:     Epoch: 29
2023-01-05 00:19:52,967 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4876303017139435, 'Total loss': 0.4876303017139435} | train loss {'Reaction outcome loss': 0.26139890497206186, 'Total loss': 0.26139890497206186}
2023-01-05 00:19:52,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:52,967 INFO:     Epoch: 30
2023-01-05 00:19:55,237 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5030523876349131, 'Total loss': 0.5030523876349131} | train loss {'Reaction outcome loss': 0.2580569368965107, 'Total loss': 0.2580569368965107}
2023-01-05 00:19:55,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:55,238 INFO:     Epoch: 31
2023-01-05 00:19:57,479 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4862774739662806, 'Total loss': 0.4862774739662806} | train loss {'Reaction outcome loss': 0.2541967575721767, 'Total loss': 0.2541967575721767}
2023-01-05 00:19:57,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:57,479 INFO:     Epoch: 32
2023-01-05 00:19:59,736 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5271028578281403, 'Total loss': 0.5271028578281403} | train loss {'Reaction outcome loss': 0.25409296175415713, 'Total loss': 0.25409296175415713}
2023-01-05 00:19:59,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:19:59,736 INFO:     Epoch: 33
2023-01-05 00:20:01,988 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5180091440677643, 'Total loss': 0.5180091440677643} | train loss {'Reaction outcome loss': 0.24854306940961565, 'Total loss': 0.24854306940961565}
2023-01-05 00:20:01,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:01,988 INFO:     Epoch: 34
2023-01-05 00:20:04,264 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5045309046904246, 'Total loss': 0.5045309046904246} | train loss {'Reaction outcome loss': 0.23851337516406193, 'Total loss': 0.23851337516406193}
2023-01-05 00:20:04,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:04,264 INFO:     Epoch: 35
2023-01-05 00:20:06,503 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5226358582576116, 'Total loss': 0.5226358582576116} | train loss {'Reaction outcome loss': 0.24431542071703216, 'Total loss': 0.24431542071703216}
2023-01-05 00:20:06,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:06,503 INFO:     Epoch: 36
2023-01-05 00:20:08,746 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.506639854113261, 'Total loss': 0.506639854113261} | train loss {'Reaction outcome loss': 0.23587417191204926, 'Total loss': 0.23587417191204926}
2023-01-05 00:20:08,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:08,746 INFO:     Epoch: 37
2023-01-05 00:20:11,011 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4931370367606481, 'Total loss': 0.4931370367606481} | train loss {'Reaction outcome loss': 0.2368795419761079, 'Total loss': 0.2368795419761079}
2023-01-05 00:20:11,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:11,012 INFO:     Epoch: 38
2023-01-05 00:20:13,272 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4952782442172368, 'Total loss': 0.4952782442172368} | train loss {'Reaction outcome loss': 0.23138126505174392, 'Total loss': 0.23138126505174392}
2023-01-05 00:20:13,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:13,273 INFO:     Epoch: 39
2023-01-05 00:20:15,537 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5143705030282338, 'Total loss': 0.5143705030282338} | train loss {'Reaction outcome loss': 0.22863542162172118, 'Total loss': 0.22863542162172118}
2023-01-05 00:20:15,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:15,537 INFO:     Epoch: 40
2023-01-05 00:20:17,795 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5084093590577443, 'Total loss': 0.5084093590577443} | train loss {'Reaction outcome loss': 0.2332459029043937, 'Total loss': 0.2332459029043937}
2023-01-05 00:20:17,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:17,796 INFO:     Epoch: 41
2023-01-05 00:20:20,042 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5147624850273133, 'Total loss': 0.5147624850273133} | train loss {'Reaction outcome loss': 0.2308288793673442, 'Total loss': 0.2308288793673442}
2023-01-05 00:20:20,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:20,042 INFO:     Epoch: 42
2023-01-05 00:20:22,278 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5118748545646667, 'Total loss': 0.5118748545646667} | train loss {'Reaction outcome loss': 0.22584178216314194, 'Total loss': 0.22584178216314194}
2023-01-05 00:20:22,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:22,278 INFO:     Epoch: 43
2023-01-05 00:20:24,548 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.49967915018399556, 'Total loss': 0.49967915018399556} | train loss {'Reaction outcome loss': 0.22533747794206146, 'Total loss': 0.22533747794206146}
2023-01-05 00:20:24,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:24,549 INFO:     Epoch: 44
2023-01-05 00:20:26,781 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5063971817493439, 'Total loss': 0.5063971817493439} | train loss {'Reaction outcome loss': 0.21854758512336706, 'Total loss': 0.21854758512336706}
2023-01-05 00:20:26,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:26,781 INFO:     Epoch: 45
2023-01-05 00:20:28,986 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5302967925866445, 'Total loss': 0.5302967925866445} | train loss {'Reaction outcome loss': 0.22144426080816682, 'Total loss': 0.22144426080816682}
2023-01-05 00:20:28,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:28,986 INFO:     Epoch: 46
2023-01-05 00:20:31,169 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4889318605264028, 'Total loss': 0.4889318605264028} | train loss {'Reaction outcome loss': 0.22052783143801102, 'Total loss': 0.22052783143801102}
2023-01-05 00:20:31,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:31,170 INFO:     Epoch: 47
2023-01-05 00:20:33,393 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5320336699485779, 'Total loss': 0.5320336699485779} | train loss {'Reaction outcome loss': 0.22305701592290297, 'Total loss': 0.22305701592290297}
2023-01-05 00:20:33,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:33,394 INFO:     Epoch: 48
2023-01-05 00:20:35,564 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5169295748074849, 'Total loss': 0.5169295748074849} | train loss {'Reaction outcome loss': 0.21521021649106473, 'Total loss': 0.21521021649106473}
2023-01-05 00:20:35,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:35,565 INFO:     Epoch: 49
2023-01-05 00:20:37,774 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5438834478457769, 'Total loss': 0.5438834478457769} | train loss {'Reaction outcome loss': 0.21150613775429572, 'Total loss': 0.21150613775429572}
2023-01-05 00:20:37,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:37,774 INFO:     Epoch: 50
2023-01-05 00:20:40,015 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5011401395003001, 'Total loss': 0.5011401395003001} | train loss {'Reaction outcome loss': 0.21418227125695263, 'Total loss': 0.21418227125695263}
2023-01-05 00:20:40,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:40,015 INFO:     Epoch: 51
2023-01-05 00:20:42,280 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.53302041888237, 'Total loss': 0.53302041888237} | train loss {'Reaction outcome loss': 0.20976079788580546, 'Total loss': 0.20976079788580546}
2023-01-05 00:20:42,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:42,280 INFO:     Epoch: 52
2023-01-05 00:20:44,494 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5603944440682729, 'Total loss': 0.5603944440682729} | train loss {'Reaction outcome loss': 0.20648618342154118, 'Total loss': 0.20648618342154118}
2023-01-05 00:20:44,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:44,494 INFO:     Epoch: 53
2023-01-05 00:20:46,744 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5551313320795696, 'Total loss': 0.5551313320795696} | train loss {'Reaction outcome loss': 0.2065916978584858, 'Total loss': 0.2065916978584858}
2023-01-05 00:20:46,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:46,746 INFO:     Epoch: 54
2023-01-05 00:20:48,880 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5053640276193618, 'Total loss': 0.5053640276193618} | train loss {'Reaction outcome loss': 0.2047750966490982, 'Total loss': 0.2047750966490982}
2023-01-05 00:20:48,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:48,881 INFO:     Epoch: 55
2023-01-05 00:20:51,093 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5425569663445154, 'Total loss': 0.5425569663445154} | train loss {'Reaction outcome loss': 0.20296549300015296, 'Total loss': 0.20296549300015296}
2023-01-05 00:20:51,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:51,093 INFO:     Epoch: 56
2023-01-05 00:20:53,335 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5347198685010274, 'Total loss': 0.5347198685010274} | train loss {'Reaction outcome loss': 0.2023456351041956, 'Total loss': 0.2023456351041956}
2023-01-05 00:20:53,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:53,336 INFO:     Epoch: 57
2023-01-05 00:20:55,596 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5303120414415995, 'Total loss': 0.5303120414415995} | train loss {'Reaction outcome loss': 0.20421932239601712, 'Total loss': 0.20421932239601712}
2023-01-05 00:20:55,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:55,596 INFO:     Epoch: 58
2023-01-05 00:20:57,867 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5101554413636525, 'Total loss': 0.5101554413636525} | train loss {'Reaction outcome loss': 0.19346919230630863, 'Total loss': 0.19346919230630863}
2023-01-05 00:20:57,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:20:57,867 INFO:     Epoch: 59
2023-01-05 00:21:00,131 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5087070981661479, 'Total loss': 0.5087070981661479} | train loss {'Reaction outcome loss': 0.19319845144122338, 'Total loss': 0.19319845144122338}
2023-01-05 00:21:00,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:00,131 INFO:     Epoch: 60
2023-01-05 00:21:02,403 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49432950019836425, 'Total loss': 0.49432950019836425} | train loss {'Reaction outcome loss': 0.19596214899122613, 'Total loss': 0.19596214899122613}
2023-01-05 00:21:02,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:02,403 INFO:     Epoch: 61
2023-01-05 00:21:04,482 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4987475405136744, 'Total loss': 0.4987475405136744} | train loss {'Reaction outcome loss': 0.19956275025733572, 'Total loss': 0.19956275025733572}
2023-01-05 00:21:04,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:04,482 INFO:     Epoch: 62
2023-01-05 00:21:06,708 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4939995547135671, 'Total loss': 0.4939995547135671} | train loss {'Reaction outcome loss': 0.1982128113757927, 'Total loss': 0.1982128113757927}
2023-01-05 00:21:06,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:06,709 INFO:     Epoch: 63
2023-01-05 00:21:08,880 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5360065549612045, 'Total loss': 0.5360065549612045} | train loss {'Reaction outcome loss': 0.19604031041861794, 'Total loss': 0.19604031041861794}
2023-01-05 00:21:08,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:08,881 INFO:     Epoch: 64
2023-01-05 00:21:10,910 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5429848661025365, 'Total loss': 0.5429848661025365} | train loss {'Reaction outcome loss': 0.19697230696961607, 'Total loss': 0.19697230696961607}
2023-01-05 00:21:10,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:10,910 INFO:     Epoch: 65
2023-01-05 00:21:12,782 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5448621620734533, 'Total loss': 0.5448621620734533} | train loss {'Reaction outcome loss': 0.1881899818616682, 'Total loss': 0.1881899818616682}
2023-01-05 00:21:12,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:12,783 INFO:     Epoch: 66
2023-01-05 00:21:14,793 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.528855150938034, 'Total loss': 0.528855150938034} | train loss {'Reaction outcome loss': 0.18610368287393256, 'Total loss': 0.18610368287393256}
2023-01-05 00:21:14,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:14,793 INFO:     Epoch: 67
2023-01-05 00:21:17,046 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5419243375460306, 'Total loss': 0.5419243375460306} | train loss {'Reaction outcome loss': 0.186774037111942, 'Total loss': 0.186774037111942}
2023-01-05 00:21:17,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:17,046 INFO:     Epoch: 68
2023-01-05 00:21:19,273 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.527397217353185, 'Total loss': 0.527397217353185} | train loss {'Reaction outcome loss': 0.18895293195880408, 'Total loss': 0.18895293195880408}
2023-01-05 00:21:19,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:19,273 INFO:     Epoch: 69
2023-01-05 00:21:21,554 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.506517039736112, 'Total loss': 0.506517039736112} | train loss {'Reaction outcome loss': 0.18810526772058042, 'Total loss': 0.18810526772058042}
2023-01-05 00:21:21,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:21,555 INFO:     Epoch: 70
2023-01-05 00:21:23,735 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5602263122797012, 'Total loss': 0.5602263122797012} | train loss {'Reaction outcome loss': 0.18115362244524463, 'Total loss': 0.18115362244524463}
2023-01-05 00:21:23,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:23,736 INFO:     Epoch: 71
2023-01-05 00:21:25,978 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5581820925076802, 'Total loss': 0.5581820925076802} | train loss {'Reaction outcome loss': 0.1878108460780071, 'Total loss': 0.1878108460780071}
2023-01-05 00:21:25,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:25,979 INFO:     Epoch: 72
2023-01-05 00:21:28,148 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5504372899731, 'Total loss': 0.5504372899731} | train loss {'Reaction outcome loss': 0.1860462230821292, 'Total loss': 0.1860462230821292}
2023-01-05 00:21:28,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:28,149 INFO:     Epoch: 73
2023-01-05 00:21:30,404 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5902381002902984, 'Total loss': 0.5902381002902984} | train loss {'Reaction outcome loss': 0.1802651608122951, 'Total loss': 0.1802651608122951}
2023-01-05 00:21:30,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:30,405 INFO:     Epoch: 74
2023-01-05 00:21:32,658 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5257806693514188, 'Total loss': 0.5257806693514188} | train loss {'Reaction outcome loss': 0.17899783449536408, 'Total loss': 0.17899783449536408}
2023-01-05 00:21:32,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:32,658 INFO:     Epoch: 75
2023-01-05 00:21:34,867 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.550076362490654, 'Total loss': 0.550076362490654} | train loss {'Reaction outcome loss': 0.18151786902487493, 'Total loss': 0.18151786902487493}
2023-01-05 00:21:34,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:34,868 INFO:     Epoch: 76
2023-01-05 00:21:37,082 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5175083345423143, 'Total loss': 0.5175083345423143} | train loss {'Reaction outcome loss': 0.17685878434238714, 'Total loss': 0.17685878434238714}
2023-01-05 00:21:37,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:37,082 INFO:     Epoch: 77
2023-01-05 00:21:39,332 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5405323445796967, 'Total loss': 0.5405323445796967} | train loss {'Reaction outcome loss': 0.1801339683609684, 'Total loss': 0.1801339683609684}
2023-01-05 00:21:39,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:39,332 INFO:     Epoch: 78
2023-01-05 00:21:41,542 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5276273362338543, 'Total loss': 0.5276273362338543} | train loss {'Reaction outcome loss': 0.17722234536832085, 'Total loss': 0.17722234536832085}
2023-01-05 00:21:41,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:41,543 INFO:     Epoch: 79
2023-01-05 00:21:43,725 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5140914012988408, 'Total loss': 0.5140914012988408} | train loss {'Reaction outcome loss': 0.17903808236470975, 'Total loss': 0.17903808236470975}
2023-01-05 00:21:43,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:43,725 INFO:     Epoch: 80
2023-01-05 00:21:45,896 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5527348756790161, 'Total loss': 0.5527348756790161} | train loss {'Reaction outcome loss': 0.17488263682479147, 'Total loss': 0.17488263682479147}
2023-01-05 00:21:45,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:45,896 INFO:     Epoch: 81
2023-01-05 00:21:48,161 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.529337922980388, 'Total loss': 0.529337922980388} | train loss {'Reaction outcome loss': 0.17529338309575088, 'Total loss': 0.17529338309575088}
2023-01-05 00:21:48,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:48,161 INFO:     Epoch: 82
2023-01-05 00:21:50,405 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5413010994593302, 'Total loss': 0.5413010994593302} | train loss {'Reaction outcome loss': 0.17750442979530012, 'Total loss': 0.17750442979530012}
2023-01-05 00:21:50,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:50,406 INFO:     Epoch: 83
2023-01-05 00:21:52,666 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5045784160494804, 'Total loss': 0.5045784160494804} | train loss {'Reaction outcome loss': 0.1729474959471533, 'Total loss': 0.1729474959471533}
2023-01-05 00:21:52,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:52,667 INFO:     Epoch: 84
2023-01-05 00:21:54,889 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49862278004487354, 'Total loss': 0.49862278004487354} | train loss {'Reaction outcome loss': 0.17522467845159606, 'Total loss': 0.17522467845159606}
2023-01-05 00:21:54,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:54,889 INFO:     Epoch: 85
2023-01-05 00:21:57,133 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5474297722180684, 'Total loss': 0.5474297722180684} | train loss {'Reaction outcome loss': 0.1729556182405719, 'Total loss': 0.1729556182405719}
2023-01-05 00:21:57,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:57,133 INFO:     Epoch: 86
2023-01-05 00:21:59,384 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5840198968847593, 'Total loss': 0.5840198968847593} | train loss {'Reaction outcome loss': 0.16808000104440685, 'Total loss': 0.16808000104440685}
2023-01-05 00:21:59,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:21:59,385 INFO:     Epoch: 87
2023-01-05 00:22:01,632 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.524743797381719, 'Total loss': 0.524743797381719} | train loss {'Reaction outcome loss': 0.1692378724489928, 'Total loss': 0.1692378724489928}
2023-01-05 00:22:01,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:01,632 INFO:     Epoch: 88
2023-01-05 00:22:03,868 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5432657599449158, 'Total loss': 0.5432657599449158} | train loss {'Reaction outcome loss': 0.17356245881418927, 'Total loss': 0.17356245881418927}
2023-01-05 00:22:03,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:03,868 INFO:     Epoch: 89
2023-01-05 00:22:06,095 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5206038018067678, 'Total loss': 0.5206038018067678} | train loss {'Reaction outcome loss': 0.1698466224420965, 'Total loss': 0.1698466224420965}
2023-01-05 00:22:06,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:06,096 INFO:     Epoch: 90
2023-01-05 00:22:08,325 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5678731272617976, 'Total loss': 0.5678731272617976} | train loss {'Reaction outcome loss': 0.17211974488378948, 'Total loss': 0.17211974488378948}
2023-01-05 00:22:08,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:08,325 INFO:     Epoch: 91
2023-01-05 00:22:10,577 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5492646118005117, 'Total loss': 0.5492646118005117} | train loss {'Reaction outcome loss': 0.17333477996525934, 'Total loss': 0.17333477996525934}
2023-01-05 00:22:10,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:10,577 INFO:     Epoch: 92
2023-01-05 00:22:12,806 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.6060742149750392, 'Total loss': 0.6060742149750392} | train loss {'Reaction outcome loss': 0.17136860634697598, 'Total loss': 0.17136860634697598}
2023-01-05 00:22:12,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:12,807 INFO:     Epoch: 93
2023-01-05 00:22:15,069 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5511743068695069, 'Total loss': 0.5511743068695069} | train loss {'Reaction outcome loss': 0.16965787120220804, 'Total loss': 0.16965787120220804}
2023-01-05 00:22:15,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:15,069 INFO:     Epoch: 94
2023-01-05 00:22:17,312 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5425877898931504, 'Total loss': 0.5425877898931504} | train loss {'Reaction outcome loss': 0.16743168031791975, 'Total loss': 0.16743168031791975}
2023-01-05 00:22:17,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:17,313 INFO:     Epoch: 95
2023-01-05 00:22:19,501 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5595559120178223, 'Total loss': 0.5595559120178223} | train loss {'Reaction outcome loss': 0.1651391961031418, 'Total loss': 0.1651391961031418}
2023-01-05 00:22:19,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:19,502 INFO:     Epoch: 96
2023-01-05 00:22:21,691 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5432125488917033, 'Total loss': 0.5432125488917033} | train loss {'Reaction outcome loss': 0.1646085988726607, 'Total loss': 0.1646085988726607}
2023-01-05 00:22:21,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:21,692 INFO:     Epoch: 97
2023-01-05 00:22:23,913 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5287515461444855, 'Total loss': 0.5287515461444855} | train loss {'Reaction outcome loss': 0.17123029062866513, 'Total loss': 0.17123029062866513}
2023-01-05 00:22:23,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:23,913 INFO:     Epoch: 98
2023-01-05 00:22:26,155 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5359217802683512, 'Total loss': 0.5359217802683512} | train loss {'Reaction outcome loss': 0.16552411468197398, 'Total loss': 0.16552411468197398}
2023-01-05 00:22:26,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:26,156 INFO:     Epoch: 99
2023-01-05 00:22:28,396 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5437911152839661, 'Total loss': 0.5437911152839661} | train loss {'Reaction outcome loss': 0.16543321703827224, 'Total loss': 0.16543321703827224}
2023-01-05 00:22:28,397 INFO:     Best model found after epoch 17 of 100.
2023-01-05 00:22:28,397 INFO:   Done with stage: TRAINING
2023-01-05 00:22:28,398 INFO:   Starting stage: EVALUATION
2023-01-05 00:22:28,531 INFO:   Done with stage: EVALUATION
2023-01-05 00:22:28,531 INFO:   Leaving out SEQ value Fold_2
2023-01-05 00:22:28,544 INFO:   examples: 20,544| examples in train: 17,236 | examples in val: 908| examples in test: 2,400
2023-01-05 00:22:28,544 INFO:   Starting stage: FEATURE SCALING
2023-01-05 00:22:29,183 INFO:   Done with stage: FEATURE SCALING
2023-01-05 00:22:29,183 INFO:   Starting stage: SCALING TARGETS
2023-01-05 00:22:29,253 INFO:   Done with stage: SCALING TARGETS
2023-01-05 00:22:29,254 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:22:29,254 INFO:     No hyperparam tuning for this model
2023-01-05 00:22:29,254 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:22:29,254 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 00:22:29,255 INFO:     None feature selector for col prot
2023-01-05 00:22:29,255 INFO:     None feature selector for col prot
2023-01-05 00:22:29,255 INFO:     None feature selector for col prot
2023-01-05 00:22:29,255 INFO:     None feature selector for col chem
2023-01-05 00:22:29,255 INFO:     None feature selector for col chem
2023-01-05 00:22:29,255 INFO:     None feature selector for col chem
2023-01-05 00:22:29,255 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 00:22:29,256 INFO:   Starting stage: BUILD MODEL
2023-01-05 00:22:29,257 INFO:     Number of params in model 72931
2023-01-05 00:22:29,260 INFO:   Done with stage: BUILD MODEL
2023-01-05 00:22:29,260 INFO:   Starting stage: TRAINING
2023-01-05 00:22:29,321 INFO:     Val loss before train {'Reaction outcome loss': 1.1255755106608072, 'Total loss': 1.1255755106608072}
2023-01-05 00:22:29,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:29,321 INFO:     Epoch: 0
2023-01-05 00:22:31,489 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.766061000029246, 'Total loss': 0.766061000029246} | train loss {'Reaction outcome loss': 0.9649344949810593, 'Total loss': 0.9649344949810593}
2023-01-05 00:22:31,489 INFO:     Found new best model at epoch 0
2023-01-05 00:22:31,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:31,491 INFO:     Epoch: 1
2023-01-05 00:22:33,704 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49885051598151525, 'Total loss': 0.49885051598151525} | train loss {'Reaction outcome loss': 0.6364294955024012, 'Total loss': 0.6364294955024012}
2023-01-05 00:22:33,705 INFO:     Found new best model at epoch 1
2023-01-05 00:22:33,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:33,706 INFO:     Epoch: 2
2023-01-05 00:22:35,909 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.505745588739713, 'Total loss': 0.505745588739713} | train loss {'Reaction outcome loss': 0.5164325975709492, 'Total loss': 0.5164325975709492}
2023-01-05 00:22:35,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:35,910 INFO:     Epoch: 3
2023-01-05 00:22:38,114 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.43873751560846963, 'Total loss': 0.43873751560846963} | train loss {'Reaction outcome loss': 0.47357198071700557, 'Total loss': 0.47357198071700557}
2023-01-05 00:22:38,114 INFO:     Found new best model at epoch 3
2023-01-05 00:22:38,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:38,116 INFO:     Epoch: 4
2023-01-05 00:22:40,307 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.42060496707757317, 'Total loss': 0.42060496707757317} | train loss {'Reaction outcome loss': 0.4443391960528162, 'Total loss': 0.4443391960528162}
2023-01-05 00:22:40,307 INFO:     Found new best model at epoch 4
2023-01-05 00:22:40,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:40,308 INFO:     Epoch: 5
2023-01-05 00:22:42,504 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.39846125394105913, 'Total loss': 0.39846125394105913} | train loss {'Reaction outcome loss': 0.4242043094502555, 'Total loss': 0.4242043094502555}
2023-01-05 00:22:42,504 INFO:     Found new best model at epoch 5
2023-01-05 00:22:42,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:42,506 INFO:     Epoch: 6
2023-01-05 00:22:44,703 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3994151562452316, 'Total loss': 0.3994151562452316} | train loss {'Reaction outcome loss': 0.4060592030899392, 'Total loss': 0.4060592030899392}
2023-01-05 00:22:44,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:44,704 INFO:     Epoch: 7
2023-01-05 00:22:46,914 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40932523012161254, 'Total loss': 0.40932523012161254} | train loss {'Reaction outcome loss': 0.391381588164303, 'Total loss': 0.391381588164303}
2023-01-05 00:22:46,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:46,914 INFO:     Epoch: 8
2023-01-05 00:22:49,122 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41102020144462587, 'Total loss': 0.41102020144462587} | train loss {'Reaction outcome loss': 0.3799527365576338, 'Total loss': 0.3799527365576338}
2023-01-05 00:22:49,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:49,123 INFO:     Epoch: 9
2023-01-05 00:22:51,344 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.36577560678124427, 'Total loss': 0.36577560678124427} | train loss {'Reaction outcome loss': 0.3648803256728031, 'Total loss': 0.3648803256728031}
2023-01-05 00:22:51,345 INFO:     Found new best model at epoch 9
2023-01-05 00:22:51,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:51,346 INFO:     Epoch: 10
2023-01-05 00:22:53,521 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.411320153872172, 'Total loss': 0.411320153872172} | train loss {'Reaction outcome loss': 0.35454341435322057, 'Total loss': 0.35454341435322057}
2023-01-05 00:22:53,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:53,521 INFO:     Epoch: 11
2023-01-05 00:22:55,739 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41609191497166953, 'Total loss': 0.41609191497166953} | train loss {'Reaction outcome loss': 0.3433818406528897, 'Total loss': 0.3433818406528897}
2023-01-05 00:22:55,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:55,740 INFO:     Epoch: 12
2023-01-05 00:22:57,894 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3497456669807434, 'Total loss': 0.3497456669807434} | train loss {'Reaction outcome loss': 0.3316877069848555, 'Total loss': 0.3316877069848555}
2023-01-05 00:22:57,894 INFO:     Found new best model at epoch 12
2023-01-05 00:22:57,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:22:57,895 INFO:     Epoch: 13
2023-01-05 00:23:00,050 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.36371219853560127, 'Total loss': 0.36371219853560127} | train loss {'Reaction outcome loss': 0.3260050240214224, 'Total loss': 0.3260050240214224}
2023-01-05 00:23:00,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:00,050 INFO:     Epoch: 14
2023-01-05 00:23:02,259 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.37950100302696227, 'Total loss': 0.37950100302696227} | train loss {'Reaction outcome loss': 0.32063651258746784, 'Total loss': 0.32063651258746784}
2023-01-05 00:23:02,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:02,259 INFO:     Epoch: 15
2023-01-05 00:23:04,454 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3583328058322271, 'Total loss': 0.3583328058322271} | train loss {'Reaction outcome loss': 0.31286620936459963, 'Total loss': 0.31286620936459963}
2023-01-05 00:23:04,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:04,456 INFO:     Epoch: 16
2023-01-05 00:23:06,674 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.37412157555421194, 'Total loss': 0.37412157555421194} | train loss {'Reaction outcome loss': 0.3038795802742243, 'Total loss': 0.3038795802742243}
2023-01-05 00:23:06,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:06,674 INFO:     Epoch: 17
2023-01-05 00:23:08,882 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3797675003608068, 'Total loss': 0.3797675003608068} | train loss {'Reaction outcome loss': 0.2961899873007227, 'Total loss': 0.2961899873007227}
2023-01-05 00:23:08,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:08,883 INFO:     Epoch: 18
2023-01-05 00:23:11,064 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.388680562376976, 'Total loss': 0.388680562376976} | train loss {'Reaction outcome loss': 0.2858290636980975, 'Total loss': 0.2858290636980975}
2023-01-05 00:23:11,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:11,065 INFO:     Epoch: 19
2023-01-05 00:23:13,273 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3712637195984522, 'Total loss': 0.3712637195984522} | train loss {'Reaction outcome loss': 0.2843173314989717, 'Total loss': 0.2843173314989717}
2023-01-05 00:23:13,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:13,273 INFO:     Epoch: 20
2023-01-05 00:23:15,466 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.384548165400823, 'Total loss': 0.384548165400823} | train loss {'Reaction outcome loss': 0.2778350435197353, 'Total loss': 0.2778350435197353}
2023-01-05 00:23:15,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:15,466 INFO:     Epoch: 21
2023-01-05 00:23:17,682 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3619210089246432, 'Total loss': 0.3619210089246432} | train loss {'Reaction outcome loss': 0.27196001149713994, 'Total loss': 0.27196001149713994}
2023-01-05 00:23:17,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:17,683 INFO:     Epoch: 22
2023-01-05 00:23:19,895 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38376689006884895, 'Total loss': 0.38376689006884895} | train loss {'Reaction outcome loss': 0.27107267968908505, 'Total loss': 0.27107267968908505}
2023-01-05 00:23:19,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:19,895 INFO:     Epoch: 23
2023-01-05 00:23:22,096 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.36784311135609943, 'Total loss': 0.36784311135609943} | train loss {'Reaction outcome loss': 0.2620224858427213, 'Total loss': 0.2620224858427213}
2023-01-05 00:23:22,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:22,096 INFO:     Epoch: 24
2023-01-05 00:23:24,313 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.37506725986798606, 'Total loss': 0.37506725986798606} | train loss {'Reaction outcome loss': 0.26272435348342965, 'Total loss': 0.26272435348342965}
2023-01-05 00:23:24,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:24,314 INFO:     Epoch: 25
2023-01-05 00:23:26,530 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3674332526822885, 'Total loss': 0.3674332526822885} | train loss {'Reaction outcome loss': 0.2543268239194596, 'Total loss': 0.2543268239194596}
2023-01-05 00:23:26,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:26,530 INFO:     Epoch: 26
2023-01-05 00:23:28,742 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38583934903144834, 'Total loss': 0.38583934903144834} | train loss {'Reaction outcome loss': 0.2517954232654086, 'Total loss': 0.2517954232654086}
2023-01-05 00:23:28,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:28,742 INFO:     Epoch: 27
2023-01-05 00:23:30,948 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3537337139248848, 'Total loss': 0.3537337139248848} | train loss {'Reaction outcome loss': 0.24213842668191152, 'Total loss': 0.24213842668191152}
2023-01-05 00:23:30,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:30,948 INFO:     Epoch: 28
2023-01-05 00:23:33,145 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40406940976778666, 'Total loss': 0.40406940976778666} | train loss {'Reaction outcome loss': 0.24227787652225405, 'Total loss': 0.24227787652225405}
2023-01-05 00:23:33,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:33,145 INFO:     Epoch: 29
2023-01-05 00:23:35,296 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4055810734629631, 'Total loss': 0.4055810734629631} | train loss {'Reaction outcome loss': 0.23516649058847516, 'Total loss': 0.23516649058847516}
2023-01-05 00:23:35,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:35,297 INFO:     Epoch: 30
2023-01-05 00:23:37,509 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3853867029848819, 'Total loss': 0.3853867029848819} | train loss {'Reaction outcome loss': 0.23292684059728075, 'Total loss': 0.23292684059728075}
2023-01-05 00:23:37,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:37,509 INFO:     Epoch: 31
2023-01-05 00:23:39,701 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39567970981200534, 'Total loss': 0.39567970981200534} | train loss {'Reaction outcome loss': 0.22886579305071522, 'Total loss': 0.22886579305071522}
2023-01-05 00:23:39,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:39,702 INFO:     Epoch: 32
2023-01-05 00:23:41,912 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.37756238656584173, 'Total loss': 0.37756238656584173} | train loss {'Reaction outcome loss': 0.2250611315170924, 'Total loss': 0.2250611315170924}
2023-01-05 00:23:41,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:41,913 INFO:     Epoch: 33
2023-01-05 00:23:44,126 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3875642816225688, 'Total loss': 0.3875642816225688} | train loss {'Reaction outcome loss': 0.22100341508371962, 'Total loss': 0.22100341508371962}
2023-01-05 00:23:44,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:44,126 INFO:     Epoch: 34
2023-01-05 00:23:46,329 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3918620059887568, 'Total loss': 0.3918620059887568} | train loss {'Reaction outcome loss': 0.22018489666214144, 'Total loss': 0.22018489666214144}
2023-01-05 00:23:46,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:46,330 INFO:     Epoch: 35
2023-01-05 00:23:48,531 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4067872216304143, 'Total loss': 0.4067872216304143} | train loss {'Reaction outcome loss': 0.2176135173412385, 'Total loss': 0.2176135173412385}
2023-01-05 00:23:48,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:48,532 INFO:     Epoch: 36
2023-01-05 00:23:50,720 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4182505816221237, 'Total loss': 0.4182505816221237} | train loss {'Reaction outcome loss': 0.2091592304546524, 'Total loss': 0.2091592304546524}
2023-01-05 00:23:50,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:50,720 INFO:     Epoch: 37
2023-01-05 00:23:52,911 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4171191612879435, 'Total loss': 0.4171191612879435} | train loss {'Reaction outcome loss': 0.20927614722814825, 'Total loss': 0.20927614722814825}
2023-01-05 00:23:52,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:52,912 INFO:     Epoch: 38
2023-01-05 00:23:55,128 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48860846608877184, 'Total loss': 0.48860846608877184} | train loss {'Reaction outcome loss': 0.2062354503337432, 'Total loss': 0.2062354503337432}
2023-01-05 00:23:55,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:55,129 INFO:     Epoch: 39
2023-01-05 00:23:57,325 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49520340462525686, 'Total loss': 0.49520340462525686} | train loss {'Reaction outcome loss': 0.20306829040939056, 'Total loss': 0.20306829040939056}
2023-01-05 00:23:57,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:57,325 INFO:     Epoch: 40
2023-01-05 00:23:59,527 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39891131420930226, 'Total loss': 0.39891131420930226} | train loss {'Reaction outcome loss': 0.20124405005739796, 'Total loss': 0.20124405005739796}
2023-01-05 00:23:59,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:23:59,527 INFO:     Epoch: 41
2023-01-05 00:24:01,713 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4084741527835528, 'Total loss': 0.4084741527835528} | train loss {'Reaction outcome loss': 0.1973632686081584, 'Total loss': 0.1973632686081584}
2023-01-05 00:24:01,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:01,714 INFO:     Epoch: 42
2023-01-05 00:24:03,878 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41945784259587526, 'Total loss': 0.41945784259587526} | train loss {'Reaction outcome loss': 0.19625533383374136, 'Total loss': 0.19625533383374136}
2023-01-05 00:24:03,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:03,878 INFO:     Epoch: 43
2023-01-05 00:24:06,039 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4268333007891973, 'Total loss': 0.4268333007891973} | train loss {'Reaction outcome loss': 0.1944028198443077, 'Total loss': 0.1944028198443077}
2023-01-05 00:24:06,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:06,040 INFO:     Epoch: 44
2023-01-05 00:24:08,253 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4181552728017171, 'Total loss': 0.4181552728017171} | train loss {'Reaction outcome loss': 0.19368444059596018, 'Total loss': 0.19368444059596018}
2023-01-05 00:24:08,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:08,253 INFO:     Epoch: 45
2023-01-05 00:24:10,380 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4234920491774877, 'Total loss': 0.4234920491774877} | train loss {'Reaction outcome loss': 0.1919297755368192, 'Total loss': 0.1919297755368192}
2023-01-05 00:24:10,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:10,381 INFO:     Epoch: 46
2023-01-05 00:24:12,572 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4545996099710464, 'Total loss': 0.4545996099710464} | train loss {'Reaction outcome loss': 0.18447853936641304, 'Total loss': 0.18447853936641304}
2023-01-05 00:24:12,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:12,572 INFO:     Epoch: 47
2023-01-05 00:24:14,776 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43730340202649437, 'Total loss': 0.43730340202649437} | train loss {'Reaction outcome loss': 0.19036252449473573, 'Total loss': 0.19036252449473573}
2023-01-05 00:24:14,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:14,776 INFO:     Epoch: 48
2023-01-05 00:24:17,018 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4451090763012568, 'Total loss': 0.4451090763012568} | train loss {'Reaction outcome loss': 0.18431794118498349, 'Total loss': 0.18431794118498349}
2023-01-05 00:24:17,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:17,020 INFO:     Epoch: 49
2023-01-05 00:24:19,219 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4315056790908178, 'Total loss': 0.4315056790908178} | train loss {'Reaction outcome loss': 0.18608673502415143, 'Total loss': 0.18608673502415143}
2023-01-05 00:24:19,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:19,219 INFO:     Epoch: 50
2023-01-05 00:24:21,429 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4280563920736313, 'Total loss': 0.4280563920736313} | train loss {'Reaction outcome loss': 0.18677255510766472, 'Total loss': 0.18677255510766472}
2023-01-05 00:24:21,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:21,430 INFO:     Epoch: 51
2023-01-05 00:24:23,622 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4390895942846934, 'Total loss': 0.4390895942846934} | train loss {'Reaction outcome loss': 0.18329405478305286, 'Total loss': 0.18329405478305286}
2023-01-05 00:24:23,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:23,622 INFO:     Epoch: 52
2023-01-05 00:24:25,818 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4425935824712118, 'Total loss': 0.4425935824712118} | train loss {'Reaction outcome loss': 0.18054042202593, 'Total loss': 0.18054042202593}
2023-01-05 00:24:25,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:25,818 INFO:     Epoch: 53
2023-01-05 00:24:27,987 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44308273096879325, 'Total loss': 0.44308273096879325} | train loss {'Reaction outcome loss': 0.17804368195572384, 'Total loss': 0.17804368195572384}
2023-01-05 00:24:27,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:27,987 INFO:     Epoch: 54
2023-01-05 00:24:30,150 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43328814866642157, 'Total loss': 0.43328814866642157} | train loss {'Reaction outcome loss': 0.1822879795950872, 'Total loss': 0.1822879795950872}
2023-01-05 00:24:30,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:30,150 INFO:     Epoch: 55
2023-01-05 00:24:32,300 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4176941949253281, 'Total loss': 0.4176941949253281} | train loss {'Reaction outcome loss': 0.17823926099334603, 'Total loss': 0.17823926099334603}
2023-01-05 00:24:32,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:32,300 INFO:     Epoch: 56
2023-01-05 00:24:34,466 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4410747503240903, 'Total loss': 0.4410747503240903} | train loss {'Reaction outcome loss': 0.1757053449956907, 'Total loss': 0.1757053449956907}
2023-01-05 00:24:34,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:34,467 INFO:     Epoch: 57
2023-01-05 00:24:36,650 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3963165774320563, 'Total loss': 0.3963165774320563} | train loss {'Reaction outcome loss': 0.17023859628717655, 'Total loss': 0.17023859628717655}
2023-01-05 00:24:36,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:36,651 INFO:     Epoch: 58
2023-01-05 00:24:38,802 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43901425302028657, 'Total loss': 0.43901425302028657} | train loss {'Reaction outcome loss': 0.17651644553644238, 'Total loss': 0.17651644553644238}
2023-01-05 00:24:38,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:38,802 INFO:     Epoch: 59
2023-01-05 00:24:41,012 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42685766418774923, 'Total loss': 0.42685766418774923} | train loss {'Reaction outcome loss': 0.1697894185902206, 'Total loss': 0.1697894185902206}
2023-01-05 00:24:41,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:41,012 INFO:     Epoch: 60
2023-01-05 00:24:43,142 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.397223368488873, 'Total loss': 0.397223368488873} | train loss {'Reaction outcome loss': 0.1731530059473934, 'Total loss': 0.1731530059473934}
2023-01-05 00:24:43,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:43,142 INFO:     Epoch: 61
2023-01-05 00:24:45,351 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41570477398733297, 'Total loss': 0.41570477398733297} | train loss {'Reaction outcome loss': 0.1655267372313473, 'Total loss': 0.1655267372313473}
2023-01-05 00:24:45,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:45,351 INFO:     Epoch: 62
2023-01-05 00:24:47,537 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4387294451395671, 'Total loss': 0.4387294451395671} | train loss {'Reaction outcome loss': 0.16692916369583044, 'Total loss': 0.16692916369583044}
2023-01-05 00:24:47,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:47,538 INFO:     Epoch: 63
2023-01-05 00:24:49,733 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4416265229384104, 'Total loss': 0.4416265229384104} | train loss {'Reaction outcome loss': 0.16620903947149163, 'Total loss': 0.16620903947149163}
2023-01-05 00:24:49,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:49,733 INFO:     Epoch: 64
2023-01-05 00:24:51,949 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4698907479643822, 'Total loss': 0.4698907479643822} | train loss {'Reaction outcome loss': 0.16624531093812375, 'Total loss': 0.16624531093812375}
2023-01-05 00:24:51,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:51,950 INFO:     Epoch: 65
2023-01-05 00:24:54,125 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40515624849746623, 'Total loss': 0.40515624849746623} | train loss {'Reaction outcome loss': 0.1607704377250263, 'Total loss': 0.1607704377250263}
2023-01-05 00:24:54,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:54,126 INFO:     Epoch: 66
2023-01-05 00:24:56,332 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47354176044464114, 'Total loss': 0.47354176044464114} | train loss {'Reaction outcome loss': 0.15976957287294447, 'Total loss': 0.15976957287294447}
2023-01-05 00:24:56,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:56,333 INFO:     Epoch: 67
2023-01-05 00:24:58,548 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4647282590468725, 'Total loss': 0.4647282590468725} | train loss {'Reaction outcome loss': 0.16046448555706, 'Total loss': 0.16046448555706}
2023-01-05 00:24:58,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:24:58,549 INFO:     Epoch: 68
2023-01-05 00:25:00,749 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4391779844959577, 'Total loss': 0.4391779844959577} | train loss {'Reaction outcome loss': 0.1563867553430437, 'Total loss': 0.1563867553430437}
2023-01-05 00:25:00,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:00,749 INFO:     Epoch: 69
2023-01-05 00:25:02,950 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46257062355677286, 'Total loss': 0.46257062355677286} | train loss {'Reaction outcome loss': 0.15982824982385394, 'Total loss': 0.15982824982385394}
2023-01-05 00:25:02,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:02,950 INFO:     Epoch: 70
2023-01-05 00:25:05,147 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4452948321898778, 'Total loss': 0.4452948321898778} | train loss {'Reaction outcome loss': 0.15852545890569067, 'Total loss': 0.15852545890569067}
2023-01-05 00:25:05,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:05,148 INFO:     Epoch: 71
2023-01-05 00:25:07,339 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46015576670567193, 'Total loss': 0.46015576670567193} | train loss {'Reaction outcome loss': 0.15534333766403574, 'Total loss': 0.15534333766403574}
2023-01-05 00:25:07,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:07,339 INFO:     Epoch: 72
2023-01-05 00:25:09,541 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40906576613585155, 'Total loss': 0.40906576613585155} | train loss {'Reaction outcome loss': 0.15919425959388414, 'Total loss': 0.15919425959388414}
2023-01-05 00:25:09,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:09,541 INFO:     Epoch: 73
2023-01-05 00:25:11,571 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46720259884993237, 'Total loss': 0.46720259884993237} | train loss {'Reaction outcome loss': 0.15899532228811747, 'Total loss': 0.15899532228811747}
2023-01-05 00:25:11,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:11,572 INFO:     Epoch: 74
2023-01-05 00:25:13,694 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4303483502163241, 'Total loss': 0.4303483502163241} | train loss {'Reaction outcome loss': 0.1563453289464599, 'Total loss': 0.1563453289464599}
2023-01-05 00:25:13,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:13,694 INFO:     Epoch: 75
2023-01-05 00:25:15,898 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46712722927331923, 'Total loss': 0.46712722927331923} | train loss {'Reaction outcome loss': 0.15068310424168077, 'Total loss': 0.15068310424168077}
2023-01-05 00:25:15,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:15,898 INFO:     Epoch: 76
2023-01-05 00:25:18,100 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4786545723676682, 'Total loss': 0.4786545723676682} | train loss {'Reaction outcome loss': 0.14731570232694072, 'Total loss': 0.14731570232694072}
2023-01-05 00:25:18,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:18,100 INFO:     Epoch: 77
2023-01-05 00:25:20,312 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4372410178184509, 'Total loss': 0.4372410178184509} | train loss {'Reaction outcome loss': 0.15474074444285146, 'Total loss': 0.15474074444285146}
2023-01-05 00:25:20,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:20,312 INFO:     Epoch: 78
2023-01-05 00:25:22,531 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4317243258158366, 'Total loss': 0.4317243258158366} | train loss {'Reaction outcome loss': 0.15424976525655776, 'Total loss': 0.15424976525655776}
2023-01-05 00:25:22,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:22,531 INFO:     Epoch: 79
2023-01-05 00:25:24,736 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4363989492257436, 'Total loss': 0.4363989492257436} | train loss {'Reaction outcome loss': 0.1529703955097055, 'Total loss': 0.1529703955097055}
2023-01-05 00:25:24,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:24,737 INFO:     Epoch: 80
2023-01-05 00:25:26,953 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4292509620388349, 'Total loss': 0.4292509620388349} | train loss {'Reaction outcome loss': 0.1510507072033188, 'Total loss': 0.1510507072033188}
2023-01-05 00:25:26,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:26,953 INFO:     Epoch: 81
2023-01-05 00:25:29,120 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4339796449057758, 'Total loss': 0.4339796449057758} | train loss {'Reaction outcome loss': 0.14913732870654375, 'Total loss': 0.14913732870654375}
2023-01-05 00:25:29,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:29,121 INFO:     Epoch: 82
2023-01-05 00:25:31,308 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.491900904973348, 'Total loss': 0.491900904973348} | train loss {'Reaction outcome loss': 0.15438967186405703, 'Total loss': 0.15438967186405703}
2023-01-05 00:25:31,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:31,309 INFO:     Epoch: 83
2023-01-05 00:25:33,518 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4323728552941854, 'Total loss': 0.4323728552941854} | train loss {'Reaction outcome loss': 0.14815176722283166, 'Total loss': 0.14815176722283166}
2023-01-05 00:25:33,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:33,518 INFO:     Epoch: 84
2023-01-05 00:25:35,689 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4428794195254644, 'Total loss': 0.4428794195254644} | train loss {'Reaction outcome loss': 0.1501188926829922, 'Total loss': 0.1501188926829922}
2023-01-05 00:25:35,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:35,690 INFO:     Epoch: 85
2023-01-05 00:25:37,830 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44947728514671326, 'Total loss': 0.44947728514671326} | train loss {'Reaction outcome loss': 0.14560359033100584, 'Total loss': 0.14560359033100584}
2023-01-05 00:25:37,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:37,831 INFO:     Epoch: 86
2023-01-05 00:25:40,030 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40890130105738837, 'Total loss': 0.40890130105738837} | train loss {'Reaction outcome loss': 0.14759556845227187, 'Total loss': 0.14759556845227187}
2023-01-05 00:25:40,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:40,031 INFO:     Epoch: 87
2023-01-05 00:25:42,224 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44928850332895914, 'Total loss': 0.44928850332895914} | train loss {'Reaction outcome loss': 0.14626711651475893, 'Total loss': 0.14626711651475893}
2023-01-05 00:25:42,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:42,224 INFO:     Epoch: 88
2023-01-05 00:25:44,329 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45977119306723274, 'Total loss': 0.45977119306723274} | train loss {'Reaction outcome loss': 0.14516664597343792, 'Total loss': 0.14516664597343792}
2023-01-05 00:25:44,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:44,329 INFO:     Epoch: 89
2023-01-05 00:25:46,545 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40803437133630116, 'Total loss': 0.40803437133630116} | train loss {'Reaction outcome loss': 0.149604880237193, 'Total loss': 0.149604880237193}
2023-01-05 00:25:46,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:46,545 INFO:     Epoch: 90
2023-01-05 00:25:48,718 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4164481995316843, 'Total loss': 0.4164481995316843} | train loss {'Reaction outcome loss': 0.1447809604117302, 'Total loss': 0.1447809604117302}
2023-01-05 00:25:48,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:48,719 INFO:     Epoch: 91
2023-01-05 00:25:50,921 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40886328138876704, 'Total loss': 0.40886328138876704} | train loss {'Reaction outcome loss': 0.14597572420758229, 'Total loss': 0.14597572420758229}
2023-01-05 00:25:50,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:50,922 INFO:     Epoch: 92
2023-01-05 00:25:53,120 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43524206678072613, 'Total loss': 0.43524206678072613} | train loss {'Reaction outcome loss': 0.14395420651244759, 'Total loss': 0.14395420651244759}
2023-01-05 00:25:53,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:53,120 INFO:     Epoch: 93
2023-01-05 00:25:55,317 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4692961871623993, 'Total loss': 0.4692961871623993} | train loss {'Reaction outcome loss': 0.1381745346011249, 'Total loss': 0.1381745346011249}
2023-01-05 00:25:55,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:55,317 INFO:     Epoch: 94
2023-01-05 00:25:57,506 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4292536166186134, 'Total loss': 0.4292536166186134} | train loss {'Reaction outcome loss': 0.14713774223777432, 'Total loss': 0.14713774223777432}
2023-01-05 00:25:57,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:57,506 INFO:     Epoch: 95
2023-01-05 00:25:59,615 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4456061989689867, 'Total loss': 0.4456061989689867} | train loss {'Reaction outcome loss': 0.13979173279798554, 'Total loss': 0.13979173279798554}
2023-01-05 00:25:59,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:25:59,616 INFO:     Epoch: 96
2023-01-05 00:26:01,781 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4154456342260043, 'Total loss': 0.4154456342260043} | train loss {'Reaction outcome loss': 0.1389571305743798, 'Total loss': 0.1389571305743798}
2023-01-05 00:26:01,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:01,781 INFO:     Epoch: 97
2023-01-05 00:26:04,009 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4287223472298744, 'Total loss': 0.4287223472298744} | train loss {'Reaction outcome loss': 0.14208286479287954, 'Total loss': 0.14208286479287954}
2023-01-05 00:26:04,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:04,009 INFO:     Epoch: 98
2023-01-05 00:26:06,203 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4888522639870644, 'Total loss': 0.4888522639870644} | train loss {'Reaction outcome loss': 0.14322932194918395, 'Total loss': 0.14322932194918395}
2023-01-05 00:26:06,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:06,204 INFO:     Epoch: 99
2023-01-05 00:26:08,355 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43524147669474283, 'Total loss': 0.43524147669474283} | train loss {'Reaction outcome loss': 0.14445001245907474, 'Total loss': 0.14445001245907474}
2023-01-05 00:26:08,356 INFO:     Best model found after epoch 13 of 100.
2023-01-05 00:26:08,356 INFO:   Done with stage: TRAINING
2023-01-05 00:26:08,356 INFO:   Starting stage: EVALUATION
2023-01-05 00:26:08,515 INFO:   Done with stage: EVALUATION
2023-01-05 00:26:08,515 INFO:   Leaving out SEQ value Fold_3
2023-01-05 00:26:08,528 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 00:26:08,528 INFO:   Starting stage: FEATURE SCALING
2023-01-05 00:26:09,169 INFO:   Done with stage: FEATURE SCALING
2023-01-05 00:26:09,169 INFO:   Starting stage: SCALING TARGETS
2023-01-05 00:26:09,238 INFO:   Done with stage: SCALING TARGETS
2023-01-05 00:26:09,239 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:26:09,239 INFO:     No hyperparam tuning for this model
2023-01-05 00:26:09,239 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:26:09,239 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 00:26:09,239 INFO:     None feature selector for col prot
2023-01-05 00:26:09,240 INFO:     None feature selector for col prot
2023-01-05 00:26:09,240 INFO:     None feature selector for col prot
2023-01-05 00:26:09,240 INFO:     None feature selector for col chem
2023-01-05 00:26:09,240 INFO:     None feature selector for col chem
2023-01-05 00:26:09,240 INFO:     None feature selector for col chem
2023-01-05 00:26:09,240 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 00:26:09,241 INFO:   Starting stage: BUILD MODEL
2023-01-05 00:26:09,242 INFO:     Number of params in model 72931
2023-01-05 00:26:09,245 INFO:   Done with stage: BUILD MODEL
2023-01-05 00:26:09,245 INFO:   Starting stage: TRAINING
2023-01-05 00:26:09,304 INFO:     Val loss before train {'Reaction outcome loss': 0.9932487607002258, 'Total loss': 0.9932487607002258}
2023-01-05 00:26:09,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:09,304 INFO:     Epoch: 0
2023-01-05 00:26:11,491 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7476719955603282, 'Total loss': 0.7476719955603282} | train loss {'Reaction outcome loss': 0.9261722123530103, 'Total loss': 0.9261722123530103}
2023-01-05 00:26:11,491 INFO:     Found new best model at epoch 0
2023-01-05 00:26:11,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:11,492 INFO:     Epoch: 1
2023-01-05 00:26:13,710 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5721702108780543, 'Total loss': 0.5721702108780543} | train loss {'Reaction outcome loss': 0.6244302191140451, 'Total loss': 0.6244302191140451}
2023-01-05 00:26:13,710 INFO:     Found new best model at epoch 1
2023-01-05 00:26:13,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:13,711 INFO:     Epoch: 2
2023-01-05 00:26:15,934 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.563447368144989, 'Total loss': 0.563447368144989} | train loss {'Reaction outcome loss': 0.5379076295501584, 'Total loss': 0.5379076295501584}
2023-01-05 00:26:15,934 INFO:     Found new best model at epoch 2
2023-01-05 00:26:15,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:15,936 INFO:     Epoch: 3
2023-01-05 00:26:18,162 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5554477830727895, 'Total loss': 0.5554477830727895} | train loss {'Reaction outcome loss': 0.5045126802646197, 'Total loss': 0.5045126802646197}
2023-01-05 00:26:18,162 INFO:     Found new best model at epoch 3
2023-01-05 00:26:18,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:18,163 INFO:     Epoch: 4
2023-01-05 00:26:20,414 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49804284373919167, 'Total loss': 0.49804284373919167} | train loss {'Reaction outcome loss': 0.4759173708193468, 'Total loss': 0.4759173708193468}
2023-01-05 00:26:20,414 INFO:     Found new best model at epoch 4
2023-01-05 00:26:20,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:20,416 INFO:     Epoch: 5
2023-01-05 00:26:22,638 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5050105134646098, 'Total loss': 0.5050105134646098} | train loss {'Reaction outcome loss': 0.45423666434191956, 'Total loss': 0.45423666434191956}
2023-01-05 00:26:22,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:22,638 INFO:     Epoch: 6
2023-01-05 00:26:24,855 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5235865672429403, 'Total loss': 0.5235865672429403} | train loss {'Reaction outcome loss': 0.44302265578028044, 'Total loss': 0.44302265578028044}
2023-01-05 00:26:24,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:24,855 INFO:     Epoch: 7
2023-01-05 00:26:27,021 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4699948370456696, 'Total loss': 0.4699948370456696} | train loss {'Reaction outcome loss': 0.422236524276681, 'Total loss': 0.422236524276681}
2023-01-05 00:26:27,021 INFO:     Found new best model at epoch 7
2023-01-05 00:26:27,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:27,022 INFO:     Epoch: 8
2023-01-05 00:26:29,324 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4778332938750585, 'Total loss': 0.4778332938750585} | train loss {'Reaction outcome loss': 0.40995648953613345, 'Total loss': 0.40995648953613345}
2023-01-05 00:26:29,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:29,326 INFO:     Epoch: 9
2023-01-05 00:26:31,645 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4810202191273371, 'Total loss': 0.4810202191273371} | train loss {'Reaction outcome loss': 0.3936912416865974, 'Total loss': 0.3936912416865974}
2023-01-05 00:26:31,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:31,645 INFO:     Epoch: 10
2023-01-05 00:26:33,961 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4593126763900121, 'Total loss': 0.4593126763900121} | train loss {'Reaction outcome loss': 0.38641920074438435, 'Total loss': 0.38641920074438435}
2023-01-05 00:26:33,962 INFO:     Found new best model at epoch 10
2023-01-05 00:26:33,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:33,963 INFO:     Epoch: 11
2023-01-05 00:26:36,183 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4614643037319183, 'Total loss': 0.4614643037319183} | train loss {'Reaction outcome loss': 0.37625172042420935, 'Total loss': 0.37625172042420935}
2023-01-05 00:26:36,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:36,184 INFO:     Epoch: 12
2023-01-05 00:26:38,379 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4476444492737452, 'Total loss': 0.4476444492737452} | train loss {'Reaction outcome loss': 0.36247101289667055, 'Total loss': 0.36247101289667055}
2023-01-05 00:26:38,379 INFO:     Found new best model at epoch 12
2023-01-05 00:26:38,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:38,381 INFO:     Epoch: 13
2023-01-05 00:26:40,563 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43419496913750966, 'Total loss': 0.43419496913750966} | train loss {'Reaction outcome loss': 0.35470724940954984, 'Total loss': 0.35470724940954984}
2023-01-05 00:26:40,564 INFO:     Found new best model at epoch 13
2023-01-05 00:26:40,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:40,565 INFO:     Epoch: 14
2023-01-05 00:26:42,791 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45792923072973885, 'Total loss': 0.45792923072973885} | train loss {'Reaction outcome loss': 0.3442741556625281, 'Total loss': 0.3442741556625281}
2023-01-05 00:26:42,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:42,792 INFO:     Epoch: 15
2023-01-05 00:26:45,005 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4675578395525614, 'Total loss': 0.4675578395525614} | train loss {'Reaction outcome loss': 0.3347793851634522, 'Total loss': 0.3347793851634522}
2023-01-05 00:26:45,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:45,005 INFO:     Epoch: 16
2023-01-05 00:26:47,209 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4460124353567759, 'Total loss': 0.4460124353567759} | train loss {'Reaction outcome loss': 0.32731305878786815, 'Total loss': 0.32731305878786815}
2023-01-05 00:26:47,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:47,209 INFO:     Epoch: 17
2023-01-05 00:26:49,417 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46458153625329335, 'Total loss': 0.46458153625329335} | train loss {'Reaction outcome loss': 0.3207126094553715, 'Total loss': 0.3207126094553715}
2023-01-05 00:26:49,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:49,418 INFO:     Epoch: 18
2023-01-05 00:26:51,577 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47669998904069266, 'Total loss': 0.47669998904069266} | train loss {'Reaction outcome loss': 0.31487721840649735, 'Total loss': 0.31487721840649735}
2023-01-05 00:26:51,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:51,578 INFO:     Epoch: 19
2023-01-05 00:26:53,839 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4730122834444046, 'Total loss': 0.4730122834444046} | train loss {'Reaction outcome loss': 0.308987260697198, 'Total loss': 0.308987260697198}
2023-01-05 00:26:53,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:53,839 INFO:     Epoch: 20
2023-01-05 00:26:56,041 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4623392363389333, 'Total loss': 0.4623392363389333} | train loss {'Reaction outcome loss': 0.30207104410553154, 'Total loss': 0.30207104410553154}
2023-01-05 00:26:56,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:56,041 INFO:     Epoch: 21
2023-01-05 00:26:58,268 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4398152619600296, 'Total loss': 0.4398152619600296} | train loss {'Reaction outcome loss': 0.29982562013816483, 'Total loss': 0.29982562013816483}
2023-01-05 00:26:58,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:26:58,268 INFO:     Epoch: 22
2023-01-05 00:27:00,512 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43755258321762086, 'Total loss': 0.43755258321762086} | train loss {'Reaction outcome loss': 0.2882891267865569, 'Total loss': 0.2882891267865569}
2023-01-05 00:27:00,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:00,512 INFO:     Epoch: 23
2023-01-05 00:27:02,724 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45250965158144635, 'Total loss': 0.45250965158144635} | train loss {'Reaction outcome loss': 0.2846384740779142, 'Total loss': 0.2846384740779142}
2023-01-05 00:27:02,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:02,724 INFO:     Epoch: 24
2023-01-05 00:27:04,953 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45549420118331907, 'Total loss': 0.45549420118331907} | train loss {'Reaction outcome loss': 0.2845378317648456, 'Total loss': 0.2845378317648456}
2023-01-05 00:27:04,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:04,955 INFO:     Epoch: 25
2023-01-05 00:27:07,163 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4358297515970965, 'Total loss': 0.4358297515970965} | train loss {'Reaction outcome loss': 0.2771652223671967, 'Total loss': 0.2771652223671967}
2023-01-05 00:27:07,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:07,164 INFO:     Epoch: 26
2023-01-05 00:27:09,374 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4355364218354225, 'Total loss': 0.4355364218354225} | train loss {'Reaction outcome loss': 0.27307331038045357, 'Total loss': 0.27307331038045357}
2023-01-05 00:27:09,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:09,374 INFO:     Epoch: 27
2023-01-05 00:27:11,526 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47770054936408995, 'Total loss': 0.47770054936408995} | train loss {'Reaction outcome loss': 0.2662793797041689, 'Total loss': 0.2662793797041689}
2023-01-05 00:27:11,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:11,527 INFO:     Epoch: 28
2023-01-05 00:27:13,748 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4615299229820569, 'Total loss': 0.4615299229820569} | train loss {'Reaction outcome loss': 0.26395858260001237, 'Total loss': 0.26395858260001237}
2023-01-05 00:27:13,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:13,749 INFO:     Epoch: 29
2023-01-05 00:27:16,008 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47796091039975486, 'Total loss': 0.47796091039975486} | train loss {'Reaction outcome loss': 0.25785239824117756, 'Total loss': 0.25785239824117756}
2023-01-05 00:27:16,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:16,008 INFO:     Epoch: 30
2023-01-05 00:27:18,263 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45469303826491037, 'Total loss': 0.45469303826491037} | train loss {'Reaction outcome loss': 0.2577811055117365, 'Total loss': 0.2577811055117365}
2023-01-05 00:27:18,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:18,264 INFO:     Epoch: 31
2023-01-05 00:27:20,465 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47485003670056664, 'Total loss': 0.47485003670056664} | train loss {'Reaction outcome loss': 0.2558498604175372, 'Total loss': 0.2558498604175372}
2023-01-05 00:27:20,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:20,466 INFO:     Epoch: 32
2023-01-05 00:27:22,684 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44488245944182075, 'Total loss': 0.44488245944182075} | train loss {'Reaction outcome loss': 0.25098251460645443, 'Total loss': 0.25098251460645443}
2023-01-05 00:27:22,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:22,685 INFO:     Epoch: 33
2023-01-05 00:27:24,903 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4658106098572413, 'Total loss': 0.4658106098572413} | train loss {'Reaction outcome loss': 0.24556607776918474, 'Total loss': 0.24556607776918474}
2023-01-05 00:27:24,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:24,904 INFO:     Epoch: 34
2023-01-05 00:27:27,144 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4708459417025248, 'Total loss': 0.4708459417025248} | train loss {'Reaction outcome loss': 0.24527497212368407, 'Total loss': 0.24527497212368407}
2023-01-05 00:27:27,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:27,145 INFO:     Epoch: 35
2023-01-05 00:27:29,388 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4627886643012365, 'Total loss': 0.4627886643012365} | train loss {'Reaction outcome loss': 0.2382213650851241, 'Total loss': 0.2382213650851241}
2023-01-05 00:27:29,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:29,388 INFO:     Epoch: 36
2023-01-05 00:27:31,630 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45475314805905026, 'Total loss': 0.45475314805905026} | train loss {'Reaction outcome loss': 0.23873271071607924, 'Total loss': 0.23873271071607924}
2023-01-05 00:27:31,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:31,630 INFO:     Epoch: 37
2023-01-05 00:27:33,830 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47895968357721963, 'Total loss': 0.47895968357721963} | train loss {'Reaction outcome loss': 0.2345802269384756, 'Total loss': 0.2345802269384756}
2023-01-05 00:27:33,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:33,830 INFO:     Epoch: 38
2023-01-05 00:27:36,060 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.467045929034551, 'Total loss': 0.467045929034551} | train loss {'Reaction outcome loss': 0.23341138401638456, 'Total loss': 0.23341138401638456}
2023-01-05 00:27:36,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:36,061 INFO:     Epoch: 39
2023-01-05 00:27:38,254 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.481641094883283, 'Total loss': 0.481641094883283} | train loss {'Reaction outcome loss': 0.23195994220974245, 'Total loss': 0.23195994220974245}
2023-01-05 00:27:38,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:38,254 INFO:     Epoch: 40
2023-01-05 00:27:40,494 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47098421653111777, 'Total loss': 0.47098421653111777} | train loss {'Reaction outcome loss': 0.22662428843246385, 'Total loss': 0.22662428843246385}
2023-01-05 00:27:40,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:40,496 INFO:     Epoch: 41
2023-01-05 00:27:42,744 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45538924684127174, 'Total loss': 0.45538924684127174} | train loss {'Reaction outcome loss': 0.22710088288391028, 'Total loss': 0.22710088288391028}
2023-01-05 00:27:42,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:42,745 INFO:     Epoch: 42
2023-01-05 00:27:44,970 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4702572869757811, 'Total loss': 0.4702572869757811} | train loss {'Reaction outcome loss': 0.22226791431779389, 'Total loss': 0.22226791431779389}
2023-01-05 00:27:44,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:44,970 INFO:     Epoch: 43
2023-01-05 00:27:47,223 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45891619262595973, 'Total loss': 0.45891619262595973} | train loss {'Reaction outcome loss': 0.2242537189902731, 'Total loss': 0.2242537189902731}
2023-01-05 00:27:47,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:47,224 INFO:     Epoch: 44
2023-01-05 00:27:49,463 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42917527854442594, 'Total loss': 0.42917527854442594} | train loss {'Reaction outcome loss': 0.22193781841177862, 'Total loss': 0.22193781841177862}
2023-01-05 00:27:49,463 INFO:     Found new best model at epoch 44
2023-01-05 00:27:49,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:49,465 INFO:     Epoch: 45
2023-01-05 00:27:51,724 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43904528170824053, 'Total loss': 0.43904528170824053} | train loss {'Reaction outcome loss': 0.2174309102797901, 'Total loss': 0.2174309102797901}
2023-01-05 00:27:51,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:51,725 INFO:     Epoch: 46
2023-01-05 00:27:53,985 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4524017184972763, 'Total loss': 0.4524017184972763} | train loss {'Reaction outcome loss': 0.2166272893977853, 'Total loss': 0.2166272893977853}
2023-01-05 00:27:53,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:53,986 INFO:     Epoch: 47
2023-01-05 00:27:56,235 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4453466032942136, 'Total loss': 0.4453466032942136} | train loss {'Reaction outcome loss': 0.21307148465770723, 'Total loss': 0.21307148465770723}
2023-01-05 00:27:56,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:56,235 INFO:     Epoch: 48
2023-01-05 00:27:58,477 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4628917594750722, 'Total loss': 0.4628917594750722} | train loss {'Reaction outcome loss': 0.2138997098164899, 'Total loss': 0.2138997098164899}
2023-01-05 00:27:58,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:27:58,478 INFO:     Epoch: 49
2023-01-05 00:28:00,639 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45757649739583334, 'Total loss': 0.45757649739583334} | train loss {'Reaction outcome loss': 0.2091083081964499, 'Total loss': 0.2091083081964499}
2023-01-05 00:28:00,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:00,641 INFO:     Epoch: 50
2023-01-05 00:28:02,847 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4866114924351374, 'Total loss': 0.4866114924351374} | train loss {'Reaction outcome loss': 0.20559286183230716, 'Total loss': 0.20559286183230716}
2023-01-05 00:28:02,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:02,848 INFO:     Epoch: 51
2023-01-05 00:28:05,058 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4540449361006419, 'Total loss': 0.4540449361006419} | train loss {'Reaction outcome loss': 0.2046239735667795, 'Total loss': 0.2046239735667795}
2023-01-05 00:28:05,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:05,058 INFO:     Epoch: 52
2023-01-05 00:28:07,250 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47289686401685077, 'Total loss': 0.47289686401685077} | train loss {'Reaction outcome loss': 0.2057736008581552, 'Total loss': 0.2057736008581552}
2023-01-05 00:28:07,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:07,251 INFO:     Epoch: 53
2023-01-05 00:28:09,480 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4697134594122569, 'Total loss': 0.4697134594122569} | train loss {'Reaction outcome loss': 0.20502488603030805, 'Total loss': 0.20502488603030805}
2023-01-05 00:28:09,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:09,480 INFO:     Epoch: 54
2023-01-05 00:28:11,702 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4967849095662435, 'Total loss': 0.4967849095662435} | train loss {'Reaction outcome loss': 0.20129942251267013, 'Total loss': 0.20129942251267013}
2023-01-05 00:28:11,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:11,703 INFO:     Epoch: 55
2023-01-05 00:28:13,934 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49945400208234786, 'Total loss': 0.49945400208234786} | train loss {'Reaction outcome loss': 0.19938872122775503, 'Total loss': 0.19938872122775503}
2023-01-05 00:28:13,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:13,934 INFO:     Epoch: 56
2023-01-05 00:28:16,141 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4611278235912323, 'Total loss': 0.4611278235912323} | train loss {'Reaction outcome loss': 0.20079082344750782, 'Total loss': 0.20079082344750782}
2023-01-05 00:28:16,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:16,142 INFO:     Epoch: 57
2023-01-05 00:28:18,359 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46062274078528087, 'Total loss': 0.46062274078528087} | train loss {'Reaction outcome loss': 0.20344810947885006, 'Total loss': 0.20344810947885006}
2023-01-05 00:28:18,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:18,360 INFO:     Epoch: 58
2023-01-05 00:28:20,575 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4419477234284083, 'Total loss': 0.4419477234284083} | train loss {'Reaction outcome loss': 0.19562846177936474, 'Total loss': 0.19562846177936474}
2023-01-05 00:28:20,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:20,575 INFO:     Epoch: 59
2023-01-05 00:28:22,781 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4528558298945427, 'Total loss': 0.4528558298945427} | train loss {'Reaction outcome loss': 0.19749444640913616, 'Total loss': 0.19749444640913616}
2023-01-05 00:28:22,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:22,782 INFO:     Epoch: 60
2023-01-05 00:28:25,023 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46193000078201296, 'Total loss': 0.46193000078201296} | train loss {'Reaction outcome loss': 0.1951033632772473, 'Total loss': 0.1951033632772473}
2023-01-05 00:28:25,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:25,024 INFO:     Epoch: 61
2023-01-05 00:28:27,249 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4877314161509275, 'Total loss': 0.4877314161509275} | train loss {'Reaction outcome loss': 0.19559237484789485, 'Total loss': 0.19559237484789485}
2023-01-05 00:28:27,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:27,249 INFO:     Epoch: 62
2023-01-05 00:28:29,486 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4952773153781891, 'Total loss': 0.4952773153781891} | train loss {'Reaction outcome loss': 0.20307252073708254, 'Total loss': 0.20307252073708254}
2023-01-05 00:28:29,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:29,487 INFO:     Epoch: 63
2023-01-05 00:28:31,703 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4717746749520302, 'Total loss': 0.4717746749520302} | train loss {'Reaction outcome loss': 0.19276565026778442, 'Total loss': 0.19276565026778442}
2023-01-05 00:28:31,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:31,703 INFO:     Epoch: 64
2023-01-05 00:28:33,886 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5151977300643921, 'Total loss': 0.5151977300643921} | train loss {'Reaction outcome loss': 0.1930070869665552, 'Total loss': 0.1930070869665552}
2023-01-05 00:28:33,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:33,887 INFO:     Epoch: 65
2023-01-05 00:28:36,105 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4658992220958074, 'Total loss': 0.4658992220958074} | train loss {'Reaction outcome loss': 0.18433456532588918, 'Total loss': 0.18433456532588918}
2023-01-05 00:28:36,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:36,106 INFO:     Epoch: 66
2023-01-05 00:28:38,324 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.49377118051052094, 'Total loss': 0.49377118051052094} | train loss {'Reaction outcome loss': 0.19451996999291274, 'Total loss': 0.19451996999291274}
2023-01-05 00:28:38,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:38,325 INFO:     Epoch: 67
2023-01-05 00:28:40,535 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48900866508483887, 'Total loss': 0.48900866508483887} | train loss {'Reaction outcome loss': 0.1865177819728783, 'Total loss': 0.1865177819728783}
2023-01-05 00:28:40,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:40,535 INFO:     Epoch: 68
2023-01-05 00:28:42,768 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5271035701036453, 'Total loss': 0.5271035701036453} | train loss {'Reaction outcome loss': 0.1863550393204222, 'Total loss': 0.1863550393204222}
2023-01-05 00:28:42,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:42,768 INFO:     Epoch: 69
2023-01-05 00:28:44,980 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48775649766127266, 'Total loss': 0.48775649766127266} | train loss {'Reaction outcome loss': 0.18928688389313963, 'Total loss': 0.18928688389313963}
2023-01-05 00:28:44,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:44,980 INFO:     Epoch: 70
2023-01-05 00:28:47,208 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4983327825864156, 'Total loss': 0.4983327825864156} | train loss {'Reaction outcome loss': 0.18452301912432734, 'Total loss': 0.18452301912432734}
2023-01-05 00:28:47,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:47,209 INFO:     Epoch: 71
2023-01-05 00:28:49,427 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.446244353055954, 'Total loss': 0.446244353055954} | train loss {'Reaction outcome loss': 0.1850541803931251, 'Total loss': 0.1850541803931251}
2023-01-05 00:28:49,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:49,427 INFO:     Epoch: 72
2023-01-05 00:28:51,665 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47860414783159894, 'Total loss': 0.47860414783159894} | train loss {'Reaction outcome loss': 0.18767275754191773, 'Total loss': 0.18767275754191773}
2023-01-05 00:28:51,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:51,666 INFO:     Epoch: 73
2023-01-05 00:28:53,912 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46843351125717164, 'Total loss': 0.46843351125717164} | train loss {'Reaction outcome loss': 0.18265516546319474, 'Total loss': 0.18265516546319474}
2023-01-05 00:28:53,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:53,913 INFO:     Epoch: 74
2023-01-05 00:28:56,116 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4724050680796305, 'Total loss': 0.4724050680796305} | train loss {'Reaction outcome loss': 0.18066173971327015, 'Total loss': 0.18066173971327015}
2023-01-05 00:28:56,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:56,116 INFO:     Epoch: 75
2023-01-05 00:28:58,351 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.477255109945933, 'Total loss': 0.477255109945933} | train loss {'Reaction outcome loss': 0.18148001168100608, 'Total loss': 0.18148001168100608}
2023-01-05 00:28:58,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:28:58,351 INFO:     Epoch: 76
2023-01-05 00:29:00,564 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.469197042286396, 'Total loss': 0.469197042286396} | train loss {'Reaction outcome loss': 0.17756205701163455, 'Total loss': 0.17756205701163455}
2023-01-05 00:29:00,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:00,564 INFO:     Epoch: 77
2023-01-05 00:29:02,804 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48318656186262765, 'Total loss': 0.48318656186262765} | train loss {'Reaction outcome loss': 0.17758123342787008, 'Total loss': 0.17758123342787008}
2023-01-05 00:29:02,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:02,804 INFO:     Epoch: 78
2023-01-05 00:29:05,019 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4772828002770742, 'Total loss': 0.4772828002770742} | train loss {'Reaction outcome loss': 0.18054052232167658, 'Total loss': 0.18054052232167658}
2023-01-05 00:29:05,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:05,019 INFO:     Epoch: 79
2023-01-05 00:29:07,242 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5346451088786125, 'Total loss': 0.5346451088786125} | train loss {'Reaction outcome loss': 0.1782971505730689, 'Total loss': 0.1782971505730689}
2023-01-05 00:29:07,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:07,243 INFO:     Epoch: 80
2023-01-05 00:29:09,462 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4763828754425049, 'Total loss': 0.4763828754425049} | train loss {'Reaction outcome loss': 0.17808286975318696, 'Total loss': 0.17808286975318696}
2023-01-05 00:29:09,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:09,462 INFO:     Epoch: 81
2023-01-05 00:29:11,602 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.510313555598259, 'Total loss': 0.510313555598259} | train loss {'Reaction outcome loss': 0.17671685370074197, 'Total loss': 0.17671685370074197}
2023-01-05 00:29:11,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:11,602 INFO:     Epoch: 82
2023-01-05 00:29:13,833 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4996678799390793, 'Total loss': 0.4996678799390793} | train loss {'Reaction outcome loss': 0.1737671092156007, 'Total loss': 0.1737671092156007}
2023-01-05 00:29:13,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:13,833 INFO:     Epoch: 83
2023-01-05 00:29:16,081 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47318292994362615, 'Total loss': 0.47318292994362615} | train loss {'Reaction outcome loss': 0.18371634590593014, 'Total loss': 0.18371634590593014}
2023-01-05 00:29:16,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:16,082 INFO:     Epoch: 84
2023-01-05 00:29:18,138 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4589435487985611, 'Total loss': 0.4589435487985611} | train loss {'Reaction outcome loss': 0.1785470142776331, 'Total loss': 0.1785470142776331}
2023-01-05 00:29:18,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:18,138 INFO:     Epoch: 85
2023-01-05 00:29:20,347 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5327226469914118, 'Total loss': 0.5327226469914118} | train loss {'Reaction outcome loss': 0.16758150947382572, 'Total loss': 0.16758150947382572}
2023-01-05 00:29:20,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:20,347 INFO:     Epoch: 86
2023-01-05 00:29:22,548 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4816117321451505, 'Total loss': 0.4816117321451505} | train loss {'Reaction outcome loss': 0.1730722921845868, 'Total loss': 0.1730722921845868}
2023-01-05 00:29:22,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:22,548 INFO:     Epoch: 87
2023-01-05 00:29:24,800 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4914704740047455, 'Total loss': 0.4914704740047455} | train loss {'Reaction outcome loss': 0.17228595884653292, 'Total loss': 0.17228595884653292}
2023-01-05 00:29:24,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:24,801 INFO:     Epoch: 88
2023-01-05 00:29:27,033 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5075996935367584, 'Total loss': 0.5075996935367584} | train loss {'Reaction outcome loss': 0.17267961034912876, 'Total loss': 0.17267961034912876}
2023-01-05 00:29:27,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:27,034 INFO:     Epoch: 89
2023-01-05 00:29:29,281 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48739500244458517, 'Total loss': 0.48739500244458517} | train loss {'Reaction outcome loss': 0.17113304285557715, 'Total loss': 0.17113304285557715}
2023-01-05 00:29:29,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:29,281 INFO:     Epoch: 90
2023-01-05 00:29:31,497 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4864875177542369, 'Total loss': 0.4864875177542369} | train loss {'Reaction outcome loss': 0.1695477547714207, 'Total loss': 0.1695477547714207}
2023-01-05 00:29:31,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:31,498 INFO:     Epoch: 91
2023-01-05 00:29:33,702 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49774649143218996, 'Total loss': 0.49774649143218996} | train loss {'Reaction outcome loss': 0.16956037630569257, 'Total loss': 0.16956037630569257}
2023-01-05 00:29:33,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:33,702 INFO:     Epoch: 92
2023-01-05 00:29:35,924 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48553491036097207, 'Total loss': 0.48553491036097207} | train loss {'Reaction outcome loss': 0.17030956354606283, 'Total loss': 0.17030956354606283}
2023-01-05 00:29:35,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:35,924 INFO:     Epoch: 93
2023-01-05 00:29:38,162 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49017306168874103, 'Total loss': 0.49017306168874103} | train loss {'Reaction outcome loss': 0.16965425846119148, 'Total loss': 0.16965425846119148}
2023-01-05 00:29:38,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:38,162 INFO:     Epoch: 94
2023-01-05 00:29:40,398 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46587153331687053, 'Total loss': 0.46587153331687053} | train loss {'Reaction outcome loss': 0.16913674745688234, 'Total loss': 0.16913674745688234}
2023-01-05 00:29:40,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:40,398 INFO:     Epoch: 95
2023-01-05 00:29:42,565 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48353218535582226, 'Total loss': 0.48353218535582226} | train loss {'Reaction outcome loss': 0.16376869936112054, 'Total loss': 0.16376869936112054}
2023-01-05 00:29:42,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:42,566 INFO:     Epoch: 96
2023-01-05 00:29:44,755 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4573443070054054, 'Total loss': 0.4573443070054054} | train loss {'Reaction outcome loss': 0.16266757508419155, 'Total loss': 0.16266757508419155}
2023-01-05 00:29:44,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:44,756 INFO:     Epoch: 97
2023-01-05 00:29:46,983 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5125146647294362, 'Total loss': 0.5125146647294362} | train loss {'Reaction outcome loss': 0.16303758318757727, 'Total loss': 0.16303758318757727}
2023-01-05 00:29:46,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:46,983 INFO:     Epoch: 98
2023-01-05 00:29:49,216 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5420415729284287, 'Total loss': 0.5420415729284287} | train loss {'Reaction outcome loss': 0.16571532617384507, 'Total loss': 0.16571532617384507}
2023-01-05 00:29:49,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:49,217 INFO:     Epoch: 99
2023-01-05 00:29:51,430 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5254587848981221, 'Total loss': 0.5254587848981221} | train loss {'Reaction outcome loss': 0.16853702487935732, 'Total loss': 0.16853702487935732}
2023-01-05 00:29:51,430 INFO:     Best model found after epoch 45 of 100.
2023-01-05 00:29:51,430 INFO:   Done with stage: TRAINING
2023-01-05 00:29:51,430 INFO:   Starting stage: EVALUATION
2023-01-05 00:29:51,579 INFO:   Done with stage: EVALUATION
2023-01-05 00:29:51,579 INFO:   Leaving out SEQ value Fold_4
2023-01-05 00:29:51,591 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 00:29:51,592 INFO:   Starting stage: FEATURE SCALING
2023-01-05 00:29:52,235 INFO:   Done with stage: FEATURE SCALING
2023-01-05 00:29:52,235 INFO:   Starting stage: SCALING TARGETS
2023-01-05 00:29:52,305 INFO:   Done with stage: SCALING TARGETS
2023-01-05 00:29:52,305 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:29:52,305 INFO:     No hyperparam tuning for this model
2023-01-05 00:29:52,305 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:29:52,305 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 00:29:52,306 INFO:     None feature selector for col prot
2023-01-05 00:29:52,306 INFO:     None feature selector for col prot
2023-01-05 00:29:52,306 INFO:     None feature selector for col prot
2023-01-05 00:29:52,307 INFO:     None feature selector for col chem
2023-01-05 00:29:52,307 INFO:     None feature selector for col chem
2023-01-05 00:29:52,307 INFO:     None feature selector for col chem
2023-01-05 00:29:52,307 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 00:29:52,307 INFO:   Starting stage: BUILD MODEL
2023-01-05 00:29:52,308 INFO:     Number of params in model 72931
2023-01-05 00:29:52,312 INFO:   Done with stage: BUILD MODEL
2023-01-05 00:29:52,312 INFO:   Starting stage: TRAINING
2023-01-05 00:29:52,372 INFO:     Val loss before train {'Reaction outcome loss': 0.9972423672676086, 'Total loss': 0.9972423672676086}
2023-01-05 00:29:52,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:52,372 INFO:     Epoch: 0
2023-01-05 00:29:54,673 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7081596652666727, 'Total loss': 0.7081596652666727} | train loss {'Reaction outcome loss': 0.9472319571490305, 'Total loss': 0.9472319571490305}
2023-01-05 00:29:54,674 INFO:     Found new best model at epoch 0
2023-01-05 00:29:54,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:54,675 INFO:     Epoch: 1
2023-01-05 00:29:56,957 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5834405461947123, 'Total loss': 0.5834405461947123} | train loss {'Reaction outcome loss': 0.6346295246462894, 'Total loss': 0.6346295246462894}
2023-01-05 00:29:56,957 INFO:     Found new best model at epoch 1
2023-01-05 00:29:56,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:56,959 INFO:     Epoch: 2
2023-01-05 00:29:59,215 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5469550808270772, 'Total loss': 0.5469550808270772} | train loss {'Reaction outcome loss': 0.5439389098057712, 'Total loss': 0.5439389098057712}
2023-01-05 00:29:59,215 INFO:     Found new best model at epoch 2
2023-01-05 00:29:59,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:29:59,216 INFO:     Epoch: 3
2023-01-05 00:30:01,492 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5157805780569712, 'Total loss': 0.5157805780569712} | train loss {'Reaction outcome loss': 0.4986067356905709, 'Total loss': 0.4986067356905709}
2023-01-05 00:30:01,493 INFO:     Found new best model at epoch 3
2023-01-05 00:30:01,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:01,494 INFO:     Epoch: 4
2023-01-05 00:30:03,766 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48082811882098514, 'Total loss': 0.48082811882098514} | train loss {'Reaction outcome loss': 0.47034543524563743, 'Total loss': 0.47034543524563743}
2023-01-05 00:30:03,766 INFO:     Found new best model at epoch 4
2023-01-05 00:30:03,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:03,767 INFO:     Epoch: 5
2023-01-05 00:30:06,018 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4807236472765605, 'Total loss': 0.4807236472765605} | train loss {'Reaction outcome loss': 0.44568105766328686, 'Total loss': 0.44568105766328686}
2023-01-05 00:30:06,019 INFO:     Found new best model at epoch 5
2023-01-05 00:30:06,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:06,020 INFO:     Epoch: 6
2023-01-05 00:30:08,267 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.443298144141833, 'Total loss': 0.443298144141833} | train loss {'Reaction outcome loss': 0.42995493132891, 'Total loss': 0.42995493132891}
2023-01-05 00:30:08,267 INFO:     Found new best model at epoch 6
2023-01-05 00:30:08,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:08,268 INFO:     Epoch: 7
2023-01-05 00:30:10,513 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43094233522812525, 'Total loss': 0.43094233522812525} | train loss {'Reaction outcome loss': 0.41624994003291704, 'Total loss': 0.41624994003291704}
2023-01-05 00:30:10,513 INFO:     Found new best model at epoch 7
2023-01-05 00:30:10,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:10,514 INFO:     Epoch: 8
2023-01-05 00:30:12,771 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42031665444374083, 'Total loss': 0.42031665444374083} | train loss {'Reaction outcome loss': 0.404878449531785, 'Total loss': 0.404878449531785}
2023-01-05 00:30:12,771 INFO:     Found new best model at epoch 8
2023-01-05 00:30:12,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:12,772 INFO:     Epoch: 9
2023-01-05 00:30:14,999 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44137686093648276, 'Total loss': 0.44137686093648276} | train loss {'Reaction outcome loss': 0.39057095529025665, 'Total loss': 0.39057095529025665}
2023-01-05 00:30:15,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:15,000 INFO:     Epoch: 10
2023-01-05 00:30:17,260 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4273945093154907, 'Total loss': 0.4273945093154907} | train loss {'Reaction outcome loss': 0.3825248800002147, 'Total loss': 0.3825248800002147}
2023-01-05 00:30:17,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:17,260 INFO:     Epoch: 11
2023-01-05 00:30:19,495 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4151986241340637, 'Total loss': 0.4151986241340637} | train loss {'Reaction outcome loss': 0.37226163256897393, 'Total loss': 0.37226163256897393}
2023-01-05 00:30:19,495 INFO:     Found new best model at epoch 11
2023-01-05 00:30:19,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:19,497 INFO:     Epoch: 12
2023-01-05 00:30:21,715 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.414879431327184, 'Total loss': 0.414879431327184} | train loss {'Reaction outcome loss': 0.35511611744416016, 'Total loss': 0.35511611744416016}
2023-01-05 00:30:21,715 INFO:     Found new best model at epoch 12
2023-01-05 00:30:21,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:21,717 INFO:     Epoch: 13
2023-01-05 00:30:23,953 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39301148454348245, 'Total loss': 0.39301148454348245} | train loss {'Reaction outcome loss': 0.34492741715673775, 'Total loss': 0.34492741715673775}
2023-01-05 00:30:23,953 INFO:     Found new best model at epoch 13
2023-01-05 00:30:23,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:23,955 INFO:     Epoch: 14
2023-01-05 00:30:26,184 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3915094196796417, 'Total loss': 0.3915094196796417} | train loss {'Reaction outcome loss': 0.33875947632654774, 'Total loss': 0.33875947632654774}
2023-01-05 00:30:26,184 INFO:     Found new best model at epoch 14
2023-01-05 00:30:26,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:26,186 INFO:     Epoch: 15
2023-01-05 00:30:28,412 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.38734666804472606, 'Total loss': 0.38734666804472606} | train loss {'Reaction outcome loss': 0.3342552381912263, 'Total loss': 0.3342552381912263}
2023-01-05 00:30:28,412 INFO:     Found new best model at epoch 15
2023-01-05 00:30:28,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:28,413 INFO:     Epoch: 16
2023-01-05 00:30:30,630 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39870979090531666, 'Total loss': 0.39870979090531666} | train loss {'Reaction outcome loss': 0.34904502352456684, 'Total loss': 0.34904502352456684}
2023-01-05 00:30:30,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:30,631 INFO:     Epoch: 17
2023-01-05 00:30:32,836 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41042591134707135, 'Total loss': 0.41042591134707135} | train loss {'Reaction outcome loss': 0.31669647287091485, 'Total loss': 0.31669647287091485}
2023-01-05 00:30:32,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:32,836 INFO:     Epoch: 18
2023-01-05 00:30:35,102 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41950557132562, 'Total loss': 0.41950557132562} | train loss {'Reaction outcome loss': 0.3123308002435859, 'Total loss': 0.3123308002435859}
2023-01-05 00:30:35,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:35,102 INFO:     Epoch: 19
2023-01-05 00:30:37,331 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40146936774253844, 'Total loss': 0.40146936774253844} | train loss {'Reaction outcome loss': 0.30685161467155686, 'Total loss': 0.30685161467155686}
2023-01-05 00:30:37,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:37,332 INFO:     Epoch: 20
2023-01-05 00:30:39,567 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.414673779408137, 'Total loss': 0.414673779408137} | train loss {'Reaction outcome loss': 0.29808998346498294, 'Total loss': 0.29808998346498294}
2023-01-05 00:30:39,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:39,567 INFO:     Epoch: 21
2023-01-05 00:30:41,767 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39872826064626377, 'Total loss': 0.39872826064626377} | train loss {'Reaction outcome loss': 0.2934281385113391, 'Total loss': 0.2934281385113391}
2023-01-05 00:30:41,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:41,768 INFO:     Epoch: 22
2023-01-05 00:30:43,995 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.395472060640653, 'Total loss': 0.395472060640653} | train loss {'Reaction outcome loss': 0.28457969838108105, 'Total loss': 0.28457969838108105}
2023-01-05 00:30:43,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:43,995 INFO:     Epoch: 23
2023-01-05 00:30:46,228 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42311037381490074, 'Total loss': 0.42311037381490074} | train loss {'Reaction outcome loss': 0.28195042283935606, 'Total loss': 0.28195042283935606}
2023-01-05 00:30:46,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:46,228 INFO:     Epoch: 24
2023-01-05 00:30:48,477 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40231961409250894, 'Total loss': 0.40231961409250894} | train loss {'Reaction outcome loss': 0.27420696838996356, 'Total loss': 0.27420696838996356}
2023-01-05 00:30:48,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:48,477 INFO:     Epoch: 25
2023-01-05 00:30:50,720 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.415923352042834, 'Total loss': 0.415923352042834} | train loss {'Reaction outcome loss': 0.27308065701694484, 'Total loss': 0.27308065701694484}
2023-01-05 00:30:50,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:50,721 INFO:     Epoch: 26
2023-01-05 00:30:52,911 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4097091103593508, 'Total loss': 0.4097091103593508} | train loss {'Reaction outcome loss': 0.26412860399948945, 'Total loss': 0.26412860399948945}
2023-01-05 00:30:52,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:52,911 INFO:     Epoch: 27
2023-01-05 00:30:55,145 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4000353733698527, 'Total loss': 0.4000353733698527} | train loss {'Reaction outcome loss': 0.26458309929855034, 'Total loss': 0.26458309929855034}
2023-01-05 00:30:55,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:55,145 INFO:     Epoch: 28
2023-01-05 00:30:57,359 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4125043402115504, 'Total loss': 0.4125043402115504} | train loss {'Reaction outcome loss': 0.2597248144312829, 'Total loss': 0.2597248144312829}
2023-01-05 00:30:57,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:57,359 INFO:     Epoch: 29
2023-01-05 00:30:59,618 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3968191166718801, 'Total loss': 0.3968191166718801} | train loss {'Reaction outcome loss': 0.2553401097851009, 'Total loss': 0.2553401097851009}
2023-01-05 00:30:59,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:30:59,619 INFO:     Epoch: 30
2023-01-05 00:31:01,876 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41983948449293773, 'Total loss': 0.41983948449293773} | train loss {'Reaction outcome loss': 0.258392471646653, 'Total loss': 0.258392471646653}
2023-01-05 00:31:01,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:01,876 INFO:     Epoch: 31
2023-01-05 00:31:04,113 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4008296514550845, 'Total loss': 0.4008296514550845} | train loss {'Reaction outcome loss': 0.2501375820653081, 'Total loss': 0.2501375820653081}
2023-01-05 00:31:04,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:04,114 INFO:     Epoch: 32
2023-01-05 00:31:06,318 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3994679133097331, 'Total loss': 0.3994679133097331} | train loss {'Reaction outcome loss': 0.24960461034767661, 'Total loss': 0.24960461034767661}
2023-01-05 00:31:06,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:06,320 INFO:     Epoch: 33
2023-01-05 00:31:08,563 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39326981008052825, 'Total loss': 0.39326981008052825} | train loss {'Reaction outcome loss': 0.24696587040291532, 'Total loss': 0.24696587040291532}
2023-01-05 00:31:08,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:08,563 INFO:     Epoch: 34
2023-01-05 00:31:10,730 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4018964891632398, 'Total loss': 0.4018964891632398} | train loss {'Reaction outcome loss': 0.2456585314070833, 'Total loss': 0.2456585314070833}
2023-01-05 00:31:10,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:10,730 INFO:     Epoch: 35
2023-01-05 00:31:12,916 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40200821260611214, 'Total loss': 0.40200821260611214} | train loss {'Reaction outcome loss': 0.24043078921090785, 'Total loss': 0.24043078921090785}
2023-01-05 00:31:12,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:12,916 INFO:     Epoch: 36
2023-01-05 00:31:15,128 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41959050099054973, 'Total loss': 0.41959050099054973} | train loss {'Reaction outcome loss': 0.23593412709316539, 'Total loss': 0.23593412709316539}
2023-01-05 00:31:15,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:15,128 INFO:     Epoch: 37
2023-01-05 00:31:17,302 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4297280917565028, 'Total loss': 0.4297280917565028} | train loss {'Reaction outcome loss': 0.23437428362903764, 'Total loss': 0.23437428362903764}
2023-01-05 00:31:17,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:17,302 INFO:     Epoch: 38
2023-01-05 00:31:19,485 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43852394123872124, 'Total loss': 0.43852394123872124} | train loss {'Reaction outcome loss': 0.2298254244049768, 'Total loss': 0.2298254244049768}
2023-01-05 00:31:19,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:19,485 INFO:     Epoch: 39
2023-01-05 00:31:21,674 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4110084513823191, 'Total loss': 0.4110084513823191} | train loss {'Reaction outcome loss': 0.22950125438417646, 'Total loss': 0.22950125438417646}
2023-01-05 00:31:21,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:21,674 INFO:     Epoch: 40
2023-01-05 00:31:23,911 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4255491574605306, 'Total loss': 0.4255491574605306} | train loss {'Reaction outcome loss': 0.2505032296150761, 'Total loss': 0.2505032296150761}
2023-01-05 00:31:23,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:23,911 INFO:     Epoch: 41
2023-01-05 00:31:26,169 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4402766058842341, 'Total loss': 0.4402766058842341} | train loss {'Reaction outcome loss': 0.22617253016843292, 'Total loss': 0.22617253016843292}
2023-01-05 00:31:26,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:26,170 INFO:     Epoch: 42
2023-01-05 00:31:28,386 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4108993150293827, 'Total loss': 0.4108993150293827} | train loss {'Reaction outcome loss': 0.2210495656691964, 'Total loss': 0.2210495656691964}
2023-01-05 00:31:28,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:28,387 INFO:     Epoch: 43
2023-01-05 00:31:30,623 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43730895121892294, 'Total loss': 0.43730895121892294} | train loss {'Reaction outcome loss': 0.2200683190730279, 'Total loss': 0.2200683190730279}
2023-01-05 00:31:30,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:30,624 INFO:     Epoch: 44
2023-01-05 00:31:32,881 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41013344998161, 'Total loss': 0.41013344998161} | train loss {'Reaction outcome loss': 0.21979641537114547, 'Total loss': 0.21979641537114547}
2023-01-05 00:31:32,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:32,881 INFO:     Epoch: 45
2023-01-05 00:31:35,019 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4138331214586894, 'Total loss': 0.4138331214586894} | train loss {'Reaction outcome loss': 0.2162768341738189, 'Total loss': 0.2162768341738189}
2023-01-05 00:31:35,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:35,019 INFO:     Epoch: 46
2023-01-05 00:31:37,236 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41502000788847604, 'Total loss': 0.41502000788847604} | train loss {'Reaction outcome loss': 0.21406824432694743, 'Total loss': 0.21406824432694743}
2023-01-05 00:31:37,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:37,237 INFO:     Epoch: 47
2023-01-05 00:31:39,496 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42492145945628484, 'Total loss': 0.42492145945628484} | train loss {'Reaction outcome loss': 0.2063124137851222, 'Total loss': 0.2063124137851222}
2023-01-05 00:31:39,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:39,497 INFO:     Epoch: 48
2023-01-05 00:31:41,708 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43531630039215086, 'Total loss': 0.43531630039215086} | train loss {'Reaction outcome loss': 0.2164647468564816, 'Total loss': 0.2164647468564816}
2023-01-05 00:31:41,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:41,709 INFO:     Epoch: 49
2023-01-05 00:31:43,908 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.466066841284434, 'Total loss': 0.466066841284434} | train loss {'Reaction outcome loss': 0.21097256636341521, 'Total loss': 0.21097256636341521}
2023-01-05 00:31:43,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:43,908 INFO:     Epoch: 50
2023-01-05 00:31:46,167 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43036320209503176, 'Total loss': 0.43036320209503176} | train loss {'Reaction outcome loss': 0.20884998255001003, 'Total loss': 0.20884998255001003}
2023-01-05 00:31:46,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:46,168 INFO:     Epoch: 51
2023-01-05 00:31:48,427 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4202909348998219, 'Total loss': 0.4202909348998219} | train loss {'Reaction outcome loss': 0.21039343044580217, 'Total loss': 0.21039343044580217}
2023-01-05 00:31:48,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:48,428 INFO:     Epoch: 52
2023-01-05 00:31:50,684 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45175255263845127, 'Total loss': 0.45175255263845127} | train loss {'Reaction outcome loss': 0.20406719424162956, 'Total loss': 0.20406719424162956}
2023-01-05 00:31:50,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:50,684 INFO:     Epoch: 53
2023-01-05 00:31:52,880 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4281425729393959, 'Total loss': 0.4281425729393959} | train loss {'Reaction outcome loss': 0.20498149819415656, 'Total loss': 0.20498149819415656}
2023-01-05 00:31:52,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:52,880 INFO:     Epoch: 54
2023-01-05 00:31:55,098 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4499661386013031, 'Total loss': 0.4499661386013031} | train loss {'Reaction outcome loss': 0.20410869619471655, 'Total loss': 0.20410869619471655}
2023-01-05 00:31:55,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:55,098 INFO:     Epoch: 55
2023-01-05 00:31:57,357 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4540905753771464, 'Total loss': 0.4540905753771464} | train loss {'Reaction outcome loss': 0.20372161382566328, 'Total loss': 0.20372161382566328}
2023-01-05 00:31:57,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:57,357 INFO:     Epoch: 56
2023-01-05 00:31:59,548 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4377484997113546, 'Total loss': 0.4377484997113546} | train loss {'Reaction outcome loss': 0.19431990653316936, 'Total loss': 0.19431990653316936}
2023-01-05 00:31:59,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:31:59,548 INFO:     Epoch: 57
2023-01-05 00:32:01,788 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4314717342456182, 'Total loss': 0.4314717342456182} | train loss {'Reaction outcome loss': 0.1936057291157709, 'Total loss': 0.1936057291157709}
2023-01-05 00:32:01,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:01,789 INFO:     Epoch: 58
2023-01-05 00:32:03,989 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44996083378791807, 'Total loss': 0.44996083378791807} | train loss {'Reaction outcome loss': 0.1952829280951688, 'Total loss': 0.1952829280951688}
2023-01-05 00:32:03,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:03,990 INFO:     Epoch: 59
2023-01-05 00:32:06,171 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43644264340400696, 'Total loss': 0.43644264340400696} | train loss {'Reaction outcome loss': 0.19459986597623513, 'Total loss': 0.19459986597623513}
2023-01-05 00:32:06,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:06,172 INFO:     Epoch: 60
2023-01-05 00:32:08,430 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42785350829362867, 'Total loss': 0.42785350829362867} | train loss {'Reaction outcome loss': 0.19668844145865255, 'Total loss': 0.19668844145865255}
2023-01-05 00:32:08,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:08,430 INFO:     Epoch: 61
2023-01-05 00:32:10,646 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42106525305037695, 'Total loss': 0.42106525305037695} | train loss {'Reaction outcome loss': 0.19719708044135917, 'Total loss': 0.19719708044135917}
2023-01-05 00:32:10,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:10,646 INFO:     Epoch: 62
2023-01-05 00:32:12,810 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4466477950414022, 'Total loss': 0.4466477950414022} | train loss {'Reaction outcome loss': 0.1926128340971933, 'Total loss': 0.1926128340971933}
2023-01-05 00:32:12,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:12,811 INFO:     Epoch: 63
2023-01-05 00:32:15,049 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47165455495317776, 'Total loss': 0.47165455495317776} | train loss {'Reaction outcome loss': 0.1933256191633004, 'Total loss': 0.1933256191633004}
2023-01-05 00:32:15,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:15,050 INFO:     Epoch: 64
2023-01-05 00:32:17,282 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45171688894430795, 'Total loss': 0.45171688894430795} | train loss {'Reaction outcome loss': 0.20199471349369033, 'Total loss': 0.20199471349369033}
2023-01-05 00:32:17,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:17,283 INFO:     Epoch: 65
2023-01-05 00:32:19,505 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41832158863544466, 'Total loss': 0.41832158863544466} | train loss {'Reaction outcome loss': 0.22765663233872477, 'Total loss': 0.22765663233872477}
2023-01-05 00:32:19,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:19,506 INFO:     Epoch: 66
2023-01-05 00:32:21,749 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43955570658047993, 'Total loss': 0.43955570658047993} | train loss {'Reaction outcome loss': 0.19370539217493057, 'Total loss': 0.19370539217493057}
2023-01-05 00:32:21,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:21,750 INFO:     Epoch: 67
2023-01-05 00:32:23,972 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43822176456451417, 'Total loss': 0.43822176456451417} | train loss {'Reaction outcome loss': 0.18661126767730582, 'Total loss': 0.18661126767730582}
2023-01-05 00:32:23,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:23,973 INFO:     Epoch: 68
2023-01-05 00:32:26,233 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4707825521628062, 'Total loss': 0.4707825521628062} | train loss {'Reaction outcome loss': 0.18690900031630747, 'Total loss': 0.18690900031630747}
2023-01-05 00:32:26,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:26,233 INFO:     Epoch: 69
2023-01-05 00:32:28,474 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4358399187525113, 'Total loss': 0.4358399187525113} | train loss {'Reaction outcome loss': 0.18702465088774814, 'Total loss': 0.18702465088774814}
2023-01-05 00:32:28,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:28,474 INFO:     Epoch: 70
2023-01-05 00:32:30,723 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4485647330681483, 'Total loss': 0.4485647330681483} | train loss {'Reaction outcome loss': 0.18078033247845757, 'Total loss': 0.18078033247845757}
2023-01-05 00:32:30,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:30,723 INFO:     Epoch: 71
2023-01-05 00:32:32,984 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4444231351216634, 'Total loss': 0.4444231351216634} | train loss {'Reaction outcome loss': 0.18747714037970686, 'Total loss': 0.18747714037970686}
2023-01-05 00:32:32,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:32,984 INFO:     Epoch: 72
2023-01-05 00:32:35,240 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45889428853988645, 'Total loss': 0.45889428853988645} | train loss {'Reaction outcome loss': 0.18138433629781872, 'Total loss': 0.18138433629781872}
2023-01-05 00:32:35,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:35,240 INFO:     Epoch: 73
2023-01-05 00:32:37,502 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45417261521021524, 'Total loss': 0.45417261521021524} | train loss {'Reaction outcome loss': 0.18469854742273828, 'Total loss': 0.18469854742273828}
2023-01-05 00:32:37,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:37,503 INFO:     Epoch: 74
2023-01-05 00:32:39,710 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47636499106884, 'Total loss': 0.47636499106884} | train loss {'Reaction outcome loss': 0.18529608682054433, 'Total loss': 0.18529608682054433}
2023-01-05 00:32:39,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:39,710 INFO:     Epoch: 75
2023-01-05 00:32:41,969 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45149271910389266, 'Total loss': 0.45149271910389266} | train loss {'Reaction outcome loss': 0.18503920659608464, 'Total loss': 0.18503920659608464}
2023-01-05 00:32:41,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:41,969 INFO:     Epoch: 76
2023-01-05 00:32:44,160 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42997321486473083, 'Total loss': 0.42997321486473083} | train loss {'Reaction outcome loss': 0.1838317889647653, 'Total loss': 0.1838317889647653}
2023-01-05 00:32:44,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:44,160 INFO:     Epoch: 77
2023-01-05 00:32:46,375 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4519207020600637, 'Total loss': 0.4519207020600637} | train loss {'Reaction outcome loss': 0.18232042173659083, 'Total loss': 0.18232042173659083}
2023-01-05 00:32:46,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:46,375 INFO:     Epoch: 78
2023-01-05 00:32:48,542 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43748578429222107, 'Total loss': 0.43748578429222107} | train loss {'Reaction outcome loss': 0.1770960672948749, 'Total loss': 0.1770960672948749}
2023-01-05 00:32:48,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:48,542 INFO:     Epoch: 79
2023-01-05 00:32:50,806 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4306725760300954, 'Total loss': 0.4306725760300954} | train loss {'Reaction outcome loss': 0.17928562083861965, 'Total loss': 0.17928562083861965}
2023-01-05 00:32:50,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:50,806 INFO:     Epoch: 80
2023-01-05 00:32:53,083 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4618317941824595, 'Total loss': 0.4618317941824595} | train loss {'Reaction outcome loss': 0.1787929505572074, 'Total loss': 0.1787929505572074}
2023-01-05 00:32:53,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:53,084 INFO:     Epoch: 81
2023-01-05 00:32:55,361 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4264882405598958, 'Total loss': 0.4264882405598958} | train loss {'Reaction outcome loss': 0.17979160881689008, 'Total loss': 0.17979160881689008}
2023-01-05 00:32:55,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:55,361 INFO:     Epoch: 82
2023-01-05 00:32:57,655 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4523271838823954, 'Total loss': 0.4523271838823954} | train loss {'Reaction outcome loss': 0.17890391991713314, 'Total loss': 0.17890391991713314}
2023-01-05 00:32:57,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:57,655 INFO:     Epoch: 83
2023-01-05 00:32:59,947 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45359559257825216, 'Total loss': 0.45359559257825216} | train loss {'Reaction outcome loss': 0.17996723529970463, 'Total loss': 0.17996723529970463}
2023-01-05 00:32:59,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:32:59,948 INFO:     Epoch: 84
2023-01-05 00:33:02,215 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44162272959947585, 'Total loss': 0.44162272959947585} | train loss {'Reaction outcome loss': 0.17447688027396394, 'Total loss': 0.17447688027396394}
2023-01-05 00:33:02,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:02,215 INFO:     Epoch: 85
2023-01-05 00:33:04,161 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4685820738474528, 'Total loss': 0.4685820738474528} | train loss {'Reaction outcome loss': 0.17629844934909025, 'Total loss': 0.17629844934909025}
2023-01-05 00:33:04,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:04,161 INFO:     Epoch: 86
2023-01-05 00:33:06,031 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44234751065572103, 'Total loss': 0.44234751065572103} | train loss {'Reaction outcome loss': 0.16902128978467046, 'Total loss': 0.16902128978467046}
2023-01-05 00:33:06,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:06,032 INFO:     Epoch: 87
2023-01-05 00:33:08,100 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45129018227259315, 'Total loss': 0.45129018227259315} | train loss {'Reaction outcome loss': 0.17326187284366376, 'Total loss': 0.17326187284366376}
2023-01-05 00:33:08,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:08,100 INFO:     Epoch: 88
2023-01-05 00:33:10,374 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44169535239537555, 'Total loss': 0.44169535239537555} | train loss {'Reaction outcome loss': 0.17477185079706428, 'Total loss': 0.17477185079706428}
2023-01-05 00:33:10,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:10,374 INFO:     Epoch: 89
2023-01-05 00:33:12,605 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4441824838519096, 'Total loss': 0.4441824838519096} | train loss {'Reaction outcome loss': 0.17927102272844184, 'Total loss': 0.17927102272844184}
2023-01-05 00:33:12,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:12,606 INFO:     Epoch: 90
2023-01-05 00:33:14,885 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4499708185593287, 'Total loss': 0.4499708185593287} | train loss {'Reaction outcome loss': 0.23383759048270025, 'Total loss': 0.23383759048270025}
2023-01-05 00:33:14,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:14,885 INFO:     Epoch: 91
2023-01-05 00:33:17,156 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.458281942208608, 'Total loss': 0.458281942208608} | train loss {'Reaction outcome loss': 0.1808580090831695, 'Total loss': 0.1808580090831695}
2023-01-05 00:33:17,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:17,156 INFO:     Epoch: 92
2023-01-05 00:33:19,418 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43467079401016234, 'Total loss': 0.43467079401016234} | train loss {'Reaction outcome loss': 0.19871456752344038, 'Total loss': 0.19871456752344038}
2023-01-05 00:33:19,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:19,418 INFO:     Epoch: 93
2023-01-05 00:33:21,668 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4406074831883113, 'Total loss': 0.4406074831883113} | train loss {'Reaction outcome loss': 0.17349503224363946, 'Total loss': 0.17349503224363946}
2023-01-05 00:33:21,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:21,669 INFO:     Epoch: 94
2023-01-05 00:33:23,875 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4693999403466781, 'Total loss': 0.4693999403466781} | train loss {'Reaction outcome loss': 0.17196299108226135, 'Total loss': 0.17196299108226135}
2023-01-05 00:33:23,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:23,876 INFO:     Epoch: 95
2023-01-05 00:33:25,949 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46351795047521593, 'Total loss': 0.46351795047521593} | train loss {'Reaction outcome loss': 0.1723275253501977, 'Total loss': 0.1723275253501977}
2023-01-05 00:33:25,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:25,950 INFO:     Epoch: 96
2023-01-05 00:33:28,153 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45134216398000715, 'Total loss': 0.45134216398000715} | train loss {'Reaction outcome loss': 0.19964764792559989, 'Total loss': 0.19964764792559989}
2023-01-05 00:33:28,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:28,154 INFO:     Epoch: 97
2023-01-05 00:33:30,377 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45744118293126423, 'Total loss': 0.45744118293126423} | train loss {'Reaction outcome loss': 0.17666852531239283, 'Total loss': 0.17666852531239283}
2023-01-05 00:33:30,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:30,379 INFO:     Epoch: 98
2023-01-05 00:33:32,598 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44650358259677886, 'Total loss': 0.44650358259677886} | train loss {'Reaction outcome loss': 0.1788378497838731, 'Total loss': 0.1788378497838731}
2023-01-05 00:33:32,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:32,598 INFO:     Epoch: 99
2023-01-05 00:33:34,830 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4621683855851491, 'Total loss': 0.4621683855851491} | train loss {'Reaction outcome loss': 0.1860917957206054, 'Total loss': 0.1860917957206054}
2023-01-05 00:33:34,830 INFO:     Best model found after epoch 16 of 100.
2023-01-05 00:33:34,830 INFO:   Done with stage: TRAINING
2023-01-05 00:33:34,830 INFO:   Starting stage: EVALUATION
2023-01-05 00:33:34,965 INFO:   Done with stage: EVALUATION
2023-01-05 00:33:34,966 INFO:   Leaving out SEQ value Fold_5
2023-01-05 00:33:34,978 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 00:33:34,978 INFO:   Starting stage: FEATURE SCALING
2023-01-05 00:33:35,620 INFO:   Done with stage: FEATURE SCALING
2023-01-05 00:33:35,620 INFO:   Starting stage: SCALING TARGETS
2023-01-05 00:33:35,692 INFO:   Done with stage: SCALING TARGETS
2023-01-05 00:33:35,692 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:33:35,692 INFO:     No hyperparam tuning for this model
2023-01-05 00:33:35,692 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:33:35,692 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 00:33:35,693 INFO:     None feature selector for col prot
2023-01-05 00:33:35,693 INFO:     None feature selector for col prot
2023-01-05 00:33:35,693 INFO:     None feature selector for col prot
2023-01-05 00:33:35,694 INFO:     None feature selector for col chem
2023-01-05 00:33:35,694 INFO:     None feature selector for col chem
2023-01-05 00:33:35,694 INFO:     None feature selector for col chem
2023-01-05 00:33:35,694 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 00:33:35,694 INFO:   Starting stage: BUILD MODEL
2023-01-05 00:33:35,696 INFO:     Number of params in model 72931
2023-01-05 00:33:35,699 INFO:   Done with stage: BUILD MODEL
2023-01-05 00:33:35,699 INFO:   Starting stage: TRAINING
2023-01-05 00:33:35,760 INFO:     Val loss before train {'Reaction outcome loss': 0.9779963850975036, 'Total loss': 0.9779963850975036}
2023-01-05 00:33:35,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:35,760 INFO:     Epoch: 0
2023-01-05 00:33:38,012 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8072118202845255, 'Total loss': 0.8072118202845255} | train loss {'Reaction outcome loss': 0.9737905546806861, 'Total loss': 0.9737905546806861}
2023-01-05 00:33:38,013 INFO:     Found new best model at epoch 0
2023-01-05 00:33:38,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:38,015 INFO:     Epoch: 1
2023-01-05 00:33:40,239 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5995618780454, 'Total loss': 0.5995618780454} | train loss {'Reaction outcome loss': 0.6773456932193991, 'Total loss': 0.6773456932193991}
2023-01-05 00:33:40,239 INFO:     Found new best model at epoch 1
2023-01-05 00:33:40,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:40,240 INFO:     Epoch: 2
2023-01-05 00:33:42,464 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6203754623730977, 'Total loss': 0.6203754623730977} | train loss {'Reaction outcome loss': 0.5558267693824904, 'Total loss': 0.5558267693824904}
2023-01-05 00:33:42,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:42,465 INFO:     Epoch: 3
2023-01-05 00:33:44,617 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5576308985551198, 'Total loss': 0.5576308985551198} | train loss {'Reaction outcome loss': 0.5160395344449342, 'Total loss': 0.5160395344449342}
2023-01-05 00:33:44,618 INFO:     Found new best model at epoch 3
2023-01-05 00:33:44,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:44,619 INFO:     Epoch: 4
2023-01-05 00:33:46,854 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5031198541323344, 'Total loss': 0.5031198541323344} | train loss {'Reaction outcome loss': 0.4870653605979422, 'Total loss': 0.4870653605979422}
2023-01-05 00:33:46,854 INFO:     Found new best model at epoch 4
2023-01-05 00:33:46,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:46,856 INFO:     Epoch: 5
2023-01-05 00:33:49,061 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.501791532834371, 'Total loss': 0.501791532834371} | train loss {'Reaction outcome loss': 0.4677805984797685, 'Total loss': 0.4677805984797685}
2023-01-05 00:33:49,061 INFO:     Found new best model at epoch 5
2023-01-05 00:33:49,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:49,063 INFO:     Epoch: 6
2023-01-05 00:33:51,322 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4966847529013952, 'Total loss': 0.4966847529013952} | train loss {'Reaction outcome loss': 0.44717039229767513, 'Total loss': 0.44717039229767513}
2023-01-05 00:33:51,323 INFO:     Found new best model at epoch 6
2023-01-05 00:33:51,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:51,324 INFO:     Epoch: 7
2023-01-05 00:33:53,545 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.508112758398056, 'Total loss': 0.508112758398056} | train loss {'Reaction outcome loss': 0.42790005356352817, 'Total loss': 0.42790005356352817}
2023-01-05 00:33:53,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:53,546 INFO:     Epoch: 8
2023-01-05 00:33:55,712 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4739841938018799, 'Total loss': 0.4739841938018799} | train loss {'Reaction outcome loss': 0.4153388343427492, 'Total loss': 0.4153388343427492}
2023-01-05 00:33:55,712 INFO:     Found new best model at epoch 8
2023-01-05 00:33:55,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:55,713 INFO:     Epoch: 9
2023-01-05 00:33:57,882 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.487024775147438, 'Total loss': 0.487024775147438} | train loss {'Reaction outcome loss': 0.4132945791588745, 'Total loss': 0.4132945791588745}
2023-01-05 00:33:57,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:33:57,882 INFO:     Epoch: 10
2023-01-05 00:34:00,111 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46726272304852806, 'Total loss': 0.46726272304852806} | train loss {'Reaction outcome loss': 0.3991799341595691, 'Total loss': 0.3991799341595691}
2023-01-05 00:34:00,112 INFO:     Found new best model at epoch 10
2023-01-05 00:34:00,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:00,113 INFO:     Epoch: 11
2023-01-05 00:34:02,306 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44273592432339987, 'Total loss': 0.44273592432339987} | train loss {'Reaction outcome loss': 0.3895502125479929, 'Total loss': 0.3895502125479929}
2023-01-05 00:34:02,306 INFO:     Found new best model at epoch 11
2023-01-05 00:34:02,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:02,307 INFO:     Epoch: 12
2023-01-05 00:34:04,517 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46461028456687925, 'Total loss': 0.46461028456687925} | train loss {'Reaction outcome loss': 0.3725547439982251, 'Total loss': 0.3725547439982251}
2023-01-05 00:34:04,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:04,517 INFO:     Epoch: 13
2023-01-05 00:34:06,759 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4766937126715978, 'Total loss': 0.4766937126715978} | train loss {'Reaction outcome loss': 0.36244658603285695, 'Total loss': 0.36244658603285695}
2023-01-05 00:34:06,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:06,760 INFO:     Epoch: 14
2023-01-05 00:34:09,007 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44289606511592866, 'Total loss': 0.44289606511592866} | train loss {'Reaction outcome loss': 0.35409731923288706, 'Total loss': 0.35409731923288706}
2023-01-05 00:34:09,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:09,007 INFO:     Epoch: 15
2023-01-05 00:34:11,212 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4621603568394979, 'Total loss': 0.4621603568394979} | train loss {'Reaction outcome loss': 0.3470744890959316, 'Total loss': 0.3470744890959316}
2023-01-05 00:34:11,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:11,212 INFO:     Epoch: 16
2023-01-05 00:34:13,370 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4622604504227638, 'Total loss': 0.4622604504227638} | train loss {'Reaction outcome loss': 0.3447464581686949, 'Total loss': 0.3447464581686949}
2023-01-05 00:34:13,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:13,371 INFO:     Epoch: 17
2023-01-05 00:34:15,544 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4343923886617025, 'Total loss': 0.4343923886617025} | train loss {'Reaction outcome loss': 0.3428186875147124, 'Total loss': 0.3428186875147124}
2023-01-05 00:34:15,544 INFO:     Found new best model at epoch 17
2023-01-05 00:34:15,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:15,545 INFO:     Epoch: 18
2023-01-05 00:34:17,749 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4393838847676913, 'Total loss': 0.4393838847676913} | train loss {'Reaction outcome loss': 0.3425253487691499, 'Total loss': 0.3425253487691499}
2023-01-05 00:34:17,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:17,749 INFO:     Epoch: 19
2023-01-05 00:34:19,998 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.444022777179877, 'Total loss': 0.444022777179877} | train loss {'Reaction outcome loss': 0.33491498860857444, 'Total loss': 0.33491498860857444}
2023-01-05 00:34:19,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:19,999 INFO:     Epoch: 20
2023-01-05 00:34:22,244 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4334553947051366, 'Total loss': 0.4334553947051366} | train loss {'Reaction outcome loss': 0.31922698656663945, 'Total loss': 0.31922698656663945}
2023-01-05 00:34:22,244 INFO:     Found new best model at epoch 20
2023-01-05 00:34:22,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:22,246 INFO:     Epoch: 21
2023-01-05 00:34:24,457 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4279021441936493, 'Total loss': 0.4279021441936493} | train loss {'Reaction outcome loss': 0.31803305607046123, 'Total loss': 0.31803305607046123}
2023-01-05 00:34:24,457 INFO:     Found new best model at epoch 21
2023-01-05 00:34:24,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:24,459 INFO:     Epoch: 22
2023-01-05 00:34:26,658 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4492568184932073, 'Total loss': 0.4492568184932073} | train loss {'Reaction outcome loss': 0.3080334193680597, 'Total loss': 0.3080334193680597}
2023-01-05 00:34:26,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:26,658 INFO:     Epoch: 23
2023-01-05 00:34:28,906 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4380875458319982, 'Total loss': 0.4380875458319982} | train loss {'Reaction outcome loss': 0.3064968606517853, 'Total loss': 0.3064968606517853}
2023-01-05 00:34:28,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:28,906 INFO:     Epoch: 24
2023-01-05 00:34:31,081 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4325752476851145, 'Total loss': 0.4325752476851145} | train loss {'Reaction outcome loss': 0.3237458501227092, 'Total loss': 0.3237458501227092}
2023-01-05 00:34:31,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:31,082 INFO:     Epoch: 25
2023-01-05 00:34:33,223 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44943590263525646, 'Total loss': 0.44943590263525646} | train loss {'Reaction outcome loss': 0.2945029455965952, 'Total loss': 0.2945029455965952}
2023-01-05 00:34:33,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:33,223 INFO:     Epoch: 26
2023-01-05 00:34:35,427 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4405089219411214, 'Total loss': 0.4405089219411214} | train loss {'Reaction outcome loss': 0.29211206996030564, 'Total loss': 0.29211206996030564}
2023-01-05 00:34:35,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:35,428 INFO:     Epoch: 27
2023-01-05 00:34:37,689 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4232039829095205, 'Total loss': 0.4232039829095205} | train loss {'Reaction outcome loss': 0.28812700681737624, 'Total loss': 0.28812700681737624}
2023-01-05 00:34:37,689 INFO:     Found new best model at epoch 27
2023-01-05 00:34:37,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:37,690 INFO:     Epoch: 28
2023-01-05 00:34:39,843 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44448529680569965, 'Total loss': 0.44448529680569965} | train loss {'Reaction outcome loss': 0.2816935721375689, 'Total loss': 0.2816935721375689}
2023-01-05 00:34:39,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:39,843 INFO:     Epoch: 29
2023-01-05 00:34:42,053 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4131439169247945, 'Total loss': 0.4131439169247945} | train loss {'Reaction outcome loss': 0.27747781429686746, 'Total loss': 0.27747781429686746}
2023-01-05 00:34:42,054 INFO:     Found new best model at epoch 29
2023-01-05 00:34:42,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:42,056 INFO:     Epoch: 30
2023-01-05 00:34:44,283 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43562992016474406, 'Total loss': 0.43562992016474406} | train loss {'Reaction outcome loss': 0.272363694076531, 'Total loss': 0.272363694076531}
2023-01-05 00:34:44,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:44,284 INFO:     Epoch: 31
2023-01-05 00:34:46,545 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.426583531498909, 'Total loss': 0.426583531498909} | train loss {'Reaction outcome loss': 0.26787161536607973, 'Total loss': 0.26787161536607973}
2023-01-05 00:34:46,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:46,545 INFO:     Epoch: 32
2023-01-05 00:34:48,772 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4354888558387756, 'Total loss': 0.4354888558387756} | train loss {'Reaction outcome loss': 0.26421032094863156, 'Total loss': 0.26421032094863156}
2023-01-05 00:34:48,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:48,773 INFO:     Epoch: 33
2023-01-05 00:34:51,033 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40534702787796656, 'Total loss': 0.40534702787796656} | train loss {'Reaction outcome loss': 0.2564073431700387, 'Total loss': 0.2564073431700387}
2023-01-05 00:34:51,033 INFO:     Found new best model at epoch 33
2023-01-05 00:34:51,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:51,034 INFO:     Epoch: 34
2023-01-05 00:34:53,253 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4423697769641876, 'Total loss': 0.4423697769641876} | train loss {'Reaction outcome loss': 0.25996100204033806, 'Total loss': 0.25996100204033806}
2023-01-05 00:34:53,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:53,254 INFO:     Epoch: 35
2023-01-05 00:34:55,492 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4327239066362381, 'Total loss': 0.4327239066362381} | train loss {'Reaction outcome loss': 0.2514169439160943, 'Total loss': 0.2514169439160943}
2023-01-05 00:34:55,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:55,493 INFO:     Epoch: 36
2023-01-05 00:34:57,747 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41043886641661326, 'Total loss': 0.41043886641661326} | train loss {'Reaction outcome loss': 0.24946331190564536, 'Total loss': 0.24946331190564536}
2023-01-05 00:34:57,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:34:57,747 INFO:     Epoch: 37
2023-01-05 00:35:00,001 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3861610605070988, 'Total loss': 0.3861610605070988} | train loss {'Reaction outcome loss': 0.2479064950528192, 'Total loss': 0.2479064950528192}
2023-01-05 00:35:00,001 INFO:     Found new best model at epoch 37
2023-01-05 00:35:00,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:00,002 INFO:     Epoch: 38
2023-01-05 00:35:02,248 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45973723828792573, 'Total loss': 0.45973723828792573} | train loss {'Reaction outcome loss': 0.2421001854531494, 'Total loss': 0.2421001854531494}
2023-01-05 00:35:02,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:02,249 INFO:     Epoch: 39
2023-01-05 00:35:04,487 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43434056440989177, 'Total loss': 0.43434056440989177} | train loss {'Reaction outcome loss': 0.23618539865965696, 'Total loss': 0.23618539865965696}
2023-01-05 00:35:04,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:04,487 INFO:     Epoch: 40
2023-01-05 00:35:06,746 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44055208265781404, 'Total loss': 0.44055208265781404} | train loss {'Reaction outcome loss': 0.2383642906167644, 'Total loss': 0.2383642906167644}
2023-01-05 00:35:06,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:06,746 INFO:     Epoch: 41
2023-01-05 00:35:08,962 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4103063682715098, 'Total loss': 0.4103063682715098} | train loss {'Reaction outcome loss': 0.23139981981754923, 'Total loss': 0.23139981981754923}
2023-01-05 00:35:08,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:08,962 INFO:     Epoch: 42
2023-01-05 00:35:11,215 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4154657597343127, 'Total loss': 0.4154657597343127} | train loss {'Reaction outcome loss': 0.232219390071673, 'Total loss': 0.232219390071673}
2023-01-05 00:35:11,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:11,216 INFO:     Epoch: 43
2023-01-05 00:35:13,440 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43545718242724735, 'Total loss': 0.43545718242724735} | train loss {'Reaction outcome loss': 0.2269959603368804, 'Total loss': 0.2269959603368804}
2023-01-05 00:35:13,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:13,441 INFO:     Epoch: 44
2023-01-05 00:35:15,705 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42006929566462836, 'Total loss': 0.42006929566462836} | train loss {'Reaction outcome loss': 0.22690511196349794, 'Total loss': 0.22690511196349794}
2023-01-05 00:35:15,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:15,705 INFO:     Epoch: 45
2023-01-05 00:35:17,894 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43983884155750275, 'Total loss': 0.43983884155750275} | train loss {'Reaction outcome loss': 0.2235346611047609, 'Total loss': 0.2235346611047609}
2023-01-05 00:35:17,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:17,895 INFO:     Epoch: 46
2023-01-05 00:35:20,134 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40696830600500106, 'Total loss': 0.40696830600500106} | train loss {'Reaction outcome loss': 0.22172504949612895, 'Total loss': 0.22172504949612895}
2023-01-05 00:35:20,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:20,134 INFO:     Epoch: 47
2023-01-05 00:35:22,410 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4141792356967926, 'Total loss': 0.4141792356967926} | train loss {'Reaction outcome loss': 0.221723634509228, 'Total loss': 0.221723634509228}
2023-01-05 00:35:22,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:22,410 INFO:     Epoch: 48
2023-01-05 00:35:24,674 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4265243788560232, 'Total loss': 0.4265243788560232} | train loss {'Reaction outcome loss': 0.22080791650628467, 'Total loss': 0.22080791650628467}
2023-01-05 00:35:24,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:24,674 INFO:     Epoch: 49
2023-01-05 00:35:26,936 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4088598350683848, 'Total loss': 0.4088598350683848} | train loss {'Reaction outcome loss': 0.21654488791450538, 'Total loss': 0.21654488791450538}
2023-01-05 00:35:26,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:26,936 INFO:     Epoch: 50
2023-01-05 00:35:29,171 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4327501853307088, 'Total loss': 0.4327501853307088} | train loss {'Reaction outcome loss': 0.2131388683050898, 'Total loss': 0.2131388683050898}
2023-01-05 00:35:29,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:29,172 INFO:     Epoch: 51
2023-01-05 00:35:31,410 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4521979103485743, 'Total loss': 0.4521979103485743} | train loss {'Reaction outcome loss': 0.20918438718081234, 'Total loss': 0.20918438718081234}
2023-01-05 00:35:31,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:31,411 INFO:     Epoch: 52
2023-01-05 00:35:33,647 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4609567483266195, 'Total loss': 0.4609567483266195} | train loss {'Reaction outcome loss': 0.21254451626800405, 'Total loss': 0.21254451626800405}
2023-01-05 00:35:33,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:33,647 INFO:     Epoch: 53
2023-01-05 00:35:35,905 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4425210396448771, 'Total loss': 0.4425210396448771} | train loss {'Reaction outcome loss': 0.20522382929482483, 'Total loss': 0.20522382929482483}
2023-01-05 00:35:35,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:35,906 INFO:     Epoch: 54
2023-01-05 00:35:38,166 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46710907022158304, 'Total loss': 0.46710907022158304} | train loss {'Reaction outcome loss': 0.21230720874766543, 'Total loss': 0.21230720874766543}
2023-01-05 00:35:38,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:38,166 INFO:     Epoch: 55
2023-01-05 00:35:40,395 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45440347691377003, 'Total loss': 0.45440347691377003} | train loss {'Reaction outcome loss': 0.2030341211253287, 'Total loss': 0.2030341211253287}
2023-01-05 00:35:40,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:40,396 INFO:     Epoch: 56
2023-01-05 00:35:42,643 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4106786554058393, 'Total loss': 0.4106786554058393} | train loss {'Reaction outcome loss': 0.20365231085114816, 'Total loss': 0.20365231085114816}
2023-01-05 00:35:42,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:42,643 INFO:     Epoch: 57
2023-01-05 00:35:44,908 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4519611209630966, 'Total loss': 0.4519611209630966} | train loss {'Reaction outcome loss': 0.2045426534411187, 'Total loss': 0.2045426534411187}
2023-01-05 00:35:44,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:44,908 INFO:     Epoch: 58
2023-01-05 00:35:47,170 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43503396908442177, 'Total loss': 0.43503396908442177} | train loss {'Reaction outcome loss': 0.20139896146542594, 'Total loss': 0.20139896146542594}
2023-01-05 00:35:47,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:47,171 INFO:     Epoch: 59
2023-01-05 00:35:49,434 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47396225730578107, 'Total loss': 0.47396225730578107} | train loss {'Reaction outcome loss': 0.20307846978117805, 'Total loss': 0.20307846978117805}
2023-01-05 00:35:49,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:49,434 INFO:     Epoch: 60
2023-01-05 00:35:51,695 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4680145223935445, 'Total loss': 0.4680145223935445} | train loss {'Reaction outcome loss': 0.1998234729019358, 'Total loss': 0.1998234729019358}
2023-01-05 00:35:51,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:51,695 INFO:     Epoch: 61
2023-01-05 00:35:53,917 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4600918193658193, 'Total loss': 0.4600918193658193} | train loss {'Reaction outcome loss': 0.19972971022007582, 'Total loss': 0.19972971022007582}
2023-01-05 00:35:53,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:53,918 INFO:     Epoch: 62
2023-01-05 00:35:56,153 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44964369932810466, 'Total loss': 0.44964369932810466} | train loss {'Reaction outcome loss': 0.19545617132145207, 'Total loss': 0.19545617132145207}
2023-01-05 00:35:56,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:56,153 INFO:     Epoch: 63
2023-01-05 00:35:58,412 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4273413235321641, 'Total loss': 0.4273413235321641} | train loss {'Reaction outcome loss': 0.1896395297565808, 'Total loss': 0.1896395297565808}
2023-01-05 00:35:58,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:35:58,413 INFO:     Epoch: 64
2023-01-05 00:36:00,657 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4371896028518677, 'Total loss': 0.4371896028518677} | train loss {'Reaction outcome loss': 0.19471360506334653, 'Total loss': 0.19471360506334653}
2023-01-05 00:36:00,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:00,658 INFO:     Epoch: 65
2023-01-05 00:36:02,914 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4129515469074249, 'Total loss': 0.4129515469074249} | train loss {'Reaction outcome loss': 0.19702791706557668, 'Total loss': 0.19702791706557668}
2023-01-05 00:36:02,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:02,914 INFO:     Epoch: 66
2023-01-05 00:36:05,133 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4564393589893977, 'Total loss': 0.4564393589893977} | train loss {'Reaction outcome loss': 0.18744556404193435, 'Total loss': 0.18744556404193435}
2023-01-05 00:36:05,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:05,134 INFO:     Epoch: 67
2023-01-05 00:36:07,384 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45341387391090393, 'Total loss': 0.45341387391090393} | train loss {'Reaction outcome loss': 0.19455088624280228, 'Total loss': 0.19455088624280228}
2023-01-05 00:36:07,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:07,385 INFO:     Epoch: 68
2023-01-05 00:36:09,646 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43440468808015187, 'Total loss': 0.43440468808015187} | train loss {'Reaction outcome loss': 0.18627806990981047, 'Total loss': 0.18627806990981047}
2023-01-05 00:36:09,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:09,646 INFO:     Epoch: 69
2023-01-05 00:36:11,800 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4322403242190679, 'Total loss': 0.4322403242190679} | train loss {'Reaction outcome loss': 0.18942134575100036, 'Total loss': 0.18942134575100036}
2023-01-05 00:36:11,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:11,801 INFO:     Epoch: 70
2023-01-05 00:36:14,015 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4672041853268941, 'Total loss': 0.4672041853268941} | train loss {'Reaction outcome loss': 0.18797720589340106, 'Total loss': 0.18797720589340106}
2023-01-05 00:36:14,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:14,016 INFO:     Epoch: 71
2023-01-05 00:36:16,198 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48411282102266945, 'Total loss': 0.48411282102266945} | train loss {'Reaction outcome loss': 0.18230406228363077, 'Total loss': 0.18230406228363077}
2023-01-05 00:36:16,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:16,199 INFO:     Epoch: 72
2023-01-05 00:36:18,439 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45530904134114586, 'Total loss': 0.45530904134114586} | train loss {'Reaction outcome loss': 0.18097021560822832, 'Total loss': 0.18097021560822832}
2023-01-05 00:36:18,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:18,439 INFO:     Epoch: 73
2023-01-05 00:36:20,665 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4493726948897044, 'Total loss': 0.4493726948897044} | train loss {'Reaction outcome loss': 0.18692260062682076, 'Total loss': 0.18692260062682076}
2023-01-05 00:36:20,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:20,665 INFO:     Epoch: 74
2023-01-05 00:36:22,908 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4570854524771372, 'Total loss': 0.4570854524771372} | train loss {'Reaction outcome loss': 0.1819218460776661, 'Total loss': 0.1819218460776661}
2023-01-05 00:36:22,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:22,910 INFO:     Epoch: 75
2023-01-05 00:36:25,182 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45239840149879457, 'Total loss': 0.45239840149879457} | train loss {'Reaction outcome loss': 0.1819269778325047, 'Total loss': 0.1819269778325047}
2023-01-05 00:36:25,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:25,182 INFO:     Epoch: 76
2023-01-05 00:36:27,434 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4494921127955119, 'Total loss': 0.4494921127955119} | train loss {'Reaction outcome loss': 0.1817253853331077, 'Total loss': 0.1817253853331077}
2023-01-05 00:36:27,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:27,434 INFO:     Epoch: 77
2023-01-05 00:36:29,666 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44150881518920265, 'Total loss': 0.44150881518920265} | train loss {'Reaction outcome loss': 0.18510999205603224, 'Total loss': 0.18510999205603224}
2023-01-05 00:36:29,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:29,667 INFO:     Epoch: 78
2023-01-05 00:36:31,877 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4623830447594325, 'Total loss': 0.4623830447594325} | train loss {'Reaction outcome loss': 0.1795221524411634, 'Total loss': 0.1795221524411634}
2023-01-05 00:36:31,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:31,878 INFO:     Epoch: 79
2023-01-05 00:36:34,086 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4785419841607412, 'Total loss': 0.4785419841607412} | train loss {'Reaction outcome loss': 0.184694550782982, 'Total loss': 0.184694550782982}
2023-01-05 00:36:34,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:34,086 INFO:     Epoch: 80
2023-01-05 00:36:36,324 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4575592746337255, 'Total loss': 0.4575592746337255} | train loss {'Reaction outcome loss': 0.1773304010866264, 'Total loss': 0.1773304010866264}
2023-01-05 00:36:36,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:36,324 INFO:     Epoch: 81
2023-01-05 00:36:38,554 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4223574436424921, 'Total loss': 0.4223574436424921} | train loss {'Reaction outcome loss': 0.1783694031857548, 'Total loss': 0.1783694031857548}
2023-01-05 00:36:38,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:38,555 INFO:     Epoch: 82
2023-01-05 00:36:40,774 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4527642031510671, 'Total loss': 0.4527642031510671} | train loss {'Reaction outcome loss': 0.17644120372437022, 'Total loss': 0.17644120372437022}
2023-01-05 00:36:40,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:40,774 INFO:     Epoch: 83
2023-01-05 00:36:43,038 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4468601872523626, 'Total loss': 0.4468601872523626} | train loss {'Reaction outcome loss': 0.17737854233828199, 'Total loss': 0.17737854233828199}
2023-01-05 00:36:43,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:43,039 INFO:     Epoch: 84
2023-01-05 00:36:45,244 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43012244602044425, 'Total loss': 0.43012244602044425} | train loss {'Reaction outcome loss': 0.1775694124204903, 'Total loss': 0.1775694124204903}
2023-01-05 00:36:45,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:45,244 INFO:     Epoch: 85
2023-01-05 00:36:47,450 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4390050361553828, 'Total loss': 0.4390050361553828} | train loss {'Reaction outcome loss': 0.1748453231099858, 'Total loss': 0.1748453231099858}
2023-01-05 00:36:47,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:47,451 INFO:     Epoch: 86
2023-01-05 00:36:49,640 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44724928041299183, 'Total loss': 0.44724928041299183} | train loss {'Reaction outcome loss': 0.1745729330437641, 'Total loss': 0.1745729330437641}
2023-01-05 00:36:49,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:49,640 INFO:     Epoch: 87
2023-01-05 00:36:51,810 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4467697265247504, 'Total loss': 0.4467697265247504} | train loss {'Reaction outcome loss': 0.17415861733650304, 'Total loss': 0.17415861733650304}
2023-01-05 00:36:51,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:51,810 INFO:     Epoch: 88
2023-01-05 00:36:54,051 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4641664832830429, 'Total loss': 0.4641664832830429} | train loss {'Reaction outcome loss': 0.17666747414193157, 'Total loss': 0.17666747414193157}
2023-01-05 00:36:54,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:54,051 INFO:     Epoch: 89
2023-01-05 00:36:56,294 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45769588351249696, 'Total loss': 0.45769588351249696} | train loss {'Reaction outcome loss': 0.17120069883315844, 'Total loss': 0.17120069883315844}
2023-01-05 00:36:56,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:56,294 INFO:     Epoch: 90
2023-01-05 00:36:58,445 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4082252616683642, 'Total loss': 0.4082252616683642} | train loss {'Reaction outcome loss': 0.1691203413987976, 'Total loss': 0.1691203413987976}
2023-01-05 00:36:58,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:36:58,445 INFO:     Epoch: 91
2023-01-05 00:37:00,688 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43762626896301904, 'Total loss': 0.43762626896301904} | train loss {'Reaction outcome loss': 0.1722733674437486, 'Total loss': 0.1722733674437486}
2023-01-05 00:37:00,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:00,690 INFO:     Epoch: 92
2023-01-05 00:37:02,908 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44253595154732467, 'Total loss': 0.44253595154732467} | train loss {'Reaction outcome loss': 0.16954327904639524, 'Total loss': 0.16954327904639524}
2023-01-05 00:37:02,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:02,908 INFO:     Epoch: 93
2023-01-05 00:37:05,149 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4389049430688222, 'Total loss': 0.4389049430688222} | train loss {'Reaction outcome loss': 0.17072649189419503, 'Total loss': 0.17072649189419503}
2023-01-05 00:37:05,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:05,149 INFO:     Epoch: 94
2023-01-05 00:37:07,417 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44835676103830335, 'Total loss': 0.44835676103830335} | train loss {'Reaction outcome loss': 0.1751177862419011, 'Total loss': 0.1751177862419011}
2023-01-05 00:37:07,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:07,418 INFO:     Epoch: 95
2023-01-05 00:37:09,672 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4625465403000514, 'Total loss': 0.4625465403000514} | train loss {'Reaction outcome loss': 0.16609305014287162, 'Total loss': 0.16609305014287162}
2023-01-05 00:37:09,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:09,672 INFO:     Epoch: 96
2023-01-05 00:37:11,940 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4520120804508527, 'Total loss': 0.4520120804508527} | train loss {'Reaction outcome loss': 0.16593108600841663, 'Total loss': 0.16593108600841663}
2023-01-05 00:37:11,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:11,941 INFO:     Epoch: 97
2023-01-05 00:37:14,173 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4583487621198098, 'Total loss': 0.4583487621198098} | train loss {'Reaction outcome loss': 0.17658005415569936, 'Total loss': 0.17658005415569936}
2023-01-05 00:37:14,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:14,173 INFO:     Epoch: 98
2023-01-05 00:37:16,381 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4330820977687836, 'Total loss': 0.4330820977687836} | train loss {'Reaction outcome loss': 0.1814889485080578, 'Total loss': 0.1814889485080578}
2023-01-05 00:37:16,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:16,382 INFO:     Epoch: 99
2023-01-05 00:37:18,615 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5002414911985398, 'Total loss': 0.5002414911985398} | train loss {'Reaction outcome loss': 0.17389556411670629, 'Total loss': 0.17389556411670629}
2023-01-05 00:37:18,615 INFO:     Best model found after epoch 38 of 100.
2023-01-05 00:37:18,616 INFO:   Done with stage: TRAINING
2023-01-05 00:37:18,616 INFO:   Starting stage: EVALUATION
2023-01-05 00:37:18,750 INFO:   Done with stage: EVALUATION
2023-01-05 00:37:18,751 INFO:   Leaving out SEQ value Fold_6
2023-01-05 00:37:18,763 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 00:37:18,763 INFO:   Starting stage: FEATURE SCALING
2023-01-05 00:37:19,409 INFO:   Done with stage: FEATURE SCALING
2023-01-05 00:37:19,409 INFO:   Starting stage: SCALING TARGETS
2023-01-05 00:37:19,481 INFO:   Done with stage: SCALING TARGETS
2023-01-05 00:37:19,482 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:37:19,482 INFO:     No hyperparam tuning for this model
2023-01-05 00:37:19,482 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:37:19,482 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 00:37:19,483 INFO:     None feature selector for col prot
2023-01-05 00:37:19,483 INFO:     None feature selector for col prot
2023-01-05 00:37:19,483 INFO:     None feature selector for col prot
2023-01-05 00:37:19,484 INFO:     None feature selector for col chem
2023-01-05 00:37:19,484 INFO:     None feature selector for col chem
2023-01-05 00:37:19,484 INFO:     None feature selector for col chem
2023-01-05 00:37:19,484 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 00:37:19,484 INFO:   Starting stage: BUILD MODEL
2023-01-05 00:37:19,485 INFO:     Number of params in model 72931
2023-01-05 00:37:19,489 INFO:   Done with stage: BUILD MODEL
2023-01-05 00:37:19,489 INFO:   Starting stage: TRAINING
2023-01-05 00:37:19,548 INFO:     Val loss before train {'Reaction outcome loss': 1.01338818470637, 'Total loss': 1.01338818470637}
2023-01-05 00:37:19,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:19,548 INFO:     Epoch: 0
2023-01-05 00:37:21,738 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7768211007118225, 'Total loss': 0.7768211007118225} | train loss {'Reaction outcome loss': 0.9444172672279503, 'Total loss': 0.9444172672279503}
2023-01-05 00:37:21,738 INFO:     Found new best model at epoch 0
2023-01-05 00:37:21,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:21,739 INFO:     Epoch: 1
2023-01-05 00:37:24,002 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5624767820040385, 'Total loss': 0.5624767820040385} | train loss {'Reaction outcome loss': 0.6479961504430874, 'Total loss': 0.6479961504430874}
2023-01-05 00:37:24,002 INFO:     Found new best model at epoch 1
2023-01-05 00:37:24,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:24,004 INFO:     Epoch: 2
2023-01-05 00:37:26,236 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5119120240211487, 'Total loss': 0.5119120240211487} | train loss {'Reaction outcome loss': 0.5481706092132431, 'Total loss': 0.5481706092132431}
2023-01-05 00:37:26,236 INFO:     Found new best model at epoch 2
2023-01-05 00:37:26,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:26,237 INFO:     Epoch: 3
2023-01-05 00:37:28,461 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4875899295012156, 'Total loss': 0.4875899295012156} | train loss {'Reaction outcome loss': 0.5078140062725415, 'Total loss': 0.5078140062725415}
2023-01-05 00:37:28,461 INFO:     Found new best model at epoch 3
2023-01-05 00:37:28,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:28,463 INFO:     Epoch: 4
2023-01-05 00:37:30,612 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4681514223416646, 'Total loss': 0.4681514223416646} | train loss {'Reaction outcome loss': 0.47780625743399613, 'Total loss': 0.47780625743399613}
2023-01-05 00:37:30,612 INFO:     Found new best model at epoch 4
2023-01-05 00:37:30,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:30,614 INFO:     Epoch: 5
2023-01-05 00:37:32,713 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4356093605359395, 'Total loss': 0.4356093605359395} | train loss {'Reaction outcome loss': 0.4500977340478288, 'Total loss': 0.4500977340478288}
2023-01-05 00:37:32,713 INFO:     Found new best model at epoch 5
2023-01-05 00:37:32,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:32,714 INFO:     Epoch: 6
2023-01-05 00:37:34,944 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.439023756980896, 'Total loss': 0.439023756980896} | train loss {'Reaction outcome loss': 0.43098385680291423, 'Total loss': 0.43098385680291423}
2023-01-05 00:37:34,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:34,945 INFO:     Epoch: 7
2023-01-05 00:37:37,170 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40790215333302815, 'Total loss': 0.40790215333302815} | train loss {'Reaction outcome loss': 0.41511495373603224, 'Total loss': 0.41511495373603224}
2023-01-05 00:37:37,171 INFO:     Found new best model at epoch 7
2023-01-05 00:37:37,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:37,172 INFO:     Epoch: 8
2023-01-05 00:37:39,405 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4157967527707418, 'Total loss': 0.4157967527707418} | train loss {'Reaction outcome loss': 0.41242220360731735, 'Total loss': 0.41242220360731735}
2023-01-05 00:37:39,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:39,405 INFO:     Epoch: 9
2023-01-05 00:37:41,628 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3892609804868698, 'Total loss': 0.3892609804868698} | train loss {'Reaction outcome loss': 0.3981273404552021, 'Total loss': 0.3981273404552021}
2023-01-05 00:37:41,629 INFO:     Found new best model at epoch 9
2023-01-05 00:37:41,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:41,630 INFO:     Epoch: 10
2023-01-05 00:37:43,875 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4083983838558197, 'Total loss': 0.4083983838558197} | train loss {'Reaction outcome loss': 0.38048940484346216, 'Total loss': 0.38048940484346216}
2023-01-05 00:37:43,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:43,875 INFO:     Epoch: 11
2023-01-05 00:37:46,088 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4051829387744268, 'Total loss': 0.4051829387744268} | train loss {'Reaction outcome loss': 0.3702430273912361, 'Total loss': 0.3702430273912361}
2023-01-05 00:37:46,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:46,088 INFO:     Epoch: 12
2023-01-05 00:37:48,318 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39857311646143595, 'Total loss': 0.39857311646143595} | train loss {'Reaction outcome loss': 0.3609685901134018, 'Total loss': 0.3609685901134018}
2023-01-05 00:37:48,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:48,319 INFO:     Epoch: 13
2023-01-05 00:37:50,580 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3932199875513713, 'Total loss': 0.3932199875513713} | train loss {'Reaction outcome loss': 0.35472087767856136, 'Total loss': 0.35472087767856136}
2023-01-05 00:37:50,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:50,580 INFO:     Epoch: 14
2023-01-05 00:37:52,837 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4069859117269516, 'Total loss': 0.4069859117269516} | train loss {'Reaction outcome loss': 0.345978937707369, 'Total loss': 0.345978937707369}
2023-01-05 00:37:52,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:52,838 INFO:     Epoch: 15
2023-01-05 00:37:55,065 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3775392251710097, 'Total loss': 0.3775392251710097} | train loss {'Reaction outcome loss': 0.3406405384410892, 'Total loss': 0.3406405384410892}
2023-01-05 00:37:55,065 INFO:     Found new best model at epoch 15
2023-01-05 00:37:55,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:55,067 INFO:     Epoch: 16
2023-01-05 00:37:57,325 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3767531494299571, 'Total loss': 0.3767531494299571} | train loss {'Reaction outcome loss': 0.33187845393510634, 'Total loss': 0.33187845393510634}
2023-01-05 00:37:57,325 INFO:     Found new best model at epoch 16
2023-01-05 00:37:57,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:57,326 INFO:     Epoch: 17
2023-01-05 00:37:59,516 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3765574405590693, 'Total loss': 0.3765574405590693} | train loss {'Reaction outcome loss': 0.3277961089882318, 'Total loss': 0.3277961089882318}
2023-01-05 00:37:59,516 INFO:     Found new best model at epoch 17
2023-01-05 00:37:59,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:37:59,517 INFO:     Epoch: 18
2023-01-05 00:38:01,743 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3716717074314753, 'Total loss': 0.3716717074314753} | train loss {'Reaction outcome loss': 0.32239300899032125, 'Total loss': 0.32239300899032125}
2023-01-05 00:38:01,743 INFO:     Found new best model at epoch 18
2023-01-05 00:38:01,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:01,745 INFO:     Epoch: 19
2023-01-05 00:38:03,957 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3766534219185511, 'Total loss': 0.3766534219185511} | train loss {'Reaction outcome loss': 0.3192986341571246, 'Total loss': 0.3192986341571246}
2023-01-05 00:38:03,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:03,958 INFO:     Epoch: 20
2023-01-05 00:38:06,179 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.37997046709060667, 'Total loss': 0.37997046709060667} | train loss {'Reaction outcome loss': 0.31391396945801336, 'Total loss': 0.31391396945801336}
2023-01-05 00:38:06,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:06,179 INFO:     Epoch: 21
2023-01-05 00:38:08,432 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3784862130880356, 'Total loss': 0.3784862130880356} | train loss {'Reaction outcome loss': 0.3098370937540481, 'Total loss': 0.3098370937540481}
2023-01-05 00:38:08,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:08,432 INFO:     Epoch: 22
2023-01-05 00:38:10,635 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3633264640967051, 'Total loss': 0.3633264640967051} | train loss {'Reaction outcome loss': 0.30154255161439814, 'Total loss': 0.30154255161439814}
2023-01-05 00:38:10,637 INFO:     Found new best model at epoch 22
2023-01-05 00:38:10,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:10,638 INFO:     Epoch: 23
2023-01-05 00:38:12,864 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.37198241154352824, 'Total loss': 0.37198241154352824} | train loss {'Reaction outcome loss': 0.29887488911744964, 'Total loss': 0.29887488911744964}
2023-01-05 00:38:12,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:12,864 INFO:     Epoch: 24
2023-01-05 00:38:15,117 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3784658124049505, 'Total loss': 0.3784658124049505} | train loss {'Reaction outcome loss': 0.2956023567180703, 'Total loss': 0.2956023567180703}
2023-01-05 00:38:15,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:15,118 INFO:     Epoch: 25
2023-01-05 00:38:17,368 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3596865991751353, 'Total loss': 0.3596865991751353} | train loss {'Reaction outcome loss': 0.2898972932145124, 'Total loss': 0.2898972932145124}
2023-01-05 00:38:17,368 INFO:     Found new best model at epoch 25
2023-01-05 00:38:17,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:17,370 INFO:     Epoch: 26
2023-01-05 00:38:19,632 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3751372903585434, 'Total loss': 0.3751372903585434} | train loss {'Reaction outcome loss': 0.28401115360210877, 'Total loss': 0.28401115360210877}
2023-01-05 00:38:19,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:19,632 INFO:     Epoch: 27
2023-01-05 00:38:21,874 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3836967796087265, 'Total loss': 0.3836967796087265} | train loss {'Reaction outcome loss': 0.2760024864025805, 'Total loss': 0.2760024864025805}
2023-01-05 00:38:21,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:21,875 INFO:     Epoch: 28
2023-01-05 00:38:24,093 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3719209561745326, 'Total loss': 0.3719209561745326} | train loss {'Reaction outcome loss': 0.27440376515480003, 'Total loss': 0.27440376515480003}
2023-01-05 00:38:24,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:24,093 INFO:     Epoch: 29
2023-01-05 00:38:26,301 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.358426333963871, 'Total loss': 0.358426333963871} | train loss {'Reaction outcome loss': 0.2745893240258422, 'Total loss': 0.2745893240258422}
2023-01-05 00:38:26,301 INFO:     Found new best model at epoch 29
2023-01-05 00:38:26,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:26,303 INFO:     Epoch: 30
2023-01-05 00:38:28,529 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3926566968361537, 'Total loss': 0.3926566968361537} | train loss {'Reaction outcome loss': 0.26583009718687856, 'Total loss': 0.26583009718687856}
2023-01-05 00:38:28,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:28,529 INFO:     Epoch: 31
2023-01-05 00:38:30,804 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3479078362385432, 'Total loss': 0.3479078362385432} | train loss {'Reaction outcome loss': 0.26931458024204324, 'Total loss': 0.26931458024204324}
2023-01-05 00:38:30,804 INFO:     Found new best model at epoch 31
2023-01-05 00:38:30,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:30,806 INFO:     Epoch: 32
2023-01-05 00:38:33,080 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.35740611602862676, 'Total loss': 0.35740611602862676} | train loss {'Reaction outcome loss': 0.25820410796913545, 'Total loss': 0.25820410796913545}
2023-01-05 00:38:33,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:33,081 INFO:     Epoch: 33
2023-01-05 00:38:35,351 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.36040702760219573, 'Total loss': 0.36040702760219573} | train loss {'Reaction outcome loss': 0.2592944358710657, 'Total loss': 0.2592944358710657}
2023-01-05 00:38:35,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:35,351 INFO:     Epoch: 34
2023-01-05 00:38:37,608 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.36850594182809193, 'Total loss': 0.36850594182809193} | train loss {'Reaction outcome loss': 0.25181906348587, 'Total loss': 0.25181906348587}
2023-01-05 00:38:37,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:37,608 INFO:     Epoch: 35
2023-01-05 00:38:39,804 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.35960205594698585, 'Total loss': 0.35960205594698585} | train loss {'Reaction outcome loss': 0.2510913139444513, 'Total loss': 0.2510913139444513}
2023-01-05 00:38:39,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:39,804 INFO:     Epoch: 36
2023-01-05 00:38:42,074 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3693997581799825, 'Total loss': 0.3693997581799825} | train loss {'Reaction outcome loss': 0.25382582556483324, 'Total loss': 0.25382582556483324}
2023-01-05 00:38:42,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:42,074 INFO:     Epoch: 37
2023-01-05 00:38:44,342 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.35094764828681946, 'Total loss': 0.35094764828681946} | train loss {'Reaction outcome loss': 0.2522106633995714, 'Total loss': 0.2522106633995714}
2023-01-05 00:38:44,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:44,343 INFO:     Epoch: 38
2023-01-05 00:38:46,590 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.36221489955981573, 'Total loss': 0.36221489955981573} | train loss {'Reaction outcome loss': 0.23397725089402546, 'Total loss': 0.23397725089402546}
2023-01-05 00:38:46,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:46,592 INFO:     Epoch: 39
2023-01-05 00:38:48,813 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3516397401690483, 'Total loss': 0.3516397401690483} | train loss {'Reaction outcome loss': 0.24061352926503826, 'Total loss': 0.24061352926503826}
2023-01-05 00:38:48,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:48,814 INFO:     Epoch: 40
2023-01-05 00:38:51,044 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3704390227794647, 'Total loss': 0.3704390227794647} | train loss {'Reaction outcome loss': 0.23525281581501273, 'Total loss': 0.23525281581501273}
2023-01-05 00:38:51,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:51,044 INFO:     Epoch: 41
2023-01-05 00:38:53,281 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3815047889947891, 'Total loss': 0.3815047889947891} | train loss {'Reaction outcome loss': 0.23061955079901963, 'Total loss': 0.23061955079901963}
2023-01-05 00:38:53,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:53,282 INFO:     Epoch: 42
2023-01-05 00:38:55,514 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3675845672686895, 'Total loss': 0.3675845672686895} | train loss {'Reaction outcome loss': 0.23090267392420344, 'Total loss': 0.23090267392420344}
2023-01-05 00:38:55,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:55,515 INFO:     Epoch: 43
2023-01-05 00:38:57,755 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.37692886739969256, 'Total loss': 0.37692886739969256} | train loss {'Reaction outcome loss': 0.2284979302767433, 'Total loss': 0.2284979302767433}
2023-01-05 00:38:57,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:57,755 INFO:     Epoch: 44
2023-01-05 00:38:59,972 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.36577064196268716, 'Total loss': 0.36577064196268716} | train loss {'Reaction outcome loss': 0.22697915426496088, 'Total loss': 0.22697915426496088}
2023-01-05 00:38:59,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:38:59,972 INFO:     Epoch: 45
2023-01-05 00:39:02,136 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38052939424912136, 'Total loss': 0.38052939424912136} | train loss {'Reaction outcome loss': 0.22523394738336258, 'Total loss': 0.22523394738336258}
2023-01-05 00:39:02,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:02,136 INFO:     Epoch: 46
2023-01-05 00:39:04,383 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3643611058592796, 'Total loss': 0.3643611058592796} | train loss {'Reaction outcome loss': 0.22526676358277167, 'Total loss': 0.22526676358277167}
2023-01-05 00:39:04,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:04,383 INFO:     Epoch: 47
2023-01-05 00:39:06,625 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38681098620096843, 'Total loss': 0.38681098620096843} | train loss {'Reaction outcome loss': 0.21816250388389127, 'Total loss': 0.21816250388389127}
2023-01-05 00:39:06,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:06,626 INFO:     Epoch: 48
2023-01-05 00:39:08,881 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3697545876105626, 'Total loss': 0.3697545876105626} | train loss {'Reaction outcome loss': 0.21736764560960084, 'Total loss': 0.21736764560960084}
2023-01-05 00:39:08,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:08,882 INFO:     Epoch: 49
2023-01-05 00:39:11,101 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.409782146414121, 'Total loss': 0.409782146414121} | train loss {'Reaction outcome loss': 0.21170500985159457, 'Total loss': 0.21170500985159457}
2023-01-05 00:39:11,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:11,101 INFO:     Epoch: 50
2023-01-05 00:39:13,333 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3812421813607216, 'Total loss': 0.3812421813607216} | train loss {'Reaction outcome loss': 0.2099646977045874, 'Total loss': 0.2099646977045874}
2023-01-05 00:39:13,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:13,333 INFO:     Epoch: 51
2023-01-05 00:39:15,485 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.38362742960453033, 'Total loss': 0.38362742960453033} | train loss {'Reaction outcome loss': 0.21462861026225585, 'Total loss': 0.21462861026225585}
2023-01-05 00:39:15,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:15,485 INFO:     Epoch: 52
2023-01-05 00:39:17,705 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3821647971868515, 'Total loss': 0.3821647971868515} | train loss {'Reaction outcome loss': 0.21097999404706122, 'Total loss': 0.21097999404706122}
2023-01-05 00:39:17,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:17,705 INFO:     Epoch: 53
2023-01-05 00:39:19,941 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3780848443508148, 'Total loss': 0.3780848443508148} | train loss {'Reaction outcome loss': 0.20238058777370801, 'Total loss': 0.20238058777370801}
2023-01-05 00:39:19,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:19,941 INFO:     Epoch: 54
2023-01-05 00:39:22,178 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3932435840368271, 'Total loss': 0.3932435840368271} | train loss {'Reaction outcome loss': 0.20934525195532816, 'Total loss': 0.20934525195532816}
2023-01-05 00:39:22,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:22,180 INFO:     Epoch: 55
2023-01-05 00:39:24,408 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39424968957901, 'Total loss': 0.39424968957901} | train loss {'Reaction outcome loss': 0.2060643048464334, 'Total loss': 0.2060643048464334}
2023-01-05 00:39:24,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:24,408 INFO:     Epoch: 56
2023-01-05 00:39:26,673 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.395409128566583, 'Total loss': 0.395409128566583} | train loss {'Reaction outcome loss': 0.19776862695900913, 'Total loss': 0.19776862695900913}
2023-01-05 00:39:26,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:26,674 INFO:     Epoch: 57
2023-01-05 00:39:28,885 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3716966261466344, 'Total loss': 0.3716966261466344} | train loss {'Reaction outcome loss': 0.20050485856051597, 'Total loss': 0.20050485856051597}
2023-01-05 00:39:28,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:28,886 INFO:     Epoch: 58
2023-01-05 00:39:31,142 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3799602727095286, 'Total loss': 0.3799602727095286} | train loss {'Reaction outcome loss': 0.19659767068166098, 'Total loss': 0.19659767068166098}
2023-01-05 00:39:31,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:31,143 INFO:     Epoch: 59
2023-01-05 00:39:33,397 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.34007503812511763, 'Total loss': 0.34007503812511763} | train loss {'Reaction outcome loss': 0.20330203408240408, 'Total loss': 0.20330203408240408}
2023-01-05 00:39:33,397 INFO:     Found new best model at epoch 59
2023-01-05 00:39:33,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:33,399 INFO:     Epoch: 60
2023-01-05 00:39:35,629 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.35962220579385756, 'Total loss': 0.35962220579385756} | train loss {'Reaction outcome loss': 0.2001668931133927, 'Total loss': 0.2001668931133927}
2023-01-05 00:39:35,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:35,629 INFO:     Epoch: 61
2023-01-05 00:39:37,884 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41965472300847373, 'Total loss': 0.41965472300847373} | train loss {'Reaction outcome loss': 0.19573311503652646, 'Total loss': 0.19573311503652646}
2023-01-05 00:39:37,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:37,884 INFO:     Epoch: 62
2023-01-05 00:39:40,131 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3925062427918116, 'Total loss': 0.3925062427918116} | train loss {'Reaction outcome loss': 0.19694508625379176, 'Total loss': 0.19694508625379176}
2023-01-05 00:39:40,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:40,132 INFO:     Epoch: 63
2023-01-05 00:39:42,393 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3977463185787201, 'Total loss': 0.3977463185787201} | train loss {'Reaction outcome loss': 0.1899241890755745, 'Total loss': 0.1899241890755745}
2023-01-05 00:39:42,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:42,394 INFO:     Epoch: 64
2023-01-05 00:39:44,617 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3772221972544988, 'Total loss': 0.3772221972544988} | train loss {'Reaction outcome loss': 0.1934881031207835, 'Total loss': 0.1934881031207835}
2023-01-05 00:39:44,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:44,618 INFO:     Epoch: 65
2023-01-05 00:39:46,836 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.382809741050005, 'Total loss': 0.382809741050005} | train loss {'Reaction outcome loss': 0.18658019345657786, 'Total loss': 0.18658019345657786}
2023-01-05 00:39:46,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:46,837 INFO:     Epoch: 66
2023-01-05 00:39:49,051 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.38070411582787833, 'Total loss': 0.38070411582787833} | train loss {'Reaction outcome loss': 0.1888094633696196, 'Total loss': 0.1888094633696196}
2023-01-05 00:39:49,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:49,051 INFO:     Epoch: 67
2023-01-05 00:39:51,317 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3783631145954132, 'Total loss': 0.3783631145954132} | train loss {'Reaction outcome loss': 0.18880678579955493, 'Total loss': 0.18880678579955493}
2023-01-05 00:39:51,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:51,318 INFO:     Epoch: 68
2023-01-05 00:39:53,590 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3728687822818756, 'Total loss': 0.3728687822818756} | train loss {'Reaction outcome loss': 0.18602937106144332, 'Total loss': 0.18602937106144332}
2023-01-05 00:39:53,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:53,591 INFO:     Epoch: 69
2023-01-05 00:39:55,844 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4004114598035812, 'Total loss': 0.4004114598035812} | train loss {'Reaction outcome loss': 0.18775325083423514, 'Total loss': 0.18775325083423514}
2023-01-05 00:39:55,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:55,844 INFO:     Epoch: 70
2023-01-05 00:39:58,063 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4272040913502375, 'Total loss': 0.4272040913502375} | train loss {'Reaction outcome loss': 0.18554833898003603, 'Total loss': 0.18554833898003603}
2023-01-05 00:39:58,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:39:58,065 INFO:     Epoch: 71
2023-01-05 00:40:00,326 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3978922580679258, 'Total loss': 0.3978922580679258} | train loss {'Reaction outcome loss': 0.1812065722075151, 'Total loss': 0.1812065722075151}
2023-01-05 00:40:00,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:00,327 INFO:     Epoch: 72
2023-01-05 00:40:02,592 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.36132067342599233, 'Total loss': 0.36132067342599233} | train loss {'Reaction outcome loss': 0.18032727196670906, 'Total loss': 0.18032727196670906}
2023-01-05 00:40:02,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:02,592 INFO:     Epoch: 73
2023-01-05 00:40:04,858 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3732505361239115, 'Total loss': 0.3732505361239115} | train loss {'Reaction outcome loss': 0.18612142668837844, 'Total loss': 0.18612142668837844}
2023-01-05 00:40:04,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:04,859 INFO:     Epoch: 74
2023-01-05 00:40:07,123 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41946522692839305, 'Total loss': 0.41946522692839305} | train loss {'Reaction outcome loss': 0.17812861041486452, 'Total loss': 0.17812861041486452}
2023-01-05 00:40:07,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:07,123 INFO:     Epoch: 75
2023-01-05 00:40:09,315 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3818359677990278, 'Total loss': 0.3818359677990278} | train loss {'Reaction outcome loss': 0.19139030628729667, 'Total loss': 0.19139030628729667}
2023-01-05 00:40:09,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:09,315 INFO:     Epoch: 76
2023-01-05 00:40:11,571 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37750727534294126, 'Total loss': 0.37750727534294126} | train loss {'Reaction outcome loss': 0.18107829034219639, 'Total loss': 0.18107829034219639}
2023-01-05 00:40:11,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:11,571 INFO:     Epoch: 77
2023-01-05 00:40:13,832 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38900233308474225, 'Total loss': 0.38900233308474225} | train loss {'Reaction outcome loss': 0.17685951800186836, 'Total loss': 0.17685951800186836}
2023-01-05 00:40:13,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:13,833 INFO:     Epoch: 78
2023-01-05 00:40:16,004 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3908153702815374, 'Total loss': 0.3908153702815374} | train loss {'Reaction outcome loss': 0.1773466615822922, 'Total loss': 0.1773466615822922}
2023-01-05 00:40:16,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:16,004 INFO:     Epoch: 79
2023-01-05 00:40:18,222 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.38423513422409694, 'Total loss': 0.38423513422409694} | train loss {'Reaction outcome loss': 0.17429211900309674, 'Total loss': 0.17429211900309674}
2023-01-05 00:40:18,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:18,223 INFO:     Epoch: 80
2023-01-05 00:40:20,473 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3991381163398425, 'Total loss': 0.3991381163398425} | train loss {'Reaction outcome loss': 0.1690179540457683, 'Total loss': 0.1690179540457683}
2023-01-05 00:40:20,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:20,473 INFO:     Epoch: 81
2023-01-05 00:40:22,733 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38878314197063446, 'Total loss': 0.38878314197063446} | train loss {'Reaction outcome loss': 0.16950522098467563, 'Total loss': 0.16950522098467563}
2023-01-05 00:40:22,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:22,733 INFO:     Epoch: 82
2023-01-05 00:40:24,970 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4006800482670466, 'Total loss': 0.4006800482670466} | train loss {'Reaction outcome loss': 0.17176814210493382, 'Total loss': 0.17176814210493382}
2023-01-05 00:40:24,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:24,971 INFO:     Epoch: 83
2023-01-05 00:40:27,215 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4055532644192378, 'Total loss': 0.4055532644192378} | train loss {'Reaction outcome loss': 0.1711310309347818, 'Total loss': 0.1711310309347818}
2023-01-05 00:40:27,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:27,215 INFO:     Epoch: 84
2023-01-05 00:40:29,484 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3667425354321798, 'Total loss': 0.3667425354321798} | train loss {'Reaction outcome loss': 0.17247834854313862, 'Total loss': 0.17247834854313862}
2023-01-05 00:40:29,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:29,484 INFO:     Epoch: 85
2023-01-05 00:40:31,666 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38838838239510853, 'Total loss': 0.38838838239510853} | train loss {'Reaction outcome loss': 0.16896644113923842, 'Total loss': 0.16896644113923842}
2023-01-05 00:40:31,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:31,667 INFO:     Epoch: 86
2023-01-05 00:40:33,517 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38864487210909526, 'Total loss': 0.38864487210909526} | train loss {'Reaction outcome loss': 0.16925861083133065, 'Total loss': 0.16925861083133065}
2023-01-05 00:40:33,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:33,518 INFO:     Epoch: 87
2023-01-05 00:40:35,391 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43184851308663685, 'Total loss': 0.43184851308663685} | train loss {'Reaction outcome loss': 0.17265147466779404, 'Total loss': 0.17265147466779404}
2023-01-05 00:40:35,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:35,391 INFO:     Epoch: 88
2023-01-05 00:40:37,571 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4167384793361028, 'Total loss': 0.4167384793361028} | train loss {'Reaction outcome loss': 0.17659662590038194, 'Total loss': 0.17659662590038194}
2023-01-05 00:40:37,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:37,571 INFO:     Epoch: 89
2023-01-05 00:40:39,722 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4206120332082113, 'Total loss': 0.4206120332082113} | train loss {'Reaction outcome loss': 0.16729907127792368, 'Total loss': 0.16729907127792368}
2023-01-05 00:40:39,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:39,723 INFO:     Epoch: 90
2023-01-05 00:40:41,988 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.37684564540783566, 'Total loss': 0.37684564540783566} | train loss {'Reaction outcome loss': 0.16877896853965585, 'Total loss': 0.16877896853965585}
2023-01-05 00:40:41,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:41,988 INFO:     Epoch: 91
2023-01-05 00:40:44,233 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.420387194554011, 'Total loss': 0.420387194554011} | train loss {'Reaction outcome loss': 0.17230577089904345, 'Total loss': 0.17230577089904345}
2023-01-05 00:40:44,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:44,233 INFO:     Epoch: 92
2023-01-05 00:40:46,495 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.38329981788992884, 'Total loss': 0.38329981788992884} | train loss {'Reaction outcome loss': 0.16771071880045213, 'Total loss': 0.16771071880045213}
2023-01-05 00:40:46,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:46,495 INFO:     Epoch: 93
2023-01-05 00:40:48,694 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.398959144949913, 'Total loss': 0.398959144949913} | train loss {'Reaction outcome loss': 0.16634580979313096, 'Total loss': 0.16634580979313096}
2023-01-05 00:40:48,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:48,694 INFO:     Epoch: 94
2023-01-05 00:40:50,894 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3812906865030527, 'Total loss': 0.3812906865030527} | train loss {'Reaction outcome loss': 0.16194482739387162, 'Total loss': 0.16194482739387162}
2023-01-05 00:40:50,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:50,895 INFO:     Epoch: 95
2023-01-05 00:40:53,129 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3595803844432036, 'Total loss': 0.3595803844432036} | train loss {'Reaction outcome loss': 0.16384042350129702, 'Total loss': 0.16384042350129702}
2023-01-05 00:40:53,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:53,130 INFO:     Epoch: 96
2023-01-05 00:40:55,368 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3858607272307078, 'Total loss': 0.3858607272307078} | train loss {'Reaction outcome loss': 0.16693163187491059, 'Total loss': 0.16693163187491059}
2023-01-05 00:40:55,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:55,369 INFO:     Epoch: 97
2023-01-05 00:40:57,615 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.407373641928037, 'Total loss': 0.407373641928037} | train loss {'Reaction outcome loss': 0.1651010472908282, 'Total loss': 0.1651010472908282}
2023-01-05 00:40:57,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:57,616 INFO:     Epoch: 98
2023-01-05 00:40:59,813 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4203370491663615, 'Total loss': 0.4203370491663615} | train loss {'Reaction outcome loss': 0.1628228762594939, 'Total loss': 0.1628228762594939}
2023-01-05 00:40:59,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:40:59,814 INFO:     Epoch: 99
2023-01-05 00:41:02,058 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37250736554463704, 'Total loss': 0.37250736554463704} | train loss {'Reaction outcome loss': 0.1633023447295167, 'Total loss': 0.1633023447295167}
2023-01-05 00:41:02,058 INFO:     Best model found after epoch 60 of 100.
2023-01-05 00:41:02,058 INFO:   Done with stage: TRAINING
2023-01-05 00:41:02,058 INFO:   Starting stage: EVALUATION
2023-01-05 00:41:02,193 INFO:   Done with stage: EVALUATION
2023-01-05 00:41:02,193 INFO:   Leaving out SEQ value Fold_7
2023-01-05 00:41:02,206 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 00:41:02,206 INFO:   Starting stage: FEATURE SCALING
2023-01-05 00:41:02,853 INFO:   Done with stage: FEATURE SCALING
2023-01-05 00:41:02,853 INFO:   Starting stage: SCALING TARGETS
2023-01-05 00:41:02,923 INFO:   Done with stage: SCALING TARGETS
2023-01-05 00:41:02,923 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:41:02,923 INFO:     No hyperparam tuning for this model
2023-01-05 00:41:02,924 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:41:02,924 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 00:41:02,924 INFO:     None feature selector for col prot
2023-01-05 00:41:02,924 INFO:     None feature selector for col prot
2023-01-05 00:41:02,925 INFO:     None feature selector for col prot
2023-01-05 00:41:02,925 INFO:     None feature selector for col chem
2023-01-05 00:41:02,925 INFO:     None feature selector for col chem
2023-01-05 00:41:02,925 INFO:     None feature selector for col chem
2023-01-05 00:41:02,925 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 00:41:02,925 INFO:   Starting stage: BUILD MODEL
2023-01-05 00:41:02,927 INFO:     Number of params in model 72931
2023-01-05 00:41:02,930 INFO:   Done with stage: BUILD MODEL
2023-01-05 00:41:02,930 INFO:   Starting stage: TRAINING
2023-01-05 00:41:02,990 INFO:     Val loss before train {'Reaction outcome loss': 0.9462856968243917, 'Total loss': 0.9462856968243917}
2023-01-05 00:41:02,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:02,990 INFO:     Epoch: 0
2023-01-05 00:41:05,270 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.731133782863617, 'Total loss': 0.731133782863617} | train loss {'Reaction outcome loss': 0.9477257392897073, 'Total loss': 0.9477257392897073}
2023-01-05 00:41:05,270 INFO:     Found new best model at epoch 0
2023-01-05 00:41:05,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:05,271 INFO:     Epoch: 1
2023-01-05 00:41:07,526 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5914624730745951, 'Total loss': 0.5914624730745951} | train loss {'Reaction outcome loss': 0.6356697509650289, 'Total loss': 0.6356697509650289}
2023-01-05 00:41:07,526 INFO:     Found new best model at epoch 1
2023-01-05 00:41:07,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:07,528 INFO:     Epoch: 2
2023-01-05 00:41:09,806 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5166243851184845, 'Total loss': 0.5166243851184845} | train loss {'Reaction outcome loss': 0.5296648323589714, 'Total loss': 0.5296648323589714}
2023-01-05 00:41:09,807 INFO:     Found new best model at epoch 2
2023-01-05 00:41:09,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:09,809 INFO:     Epoch: 3
2023-01-05 00:41:12,037 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4866568704446157, 'Total loss': 0.4866568704446157} | train loss {'Reaction outcome loss': 0.48533075864995, 'Total loss': 0.48533075864995}
2023-01-05 00:41:12,038 INFO:     Found new best model at epoch 3
2023-01-05 00:41:12,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:12,039 INFO:     Epoch: 4
2023-01-05 00:41:14,320 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46368801097075146, 'Total loss': 0.46368801097075146} | train loss {'Reaction outcome loss': 0.45880567607896855, 'Total loss': 0.45880567607896855}
2023-01-05 00:41:14,320 INFO:     Found new best model at epoch 4
2023-01-05 00:41:14,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:14,321 INFO:     Epoch: 5
2023-01-05 00:41:16,602 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4628408561150233, 'Total loss': 0.4628408561150233} | train loss {'Reaction outcome loss': 0.4386760768369647, 'Total loss': 0.4386760768369647}
2023-01-05 00:41:16,603 INFO:     Found new best model at epoch 5
2023-01-05 00:41:16,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:16,604 INFO:     Epoch: 6
2023-01-05 00:41:18,863 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44175072213013966, 'Total loss': 0.44175072213013966} | train loss {'Reaction outcome loss': 0.41766594439099414, 'Total loss': 0.41766594439099414}
2023-01-05 00:41:18,863 INFO:     Found new best model at epoch 6
2023-01-05 00:41:18,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:18,864 INFO:     Epoch: 7
2023-01-05 00:41:21,137 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4456797957420349, 'Total loss': 0.4456797957420349} | train loss {'Reaction outcome loss': 0.4069582850063751, 'Total loss': 0.4069582850063751}
2023-01-05 00:41:21,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:21,137 INFO:     Epoch: 8
2023-01-05 00:41:23,391 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4245428969462713, 'Total loss': 0.4245428969462713} | train loss {'Reaction outcome loss': 0.39376658801029735, 'Total loss': 0.39376658801029735}
2023-01-05 00:41:23,391 INFO:     Found new best model at epoch 8
2023-01-05 00:41:23,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:23,392 INFO:     Epoch: 9
2023-01-05 00:41:25,675 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4609312693277995, 'Total loss': 0.4609312693277995} | train loss {'Reaction outcome loss': 0.3875667109601334, 'Total loss': 0.3875667109601334}
2023-01-05 00:41:25,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:25,675 INFO:     Epoch: 10
2023-01-05 00:41:27,946 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4545716683069865, 'Total loss': 0.4545716683069865} | train loss {'Reaction outcome loss': 0.37009799036631086, 'Total loss': 0.37009799036631086}
2023-01-05 00:41:27,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:27,946 INFO:     Epoch: 11
2023-01-05 00:41:30,210 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48301538030306496, 'Total loss': 0.48301538030306496} | train loss {'Reaction outcome loss': 0.35545406654638506, 'Total loss': 0.35545406654638506}
2023-01-05 00:41:30,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:30,211 INFO:     Epoch: 12
2023-01-05 00:41:32,453 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4670254727204641, 'Total loss': 0.4670254727204641} | train loss {'Reaction outcome loss': 0.3515213469063547, 'Total loss': 0.3515213469063547}
2023-01-05 00:41:32,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:32,453 INFO:     Epoch: 13
2023-01-05 00:41:34,619 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4757959177096685, 'Total loss': 0.4757959177096685} | train loss {'Reaction outcome loss': 0.34375582694576967, 'Total loss': 0.34375582694576967}
2023-01-05 00:41:34,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:34,620 INFO:     Epoch: 14
2023-01-05 00:41:36,711 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46987709899743396, 'Total loss': 0.46987709899743396} | train loss {'Reaction outcome loss': 0.328830808616287, 'Total loss': 0.328830808616287}
2023-01-05 00:41:36,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:36,711 INFO:     Epoch: 15
2023-01-05 00:41:38,830 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46463331778844197, 'Total loss': 0.46463331778844197} | train loss {'Reaction outcome loss': 0.31863240217151195, 'Total loss': 0.31863240217151195}
2023-01-05 00:41:38,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:38,830 INFO:     Epoch: 16
2023-01-05 00:41:41,110 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4684772441784541, 'Total loss': 0.4684772441784541} | train loss {'Reaction outcome loss': 0.3129169293662486, 'Total loss': 0.3129169293662486}
2023-01-05 00:41:41,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:41,110 INFO:     Epoch: 17
2023-01-05 00:41:43,366 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4730987290541331, 'Total loss': 0.4730987290541331} | train loss {'Reaction outcome loss': 0.3053840072119494, 'Total loss': 0.3053840072119494}
2023-01-05 00:41:43,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:43,366 INFO:     Epoch: 18
2023-01-05 00:41:45,613 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4559447209040324, 'Total loss': 0.4559447209040324} | train loss {'Reaction outcome loss': 0.2999167344549718, 'Total loss': 0.2999167344549718}
2023-01-05 00:41:45,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:45,614 INFO:     Epoch: 19
2023-01-05 00:41:47,819 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4503964672485987, 'Total loss': 0.4503964672485987} | train loss {'Reaction outcome loss': 0.29366229830935114, 'Total loss': 0.29366229830935114}
2023-01-05 00:41:47,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:47,819 INFO:     Epoch: 20
2023-01-05 00:41:50,070 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47467132409413654, 'Total loss': 0.47467132409413654} | train loss {'Reaction outcome loss': 0.28514711545370114, 'Total loss': 0.28514711545370114}
2023-01-05 00:41:50,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:50,071 INFO:     Epoch: 21
2023-01-05 00:41:52,337 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46551780998706815, 'Total loss': 0.46551780998706815} | train loss {'Reaction outcome loss': 0.28645367679666955, 'Total loss': 0.28645367679666955}
2023-01-05 00:41:52,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:52,338 INFO:     Epoch: 22
2023-01-05 00:41:54,600 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44224923650423686, 'Total loss': 0.44224923650423686} | train loss {'Reaction outcome loss': 0.27864752547136284, 'Total loss': 0.27864752547136284}
2023-01-05 00:41:54,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:54,600 INFO:     Epoch: 23
2023-01-05 00:41:56,854 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4683749462167422, 'Total loss': 0.4683749462167422} | train loss {'Reaction outcome loss': 0.27248769397393463, 'Total loss': 0.27248769397393463}
2023-01-05 00:41:56,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:56,854 INFO:     Epoch: 24
2023-01-05 00:41:59,137 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4523704618215561, 'Total loss': 0.4523704618215561} | train loss {'Reaction outcome loss': 0.2688834865943996, 'Total loss': 0.2688834865943996}
2023-01-05 00:41:59,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:41:59,138 INFO:     Epoch: 25
2023-01-05 00:42:01,412 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4475380967060725, 'Total loss': 0.4475380967060725} | train loss {'Reaction outcome loss': 0.2661525500393624, 'Total loss': 0.2661525500393624}
2023-01-05 00:42:01,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:01,413 INFO:     Epoch: 26
2023-01-05 00:42:03,655 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45579506357510885, 'Total loss': 0.45579506357510885} | train loss {'Reaction outcome loss': 0.2574543059275684, 'Total loss': 0.2574543059275684}
2023-01-05 00:42:03,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:03,656 INFO:     Epoch: 27
2023-01-05 00:42:05,920 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4400984982649485, 'Total loss': 0.4400984982649485} | train loss {'Reaction outcome loss': 0.25868034941759566, 'Total loss': 0.25868034941759566}
2023-01-05 00:42:05,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:05,921 INFO:     Epoch: 28
2023-01-05 00:42:08,175 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4522828385233879, 'Total loss': 0.4522828385233879} | train loss {'Reaction outcome loss': 0.2533068306582714, 'Total loss': 0.2533068306582714}
2023-01-05 00:42:08,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:08,176 INFO:     Epoch: 29
2023-01-05 00:42:10,461 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45872916181882223, 'Total loss': 0.45872916181882223} | train loss {'Reaction outcome loss': 0.24559596172174178, 'Total loss': 0.24559596172174178}
2023-01-05 00:42:10,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:10,461 INFO:     Epoch: 30
2023-01-05 00:42:12,747 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4493338977297147, 'Total loss': 0.4493338977297147} | train loss {'Reaction outcome loss': 0.24923473091574136, 'Total loss': 0.24923473091574136}
2023-01-05 00:42:12,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:12,747 INFO:     Epoch: 31
2023-01-05 00:42:14,925 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44433155556519827, 'Total loss': 0.44433155556519827} | train loss {'Reaction outcome loss': 0.23973659319729151, 'Total loss': 0.23973659319729151}
2023-01-05 00:42:14,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:14,926 INFO:     Epoch: 32
2023-01-05 00:42:17,134 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43042442997296654, 'Total loss': 0.43042442997296654} | train loss {'Reaction outcome loss': 0.23800540798837957, 'Total loss': 0.23800540798837957}
2023-01-05 00:42:17,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:17,134 INFO:     Epoch: 33
2023-01-05 00:42:19,383 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4193548709154129, 'Total loss': 0.4193548709154129} | train loss {'Reaction outcome loss': 0.23097263567741383, 'Total loss': 0.23097263567741383}
2023-01-05 00:42:19,383 INFO:     Found new best model at epoch 33
2023-01-05 00:42:19,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:19,385 INFO:     Epoch: 34
2023-01-05 00:42:21,527 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45115305930376054, 'Total loss': 0.45115305930376054} | train loss {'Reaction outcome loss': 0.23307399290348219, 'Total loss': 0.23307399290348219}
2023-01-05 00:42:21,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:21,529 INFO:     Epoch: 35
2023-01-05 00:42:23,802 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42169300516446434, 'Total loss': 0.42169300516446434} | train loss {'Reaction outcome loss': 0.23402411572715867, 'Total loss': 0.23402411572715867}
2023-01-05 00:42:23,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:23,802 INFO:     Epoch: 36
2023-01-05 00:42:26,056 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4393547669053078, 'Total loss': 0.4393547669053078} | train loss {'Reaction outcome loss': 0.2213205604239061, 'Total loss': 0.2213205604239061}
2023-01-05 00:42:26,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:26,057 INFO:     Epoch: 37
2023-01-05 00:42:28,326 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4315298895041148, 'Total loss': 0.4315298895041148} | train loss {'Reaction outcome loss': 0.221490047038247, 'Total loss': 0.221490047038247}
2023-01-05 00:42:28,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:28,327 INFO:     Epoch: 38
2023-01-05 00:42:30,583 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4315402522683144, 'Total loss': 0.4315402522683144} | train loss {'Reaction outcome loss': 0.2182004684111648, 'Total loss': 0.2182004684111648}
2023-01-05 00:42:30,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:30,584 INFO:     Epoch: 39
2023-01-05 00:42:32,843 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45308738251527153, 'Total loss': 0.45308738251527153} | train loss {'Reaction outcome loss': 0.22092461284747622, 'Total loss': 0.22092461284747622}
2023-01-05 00:42:32,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:32,843 INFO:     Epoch: 40
2023-01-05 00:42:35,101 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44358126918474833, 'Total loss': 0.44358126918474833} | train loss {'Reaction outcome loss': 0.21570672293190277, 'Total loss': 0.21570672293190277}
2023-01-05 00:42:35,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:35,101 INFO:     Epoch: 41
2023-01-05 00:42:37,374 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4366351455450058, 'Total loss': 0.4366351455450058} | train loss {'Reaction outcome loss': 0.216219781665972, 'Total loss': 0.216219781665972}
2023-01-05 00:42:37,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:37,374 INFO:     Epoch: 42
2023-01-05 00:42:39,633 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45272237857182823, 'Total loss': 0.45272237857182823} | train loss {'Reaction outcome loss': 0.2172786885660666, 'Total loss': 0.2172786885660666}
2023-01-05 00:42:39,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:39,634 INFO:     Epoch: 43
2023-01-05 00:42:41,851 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4464784413576126, 'Total loss': 0.4464784413576126} | train loss {'Reaction outcome loss': 0.21108355589668243, 'Total loss': 0.21108355589668243}
2023-01-05 00:42:41,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:41,852 INFO:     Epoch: 44
2023-01-05 00:42:44,114 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42647534708182017, 'Total loss': 0.42647534708182017} | train loss {'Reaction outcome loss': 0.2053779695747884, 'Total loss': 0.2053779695747884}
2023-01-05 00:42:44,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:44,115 INFO:     Epoch: 45
2023-01-05 00:42:46,367 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43536349236965177, 'Total loss': 0.43536349236965177} | train loss {'Reaction outcome loss': 0.2066779157940285, 'Total loss': 0.2066779157940285}
2023-01-05 00:42:46,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:46,367 INFO:     Epoch: 46
2023-01-05 00:42:48,612 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41872590482234956, 'Total loss': 0.41872590482234956} | train loss {'Reaction outcome loss': 0.2084026831447648, 'Total loss': 0.2084026831447648}
2023-01-05 00:42:48,612 INFO:     Found new best model at epoch 46
2023-01-05 00:42:48,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:48,614 INFO:     Epoch: 47
2023-01-05 00:42:50,881 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44048736890157064, 'Total loss': 0.44048736890157064} | train loss {'Reaction outcome loss': 0.20243043138810335, 'Total loss': 0.20243043138810335}
2023-01-05 00:42:50,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:50,882 INFO:     Epoch: 48
2023-01-05 00:42:53,132 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4337867319583893, 'Total loss': 0.4337867319583893} | train loss {'Reaction outcome loss': 0.20056945579429072, 'Total loss': 0.20056945579429072}
2023-01-05 00:42:53,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:53,133 INFO:     Epoch: 49
2023-01-05 00:42:55,386 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45390449861685433, 'Total loss': 0.45390449861685433} | train loss {'Reaction outcome loss': 0.1980986949325361, 'Total loss': 0.1980986949325361}
2023-01-05 00:42:55,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:55,386 INFO:     Epoch: 50
2023-01-05 00:42:57,663 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4324826404452324, 'Total loss': 0.4324826404452324} | train loss {'Reaction outcome loss': 0.20054369310542458, 'Total loss': 0.20054369310542458}
2023-01-05 00:42:57,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:57,664 INFO:     Epoch: 51
2023-01-05 00:42:59,935 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.444993956387043, 'Total loss': 0.444993956387043} | train loss {'Reaction outcome loss': 0.19809730551020654, 'Total loss': 0.19809730551020654}
2023-01-05 00:42:59,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:42:59,935 INFO:     Epoch: 52
2023-01-05 00:43:02,204 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4125426908334096, 'Total loss': 0.4125426908334096} | train loss {'Reaction outcome loss': 0.1977166554315641, 'Total loss': 0.1977166554315641}
2023-01-05 00:43:02,204 INFO:     Found new best model at epoch 52
2023-01-05 00:43:02,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:02,206 INFO:     Epoch: 53
2023-01-05 00:43:04,479 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42674898902575176, 'Total loss': 0.42674898902575176} | train loss {'Reaction outcome loss': 0.19510799200889328, 'Total loss': 0.19510799200889328}
2023-01-05 00:43:04,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:04,480 INFO:     Epoch: 54
2023-01-05 00:43:06,737 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45465662479400637, 'Total loss': 0.45465662479400637} | train loss {'Reaction outcome loss': 0.18963682598397405, 'Total loss': 0.18963682598397405}
2023-01-05 00:43:06,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:06,737 INFO:     Epoch: 55
2023-01-05 00:43:08,994 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4481841504573822, 'Total loss': 0.4481841504573822} | train loss {'Reaction outcome loss': 0.19087632058780063, 'Total loss': 0.19087632058780063}
2023-01-05 00:43:08,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:08,994 INFO:     Epoch: 56
2023-01-05 00:43:11,270 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44290214677651724, 'Total loss': 0.44290214677651724} | train loss {'Reaction outcome loss': 0.19147660216696508, 'Total loss': 0.19147660216696508}
2023-01-05 00:43:11,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:11,270 INFO:     Epoch: 57
2023-01-05 00:43:13,517 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42950648367404937, 'Total loss': 0.42950648367404937} | train loss {'Reaction outcome loss': 0.19363625315169297, 'Total loss': 0.19363625315169297}
2023-01-05 00:43:13,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:13,517 INFO:     Epoch: 58
2023-01-05 00:43:15,795 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.48703462978204093, 'Total loss': 0.48703462978204093} | train loss {'Reaction outcome loss': 0.19335509848945676, 'Total loss': 0.19335509848945676}
2023-01-05 00:43:15,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:15,796 INFO:     Epoch: 59
2023-01-05 00:43:18,048 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45124907890955607, 'Total loss': 0.45124907890955607} | train loss {'Reaction outcome loss': 0.18925694813985472, 'Total loss': 0.18925694813985472}
2023-01-05 00:43:18,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:18,049 INFO:     Epoch: 60
2023-01-05 00:43:20,284 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45367338458697, 'Total loss': 0.45367338458697} | train loss {'Reaction outcome loss': 0.18612100038381582, 'Total loss': 0.18612100038381582}
2023-01-05 00:43:20,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:20,284 INFO:     Epoch: 61
2023-01-05 00:43:22,561 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4418225740393003, 'Total loss': 0.4418225740393003} | train loss {'Reaction outcome loss': 0.18962197161249358, 'Total loss': 0.18962197161249358}
2023-01-05 00:43:22,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:22,561 INFO:     Epoch: 62
2023-01-05 00:43:24,845 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46731119553248085, 'Total loss': 0.46731119553248085} | train loss {'Reaction outcome loss': 0.18742882573661068, 'Total loss': 0.18742882573661068}
2023-01-05 00:43:24,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:24,845 INFO:     Epoch: 63
2023-01-05 00:43:27,094 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46843200487395126, 'Total loss': 0.46843200487395126} | train loss {'Reaction outcome loss': 0.19215578171643108, 'Total loss': 0.19215578171643108}
2023-01-05 00:43:27,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:27,094 INFO:     Epoch: 64
2023-01-05 00:43:29,341 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45467055837313336, 'Total loss': 0.45467055837313336} | train loss {'Reaction outcome loss': 0.18403151631355286, 'Total loss': 0.18403151631355286}
2023-01-05 00:43:29,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:29,341 INFO:     Epoch: 65
2023-01-05 00:43:31,620 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43468629419803617, 'Total loss': 0.43468629419803617} | train loss {'Reaction outcome loss': 0.1868388071178798, 'Total loss': 0.1868388071178798}
2023-01-05 00:43:31,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:31,620 INFO:     Epoch: 66
2023-01-05 00:43:33,903 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45372478365898133, 'Total loss': 0.45372478365898133} | train loss {'Reaction outcome loss': 0.18527327593254592, 'Total loss': 0.18527327593254592}
2023-01-05 00:43:33,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:33,905 INFO:     Epoch: 67
2023-01-05 00:43:36,147 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4594854285319646, 'Total loss': 0.4594854285319646} | train loss {'Reaction outcome loss': 0.18569141092948913, 'Total loss': 0.18569141092948913}
2023-01-05 00:43:36,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:36,147 INFO:     Epoch: 68
2023-01-05 00:43:38,424 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4523183713356654, 'Total loss': 0.4523183713356654} | train loss {'Reaction outcome loss': 0.18230392921056987, 'Total loss': 0.18230392921056987}
2023-01-05 00:43:38,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:38,424 INFO:     Epoch: 69
2023-01-05 00:43:40,652 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4664310932159424, 'Total loss': 0.4664310932159424} | train loss {'Reaction outcome loss': 0.1797518333931208, 'Total loss': 0.1797518333931208}
2023-01-05 00:43:40,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:40,652 INFO:     Epoch: 70
2023-01-05 00:43:42,909 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44670833547910055, 'Total loss': 0.44670833547910055} | train loss {'Reaction outcome loss': 0.17980657332317923, 'Total loss': 0.17980657332317923}
2023-01-05 00:43:42,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:42,909 INFO:     Epoch: 71
2023-01-05 00:43:45,185 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44850127696990966, 'Total loss': 0.44850127696990966} | train loss {'Reaction outcome loss': 0.17475018801927458, 'Total loss': 0.17475018801927458}
2023-01-05 00:43:45,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:45,186 INFO:     Epoch: 72
2023-01-05 00:43:47,464 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4495379913598299, 'Total loss': 0.4495379913598299} | train loss {'Reaction outcome loss': 0.17685315635858864, 'Total loss': 0.17685315635858864}
2023-01-05 00:43:47,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:47,464 INFO:     Epoch: 73
2023-01-05 00:43:49,741 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4427014023065567, 'Total loss': 0.4427014023065567} | train loss {'Reaction outcome loss': 0.17624669167337542, 'Total loss': 0.17624669167337542}
2023-01-05 00:43:49,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:49,741 INFO:     Epoch: 74
2023-01-05 00:43:51,989 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46611355344454447, 'Total loss': 0.46611355344454447} | train loss {'Reaction outcome loss': 0.1766547998480687, 'Total loss': 0.1766547998480687}
2023-01-05 00:43:51,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:51,989 INFO:     Epoch: 75
2023-01-05 00:43:54,241 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45701020359992983, 'Total loss': 0.45701020359992983} | train loss {'Reaction outcome loss': 0.1774754258013912, 'Total loss': 0.1774754258013912}
2023-01-05 00:43:54,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:54,242 INFO:     Epoch: 76
2023-01-05 00:43:56,520 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44492716987927755, 'Total loss': 0.44492716987927755} | train loss {'Reaction outcome loss': 0.17372017198272507, 'Total loss': 0.17372017198272507}
2023-01-05 00:43:56,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:56,520 INFO:     Epoch: 77
2023-01-05 00:43:58,777 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4284011999766032, 'Total loss': 0.4284011999766032} | train loss {'Reaction outcome loss': 0.1718362192387965, 'Total loss': 0.1718362192387965}
2023-01-05 00:43:58,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:43:58,778 INFO:     Epoch: 78
2023-01-05 00:44:00,994 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42348060409228006, 'Total loss': 0.42348060409228006} | train loss {'Reaction outcome loss': 0.17372246872505934, 'Total loss': 0.17372246872505934}
2023-01-05 00:44:00,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:00,994 INFO:     Epoch: 79
2023-01-05 00:44:03,237 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47499046425024666, 'Total loss': 0.47499046425024666} | train loss {'Reaction outcome loss': 0.17057396567322394, 'Total loss': 0.17057396567322394}
2023-01-05 00:44:03,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:03,237 INFO:     Epoch: 80
2023-01-05 00:44:05,484 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4403597645772, 'Total loss': 0.4403597645772} | train loss {'Reaction outcome loss': 0.17125195713414532, 'Total loss': 0.17125195713414532}
2023-01-05 00:44:05,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:05,485 INFO:     Epoch: 81
2023-01-05 00:44:07,751 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48967686692873635, 'Total loss': 0.48967686692873635} | train loss {'Reaction outcome loss': 0.16973766406144045, 'Total loss': 0.16973766406144045}
2023-01-05 00:44:07,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:07,751 INFO:     Epoch: 82
2023-01-05 00:44:10,024 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48007745246092476, 'Total loss': 0.48007745246092476} | train loss {'Reaction outcome loss': 0.17373644078439537, 'Total loss': 0.17373644078439537}
2023-01-05 00:44:10,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:10,026 INFO:     Epoch: 83
2023-01-05 00:44:12,257 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4575447340806325, 'Total loss': 0.4575447340806325} | train loss {'Reaction outcome loss': 0.1727048174044393, 'Total loss': 0.1727048174044393}
2023-01-05 00:44:12,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:12,257 INFO:     Epoch: 84
2023-01-05 00:44:14,526 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5008123854796092, 'Total loss': 0.5008123854796092} | train loss {'Reaction outcome loss': 0.16936831929744472, 'Total loss': 0.16936831929744472}
2023-01-05 00:44:14,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:14,527 INFO:     Epoch: 85
2023-01-05 00:44:16,707 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4590050051609675, 'Total loss': 0.4590050051609675} | train loss {'Reaction outcome loss': 0.17216191758546265, 'Total loss': 0.17216191758546265}
2023-01-05 00:44:16,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:16,708 INFO:     Epoch: 86
2023-01-05 00:44:18,969 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43616351087888083, 'Total loss': 0.43616351087888083} | train loss {'Reaction outcome loss': 0.17060714025581625, 'Total loss': 0.17060714025581625}
2023-01-05 00:44:18,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:18,969 INFO:     Epoch: 87
2023-01-05 00:44:21,215 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42684535880883534, 'Total loss': 0.42684535880883534} | train loss {'Reaction outcome loss': 0.16928806359499746, 'Total loss': 0.16928806359499746}
2023-01-05 00:44:21,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:21,215 INFO:     Epoch: 88
2023-01-05 00:44:23,466 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4477861752112707, 'Total loss': 0.4477861752112707} | train loss {'Reaction outcome loss': 0.16350039919512177, 'Total loss': 0.16350039919512177}
2023-01-05 00:44:23,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:23,466 INFO:     Epoch: 89
2023-01-05 00:44:25,726 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4297838027278582, 'Total loss': 0.4297838027278582} | train loss {'Reaction outcome loss': 0.16761683499262356, 'Total loss': 0.16761683499262356}
2023-01-05 00:44:25,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:25,726 INFO:     Epoch: 90
2023-01-05 00:44:27,960 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45339059333006543, 'Total loss': 0.45339059333006543} | train loss {'Reaction outcome loss': 0.16200914318649778, 'Total loss': 0.16200914318649778}
2023-01-05 00:44:27,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:27,960 INFO:     Epoch: 91
2023-01-05 00:44:30,220 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4375092233220736, 'Total loss': 0.4375092233220736} | train loss {'Reaction outcome loss': 0.1646451226802079, 'Total loss': 0.1646451226802079}
2023-01-05 00:44:30,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:30,220 INFO:     Epoch: 92
2023-01-05 00:44:32,499 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42058842480182645, 'Total loss': 0.42058842480182645} | train loss {'Reaction outcome loss': 0.16898843119028512, 'Total loss': 0.16898843119028512}
2023-01-05 00:44:32,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:32,499 INFO:     Epoch: 93
2023-01-05 00:44:34,777 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4668083628018697, 'Total loss': 0.4668083628018697} | train loss {'Reaction outcome loss': 0.16067196952518653, 'Total loss': 0.16067196952518653}
2023-01-05 00:44:34,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:34,778 INFO:     Epoch: 94
2023-01-05 00:44:37,049 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45662699987490973, 'Total loss': 0.45662699987490973} | train loss {'Reaction outcome loss': 0.16487909618778565, 'Total loss': 0.16487909618778565}
2023-01-05 00:44:37,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:37,049 INFO:     Epoch: 95
2023-01-05 00:44:39,294 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45105311224857964, 'Total loss': 0.45105311224857964} | train loss {'Reaction outcome loss': 0.15769855141982653, 'Total loss': 0.15769855141982653}
2023-01-05 00:44:39,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:39,294 INFO:     Epoch: 96
2023-01-05 00:44:41,574 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4350929776827494, 'Total loss': 0.4350929776827494} | train loss {'Reaction outcome loss': 0.16432559602164296, 'Total loss': 0.16432559602164296}
2023-01-05 00:44:41,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:41,574 INFO:     Epoch: 97
2023-01-05 00:44:43,844 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4544364328185717, 'Total loss': 0.4544364328185717} | train loss {'Reaction outcome loss': 0.16396699719036853, 'Total loss': 0.16396699719036853}
2023-01-05 00:44:43,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:43,845 INFO:     Epoch: 98
2023-01-05 00:44:46,123 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42555731187264123, 'Total loss': 0.42555731187264123} | train loss {'Reaction outcome loss': 0.16152175883207778, 'Total loss': 0.16152175883207778}
2023-01-05 00:44:46,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:46,125 INFO:     Epoch: 99
2023-01-05 00:44:48,405 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42525867819786073, 'Total loss': 0.42525867819786073} | train loss {'Reaction outcome loss': 0.16193155644105123, 'Total loss': 0.16193155644105123}
2023-01-05 00:44:48,406 INFO:     Best model found after epoch 53 of 100.
2023-01-05 00:44:48,406 INFO:   Done with stage: TRAINING
2023-01-05 00:44:48,406 INFO:   Starting stage: EVALUATION
2023-01-05 00:44:48,535 INFO:   Done with stage: EVALUATION
2023-01-05 00:44:48,535 INFO:   Leaving out SEQ value Fold_8
2023-01-05 00:44:48,548 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 00:44:48,548 INFO:   Starting stage: FEATURE SCALING
2023-01-05 00:44:49,203 INFO:   Done with stage: FEATURE SCALING
2023-01-05 00:44:49,203 INFO:   Starting stage: SCALING TARGETS
2023-01-05 00:44:49,273 INFO:   Done with stage: SCALING TARGETS
2023-01-05 00:44:49,273 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:44:49,273 INFO:     No hyperparam tuning for this model
2023-01-05 00:44:49,273 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:44:49,273 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 00:44:49,274 INFO:     None feature selector for col prot
2023-01-05 00:44:49,274 INFO:     None feature selector for col prot
2023-01-05 00:44:49,274 INFO:     None feature selector for col prot
2023-01-05 00:44:49,274 INFO:     None feature selector for col chem
2023-01-05 00:44:49,274 INFO:     None feature selector for col chem
2023-01-05 00:44:49,274 INFO:     None feature selector for col chem
2023-01-05 00:44:49,275 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 00:44:49,275 INFO:   Starting stage: BUILD MODEL
2023-01-05 00:44:49,277 INFO:     Number of params in model 72931
2023-01-05 00:44:49,280 INFO:   Done with stage: BUILD MODEL
2023-01-05 00:44:49,280 INFO:   Starting stage: TRAINING
2023-01-05 00:44:49,342 INFO:     Val loss before train {'Reaction outcome loss': 0.9260881046454111, 'Total loss': 0.9260881046454111}
2023-01-05 00:44:49,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:49,342 INFO:     Epoch: 0
2023-01-05 00:44:51,599 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7033440589904785, 'Total loss': 0.7033440589904785} | train loss {'Reaction outcome loss': 0.9430334404487473, 'Total loss': 0.9430334404487473}
2023-01-05 00:44:51,599 INFO:     Found new best model at epoch 0
2023-01-05 00:44:51,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:51,600 INFO:     Epoch: 1
2023-01-05 00:44:53,858 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5341648042201996, 'Total loss': 0.5341648042201996} | train loss {'Reaction outcome loss': 0.6392254066596392, 'Total loss': 0.6392254066596392}
2023-01-05 00:44:53,859 INFO:     Found new best model at epoch 1
2023-01-05 00:44:53,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:53,860 INFO:     Epoch: 2
2023-01-05 00:44:56,123 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4995673398176829, 'Total loss': 0.4995673398176829} | train loss {'Reaction outcome loss': 0.5534667836952726, 'Total loss': 0.5534667836952726}
2023-01-05 00:44:56,124 INFO:     Found new best model at epoch 2
2023-01-05 00:44:56,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:56,125 INFO:     Epoch: 3
2023-01-05 00:44:58,393 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4914176781972249, 'Total loss': 0.4914176781972249} | train loss {'Reaction outcome loss': 0.5150459026279002, 'Total loss': 0.5150459026279002}
2023-01-05 00:44:58,393 INFO:     Found new best model at epoch 3
2023-01-05 00:44:58,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:44:58,394 INFO:     Epoch: 4
2023-01-05 00:45:00,665 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4711583122611046, 'Total loss': 0.4711583122611046} | train loss {'Reaction outcome loss': 0.48050005873833324, 'Total loss': 0.48050005873833324}
2023-01-05 00:45:00,665 INFO:     Found new best model at epoch 4
2023-01-05 00:45:00,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:00,666 INFO:     Epoch: 5
2023-01-05 00:45:02,878 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4666169007619222, 'Total loss': 0.4666169007619222} | train loss {'Reaction outcome loss': 0.4542303353763229, 'Total loss': 0.4542303353763229}
2023-01-05 00:45:02,878 INFO:     Found new best model at epoch 5
2023-01-05 00:45:02,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:02,880 INFO:     Epoch: 6
2023-01-05 00:45:05,140 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44747894008954364, 'Total loss': 0.44747894008954364} | train loss {'Reaction outcome loss': 0.43667524789429746, 'Total loss': 0.43667524789429746}
2023-01-05 00:45:05,140 INFO:     Found new best model at epoch 6
2023-01-05 00:45:05,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:05,141 INFO:     Epoch: 7
2023-01-05 00:45:07,394 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4492218315601349, 'Total loss': 0.4492218315601349} | train loss {'Reaction outcome loss': 0.4153606610285246, 'Total loss': 0.4153606610285246}
2023-01-05 00:45:07,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:07,395 INFO:     Epoch: 8
2023-01-05 00:45:09,653 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42819018761316935, 'Total loss': 0.42819018761316935} | train loss {'Reaction outcome loss': 0.40485962573102663, 'Total loss': 0.40485962573102663}
2023-01-05 00:45:09,653 INFO:     Found new best model at epoch 8
2023-01-05 00:45:09,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:09,654 INFO:     Epoch: 9
2023-01-05 00:45:11,925 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43341837922732035, 'Total loss': 0.43341837922732035} | train loss {'Reaction outcome loss': 0.39331287565214107, 'Total loss': 0.39331287565214107}
2023-01-05 00:45:11,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:11,925 INFO:     Epoch: 10
2023-01-05 00:45:14,159 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4162556707859039, 'Total loss': 0.4162556707859039} | train loss {'Reaction outcome loss': 0.376395536754751, 'Total loss': 0.376395536754751}
2023-01-05 00:45:14,159 INFO:     Found new best model at epoch 10
2023-01-05 00:45:14,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:14,160 INFO:     Epoch: 11
2023-01-05 00:45:16,415 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4066937069098155, 'Total loss': 0.4066937069098155} | train loss {'Reaction outcome loss': 0.3701792155066337, 'Total loss': 0.3701792155066337}
2023-01-05 00:45:16,416 INFO:     Found new best model at epoch 11
2023-01-05 00:45:16,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:16,418 INFO:     Epoch: 12
2023-01-05 00:45:18,663 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40874610741933187, 'Total loss': 0.40874610741933187} | train loss {'Reaction outcome loss': 0.35647748636639937, 'Total loss': 0.35647748636639937}
2023-01-05 00:45:18,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:18,663 INFO:     Epoch: 13
2023-01-05 00:45:20,931 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41017163495222725, 'Total loss': 0.41017163495222725} | train loss {'Reaction outcome loss': 0.34403818342767467, 'Total loss': 0.34403818342767467}
2023-01-05 00:45:20,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:20,932 INFO:     Epoch: 14
2023-01-05 00:45:23,150 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.38532533049583434, 'Total loss': 0.38532533049583434} | train loss {'Reaction outcome loss': 0.33927032383770717, 'Total loss': 0.33927032383770717}
2023-01-05 00:45:23,151 INFO:     Found new best model at epoch 14
2023-01-05 00:45:23,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:23,152 INFO:     Epoch: 15
2023-01-05 00:45:25,392 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4032125780979792, 'Total loss': 0.4032125780979792} | train loss {'Reaction outcome loss': 0.32926756503995147, 'Total loss': 0.32926756503995147}
2023-01-05 00:45:25,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:25,392 INFO:     Epoch: 16
2023-01-05 00:45:27,638 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3951957732439041, 'Total loss': 0.3951957732439041} | train loss {'Reaction outcome loss': 0.3291004224401304, 'Total loss': 0.3291004224401304}
2023-01-05 00:45:27,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:27,638 INFO:     Epoch: 17
2023-01-05 00:45:29,891 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39178475737571716, 'Total loss': 0.39178475737571716} | train loss {'Reaction outcome loss': 0.31275915346421057, 'Total loss': 0.31275915346421057}
2023-01-05 00:45:29,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:29,891 INFO:     Epoch: 18
2023-01-05 00:45:32,126 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40258647203445436, 'Total loss': 0.40258647203445436} | train loss {'Reaction outcome loss': 0.3120321084876353, 'Total loss': 0.3120321084876353}
2023-01-05 00:45:32,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:32,126 INFO:     Epoch: 19
2023-01-05 00:45:34,305 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40453961690266926, 'Total loss': 0.40453961690266926} | train loss {'Reaction outcome loss': 0.3038878644873734, 'Total loss': 0.3038878644873734}
2023-01-05 00:45:34,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:34,305 INFO:     Epoch: 20
2023-01-05 00:45:36,539 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41022714376449587, 'Total loss': 0.41022714376449587} | train loss {'Reaction outcome loss': 0.3018941392563956, 'Total loss': 0.3018941392563956}
2023-01-05 00:45:36,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:36,540 INFO:     Epoch: 21
2023-01-05 00:45:38,749 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3951309045155843, 'Total loss': 0.3951309045155843} | train loss {'Reaction outcome loss': 0.2923498127528799, 'Total loss': 0.2923498127528799}
2023-01-05 00:45:38,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:38,749 INFO:     Epoch: 22
2023-01-05 00:45:40,962 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40383208990097047, 'Total loss': 0.40383208990097047} | train loss {'Reaction outcome loss': 0.2856125565117985, 'Total loss': 0.2856125565117985}
2023-01-05 00:45:40,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:40,962 INFO:     Epoch: 23
2023-01-05 00:45:43,218 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.412222029765447, 'Total loss': 0.412222029765447} | train loss {'Reaction outcome loss': 0.28160128898461373, 'Total loss': 0.28160128898461373}
2023-01-05 00:45:43,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:43,218 INFO:     Epoch: 24
2023-01-05 00:45:45,388 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41082975069681804, 'Total loss': 0.41082975069681804} | train loss {'Reaction outcome loss': 0.2764936236913454, 'Total loss': 0.2764936236913454}
2023-01-05 00:45:45,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:45,388 INFO:     Epoch: 25
2023-01-05 00:45:47,533 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41415713826815287, 'Total loss': 0.41415713826815287} | train loss {'Reaction outcome loss': 0.2754756449066129, 'Total loss': 0.2754756449066129}
2023-01-05 00:45:47,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:47,533 INFO:     Epoch: 26
2023-01-05 00:45:49,664 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4054624646902084, 'Total loss': 0.4054624646902084} | train loss {'Reaction outcome loss': 0.2672144955541898, 'Total loss': 0.2672144955541898}
2023-01-05 00:45:49,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:49,664 INFO:     Epoch: 27
2023-01-05 00:45:51,945 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4037442614634832, 'Total loss': 0.4037442614634832} | train loss {'Reaction outcome loss': 0.26504517331154553, 'Total loss': 0.26504517331154553}
2023-01-05 00:45:51,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:51,946 INFO:     Epoch: 28
2023-01-05 00:45:54,191 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4105335767070452, 'Total loss': 0.4105335767070452} | train loss {'Reaction outcome loss': 0.25981135627369156, 'Total loss': 0.25981135627369156}
2023-01-05 00:45:54,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:54,191 INFO:     Epoch: 29
2023-01-05 00:45:56,447 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4154628207286199, 'Total loss': 0.4154628207286199} | train loss {'Reaction outcome loss': 0.25959043614969785, 'Total loss': 0.25959043614969785}
2023-01-05 00:45:56,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:56,447 INFO:     Epoch: 30
2023-01-05 00:45:58,678 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41285014351209004, 'Total loss': 0.41285014351209004} | train loss {'Reaction outcome loss': 0.2519283216809753, 'Total loss': 0.2519283216809753}
2023-01-05 00:45:58,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:45:58,678 INFO:     Epoch: 31
2023-01-05 00:46:00,896 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38756567339102427, 'Total loss': 0.38756567339102427} | train loss {'Reaction outcome loss': 0.25149928568610214, 'Total loss': 0.25149928568610214}
2023-01-05 00:46:00,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:00,896 INFO:     Epoch: 32
2023-01-05 00:46:03,143 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3925668030977249, 'Total loss': 0.3925668030977249} | train loss {'Reaction outcome loss': 0.24802812077239533, 'Total loss': 0.24802812077239533}
2023-01-05 00:46:03,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:03,144 INFO:     Epoch: 33
2023-01-05 00:46:05,352 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3867403469979763, 'Total loss': 0.3867403469979763} | train loss {'Reaction outcome loss': 0.24136861034463888, 'Total loss': 0.24136861034463888}
2023-01-05 00:46:05,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:05,352 INFO:     Epoch: 34
2023-01-05 00:46:07,552 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39467991292476656, 'Total loss': 0.39467991292476656} | train loss {'Reaction outcome loss': 0.24199197712330828, 'Total loss': 0.24199197712330828}
2023-01-05 00:46:07,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:07,552 INFO:     Epoch: 35
2023-01-05 00:46:09,797 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3906943455338478, 'Total loss': 0.3906943455338478} | train loss {'Reaction outcome loss': 0.2392150458210696, 'Total loss': 0.2392150458210696}
2023-01-05 00:46:09,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:09,798 INFO:     Epoch: 36
2023-01-05 00:46:12,016 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3944174278527498, 'Total loss': 0.3944174278527498} | train loss {'Reaction outcome loss': 0.23712681909007716, 'Total loss': 0.23712681909007716}
2023-01-05 00:46:12,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:12,017 INFO:     Epoch: 37
2023-01-05 00:46:14,234 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3772433857123057, 'Total loss': 0.3772433857123057} | train loss {'Reaction outcome loss': 0.22745850801279613, 'Total loss': 0.22745850801279613}
2023-01-05 00:46:14,234 INFO:     Found new best model at epoch 37
2023-01-05 00:46:14,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:14,235 INFO:     Epoch: 38
2023-01-05 00:46:16,504 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3974653214216232, 'Total loss': 0.3974653214216232} | train loss {'Reaction outcome loss': 0.22976647526536823, 'Total loss': 0.22976647526536823}
2023-01-05 00:46:16,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:16,504 INFO:     Epoch: 39
2023-01-05 00:46:18,762 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3961192985375722, 'Total loss': 0.3961192985375722} | train loss {'Reaction outcome loss': 0.2296238594456485, 'Total loss': 0.2296238594456485}
2023-01-05 00:46:18,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:18,762 INFO:     Epoch: 40
2023-01-05 00:46:21,015 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4157097041606903, 'Total loss': 0.4157097041606903} | train loss {'Reaction outcome loss': 0.22933485232535683, 'Total loss': 0.22933485232535683}
2023-01-05 00:46:21,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:21,015 INFO:     Epoch: 41
2023-01-05 00:46:23,266 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40083248217900597, 'Total loss': 0.40083248217900597} | train loss {'Reaction outcome loss': 0.22445417005259422, 'Total loss': 0.22445417005259422}
2023-01-05 00:46:23,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:23,266 INFO:     Epoch: 42
2023-01-05 00:46:25,510 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.36963896205027896, 'Total loss': 0.36963896205027896} | train loss {'Reaction outcome loss': 0.22105795755605837, 'Total loss': 0.22105795755605837}
2023-01-05 00:46:25,510 INFO:     Found new best model at epoch 42
2023-01-05 00:46:25,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:25,512 INFO:     Epoch: 43
2023-01-05 00:46:27,753 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.378469905257225, 'Total loss': 0.378469905257225} | train loss {'Reaction outcome loss': 0.2205365517778517, 'Total loss': 0.2205365517778517}
2023-01-05 00:46:27,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:27,754 INFO:     Epoch: 44
2023-01-05 00:46:29,962 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3790102988481522, 'Total loss': 0.3790102988481522} | train loss {'Reaction outcome loss': 0.21983820797088774, 'Total loss': 0.21983820797088774}
2023-01-05 00:46:29,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:29,962 INFO:     Epoch: 45
2023-01-05 00:46:32,188 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.37253928929567337, 'Total loss': 0.37253928929567337} | train loss {'Reaction outcome loss': 0.21770813277105563, 'Total loss': 0.21770813277105563}
2023-01-05 00:46:32,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:32,188 INFO:     Epoch: 46
2023-01-05 00:46:34,403 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.36493334571520486, 'Total loss': 0.36493334571520486} | train loss {'Reaction outcome loss': 0.2139746773826624, 'Total loss': 0.2139746773826624}
2023-01-05 00:46:34,404 INFO:     Found new best model at epoch 46
2023-01-05 00:46:34,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:34,405 INFO:     Epoch: 47
2023-01-05 00:46:36,618 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3841968139012655, 'Total loss': 0.3841968139012655} | train loss {'Reaction outcome loss': 0.21561459619350168, 'Total loss': 0.21561459619350168}
2023-01-05 00:46:36,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:36,618 INFO:     Epoch: 48
2023-01-05 00:46:38,834 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3740279018878937, 'Total loss': 0.3740279018878937} | train loss {'Reaction outcome loss': 0.2152741668486988, 'Total loss': 0.2152741668486988}
2023-01-05 00:46:38,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:38,835 INFO:     Epoch: 49
2023-01-05 00:46:41,067 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3796280801296234, 'Total loss': 0.3796280801296234} | train loss {'Reaction outcome loss': 0.20902754565102422, 'Total loss': 0.20902754565102422}
2023-01-05 00:46:41,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:41,067 INFO:     Epoch: 50
2023-01-05 00:46:43,302 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39182697534561156, 'Total loss': 0.39182697534561156} | train loss {'Reaction outcome loss': 0.20675963420246052, 'Total loss': 0.20675963420246052}
2023-01-05 00:46:43,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:43,303 INFO:     Epoch: 51
2023-01-05 00:46:45,571 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4008391280968984, 'Total loss': 0.4008391280968984} | train loss {'Reaction outcome loss': 0.2110163500055079, 'Total loss': 0.2110163500055079}
2023-01-05 00:46:45,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:45,571 INFO:     Epoch: 52
2023-01-05 00:46:47,754 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3805969665447871, 'Total loss': 0.3805969665447871} | train loss {'Reaction outcome loss': 0.20897603542325408, 'Total loss': 0.20897603542325408}
2023-01-05 00:46:47,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:47,755 INFO:     Epoch: 53
2023-01-05 00:46:50,020 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40051469057798383, 'Total loss': 0.40051469057798383} | train loss {'Reaction outcome loss': 0.20971877548830173, 'Total loss': 0.20971877548830173}
2023-01-05 00:46:50,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:50,020 INFO:     Epoch: 54
2023-01-05 00:46:52,291 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4289368326465289, 'Total loss': 0.4289368326465289} | train loss {'Reaction outcome loss': 0.2041412087338926, 'Total loss': 0.2041412087338926}
2023-01-05 00:46:52,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:52,291 INFO:     Epoch: 55
2023-01-05 00:46:54,531 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3987574686606725, 'Total loss': 0.3987574686606725} | train loss {'Reaction outcome loss': 0.21052337676750676, 'Total loss': 0.21052337676750676}
2023-01-05 00:46:54,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:54,532 INFO:     Epoch: 56
2023-01-05 00:46:56,805 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.36348371307055155, 'Total loss': 0.36348371307055155} | train loss {'Reaction outcome loss': 0.20597101391599065, 'Total loss': 0.20597101391599065}
2023-01-05 00:46:56,805 INFO:     Found new best model at epoch 56
2023-01-05 00:46:56,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:56,806 INFO:     Epoch: 57
2023-01-05 00:46:59,062 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4231885736187299, 'Total loss': 0.4231885736187299} | train loss {'Reaction outcome loss': 0.1999707389152222, 'Total loss': 0.1999707389152222}
2023-01-05 00:46:59,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:46:59,063 INFO:     Epoch: 58
2023-01-05 00:47:01,333 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3959659695625305, 'Total loss': 0.3959659695625305} | train loss {'Reaction outcome loss': 0.20120785161449375, 'Total loss': 0.20120785161449375}
2023-01-05 00:47:01,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:01,333 INFO:     Epoch: 59
2023-01-05 00:47:03,610 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3869535207748413, 'Total loss': 0.3869535207748413} | train loss {'Reaction outcome loss': 0.1966913248049196, 'Total loss': 0.1966913248049196}
2023-01-05 00:47:03,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:03,611 INFO:     Epoch: 60
2023-01-05 00:47:05,862 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40123553375403087, 'Total loss': 0.40123553375403087} | train loss {'Reaction outcome loss': 0.20011413226489125, 'Total loss': 0.20011413226489125}
2023-01-05 00:47:05,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:05,862 INFO:     Epoch: 61
2023-01-05 00:47:08,056 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3492596703271071, 'Total loss': 0.3492596703271071} | train loss {'Reaction outcome loss': 0.19394349539988684, 'Total loss': 0.19394349539988684}
2023-01-05 00:47:08,056 INFO:     Found new best model at epoch 61
2023-01-05 00:47:08,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:08,057 INFO:     Epoch: 62
2023-01-05 00:47:10,313 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39004956583182016, 'Total loss': 0.39004956583182016} | train loss {'Reaction outcome loss': 0.19391519560845105, 'Total loss': 0.19391519560845105}
2023-01-05 00:47:10,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:10,314 INFO:     Epoch: 63
2023-01-05 00:47:12,556 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36747471392154696, 'Total loss': 0.36747471392154696} | train loss {'Reaction outcome loss': 0.1936814733058053, 'Total loss': 0.1936814733058053}
2023-01-05 00:47:12,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:12,556 INFO:     Epoch: 64
2023-01-05 00:47:14,770 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3685629556576411, 'Total loss': 0.3685629556576411} | train loss {'Reaction outcome loss': 0.19217040839299077, 'Total loss': 0.19217040839299077}
2023-01-05 00:47:14,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:14,770 INFO:     Epoch: 65
2023-01-05 00:47:17,037 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3867465923229853, 'Total loss': 0.3867465923229853} | train loss {'Reaction outcome loss': 0.19300518349646875, 'Total loss': 0.19300518349646875}
2023-01-05 00:47:17,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:17,037 INFO:     Epoch: 66
2023-01-05 00:47:19,285 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37768458140393096, 'Total loss': 0.37768458140393096} | train loss {'Reaction outcome loss': 0.19621903042473732, 'Total loss': 0.19621903042473732}
2023-01-05 00:47:19,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:19,285 INFO:     Epoch: 67
2023-01-05 00:47:21,482 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40549307465553286, 'Total loss': 0.40549307465553286} | train loss {'Reaction outcome loss': 0.1921886587717204, 'Total loss': 0.1921886587717204}
2023-01-05 00:47:21,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:21,483 INFO:     Epoch: 68
2023-01-05 00:47:23,699 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3784667566418648, 'Total loss': 0.3784667566418648} | train loss {'Reaction outcome loss': 0.1902642963565079, 'Total loss': 0.1902642963565079}
2023-01-05 00:47:23,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:23,700 INFO:     Epoch: 69
2023-01-05 00:47:25,900 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41388029158115386, 'Total loss': 0.41388029158115386} | train loss {'Reaction outcome loss': 0.1908322430353625, 'Total loss': 0.1908322430353625}
2023-01-05 00:47:25,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:25,900 INFO:     Epoch: 70
2023-01-05 00:47:28,128 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3787176092465719, 'Total loss': 0.3787176092465719} | train loss {'Reaction outcome loss': 0.19110993854029085, 'Total loss': 0.19110993854029085}
2023-01-05 00:47:28,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:28,128 INFO:     Epoch: 71
2023-01-05 00:47:30,370 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3897248069445292, 'Total loss': 0.3897248069445292} | train loss {'Reaction outcome loss': 0.19201319397928107, 'Total loss': 0.19201319397928107}
2023-01-05 00:47:30,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:30,371 INFO:     Epoch: 72
2023-01-05 00:47:32,580 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3840681672096252, 'Total loss': 0.3840681672096252} | train loss {'Reaction outcome loss': 0.1876409768718648, 'Total loss': 0.1876409768718648}
2023-01-05 00:47:32,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:32,581 INFO:     Epoch: 73
2023-01-05 00:47:34,739 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40395657122135165, 'Total loss': 0.40395657122135165} | train loss {'Reaction outcome loss': 0.18347711518527907, 'Total loss': 0.18347711518527907}
2023-01-05 00:47:34,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:34,739 INFO:     Epoch: 74
2023-01-05 00:47:37,004 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38266878177722297, 'Total loss': 0.38266878177722297} | train loss {'Reaction outcome loss': 0.18478133239268935, 'Total loss': 0.18478133239268935}
2023-01-05 00:47:37,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:37,004 INFO:     Epoch: 75
2023-01-05 00:47:39,181 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42843330403168994, 'Total loss': 0.42843330403168994} | train loss {'Reaction outcome loss': 0.18441218550784333, 'Total loss': 0.18441218550784333}
2023-01-05 00:47:39,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:39,182 INFO:     Epoch: 76
2023-01-05 00:47:41,409 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42215983433028065, 'Total loss': 0.42215983433028065} | train loss {'Reaction outcome loss': 0.1874465491346988, 'Total loss': 0.1874465491346988}
2023-01-05 00:47:41,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:41,410 INFO:     Epoch: 77
2023-01-05 00:47:43,638 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43274754484494526, 'Total loss': 0.43274754484494526} | train loss {'Reaction outcome loss': 0.18128403589391698, 'Total loss': 0.18128403589391698}
2023-01-05 00:47:43,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:43,638 INFO:     Epoch: 78
2023-01-05 00:47:45,877 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4128369907538096, 'Total loss': 0.4128369907538096} | train loss {'Reaction outcome loss': 0.18877964405282419, 'Total loss': 0.18877964405282419}
2023-01-05 00:47:45,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:45,878 INFO:     Epoch: 79
2023-01-05 00:47:48,146 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39422419369220735, 'Total loss': 0.39422419369220735} | train loss {'Reaction outcome loss': 0.18264529623077772, 'Total loss': 0.18264529623077772}
2023-01-05 00:47:48,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:48,146 INFO:     Epoch: 80
2023-01-05 00:47:50,413 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37736972694595655, 'Total loss': 0.37736972694595655} | train loss {'Reaction outcome loss': 0.18311757615528704, 'Total loss': 0.18311757615528704}
2023-01-05 00:47:50,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:50,413 INFO:     Epoch: 81
2023-01-05 00:47:52,635 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3814723710219065, 'Total loss': 0.3814723710219065} | train loss {'Reaction outcome loss': 0.1859040385892191, 'Total loss': 0.1859040385892191}
2023-01-05 00:47:52,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:52,636 INFO:     Epoch: 82
2023-01-05 00:47:54,928 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.36883353448162476, 'Total loss': 0.36883353448162476} | train loss {'Reaction outcome loss': 0.18497421546244072, 'Total loss': 0.18497421546244072}
2023-01-05 00:47:54,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:54,928 INFO:     Epoch: 83
2023-01-05 00:47:57,196 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.35988194644451144, 'Total loss': 0.35988194644451144} | train loss {'Reaction outcome loss': 0.18373795087190364, 'Total loss': 0.18373795087190364}
2023-01-05 00:47:57,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:57,196 INFO:     Epoch: 84
2023-01-05 00:47:59,454 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37901993791262306, 'Total loss': 0.37901993791262306} | train loss {'Reaction outcome loss': 0.17752586645561705, 'Total loss': 0.17752586645561705}
2023-01-05 00:47:59,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:47:59,455 INFO:     Epoch: 85
2023-01-05 00:48:01,742 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3496871213118235, 'Total loss': 0.3496871213118235} | train loss {'Reaction outcome loss': 0.17815480341576712, 'Total loss': 0.17815480341576712}
2023-01-05 00:48:01,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:01,742 INFO:     Epoch: 86
2023-01-05 00:48:04,013 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3656894197066625, 'Total loss': 0.3656894197066625} | train loss {'Reaction outcome loss': 0.1756423558747322, 'Total loss': 0.1756423558747322}
2023-01-05 00:48:04,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:04,014 INFO:     Epoch: 87
2023-01-05 00:48:06,284 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.36852850914001467, 'Total loss': 0.36852850914001467} | train loss {'Reaction outcome loss': 0.17627716770509952, 'Total loss': 0.17627716770509952}
2023-01-05 00:48:06,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:06,285 INFO:     Epoch: 88
2023-01-05 00:48:08,508 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40504063069820406, 'Total loss': 0.40504063069820406} | train loss {'Reaction outcome loss': 0.17719616915438902, 'Total loss': 0.17719616915438902}
2023-01-05 00:48:08,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:08,508 INFO:     Epoch: 89
2023-01-05 00:48:10,710 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3865404263138771, 'Total loss': 0.3865404263138771} | train loss {'Reaction outcome loss': 0.17705646159282015, 'Total loss': 0.17705646159282015}
2023-01-05 00:48:10,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:10,710 INFO:     Epoch: 90
2023-01-05 00:48:12,985 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.36120201150576275, 'Total loss': 0.36120201150576275} | train loss {'Reaction outcome loss': 0.18364861111294492, 'Total loss': 0.18364861111294492}
2023-01-05 00:48:12,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:12,985 INFO:     Epoch: 91
2023-01-05 00:48:15,233 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39546767274538674, 'Total loss': 0.39546767274538674} | train loss {'Reaction outcome loss': 0.17632728854416188, 'Total loss': 0.17632728854416188}
2023-01-05 00:48:15,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:15,235 INFO:     Epoch: 92
2023-01-05 00:48:17,479 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3702963461478551, 'Total loss': 0.3702963461478551} | train loss {'Reaction outcome loss': 0.1718868784915777, 'Total loss': 0.1718868784915777}
2023-01-05 00:48:17,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:17,480 INFO:     Epoch: 93
2023-01-05 00:48:19,731 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.363143157462279, 'Total loss': 0.363143157462279} | train loss {'Reaction outcome loss': 0.17790272235130683, 'Total loss': 0.17790272235130683}
2023-01-05 00:48:19,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:19,731 INFO:     Epoch: 94
2023-01-05 00:48:21,991 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3547663648923238, 'Total loss': 0.3547663648923238} | train loss {'Reaction outcome loss': 0.1703745832117039, 'Total loss': 0.1703745832117039}
2023-01-05 00:48:21,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:21,992 INFO:     Epoch: 95
2023-01-05 00:48:24,264 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4019620974858602, 'Total loss': 0.4019620974858602} | train loss {'Reaction outcome loss': 0.17090407202847382, 'Total loss': 0.17090407202847382}
2023-01-05 00:48:24,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:24,264 INFO:     Epoch: 96
2023-01-05 00:48:26,520 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.36374142915010454, 'Total loss': 0.36374142915010454} | train loss {'Reaction outcome loss': 0.17173193372443102, 'Total loss': 0.17173193372443102}
2023-01-05 00:48:26,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:26,521 INFO:     Epoch: 97
2023-01-05 00:48:28,799 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.36680485506852467, 'Total loss': 0.36680485506852467} | train loss {'Reaction outcome loss': 0.1690454373946447, 'Total loss': 0.1690454373946447}
2023-01-05 00:48:28,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:28,800 INFO:     Epoch: 98
2023-01-05 00:48:31,061 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39723049600919086, 'Total loss': 0.39723049600919086} | train loss {'Reaction outcome loss': 0.1690254820433415, 'Total loss': 0.1690254820433415}
2023-01-05 00:48:31,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:31,061 INFO:     Epoch: 99
2023-01-05 00:48:33,258 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3996423800786336, 'Total loss': 0.3996423800786336} | train loss {'Reaction outcome loss': 0.175343751147497, 'Total loss': 0.175343751147497}
2023-01-05 00:48:33,258 INFO:     Best model found after epoch 62 of 100.
2023-01-05 00:48:33,258 INFO:   Done with stage: TRAINING
2023-01-05 00:48:33,258 INFO:   Starting stage: EVALUATION
2023-01-05 00:48:33,387 INFO:   Done with stage: EVALUATION
2023-01-05 00:48:33,387 INFO:   Leaving out SEQ value Fold_9
2023-01-05 00:48:33,400 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 00:48:33,400 INFO:   Starting stage: FEATURE SCALING
2023-01-05 00:48:34,050 INFO:   Done with stage: FEATURE SCALING
2023-01-05 00:48:34,051 INFO:   Starting stage: SCALING TARGETS
2023-01-05 00:48:34,123 INFO:   Done with stage: SCALING TARGETS
2023-01-05 00:48:34,124 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:48:34,124 INFO:     No hyperparam tuning for this model
2023-01-05 00:48:34,124 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 00:48:34,124 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 00:48:34,124 INFO:     None feature selector for col prot
2023-01-05 00:48:34,125 INFO:     None feature selector for col prot
2023-01-05 00:48:34,125 INFO:     None feature selector for col prot
2023-01-05 00:48:34,125 INFO:     None feature selector for col chem
2023-01-05 00:48:34,125 INFO:     None feature selector for col chem
2023-01-05 00:48:34,125 INFO:     None feature selector for col chem
2023-01-05 00:48:34,125 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 00:48:34,126 INFO:   Starting stage: BUILD MODEL
2023-01-05 00:48:34,127 INFO:     Number of params in model 72931
2023-01-05 00:48:34,130 INFO:   Done with stage: BUILD MODEL
2023-01-05 00:48:34,130 INFO:   Starting stage: TRAINING
2023-01-05 00:48:34,191 INFO:     Val loss before train {'Reaction outcome loss': 1.0376712838808695, 'Total loss': 1.0376712838808695}
2023-01-05 00:48:34,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:34,192 INFO:     Epoch: 0
2023-01-05 00:48:36,451 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6520604828993479, 'Total loss': 0.6520604828993479} | train loss {'Reaction outcome loss': 0.9309751377373502, 'Total loss': 0.9309751377373502}
2023-01-05 00:48:36,451 INFO:     Found new best model at epoch 0
2023-01-05 00:48:36,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:36,453 INFO:     Epoch: 1
2023-01-05 00:48:38,711 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.492401792605718, 'Total loss': 0.492401792605718} | train loss {'Reaction outcome loss': 0.6440671256918838, 'Total loss': 0.6440671256918838}
2023-01-05 00:48:38,711 INFO:     Found new best model at epoch 1
2023-01-05 00:48:38,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:38,712 INFO:     Epoch: 2
2023-01-05 00:48:40,960 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.43364717364311217, 'Total loss': 0.43364717364311217} | train loss {'Reaction outcome loss': 0.5433709793277017, 'Total loss': 0.5433709793277017}
2023-01-05 00:48:40,960 INFO:     Found new best model at epoch 2
2023-01-05 00:48:40,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:40,962 INFO:     Epoch: 3
2023-01-05 00:48:43,210 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4121375322341919, 'Total loss': 0.4121375322341919} | train loss {'Reaction outcome loss': 0.5048209127254676, 'Total loss': 0.5048209127254676}
2023-01-05 00:48:43,210 INFO:     Found new best model at epoch 3
2023-01-05 00:48:43,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:43,211 INFO:     Epoch: 4
2023-01-05 00:48:45,454 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.3828700522581736, 'Total loss': 0.3828700522581736} | train loss {'Reaction outcome loss': 0.47903506590080436, 'Total loss': 0.47903506590080436}
2023-01-05 00:48:45,454 INFO:     Found new best model at epoch 4
2023-01-05 00:48:45,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:45,456 INFO:     Epoch: 5
2023-01-05 00:48:47,701 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.39606422583262124, 'Total loss': 0.39606422583262124} | train loss {'Reaction outcome loss': 0.4547270194397888, 'Total loss': 0.4547270194397888}
2023-01-05 00:48:47,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:47,701 INFO:     Epoch: 6
2023-01-05 00:48:49,958 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.36426831781864166, 'Total loss': 0.36426831781864166} | train loss {'Reaction outcome loss': 0.4381882304446333, 'Total loss': 0.4381882304446333}
2023-01-05 00:48:49,958 INFO:     Found new best model at epoch 6
2023-01-05 00:48:49,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:49,959 INFO:     Epoch: 7
2023-01-05 00:48:52,217 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.34597007632255555, 'Total loss': 0.34597007632255555} | train loss {'Reaction outcome loss': 0.4181430909820188, 'Total loss': 0.4181430909820188}
2023-01-05 00:48:52,218 INFO:     Found new best model at epoch 7
2023-01-05 00:48:52,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:52,219 INFO:     Epoch: 8
2023-01-05 00:48:54,452 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3557333638270696, 'Total loss': 0.3557333638270696} | train loss {'Reaction outcome loss': 0.40312063479728566, 'Total loss': 0.40312063479728566}
2023-01-05 00:48:54,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:54,452 INFO:     Epoch: 9
2023-01-05 00:48:56,677 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3241467535495758, 'Total loss': 0.3241467535495758} | train loss {'Reaction outcome loss': 0.38896817771339975, 'Total loss': 0.38896817771339975}
2023-01-05 00:48:56,677 INFO:     Found new best model at epoch 9
2023-01-05 00:48:56,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:56,679 INFO:     Epoch: 10
2023-01-05 00:48:58,953 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.317084534962972, 'Total loss': 0.317084534962972} | train loss {'Reaction outcome loss': 0.4054382595139137, 'Total loss': 0.4054382595139137}
2023-01-05 00:48:58,954 INFO:     Found new best model at epoch 10
2023-01-05 00:48:58,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:48:58,955 INFO:     Epoch: 11
2023-01-05 00:49:01,214 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3371608704328537, 'Total loss': 0.3371608704328537} | train loss {'Reaction outcome loss': 0.3681690176355018, 'Total loss': 0.3681690176355018}
2023-01-05 00:49:01,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:01,215 INFO:     Epoch: 12
2023-01-05 00:49:03,390 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.31944616734981535, 'Total loss': 0.31944616734981535} | train loss {'Reaction outcome loss': 0.3588203020763762, 'Total loss': 0.3588203020763762}
2023-01-05 00:49:03,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:03,390 INFO:     Epoch: 13
2023-01-05 00:49:05,633 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3298932373523712, 'Total loss': 0.3298932373523712} | train loss {'Reaction outcome loss': 0.3522320234223498, 'Total loss': 0.3522320234223498}
2023-01-05 00:49:05,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:05,633 INFO:     Epoch: 14
2023-01-05 00:49:07,883 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3098839044570923, 'Total loss': 0.3098839044570923} | train loss {'Reaction outcome loss': 0.3408921755514098, 'Total loss': 0.3408921755514098}
2023-01-05 00:49:07,883 INFO:     Found new best model at epoch 14
2023-01-05 00:49:07,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:07,885 INFO:     Epoch: 15
2023-01-05 00:49:10,159 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.31315486232439677, 'Total loss': 0.31315486232439677} | train loss {'Reaction outcome loss': 0.3528439556180999, 'Total loss': 0.3528439556180999}
2023-01-05 00:49:10,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:10,159 INFO:     Epoch: 16
2023-01-05 00:49:12,379 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3005586672574282, 'Total loss': 0.3005586672574282} | train loss {'Reaction outcome loss': 0.3316650605065397, 'Total loss': 0.3316650605065397}
2023-01-05 00:49:12,380 INFO:     Found new best model at epoch 16
2023-01-05 00:49:12,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:12,381 INFO:     Epoch: 17
2023-01-05 00:49:14,568 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.30044338007767996, 'Total loss': 0.30044338007767996} | train loss {'Reaction outcome loss': 0.3144295780744026, 'Total loss': 0.3144295780744026}
2023-01-05 00:49:14,568 INFO:     Found new best model at epoch 17
2023-01-05 00:49:14,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:14,569 INFO:     Epoch: 18
2023-01-05 00:49:16,846 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.33985306322574615, 'Total loss': 0.33985306322574615} | train loss {'Reaction outcome loss': 0.3088930690613832, 'Total loss': 0.3088930690613832}
2023-01-05 00:49:16,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:16,847 INFO:     Epoch: 19
2023-01-05 00:49:19,121 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.30310767740011213, 'Total loss': 0.30310767740011213} | train loss {'Reaction outcome loss': 0.3087281624962022, 'Total loss': 0.3087281624962022}
2023-01-05 00:49:19,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:19,121 INFO:     Epoch: 20
2023-01-05 00:49:21,387 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.30857644776503246, 'Total loss': 0.30857644776503246} | train loss {'Reaction outcome loss': 0.3027683959715406, 'Total loss': 0.3027683959715406}
2023-01-05 00:49:21,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:21,388 INFO:     Epoch: 21
2023-01-05 00:49:23,657 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.31810634235541024, 'Total loss': 0.31810634235541024} | train loss {'Reaction outcome loss': 0.28670277236285957, 'Total loss': 0.28670277236285957}
2023-01-05 00:49:23,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:23,657 INFO:     Epoch: 22
2023-01-05 00:49:25,923 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.32191389203071596, 'Total loss': 0.32191389203071596} | train loss {'Reaction outcome loss': 0.28329221191951004, 'Total loss': 0.28329221191951004}
2023-01-05 00:49:25,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:25,923 INFO:     Epoch: 23
2023-01-05 00:49:28,174 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.305341574549675, 'Total loss': 0.305341574549675} | train loss {'Reaction outcome loss': 0.27520748568560416, 'Total loss': 0.27520748568560416}
2023-01-05 00:49:28,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:28,175 INFO:     Epoch: 24
2023-01-05 00:49:30,437 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.30484076142311095, 'Total loss': 0.30484076142311095} | train loss {'Reaction outcome loss': 0.26795151854014915, 'Total loss': 0.26795151854014915}
2023-01-05 00:49:30,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:30,437 INFO:     Epoch: 25
2023-01-05 00:49:32,652 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.2903948279718558, 'Total loss': 0.2903948279718558} | train loss {'Reaction outcome loss': 0.2668358018323172, 'Total loss': 0.2668358018323172}
2023-01-05 00:49:32,652 INFO:     Found new best model at epoch 25
2023-01-05 00:49:32,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:32,653 INFO:     Epoch: 26
2023-01-05 00:49:34,937 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3274529630939166, 'Total loss': 0.3274529630939166} | train loss {'Reaction outcome loss': 0.2589389451138719, 'Total loss': 0.2589389451138719}
2023-01-05 00:49:34,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:34,938 INFO:     Epoch: 27
2023-01-05 00:49:37,229 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.28113941301902134, 'Total loss': 0.28113941301902134} | train loss {'Reaction outcome loss': 0.2556126065133814, 'Total loss': 0.2556126065133814}
2023-01-05 00:49:37,229 INFO:     Found new best model at epoch 27
2023-01-05 00:49:37,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:37,231 INFO:     Epoch: 28
2023-01-05 00:49:39,513 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3119838361938794, 'Total loss': 0.3119838361938794} | train loss {'Reaction outcome loss': 0.252501913504075, 'Total loss': 0.252501913504075}
2023-01-05 00:49:39,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:39,513 INFO:     Epoch: 29
2023-01-05 00:49:41,770 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.31641972561677295, 'Total loss': 0.31641972561677295} | train loss {'Reaction outcome loss': 0.25087020555983525, 'Total loss': 0.25087020555983525}
2023-01-05 00:49:41,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:41,771 INFO:     Epoch: 30
2023-01-05 00:49:43,980 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.30049522320429484, 'Total loss': 0.30049522320429484} | train loss {'Reaction outcome loss': 0.2430819329144298, 'Total loss': 0.2430819329144298}
2023-01-05 00:49:43,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:43,980 INFO:     Epoch: 31
2023-01-05 00:49:46,215 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3025243947903315, 'Total loss': 0.3025243947903315} | train loss {'Reaction outcome loss': 0.23851144570600835, 'Total loss': 0.23851144570600835}
2023-01-05 00:49:46,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:46,215 INFO:     Epoch: 32
2023-01-05 00:49:48,473 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3210374191403389, 'Total loss': 0.3210374191403389} | train loss {'Reaction outcome loss': 0.2371939569576711, 'Total loss': 0.2371939569576711}
2023-01-05 00:49:48,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:48,473 INFO:     Epoch: 33
2023-01-05 00:49:50,707 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3079260100920995, 'Total loss': 0.3079260100920995} | train loss {'Reaction outcome loss': 0.23300014941301872, 'Total loss': 0.23300014941301872}
2023-01-05 00:49:50,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:50,707 INFO:     Epoch: 34
2023-01-05 00:49:52,874 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3201542009909948, 'Total loss': 0.3201542009909948} | train loss {'Reaction outcome loss': 0.22614122182805685, 'Total loss': 0.22614122182805685}
2023-01-05 00:49:52,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:52,874 INFO:     Epoch: 35
2023-01-05 00:49:54,917 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.30845755338668823, 'Total loss': 0.30845755338668823} | train loss {'Reaction outcome loss': 0.22763515550363134, 'Total loss': 0.22763515550363134}
2023-01-05 00:49:54,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:54,917 INFO:     Epoch: 36
2023-01-05 00:49:57,190 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.33228420118490853, 'Total loss': 0.33228420118490853} | train loss {'Reaction outcome loss': 0.22257335806278972, 'Total loss': 0.22257335806278972}
2023-01-05 00:49:57,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:57,192 INFO:     Epoch: 37
2023-01-05 00:49:59,435 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.32998886952797574, 'Total loss': 0.32998886952797574} | train loss {'Reaction outcome loss': 0.22456099731388732, 'Total loss': 0.22456099731388732}
2023-01-05 00:49:59,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:49:59,436 INFO:     Epoch: 38
2023-01-05 00:50:01,693 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3316179350018501, 'Total loss': 0.3316179350018501} | train loss {'Reaction outcome loss': 0.2195030718812368, 'Total loss': 0.2195030718812368}
2023-01-05 00:50:01,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:01,693 INFO:     Epoch: 39
2023-01-05 00:50:03,829 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.35568051716933646, 'Total loss': 0.35568051716933646} | train loss {'Reaction outcome loss': 0.2156252353148454, 'Total loss': 0.2156252353148454}
2023-01-05 00:50:03,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:03,829 INFO:     Epoch: 40
2023-01-05 00:50:06,037 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3517771561940511, 'Total loss': 0.3517771561940511} | train loss {'Reaction outcome loss': 0.214867052980253, 'Total loss': 0.214867052980253}
2023-01-05 00:50:06,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:06,037 INFO:     Epoch: 41
2023-01-05 00:50:08,281 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.34909039636452993, 'Total loss': 0.34909039636452993} | train loss {'Reaction outcome loss': 0.2107100898281425, 'Total loss': 0.2107100898281425}
2023-01-05 00:50:08,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:08,282 INFO:     Epoch: 42
2023-01-05 00:50:10,522 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3307342360417048, 'Total loss': 0.3307342360417048} | train loss {'Reaction outcome loss': 0.20944355499080342, 'Total loss': 0.20944355499080342}
2023-01-05 00:50:10,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:10,522 INFO:     Epoch: 43
2023-01-05 00:50:12,767 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3386313130458196, 'Total loss': 0.3386313130458196} | train loss {'Reaction outcome loss': 0.21298338515760776, 'Total loss': 0.21298338515760776}
2023-01-05 00:50:12,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:12,767 INFO:     Epoch: 44
2023-01-05 00:50:14,976 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3444188872973124, 'Total loss': 0.3444188872973124} | train loss {'Reaction outcome loss': 0.20090398147358032, 'Total loss': 0.20090398147358032}
2023-01-05 00:50:14,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:14,977 INFO:     Epoch: 45
2023-01-05 00:50:17,198 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3548650718604525, 'Total loss': 0.3548650718604525} | train loss {'Reaction outcome loss': 0.20024866037124742, 'Total loss': 0.20024866037124742}
2023-01-05 00:50:17,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:17,199 INFO:     Epoch: 46
2023-01-05 00:50:19,476 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.34100545446077984, 'Total loss': 0.34100545446077984} | train loss {'Reaction outcome loss': 0.20082613716426684, 'Total loss': 0.20082613716426684}
2023-01-05 00:50:19,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:19,476 INFO:     Epoch: 47
2023-01-05 00:50:21,822 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.34097808549801506, 'Total loss': 0.34097808549801506} | train loss {'Reaction outcome loss': 0.19828815413943696, 'Total loss': 0.19828815413943696}
2023-01-05 00:50:21,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:21,822 INFO:     Epoch: 48
2023-01-05 00:50:24,155 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.33508734839657944, 'Total loss': 0.33508734839657944} | train loss {'Reaction outcome loss': 0.1984036514458358, 'Total loss': 0.1984036514458358}
2023-01-05 00:50:24,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:24,155 INFO:     Epoch: 49
2023-01-05 00:50:26,457 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.34208072622617086, 'Total loss': 0.34208072622617086} | train loss {'Reaction outcome loss': 0.19744599762244447, 'Total loss': 0.19744599762244447}
2023-01-05 00:50:26,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:26,458 INFO:     Epoch: 50
2023-01-05 00:50:28,651 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3330704440673192, 'Total loss': 0.3330704440673192} | train loss {'Reaction outcome loss': 0.1968281166623785, 'Total loss': 0.1968281166623785}
2023-01-05 00:50:28,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:28,652 INFO:     Epoch: 51
2023-01-05 00:50:30,878 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3489567180474599, 'Total loss': 0.3489567180474599} | train loss {'Reaction outcome loss': 0.19070297263670657, 'Total loss': 0.19070297263670657}
2023-01-05 00:50:30,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:30,878 INFO:     Epoch: 52
2023-01-05 00:50:33,092 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36026025083847346, 'Total loss': 0.36026025083847346} | train loss {'Reaction outcome loss': 0.19555640404544555, 'Total loss': 0.19555640404544555}
2023-01-05 00:50:33,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:33,094 INFO:     Epoch: 53
2023-01-05 00:50:35,330 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.35832607597112653, 'Total loss': 0.35832607597112653} | train loss {'Reaction outcome loss': 0.1919693126034437, 'Total loss': 0.1919693126034437}
2023-01-05 00:50:35,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:35,330 INFO:     Epoch: 54
2023-01-05 00:50:37,577 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3382211742301782, 'Total loss': 0.3382211742301782} | train loss {'Reaction outcome loss': 0.18915762230618924, 'Total loss': 0.18915762230618924}
2023-01-05 00:50:37,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:37,577 INFO:     Epoch: 55
2023-01-05 00:50:39,779 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3362876271208127, 'Total loss': 0.3362876271208127} | train loss {'Reaction outcome loss': 0.1878577343190757, 'Total loss': 0.1878577343190757}
2023-01-05 00:50:39,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:39,780 INFO:     Epoch: 56
2023-01-05 00:50:42,029 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.35060656319061917, 'Total loss': 0.35060656319061917} | train loss {'Reaction outcome loss': 0.1877925059694014, 'Total loss': 0.1877925059694014}
2023-01-05 00:50:42,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:42,029 INFO:     Epoch: 57
2023-01-05 00:50:44,269 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.37016761203606924, 'Total loss': 0.37016761203606924} | train loss {'Reaction outcome loss': 0.18490277126893753, 'Total loss': 0.18490277126893753}
2023-01-05 00:50:44,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:44,269 INFO:     Epoch: 58
2023-01-05 00:50:46,531 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3396831010778745, 'Total loss': 0.3396831010778745} | train loss {'Reaction outcome loss': 0.1814600418565401, 'Total loss': 0.1814600418565401}
2023-01-05 00:50:46,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:46,531 INFO:     Epoch: 59
2023-01-05 00:50:48,738 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.34897321462631226, 'Total loss': 0.34897321462631226} | train loss {'Reaction outcome loss': 0.18951651655420984, 'Total loss': 0.18951651655420984}
2023-01-05 00:50:48,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:48,738 INFO:     Epoch: 60
2023-01-05 00:50:50,967 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.35732602775096894, 'Total loss': 0.35732602775096894} | train loss {'Reaction outcome loss': 0.18307177557785442, 'Total loss': 0.18307177557785442}
2023-01-05 00:50:50,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:50,967 INFO:     Epoch: 61
2023-01-05 00:50:53,212 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37370959545175236, 'Total loss': 0.37370959545175236} | train loss {'Reaction outcome loss': 0.1879079699426876, 'Total loss': 0.1879079699426876}
2023-01-05 00:50:53,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:53,213 INFO:     Epoch: 62
2023-01-05 00:50:55,419 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3277575521419446, 'Total loss': 0.3277575521419446} | train loss {'Reaction outcome loss': 0.1813186208465081, 'Total loss': 0.1813186208465081}
2023-01-05 00:50:55,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:55,419 INFO:     Epoch: 63
2023-01-05 00:50:57,686 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.33854252795378365, 'Total loss': 0.33854252795378365} | train loss {'Reaction outcome loss': 0.17984519890157663, 'Total loss': 0.17984519890157663}
2023-01-05 00:50:57,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:57,686 INFO:     Epoch: 64
2023-01-05 00:50:59,948 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3435988465944926, 'Total loss': 0.3435988465944926} | train loss {'Reaction outcome loss': 0.1766441543822757, 'Total loss': 0.1766441543822757}
2023-01-05 00:50:59,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:50:59,948 INFO:     Epoch: 65
2023-01-05 00:51:02,152 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.33794329067071277, 'Total loss': 0.33794329067071277} | train loss {'Reaction outcome loss': 0.1768583793166107, 'Total loss': 0.1768583793166107}
2023-01-05 00:51:02,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:02,153 INFO:     Epoch: 66
2023-01-05 00:51:04,410 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3439304053783417, 'Total loss': 0.3439304053783417} | train loss {'Reaction outcome loss': 0.17451285751388018, 'Total loss': 0.17451285751388018}
2023-01-05 00:51:04,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:04,410 INFO:     Epoch: 67
2023-01-05 00:51:06,650 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.34506300166249276, 'Total loss': 0.34506300166249276} | train loss {'Reaction outcome loss': 0.17365878538323054, 'Total loss': 0.17365878538323054}
2023-01-05 00:51:06,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:06,650 INFO:     Epoch: 68
2023-01-05 00:51:08,876 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.36925601263840996, 'Total loss': 0.36925601263840996} | train loss {'Reaction outcome loss': 0.17596608952389678, 'Total loss': 0.17596608952389678}
2023-01-05 00:51:08,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:08,877 INFO:     Epoch: 69
2023-01-05 00:51:11,035 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3631650537252426, 'Total loss': 0.3631650537252426} | train loss {'Reaction outcome loss': 0.17446888253882364, 'Total loss': 0.17446888253882364}
2023-01-05 00:51:11,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:11,035 INFO:     Epoch: 70
2023-01-05 00:51:13,291 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3561430941025416, 'Total loss': 0.3561430941025416} | train loss {'Reaction outcome loss': 0.17412278382951205, 'Total loss': 0.17412278382951205}
2023-01-05 00:51:13,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:13,291 INFO:     Epoch: 71
2023-01-05 00:51:15,597 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3359949618577957, 'Total loss': 0.3359949618577957} | train loss {'Reaction outcome loss': 0.17375545900655112, 'Total loss': 0.17375545900655112}
2023-01-05 00:51:15,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:15,598 INFO:     Epoch: 72
2023-01-05 00:51:17,850 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3483448108037313, 'Total loss': 0.3483448108037313} | train loss {'Reaction outcome loss': 0.17095172669370726, 'Total loss': 0.17095172669370726}
2023-01-05 00:51:17,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:17,850 INFO:     Epoch: 73
2023-01-05 00:51:20,093 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38131873607635497, 'Total loss': 0.38131873607635497} | train loss {'Reaction outcome loss': 0.17406448759834017, 'Total loss': 0.17406448759834017}
2023-01-05 00:51:20,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:20,093 INFO:     Epoch: 74
2023-01-05 00:51:22,284 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.33780892578264077, 'Total loss': 0.33780892578264077} | train loss {'Reaction outcome loss': 0.16899316333254558, 'Total loss': 0.16899316333254558}
2023-01-05 00:51:22,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:22,284 INFO:     Epoch: 75
2023-01-05 00:51:24,498 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.34849310566981634, 'Total loss': 0.34849310566981634} | train loss {'Reaction outcome loss': 0.16729243638743038, 'Total loss': 0.16729243638743038}
2023-01-05 00:51:24,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:24,498 INFO:     Epoch: 76
2023-01-05 00:51:26,722 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3464765867839257, 'Total loss': 0.3464765867839257} | train loss {'Reaction outcome loss': 0.16916372385753345, 'Total loss': 0.16916372385753345}
2023-01-05 00:51:26,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:26,723 INFO:     Epoch: 77
2023-01-05 00:51:28,968 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.34618631303310393, 'Total loss': 0.34618631303310393} | train loss {'Reaction outcome loss': 0.17359390966466098, 'Total loss': 0.17359390966466098}
2023-01-05 00:51:28,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:28,969 INFO:     Epoch: 78
2023-01-05 00:51:31,196 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3359844227631887, 'Total loss': 0.3359844227631887} | train loss {'Reaction outcome loss': 0.16930682561080862, 'Total loss': 0.16930682561080862}
2023-01-05 00:51:31,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:31,196 INFO:     Epoch: 79
2023-01-05 00:51:33,376 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3468445437649886, 'Total loss': 0.3468445437649886} | train loss {'Reaction outcome loss': 0.17400411494494672, 'Total loss': 0.17400411494494672}
2023-01-05 00:51:33,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:33,376 INFO:     Epoch: 80
2023-01-05 00:51:35,598 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.33907082080841067, 'Total loss': 0.33907082080841067} | train loss {'Reaction outcome loss': 0.17720962044850108, 'Total loss': 0.17720962044850108}
2023-01-05 00:51:35,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:35,598 INFO:     Epoch: 81
2023-01-05 00:51:37,868 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.343677328278621, 'Total loss': 0.343677328278621} | train loss {'Reaction outcome loss': 0.16273323114939453, 'Total loss': 0.16273323114939453}
2023-01-05 00:51:37,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:37,868 INFO:     Epoch: 82
2023-01-05 00:51:40,116 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3459399608274301, 'Total loss': 0.3459399608274301} | train loss {'Reaction outcome loss': 0.16339166824152504, 'Total loss': 0.16339166824152504}
2023-01-05 00:51:40,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:40,116 INFO:     Epoch: 83
2023-01-05 00:51:42,357 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.35632204413414004, 'Total loss': 0.35632204413414004} | train loss {'Reaction outcome loss': 0.16207113353782363, 'Total loss': 0.16207113353782363}
2023-01-05 00:51:42,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:42,357 INFO:     Epoch: 84
2023-01-05 00:51:44,566 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.34741473297278086, 'Total loss': 0.34741473297278086} | train loss {'Reaction outcome loss': 0.16104282206166923, 'Total loss': 0.16104282206166923}
2023-01-05 00:51:44,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:44,568 INFO:     Epoch: 85
2023-01-05 00:51:46,842 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.35048454453547795, 'Total loss': 0.35048454453547795} | train loss {'Reaction outcome loss': 0.16118747488582047, 'Total loss': 0.16118747488582047}
2023-01-05 00:51:46,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:46,842 INFO:     Epoch: 86
2023-01-05 00:51:49,083 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3276248815159003, 'Total loss': 0.3276248815159003} | train loss {'Reaction outcome loss': 0.15943331255972304, 'Total loss': 0.15943331255972304}
2023-01-05 00:51:49,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:49,083 INFO:     Epoch: 87
2023-01-05 00:51:51,309 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.35636364221572875, 'Total loss': 0.35636364221572875} | train loss {'Reaction outcome loss': 0.1639832737200777, 'Total loss': 0.1639832737200777}
2023-01-05 00:51:51,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:51,310 INFO:     Epoch: 88
2023-01-05 00:51:53,556 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.36085468071202437, 'Total loss': 0.36085468071202437} | train loss {'Reaction outcome loss': 0.16186314164762103, 'Total loss': 0.16186314164762103}
2023-01-05 00:51:53,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:53,556 INFO:     Epoch: 89
2023-01-05 00:51:55,761 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.36308610439300537, 'Total loss': 0.36308610439300537} | train loss {'Reaction outcome loss': 0.16189990476498456, 'Total loss': 0.16189990476498456}
2023-01-05 00:51:55,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:55,762 INFO:     Epoch: 90
2023-01-05 00:51:58,071 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.34722884744405746, 'Total loss': 0.34722884744405746} | train loss {'Reaction outcome loss': 0.1583261211138618, 'Total loss': 0.1583261211138618}
2023-01-05 00:51:58,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:51:58,071 INFO:     Epoch: 91
2023-01-05 00:52:00,354 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.35617036720116935, 'Total loss': 0.35617036720116935} | train loss {'Reaction outcome loss': 0.15942265205355227, 'Total loss': 0.15942265205355227}
2023-01-05 00:52:00,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:00,354 INFO:     Epoch: 92
2023-01-05 00:52:02,617 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3368764281272888, 'Total loss': 0.3368764281272888} | train loss {'Reaction outcome loss': 0.16278468930344706, 'Total loss': 0.16278468930344706}
2023-01-05 00:52:02,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:02,618 INFO:     Epoch: 93
2023-01-05 00:52:04,856 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.34026959811647733, 'Total loss': 0.34026959811647733} | train loss {'Reaction outcome loss': 0.1623070327036987, 'Total loss': 0.1623070327036987}
2023-01-05 00:52:04,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:04,857 INFO:     Epoch: 94
2023-01-05 00:52:07,106 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.35724940051635107, 'Total loss': 0.35724940051635107} | train loss {'Reaction outcome loss': 0.16445117606654885, 'Total loss': 0.16445117606654885}
2023-01-05 00:52:07,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:07,106 INFO:     Epoch: 95
2023-01-05 00:52:09,383 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3430680051445961, 'Total loss': 0.3430680051445961} | train loss {'Reaction outcome loss': 0.15749316455027007, 'Total loss': 0.15749316455027007}
2023-01-05 00:52:09,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:09,383 INFO:     Epoch: 96
2023-01-05 00:52:11,616 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37088362624247867, 'Total loss': 0.37088362624247867} | train loss {'Reaction outcome loss': 0.1548438400915483, 'Total loss': 0.1548438400915483}
2023-01-05 00:52:11,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:11,616 INFO:     Epoch: 97
2023-01-05 00:52:13,845 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3740587033331394, 'Total loss': 0.3740587033331394} | train loss {'Reaction outcome loss': 0.155419534769691, 'Total loss': 0.155419534769691}
2023-01-05 00:52:13,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:13,845 INFO:     Epoch: 98
2023-01-05 00:52:16,090 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.36957201262315115, 'Total loss': 0.36957201262315115} | train loss {'Reaction outcome loss': 0.15403792072944614, 'Total loss': 0.15403792072944614}
2023-01-05 00:52:16,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 00:52:16,090 INFO:     Epoch: 99
2023-01-05 00:52:18,396 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.34685326417287193, 'Total loss': 0.34685326417287193} | train loss {'Reaction outcome loss': 0.16049488886357352, 'Total loss': 0.16049488886357352}
2023-01-05 00:52:18,396 INFO:     Best model found after epoch 28 of 100.
2023-01-05 00:52:18,396 INFO:   Done with stage: TRAINING
2023-01-05 00:52:18,396 INFO:   Starting stage: EVALUATION
2023-01-05 00:52:18,532 INFO:   Done with stage: EVALUATION
2023-01-05 00:52:18,532 INFO: Done with stage: RUNNING SPLITS
2023-01-05 00:52:18,532 INFO: Starting stage: COMPUTE METRICS
2023-01-05 00:52:19,723 INFO: Done with stage: COMPUTE METRICS
2023-01-05 00:52:19,723 INFO: Starting stage: EXPORT RESULTS
2023-01-05 00:52:19,741 INFO:   Final results averaged over 50 folds: 
2023-01-05 00:52:19,744 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.165855           NaN  0.319422       NaN
2023-01-05 00:52:21,418 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2023-01-05 00:52:21,425 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2023-01-05 00:52:21,426 DEBUG:   interactive is False
2023-01-05 00:52:21,426 DEBUG:   platform is linux
2023-01-05 00:52:21,427 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.naming', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2023-01-05 00:52:21,601 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2023-01-05 00:52:21,603 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2023-01-05 00:52:22,041 DEBUG:   Loaded backend agg version unknown.
2023-01-05 00:52:22,044 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-05 00:52:22,044 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,044 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,044 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,044 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 00:52:22,044 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 00:52:22,044 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 00:52:22,044 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,044 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,045 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,045 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,045 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 00:52:22,045 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 00:52:22,045 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,045 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,045 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,045 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 00:52:22,045 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,045 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 00:52:22,045 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,045 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,045 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-05 00:52:22,045 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 00:52:22,045 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 00:52:22,045 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,045 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,046 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,046 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,046 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,046 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,046 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,046 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,046 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,046 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-05 00:52:22,046 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,046 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,046 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,046 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,046 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 00:52:22,046 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 00:52:22,046 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,046 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,046 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,047 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 00:52:22,047 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,047 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-05 00:52:22,084 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2023-01-05 00:52:22,084 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,084 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,084 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,084 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 00:52:22,084 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 00:52:22,084 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 00:52:22,085 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,085 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,085 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,085 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,085 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 00:52:22,085 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 00:52:22,085 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,085 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,085 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,085 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 00:52:22,085 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,085 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 00:52:22,085 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,085 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,085 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-05 00:52:22,085 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 00:52:22,086 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 00:52:22,086 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,086 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,086 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,086 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,086 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,086 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,086 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,086 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,086 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,086 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-05 00:52:22,086 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,086 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,086 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,086 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,086 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 00:52:22,086 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 00:52:22,087 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,087 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,087 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,087 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 00:52:22,087 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,087 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-05 00:52:22,095 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-05 00:52:22,096 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,096 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,096 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,096 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 00:52:22,096 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 00:52:22,096 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 00:52:22,096 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,096 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,096 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,096 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,096 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 00:52:22,096 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 00:52:22,097 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,097 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,097 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,097 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 00:52:22,097 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,097 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 00:52:22,097 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,097 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,097 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-05 00:52:22,097 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 00:52:22,097 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 00:52:22,097 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,097 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,097 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,097 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,097 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,097 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,098 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,098 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,098 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,098 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-05 00:52:22,098 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,098 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,098 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,098 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,098 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 00:52:22,098 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 00:52:22,098 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,098 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,098 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 00:52:22,098 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 00:52:22,098 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 00:52:22,098 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-05 00:52:22,387 INFO: Done with stage: EXPORT RESULTS
2023-01-05 00:52:22,387 INFO: Starting stage: SAVE MODEL
2023-01-05 00:52:22,446 INFO: Done with stage: SAVE MODEL
2023-01-05 00:52:22,481 INFO: Wall time for program:  11237.14 seconds
