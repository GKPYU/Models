2023-01-03 22:56:02,956 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffndot/627c1b67d370404b2f30e216599aa6ef/2023_01_03-225546",
  "seed": 1,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "morgan1024",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffndot",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.95,
  "val_size": 0.05,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.00015553873022161447,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 30,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2023-01-03 22:56:02,964 INFO: Starting stage: BUILD FEATURIZERS
2023-01-03 22:56:02,967 INFO:   Creating esm representation model
2023-01-03 22:56:02,968 INFO:   Done esm representation model
2023-01-03 22:56:02,968 INFO: Done with stage: BUILD FEATURIZERS
2023-01-03 22:56:02,968 INFO: Starting stage: BUILDING DATASET
2023-01-03 22:56:03,023 INFO: Done with stage: BUILDING DATASET
2023-01-03 22:56:03,023 INFO: Starting stage: FEATURIZING DATA
2023-01-03 22:56:03,023 INFO:   Featurizing proteins
2023-01-03 22:56:03,025 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2023-01-03 22:56:03,056 INFO:   Loaded feature cache of size 489
2023-01-03 22:56:03,057 INFO:   Starting to pool ESM Embeddings
2023-01-03 22:56:03,178 INFO:   Featurizing molecules
2023-01-03 22:56:03,180 INFO:   Loading cache file data/program_cache/739a0d20a6c75d701bd3663cec254635
2023-01-03 22:56:03,182 INFO:   Loaded feature cache of size 498
2023-01-03 22:56:04,524 INFO: Done with stage: FEATURIZING DATA
2023-01-03 22:56:04,525 INFO: Starting stage: RUNNING SPLITS
2023-01-03 22:56:04,533 INFO:   Leaving out SEQ value Fold_0
2023-01-03 22:56:04,548 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-03 22:56:04,548 INFO:   Starting stage: FEATURE SCALING
2023-01-03 22:56:05,208 INFO:   Done with stage: FEATURE SCALING
2023-01-03 22:56:05,209 INFO:   Starting stage: SCALING TARGETS
2023-01-03 22:56:05,277 INFO:   Done with stage: SCALING TARGETS
2023-01-03 22:56:05,277 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 22:56:05,277 INFO:     No hyperparam tuning for this model
2023-01-03 22:56:05,277 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 22:56:05,277 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 22:56:05,278 INFO:     None feature selector for col prot
2023-01-03 22:56:05,278 INFO:     None feature selector for col prot
2023-01-03 22:56:05,278 INFO:     None feature selector for col prot
2023-01-03 22:56:05,279 INFO:     None feature selector for col chem
2023-01-03 22:56:05,279 INFO:     None feature selector for col chem
2023-01-03 22:56:05,279 INFO:     None feature selector for col chem
2023-01-03 22:56:05,279 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 22:56:05,279 INFO:   Starting stage: BUILD MODEL
2023-01-03 22:56:05,280 INFO:     Number of params in model 70141
2023-01-03 22:56:05,280 INFO:   Done with stage: BUILD MODEL
2023-01-03 22:56:05,280 INFO:   Starting stage: TRAINING
2023-01-03 22:56:06,901 INFO:     Val loss before train {'Reaction outcome loss': 0.9049340188503265, 'Total loss': 0.9049340188503265}
2023-01-03 22:56:06,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:06,902 INFO:     Epoch: 0
2023-01-03 22:56:08,480 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.579918862382571, 'Total loss': 0.579918862382571} | train loss {'Reaction outcome loss': 0.8489556230686524, 'Total loss': 0.8489556230686524}
2023-01-03 22:56:08,480 INFO:     Found new best model at epoch 0
2023-01-03 22:56:08,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:08,481 INFO:     Epoch: 1
2023-01-03 22:56:10,058 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.504764876763026, 'Total loss': 0.504764876763026} | train loss {'Reaction outcome loss': 0.6057488310249733, 'Total loss': 0.6057488310249733}
2023-01-03 22:56:10,058 INFO:     Found new best model at epoch 1
2023-01-03 22:56:10,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:10,059 INFO:     Epoch: 2
2023-01-03 22:56:11,636 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49052660663922626, 'Total loss': 0.49052660663922626} | train loss {'Reaction outcome loss': 0.5228108094507085, 'Total loss': 0.5228108094507085}
2023-01-03 22:56:11,636 INFO:     Found new best model at epoch 2
2023-01-03 22:56:11,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:11,637 INFO:     Epoch: 3
2023-01-03 22:56:13,237 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46745381156603494, 'Total loss': 0.46745381156603494} | train loss {'Reaction outcome loss': 0.4830042350314039, 'Total loss': 0.4830042350314039}
2023-01-03 22:56:13,237 INFO:     Found new best model at epoch 3
2023-01-03 22:56:13,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:13,238 INFO:     Epoch: 4
2023-01-03 22:56:14,846 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47747415701548257, 'Total loss': 0.47747415701548257} | train loss {'Reaction outcome loss': 0.46150063125641794, 'Total loss': 0.46150063125641794}
2023-01-03 22:56:14,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:14,846 INFO:     Epoch: 5
2023-01-03 22:56:16,455 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4700851202011108, 'Total loss': 0.4700851202011108} | train loss {'Reaction outcome loss': 0.43991928768681954, 'Total loss': 0.43991928768681954}
2023-01-03 22:56:16,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:16,455 INFO:     Epoch: 6
2023-01-03 22:56:18,054 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45706087350845337, 'Total loss': 0.45706087350845337} | train loss {'Reaction outcome loss': 0.42593419759264795, 'Total loss': 0.42593419759264795}
2023-01-03 22:56:18,054 INFO:     Found new best model at epoch 6
2023-01-03 22:56:18,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:18,055 INFO:     Epoch: 7
2023-01-03 22:56:19,642 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4316757912437121, 'Total loss': 0.4316757912437121} | train loss {'Reaction outcome loss': 0.41150555099213953, 'Total loss': 0.41150555099213953}
2023-01-03 22:56:19,642 INFO:     Found new best model at epoch 7
2023-01-03 22:56:19,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:19,643 INFO:     Epoch: 8
2023-01-03 22:56:21,233 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43169331351915996, 'Total loss': 0.43169331351915996} | train loss {'Reaction outcome loss': 0.4005298050932395, 'Total loss': 0.4005298050932395}
2023-01-03 22:56:21,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:21,233 INFO:     Epoch: 9
2023-01-03 22:56:22,819 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4466083427270254, 'Total loss': 0.4466083427270254} | train loss {'Reaction outcome loss': 0.38955666288569735, 'Total loss': 0.38955666288569735}
2023-01-03 22:56:22,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:22,820 INFO:     Epoch: 10
2023-01-03 22:56:24,432 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42689924836158755, 'Total loss': 0.42689924836158755} | train loss {'Reaction outcome loss': 0.3813057506914104, 'Total loss': 0.3813057506914104}
2023-01-03 22:56:24,432 INFO:     Found new best model at epoch 10
2023-01-03 22:56:24,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:24,433 INFO:     Epoch: 11
2023-01-03 22:56:26,027 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44087396264076234, 'Total loss': 0.44087396264076234} | train loss {'Reaction outcome loss': 0.37268216839749296, 'Total loss': 0.37268216839749296}
2023-01-03 22:56:26,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:26,028 INFO:     Epoch: 12
2023-01-03 22:56:27,612 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4425812800725301, 'Total loss': 0.4425812800725301} | train loss {'Reaction outcome loss': 0.36519548496156384, 'Total loss': 0.36519548496156384}
2023-01-03 22:56:27,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:27,612 INFO:     Epoch: 13
2023-01-03 22:56:29,202 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4285362442334493, 'Total loss': 0.4285362442334493} | train loss {'Reaction outcome loss': 0.3600995930068659, 'Total loss': 0.3600995930068659}
2023-01-03 22:56:29,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:29,203 INFO:     Epoch: 14
2023-01-03 22:56:30,772 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4199071109294891, 'Total loss': 0.4199071109294891} | train loss {'Reaction outcome loss': 0.3525760170522627, 'Total loss': 0.3525760170522627}
2023-01-03 22:56:30,772 INFO:     Found new best model at epoch 14
2023-01-03 22:56:30,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:30,773 INFO:     Epoch: 15
2023-01-03 22:56:32,359 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43735849261283877, 'Total loss': 0.43735849261283877} | train loss {'Reaction outcome loss': 0.3470312867845808, 'Total loss': 0.3470312867845808}
2023-01-03 22:56:32,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:32,359 INFO:     Epoch: 16
2023-01-03 22:56:33,961 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45147016247113547, 'Total loss': 0.45147016247113547} | train loss {'Reaction outcome loss': 0.33933932527954325, 'Total loss': 0.33933932527954325}
2023-01-03 22:56:33,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:33,962 INFO:     Epoch: 17
2023-01-03 22:56:35,529 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43776739835739137, 'Total loss': 0.43776739835739137} | train loss {'Reaction outcome loss': 0.3327337559585497, 'Total loss': 0.3327337559585497}
2023-01-03 22:56:35,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:35,529 INFO:     Epoch: 18
2023-01-03 22:56:37,109 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44565289715925854, 'Total loss': 0.44565289715925854} | train loss {'Reaction outcome loss': 0.3298348591495783, 'Total loss': 0.3298348591495783}
2023-01-03 22:56:37,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:37,109 INFO:     Epoch: 19
2023-01-03 22:56:38,672 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45806187987327573, 'Total loss': 0.45806187987327573} | train loss {'Reaction outcome loss': 0.32570633322218834, 'Total loss': 0.32570633322218834}
2023-01-03 22:56:38,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:38,673 INFO:     Epoch: 20
2023-01-03 22:56:40,244 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4441966285308202, 'Total loss': 0.4441966285308202} | train loss {'Reaction outcome loss': 0.3178770177803197, 'Total loss': 0.3178770177803197}
2023-01-03 22:56:40,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:40,244 INFO:     Epoch: 21
2023-01-03 22:56:41,833 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4379376868406932, 'Total loss': 0.4379376868406932} | train loss {'Reaction outcome loss': 0.3136530896246215, 'Total loss': 0.3136530896246215}
2023-01-03 22:56:41,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:41,833 INFO:     Epoch: 22
2023-01-03 22:56:43,448 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46087577044963834, 'Total loss': 0.46087577044963834} | train loss {'Reaction outcome loss': 0.31250409361643666, 'Total loss': 0.31250409361643666}
2023-01-03 22:56:43,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:43,448 INFO:     Epoch: 23
2023-01-03 22:56:45,011 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4401486734549204, 'Total loss': 0.4401486734549204} | train loss {'Reaction outcome loss': 0.3052068529002396, 'Total loss': 0.3052068529002396}
2023-01-03 22:56:45,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:45,012 INFO:     Epoch: 24
2023-01-03 22:56:46,593 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4408800562222799, 'Total loss': 0.4408800562222799} | train loss {'Reaction outcome loss': 0.30187269690490903, 'Total loss': 0.30187269690490903}
2023-01-03 22:56:46,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:46,594 INFO:     Epoch: 25
2023-01-03 22:56:48,178 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4486091911792755, 'Total loss': 0.4486091911792755} | train loss {'Reaction outcome loss': 0.29774998956029014, 'Total loss': 0.29774998956029014}
2023-01-03 22:56:48,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:48,179 INFO:     Epoch: 26
2023-01-03 22:56:49,765 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4424356977144877, 'Total loss': 0.4424356977144877} | train loss {'Reaction outcome loss': 0.2957090717696008, 'Total loss': 0.2957090717696008}
2023-01-03 22:56:49,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:49,765 INFO:     Epoch: 27
2023-01-03 22:56:51,360 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.451852015654246, 'Total loss': 0.451852015654246} | train loss {'Reaction outcome loss': 0.29152739198107425, 'Total loss': 0.29152739198107425}
2023-01-03 22:56:51,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:51,360 INFO:     Epoch: 28
2023-01-03 22:56:52,954 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48176281054814657, 'Total loss': 0.48176281054814657} | train loss {'Reaction outcome loss': 0.2858386368869425, 'Total loss': 0.2858386368869425}
2023-01-03 22:56:52,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:52,955 INFO:     Epoch: 29
2023-01-03 22:56:54,542 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42118119100729623, 'Total loss': 0.42118119100729623} | train loss {'Reaction outcome loss': 0.28574403945779625, 'Total loss': 0.28574403945779625}
2023-01-03 22:56:54,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:54,542 INFO:     Epoch: 30
2023-01-03 22:56:56,131 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4205209126075109, 'Total loss': 0.4205209126075109} | train loss {'Reaction outcome loss': 0.280371099683173, 'Total loss': 0.280371099683173}
2023-01-03 22:56:56,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:56,131 INFO:     Epoch: 31
2023-01-03 22:56:57,710 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4209263374408086, 'Total loss': 0.4209263374408086} | train loss {'Reaction outcome loss': 0.2792002968080751, 'Total loss': 0.2792002968080751}
2023-01-03 22:56:57,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:57,711 INFO:     Epoch: 32
2023-01-03 22:56:59,310 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.411644313732783, 'Total loss': 0.411644313732783} | train loss {'Reaction outcome loss': 0.27422331616575846, 'Total loss': 0.27422331616575846}
2023-01-03 22:56:59,310 INFO:     Found new best model at epoch 32
2023-01-03 22:56:59,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:56:59,311 INFO:     Epoch: 33
2023-01-03 22:57:00,888 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41680969173709553, 'Total loss': 0.41680969173709553} | train loss {'Reaction outcome loss': 0.27272194430177465, 'Total loss': 0.27272194430177465}
2023-01-03 22:57:00,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:00,889 INFO:     Epoch: 34
2023-01-03 22:57:02,473 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4356024205684662, 'Total loss': 0.4356024205684662} | train loss {'Reaction outcome loss': 0.26999958159722687, 'Total loss': 0.26999958159722687}
2023-01-03 22:57:02,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:02,474 INFO:     Epoch: 35
2023-01-03 22:57:04,067 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4295487701892853, 'Total loss': 0.4295487701892853} | train loss {'Reaction outcome loss': 0.26438144579420597, 'Total loss': 0.26438144579420597}
2023-01-03 22:57:04,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:04,067 INFO:     Epoch: 36
2023-01-03 22:57:05,671 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42944112916787464, 'Total loss': 0.42944112916787464} | train loss {'Reaction outcome loss': 0.26269930913607714, 'Total loss': 0.26269930913607714}
2023-01-03 22:57:05,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:05,671 INFO:     Epoch: 37
2023-01-03 22:57:07,240 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41301727096239726, 'Total loss': 0.41301727096239726} | train loss {'Reaction outcome loss': 0.2598864666489891, 'Total loss': 0.2598864666489891}
2023-01-03 22:57:07,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:07,240 INFO:     Epoch: 38
2023-01-03 22:57:08,856 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4104451100031535, 'Total loss': 0.4104451100031535} | train loss {'Reaction outcome loss': 0.255899071331808, 'Total loss': 0.255899071331808}
2023-01-03 22:57:08,856 INFO:     Found new best model at epoch 38
2023-01-03 22:57:08,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:08,857 INFO:     Epoch: 39
2023-01-03 22:57:10,452 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.449712797999382, 'Total loss': 0.449712797999382} | train loss {'Reaction outcome loss': 0.25365999242761633, 'Total loss': 0.25365999242761633}
2023-01-03 22:57:10,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:10,453 INFO:     Epoch: 40
2023-01-03 22:57:12,017 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4373282462358475, 'Total loss': 0.4373282462358475} | train loss {'Reaction outcome loss': 0.25165826644434597, 'Total loss': 0.25165826644434597}
2023-01-03 22:57:12,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:12,017 INFO:     Epoch: 41
2023-01-03 22:57:13,623 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4157888382673264, 'Total loss': 0.4157888382673264} | train loss {'Reaction outcome loss': 0.2518286813364361, 'Total loss': 0.2518286813364361}
2023-01-03 22:57:13,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:13,624 INFO:     Epoch: 42
2023-01-03 22:57:15,207 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46003552675247195, 'Total loss': 0.46003552675247195} | train loss {'Reaction outcome loss': 0.24705527062381144, 'Total loss': 0.24705527062381144}
2023-01-03 22:57:15,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:15,207 INFO:     Epoch: 43
2023-01-03 22:57:16,796 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4375031610329946, 'Total loss': 0.4375031610329946} | train loss {'Reaction outcome loss': 0.24600341168808795, 'Total loss': 0.24600341168808795}
2023-01-03 22:57:16,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:16,796 INFO:     Epoch: 44
2023-01-03 22:57:18,413 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4558380534251531, 'Total loss': 0.4558380534251531} | train loss {'Reaction outcome loss': 0.24089048619999553, 'Total loss': 0.24089048619999553}
2023-01-03 22:57:18,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:18,413 INFO:     Epoch: 45
2023-01-03 22:57:19,996 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4470028380552928, 'Total loss': 0.4470028380552928} | train loss {'Reaction outcome loss': 0.23967700792756272, 'Total loss': 0.23967700792756272}
2023-01-03 22:57:19,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:19,997 INFO:     Epoch: 46
2023-01-03 22:57:21,584 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.50898730357488, 'Total loss': 0.50898730357488} | train loss {'Reaction outcome loss': 0.23835714641726496, 'Total loss': 0.23835714641726496}
2023-01-03 22:57:21,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:21,584 INFO:     Epoch: 47
2023-01-03 22:57:23,191 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4334728787342707, 'Total loss': 0.4334728787342707} | train loss {'Reaction outcome loss': 0.23523069635006316, 'Total loss': 0.23523069635006316}
2023-01-03 22:57:23,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:23,192 INFO:     Epoch: 48
2023-01-03 22:57:24,770 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4233162492513657, 'Total loss': 0.4233162492513657} | train loss {'Reaction outcome loss': 0.23161972611596732, 'Total loss': 0.23161972611596732}
2023-01-03 22:57:24,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:24,770 INFO:     Epoch: 49
2023-01-03 22:57:26,351 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41951187551021574, 'Total loss': 0.41951187551021574} | train loss {'Reaction outcome loss': 0.2302218549014939, 'Total loss': 0.2302218549014939}
2023-01-03 22:57:26,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:26,351 INFO:     Epoch: 50
2023-01-03 22:57:27,933 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4372657557328542, 'Total loss': 0.4372657557328542} | train loss {'Reaction outcome loss': 0.229445176615274, 'Total loss': 0.229445176615274}
2023-01-03 22:57:27,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:27,933 INFO:     Epoch: 51
2023-01-03 22:57:29,501 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44501846432685854, 'Total loss': 0.44501846432685854} | train loss {'Reaction outcome loss': 0.22775698657874222, 'Total loss': 0.22775698657874222}
2023-01-03 22:57:29,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:29,501 INFO:     Epoch: 52
2023-01-03 22:57:31,089 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4569922079642614, 'Total loss': 0.4569922079642614} | train loss {'Reaction outcome loss': 0.22735648181958076, 'Total loss': 0.22735648181958076}
2023-01-03 22:57:31,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:31,089 INFO:     Epoch: 53
2023-01-03 22:57:32,687 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.429287326335907, 'Total loss': 0.429287326335907} | train loss {'Reaction outcome loss': 0.22347430464548942, 'Total loss': 0.22347430464548942}
2023-01-03 22:57:32,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:32,687 INFO:     Epoch: 54
2023-01-03 22:57:34,254 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43981282313664755, 'Total loss': 0.43981282313664755} | train loss {'Reaction outcome loss': 0.22311470718992935, 'Total loss': 0.22311470718992935}
2023-01-03 22:57:34,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:34,255 INFO:     Epoch: 55
2023-01-03 22:57:35,837 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4257822116216024, 'Total loss': 0.4257822116216024} | train loss {'Reaction outcome loss': 0.22053022656739849, 'Total loss': 0.22053022656739849}
2023-01-03 22:57:35,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:35,837 INFO:     Epoch: 56
2023-01-03 22:57:37,418 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.442685212691625, 'Total loss': 0.442685212691625} | train loss {'Reaction outcome loss': 0.21803337334221973, 'Total loss': 0.21803337334221973}
2023-01-03 22:57:37,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:37,418 INFO:     Epoch: 57
2023-01-03 22:57:38,987 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48751389781634014, 'Total loss': 0.48751389781634014} | train loss {'Reaction outcome loss': 0.21779437757509967, 'Total loss': 0.21779437757509967}
2023-01-03 22:57:38,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:38,987 INFO:     Epoch: 58
2023-01-03 22:57:40,556 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4333626131216685, 'Total loss': 0.4333626131216685} | train loss {'Reaction outcome loss': 0.21670774357127293, 'Total loss': 0.21670774357127293}
2023-01-03 22:57:40,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:40,556 INFO:     Epoch: 59
2023-01-03 22:57:42,134 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44143375257651013, 'Total loss': 0.44143375257651013} | train loss {'Reaction outcome loss': 0.214286235335109, 'Total loss': 0.214286235335109}
2023-01-03 22:57:42,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:42,134 INFO:     Epoch: 60
2023-01-03 22:57:43,729 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42350591719150543, 'Total loss': 0.42350591719150543} | train loss {'Reaction outcome loss': 0.210130654623384, 'Total loss': 0.210130654623384}
2023-01-03 22:57:43,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:43,729 INFO:     Epoch: 61
2023-01-03 22:57:45,320 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45112957855065666, 'Total loss': 0.45112957855065666} | train loss {'Reaction outcome loss': 0.21069851742832216, 'Total loss': 0.21069851742832216}
2023-01-03 22:57:45,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:45,321 INFO:     Epoch: 62
2023-01-03 22:57:46,917 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40436009702583153, 'Total loss': 0.40436009702583153} | train loss {'Reaction outcome loss': 0.21271783263582886, 'Total loss': 0.21271783263582886}
2023-01-03 22:57:46,917 INFO:     Found new best model at epoch 62
2023-01-03 22:57:46,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:46,918 INFO:     Epoch: 63
2023-01-03 22:57:48,500 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4192561666170756, 'Total loss': 0.4192561666170756} | train loss {'Reaction outcome loss': 0.2103767688539657, 'Total loss': 0.2103767688539657}
2023-01-03 22:57:48,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:48,500 INFO:     Epoch: 64
2023-01-03 22:57:50,103 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42782422999540964, 'Total loss': 0.42782422999540964} | train loss {'Reaction outcome loss': 0.20654243782108084, 'Total loss': 0.20654243782108084}
2023-01-03 22:57:50,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:50,103 INFO:     Epoch: 65
2023-01-03 22:57:51,681 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4386678208907445, 'Total loss': 0.4386678208907445} | train loss {'Reaction outcome loss': 0.2079199343210175, 'Total loss': 0.2079199343210175}
2023-01-03 22:57:51,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:51,682 INFO:     Epoch: 66
2023-01-03 22:57:53,265 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4545061727364858, 'Total loss': 0.4545061727364858} | train loss {'Reaction outcome loss': 0.2026713890852509, 'Total loss': 0.2026713890852509}
2023-01-03 22:57:53,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:53,266 INFO:     Epoch: 67
2023-01-03 22:57:54,858 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42976058820883434, 'Total loss': 0.42976058820883434} | train loss {'Reaction outcome loss': 0.2020332464204603, 'Total loss': 0.2020332464204603}
2023-01-03 22:57:54,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:54,859 INFO:     Epoch: 68
2023-01-03 22:57:56,446 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44919721484184266, 'Total loss': 0.44919721484184266} | train loss {'Reaction outcome loss': 0.20283096601620262, 'Total loss': 0.20283096601620262}
2023-01-03 22:57:56,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:56,446 INFO:     Epoch: 69
2023-01-03 22:57:58,049 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4267061988512675, 'Total loss': 0.4267061988512675} | train loss {'Reaction outcome loss': 0.20331692957616115, 'Total loss': 0.20331692957616115}
2023-01-03 22:57:58,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:58,049 INFO:     Epoch: 70
2023-01-03 22:57:59,616 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4162607436378797, 'Total loss': 0.4162607436378797} | train loss {'Reaction outcome loss': 0.2007194455412827, 'Total loss': 0.2007194455412827}
2023-01-03 22:57:59,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:57:59,616 INFO:     Epoch: 71
2023-01-03 22:58:01,176 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43613166610399884, 'Total loss': 0.43613166610399884} | train loss {'Reaction outcome loss': 0.19672292875528555, 'Total loss': 0.19672292875528555}
2023-01-03 22:58:01,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:01,176 INFO:     Epoch: 72
2023-01-03 22:58:02,761 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4275594453016917, 'Total loss': 0.4275594453016917} | train loss {'Reaction outcome loss': 0.1956899702589918, 'Total loss': 0.1956899702589918}
2023-01-03 22:58:02,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:02,762 INFO:     Epoch: 73
2023-01-03 22:58:04,363 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42454305787881214, 'Total loss': 0.42454305787881214} | train loss {'Reaction outcome loss': 0.1956382475165657, 'Total loss': 0.1956382475165657}
2023-01-03 22:58:04,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:04,364 INFO:     Epoch: 74
2023-01-03 22:58:05,941 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4670361528793971, 'Total loss': 0.4670361528793971} | train loss {'Reaction outcome loss': 0.19482134866584502, 'Total loss': 0.19482134866584502}
2023-01-03 22:58:05,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:05,941 INFO:     Epoch: 75
2023-01-03 22:58:07,531 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45185463031133016, 'Total loss': 0.45185463031133016} | train loss {'Reaction outcome loss': 0.19112164539970702, 'Total loss': 0.19112164539970702}
2023-01-03 22:58:07,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:07,531 INFO:     Epoch: 76
2023-01-03 22:58:09,116 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4564954688151677, 'Total loss': 0.4564954688151677} | train loss {'Reaction outcome loss': 0.19186177483210579, 'Total loss': 0.19186177483210579}
2023-01-03 22:58:09,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:09,116 INFO:     Epoch: 77
2023-01-03 22:58:10,724 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4275830974181493, 'Total loss': 0.4275830974181493} | train loss {'Reaction outcome loss': 0.1943286356512771, 'Total loss': 0.1943286356512771}
2023-01-03 22:58:10,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:10,724 INFO:     Epoch: 78
2023-01-03 22:58:12,329 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.472531267007192, 'Total loss': 0.472531267007192} | train loss {'Reaction outcome loss': 0.18979673295524038, 'Total loss': 0.18979673295524038}
2023-01-03 22:58:12,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:12,330 INFO:     Epoch: 79
2023-01-03 22:58:13,930 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5039415816466014, 'Total loss': 0.5039415816466014} | train loss {'Reaction outcome loss': 0.18717361870051222, 'Total loss': 0.18717361870051222}
2023-01-03 22:58:13,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:13,930 INFO:     Epoch: 80
2023-01-03 22:58:15,512 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42426295280456544, 'Total loss': 0.42426295280456544} | train loss {'Reaction outcome loss': 0.18827322873222085, 'Total loss': 0.18827322873222085}
2023-01-03 22:58:15,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:15,513 INFO:     Epoch: 81
2023-01-03 22:58:17,119 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4458704988161723, 'Total loss': 0.4458704988161723} | train loss {'Reaction outcome loss': 0.18883943425375463, 'Total loss': 0.18883943425375463}
2023-01-03 22:58:17,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:17,120 INFO:     Epoch: 82
2023-01-03 22:58:18,676 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40461429953575134, 'Total loss': 0.40461429953575134} | train loss {'Reaction outcome loss': 0.186955713172317, 'Total loss': 0.186955713172317}
2023-01-03 22:58:18,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:18,676 INFO:     Epoch: 83
2023-01-03 22:58:20,249 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45216177602609, 'Total loss': 0.45216177602609} | train loss {'Reaction outcome loss': 0.18363462509962666, 'Total loss': 0.18363462509962666}
2023-01-03 22:58:20,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:20,249 INFO:     Epoch: 84
2023-01-03 22:58:21,836 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4545491586128871, 'Total loss': 0.4545491586128871} | train loss {'Reaction outcome loss': 0.1871878785309774, 'Total loss': 0.1871878785309774}
2023-01-03 22:58:21,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:21,837 INFO:     Epoch: 85
2023-01-03 22:58:23,423 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4368479371070862, 'Total loss': 0.4368479371070862} | train loss {'Reaction outcome loss': 0.18511753149276033, 'Total loss': 0.18511753149276033}
2023-01-03 22:58:23,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:23,424 INFO:     Epoch: 86
2023-01-03 22:58:25,005 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43394997318585715, 'Total loss': 0.43394997318585715} | train loss {'Reaction outcome loss': 0.1848759596873989, 'Total loss': 0.1848759596873989}
2023-01-03 22:58:25,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:25,005 INFO:     Epoch: 87
2023-01-03 22:58:26,573 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42066538433233897, 'Total loss': 0.42066538433233897} | train loss {'Reaction outcome loss': 0.18177979589600265, 'Total loss': 0.18177979589600265}
2023-01-03 22:58:26,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:26,573 INFO:     Epoch: 88
2023-01-03 22:58:28,134 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5042251209417979, 'Total loss': 0.5042251209417979} | train loss {'Reaction outcome loss': 0.18171789344304648, 'Total loss': 0.18171789344304648}
2023-01-03 22:58:28,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:28,134 INFO:     Epoch: 89
2023-01-03 22:58:29,718 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46329765717188515, 'Total loss': 0.46329765717188515} | train loss {'Reaction outcome loss': 0.17847996379757103, 'Total loss': 0.17847996379757103}
2023-01-03 22:58:29,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:29,718 INFO:     Epoch: 90
2023-01-03 22:58:31,321 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4542852024237315, 'Total loss': 0.4542852024237315} | train loss {'Reaction outcome loss': 0.17999140050385024, 'Total loss': 0.17999140050385024}
2023-01-03 22:58:31,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:31,321 INFO:     Epoch: 91
2023-01-03 22:58:32,901 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42619309773047764, 'Total loss': 0.42619309773047764} | train loss {'Reaction outcome loss': 0.17743732580990146, 'Total loss': 0.17743732580990146}
2023-01-03 22:58:32,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:32,901 INFO:     Epoch: 92
2023-01-03 22:58:34,504 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46077910959720614, 'Total loss': 0.46077910959720614} | train loss {'Reaction outcome loss': 0.18176477530718724, 'Total loss': 0.18176477530718724}
2023-01-03 22:58:34,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:34,504 INFO:     Epoch: 93
2023-01-03 22:58:36,087 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42307299822568895, 'Total loss': 0.42307299822568895} | train loss {'Reaction outcome loss': 0.17645659958159093, 'Total loss': 0.17645659958159093}
2023-01-03 22:58:36,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:36,088 INFO:     Epoch: 94
2023-01-03 22:58:37,657 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.432341401775678, 'Total loss': 0.432341401775678} | train loss {'Reaction outcome loss': 0.17549975858421335, 'Total loss': 0.17549975858421335}
2023-01-03 22:58:37,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:37,658 INFO:     Epoch: 95
2023-01-03 22:58:39,263 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4673503577709198, 'Total loss': 0.4673503577709198} | train loss {'Reaction outcome loss': 0.17724114557729878, 'Total loss': 0.17724114557729878}
2023-01-03 22:58:39,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:39,263 INFO:     Epoch: 96
2023-01-03 22:58:40,860 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4348039170106252, 'Total loss': 0.4348039170106252} | train loss {'Reaction outcome loss': 0.17481553975676933, 'Total loss': 0.17481553975676933}
2023-01-03 22:58:40,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:40,860 INFO:     Epoch: 97
2023-01-03 22:58:42,445 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4286467301348845, 'Total loss': 0.4286467301348845} | train loss {'Reaction outcome loss': 0.1732083934089749, 'Total loss': 0.1732083934089749}
2023-01-03 22:58:42,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:42,445 INFO:     Epoch: 98
2023-01-03 22:58:44,048 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43751476804415385, 'Total loss': 0.43751476804415385} | train loss {'Reaction outcome loss': 0.17206833723782403, 'Total loss': 0.17206833723782403}
2023-01-03 22:58:44,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:44,048 INFO:     Epoch: 99
2023-01-03 22:58:45,618 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46670719385147097, 'Total loss': 0.46670719385147097} | train loss {'Reaction outcome loss': 0.17521530163266283, 'Total loss': 0.17521530163266283}
2023-01-03 22:58:45,618 INFO:     Best model found after epoch 63 of 100.
2023-01-03 22:58:45,618 INFO:   Done with stage: TRAINING
2023-01-03 22:58:45,618 INFO:   Starting stage: EVALUATION
2023-01-03 22:58:45,758 INFO:   Done with stage: EVALUATION
2023-01-03 22:58:45,758 INFO:   Leaving out SEQ value Fold_1
2023-01-03 22:58:45,771 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-03 22:58:45,771 INFO:   Starting stage: FEATURE SCALING
2023-01-03 22:58:46,429 INFO:   Done with stage: FEATURE SCALING
2023-01-03 22:58:46,429 INFO:   Starting stage: SCALING TARGETS
2023-01-03 22:58:46,499 INFO:   Done with stage: SCALING TARGETS
2023-01-03 22:58:46,499 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 22:58:46,499 INFO:     No hyperparam tuning for this model
2023-01-03 22:58:46,500 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 22:58:46,500 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 22:58:46,500 INFO:     None feature selector for col prot
2023-01-03 22:58:46,500 INFO:     None feature selector for col prot
2023-01-03 22:58:46,500 INFO:     None feature selector for col prot
2023-01-03 22:58:46,501 INFO:     None feature selector for col chem
2023-01-03 22:58:46,501 INFO:     None feature selector for col chem
2023-01-03 22:58:46,501 INFO:     None feature selector for col chem
2023-01-03 22:58:46,501 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 22:58:46,501 INFO:   Starting stage: BUILD MODEL
2023-01-03 22:58:46,502 INFO:     Number of params in model 70141
2023-01-03 22:58:46,505 INFO:   Done with stage: BUILD MODEL
2023-01-03 22:58:46,505 INFO:   Starting stage: TRAINING
2023-01-03 22:58:46,549 INFO:     Val loss before train {'Reaction outcome loss': 1.0409813841183981, 'Total loss': 1.0409813841183981}
2023-01-03 22:58:46,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:46,549 INFO:     Epoch: 0
2023-01-03 22:58:48,158 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7204283873240153, 'Total loss': 0.7204283873240153} | train loss {'Reaction outcome loss': 0.8578888389511384, 'Total loss': 0.8578888389511384}
2023-01-03 22:58:48,158 INFO:     Found new best model at epoch 0
2023-01-03 22:58:48,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:48,159 INFO:     Epoch: 1
2023-01-03 22:58:49,747 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6558164437611897, 'Total loss': 0.6558164437611897} | train loss {'Reaction outcome loss': 0.6181001029908657, 'Total loss': 0.6181001029908657}
2023-01-03 22:58:49,748 INFO:     Found new best model at epoch 1
2023-01-03 22:58:49,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:49,749 INFO:     Epoch: 2
2023-01-03 22:58:51,324 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6126861135164897, 'Total loss': 0.6126861135164897} | train loss {'Reaction outcome loss': 0.5315536226861287, 'Total loss': 0.5315536226861287}
2023-01-03 22:58:51,324 INFO:     Found new best model at epoch 2
2023-01-03 22:58:51,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:51,325 INFO:     Epoch: 3
2023-01-03 22:58:52,917 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.583270404736201, 'Total loss': 0.583270404736201} | train loss {'Reaction outcome loss': 0.48664758805281727, 'Total loss': 0.48664758805281727}
2023-01-03 22:58:52,918 INFO:     Found new best model at epoch 3
2023-01-03 22:58:52,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:52,919 INFO:     Epoch: 4
2023-01-03 22:58:54,506 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5753797133763631, 'Total loss': 0.5753797133763631} | train loss {'Reaction outcome loss': 0.4567863278384523, 'Total loss': 0.4567863278384523}
2023-01-03 22:58:54,507 INFO:     Found new best model at epoch 4
2023-01-03 22:58:54,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:54,507 INFO:     Epoch: 5
2023-01-03 22:58:56,100 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.548275907834371, 'Total loss': 0.548275907834371} | train loss {'Reaction outcome loss': 0.44737632367489993, 'Total loss': 0.44737632367489993}
2023-01-03 22:58:56,100 INFO:     Found new best model at epoch 5
2023-01-03 22:58:56,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:56,101 INFO:     Epoch: 6
2023-01-03 22:58:57,692 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5619336744149526, 'Total loss': 0.5619336744149526} | train loss {'Reaction outcome loss': 0.4309175255289976, 'Total loss': 0.4309175255289976}
2023-01-03 22:58:57,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:57,692 INFO:     Epoch: 7
2023-01-03 22:58:59,270 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5294642756382625, 'Total loss': 0.5294642756382625} | train loss {'Reaction outcome loss': 0.4096504048565808, 'Total loss': 0.4096504048565808}
2023-01-03 22:58:59,271 INFO:     Found new best model at epoch 7
2023-01-03 22:58:59,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:58:59,272 INFO:     Epoch: 8
2023-01-03 22:59:00,863 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5402133464813232, 'Total loss': 0.5402133464813232} | train loss {'Reaction outcome loss': 0.39717992551732756, 'Total loss': 0.39717992551732756}
2023-01-03 22:59:00,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:00,863 INFO:     Epoch: 9
2023-01-03 22:59:02,437 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5205333630243937, 'Total loss': 0.5205333630243937} | train loss {'Reaction outcome loss': 0.3836373904946874, 'Total loss': 0.3836373904946874}
2023-01-03 22:59:02,437 INFO:     Found new best model at epoch 9
2023-01-03 22:59:02,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:02,438 INFO:     Epoch: 10
2023-01-03 22:59:04,030 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.519244929154714, 'Total loss': 0.519244929154714} | train loss {'Reaction outcome loss': 0.37529614457077737, 'Total loss': 0.37529614457077737}
2023-01-03 22:59:04,030 INFO:     Found new best model at epoch 10
2023-01-03 22:59:04,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:04,031 INFO:     Epoch: 11
2023-01-03 22:59:05,628 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5455631295839946, 'Total loss': 0.5455631295839946} | train loss {'Reaction outcome loss': 0.3656997554328131, 'Total loss': 0.3656997554328131}
2023-01-03 22:59:05,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:05,628 INFO:     Epoch: 12
2023-01-03 22:59:07,222 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.519670327504476, 'Total loss': 0.519670327504476} | train loss {'Reaction outcome loss': 0.35869536292401777, 'Total loss': 0.35869536292401777}
2023-01-03 22:59:07,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:07,222 INFO:     Epoch: 13
2023-01-03 22:59:08,798 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5114144285519918, 'Total loss': 0.5114144285519918} | train loss {'Reaction outcome loss': 0.3486309737149302, 'Total loss': 0.3486309737149302}
2023-01-03 22:59:08,798 INFO:     Found new best model at epoch 13
2023-01-03 22:59:08,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:08,799 INFO:     Epoch: 14
2023-01-03 22:59:10,397 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5117791136105855, 'Total loss': 0.5117791136105855} | train loss {'Reaction outcome loss': 0.34557925342865614, 'Total loss': 0.34557925342865614}
2023-01-03 22:59:10,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:10,397 INFO:     Epoch: 15
2023-01-03 22:59:11,988 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5147056063016255, 'Total loss': 0.5147056063016255} | train loss {'Reaction outcome loss': 0.3448500860806393, 'Total loss': 0.3448500860806393}
2023-01-03 22:59:11,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:11,989 INFO:     Epoch: 16
2023-01-03 22:59:13,582 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5223306934038798, 'Total loss': 0.5223306934038798} | train loss {'Reaction outcome loss': 0.33739463048244733, 'Total loss': 0.33739463048244733}
2023-01-03 22:59:13,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:13,582 INFO:     Epoch: 17
2023-01-03 22:59:15,175 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.505737907687823, 'Total loss': 0.505737907687823} | train loss {'Reaction outcome loss': 0.327795655777057, 'Total loss': 0.327795655777057}
2023-01-03 22:59:15,175 INFO:     Found new best model at epoch 17
2023-01-03 22:59:15,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:15,176 INFO:     Epoch: 18
2023-01-03 22:59:16,759 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5056113044420878, 'Total loss': 0.5056113044420878} | train loss {'Reaction outcome loss': 0.32149039585635986, 'Total loss': 0.32149039585635986}
2023-01-03 22:59:16,759 INFO:     Found new best model at epoch 18
2023-01-03 22:59:16,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:16,760 INFO:     Epoch: 19
2023-01-03 22:59:18,375 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5032501955827077, 'Total loss': 0.5032501955827077} | train loss {'Reaction outcome loss': 0.31895448548206384, 'Total loss': 0.31895448548206384}
2023-01-03 22:59:18,375 INFO:     Found new best model at epoch 19
2023-01-03 22:59:18,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:18,376 INFO:     Epoch: 20
2023-01-03 22:59:19,955 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5081660230954488, 'Total loss': 0.5081660230954488} | train loss {'Reaction outcome loss': 0.3218697692551043, 'Total loss': 0.3218697692551043}
2023-01-03 22:59:19,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:19,955 INFO:     Epoch: 21
2023-01-03 22:59:21,548 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5046492675940196, 'Total loss': 0.5046492675940196} | train loss {'Reaction outcome loss': 0.31543701919693284, 'Total loss': 0.31543701919693284}
2023-01-03 22:59:21,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:21,549 INFO:     Epoch: 22
2023-01-03 22:59:23,173 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5160607814788818, 'Total loss': 0.5160607814788818} | train loss {'Reaction outcome loss': 0.30621524618101725, 'Total loss': 0.30621524618101725}
2023-01-03 22:59:23,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:23,173 INFO:     Epoch: 23
2023-01-03 22:59:24,795 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.49697134097417195, 'Total loss': 0.49697134097417195} | train loss {'Reaction outcome loss': 0.30197825145138346, 'Total loss': 0.30197825145138346}
2023-01-03 22:59:24,795 INFO:     Found new best model at epoch 23
2023-01-03 22:59:24,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:24,796 INFO:     Epoch: 24
2023-01-03 22:59:26,373 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48695021867752075, 'Total loss': 0.48695021867752075} | train loss {'Reaction outcome loss': 0.2980314728911912, 'Total loss': 0.2980314728911912}
2023-01-03 22:59:26,373 INFO:     Found new best model at epoch 24
2023-01-03 22:59:26,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:26,374 INFO:     Epoch: 25
2023-01-03 22:59:27,985 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4894740045070648, 'Total loss': 0.4894740045070648} | train loss {'Reaction outcome loss': 0.2911623299823723, 'Total loss': 0.2911623299823723}
2023-01-03 22:59:27,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:27,986 INFO:     Epoch: 26
2023-01-03 22:59:29,570 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5080617368221283, 'Total loss': 0.5080617368221283} | train loss {'Reaction outcome loss': 0.28693554368700186, 'Total loss': 0.28693554368700186}
2023-01-03 22:59:29,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:29,570 INFO:     Epoch: 27
2023-01-03 22:59:31,192 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49132270614306134, 'Total loss': 0.49132270614306134} | train loss {'Reaction outcome loss': 0.28446008261762734, 'Total loss': 0.28446008261762734}
2023-01-03 22:59:31,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:31,192 INFO:     Epoch: 28
2023-01-03 22:59:32,797 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4864607393741608, 'Total loss': 0.4864607393741608} | train loss {'Reaction outcome loss': 0.27946793181194074, 'Total loss': 0.27946793181194074}
2023-01-03 22:59:32,797 INFO:     Found new best model at epoch 28
2023-01-03 22:59:32,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:32,798 INFO:     Epoch: 29
2023-01-03 22:59:34,417 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49238657553990683, 'Total loss': 0.49238657553990683} | train loss {'Reaction outcome loss': 0.27786066539704113, 'Total loss': 0.27786066539704113}
2023-01-03 22:59:34,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:34,418 INFO:     Epoch: 30
2023-01-03 22:59:36,014 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4934812029202779, 'Total loss': 0.4934812029202779} | train loss {'Reaction outcome loss': 0.27475135123213346, 'Total loss': 0.27475135123213346}
2023-01-03 22:59:36,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:36,015 INFO:     Epoch: 31
2023-01-03 22:59:37,637 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4911530137062073, 'Total loss': 0.4911530137062073} | train loss {'Reaction outcome loss': 0.27148411838688713, 'Total loss': 0.27148411838688713}
2023-01-03 22:59:37,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:37,637 INFO:     Epoch: 32
2023-01-03 22:59:39,210 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.477704252799352, 'Total loss': 0.477704252799352} | train loss {'Reaction outcome loss': 0.2691797009547767, 'Total loss': 0.2691797009547767}
2023-01-03 22:59:39,210 INFO:     Found new best model at epoch 32
2023-01-03 22:59:39,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:39,211 INFO:     Epoch: 33
2023-01-03 22:59:40,832 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4657625049352646, 'Total loss': 0.4657625049352646} | train loss {'Reaction outcome loss': 0.26487110345961823, 'Total loss': 0.26487110345961823}
2023-01-03 22:59:40,832 INFO:     Found new best model at epoch 33
2023-01-03 22:59:40,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:40,833 INFO:     Epoch: 34
2023-01-03 22:59:42,430 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5059277842442195, 'Total loss': 0.5059277842442195} | train loss {'Reaction outcome loss': 0.2631467934562892, 'Total loss': 0.2631467934562892}
2023-01-03 22:59:42,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:42,430 INFO:     Epoch: 35
2023-01-03 22:59:44,029 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.515106733640035, 'Total loss': 0.515106733640035} | train loss {'Reaction outcome loss': 0.2620803645434047, 'Total loss': 0.2620803645434047}
2023-01-03 22:59:44,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:44,029 INFO:     Epoch: 36
2023-01-03 22:59:45,620 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4762344717979431, 'Total loss': 0.4762344717979431} | train loss {'Reaction outcome loss': 0.2565718923351201, 'Total loss': 0.2565718923351201}
2023-01-03 22:59:45,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:45,620 INFO:     Epoch: 37
2023-01-03 22:59:47,194 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5080135146776835, 'Total loss': 0.5080135146776835} | train loss {'Reaction outcome loss': 0.27324977112205134, 'Total loss': 0.27324977112205134}
2023-01-03 22:59:47,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:47,195 INFO:     Epoch: 38
2023-01-03 22:59:48,787 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4905800104141235, 'Total loss': 0.4905800104141235} | train loss {'Reaction outcome loss': 0.2579593006386489, 'Total loss': 0.2579593006386489}
2023-01-03 22:59:48,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:48,787 INFO:     Epoch: 39
2023-01-03 22:59:50,411 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49093345602353416, 'Total loss': 0.49093345602353416} | train loss {'Reaction outcome loss': 0.2637863974424376, 'Total loss': 0.2637863974424376}
2023-01-03 22:59:50,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:50,412 INFO:     Epoch: 40
2023-01-03 22:59:52,031 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4857495129108429, 'Total loss': 0.4857495129108429} | train loss {'Reaction outcome loss': 0.2531381064715485, 'Total loss': 0.2531381064715485}
2023-01-03 22:59:52,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:52,031 INFO:     Epoch: 41
2023-01-03 22:59:53,623 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49329721530278525, 'Total loss': 0.49329721530278525} | train loss {'Reaction outcome loss': 0.24549244823730618, 'Total loss': 0.24549244823730618}
2023-01-03 22:59:53,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:53,623 INFO:     Epoch: 42
2023-01-03 22:59:55,245 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4869075576464335, 'Total loss': 0.4869075576464335} | train loss {'Reaction outcome loss': 0.24193674478801372, 'Total loss': 0.24193674478801372}
2023-01-03 22:59:55,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:55,246 INFO:     Epoch: 43
2023-01-03 22:59:56,849 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47829391360282897, 'Total loss': 0.47829391360282897} | train loss {'Reaction outcome loss': 0.24244537576358172, 'Total loss': 0.24244537576358172}
2023-01-03 22:59:56,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:56,849 INFO:     Epoch: 44
2023-01-03 22:59:58,460 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5086468040943146, 'Total loss': 0.5086468040943146} | train loss {'Reaction outcome loss': 0.23729611329221423, 'Total loss': 0.23729611329221423}
2023-01-03 22:59:58,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 22:59:58,462 INFO:     Epoch: 45
2023-01-03 23:00:00,070 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5030990600585937, 'Total loss': 0.5030990600585937} | train loss {'Reaction outcome loss': 0.2383234403138319, 'Total loss': 0.2383234403138319}
2023-01-03 23:00:00,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:00,070 INFO:     Epoch: 46
2023-01-03 23:00:01,682 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4816607693831126, 'Total loss': 0.4816607693831126} | train loss {'Reaction outcome loss': 0.2340341463037159, 'Total loss': 0.2340341463037159}
2023-01-03 23:00:01,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:01,682 INFO:     Epoch: 47
2023-01-03 23:00:03,295 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4913297454516093, 'Total loss': 0.4913297454516093} | train loss {'Reaction outcome loss': 0.2363434838252547, 'Total loss': 0.2363434838252547}
2023-01-03 23:00:03,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:03,295 INFO:     Epoch: 48
2023-01-03 23:00:04,915 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4956201136112213, 'Total loss': 0.4956201136112213} | train loss {'Reaction outcome loss': 0.23185279192672908, 'Total loss': 0.23185279192672908}
2023-01-03 23:00:04,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:04,916 INFO:     Epoch: 49
2023-01-03 23:00:06,499 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.502559357881546, 'Total loss': 0.502559357881546} | train loss {'Reaction outcome loss': 0.2310185214045687, 'Total loss': 0.2310185214045687}
2023-01-03 23:00:06,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:06,499 INFO:     Epoch: 50
2023-01-03 23:00:08,094 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4805718630552292, 'Total loss': 0.4805718630552292} | train loss {'Reaction outcome loss': 0.2350239074490357, 'Total loss': 0.2350239074490357}
2023-01-03 23:00:08,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:08,095 INFO:     Epoch: 51
2023-01-03 23:00:09,707 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4925937612851461, 'Total loss': 0.4925937612851461} | train loss {'Reaction outcome loss': 0.22794585696259595, 'Total loss': 0.22794585696259595}
2023-01-03 23:00:09,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:09,707 INFO:     Epoch: 52
2023-01-03 23:00:11,299 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4959756394227346, 'Total loss': 0.4959756394227346} | train loss {'Reaction outcome loss': 0.2264486231935629, 'Total loss': 0.2264486231935629}
2023-01-03 23:00:11,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:11,299 INFO:     Epoch: 53
2023-01-03 23:00:12,908 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5028972327709198, 'Total loss': 0.5028972327709198} | train loss {'Reaction outcome loss': 0.222028157826189, 'Total loss': 0.222028157826189}
2023-01-03 23:00:12,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:12,908 INFO:     Epoch: 54
2023-01-03 23:00:14,486 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49881311257680255, 'Total loss': 0.49881311257680255} | train loss {'Reaction outcome loss': 0.2215195368199615, 'Total loss': 0.2215195368199615}
2023-01-03 23:00:14,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:14,487 INFO:     Epoch: 55
2023-01-03 23:00:16,082 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49616210063298544, 'Total loss': 0.49616210063298544} | train loss {'Reaction outcome loss': 0.22199548160711277, 'Total loss': 0.22199548160711277}
2023-01-03 23:00:16,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:16,083 INFO:     Epoch: 56
2023-01-03 23:00:17,677 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5089990933736165, 'Total loss': 0.5089990933736165} | train loss {'Reaction outcome loss': 0.21832479809877375, 'Total loss': 0.21832479809877375}
2023-01-03 23:00:17,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:17,678 INFO:     Epoch: 57
2023-01-03 23:00:19,272 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5036490082740783, 'Total loss': 0.5036490082740783} | train loss {'Reaction outcome loss': 0.21842463902008813, 'Total loss': 0.21842463902008813}
2023-01-03 23:00:19,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:19,273 INFO:     Epoch: 58
2023-01-03 23:00:20,857 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5247420241435369, 'Total loss': 0.5247420241435369} | train loss {'Reaction outcome loss': 0.21441163415632522, 'Total loss': 0.21441163415632522}
2023-01-03 23:00:20,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:20,858 INFO:     Epoch: 59
2023-01-03 23:00:22,452 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5090375810861587, 'Total loss': 0.5090375810861587} | train loss {'Reaction outcome loss': 0.216187144067405, 'Total loss': 0.216187144067405}
2023-01-03 23:00:22,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:22,452 INFO:     Epoch: 60
2023-01-03 23:00:24,034 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.486691552400589, 'Total loss': 0.486691552400589} | train loss {'Reaction outcome loss': 0.21668819979211126, 'Total loss': 0.21668819979211126}
2023-01-03 23:00:24,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:24,034 INFO:     Epoch: 61
2023-01-03 23:00:25,631 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.514904095729192, 'Total loss': 0.514904095729192} | train loss {'Reaction outcome loss': 0.21677237841409489, 'Total loss': 0.21677237841409489}
2023-01-03 23:00:25,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:25,631 INFO:     Epoch: 62
2023-01-03 23:00:27,229 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5123919387658437, 'Total loss': 0.5123919387658437} | train loss {'Reaction outcome loss': 0.21162113569595892, 'Total loss': 0.21162113569595892}
2023-01-03 23:00:27,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:27,229 INFO:     Epoch: 63
2023-01-03 23:00:28,811 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4876853326956431, 'Total loss': 0.4876853326956431} | train loss {'Reaction outcome loss': 0.21327947001259748, 'Total loss': 0.21327947001259748}
2023-01-03 23:00:28,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:28,813 INFO:     Epoch: 64
2023-01-03 23:00:30,426 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5206161538759867, 'Total loss': 0.5206161538759867} | train loss {'Reaction outcome loss': 0.21201645461437496, 'Total loss': 0.21201645461437496}
2023-01-03 23:00:30,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:30,426 INFO:     Epoch: 65
2023-01-03 23:00:32,030 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4928879996140798, 'Total loss': 0.4928879996140798} | train loss {'Reaction outcome loss': 0.21187357481170876, 'Total loss': 0.21187357481170876}
2023-01-03 23:00:32,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:32,030 INFO:     Epoch: 66
2023-01-03 23:00:33,629 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5027834415435791, 'Total loss': 0.5027834415435791} | train loss {'Reaction outcome loss': 0.20525420789836327, 'Total loss': 0.20525420789836327}
2023-01-03 23:00:33,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:33,629 INFO:     Epoch: 67
2023-01-03 23:00:35,254 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.530328079064687, 'Total loss': 0.530328079064687} | train loss {'Reaction outcome loss': 0.20395899828577388, 'Total loss': 0.20395899828577388}
2023-01-03 23:00:35,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:35,254 INFO:     Epoch: 68
2023-01-03 23:00:36,863 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5195746421813965, 'Total loss': 0.5195746421813965} | train loss {'Reaction outcome loss': 0.20387265627420897, 'Total loss': 0.20387265627420897}
2023-01-03 23:00:36,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:36,864 INFO:     Epoch: 69
2023-01-03 23:00:38,462 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5054846187432607, 'Total loss': 0.5054846187432607} | train loss {'Reaction outcome loss': 0.20535294966691214, 'Total loss': 0.20535294966691214}
2023-01-03 23:00:38,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:38,462 INFO:     Epoch: 70
2023-01-03 23:00:40,069 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5193966666857401, 'Total loss': 0.5193966666857401} | train loss {'Reaction outcome loss': 0.2016337978505138, 'Total loss': 0.2016337978505138}
2023-01-03 23:00:40,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:40,070 INFO:     Epoch: 71
2023-01-03 23:00:41,671 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5100131471951802, 'Total loss': 0.5100131471951802} | train loss {'Reaction outcome loss': 0.19950536302602143, 'Total loss': 0.19950536302602143}
2023-01-03 23:00:41,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:41,671 INFO:     Epoch: 72
2023-01-03 23:00:43,279 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5216919253269832, 'Total loss': 0.5216919253269832} | train loss {'Reaction outcome loss': 0.20095209137070924, 'Total loss': 0.20095209137070924}
2023-01-03 23:00:43,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:43,279 INFO:     Epoch: 73
2023-01-03 23:00:44,875 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5064187367757161, 'Total loss': 0.5064187367757161} | train loss {'Reaction outcome loss': 0.20063469638589068, 'Total loss': 0.20063469638589068}
2023-01-03 23:00:44,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:44,875 INFO:     Epoch: 74
2023-01-03 23:00:46,465 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5322393357753754, 'Total loss': 0.5322393357753754} | train loss {'Reaction outcome loss': 0.2040498277671851, 'Total loss': 0.2040498277671851}
2023-01-03 23:00:46,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:46,465 INFO:     Epoch: 75
2023-01-03 23:00:48,073 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5259652227163315, 'Total loss': 0.5259652227163315} | train loss {'Reaction outcome loss': 0.21014167593228564, 'Total loss': 0.21014167593228564}
2023-01-03 23:00:48,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:48,074 INFO:     Epoch: 76
2023-01-03 23:00:49,682 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5702169279257456, 'Total loss': 0.5702169279257456} | train loss {'Reaction outcome loss': 0.19876316189597212, 'Total loss': 0.19876316189597212}
2023-01-03 23:00:49,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:49,682 INFO:     Epoch: 77
2023-01-03 23:00:51,278 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5282684246699015, 'Total loss': 0.5282684246699015} | train loss {'Reaction outcome loss': 0.19468928154126025, 'Total loss': 0.19468928154126025}
2023-01-03 23:00:51,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:51,278 INFO:     Epoch: 78
2023-01-03 23:00:52,900 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5056432694196701, 'Total loss': 0.5056432694196701} | train loss {'Reaction outcome loss': 0.19651222633251894, 'Total loss': 0.19651222633251894}
2023-01-03 23:00:52,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:52,901 INFO:     Epoch: 79
2023-01-03 23:00:54,517 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5208784401416778, 'Total loss': 0.5208784401416778} | train loss {'Reaction outcome loss': 0.19372975957863356, 'Total loss': 0.19372975957863356}
2023-01-03 23:00:54,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:54,518 INFO:     Epoch: 80
2023-01-03 23:00:56,116 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5460077961285908, 'Total loss': 0.5460077961285908} | train loss {'Reaction outcome loss': 0.192403868984674, 'Total loss': 0.192403868984674}
2023-01-03 23:00:56,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:56,116 INFO:     Epoch: 81
2023-01-03 23:00:57,739 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5288773308197657, 'Total loss': 0.5288773308197657} | train loss {'Reaction outcome loss': 0.19016008826219005, 'Total loss': 0.19016008826219005}
2023-01-03 23:00:57,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:57,739 INFO:     Epoch: 82
2023-01-03 23:00:59,338 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5397859831651052, 'Total loss': 0.5397859831651052} | train loss {'Reaction outcome loss': 0.19064887272606543, 'Total loss': 0.19064887272606543}
2023-01-03 23:00:59,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:00:59,338 INFO:     Epoch: 83
2023-01-03 23:01:00,964 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5324911544720332, 'Total loss': 0.5324911544720332} | train loss {'Reaction outcome loss': 0.1898575778557089, 'Total loss': 0.1898575778557089}
2023-01-03 23:01:00,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:00,964 INFO:     Epoch: 84
2023-01-03 23:01:02,588 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5167703022559483, 'Total loss': 0.5167703022559483} | train loss {'Reaction outcome loss': 0.19142286380941886, 'Total loss': 0.19142286380941886}
2023-01-03 23:01:02,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:02,588 INFO:     Epoch: 85
2023-01-03 23:01:04,206 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5314974625905354, 'Total loss': 0.5314974625905354} | train loss {'Reaction outcome loss': 0.19741286667643484, 'Total loss': 0.19741286667643484}
2023-01-03 23:01:04,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:04,206 INFO:     Epoch: 86
2023-01-03 23:01:05,811 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5094329059123993, 'Total loss': 0.5094329059123993} | train loss {'Reaction outcome loss': 0.19148400026387064, 'Total loss': 0.19148400026387064}
2023-01-03 23:01:05,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:05,812 INFO:     Epoch: 87
2023-01-03 23:01:07,422 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.535129561026891, 'Total loss': 0.535129561026891} | train loss {'Reaction outcome loss': 0.19280594159457562, 'Total loss': 0.19280594159457562}
2023-01-03 23:01:07,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:07,423 INFO:     Epoch: 88
2023-01-03 23:01:09,013 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5359704077243805, 'Total loss': 0.5359704077243805} | train loss {'Reaction outcome loss': 0.18696291450802507, 'Total loss': 0.18696291450802507}
2023-01-03 23:01:09,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:09,014 INFO:     Epoch: 89
2023-01-03 23:01:10,612 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5499496161937714, 'Total loss': 0.5499496161937714} | train loss {'Reaction outcome loss': 0.18479041462600487, 'Total loss': 0.18479041462600487}
2023-01-03 23:01:10,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:10,612 INFO:     Epoch: 90
2023-01-03 23:01:12,212 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5462449173132579, 'Total loss': 0.5462449173132579} | train loss {'Reaction outcome loss': 0.18386360081068773, 'Total loss': 0.18386360081068773}
2023-01-03 23:01:12,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:12,213 INFO:     Epoch: 91
2023-01-03 23:01:13,795 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5414492626984914, 'Total loss': 0.5414492626984914} | train loss {'Reaction outcome loss': 0.1853286297342308, 'Total loss': 0.1853286297342308}
2023-01-03 23:01:13,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:13,796 INFO:     Epoch: 92
2023-01-03 23:01:15,395 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5292103668053945, 'Total loss': 0.5292103668053945} | train loss {'Reaction outcome loss': 0.18474865613667213, 'Total loss': 0.18474865613667213}
2023-01-03 23:01:15,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:15,395 INFO:     Epoch: 93
2023-01-03 23:01:16,981 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5288853655258815, 'Total loss': 0.5288853655258815} | train loss {'Reaction outcome loss': 0.18396110775748917, 'Total loss': 0.18396110775748917}
2023-01-03 23:01:16,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:16,981 INFO:     Epoch: 94
2023-01-03 23:01:18,581 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5247214863697688, 'Total loss': 0.5247214863697688} | train loss {'Reaction outcome loss': 0.18269692487471426, 'Total loss': 0.18269692487471426}
2023-01-03 23:01:18,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:18,581 INFO:     Epoch: 95
2023-01-03 23:01:20,206 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5394882927338283, 'Total loss': 0.5394882927338283} | train loss {'Reaction outcome loss': 0.181480638623791, 'Total loss': 0.181480638623791}
2023-01-03 23:01:20,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:20,206 INFO:     Epoch: 96
2023-01-03 23:01:21,829 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5294004897276561, 'Total loss': 0.5294004897276561} | train loss {'Reaction outcome loss': 0.1839430474716684, 'Total loss': 0.1839430474716684}
2023-01-03 23:01:21,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:21,829 INFO:     Epoch: 97
2023-01-03 23:01:23,434 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5127851118644079, 'Total loss': 0.5127851118644079} | train loss {'Reaction outcome loss': 0.18498581833884362, 'Total loss': 0.18498581833884362}
2023-01-03 23:01:23,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:23,435 INFO:     Epoch: 98
2023-01-03 23:01:25,058 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5306947280963262, 'Total loss': 0.5306947280963262} | train loss {'Reaction outcome loss': 0.18009390731922525, 'Total loss': 0.18009390731922525}
2023-01-03 23:01:25,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:25,059 INFO:     Epoch: 99
2023-01-03 23:01:26,656 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5259536842505137, 'Total loss': 0.5259536842505137} | train loss {'Reaction outcome loss': 0.17989516824456878, 'Total loss': 0.17989516824456878}
2023-01-03 23:01:26,656 INFO:     Best model found after epoch 34 of 100.
2023-01-03 23:01:26,656 INFO:   Done with stage: TRAINING
2023-01-03 23:01:26,656 INFO:   Starting stage: EVALUATION
2023-01-03 23:01:26,783 INFO:   Done with stage: EVALUATION
2023-01-03 23:01:26,784 INFO:   Leaving out SEQ value Fold_2
2023-01-03 23:01:26,796 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-03 23:01:26,796 INFO:   Starting stage: FEATURE SCALING
2023-01-03 23:01:27,445 INFO:   Done with stage: FEATURE SCALING
2023-01-03 23:01:27,445 INFO:   Starting stage: SCALING TARGETS
2023-01-03 23:01:27,515 INFO:   Done with stage: SCALING TARGETS
2023-01-03 23:01:27,516 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:01:27,516 INFO:     No hyperparam tuning for this model
2023-01-03 23:01:27,516 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:01:27,516 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 23:01:27,516 INFO:     None feature selector for col prot
2023-01-03 23:01:27,517 INFO:     None feature selector for col prot
2023-01-03 23:01:27,517 INFO:     None feature selector for col prot
2023-01-03 23:01:27,517 INFO:     None feature selector for col chem
2023-01-03 23:01:27,517 INFO:     None feature selector for col chem
2023-01-03 23:01:27,517 INFO:     None feature selector for col chem
2023-01-03 23:01:27,517 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 23:01:27,518 INFO:   Starting stage: BUILD MODEL
2023-01-03 23:01:27,519 INFO:     Number of params in model 70141
2023-01-03 23:01:27,522 INFO:   Done with stage: BUILD MODEL
2023-01-03 23:01:27,522 INFO:   Starting stage: TRAINING
2023-01-03 23:01:27,567 INFO:     Val loss before train {'Reaction outcome loss': 0.9455646316210429, 'Total loss': 0.9455646316210429}
2023-01-03 23:01:27,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:27,568 INFO:     Epoch: 0
2023-01-03 23:01:29,175 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6130714813868204, 'Total loss': 0.6130714813868204} | train loss {'Reaction outcome loss': 0.8567765588960509, 'Total loss': 0.8567765588960509}
2023-01-03 23:01:29,175 INFO:     Found new best model at epoch 0
2023-01-03 23:01:29,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:29,176 INFO:     Epoch: 1
2023-01-03 23:01:30,792 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4970909635225932, 'Total loss': 0.4970909635225932} | train loss {'Reaction outcome loss': 0.5984973122168632, 'Total loss': 0.5984973122168632}
2023-01-03 23:01:30,792 INFO:     Found new best model at epoch 1
2023-01-03 23:01:30,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:30,793 INFO:     Epoch: 2
2023-01-03 23:01:32,373 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45564148426055906, 'Total loss': 0.45564148426055906} | train loss {'Reaction outcome loss': 0.530523890561431, 'Total loss': 0.530523890561431}
2023-01-03 23:01:32,373 INFO:     Found new best model at epoch 2
2023-01-03 23:01:32,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:32,374 INFO:     Epoch: 3
2023-01-03 23:01:33,965 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4399338781833649, 'Total loss': 0.4399338781833649} | train loss {'Reaction outcome loss': 0.4912281670492061, 'Total loss': 0.4912281670492061}
2023-01-03 23:01:33,965 INFO:     Found new best model at epoch 3
2023-01-03 23:01:33,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:33,966 INFO:     Epoch: 4
2023-01-03 23:01:35,535 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4058259576559067, 'Total loss': 0.4058259576559067} | train loss {'Reaction outcome loss': 0.4630163912355465, 'Total loss': 0.4630163912355465}
2023-01-03 23:01:35,535 INFO:     Found new best model at epoch 4
2023-01-03 23:01:35,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:35,536 INFO:     Epoch: 5
2023-01-03 23:01:37,136 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41066984037558235, 'Total loss': 0.41066984037558235} | train loss {'Reaction outcome loss': 0.44481775817209784, 'Total loss': 0.44481775817209784}
2023-01-03 23:01:37,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:37,136 INFO:     Epoch: 6
2023-01-03 23:01:38,715 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.39180869062741597, 'Total loss': 0.39180869062741597} | train loss {'Reaction outcome loss': 0.42764341956290014, 'Total loss': 0.42764341956290014}
2023-01-03 23:01:38,715 INFO:     Found new best model at epoch 6
2023-01-03 23:01:38,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:38,716 INFO:     Epoch: 7
2023-01-03 23:01:40,322 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3766062408685684, 'Total loss': 0.3766062408685684} | train loss {'Reaction outcome loss': 0.4120522972169149, 'Total loss': 0.4120522972169149}
2023-01-03 23:01:40,322 INFO:     Found new best model at epoch 7
2023-01-03 23:01:40,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:40,323 INFO:     Epoch: 8
2023-01-03 23:01:41,889 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3999722421169281, 'Total loss': 0.3999722421169281} | train loss {'Reaction outcome loss': 0.4015107885764463, 'Total loss': 0.4015107885764463}
2023-01-03 23:01:41,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:41,891 INFO:     Epoch: 9
2023-01-03 23:01:43,474 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.38301204244295756, 'Total loss': 0.38301204244295756} | train loss {'Reaction outcome loss': 0.3932758845987111, 'Total loss': 0.3932758845987111}
2023-01-03 23:01:43,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:43,475 INFO:     Epoch: 10
2023-01-03 23:01:45,037 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.38299139638741814, 'Total loss': 0.38299139638741814} | train loss {'Reaction outcome loss': 0.38353238368991516, 'Total loss': 0.38353238368991516}
2023-01-03 23:01:45,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:45,037 INFO:     Epoch: 11
2023-01-03 23:01:46,641 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3860631843407949, 'Total loss': 0.3860631843407949} | train loss {'Reaction outcome loss': 0.3734881112175266, 'Total loss': 0.3734881112175266}
2023-01-03 23:01:46,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:46,641 INFO:     Epoch: 12
2023-01-03 23:01:48,232 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40288148522377015, 'Total loss': 0.40288148522377015} | train loss {'Reaction outcome loss': 0.3686854704725046, 'Total loss': 0.3686854704725046}
2023-01-03 23:01:48,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:48,233 INFO:     Epoch: 13
2023-01-03 23:01:49,817 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3823932965596517, 'Total loss': 0.3823932965596517} | train loss {'Reaction outcome loss': 0.35759935990302233, 'Total loss': 0.35759935990302233}
2023-01-03 23:01:49,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:49,817 INFO:     Epoch: 14
2023-01-03 23:01:51,428 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39856963356335956, 'Total loss': 0.39856963356335956} | train loss {'Reaction outcome loss': 0.3538677609749954, 'Total loss': 0.3538677609749954}
2023-01-03 23:01:51,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:51,428 INFO:     Epoch: 15
2023-01-03 23:01:53,018 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.37391163806120553, 'Total loss': 0.37391163806120553} | train loss {'Reaction outcome loss': 0.34575574301237605, 'Total loss': 0.34575574301237605}
2023-01-03 23:01:53,019 INFO:     Found new best model at epoch 15
2023-01-03 23:01:53,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:53,019 INFO:     Epoch: 16
2023-01-03 23:01:54,612 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.36825524270534515, 'Total loss': 0.36825524270534515} | train loss {'Reaction outcome loss': 0.34075408214091385, 'Total loss': 0.34075408214091385}
2023-01-03 23:01:54,612 INFO:     Found new best model at epoch 16
2023-01-03 23:01:54,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:54,613 INFO:     Epoch: 17
2023-01-03 23:01:56,218 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3865328937768936, 'Total loss': 0.3865328937768936} | train loss {'Reaction outcome loss': 0.33479080395433153, 'Total loss': 0.33479080395433153}
2023-01-03 23:01:56,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:56,219 INFO:     Epoch: 18
2023-01-03 23:01:57,824 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3723268340031306, 'Total loss': 0.3723268340031306} | train loss {'Reaction outcome loss': 0.3300872041578711, 'Total loss': 0.3300872041578711}
2023-01-03 23:01:57,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:57,824 INFO:     Epoch: 19
2023-01-03 23:01:59,410 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3851526429255803, 'Total loss': 0.3851526429255803} | train loss {'Reaction outcome loss': 0.3221951729352892, 'Total loss': 0.3221951729352892}
2023-01-03 23:01:59,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:01:59,410 INFO:     Epoch: 20
2023-01-03 23:02:01,044 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3782417009274165, 'Total loss': 0.3782417009274165} | train loss {'Reaction outcome loss': 0.31786930022666054, 'Total loss': 0.31786930022666054}
2023-01-03 23:02:01,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:01,045 INFO:     Epoch: 21
2023-01-03 23:02:02,645 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.36893282184998194, 'Total loss': 0.36893282184998194} | train loss {'Reaction outcome loss': 0.3131216601978471, 'Total loss': 0.3131216601978471}
2023-01-03 23:02:02,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:02,645 INFO:     Epoch: 22
2023-01-03 23:02:04,284 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.36595878601074217, 'Total loss': 0.36595878601074217} | train loss {'Reaction outcome loss': 0.3082209932379914, 'Total loss': 0.3082209932379914}
2023-01-03 23:02:04,285 INFO:     Found new best model at epoch 22
2023-01-03 23:02:04,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:04,285 INFO:     Epoch: 23
2023-01-03 23:02:05,892 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.36530310809612276, 'Total loss': 0.36530310809612276} | train loss {'Reaction outcome loss': 0.30478087633195583, 'Total loss': 0.30478087633195583}
2023-01-03 23:02:05,892 INFO:     Found new best model at epoch 23
2023-01-03 23:02:05,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:05,893 INFO:     Epoch: 24
2023-01-03 23:02:07,492 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3758752832810084, 'Total loss': 0.3758752832810084} | train loss {'Reaction outcome loss': 0.29802362191198517, 'Total loss': 0.29802362191198517}
2023-01-03 23:02:07,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:07,492 INFO:     Epoch: 25
2023-01-03 23:02:09,068 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3574998289346695, 'Total loss': 0.3574998289346695} | train loss {'Reaction outcome loss': 0.2926444608690965, 'Total loss': 0.2926444608690965}
2023-01-03 23:02:09,068 INFO:     Found new best model at epoch 25
2023-01-03 23:02:09,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:09,069 INFO:     Epoch: 26
2023-01-03 23:02:10,674 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3613773991664251, 'Total loss': 0.3613773991664251} | train loss {'Reaction outcome loss': 0.2904834369618962, 'Total loss': 0.2904834369618962}
2023-01-03 23:02:10,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:10,675 INFO:     Epoch: 27
2023-01-03 23:02:12,242 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39829328159491223, 'Total loss': 0.39829328159491223} | train loss {'Reaction outcome loss': 0.2893039721478946, 'Total loss': 0.2893039721478946}
2023-01-03 23:02:12,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:12,243 INFO:     Epoch: 28
2023-01-03 23:02:13,834 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.384529987970988, 'Total loss': 0.384529987970988} | train loss {'Reaction outcome loss': 0.2842001849989386, 'Total loss': 0.2842001849989386}
2023-01-03 23:02:13,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:13,835 INFO:     Epoch: 29
2023-01-03 23:02:15,412 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3731599549452464, 'Total loss': 0.3731599549452464} | train loss {'Reaction outcome loss': 0.27983804242889376, 'Total loss': 0.27983804242889376}
2023-01-03 23:02:15,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:15,412 INFO:     Epoch: 30
2023-01-03 23:02:16,978 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3814747601747513, 'Total loss': 0.3814747601747513} | train loss {'Reaction outcome loss': 0.27864745822157305, 'Total loss': 0.27864745822157305}
2023-01-03 23:02:16,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:16,979 INFO:     Epoch: 31
2023-01-03 23:02:18,560 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3515038845439752, 'Total loss': 0.3515038845439752} | train loss {'Reaction outcome loss': 0.27484946260160775, 'Total loss': 0.27484946260160775}
2023-01-03 23:02:18,560 INFO:     Found new best model at epoch 31
2023-01-03 23:02:18,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:18,561 INFO:     Epoch: 32
2023-01-03 23:02:20,121 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.36494391957918804, 'Total loss': 0.36494391957918804} | train loss {'Reaction outcome loss': 0.2698506146642196, 'Total loss': 0.2698506146642196}
2023-01-03 23:02:20,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:20,122 INFO:     Epoch: 33
2023-01-03 23:02:21,730 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4003874917825063, 'Total loss': 0.4003874917825063} | train loss {'Reaction outcome loss': 0.2680052697767306, 'Total loss': 0.2680052697767306}
2023-01-03 23:02:21,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:21,730 INFO:     Epoch: 34
2023-01-03 23:02:23,336 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.36079848210016885, 'Total loss': 0.36079848210016885} | train loss {'Reaction outcome loss': 0.2633572559341462, 'Total loss': 0.2633572559341462}
2023-01-03 23:02:23,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:23,337 INFO:     Epoch: 35
2023-01-03 23:02:24,950 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3485224634408951, 'Total loss': 0.3485224634408951} | train loss {'Reaction outcome loss': 0.2605541210458444, 'Total loss': 0.2605541210458444}
2023-01-03 23:02:24,951 INFO:     Found new best model at epoch 35
2023-01-03 23:02:24,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:24,951 INFO:     Epoch: 36
2023-01-03 23:02:26,543 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.35717714329560596, 'Total loss': 0.35717714329560596} | train loss {'Reaction outcome loss': 0.2575891522323563, 'Total loss': 0.2575891522323563}
2023-01-03 23:02:26,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:26,543 INFO:     Epoch: 37
2023-01-03 23:02:28,153 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.333674651881059, 'Total loss': 0.333674651881059} | train loss {'Reaction outcome loss': 0.2562405137875437, 'Total loss': 0.2562405137875437}
2023-01-03 23:02:28,153 INFO:     Found new best model at epoch 37
2023-01-03 23:02:28,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:28,154 INFO:     Epoch: 38
2023-01-03 23:02:29,728 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3702430119117101, 'Total loss': 0.3702430119117101} | train loss {'Reaction outcome loss': 0.25386956804533944, 'Total loss': 0.25386956804533944}
2023-01-03 23:02:29,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:29,728 INFO:     Epoch: 39
2023-01-03 23:02:31,305 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.36887075106302897, 'Total loss': 0.36887075106302897} | train loss {'Reaction outcome loss': 0.2507924273555731, 'Total loss': 0.2507924273555731}
2023-01-03 23:02:31,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:31,305 INFO:     Epoch: 40
2023-01-03 23:02:32,916 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37972687780857084, 'Total loss': 0.37972687780857084} | train loss {'Reaction outcome loss': 0.24857823458248682, 'Total loss': 0.24857823458248682}
2023-01-03 23:02:32,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:32,917 INFO:     Epoch: 41
2023-01-03 23:02:34,519 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3440113137165705, 'Total loss': 0.3440113137165705} | train loss {'Reaction outcome loss': 0.2450869161173375, 'Total loss': 0.2450869161173375}
2023-01-03 23:02:34,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:34,519 INFO:     Epoch: 42
2023-01-03 23:02:36,114 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.34430729945500693, 'Total loss': 0.34430729945500693} | train loss {'Reaction outcome loss': 0.24376897932621686, 'Total loss': 0.24376897932621686}
2023-01-03 23:02:36,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:36,115 INFO:     Epoch: 43
2023-01-03 23:02:37,721 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3770546853542328, 'Total loss': 0.3770546853542328} | train loss {'Reaction outcome loss': 0.24332820821254358, 'Total loss': 0.24332820821254358}
2023-01-03 23:02:37,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:37,721 INFO:     Epoch: 44
2023-01-03 23:02:39,282 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.36071997284889223, 'Total loss': 0.36071997284889223} | train loss {'Reaction outcome loss': 0.24135681016057947, 'Total loss': 0.24135681016057947}
2023-01-03 23:02:39,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:39,282 INFO:     Epoch: 45
2023-01-03 23:02:40,852 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3569439321756363, 'Total loss': 0.3569439321756363} | train loss {'Reaction outcome loss': 0.23890300969300915, 'Total loss': 0.23890300969300915}
2023-01-03 23:02:40,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:40,852 INFO:     Epoch: 46
2023-01-03 23:02:42,422 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3542569080988566, 'Total loss': 0.3542569080988566} | train loss {'Reaction outcome loss': 0.23780520949648679, 'Total loss': 0.23780520949648679}
2023-01-03 23:02:42,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:42,422 INFO:     Epoch: 47
2023-01-03 23:02:43,986 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.35649901032447817, 'Total loss': 0.35649901032447817} | train loss {'Reaction outcome loss': 0.2342730675463694, 'Total loss': 0.2342730675463694}
2023-01-03 23:02:43,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:43,986 INFO:     Epoch: 48
2023-01-03 23:02:45,580 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4067678352197011, 'Total loss': 0.4067678352197011} | train loss {'Reaction outcome loss': 0.23426830088787706, 'Total loss': 0.23426830088787706}
2023-01-03 23:02:45,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:45,580 INFO:     Epoch: 49
2023-01-03 23:02:47,144 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.34878417750199636, 'Total loss': 0.34878417750199636} | train loss {'Reaction outcome loss': 0.23233558707972513, 'Total loss': 0.23233558707972513}
2023-01-03 23:02:47,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:47,145 INFO:     Epoch: 50
2023-01-03 23:02:48,725 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3667400747537613, 'Total loss': 0.3667400747537613} | train loss {'Reaction outcome loss': 0.23051364796005025, 'Total loss': 0.23051364796005025}
2023-01-03 23:02:48,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:48,726 INFO:     Epoch: 51
2023-01-03 23:02:50,310 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3518195579449336, 'Total loss': 0.3518195579449336} | train loss {'Reaction outcome loss': 0.22765537169184127, 'Total loss': 0.22765537169184127}
2023-01-03 23:02:50,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:50,310 INFO:     Epoch: 52
2023-01-03 23:02:51,892 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.37757328947385155, 'Total loss': 0.37757328947385155} | train loss {'Reaction outcome loss': 0.2238083219250841, 'Total loss': 0.2238083219250841}
2023-01-03 23:02:51,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:51,892 INFO:     Epoch: 53
2023-01-03 23:02:53,460 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3647118806838989, 'Total loss': 0.3647118806838989} | train loss {'Reaction outcome loss': 0.2265191293002045, 'Total loss': 0.2265191293002045}
2023-01-03 23:02:53,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:53,461 INFO:     Epoch: 54
2023-01-03 23:02:55,045 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.37368147969245913, 'Total loss': 0.37368147969245913} | train loss {'Reaction outcome loss': 0.22210057843884412, 'Total loss': 0.22210057843884412}
2023-01-03 23:02:55,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:55,045 INFO:     Epoch: 55
2023-01-03 23:02:56,609 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3920707980791728, 'Total loss': 0.3920707980791728} | train loss {'Reaction outcome loss': 0.2212608992835901, 'Total loss': 0.2212608992835901}
2023-01-03 23:02:56,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:56,609 INFO:     Epoch: 56
2023-01-03 23:02:58,208 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.35473841031392417, 'Total loss': 0.35473841031392417} | train loss {'Reaction outcome loss': 0.2206533364815651, 'Total loss': 0.2206533364815651}
2023-01-03 23:02:58,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:58,208 INFO:     Epoch: 57
2023-01-03 23:02:59,812 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3493597745895386, 'Total loss': 0.3493597745895386} | train loss {'Reaction outcome loss': 0.21689707652604492, 'Total loss': 0.21689707652604492}
2023-01-03 23:02:59,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:02:59,812 INFO:     Epoch: 58
2023-01-03 23:03:01,405 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.35621271034081775, 'Total loss': 0.35621271034081775} | train loss {'Reaction outcome loss': 0.21530350894551642, 'Total loss': 0.21530350894551642}
2023-01-03 23:03:01,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:01,406 INFO:     Epoch: 59
2023-01-03 23:03:03,011 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3635158767302831, 'Total loss': 0.3635158767302831} | train loss {'Reaction outcome loss': 0.2134392289512784, 'Total loss': 0.2134392289512784}
2023-01-03 23:03:03,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:03,012 INFO:     Epoch: 60
2023-01-03 23:03:04,617 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.36740185221036276, 'Total loss': 0.36740185221036276} | train loss {'Reaction outcome loss': 0.2122726575437471, 'Total loss': 0.2122726575437471}
2023-01-03 23:03:04,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:04,617 INFO:     Epoch: 61
2023-01-03 23:03:06,210 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38769867420196535, 'Total loss': 0.38769867420196535} | train loss {'Reaction outcome loss': 0.2119075208358521, 'Total loss': 0.2119075208358521}
2023-01-03 23:03:06,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:06,211 INFO:     Epoch: 62
2023-01-03 23:03:07,833 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3542053441206614, 'Total loss': 0.3542053441206614} | train loss {'Reaction outcome loss': 0.21093425973162164, 'Total loss': 0.21093425973162164}
2023-01-03 23:03:07,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:07,833 INFO:     Epoch: 63
2023-01-03 23:03:09,445 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3554592619339625, 'Total loss': 0.3554592619339625} | train loss {'Reaction outcome loss': 0.20755669316888725, 'Total loss': 0.20755669316888725}
2023-01-03 23:03:09,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:09,445 INFO:     Epoch: 64
2023-01-03 23:03:11,006 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.36858950853347777, 'Total loss': 0.36858950853347777} | train loss {'Reaction outcome loss': 0.20594340848335385, 'Total loss': 0.20594340848335385}
2023-01-03 23:03:11,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:11,006 INFO:     Epoch: 65
2023-01-03 23:03:12,592 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3484517047802607, 'Total loss': 0.3484517047802607} | train loss {'Reaction outcome loss': 0.20519784398132215, 'Total loss': 0.20519784398132215}
2023-01-03 23:03:12,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:12,592 INFO:     Epoch: 66
2023-01-03 23:03:14,175 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3625115027030309, 'Total loss': 0.3625115027030309} | train loss {'Reaction outcome loss': 0.20397860337946103, 'Total loss': 0.20397860337946103}
2023-01-03 23:03:14,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:14,175 INFO:     Epoch: 67
2023-01-03 23:03:15,753 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.35236220955848696, 'Total loss': 0.35236220955848696} | train loss {'Reaction outcome loss': 0.20387475783970668, 'Total loss': 0.20387475783970668}
2023-01-03 23:03:15,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:15,753 INFO:     Epoch: 68
2023-01-03 23:03:17,364 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3828313698371251, 'Total loss': 0.3828313698371251} | train loss {'Reaction outcome loss': 0.20308627466922693, 'Total loss': 0.20308627466922693}
2023-01-03 23:03:17,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:17,364 INFO:     Epoch: 69
2023-01-03 23:03:18,990 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3821182290712992, 'Total loss': 0.3821182290712992} | train loss {'Reaction outcome loss': 0.199757379282565, 'Total loss': 0.199757379282565}
2023-01-03 23:03:18,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:18,990 INFO:     Epoch: 70
2023-01-03 23:03:20,581 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.377411620815595, 'Total loss': 0.377411620815595} | train loss {'Reaction outcome loss': 0.19869946243146258, 'Total loss': 0.19869946243146258}
2023-01-03 23:03:20,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:20,582 INFO:     Epoch: 71
2023-01-03 23:03:22,177 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3816877583662669, 'Total loss': 0.3816877583662669} | train loss {'Reaction outcome loss': 0.1979828039660071, 'Total loss': 0.1979828039660071}
2023-01-03 23:03:22,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:22,177 INFO:     Epoch: 72
2023-01-03 23:03:23,759 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3806542843580246, 'Total loss': 0.3806542843580246} | train loss {'Reaction outcome loss': 0.19576060835843104, 'Total loss': 0.19576060835843104}
2023-01-03 23:03:23,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:23,760 INFO:     Epoch: 73
2023-01-03 23:03:25,372 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.36859673460324605, 'Total loss': 0.36859673460324605} | train loss {'Reaction outcome loss': 0.1949547990667124, 'Total loss': 0.1949547990667124}
2023-01-03 23:03:25,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:25,372 INFO:     Epoch: 74
2023-01-03 23:03:26,945 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3865175858139992, 'Total loss': 0.3865175858139992} | train loss {'Reaction outcome loss': 0.19416138664377433, 'Total loss': 0.19416138664377433}
2023-01-03 23:03:26,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:26,945 INFO:     Epoch: 75
2023-01-03 23:03:28,519 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3867197910944621, 'Total loss': 0.3867197910944621} | train loss {'Reaction outcome loss': 0.19435426440552203, 'Total loss': 0.19435426440552203}
2023-01-03 23:03:28,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:28,520 INFO:     Epoch: 76
2023-01-03 23:03:30,141 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.363242340584596, 'Total loss': 0.363242340584596} | train loss {'Reaction outcome loss': 0.19109138586714755, 'Total loss': 0.19109138586714755}
2023-01-03 23:03:30,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:30,142 INFO:     Epoch: 77
2023-01-03 23:03:31,735 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38188055555025735, 'Total loss': 0.38188055555025735} | train loss {'Reaction outcome loss': 0.1919791513143012, 'Total loss': 0.1919791513143012}
2023-01-03 23:03:31,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:31,735 INFO:     Epoch: 78
2023-01-03 23:03:33,321 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39169803261756897, 'Total loss': 0.39169803261756897} | train loss {'Reaction outcome loss': 0.19195834775693224, 'Total loss': 0.19195834775693224}
2023-01-03 23:03:33,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:33,321 INFO:     Epoch: 79
2023-01-03 23:03:34,942 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.36498606304327647, 'Total loss': 0.36498606304327647} | train loss {'Reaction outcome loss': 0.1891902969660659, 'Total loss': 0.1891902969660659}
2023-01-03 23:03:34,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:34,942 INFO:     Epoch: 80
2023-01-03 23:03:36,543 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3819134106238683, 'Total loss': 0.3819134106238683} | train loss {'Reaction outcome loss': 0.1908586406468475, 'Total loss': 0.1908586406468475}
2023-01-03 23:03:36,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:36,543 INFO:     Epoch: 81
2023-01-03 23:03:38,125 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39530713657538097, 'Total loss': 0.39530713657538097} | train loss {'Reaction outcome loss': 0.18968475930882198, 'Total loss': 0.18968475930882198}
2023-01-03 23:03:38,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:38,125 INFO:     Epoch: 82
2023-01-03 23:03:39,729 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37822264631589253, 'Total loss': 0.37822264631589253} | train loss {'Reaction outcome loss': 0.18828563707588364, 'Total loss': 0.18828563707588364}
2023-01-03 23:03:39,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:39,729 INFO:     Epoch: 83
2023-01-03 23:03:41,318 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.364840113123258, 'Total loss': 0.364840113123258} | train loss {'Reaction outcome loss': 0.18585841709163284, 'Total loss': 0.18585841709163284}
2023-01-03 23:03:41,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:41,318 INFO:     Epoch: 84
2023-01-03 23:03:42,924 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37524746159712474, 'Total loss': 0.37524746159712474} | train loss {'Reaction outcome loss': 0.1873653283900153, 'Total loss': 0.1873653283900153}
2023-01-03 23:03:42,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:42,925 INFO:     Epoch: 85
2023-01-03 23:03:44,515 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4094642544786135, 'Total loss': 0.4094642544786135} | train loss {'Reaction outcome loss': 0.18412588270258728, 'Total loss': 0.18412588270258728}
2023-01-03 23:03:44,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:44,515 INFO:     Epoch: 86
2023-01-03 23:03:46,139 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.37794873813788094, 'Total loss': 0.37794873813788094} | train loss {'Reaction outcome loss': 0.18294770961260273, 'Total loss': 0.18294770961260273}
2023-01-03 23:03:46,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:46,139 INFO:     Epoch: 87
2023-01-03 23:03:47,728 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.37666661143302915, 'Total loss': 0.37666661143302915} | train loss {'Reaction outcome loss': 0.18307183447708614, 'Total loss': 0.18307183447708614}
2023-01-03 23:03:47,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:47,729 INFO:     Epoch: 88
2023-01-03 23:03:49,322 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38945306340853375, 'Total loss': 0.38945306340853375} | train loss {'Reaction outcome loss': 0.18353482360278603, 'Total loss': 0.18353482360278603}
2023-01-03 23:03:49,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:49,322 INFO:     Epoch: 89
2023-01-03 23:03:50,911 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3873789886633555, 'Total loss': 0.3873789886633555} | train loss {'Reaction outcome loss': 0.1831246397464815, 'Total loss': 0.1831246397464815}
2023-01-03 23:03:50,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:50,911 INFO:     Epoch: 90
2023-01-03 23:03:52,533 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4086050381263097, 'Total loss': 0.4086050381263097} | train loss {'Reaction outcome loss': 0.18120590639538572, 'Total loss': 0.18120590639538572}
2023-01-03 23:03:52,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:52,533 INFO:     Epoch: 91
2023-01-03 23:03:54,151 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39727082749207815, 'Total loss': 0.39727082749207815} | train loss {'Reaction outcome loss': 0.1768353023178821, 'Total loss': 0.1768353023178821}
2023-01-03 23:03:54,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:54,151 INFO:     Epoch: 92
2023-01-03 23:03:55,740 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.38755914171536765, 'Total loss': 0.38755914171536765} | train loss {'Reaction outcome loss': 0.1772298099690654, 'Total loss': 0.1772298099690654}
2023-01-03 23:03:55,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:55,740 INFO:     Epoch: 93
2023-01-03 23:03:57,312 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.427322914203008, 'Total loss': 0.427322914203008} | train loss {'Reaction outcome loss': 0.1778587800498209, 'Total loss': 0.1778587800498209}
2023-01-03 23:03:57,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:57,312 INFO:     Epoch: 94
2023-01-03 23:03:58,925 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38222799201806384, 'Total loss': 0.38222799201806384} | train loss {'Reaction outcome loss': 0.17893994732821075, 'Total loss': 0.17893994732821075}
2023-01-03 23:03:58,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:03:58,927 INFO:     Epoch: 95
2023-01-03 23:04:00,528 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38705409665902457, 'Total loss': 0.38705409665902457} | train loss {'Reaction outcome loss': 0.17641999861429425, 'Total loss': 0.17641999861429425}
2023-01-03 23:04:00,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:00,528 INFO:     Epoch: 96
2023-01-03 23:04:02,150 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3843888580799103, 'Total loss': 0.3843888580799103} | train loss {'Reaction outcome loss': 0.17718807896123315, 'Total loss': 0.17718807896123315}
2023-01-03 23:04:02,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:02,150 INFO:     Epoch: 97
2023-01-03 23:04:03,756 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.39574646949768066, 'Total loss': 0.39574646949768066} | train loss {'Reaction outcome loss': 0.17629175610758746, 'Total loss': 0.17629175610758746}
2023-01-03 23:04:03,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:03,757 INFO:     Epoch: 98
2023-01-03 23:04:05,346 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4029048472642899, 'Total loss': 0.4029048472642899} | train loss {'Reaction outcome loss': 0.17481346497733663, 'Total loss': 0.17481346497733663}
2023-01-03 23:04:05,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:05,347 INFO:     Epoch: 99
2023-01-03 23:04:06,918 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4047584484020869, 'Total loss': 0.4047584484020869} | train loss {'Reaction outcome loss': 0.1757371628276297, 'Total loss': 0.1757371628276297}
2023-01-03 23:04:06,918 INFO:     Best model found after epoch 38 of 100.
2023-01-03 23:04:06,918 INFO:   Done with stage: TRAINING
2023-01-03 23:04:06,918 INFO:   Starting stage: EVALUATION
2023-01-03 23:04:07,053 INFO:   Done with stage: EVALUATION
2023-01-03 23:04:07,053 INFO:   Leaving out SEQ value Fold_3
2023-01-03 23:04:07,065 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-03 23:04:07,066 INFO:   Starting stage: FEATURE SCALING
2023-01-03 23:04:07,710 INFO:   Done with stage: FEATURE SCALING
2023-01-03 23:04:07,710 INFO:   Starting stage: SCALING TARGETS
2023-01-03 23:04:07,779 INFO:   Done with stage: SCALING TARGETS
2023-01-03 23:04:07,779 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:04:07,779 INFO:     No hyperparam tuning for this model
2023-01-03 23:04:07,779 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:04:07,779 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 23:04:07,780 INFO:     None feature selector for col prot
2023-01-03 23:04:07,780 INFO:     None feature selector for col prot
2023-01-03 23:04:07,780 INFO:     None feature selector for col prot
2023-01-03 23:04:07,781 INFO:     None feature selector for col chem
2023-01-03 23:04:07,781 INFO:     None feature selector for col chem
2023-01-03 23:04:07,781 INFO:     None feature selector for col chem
2023-01-03 23:04:07,781 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 23:04:07,781 INFO:   Starting stage: BUILD MODEL
2023-01-03 23:04:07,782 INFO:     Number of params in model 70141
2023-01-03 23:04:07,785 INFO:   Done with stage: BUILD MODEL
2023-01-03 23:04:07,785 INFO:   Starting stage: TRAINING
2023-01-03 23:04:07,828 INFO:     Val loss before train {'Reaction outcome loss': 0.9627197285493215, 'Total loss': 0.9627197285493215}
2023-01-03 23:04:07,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:07,828 INFO:     Epoch: 0
2023-01-03 23:04:09,410 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6649553696314494, 'Total loss': 0.6649553696314494} | train loss {'Reaction outcome loss': 0.8507451313908083, 'Total loss': 0.8507451313908083}
2023-01-03 23:04:09,410 INFO:     Found new best model at epoch 0
2023-01-03 23:04:09,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:09,411 INFO:     Epoch: 1
2023-01-03 23:04:10,993 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5511394441127777, 'Total loss': 0.5511394441127777} | train loss {'Reaction outcome loss': 0.6004138624798643, 'Total loss': 0.6004138624798643}
2023-01-03 23:04:10,993 INFO:     Found new best model at epoch 1
2023-01-03 23:04:10,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:10,994 INFO:     Epoch: 2
2023-01-03 23:04:12,573 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5020146429538727, 'Total loss': 0.5020146429538727} | train loss {'Reaction outcome loss': 0.5250388708536642, 'Total loss': 0.5250388708536642}
2023-01-03 23:04:12,573 INFO:     Found new best model at epoch 2
2023-01-03 23:04:12,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:12,574 INFO:     Epoch: 3
2023-01-03 23:04:14,157 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4781765242417653, 'Total loss': 0.4781765242417653} | train loss {'Reaction outcome loss': 0.4890138462294627, 'Total loss': 0.4890138462294627}
2023-01-03 23:04:14,158 INFO:     Found new best model at epoch 3
2023-01-03 23:04:14,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:14,158 INFO:     Epoch: 4
2023-01-03 23:04:15,752 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45173369646072387, 'Total loss': 0.45173369646072387} | train loss {'Reaction outcome loss': 0.4646424393366723, 'Total loss': 0.4646424393366723}
2023-01-03 23:04:15,752 INFO:     Found new best model at epoch 4
2023-01-03 23:04:15,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:15,753 INFO:     Epoch: 5
2023-01-03 23:04:17,305 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46176286538441974, 'Total loss': 0.46176286538441974} | train loss {'Reaction outcome loss': 0.4443461726399234, 'Total loss': 0.4443461726399234}
2023-01-03 23:04:17,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:17,305 INFO:     Epoch: 6
2023-01-03 23:04:18,908 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4356330752372742, 'Total loss': 0.4356330752372742} | train loss {'Reaction outcome loss': 0.428471687610132, 'Total loss': 0.428471687610132}
2023-01-03 23:04:18,909 INFO:     Found new best model at epoch 6
2023-01-03 23:04:18,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:18,910 INFO:     Epoch: 7
2023-01-03 23:04:20,482 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4357146312793096, 'Total loss': 0.4357146312793096} | train loss {'Reaction outcome loss': 0.4179207734274168, 'Total loss': 0.4179207734274168}
2023-01-03 23:04:20,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:20,482 INFO:     Epoch: 8
2023-01-03 23:04:22,084 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4297948608795802, 'Total loss': 0.4297948608795802} | train loss {'Reaction outcome loss': 0.4030779112864585, 'Total loss': 0.4030779112864585}
2023-01-03 23:04:22,084 INFO:     Found new best model at epoch 8
2023-01-03 23:04:22,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:22,085 INFO:     Epoch: 9
2023-01-03 23:04:23,686 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40950619280338285, 'Total loss': 0.40950619280338285} | train loss {'Reaction outcome loss': 0.39239944642695196, 'Total loss': 0.39239944642695196}
2023-01-03 23:04:23,686 INFO:     Found new best model at epoch 9
2023-01-03 23:04:23,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:23,687 INFO:     Epoch: 10
2023-01-03 23:04:25,259 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41111838618914287, 'Total loss': 0.41111838618914287} | train loss {'Reaction outcome loss': 0.38587988913059235, 'Total loss': 0.38587988913059235}
2023-01-03 23:04:25,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:25,260 INFO:     Epoch: 11
2023-01-03 23:04:26,835 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41738412181536355, 'Total loss': 0.41738412181536355} | train loss {'Reaction outcome loss': 0.37329978778632017, 'Total loss': 0.37329978778632017}
2023-01-03 23:04:26,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:26,835 INFO:     Epoch: 12
2023-01-03 23:04:28,439 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42488675912221274, 'Total loss': 0.42488675912221274} | train loss {'Reaction outcome loss': 0.3683125874041206, 'Total loss': 0.3683125874041206}
2023-01-03 23:04:28,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:28,439 INFO:     Epoch: 13
2023-01-03 23:04:30,042 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39625127116839093, 'Total loss': 0.39625127116839093} | train loss {'Reaction outcome loss': 0.3579981827387845, 'Total loss': 0.3579981827387845}
2023-01-03 23:04:30,043 INFO:     Found new best model at epoch 13
2023-01-03 23:04:30,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:30,044 INFO:     Epoch: 14
2023-01-03 23:04:31,627 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39979249437650044, 'Total loss': 0.39979249437650044} | train loss {'Reaction outcome loss': 0.35190998577941074, 'Total loss': 0.35190998577941074}
2023-01-03 23:04:31,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:31,628 INFO:     Epoch: 15
2023-01-03 23:04:33,229 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40811576346556344, 'Total loss': 0.40811576346556344} | train loss {'Reaction outcome loss': 0.34567373093679876, 'Total loss': 0.34567373093679876}
2023-01-03 23:04:33,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:33,229 INFO:     Epoch: 16
2023-01-03 23:04:34,780 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39320626656214397, 'Total loss': 0.39320626656214397} | train loss {'Reaction outcome loss': 0.336701664040341, 'Total loss': 0.336701664040341}
2023-01-03 23:04:34,780 INFO:     Found new best model at epoch 16
2023-01-03 23:04:34,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:34,781 INFO:     Epoch: 17
2023-01-03 23:04:35,832 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3830274552106857, 'Total loss': 0.3830274552106857} | train loss {'Reaction outcome loss': 0.3316211748025278, 'Total loss': 0.3316211748025278}
2023-01-03 23:04:35,832 INFO:     Found new best model at epoch 17
2023-01-03 23:04:35,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:35,833 INFO:     Epoch: 18
2023-01-03 23:04:36,877 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3954107890526454, 'Total loss': 0.3954107890526454} | train loss {'Reaction outcome loss': 0.32629041286715627, 'Total loss': 0.32629041286715627}
2023-01-03 23:04:36,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:36,878 INFO:     Epoch: 19
2023-01-03 23:04:37,921 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.387844443321228, 'Total loss': 0.387844443321228} | train loss {'Reaction outcome loss': 0.31904200945783706, 'Total loss': 0.31904200945783706}
2023-01-03 23:04:37,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:37,922 INFO:     Epoch: 20
2023-01-03 23:04:38,984 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39609928131103517, 'Total loss': 0.39609928131103517} | train loss {'Reaction outcome loss': 0.3161268102916053, 'Total loss': 0.3161268102916053}
2023-01-03 23:04:38,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:38,984 INFO:     Epoch: 21
2023-01-03 23:04:40,332 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3987030973037084, 'Total loss': 0.3987030973037084} | train loss {'Reaction outcome loss': 0.30887220128283016, 'Total loss': 0.30887220128283016}
2023-01-03 23:04:40,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:40,332 INFO:     Epoch: 22
2023-01-03 23:04:41,946 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3943070004383723, 'Total loss': 0.3943070004383723} | train loss {'Reaction outcome loss': 0.30698090909987036, 'Total loss': 0.30698090909987036}
2023-01-03 23:04:41,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:41,946 INFO:     Epoch: 23
2023-01-03 23:04:43,548 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3832453707853953, 'Total loss': 0.3832453707853953} | train loss {'Reaction outcome loss': 0.29843249778351644, 'Total loss': 0.29843249778351644}
2023-01-03 23:04:43,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:43,549 INFO:     Epoch: 24
2023-01-03 23:04:45,152 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.37641074458758034, 'Total loss': 0.37641074458758034} | train loss {'Reaction outcome loss': 0.2941484632663918, 'Total loss': 0.2941484632663918}
2023-01-03 23:04:45,152 INFO:     Found new best model at epoch 24
2023-01-03 23:04:45,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:45,153 INFO:     Epoch: 25
2023-01-03 23:04:46,739 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3820220043261846, 'Total loss': 0.3820220043261846} | train loss {'Reaction outcome loss': 0.2920609974458705, 'Total loss': 0.2920609974458705}
2023-01-03 23:04:46,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:46,739 INFO:     Epoch: 26
2023-01-03 23:04:48,313 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3730010807514191, 'Total loss': 0.3730010807514191} | train loss {'Reaction outcome loss': 0.28851142577337524, 'Total loss': 0.28851142577337524}
2023-01-03 23:04:48,313 INFO:     Found new best model at epoch 26
2023-01-03 23:04:48,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:48,314 INFO:     Epoch: 27
2023-01-03 23:04:49,870 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38039759794871014, 'Total loss': 0.38039759794871014} | train loss {'Reaction outcome loss': 0.2829525801251187, 'Total loss': 0.2829525801251187}
2023-01-03 23:04:49,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:49,871 INFO:     Epoch: 28
2023-01-03 23:04:51,467 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3712457229693731, 'Total loss': 0.3712457229693731} | train loss {'Reaction outcome loss': 0.2794549595836523, 'Total loss': 0.2794549595836523}
2023-01-03 23:04:51,467 INFO:     Found new best model at epoch 28
2023-01-03 23:04:51,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:51,468 INFO:     Epoch: 29
2023-01-03 23:04:53,074 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.36324533124764763, 'Total loss': 0.36324533124764763} | train loss {'Reaction outcome loss': 0.27613316163638213, 'Total loss': 0.27613316163638213}
2023-01-03 23:04:53,075 INFO:     Found new best model at epoch 29
2023-01-03 23:04:53,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:53,075 INFO:     Epoch: 30
2023-01-03 23:04:54,681 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3785724719365438, 'Total loss': 0.3785724719365438} | train loss {'Reaction outcome loss': 0.272759134181007, 'Total loss': 0.272759134181007}
2023-01-03 23:04:54,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:54,681 INFO:     Epoch: 31
2023-01-03 23:04:56,254 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3791771322488785, 'Total loss': 0.3791771322488785} | train loss {'Reaction outcome loss': 0.27103131813724546, 'Total loss': 0.27103131813724546}
2023-01-03 23:04:56,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:56,254 INFO:     Epoch: 32
2023-01-03 23:04:57,814 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.35025917887687685, 'Total loss': 0.35025917887687685} | train loss {'Reaction outcome loss': 0.2674948142120873, 'Total loss': 0.2674948142120873}
2023-01-03 23:04:57,814 INFO:     Found new best model at epoch 32
2023-01-03 23:04:57,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:57,815 INFO:     Epoch: 33
2023-01-03 23:04:59,424 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3440319746732712, 'Total loss': 0.3440319746732712} | train loss {'Reaction outcome loss': 0.26331972579614527, 'Total loss': 0.26331972579614527}
2023-01-03 23:04:59,425 INFO:     Found new best model at epoch 33
2023-01-03 23:04:59,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:04:59,425 INFO:     Epoch: 34
2023-01-03 23:05:01,034 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3636749178171158, 'Total loss': 0.3636749178171158} | train loss {'Reaction outcome loss': 0.25959255695886857, 'Total loss': 0.25959255695886857}
2023-01-03 23:05:01,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:01,035 INFO:     Epoch: 35
2023-01-03 23:05:02,619 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.37652108321587247, 'Total loss': 0.37652108321587247} | train loss {'Reaction outcome loss': 0.25990251429977207, 'Total loss': 0.25990251429977207}
2023-01-03 23:05:02,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:02,619 INFO:     Epoch: 36
2023-01-03 23:05:04,219 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39228967726230624, 'Total loss': 0.39228967726230624} | train loss {'Reaction outcome loss': 0.2564988481220755, 'Total loss': 0.2564988481220755}
2023-01-03 23:05:04,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:04,219 INFO:     Epoch: 37
2023-01-03 23:05:05,809 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3779092788696289, 'Total loss': 0.3779092788696289} | train loss {'Reaction outcome loss': 0.25236962156465453, 'Total loss': 0.25236962156465453}
2023-01-03 23:05:05,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:05,809 INFO:     Epoch: 38
2023-01-03 23:05:07,378 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3565753556787968, 'Total loss': 0.3565753556787968} | train loss {'Reaction outcome loss': 0.24939648548725749, 'Total loss': 0.24939648548725749}
2023-01-03 23:05:07,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:07,379 INFO:     Epoch: 39
2023-01-03 23:05:08,949 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39050976037979124, 'Total loss': 0.39050976037979124} | train loss {'Reaction outcome loss': 0.24718423127910516, 'Total loss': 0.24718423127910516}
2023-01-03 23:05:08,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:08,949 INFO:     Epoch: 40
2023-01-03 23:05:10,554 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37294871906439464, 'Total loss': 0.37294871906439464} | train loss {'Reaction outcome loss': 0.2435561786167813, 'Total loss': 0.2435561786167813}
2023-01-03 23:05:10,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:10,554 INFO:     Epoch: 41
2023-01-03 23:05:12,159 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3653170774380366, 'Total loss': 0.3653170774380366} | train loss {'Reaction outcome loss': 0.24252961722821215, 'Total loss': 0.24252961722821215}
2023-01-03 23:05:12,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:12,159 INFO:     Epoch: 42
2023-01-03 23:05:13,746 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.36317551384369534, 'Total loss': 0.36317551384369534} | train loss {'Reaction outcome loss': 0.23858850699489134, 'Total loss': 0.23858850699489134}
2023-01-03 23:05:13,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:13,746 INFO:     Epoch: 43
2023-01-03 23:05:15,361 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3751208782196045, 'Total loss': 0.3751208782196045} | train loss {'Reaction outcome loss': 0.23872915757344151, 'Total loss': 0.23872915757344151}
2023-01-03 23:05:15,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:15,362 INFO:     Epoch: 44
2023-01-03 23:05:16,927 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3597107301155726, 'Total loss': 0.3597107301155726} | train loss {'Reaction outcome loss': 0.23648788986632424, 'Total loss': 0.23648788986632424}
2023-01-03 23:05:16,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:16,927 INFO:     Epoch: 45
2023-01-03 23:05:18,500 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.367304057876269, 'Total loss': 0.367304057876269} | train loss {'Reaction outcome loss': 0.23221267584412203, 'Total loss': 0.23221267584412203}
2023-01-03 23:05:18,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:18,500 INFO:     Epoch: 46
2023-01-03 23:05:20,071 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3702273095647494, 'Total loss': 0.3702273095647494} | train loss {'Reaction outcome loss': 0.22949405940399117, 'Total loss': 0.22949405940399117}
2023-01-03 23:05:20,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:20,072 INFO:     Epoch: 47
2023-01-03 23:05:21,649 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3781566669543584, 'Total loss': 0.3781566669543584} | train loss {'Reaction outcome loss': 0.23002118344017625, 'Total loss': 0.23002118344017625}
2023-01-03 23:05:21,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:21,649 INFO:     Epoch: 48
2023-01-03 23:05:23,223 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3730159680048625, 'Total loss': 0.3730159680048625} | train loss {'Reaction outcome loss': 0.22610020648388968, 'Total loss': 0.22610020648388968}
2023-01-03 23:05:23,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:23,223 INFO:     Epoch: 49
2023-01-03 23:05:24,781 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3685014317433039, 'Total loss': 0.3685014317433039} | train loss {'Reaction outcome loss': 0.2232163570087104, 'Total loss': 0.2232163570087104}
2023-01-03 23:05:24,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:24,781 INFO:     Epoch: 50
2023-01-03 23:05:26,389 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3610539801418781, 'Total loss': 0.3610539801418781} | train loss {'Reaction outcome loss': 0.22342676808717696, 'Total loss': 0.22342676808717696}
2023-01-03 23:05:26,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:26,389 INFO:     Epoch: 51
2023-01-03 23:05:27,994 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.36481897632280985, 'Total loss': 0.36481897632280985} | train loss {'Reaction outcome loss': 0.220679869562605, 'Total loss': 0.220679869562605}
2023-01-03 23:05:27,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:27,995 INFO:     Epoch: 52
2023-01-03 23:05:29,604 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.393176398674647, 'Total loss': 0.393176398674647} | train loss {'Reaction outcome loss': 0.21863267902475203, 'Total loss': 0.21863267902475203}
2023-01-03 23:05:29,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:29,604 INFO:     Epoch: 53
2023-01-03 23:05:31,212 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37259866346915566, 'Total loss': 0.37259866346915566} | train loss {'Reaction outcome loss': 0.21660199345354617, 'Total loss': 0.21660199345354617}
2023-01-03 23:05:31,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:31,214 INFO:     Epoch: 54
2023-01-03 23:05:32,769 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4042792409658432, 'Total loss': 0.4042792409658432} | train loss {'Reaction outcome loss': 0.21507996971970492, 'Total loss': 0.21507996971970492}
2023-01-03 23:05:32,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:32,769 INFO:     Epoch: 55
2023-01-03 23:05:34,325 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3937657207250595, 'Total loss': 0.3937657207250595} | train loss {'Reaction outcome loss': 0.21177668138033282, 'Total loss': 0.21177668138033282}
2023-01-03 23:05:34,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:34,326 INFO:     Epoch: 56
2023-01-03 23:05:35,931 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3921391228834788, 'Total loss': 0.3921391228834788} | train loss {'Reaction outcome loss': 0.2099622439484309, 'Total loss': 0.2099622439484309}
2023-01-03 23:05:35,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:35,931 INFO:     Epoch: 57
2023-01-03 23:05:37,537 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38822974960009254, 'Total loss': 0.38822974960009254} | train loss {'Reaction outcome loss': 0.21144360918415725, 'Total loss': 0.21144360918415725}
2023-01-03 23:05:37,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:37,538 INFO:     Epoch: 58
2023-01-03 23:05:39,143 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41693379282951354, 'Total loss': 0.41693379282951354} | train loss {'Reaction outcome loss': 0.20860655142171106, 'Total loss': 0.20860655142171106}
2023-01-03 23:05:39,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:39,143 INFO:     Epoch: 59
2023-01-03 23:05:40,722 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41192312141259513, 'Total loss': 0.41192312141259513} | train loss {'Reaction outcome loss': 0.20828321898342483, 'Total loss': 0.20828321898342483}
2023-01-03 23:05:40,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:40,723 INFO:     Epoch: 60
2023-01-03 23:05:42,319 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37824288904666903, 'Total loss': 0.37824288904666903} | train loss {'Reaction outcome loss': 0.2075987721174738, 'Total loss': 0.2075987721174738}
2023-01-03 23:05:42,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:42,320 INFO:     Epoch: 61
2023-01-03 23:05:43,919 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41625290165344875, 'Total loss': 0.41625290165344875} | train loss {'Reaction outcome loss': 0.20437256293031422, 'Total loss': 0.20437256293031422}
2023-01-03 23:05:43,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:43,920 INFO:     Epoch: 62
2023-01-03 23:05:45,527 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4025365561246872, 'Total loss': 0.4025365561246872} | train loss {'Reaction outcome loss': 0.20431281895424327, 'Total loss': 0.20431281895424327}
2023-01-03 23:05:45,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:45,527 INFO:     Epoch: 63
2023-01-03 23:05:47,108 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4123270273208618, 'Total loss': 0.4123270273208618} | train loss {'Reaction outcome loss': 0.20335266267350555, 'Total loss': 0.20335266267350555}
2023-01-03 23:05:47,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:47,109 INFO:     Epoch: 64
2023-01-03 23:05:48,719 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40935120085875193, 'Total loss': 0.40935120085875193} | train loss {'Reaction outcome loss': 0.2020446075072145, 'Total loss': 0.2020446075072145}
2023-01-03 23:05:48,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:48,719 INFO:     Epoch: 65
2023-01-03 23:05:50,309 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41270242432753246, 'Total loss': 0.41270242432753246} | train loss {'Reaction outcome loss': 0.20191847620001674, 'Total loss': 0.20191847620001674}
2023-01-03 23:05:50,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:50,309 INFO:     Epoch: 66
2023-01-03 23:05:51,879 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44078961610794065, 'Total loss': 0.44078961610794065} | train loss {'Reaction outcome loss': 0.20008123904656971, 'Total loss': 0.20008123904656971}
2023-01-03 23:05:51,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:51,879 INFO:     Epoch: 67
2023-01-03 23:05:53,488 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4057332336902618, 'Total loss': 0.4057332336902618} | train loss {'Reaction outcome loss': 0.1982947280154611, 'Total loss': 0.1982947280154611}
2023-01-03 23:05:53,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:53,488 INFO:     Epoch: 68
2023-01-03 23:05:55,100 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38999395867188774, 'Total loss': 0.38999395867188774} | train loss {'Reaction outcome loss': 0.19734624948651686, 'Total loss': 0.19734624948651686}
2023-01-03 23:05:55,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:55,100 INFO:     Epoch: 69
2023-01-03 23:05:56,672 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40401832858721415, 'Total loss': 0.40401832858721415} | train loss {'Reaction outcome loss': 0.19373830062520764, 'Total loss': 0.19373830062520764}
2023-01-03 23:05:56,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:56,672 INFO:     Epoch: 70
2023-01-03 23:05:58,274 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3800840506951014, 'Total loss': 0.3800840506951014} | train loss {'Reaction outcome loss': 0.1930119723326316, 'Total loss': 0.1930119723326316}
2023-01-03 23:05:58,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:58,274 INFO:     Epoch: 71
2023-01-03 23:05:59,860 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3852465162674586, 'Total loss': 0.3852465162674586} | train loss {'Reaction outcome loss': 0.1957123740202319, 'Total loss': 0.1957123740202319}
2023-01-03 23:05:59,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:05:59,860 INFO:     Epoch: 72
2023-01-03 23:06:01,459 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42051121493180593, 'Total loss': 0.42051121493180593} | train loss {'Reaction outcome loss': 0.19138041038038958, 'Total loss': 0.19138041038038958}
2023-01-03 23:06:01,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:01,459 INFO:     Epoch: 73
2023-01-03 23:06:03,065 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42794684171676634, 'Total loss': 0.42794684171676634} | train loss {'Reaction outcome loss': 0.19015430527174995, 'Total loss': 0.19015430527174995}
2023-01-03 23:06:03,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:03,067 INFO:     Epoch: 74
2023-01-03 23:06:04,653 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4246048331260681, 'Total loss': 0.4246048331260681} | train loss {'Reaction outcome loss': 0.1890686928858831, 'Total loss': 0.1890686928858831}
2023-01-03 23:06:04,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:04,653 INFO:     Epoch: 75
2023-01-03 23:06:06,293 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39904423455397287, 'Total loss': 0.39904423455397287} | train loss {'Reaction outcome loss': 0.19104311804212357, 'Total loss': 0.19104311804212357}
2023-01-03 23:06:06,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:06,293 INFO:     Epoch: 76
2023-01-03 23:06:07,915 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4410140226284663, 'Total loss': 0.4410140226284663} | train loss {'Reaction outcome loss': 0.18547158784838053, 'Total loss': 0.18547158784838053}
2023-01-03 23:06:07,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:07,915 INFO:     Epoch: 77
2023-01-03 23:06:09,521 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4178055008252462, 'Total loss': 0.4178055008252462} | train loss {'Reaction outcome loss': 0.18737695614950065, 'Total loss': 0.18737695614950065}
2023-01-03 23:06:09,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:09,522 INFO:     Epoch: 78
2023-01-03 23:06:11,133 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41577670474847156, 'Total loss': 0.41577670474847156} | train loss {'Reaction outcome loss': 0.1851788529867891, 'Total loss': 0.1851788529867891}
2023-01-03 23:06:11,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:11,133 INFO:     Epoch: 79
2023-01-03 23:06:12,750 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4246505637963613, 'Total loss': 0.4246505637963613} | train loss {'Reaction outcome loss': 0.18406801037898246, 'Total loss': 0.18406801037898246}
2023-01-03 23:06:12,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:12,751 INFO:     Epoch: 80
2023-01-03 23:06:14,361 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4383738358815511, 'Total loss': 0.4383738358815511} | train loss {'Reaction outcome loss': 0.18584588779150135, 'Total loss': 0.18584588779150135}
2023-01-03 23:06:14,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:14,361 INFO:     Epoch: 81
2023-01-03 23:06:15,976 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4233717660109202, 'Total loss': 0.4233717660109202} | train loss {'Reaction outcome loss': 0.1825891702918567, 'Total loss': 0.1825891702918567}
2023-01-03 23:06:15,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:15,976 INFO:     Epoch: 82
2023-01-03 23:06:17,571 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41309637427330015, 'Total loss': 0.41309637427330015} | train loss {'Reaction outcome loss': 0.18161573131861042, 'Total loss': 0.18161573131861042}
2023-01-03 23:06:17,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:17,571 INFO:     Epoch: 83
2023-01-03 23:06:19,163 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4081858217716217, 'Total loss': 0.4081858217716217} | train loss {'Reaction outcome loss': 0.18015356739833407, 'Total loss': 0.18015356739833407}
2023-01-03 23:06:19,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:19,163 INFO:     Epoch: 84
2023-01-03 23:06:20,783 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4245668431123098, 'Total loss': 0.4245668431123098} | train loss {'Reaction outcome loss': 0.18143908985394197, 'Total loss': 0.18143908985394197}
2023-01-03 23:06:20,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:20,784 INFO:     Epoch: 85
2023-01-03 23:06:22,414 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4450182398160299, 'Total loss': 0.4450182398160299} | train loss {'Reaction outcome loss': 0.1788717857120137, 'Total loss': 0.1788717857120137}
2023-01-03 23:06:22,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:22,415 INFO:     Epoch: 86
2023-01-03 23:06:24,050 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44533938765525816, 'Total loss': 0.44533938765525816} | train loss {'Reaction outcome loss': 0.17735581217591997, 'Total loss': 0.17735581217591997}
2023-01-03 23:06:24,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:24,051 INFO:     Epoch: 87
2023-01-03 23:06:25,677 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4079375028610229, 'Total loss': 0.4079375028610229} | train loss {'Reaction outcome loss': 0.17838907423327222, 'Total loss': 0.17838907423327222}
2023-01-03 23:06:25,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:25,678 INFO:     Epoch: 88
2023-01-03 23:06:27,281 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4263821065425873, 'Total loss': 0.4263821065425873} | train loss {'Reaction outcome loss': 0.17805226943897504, 'Total loss': 0.17805226943897504}
2023-01-03 23:06:27,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:27,281 INFO:     Epoch: 89
2023-01-03 23:06:28,872 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42019580900669096, 'Total loss': 0.42019580900669096} | train loss {'Reaction outcome loss': 0.17662837660198447, 'Total loss': 0.17662837660198447}
2023-01-03 23:06:28,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:28,873 INFO:     Epoch: 90
2023-01-03 23:06:30,477 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.393557600180308, 'Total loss': 0.393557600180308} | train loss {'Reaction outcome loss': 0.17603864474901862, 'Total loss': 0.17603864474901862}
2023-01-03 23:06:30,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:30,478 INFO:     Epoch: 91
2023-01-03 23:06:32,094 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4221848686536153, 'Total loss': 0.4221848686536153} | train loss {'Reaction outcome loss': 0.1730068160397728, 'Total loss': 0.1730068160397728}
2023-01-03 23:06:32,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:32,095 INFO:     Epoch: 92
2023-01-03 23:06:33,664 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4184740920861562, 'Total loss': 0.4184740920861562} | train loss {'Reaction outcome loss': 0.17596325444832553, 'Total loss': 0.17596325444832553}
2023-01-03 23:06:33,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:33,665 INFO:     Epoch: 93
2023-01-03 23:06:35,253 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41792238454023994, 'Total loss': 0.41792238454023994} | train loss {'Reaction outcome loss': 0.17374642939395168, 'Total loss': 0.17374642939395168}
2023-01-03 23:06:35,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:35,253 INFO:     Epoch: 94
2023-01-03 23:06:36,833 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44756882190704345, 'Total loss': 0.44756882190704345} | train loss {'Reaction outcome loss': 0.1742891861656069, 'Total loss': 0.1742891861656069}
2023-01-03 23:06:36,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:36,833 INFO:     Epoch: 95
2023-01-03 23:06:38,412 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4401659776767095, 'Total loss': 0.4401659776767095} | train loss {'Reaction outcome loss': 0.1723185516825884, 'Total loss': 0.1723185516825884}
2023-01-03 23:06:38,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:38,413 INFO:     Epoch: 96
2023-01-03 23:06:39,998 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44606788059075675, 'Total loss': 0.44606788059075675} | train loss {'Reaction outcome loss': 0.17254386936742677, 'Total loss': 0.17254386936742677}
2023-01-03 23:06:39,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:39,998 INFO:     Epoch: 97
2023-01-03 23:06:41,583 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4279574712117513, 'Total loss': 0.4279574712117513} | train loss {'Reaction outcome loss': 0.17264019486487564, 'Total loss': 0.17264019486487564}
2023-01-03 23:06:41,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:41,583 INFO:     Epoch: 98
2023-01-03 23:06:43,168 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4149298697710037, 'Total loss': 0.4149298697710037} | train loss {'Reaction outcome loss': 0.17010990167240592, 'Total loss': 0.17010990167240592}
2023-01-03 23:06:43,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:43,169 INFO:     Epoch: 99
2023-01-03 23:06:44,727 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44574496845404304, 'Total loss': 0.44574496845404304} | train loss {'Reaction outcome loss': 0.1717315787163964, 'Total loss': 0.1717315787163964}
2023-01-03 23:06:44,727 INFO:     Best model found after epoch 34 of 100.
2023-01-03 23:06:44,728 INFO:   Done with stage: TRAINING
2023-01-03 23:06:44,728 INFO:   Starting stage: EVALUATION
2023-01-03 23:06:44,863 INFO:   Done with stage: EVALUATION
2023-01-03 23:06:44,863 INFO:   Leaving out SEQ value Fold_4
2023-01-03 23:06:44,876 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-03 23:06:44,876 INFO:   Starting stage: FEATURE SCALING
2023-01-03 23:06:45,519 INFO:   Done with stage: FEATURE SCALING
2023-01-03 23:06:45,519 INFO:   Starting stage: SCALING TARGETS
2023-01-03 23:06:45,590 INFO:   Done with stage: SCALING TARGETS
2023-01-03 23:06:45,590 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:06:45,590 INFO:     No hyperparam tuning for this model
2023-01-03 23:06:45,590 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:06:45,590 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 23:06:45,591 INFO:     None feature selector for col prot
2023-01-03 23:06:45,591 INFO:     None feature selector for col prot
2023-01-03 23:06:45,591 INFO:     None feature selector for col prot
2023-01-03 23:06:45,591 INFO:     None feature selector for col chem
2023-01-03 23:06:45,591 INFO:     None feature selector for col chem
2023-01-03 23:06:45,592 INFO:     None feature selector for col chem
2023-01-03 23:06:45,592 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 23:06:45,592 INFO:   Starting stage: BUILD MODEL
2023-01-03 23:06:45,593 INFO:     Number of params in model 70141
2023-01-03 23:06:45,596 INFO:   Done with stage: BUILD MODEL
2023-01-03 23:06:45,596 INFO:   Starting stage: TRAINING
2023-01-03 23:06:45,639 INFO:     Val loss before train {'Reaction outcome loss': 0.9790367841720581, 'Total loss': 0.9790367841720581}
2023-01-03 23:06:45,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:45,640 INFO:     Epoch: 0
2023-01-03 23:06:47,225 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6335632542769114, 'Total loss': 0.6335632542769114} | train loss {'Reaction outcome loss': 0.8348203805023736, 'Total loss': 0.8348203805023736}
2023-01-03 23:06:47,225 INFO:     Found new best model at epoch 0
2023-01-03 23:06:47,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:47,226 INFO:     Epoch: 1
2023-01-03 23:06:48,800 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5528950293858846, 'Total loss': 0.5528950293858846} | train loss {'Reaction outcome loss': 0.5978220819774336, 'Total loss': 0.5978220819774336}
2023-01-03 23:06:48,800 INFO:     Found new best model at epoch 1
2023-01-03 23:06:48,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:48,801 INFO:     Epoch: 2
2023-01-03 23:06:50,377 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.537124248345693, 'Total loss': 0.537124248345693} | train loss {'Reaction outcome loss': 0.5138822454605659, 'Total loss': 0.5138822454605659}
2023-01-03 23:06:50,377 INFO:     Found new best model at epoch 2
2023-01-03 23:06:50,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:50,378 INFO:     Epoch: 3
2023-01-03 23:06:51,975 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48959253827730814, 'Total loss': 0.48959253827730814} | train loss {'Reaction outcome loss': 0.4764312555211304, 'Total loss': 0.4764312555211304}
2023-01-03 23:06:51,975 INFO:     Found new best model at epoch 3
2023-01-03 23:06:51,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:51,976 INFO:     Epoch: 4
2023-01-03 23:06:53,538 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4959652304649353, 'Total loss': 0.4959652304649353} | train loss {'Reaction outcome loss': 0.4486821276428056, 'Total loss': 0.4486821276428056}
2023-01-03 23:06:53,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:53,539 INFO:     Epoch: 5
2023-01-03 23:06:55,105 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4529947241147359, 'Total loss': 0.4529947241147359} | train loss {'Reaction outcome loss': 0.4278953768530466, 'Total loss': 0.4278953768530466}
2023-01-03 23:06:55,106 INFO:     Found new best model at epoch 5
2023-01-03 23:06:55,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:55,107 INFO:     Epoch: 6
2023-01-03 23:06:56,688 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4351393183072408, 'Total loss': 0.4351393183072408} | train loss {'Reaction outcome loss': 0.4137772771998914, 'Total loss': 0.4137772771998914}
2023-01-03 23:06:56,689 INFO:     Found new best model at epoch 6
2023-01-03 23:06:56,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:56,690 INFO:     Epoch: 7
2023-01-03 23:06:58,270 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4550964891910553, 'Total loss': 0.4550964891910553} | train loss {'Reaction outcome loss': 0.39789949303125816, 'Total loss': 0.39789949303125816}
2023-01-03 23:06:58,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:58,271 INFO:     Epoch: 8
2023-01-03 23:06:59,852 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43454754451910654, 'Total loss': 0.43454754451910654} | train loss {'Reaction outcome loss': 0.389320078883728, 'Total loss': 0.389320078883728}
2023-01-03 23:06:59,852 INFO:     Found new best model at epoch 8
2023-01-03 23:06:59,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:06:59,853 INFO:     Epoch: 9
2023-01-03 23:07:01,413 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41734215021133425, 'Total loss': 0.41734215021133425} | train loss {'Reaction outcome loss': 0.3783348778357906, 'Total loss': 0.3783348778357906}
2023-01-03 23:07:01,413 INFO:     Found new best model at epoch 9
2023-01-03 23:07:01,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:01,414 INFO:     Epoch: 10
2023-01-03 23:07:03,036 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4284051388502121, 'Total loss': 0.4284051388502121} | train loss {'Reaction outcome loss': 0.3672597032774539, 'Total loss': 0.3672597032774539}
2023-01-03 23:07:03,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:03,036 INFO:     Epoch: 11
2023-01-03 23:07:04,624 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42798588474591576, 'Total loss': 0.42798588474591576} | train loss {'Reaction outcome loss': 0.3625916645583445, 'Total loss': 0.3625916645583445}
2023-01-03 23:07:04,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:04,624 INFO:     Epoch: 12
2023-01-03 23:07:06,232 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40346511925260226, 'Total loss': 0.40346511925260226} | train loss {'Reaction outcome loss': 0.3541028848203429, 'Total loss': 0.3541028848203429}
2023-01-03 23:07:06,232 INFO:     Found new best model at epoch 12
2023-01-03 23:07:06,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:06,233 INFO:     Epoch: 13
2023-01-03 23:07:07,838 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4012749622265498, 'Total loss': 0.4012749622265498} | train loss {'Reaction outcome loss': 0.3496657995520717, 'Total loss': 0.3496657995520717}
2023-01-03 23:07:07,838 INFO:     Found new best model at epoch 13
2023-01-03 23:07:07,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:07,839 INFO:     Epoch: 14
2023-01-03 23:07:09,446 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.38989242911338806, 'Total loss': 0.38989242911338806} | train loss {'Reaction outcome loss': 0.34163549202528315, 'Total loss': 0.34163549202528315}
2023-01-03 23:07:09,446 INFO:     Found new best model at epoch 14
2023-01-03 23:07:09,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:09,447 INFO:     Epoch: 15
2023-01-03 23:07:11,027 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3955921391646067, 'Total loss': 0.3955921391646067} | train loss {'Reaction outcome loss': 0.3373599627537884, 'Total loss': 0.3373599627537884}
2023-01-03 23:07:11,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:11,028 INFO:     Epoch: 16
2023-01-03 23:07:12,611 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3893388176957766, 'Total loss': 0.3893388176957766} | train loss {'Reaction outcome loss': 0.33098871734020485, 'Total loss': 0.33098871734020485}
2023-01-03 23:07:12,612 INFO:     Found new best model at epoch 16
2023-01-03 23:07:12,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:12,612 INFO:     Epoch: 17
2023-01-03 23:07:14,196 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40528371135393776, 'Total loss': 0.40528371135393776} | train loss {'Reaction outcome loss': 0.3265611598145788, 'Total loss': 0.3265611598145788}
2023-01-03 23:07:14,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:14,197 INFO:     Epoch: 18
2023-01-03 23:07:15,783 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.397862250606219, 'Total loss': 0.397862250606219} | train loss {'Reaction outcome loss': 0.3209976673289372, 'Total loss': 0.3209976673289372}
2023-01-03 23:07:15,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:15,783 INFO:     Epoch: 19
2023-01-03 23:07:17,366 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44795093685388565, 'Total loss': 0.44795093685388565} | train loss {'Reaction outcome loss': 0.3146772083629222, 'Total loss': 0.3146772083629222}
2023-01-03 23:07:17,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:17,366 INFO:     Epoch: 20
2023-01-03 23:07:18,946 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39907060861587523, 'Total loss': 0.39907060861587523} | train loss {'Reaction outcome loss': 0.31021810116341514, 'Total loss': 0.31021810116341514}
2023-01-03 23:07:18,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:18,946 INFO:     Epoch: 21
2023-01-03 23:07:20,534 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3625079969565074, 'Total loss': 0.3625079969565074} | train loss {'Reaction outcome loss': 0.3046500050891055, 'Total loss': 0.3046500050891055}
2023-01-03 23:07:20,535 INFO:     Found new best model at epoch 21
2023-01-03 23:07:20,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:20,536 INFO:     Epoch: 22
2023-01-03 23:07:22,111 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39580792287985483, 'Total loss': 0.39580792287985483} | train loss {'Reaction outcome loss': 0.3015005714158072, 'Total loss': 0.3015005714158072}
2023-01-03 23:07:22,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:22,112 INFO:     Epoch: 23
2023-01-03 23:07:23,717 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39944491187731423, 'Total loss': 0.39944491187731423} | train loss {'Reaction outcome loss': 0.29709110789707976, 'Total loss': 0.29709110789707976}
2023-01-03 23:07:23,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:23,717 INFO:     Epoch: 24
2023-01-03 23:07:25,321 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4279328852891922, 'Total loss': 0.4279328852891922} | train loss {'Reaction outcome loss': 0.2918303925951902, 'Total loss': 0.2918303925951902}
2023-01-03 23:07:25,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:25,321 INFO:     Epoch: 25
2023-01-03 23:07:26,926 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.38865816990534463, 'Total loss': 0.38865816990534463} | train loss {'Reaction outcome loss': 0.2873316719638605, 'Total loss': 0.2873316719638605}
2023-01-03 23:07:26,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:26,926 INFO:     Epoch: 26
2023-01-03 23:07:28,514 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39477476676305134, 'Total loss': 0.39477476676305134} | train loss {'Reaction outcome loss': 0.2840878738865365, 'Total loss': 0.2840878738865365}
2023-01-03 23:07:28,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:28,514 INFO:     Epoch: 27
2023-01-03 23:07:30,094 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3630889614423116, 'Total loss': 0.3630889614423116} | train loss {'Reaction outcome loss': 0.27910183046529763, 'Total loss': 0.27910183046529763}
2023-01-03 23:07:30,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:30,094 INFO:     Epoch: 28
2023-01-03 23:07:31,658 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3725881904363632, 'Total loss': 0.3725881904363632} | train loss {'Reaction outcome loss': 0.2771344535922917, 'Total loss': 0.2771344535922917}
2023-01-03 23:07:31,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:31,658 INFO:     Epoch: 29
2023-01-03 23:07:33,244 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38381441434224445, 'Total loss': 0.38381441434224445} | train loss {'Reaction outcome loss': 0.27261781107879035, 'Total loss': 0.27261781107879035}
2023-01-03 23:07:33,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:33,245 INFO:     Epoch: 30
2023-01-03 23:07:34,823 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3861953814824422, 'Total loss': 0.3861953814824422} | train loss {'Reaction outcome loss': 0.2704018238034562, 'Total loss': 0.2704018238034562}
2023-01-03 23:07:34,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:34,824 INFO:     Epoch: 31
2023-01-03 23:07:36,407 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.368790132800738, 'Total loss': 0.368790132800738} | train loss {'Reaction outcome loss': 0.267685991596349, 'Total loss': 0.267685991596349}
2023-01-03 23:07:36,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:36,407 INFO:     Epoch: 32
2023-01-03 23:07:37,974 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3952312539021174, 'Total loss': 0.3952312539021174} | train loss {'Reaction outcome loss': 0.26371000410757794, 'Total loss': 0.26371000410757794}
2023-01-03 23:07:37,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:37,974 INFO:     Epoch: 33
2023-01-03 23:07:39,536 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3916337559620539, 'Total loss': 0.3916337559620539} | train loss {'Reaction outcome loss': 0.258797582945902, 'Total loss': 0.258797582945902}
2023-01-03 23:07:39,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:39,536 INFO:     Epoch: 34
2023-01-03 23:07:41,112 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.37694515188535055, 'Total loss': 0.37694515188535055} | train loss {'Reaction outcome loss': 0.2574875493173617, 'Total loss': 0.2574875493173617}
2023-01-03 23:07:41,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:41,112 INFO:     Epoch: 35
2023-01-03 23:07:42,688 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3983264605204264, 'Total loss': 0.3983264605204264} | train loss {'Reaction outcome loss': 0.25637175969398807, 'Total loss': 0.25637175969398807}
2023-01-03 23:07:42,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:42,688 INFO:     Epoch: 36
2023-01-03 23:07:44,289 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37772947748502095, 'Total loss': 0.37772947748502095} | train loss {'Reaction outcome loss': 0.251295091258022, 'Total loss': 0.251295091258022}
2023-01-03 23:07:44,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:44,289 INFO:     Epoch: 37
2023-01-03 23:07:45,900 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3748026599486669, 'Total loss': 0.3748026599486669} | train loss {'Reaction outcome loss': 0.2470247379782861, 'Total loss': 0.2470247379782861}
2023-01-03 23:07:45,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:45,900 INFO:     Epoch: 38
2023-01-03 23:07:47,463 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39636371632417045, 'Total loss': 0.39636371632417045} | train loss {'Reaction outcome loss': 0.24825275116973985, 'Total loss': 0.24825275116973985}
2023-01-03 23:07:47,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:47,464 INFO:     Epoch: 39
2023-01-03 23:07:49,024 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.37964912950992585, 'Total loss': 0.37964912950992585} | train loss {'Reaction outcome loss': 0.24671802919929045, 'Total loss': 0.24671802919929045}
2023-01-03 23:07:49,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:49,025 INFO:     Epoch: 40
2023-01-03 23:07:50,595 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.376957901318868, 'Total loss': 0.376957901318868} | train loss {'Reaction outcome loss': 0.24269703967347198, 'Total loss': 0.24269703967347198}
2023-01-03 23:07:50,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:50,597 INFO:     Epoch: 41
2023-01-03 23:07:52,202 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3918956140677134, 'Total loss': 0.3918956140677134} | train loss {'Reaction outcome loss': 0.23981094886514828, 'Total loss': 0.23981094886514828}
2023-01-03 23:07:52,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:52,202 INFO:     Epoch: 42
2023-01-03 23:07:53,811 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4150653089086215, 'Total loss': 0.4150653089086215} | train loss {'Reaction outcome loss': 0.23835907982539956, 'Total loss': 0.23835907982539956}
2023-01-03 23:07:53,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:53,812 INFO:     Epoch: 43
2023-01-03 23:07:55,397 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3779080202182134, 'Total loss': 0.3779080202182134} | train loss {'Reaction outcome loss': 0.2353641124047937, 'Total loss': 0.2353641124047937}
2023-01-03 23:07:55,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:55,397 INFO:     Epoch: 44
2023-01-03 23:07:56,987 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3907812337080638, 'Total loss': 0.3907812337080638} | train loss {'Reaction outcome loss': 0.23582765090204502, 'Total loss': 0.23582765090204502}
2023-01-03 23:07:56,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:56,988 INFO:     Epoch: 45
2023-01-03 23:07:58,573 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39107317129770913, 'Total loss': 0.39107317129770913} | train loss {'Reaction outcome loss': 0.23134424546937438, 'Total loss': 0.23134424546937438}
2023-01-03 23:07:58,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:07:58,573 INFO:     Epoch: 46
2023-01-03 23:08:00,177 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4072810928026835, 'Total loss': 0.4072810928026835} | train loss {'Reaction outcome loss': 0.22968406567390817, 'Total loss': 0.22968406567390817}
2023-01-03 23:08:00,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:00,177 INFO:     Epoch: 47
2023-01-03 23:08:01,784 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4144473701715469, 'Total loss': 0.4144473701715469} | train loss {'Reaction outcome loss': 0.2287224900711627, 'Total loss': 0.2287224900711627}
2023-01-03 23:08:01,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:01,785 INFO:     Epoch: 48
2023-01-03 23:08:03,393 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3874467184146245, 'Total loss': 0.3874467184146245} | train loss {'Reaction outcome loss': 0.22451751204683398, 'Total loss': 0.22451751204683398}
2023-01-03 23:08:03,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:03,393 INFO:     Epoch: 49
2023-01-03 23:08:04,946 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4010569055875142, 'Total loss': 0.4010569055875142} | train loss {'Reaction outcome loss': 0.22506960582015287, 'Total loss': 0.22506960582015287}
2023-01-03 23:08:04,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:04,946 INFO:     Epoch: 50
2023-01-03 23:08:06,513 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41991794655720394, 'Total loss': 0.41991794655720394} | train loss {'Reaction outcome loss': 0.22380400314437646, 'Total loss': 0.22380400314437646}
2023-01-03 23:08:06,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:06,514 INFO:     Epoch: 51
2023-01-03 23:08:08,117 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3973974277575811, 'Total loss': 0.3973974277575811} | train loss {'Reaction outcome loss': 0.22144007272882402, 'Total loss': 0.22144007272882402}
2023-01-03 23:08:08,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:08,117 INFO:     Epoch: 52
2023-01-03 23:08:09,717 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3917666216691335, 'Total loss': 0.3917666216691335} | train loss {'Reaction outcome loss': 0.21941913464480509, 'Total loss': 0.21941913464480509}
2023-01-03 23:08:09,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:09,718 INFO:     Epoch: 53
2023-01-03 23:08:11,308 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3983638554811478, 'Total loss': 0.3983638554811478} | train loss {'Reaction outcome loss': 0.21939881919563686, 'Total loss': 0.21939881919563686}
2023-01-03 23:08:11,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:11,308 INFO:     Epoch: 54
2023-01-03 23:08:12,915 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3984343945980072, 'Total loss': 0.3984343945980072} | train loss {'Reaction outcome loss': 0.21773527742084794, 'Total loss': 0.21773527742084794}
2023-01-03 23:08:12,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:12,915 INFO:     Epoch: 55
2023-01-03 23:08:14,511 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38907936712106067, 'Total loss': 0.38907936712106067} | train loss {'Reaction outcome loss': 0.2134618745967202, 'Total loss': 0.2134618745967202}
2023-01-03 23:08:14,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:14,511 INFO:     Epoch: 56
2023-01-03 23:08:16,073 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40629153152306874, 'Total loss': 0.40629153152306874} | train loss {'Reaction outcome loss': 0.21300447176135803, 'Total loss': 0.21300447176135803}
2023-01-03 23:08:16,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:16,073 INFO:     Epoch: 57
2023-01-03 23:08:17,676 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3963337500890096, 'Total loss': 0.3963337500890096} | train loss {'Reaction outcome loss': 0.21108181814044497, 'Total loss': 0.21108181814044497}
2023-01-03 23:08:17,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:17,677 INFO:     Epoch: 58
2023-01-03 23:08:19,280 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3799814065297445, 'Total loss': 0.3799814065297445} | train loss {'Reaction outcome loss': 0.21111305112386272, 'Total loss': 0.21111305112386272}
2023-01-03 23:08:19,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:19,281 INFO:     Epoch: 59
2023-01-03 23:08:20,885 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39602864185969033, 'Total loss': 0.39602864185969033} | train loss {'Reaction outcome loss': 0.20798594809144083, 'Total loss': 0.20798594809144083}
2023-01-03 23:08:20,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:20,885 INFO:     Epoch: 60
2023-01-03 23:08:22,462 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4020319978396098, 'Total loss': 0.4020319978396098} | train loss {'Reaction outcome loss': 0.20992632217052645, 'Total loss': 0.20992632217052645}
2023-01-03 23:08:22,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:22,463 INFO:     Epoch: 61
2023-01-03 23:08:24,031 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3772665192683538, 'Total loss': 0.3772665192683538} | train loss {'Reaction outcome loss': 0.20424953026928172, 'Total loss': 0.20424953026928172}
2023-01-03 23:08:24,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:24,031 INFO:     Epoch: 62
2023-01-03 23:08:25,631 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39871115585168204, 'Total loss': 0.39871115585168204} | train loss {'Reaction outcome loss': 0.20629426520181834, 'Total loss': 0.20629426520181834}
2023-01-03 23:08:25,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:25,632 INFO:     Epoch: 63
2023-01-03 23:08:27,217 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38040210207303365, 'Total loss': 0.38040210207303365} | train loss {'Reaction outcome loss': 0.20513854637388548, 'Total loss': 0.20513854637388548}
2023-01-03 23:08:27,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:27,217 INFO:     Epoch: 64
2023-01-03 23:08:28,803 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42477690875530244, 'Total loss': 0.42477690875530244} | train loss {'Reaction outcome loss': 0.20262024936395406, 'Total loss': 0.20262024936395406}
2023-01-03 23:08:28,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:28,803 INFO:     Epoch: 65
2023-01-03 23:08:30,408 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3901504298051198, 'Total loss': 0.3901504298051198} | train loss {'Reaction outcome loss': 0.19830372319114906, 'Total loss': 0.19830372319114906}
2023-01-03 23:08:30,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:30,408 INFO:     Epoch: 66
2023-01-03 23:08:31,974 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4201961507399877, 'Total loss': 0.4201961507399877} | train loss {'Reaction outcome loss': 0.19813494520248287, 'Total loss': 0.19813494520248287}
2023-01-03 23:08:31,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:31,975 INFO:     Epoch: 67
2023-01-03 23:08:33,544 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4220034380753835, 'Total loss': 0.4220034380753835} | train loss {'Reaction outcome loss': 0.19840976945294517, 'Total loss': 0.19840976945294517}
2023-01-03 23:08:33,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:33,545 INFO:     Epoch: 68
2023-01-03 23:08:35,125 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.418176132440567, 'Total loss': 0.418176132440567} | train loss {'Reaction outcome loss': 0.1950117885984861, 'Total loss': 0.1950117885984861}
2023-01-03 23:08:35,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:35,125 INFO:     Epoch: 69
2023-01-03 23:08:36,704 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3723810245593389, 'Total loss': 0.3723810245593389} | train loss {'Reaction outcome loss': 0.19456132718898955, 'Total loss': 0.19456132718898955}
2023-01-03 23:08:36,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:36,705 INFO:     Epoch: 70
2023-01-03 23:08:38,284 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4045491337776184, 'Total loss': 0.4045491337776184} | train loss {'Reaction outcome loss': 0.19374429184372408, 'Total loss': 0.19374429184372408}
2023-01-03 23:08:38,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:38,284 INFO:     Epoch: 71
2023-01-03 23:08:39,851 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3887760390837987, 'Total loss': 0.3887760390837987} | train loss {'Reaction outcome loss': 0.19463383526045042, 'Total loss': 0.19463383526045042}
2023-01-03 23:08:39,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:39,851 INFO:     Epoch: 72
2023-01-03 23:08:41,429 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40841703514258065, 'Total loss': 0.40841703514258065} | train loss {'Reaction outcome loss': 0.19365641575333845, 'Total loss': 0.19365641575333845}
2023-01-03 23:08:41,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:41,429 INFO:     Epoch: 73
2023-01-03 23:08:42,988 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3968725522359212, 'Total loss': 0.3968725522359212} | train loss {'Reaction outcome loss': 0.1926537627748547, 'Total loss': 0.1926537627748547}
2023-01-03 23:08:42,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:42,988 INFO:     Epoch: 74
2023-01-03 23:08:44,594 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4081840376059214, 'Total loss': 0.4081840376059214} | train loss {'Reaction outcome loss': 0.19066376447079392, 'Total loss': 0.19066376447079392}
2023-01-03 23:08:44,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:44,595 INFO:     Epoch: 75
2023-01-03 23:08:46,174 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39015800654888155, 'Total loss': 0.39015800654888155} | train loss {'Reaction outcome loss': 0.19245299745187924, 'Total loss': 0.19245299745187924}
2023-01-03 23:08:46,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:46,174 INFO:     Epoch: 76
2023-01-03 23:08:47,760 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.415417139728864, 'Total loss': 0.415417139728864} | train loss {'Reaction outcome loss': 0.1879484426012657, 'Total loss': 0.1879484426012657}
2023-01-03 23:08:47,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:47,760 INFO:     Epoch: 77
2023-01-03 23:08:49,343 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4179102391004562, 'Total loss': 0.4179102391004562} | train loss {'Reaction outcome loss': 0.18903677138316372, 'Total loss': 0.18903677138316372}
2023-01-03 23:08:49,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:49,343 INFO:     Epoch: 78
2023-01-03 23:08:50,937 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39626398086547854, 'Total loss': 0.39626398086547854} | train loss {'Reaction outcome loss': 0.18650919564720922, 'Total loss': 0.18650919564720922}
2023-01-03 23:08:50,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:50,938 INFO:     Epoch: 79
2023-01-03 23:08:52,516 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4213068693876266, 'Total loss': 0.4213068693876266} | train loss {'Reaction outcome loss': 0.1883737271801181, 'Total loss': 0.1883737271801181}
2023-01-03 23:08:52,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:52,517 INFO:     Epoch: 80
2023-01-03 23:08:54,098 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4115741024414698, 'Total loss': 0.4115741024414698} | train loss {'Reaction outcome loss': 0.18655815063193984, 'Total loss': 0.18655815063193984}
2023-01-03 23:08:54,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:54,098 INFO:     Epoch: 81
2023-01-03 23:08:55,679 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4128593693176905, 'Total loss': 0.4128593693176905} | train loss {'Reaction outcome loss': 0.1847591244132958, 'Total loss': 0.1847591244132958}
2023-01-03 23:08:55,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:55,680 INFO:     Epoch: 82
2023-01-03 23:08:57,259 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3891814221938451, 'Total loss': 0.3891814221938451} | train loss {'Reaction outcome loss': 0.18480860258377815, 'Total loss': 0.18480860258377815}
2023-01-03 23:08:57,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:57,260 INFO:     Epoch: 83
2023-01-03 23:08:58,827 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4221399625142415, 'Total loss': 0.4221399625142415} | train loss {'Reaction outcome loss': 0.18340264153360886, 'Total loss': 0.18340264153360886}
2023-01-03 23:08:58,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:08:58,827 INFO:     Epoch: 84
2023-01-03 23:09:00,399 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40722582340240476, 'Total loss': 0.40722582340240476} | train loss {'Reaction outcome loss': 0.18320731135479507, 'Total loss': 0.18320731135479507}
2023-01-03 23:09:00,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:00,400 INFO:     Epoch: 85
2023-01-03 23:09:01,980 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3860140934586525, 'Total loss': 0.3860140934586525} | train loss {'Reaction outcome loss': 0.18384675296145853, 'Total loss': 0.18384675296145853}
2023-01-03 23:09:01,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:01,981 INFO:     Epoch: 86
2023-01-03 23:09:03,561 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.39970077176888785, 'Total loss': 0.39970077176888785} | train loss {'Reaction outcome loss': 0.18206090072210687, 'Total loss': 0.18206090072210687}
2023-01-03 23:09:03,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:03,562 INFO:     Epoch: 87
2023-01-03 23:09:05,145 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40542699297269186, 'Total loss': 0.40542699297269186} | train loss {'Reaction outcome loss': 0.18198210518997515, 'Total loss': 0.18198210518997515}
2023-01-03 23:09:05,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:05,145 INFO:     Epoch: 88
2023-01-03 23:09:06,706 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4286961326996485, 'Total loss': 0.4286961326996485} | train loss {'Reaction outcome loss': 0.18045858577927099, 'Total loss': 0.18045858577927099}
2023-01-03 23:09:06,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:06,706 INFO:     Epoch: 89
2023-01-03 23:09:08,323 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4093801885843277, 'Total loss': 0.4093801885843277} | train loss {'Reaction outcome loss': 0.1802221521272929, 'Total loss': 0.1802221521272929}
2023-01-03 23:09:08,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:08,324 INFO:     Epoch: 90
2023-01-03 23:09:09,908 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4115592082341512, 'Total loss': 0.4115592082341512} | train loss {'Reaction outcome loss': 0.17810526839627402, 'Total loss': 0.17810526839627402}
2023-01-03 23:09:09,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:09,908 INFO:     Epoch: 91
2023-01-03 23:09:11,522 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3991565654675166, 'Total loss': 0.3991565654675166} | train loss {'Reaction outcome loss': 0.17719610779117928, 'Total loss': 0.17719610779117928}
2023-01-03 23:09:11,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:11,522 INFO:     Epoch: 92
2023-01-03 23:09:13,122 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4018895775079727, 'Total loss': 0.4018895775079727} | train loss {'Reaction outcome loss': 0.1776605750345727, 'Total loss': 0.1776605750345727}
2023-01-03 23:09:13,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:13,122 INFO:     Epoch: 93
2023-01-03 23:09:14,731 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4192102948824565, 'Total loss': 0.4192102948824565} | train loss {'Reaction outcome loss': 0.17557207042229, 'Total loss': 0.17557207042229}
2023-01-03 23:09:14,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:14,732 INFO:     Epoch: 94
2023-01-03 23:09:16,309 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39249665836493175, 'Total loss': 0.39249665836493175} | train loss {'Reaction outcome loss': 0.17439133706536605, 'Total loss': 0.17439133706536605}
2023-01-03 23:09:16,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:16,310 INFO:     Epoch: 95
2023-01-03 23:09:17,896 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39633831481138865, 'Total loss': 0.39633831481138865} | train loss {'Reaction outcome loss': 0.1755018547911496, 'Total loss': 0.1755018547911496}
2023-01-03 23:09:17,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:17,896 INFO:     Epoch: 96
2023-01-03 23:09:19,477 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.431349308292071, 'Total loss': 0.431349308292071} | train loss {'Reaction outcome loss': 0.1749614461012402, 'Total loss': 0.1749614461012402}
2023-01-03 23:09:19,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:19,477 INFO:     Epoch: 97
2023-01-03 23:09:21,056 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43497765958309176, 'Total loss': 0.43497765958309176} | train loss {'Reaction outcome loss': 0.1746567115187645, 'Total loss': 0.1746567115187645}
2023-01-03 23:09:21,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:21,056 INFO:     Epoch: 98
2023-01-03 23:09:22,636 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4111031830310822, 'Total loss': 0.4111031830310822} | train loss {'Reaction outcome loss': 0.17313855477901052, 'Total loss': 0.17313855477901052}
2023-01-03 23:09:22,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:22,636 INFO:     Epoch: 99
2023-01-03 23:09:24,217 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42983290553092957, 'Total loss': 0.42983290553092957} | train loss {'Reaction outcome loss': 0.1718151933398016, 'Total loss': 0.1718151933398016}
2023-01-03 23:09:24,217 INFO:     Best model found after epoch 22 of 100.
2023-01-03 23:09:24,217 INFO:   Done with stage: TRAINING
2023-01-03 23:09:24,217 INFO:   Starting stage: EVALUATION
2023-01-03 23:09:24,350 INFO:   Done with stage: EVALUATION
2023-01-03 23:09:24,350 INFO:   Leaving out SEQ value Fold_5
2023-01-03 23:09:24,363 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-03 23:09:24,363 INFO:   Starting stage: FEATURE SCALING
2023-01-03 23:09:25,007 INFO:   Done with stage: FEATURE SCALING
2023-01-03 23:09:25,008 INFO:   Starting stage: SCALING TARGETS
2023-01-03 23:09:25,078 INFO:   Done with stage: SCALING TARGETS
2023-01-03 23:09:25,078 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:09:25,078 INFO:     No hyperparam tuning for this model
2023-01-03 23:09:25,078 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:09:25,078 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 23:09:25,079 INFO:     None feature selector for col prot
2023-01-03 23:09:25,079 INFO:     None feature selector for col prot
2023-01-03 23:09:25,079 INFO:     None feature selector for col prot
2023-01-03 23:09:25,079 INFO:     None feature selector for col chem
2023-01-03 23:09:25,080 INFO:     None feature selector for col chem
2023-01-03 23:09:25,080 INFO:     None feature selector for col chem
2023-01-03 23:09:25,080 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 23:09:25,080 INFO:   Starting stage: BUILD MODEL
2023-01-03 23:09:25,081 INFO:     Number of params in model 70141
2023-01-03 23:09:25,084 INFO:   Done with stage: BUILD MODEL
2023-01-03 23:09:25,084 INFO:   Starting stage: TRAINING
2023-01-03 23:09:25,128 INFO:     Val loss before train {'Reaction outcome loss': 1.0410335501035055, 'Total loss': 1.0410335501035055}
2023-01-03 23:09:25,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:25,128 INFO:     Epoch: 0
2023-01-03 23:09:26,706 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6797448376814524, 'Total loss': 0.6797448376814524} | train loss {'Reaction outcome loss': 0.8770434771111046, 'Total loss': 0.8770434771111046}
2023-01-03 23:09:26,706 INFO:     Found new best model at epoch 0
2023-01-03 23:09:26,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:26,707 INFO:     Epoch: 1
2023-01-03 23:09:28,292 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5651133596897125, 'Total loss': 0.5651133596897125} | train loss {'Reaction outcome loss': 0.6236904065792813, 'Total loss': 0.6236904065792813}
2023-01-03 23:09:28,292 INFO:     Found new best model at epoch 1
2023-01-03 23:09:28,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:28,293 INFO:     Epoch: 2
2023-01-03 23:09:29,883 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.501023934284846, 'Total loss': 0.501023934284846} | train loss {'Reaction outcome loss': 0.5425016479296745, 'Total loss': 0.5425016479296745}
2023-01-03 23:09:29,883 INFO:     Found new best model at epoch 2
2023-01-03 23:09:29,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:29,884 INFO:     Epoch: 3
2023-01-03 23:09:31,462 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47628435492515564, 'Total loss': 0.47628435492515564} | train loss {'Reaction outcome loss': 0.5030243613257788, 'Total loss': 0.5030243613257788}
2023-01-03 23:09:31,462 INFO:     Found new best model at epoch 3
2023-01-03 23:09:31,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:31,463 INFO:     Epoch: 4
2023-01-03 23:09:33,044 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4634610970815023, 'Total loss': 0.4634610970815023} | train loss {'Reaction outcome loss': 0.47287510678944417, 'Total loss': 0.47287510678944417}
2023-01-03 23:09:33,045 INFO:     Found new best model at epoch 4
2023-01-03 23:09:33,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:33,046 INFO:     Epoch: 5
2023-01-03 23:09:34,652 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.468737796942393, 'Total loss': 0.468737796942393} | train loss {'Reaction outcome loss': 0.45642485923093296, 'Total loss': 0.45642485923093296}
2023-01-03 23:09:34,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:34,653 INFO:     Epoch: 6
2023-01-03 23:09:36,242 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44320339560508726, 'Total loss': 0.44320339560508726} | train loss {'Reaction outcome loss': 0.43692310359598935, 'Total loss': 0.43692310359598935}
2023-01-03 23:09:36,242 INFO:     Found new best model at epoch 6
2023-01-03 23:09:36,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:36,243 INFO:     Epoch: 7
2023-01-03 23:09:37,843 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44266094962755836, 'Total loss': 0.44266094962755836} | train loss {'Reaction outcome loss': 0.4193249761896289, 'Total loss': 0.4193249761896289}
2023-01-03 23:09:37,843 INFO:     Found new best model at epoch 7
2023-01-03 23:09:37,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:37,844 INFO:     Epoch: 8
2023-01-03 23:09:39,435 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4408929566542307, 'Total loss': 0.4408929566542307} | train loss {'Reaction outcome loss': 0.4083412800569813, 'Total loss': 0.4083412800569813}
2023-01-03 23:09:39,436 INFO:     Found new best model at epoch 8
2023-01-03 23:09:39,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:39,437 INFO:     Epoch: 9
2023-01-03 23:09:41,026 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4210194021463394, 'Total loss': 0.4210194021463394} | train loss {'Reaction outcome loss': 0.3954325343846627, 'Total loss': 0.3954325343846627}
2023-01-03 23:09:41,026 INFO:     Found new best model at epoch 9
2023-01-03 23:09:41,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:41,027 INFO:     Epoch: 10
2023-01-03 23:09:42,617 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4398286680380503, 'Total loss': 0.4398286680380503} | train loss {'Reaction outcome loss': 0.38464539083407623, 'Total loss': 0.38464539083407623}
2023-01-03 23:09:42,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:42,617 INFO:     Epoch: 11
2023-01-03 23:09:44,202 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4238355894883474, 'Total loss': 0.4238355894883474} | train loss {'Reaction outcome loss': 0.375919216727514, 'Total loss': 0.375919216727514}
2023-01-03 23:09:44,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:44,202 INFO:     Epoch: 12
2023-01-03 23:09:45,785 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40854819416999816, 'Total loss': 0.40854819416999816} | train loss {'Reaction outcome loss': 0.3671815053600332, 'Total loss': 0.3671815053600332}
2023-01-03 23:09:45,785 INFO:     Found new best model at epoch 12
2023-01-03 23:09:45,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:45,787 INFO:     Epoch: 13
2023-01-03 23:09:47,386 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4332765996456146, 'Total loss': 0.4332765996456146} | train loss {'Reaction outcome loss': 0.3633583652630003, 'Total loss': 0.3633583652630003}
2023-01-03 23:09:47,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:47,386 INFO:     Epoch: 14
2023-01-03 23:09:48,980 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42992526292800903, 'Total loss': 0.42992526292800903} | train loss {'Reaction outcome loss': 0.3524919722424955, 'Total loss': 0.3524919722424955}
2023-01-03 23:09:48,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:48,980 INFO:     Epoch: 15
2023-01-03 23:09:50,575 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.423457936445872, 'Total loss': 0.423457936445872} | train loss {'Reaction outcome loss': 0.3443034609916377, 'Total loss': 0.3443034609916377}
2023-01-03 23:09:50,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:50,576 INFO:     Epoch: 16
2023-01-03 23:09:52,171 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.416679718097051, 'Total loss': 0.416679718097051} | train loss {'Reaction outcome loss': 0.3374800071174252, 'Total loss': 0.3374800071174252}
2023-01-03 23:09:52,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:52,172 INFO:     Epoch: 17
2023-01-03 23:09:53,734 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4282029708226522, 'Total loss': 0.4282029708226522} | train loss {'Reaction outcome loss': 0.33063428079628426, 'Total loss': 0.33063428079628426}
2023-01-03 23:09:53,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:53,735 INFO:     Epoch: 18
2023-01-03 23:09:55,351 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40464426477750143, 'Total loss': 0.40464426477750143} | train loss {'Reaction outcome loss': 0.32940871786812076, 'Total loss': 0.32940871786812076}
2023-01-03 23:09:55,351 INFO:     Found new best model at epoch 18
2023-01-03 23:09:55,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:55,352 INFO:     Epoch: 19
2023-01-03 23:09:56,973 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4112930754820506, 'Total loss': 0.4112930754820506} | train loss {'Reaction outcome loss': 0.31887277038228035, 'Total loss': 0.31887277038228035}
2023-01-03 23:09:56,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:56,974 INFO:     Epoch: 20
2023-01-03 23:09:58,554 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43328305780887605, 'Total loss': 0.43328305780887605} | train loss {'Reaction outcome loss': 0.3133982765231875, 'Total loss': 0.3133982765231875}
2023-01-03 23:09:58,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:09:58,554 INFO:     Epoch: 21
2023-01-03 23:10:00,118 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43668016195297243, 'Total loss': 0.43668016195297243} | train loss {'Reaction outcome loss': 0.30939747729681205, 'Total loss': 0.30939747729681205}
2023-01-03 23:10:00,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:00,119 INFO:     Epoch: 22
2023-01-03 23:10:01,715 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42904621760050454, 'Total loss': 0.42904621760050454} | train loss {'Reaction outcome loss': 0.30328466710836993, 'Total loss': 0.30328466710836993}
2023-01-03 23:10:01,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:01,716 INFO:     Epoch: 23
2023-01-03 23:10:03,306 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4136655429999034, 'Total loss': 0.4136655429999034} | train loss {'Reaction outcome loss': 0.2995175981651182, 'Total loss': 0.2995175981651182}
2023-01-03 23:10:03,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:03,306 INFO:     Epoch: 24
2023-01-03 23:10:04,930 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40405984421571095, 'Total loss': 0.40405984421571095} | train loss {'Reaction outcome loss': 0.294164973109772, 'Total loss': 0.294164973109772}
2023-01-03 23:10:04,930 INFO:     Found new best model at epoch 24
2023-01-03 23:10:04,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:04,931 INFO:     Epoch: 25
2023-01-03 23:10:06,531 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4284199138482412, 'Total loss': 0.4284199138482412} | train loss {'Reaction outcome loss': 0.29389291931537614, 'Total loss': 0.29389291931537614}
2023-01-03 23:10:06,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:06,532 INFO:     Epoch: 26
2023-01-03 23:10:08,143 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3978293697039286, 'Total loss': 0.3978293697039286} | train loss {'Reaction outcome loss': 0.2911394923054183, 'Total loss': 0.2911394923054183}
2023-01-03 23:10:08,145 INFO:     Found new best model at epoch 26
2023-01-03 23:10:08,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:08,145 INFO:     Epoch: 27
2023-01-03 23:10:09,533 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40743472079435983, 'Total loss': 0.40743472079435983} | train loss {'Reaction outcome loss': 0.2812900667794157, 'Total loss': 0.2812900667794157}
2023-01-03 23:10:09,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:09,533 INFO:     Epoch: 28
2023-01-03 23:10:10,613 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4138046711683273, 'Total loss': 0.4138046711683273} | train loss {'Reaction outcome loss': 0.27795046668135276, 'Total loss': 0.27795046668135276}
2023-01-03 23:10:10,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:10,613 INFO:     Epoch: 29
2023-01-03 23:10:11,681 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42605622808138527, 'Total loss': 0.42605622808138527} | train loss {'Reaction outcome loss': 0.2757690498686355, 'Total loss': 0.2757690498686355}
2023-01-03 23:10:11,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:11,682 INFO:     Epoch: 30
2023-01-03 23:10:12,752 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4363354484240214, 'Total loss': 0.4363354484240214} | train loss {'Reaction outcome loss': 0.2717268744612659, 'Total loss': 0.2717268744612659}
2023-01-03 23:10:12,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:12,752 INFO:     Epoch: 31
2023-01-03 23:10:14,094 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42856900493303934, 'Total loss': 0.42856900493303934} | train loss {'Reaction outcome loss': 0.2688912692829035, 'Total loss': 0.2688912692829035}
2023-01-03 23:10:14,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:14,095 INFO:     Epoch: 32
2023-01-03 23:10:15,689 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42839224537213644, 'Total loss': 0.42839224537213644} | train loss {'Reaction outcome loss': 0.26647175223553093, 'Total loss': 0.26647175223553093}
2023-01-03 23:10:15,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:15,690 INFO:     Epoch: 33
2023-01-03 23:10:17,301 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4271089474360148, 'Total loss': 0.4271089474360148} | train loss {'Reaction outcome loss': 0.2706998832037915, 'Total loss': 0.2706998832037915}
2023-01-03 23:10:17,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:17,301 INFO:     Epoch: 34
2023-01-03 23:10:18,871 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42604078849156696, 'Total loss': 0.42604078849156696} | train loss {'Reaction outcome loss': 0.27408852071865747, 'Total loss': 0.27408852071865747}
2023-01-03 23:10:18,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:18,871 INFO:     Epoch: 35
2023-01-03 23:10:20,461 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42381410201390585, 'Total loss': 0.42381410201390585} | train loss {'Reaction outcome loss': 0.26406974869108957, 'Total loss': 0.26406974869108957}
2023-01-03 23:10:20,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:20,462 INFO:     Epoch: 36
2023-01-03 23:10:22,081 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43822574615478516, 'Total loss': 0.43822574615478516} | train loss {'Reaction outcome loss': 0.2546529472306577, 'Total loss': 0.2546529472306577}
2023-01-03 23:10:22,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:22,081 INFO:     Epoch: 37
2023-01-03 23:10:23,677 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4353760172923406, 'Total loss': 0.4353760172923406} | train loss {'Reaction outcome loss': 0.24901845819903942, 'Total loss': 0.24901845819903942}
2023-01-03 23:10:23,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:23,677 INFO:     Epoch: 38
2023-01-03 23:10:25,281 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42387971878051756, 'Total loss': 0.42387971878051756} | train loss {'Reaction outcome loss': 0.24828914498937302, 'Total loss': 0.24828914498937302}
2023-01-03 23:10:25,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:25,282 INFO:     Epoch: 39
2023-01-03 23:10:26,879 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4664593373735746, 'Total loss': 0.4664593373735746} | train loss {'Reaction outcome loss': 0.24519371895618952, 'Total loss': 0.24519371895618952}
2023-01-03 23:10:26,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:26,880 INFO:     Epoch: 40
2023-01-03 23:10:28,462 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4441319078207016, 'Total loss': 0.4441319078207016} | train loss {'Reaction outcome loss': 0.24184772123872011, 'Total loss': 0.24184772123872011}
2023-01-03 23:10:28,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:28,463 INFO:     Epoch: 41
2023-01-03 23:10:30,068 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41459371745586393, 'Total loss': 0.41459371745586393} | train loss {'Reaction outcome loss': 0.24884637370975554, 'Total loss': 0.24884637370975554}
2023-01-03 23:10:30,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:30,068 INFO:     Epoch: 42
2023-01-03 23:10:31,647 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4617401341597239, 'Total loss': 0.4617401341597239} | train loss {'Reaction outcome loss': 0.2542810624944505, 'Total loss': 0.2542810624944505}
2023-01-03 23:10:31,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:31,647 INFO:     Epoch: 43
2023-01-03 23:10:33,231 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43904656966527306, 'Total loss': 0.43904656966527306} | train loss {'Reaction outcome loss': 0.2376795523214505, 'Total loss': 0.2376795523214505}
2023-01-03 23:10:33,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:33,231 INFO:     Epoch: 44
2023-01-03 23:10:34,814 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4445249984661738, 'Total loss': 0.4445249984661738} | train loss {'Reaction outcome loss': 0.23477255403960715, 'Total loss': 0.23477255403960715}
2023-01-03 23:10:34,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:34,814 INFO:     Epoch: 45
2023-01-03 23:10:36,403 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4747623264789581, 'Total loss': 0.4747623264789581} | train loss {'Reaction outcome loss': 0.23057198273422924, 'Total loss': 0.23057198273422924}
2023-01-03 23:10:36,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:36,404 INFO:     Epoch: 46
2023-01-03 23:10:37,998 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44487294753392537, 'Total loss': 0.44487294753392537} | train loss {'Reaction outcome loss': 0.23235883836405, 'Total loss': 0.23235883836405}
2023-01-03 23:10:37,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:37,998 INFO:     Epoch: 47
2023-01-03 23:10:39,604 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44755638142426807, 'Total loss': 0.44755638142426807} | train loss {'Reaction outcome loss': 0.22921223178159184, 'Total loss': 0.22921223178159184}
2023-01-03 23:10:39,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:39,606 INFO:     Epoch: 48
2023-01-03 23:10:41,186 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4590099195639292, 'Total loss': 0.4590099195639292} | train loss {'Reaction outcome loss': 0.2280806143106125, 'Total loss': 0.2280806143106125}
2023-01-03 23:10:41,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:41,186 INFO:     Epoch: 49
2023-01-03 23:10:42,794 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45396677454312645, 'Total loss': 0.45396677454312645} | train loss {'Reaction outcome loss': 0.2270180064631437, 'Total loss': 0.2270180064631437}
2023-01-03 23:10:42,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:42,795 INFO:     Epoch: 50
2023-01-03 23:10:44,377 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4784045726060867, 'Total loss': 0.4784045726060867} | train loss {'Reaction outcome loss': 0.22596076056631148, 'Total loss': 0.22596076056631148}
2023-01-03 23:10:44,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:44,377 INFO:     Epoch: 51
2023-01-03 23:10:45,958 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44683485130469003, 'Total loss': 0.44683485130469003} | train loss {'Reaction outcome loss': 0.2231686326516522, 'Total loss': 0.2231686326516522}
2023-01-03 23:10:45,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:45,959 INFO:     Epoch: 52
2023-01-03 23:10:47,552 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4610223452250163, 'Total loss': 0.4610223452250163} | train loss {'Reaction outcome loss': 0.21816550170779736, 'Total loss': 0.21816550170779736}
2023-01-03 23:10:47,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:47,552 INFO:     Epoch: 53
2023-01-03 23:10:49,145 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46451290051142374, 'Total loss': 0.46451290051142374} | train loss {'Reaction outcome loss': 0.22000401602523145, 'Total loss': 0.22000401602523145}
2023-01-03 23:10:49,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:49,145 INFO:     Epoch: 54
2023-01-03 23:10:50,746 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4618718842665354, 'Total loss': 0.4618718842665354} | train loss {'Reaction outcome loss': 0.21733569309277379, 'Total loss': 0.21733569309277379}
2023-01-03 23:10:50,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:50,746 INFO:     Epoch: 55
2023-01-03 23:10:52,345 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4423796663681666, 'Total loss': 0.4423796663681666} | train loss {'Reaction outcome loss': 0.21732571612468962, 'Total loss': 0.21732571612468962}
2023-01-03 23:10:52,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:52,345 INFO:     Epoch: 56
2023-01-03 23:10:53,926 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4697921564181646, 'Total loss': 0.4697921564181646} | train loss {'Reaction outcome loss': 0.21332351952467277, 'Total loss': 0.21332351952467277}
2023-01-03 23:10:53,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:53,926 INFO:     Epoch: 57
2023-01-03 23:10:55,554 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4476595381895701, 'Total loss': 0.4476595381895701} | train loss {'Reaction outcome loss': 0.21554063890885183, 'Total loss': 0.21554063890885183}
2023-01-03 23:10:55,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:55,554 INFO:     Epoch: 58
2023-01-03 23:10:57,158 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4439316689968109, 'Total loss': 0.4439316689968109} | train loss {'Reaction outcome loss': 0.21217284401831604, 'Total loss': 0.21217284401831604}
2023-01-03 23:10:57,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:57,158 INFO:     Epoch: 59
2023-01-03 23:10:58,733 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.446863180398941, 'Total loss': 0.446863180398941} | train loss {'Reaction outcome loss': 0.20875606814645478, 'Total loss': 0.20875606814645478}
2023-01-03 23:10:58,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:10:58,735 INFO:     Epoch: 60
2023-01-03 23:11:00,358 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4595452884833018, 'Total loss': 0.4595452884833018} | train loss {'Reaction outcome loss': 0.21094092019442198, 'Total loss': 0.21094092019442198}
2023-01-03 23:11:00,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:00,358 INFO:     Epoch: 61
2023-01-03 23:11:01,977 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45787728230158486, 'Total loss': 0.45787728230158486} | train loss {'Reaction outcome loss': 0.2230116768811401, 'Total loss': 0.2230116768811401}
2023-01-03 23:11:01,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:01,977 INFO:     Epoch: 62
2023-01-03 23:11:03,571 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4432601511478424, 'Total loss': 0.4432601511478424} | train loss {'Reaction outcome loss': 0.20998967421389575, 'Total loss': 0.20998967421389575}
2023-01-03 23:11:03,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:03,571 INFO:     Epoch: 63
2023-01-03 23:11:05,167 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46454688211282097, 'Total loss': 0.46454688211282097} | train loss {'Reaction outcome loss': 0.21073781063888167, 'Total loss': 0.21073781063888167}
2023-01-03 23:11:05,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:05,167 INFO:     Epoch: 64
2023-01-03 23:11:06,761 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4504573265711466, 'Total loss': 0.4504573265711466} | train loss {'Reaction outcome loss': 0.20148382559789857, 'Total loss': 0.20148382559789857}
2023-01-03 23:11:06,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:06,762 INFO:     Epoch: 65
2023-01-03 23:11:08,336 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43494904836018883, 'Total loss': 0.43494904836018883} | train loss {'Reaction outcome loss': 0.20346030970846396, 'Total loss': 0.20346030970846396}
2023-01-03 23:11:08,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:08,336 INFO:     Epoch: 66
2023-01-03 23:11:09,965 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46341487765312195, 'Total loss': 0.46341487765312195} | train loss {'Reaction outcome loss': 0.20384459487275677, 'Total loss': 0.20384459487275677}
2023-01-03 23:11:09,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:09,965 INFO:     Epoch: 67
2023-01-03 23:11:11,597 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45416659911473595, 'Total loss': 0.45416659911473595} | train loss {'Reaction outcome loss': 0.20041118483146317, 'Total loss': 0.20041118483146317}
2023-01-03 23:11:11,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:11,598 INFO:     Epoch: 68
2023-01-03 23:11:13,176 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.454188247025013, 'Total loss': 0.454188247025013} | train loss {'Reaction outcome loss': 0.19824172503633788, 'Total loss': 0.19824172503633788}
2023-01-03 23:11:13,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:13,176 INFO:     Epoch: 69
2023-01-03 23:11:14,794 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4542307496070862, 'Total loss': 0.4542307496070862} | train loss {'Reaction outcome loss': 0.19761695484972416, 'Total loss': 0.19761695484972416}
2023-01-03 23:11:14,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:14,796 INFO:     Epoch: 70
2023-01-03 23:11:16,383 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4593252976735433, 'Total loss': 0.4593252976735433} | train loss {'Reaction outcome loss': 0.1940235160679246, 'Total loss': 0.1940235160679246}
2023-01-03 23:11:16,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:16,383 INFO:     Epoch: 71
2023-01-03 23:11:18,008 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47152104377746584, 'Total loss': 0.47152104377746584} | train loss {'Reaction outcome loss': 0.1952913662324241, 'Total loss': 0.1952913662324241}
2023-01-03 23:11:18,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:18,008 INFO:     Epoch: 72
2023-01-03 23:11:19,601 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4458958695332209, 'Total loss': 0.4458958695332209} | train loss {'Reaction outcome loss': 0.19694953390727818, 'Total loss': 0.19694953390727818}
2023-01-03 23:11:19,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:19,601 INFO:     Epoch: 73
2023-01-03 23:11:21,199 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44308889905611676, 'Total loss': 0.44308889905611676} | train loss {'Reaction outcome loss': 0.21765306921324867, 'Total loss': 0.21765306921324867}
2023-01-03 23:11:21,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:21,200 INFO:     Epoch: 74
2023-01-03 23:11:22,806 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44093172351519266, 'Total loss': 0.44093172351519266} | train loss {'Reaction outcome loss': 0.1986991831580636, 'Total loss': 0.1986991831580636}
2023-01-03 23:11:22,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:22,806 INFO:     Epoch: 75
2023-01-03 23:11:24,425 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47757644156614937, 'Total loss': 0.47757644156614937} | train loss {'Reaction outcome loss': 0.18969789570241963, 'Total loss': 0.18969789570241963}
2023-01-03 23:11:24,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:24,426 INFO:     Epoch: 76
2023-01-03 23:11:26,016 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46130940516789753, 'Total loss': 0.46130940516789753} | train loss {'Reaction outcome loss': 0.19127654688486803, 'Total loss': 0.19127654688486803}
2023-01-03 23:11:26,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:26,016 INFO:     Epoch: 77
2023-01-03 23:11:27,637 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46055012245972954, 'Total loss': 0.46055012245972954} | train loss {'Reaction outcome loss': 0.19068222046294925, 'Total loss': 0.19068222046294925}
2023-01-03 23:11:27,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:27,637 INFO:     Epoch: 78
2023-01-03 23:11:29,254 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4709432105223338, 'Total loss': 0.4709432105223338} | train loss {'Reaction outcome loss': 0.18619419646152444, 'Total loss': 0.18619419646152444}
2023-01-03 23:11:29,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:29,254 INFO:     Epoch: 79
2023-01-03 23:11:30,831 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.450592831770579, 'Total loss': 0.450592831770579} | train loss {'Reaction outcome loss': 0.18690028294329988, 'Total loss': 0.18690028294329988}
2023-01-03 23:11:30,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:30,831 INFO:     Epoch: 80
2023-01-03 23:11:32,432 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43431791961193084, 'Total loss': 0.43431791961193084} | train loss {'Reaction outcome loss': 0.1881955892597077, 'Total loss': 0.1881955892597077}
2023-01-03 23:11:32,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:32,432 INFO:     Epoch: 81
2023-01-03 23:11:34,053 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4201617017388344, 'Total loss': 0.4201617017388344} | train loss {'Reaction outcome loss': 0.18770713500840508, 'Total loss': 0.18770713500840508}
2023-01-03 23:11:34,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:34,053 INFO:     Epoch: 82
2023-01-03 23:11:35,643 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4619152267773946, 'Total loss': 0.4619152267773946} | train loss {'Reaction outcome loss': 0.19011984718204272, 'Total loss': 0.19011984718204272}
2023-01-03 23:11:35,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:35,643 INFO:     Epoch: 83
2023-01-03 23:11:37,272 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4527348985274633, 'Total loss': 0.4527348985274633} | train loss {'Reaction outcome loss': 0.18342297937388008, 'Total loss': 0.18342297937388008}
2023-01-03 23:11:37,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:37,273 INFO:     Epoch: 84
2023-01-03 23:11:38,882 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44422679046789804, 'Total loss': 0.44422679046789804} | train loss {'Reaction outcome loss': 0.18166775983295141, 'Total loss': 0.18166775983295141}
2023-01-03 23:11:38,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:38,882 INFO:     Epoch: 85
2023-01-03 23:11:40,506 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4396604796250661, 'Total loss': 0.4396604796250661} | train loss {'Reaction outcome loss': 0.18115019115087477, 'Total loss': 0.18115019115087477}
2023-01-03 23:11:40,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:40,507 INFO:     Epoch: 86
2023-01-03 23:11:42,127 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43456387519836426, 'Total loss': 0.43456387519836426} | train loss {'Reaction outcome loss': 0.18183896367891988, 'Total loss': 0.18183896367891988}
2023-01-03 23:11:42,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:42,127 INFO:     Epoch: 87
2023-01-03 23:11:43,733 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4547108054161072, 'Total loss': 0.4547108054161072} | train loss {'Reaction outcome loss': 0.17919733379056962, 'Total loss': 0.17919733379056962}
2023-01-03 23:11:43,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:43,733 INFO:     Epoch: 88
2023-01-03 23:11:45,358 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45863393197457, 'Total loss': 0.45863393197457} | train loss {'Reaction outcome loss': 0.17851785559031524, 'Total loss': 0.17851785559031524}
2023-01-03 23:11:45,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:45,359 INFO:     Epoch: 89
2023-01-03 23:11:46,972 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4229104389746984, 'Total loss': 0.4229104389746984} | train loss {'Reaction outcome loss': 0.17884858431626935, 'Total loss': 0.17884858431626935}
2023-01-03 23:11:46,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:46,972 INFO:     Epoch: 90
2023-01-03 23:11:48,565 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4540786306063334, 'Total loss': 0.4540786306063334} | train loss {'Reaction outcome loss': 0.17861928214130085, 'Total loss': 0.17861928214130085}
2023-01-03 23:11:48,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:48,565 INFO:     Epoch: 91
2023-01-03 23:11:50,193 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4544036954641342, 'Total loss': 0.4544036954641342} | train loss {'Reaction outcome loss': 0.17703241599382888, 'Total loss': 0.17703241599382888}
2023-01-03 23:11:50,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:50,193 INFO:     Epoch: 92
2023-01-03 23:11:51,790 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42995658914248147, 'Total loss': 0.42995658914248147} | train loss {'Reaction outcome loss': 0.17908987886034267, 'Total loss': 0.17908987886034267}
2023-01-03 23:11:51,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:51,790 INFO:     Epoch: 93
2023-01-03 23:11:53,382 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48299148976802825, 'Total loss': 0.48299148976802825} | train loss {'Reaction outcome loss': 0.17585788823935614, 'Total loss': 0.17585788823935614}
2023-01-03 23:11:53,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:53,382 INFO:     Epoch: 94
2023-01-03 23:11:54,996 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4664088467756907, 'Total loss': 0.4664088467756907} | train loss {'Reaction outcome loss': 0.17593941949156072, 'Total loss': 0.17593941949156072}
2023-01-03 23:11:54,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:54,996 INFO:     Epoch: 95
2023-01-03 23:11:56,622 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45880578756332396, 'Total loss': 0.45880578756332396} | train loss {'Reaction outcome loss': 0.17347747266319566, 'Total loss': 0.17347747266319566}
2023-01-03 23:11:56,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:56,622 INFO:     Epoch: 96
2023-01-03 23:11:58,222 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4648824910322825, 'Total loss': 0.4648824910322825} | train loss {'Reaction outcome loss': 0.17526764701833072, 'Total loss': 0.17526764701833072}
2023-01-03 23:11:58,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:58,222 INFO:     Epoch: 97
2023-01-03 23:11:59,836 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43838449666897455, 'Total loss': 0.43838449666897455} | train loss {'Reaction outcome loss': 0.1718853098961214, 'Total loss': 0.1718853098961214}
2023-01-03 23:11:59,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:11:59,836 INFO:     Epoch: 98
2023-01-03 23:12:01,438 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45094571113586424, 'Total loss': 0.45094571113586424} | train loss {'Reaction outcome loss': 0.17355096028726277, 'Total loss': 0.17355096028726277}
2023-01-03 23:12:01,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:01,438 INFO:     Epoch: 99
2023-01-03 23:12:03,058 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4594871819019318, 'Total loss': 0.4594871819019318} | train loss {'Reaction outcome loss': 0.17128107754246413, 'Total loss': 0.17128107754246413}
2023-01-03 23:12:03,058 INFO:     Best model found after epoch 27 of 100.
2023-01-03 23:12:03,058 INFO:   Done with stage: TRAINING
2023-01-03 23:12:03,058 INFO:   Starting stage: EVALUATION
2023-01-03 23:12:03,188 INFO:   Done with stage: EVALUATION
2023-01-03 23:12:03,188 INFO:   Leaving out SEQ value Fold_6
2023-01-03 23:12:03,201 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-03 23:12:03,201 INFO:   Starting stage: FEATURE SCALING
2023-01-03 23:12:03,845 INFO:   Done with stage: FEATURE SCALING
2023-01-03 23:12:03,846 INFO:   Starting stage: SCALING TARGETS
2023-01-03 23:12:03,916 INFO:   Done with stage: SCALING TARGETS
2023-01-03 23:12:03,916 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:12:03,916 INFO:     No hyperparam tuning for this model
2023-01-03 23:12:03,916 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:12:03,916 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 23:12:03,917 INFO:     None feature selector for col prot
2023-01-03 23:12:03,917 INFO:     None feature selector for col prot
2023-01-03 23:12:03,917 INFO:     None feature selector for col prot
2023-01-03 23:12:03,917 INFO:     None feature selector for col chem
2023-01-03 23:12:03,918 INFO:     None feature selector for col chem
2023-01-03 23:12:03,918 INFO:     None feature selector for col chem
2023-01-03 23:12:03,918 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 23:12:03,918 INFO:   Starting stage: BUILD MODEL
2023-01-03 23:12:03,919 INFO:     Number of params in model 70141
2023-01-03 23:12:03,922 INFO:   Done with stage: BUILD MODEL
2023-01-03 23:12:03,922 INFO:   Starting stage: TRAINING
2023-01-03 23:12:03,966 INFO:     Val loss before train {'Reaction outcome loss': 1.0274319966634116, 'Total loss': 1.0274319966634116}
2023-01-03 23:12:03,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:03,966 INFO:     Epoch: 0
2023-01-03 23:12:05,578 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.641114886601766, 'Total loss': 0.641114886601766} | train loss {'Reaction outcome loss': 0.8485058611695947, 'Total loss': 0.8485058611695947}
2023-01-03 23:12:05,578 INFO:     Found new best model at epoch 0
2023-01-03 23:12:05,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:05,579 INFO:     Epoch: 1
2023-01-03 23:12:07,165 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.528198222319285, 'Total loss': 0.528198222319285} | train loss {'Reaction outcome loss': 0.5933582666548581, 'Total loss': 0.5933582666548581}
2023-01-03 23:12:07,165 INFO:     Found new best model at epoch 1
2023-01-03 23:12:07,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:07,166 INFO:     Epoch: 2
2023-01-03 23:12:08,762 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48858601649602257, 'Total loss': 0.48858601649602257} | train loss {'Reaction outcome loss': 0.5175367963873523, 'Total loss': 0.5175367963873523}
2023-01-03 23:12:08,762 INFO:     Found new best model at epoch 2
2023-01-03 23:12:08,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:08,763 INFO:     Epoch: 3
2023-01-03 23:12:10,339 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45729505916436514, 'Total loss': 0.45729505916436514} | train loss {'Reaction outcome loss': 0.4775070067131993, 'Total loss': 0.4775070067131993}
2023-01-03 23:12:10,339 INFO:     Found new best model at epoch 3
2023-01-03 23:12:10,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:10,340 INFO:     Epoch: 4
2023-01-03 23:12:11,941 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4462734445929527, 'Total loss': 0.4462734445929527} | train loss {'Reaction outcome loss': 0.45246453766142847, 'Total loss': 0.45246453766142847}
2023-01-03 23:12:11,941 INFO:     Found new best model at epoch 4
2023-01-03 23:12:11,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:11,942 INFO:     Epoch: 5
2023-01-03 23:12:13,545 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4332390288511912, 'Total loss': 0.4332390288511912} | train loss {'Reaction outcome loss': 0.433763443186395, 'Total loss': 0.433763443186395}
2023-01-03 23:12:13,545 INFO:     Found new best model at epoch 5
2023-01-03 23:12:13,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:13,546 INFO:     Epoch: 6
2023-01-03 23:12:15,131 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4285989930232366, 'Total loss': 0.4285989930232366} | train loss {'Reaction outcome loss': 0.41473795094322213, 'Total loss': 0.41473795094322213}
2023-01-03 23:12:15,131 INFO:     Found new best model at epoch 6
2023-01-03 23:12:15,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:15,132 INFO:     Epoch: 7
2023-01-03 23:12:16,736 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4169466247161229, 'Total loss': 0.4169466247161229} | train loss {'Reaction outcome loss': 0.40239681556336715, 'Total loss': 0.40239681556336715}
2023-01-03 23:12:16,737 INFO:     Found new best model at epoch 7
2023-01-03 23:12:16,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:16,738 INFO:     Epoch: 8
2023-01-03 23:12:18,335 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43335415025552115, 'Total loss': 0.43335415025552115} | train loss {'Reaction outcome loss': 0.3912278801095184, 'Total loss': 0.3912278801095184}
2023-01-03 23:12:18,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:18,335 INFO:     Epoch: 9
2023-01-03 23:12:19,921 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4121070067087809, 'Total loss': 0.4121070067087809} | train loss {'Reaction outcome loss': 0.38269004518912586, 'Total loss': 0.38269004518912586}
2023-01-03 23:12:19,921 INFO:     Found new best model at epoch 9
2023-01-03 23:12:19,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:19,922 INFO:     Epoch: 10
2023-01-03 23:12:21,522 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40573999683062234, 'Total loss': 0.40573999683062234} | train loss {'Reaction outcome loss': 0.37382401956332717, 'Total loss': 0.37382401956332717}
2023-01-03 23:12:21,522 INFO:     Found new best model at epoch 10
2023-01-03 23:12:21,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:21,523 INFO:     Epoch: 11
2023-01-03 23:12:23,119 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39547064155340195, 'Total loss': 0.39547064155340195} | train loss {'Reaction outcome loss': 0.3660576994722501, 'Total loss': 0.3660576994722501}
2023-01-03 23:12:23,120 INFO:     Found new best model at epoch 11
2023-01-03 23:12:23,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:23,121 INFO:     Epoch: 12
2023-01-03 23:12:24,717 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3947839071353277, 'Total loss': 0.3947839071353277} | train loss {'Reaction outcome loss': 0.35612385547871195, 'Total loss': 0.35612385547871195}
2023-01-03 23:12:24,717 INFO:     Found new best model at epoch 12
2023-01-03 23:12:24,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:24,718 INFO:     Epoch: 13
2023-01-03 23:12:26,323 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3907907664775848, 'Total loss': 0.3907907664775848} | train loss {'Reaction outcome loss': 0.3521333869936664, 'Total loss': 0.3521333869936664}
2023-01-03 23:12:26,324 INFO:     Found new best model at epoch 13
2023-01-03 23:12:26,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:26,324 INFO:     Epoch: 14
2023-01-03 23:12:27,938 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4020533214012782, 'Total loss': 0.4020533214012782} | train loss {'Reaction outcome loss': 0.3448988563962792, 'Total loss': 0.3448988563962792}
2023-01-03 23:12:27,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:27,938 INFO:     Epoch: 15
2023-01-03 23:12:29,536 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.38966678182284037, 'Total loss': 0.38966678182284037} | train loss {'Reaction outcome loss': 0.3379163836744288, 'Total loss': 0.3379163836744288}
2023-01-03 23:12:29,536 INFO:     Found new best model at epoch 15
2023-01-03 23:12:29,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:29,537 INFO:     Epoch: 16
2023-01-03 23:12:31,166 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.38479920079310737, 'Total loss': 0.38479920079310737} | train loss {'Reaction outcome loss': 0.331609736738007, 'Total loss': 0.331609736738007}
2023-01-03 23:12:31,166 INFO:     Found new best model at epoch 16
2023-01-03 23:12:31,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:31,167 INFO:     Epoch: 17
2023-01-03 23:12:32,772 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39910462001959485, 'Total loss': 0.39910462001959485} | train loss {'Reaction outcome loss': 0.3274226183280187, 'Total loss': 0.3274226183280187}
2023-01-03 23:12:32,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:32,772 INFO:     Epoch: 18
2023-01-03 23:12:34,371 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3833492894967397, 'Total loss': 0.3833492894967397} | train loss {'Reaction outcome loss': 0.32095068811509586, 'Total loss': 0.32095068811509586}
2023-01-03 23:12:34,371 INFO:     Found new best model at epoch 18
2023-01-03 23:12:34,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:34,372 INFO:     Epoch: 19
2023-01-03 23:12:35,971 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38112593988577526, 'Total loss': 0.38112593988577526} | train loss {'Reaction outcome loss': 0.3196647581291328, 'Total loss': 0.3196647581291328}
2023-01-03 23:12:35,972 INFO:     Found new best model at epoch 19
2023-01-03 23:12:35,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:35,973 INFO:     Epoch: 20
2023-01-03 23:12:37,561 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38531926572322844, 'Total loss': 0.38531926572322844} | train loss {'Reaction outcome loss': 0.3133335898122633, 'Total loss': 0.3133335898122633}
2023-01-03 23:12:37,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:37,562 INFO:     Epoch: 21
2023-01-03 23:12:39,197 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3904328445593516, 'Total loss': 0.3904328445593516} | train loss {'Reaction outcome loss': 0.30969578428496525, 'Total loss': 0.30969578428496525}
2023-01-03 23:12:39,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:39,198 INFO:     Epoch: 22
2023-01-03 23:12:40,811 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39551697472731273, 'Total loss': 0.39551697472731273} | train loss {'Reaction outcome loss': 0.30084382164349194, 'Total loss': 0.30084382164349194}
2023-01-03 23:12:40,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:40,811 INFO:     Epoch: 23
2023-01-03 23:12:42,394 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3873991847038269, 'Total loss': 0.3873991847038269} | train loss {'Reaction outcome loss': 0.3000424136323619, 'Total loss': 0.3000424136323619}
2023-01-03 23:12:42,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:42,394 INFO:     Epoch: 24
2023-01-03 23:12:44,017 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3919009268283844, 'Total loss': 0.3919009268283844} | train loss {'Reaction outcome loss': 0.29600805213627834, 'Total loss': 0.29600805213627834}
2023-01-03 23:12:44,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:44,017 INFO:     Epoch: 25
2023-01-03 23:12:45,638 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3778928190469742, 'Total loss': 0.3778928190469742} | train loss {'Reaction outcome loss': 0.29240107802600207, 'Total loss': 0.29240107802600207}
2023-01-03 23:12:45,638 INFO:     Found new best model at epoch 25
2023-01-03 23:12:45,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:45,639 INFO:     Epoch: 26
2023-01-03 23:12:47,218 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3773993740479151, 'Total loss': 0.3773993740479151} | train loss {'Reaction outcome loss': 0.2902731021953619, 'Total loss': 0.2902731021953619}
2023-01-03 23:12:47,218 INFO:     Found new best model at epoch 26
2023-01-03 23:12:47,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:47,219 INFO:     Epoch: 27
2023-01-03 23:12:48,819 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40327954093615215, 'Total loss': 0.40327954093615215} | train loss {'Reaction outcome loss': 0.28499101936171634, 'Total loss': 0.28499101936171634}
2023-01-03 23:12:48,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:48,819 INFO:     Epoch: 28
2023-01-03 23:12:50,410 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39040314555168154, 'Total loss': 0.39040314555168154} | train loss {'Reaction outcome loss': 0.28140426830586973, 'Total loss': 0.28140426830586973}
2023-01-03 23:12:50,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:50,411 INFO:     Epoch: 29
2023-01-03 23:12:51,990 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39692783951759336, 'Total loss': 0.39692783951759336} | train loss {'Reaction outcome loss': 0.27997023858372055, 'Total loss': 0.27997023858372055}
2023-01-03 23:12:51,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:51,991 INFO:     Epoch: 30
2023-01-03 23:12:53,600 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38730583985646566, 'Total loss': 0.38730583985646566} | train loss {'Reaction outcome loss': 0.27465722266087034, 'Total loss': 0.27465722266087034}
2023-01-03 23:12:53,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:53,600 INFO:     Epoch: 31
2023-01-03 23:12:55,210 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3900681128104528, 'Total loss': 0.3900681128104528} | train loss {'Reaction outcome loss': 0.27251937331813336, 'Total loss': 0.27251937331813336}
2023-01-03 23:12:55,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:55,210 INFO:     Epoch: 32
2023-01-03 23:12:56,811 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.38733347654342654, 'Total loss': 0.38733347654342654} | train loss {'Reaction outcome loss': 0.27143768950059527, 'Total loss': 0.27143768950059527}
2023-01-03 23:12:56,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:56,811 INFO:     Epoch: 33
2023-01-03 23:12:58,413 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3742546230554581, 'Total loss': 0.3742546230554581} | train loss {'Reaction outcome loss': 0.26750044349836527, 'Total loss': 0.26750044349836527}
2023-01-03 23:12:58,414 INFO:     Found new best model at epoch 33
2023-01-03 23:12:58,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:12:58,414 INFO:     Epoch: 34
2023-01-03 23:13:00,005 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.387343430519104, 'Total loss': 0.387343430519104} | train loss {'Reaction outcome loss': 0.2645387801775433, 'Total loss': 0.2645387801775433}
2023-01-03 23:13:00,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:00,005 INFO:     Epoch: 35
2023-01-03 23:13:01,620 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3883277545372645, 'Total loss': 0.3883277545372645} | train loss {'Reaction outcome loss': 0.2642205870350561, 'Total loss': 0.2642205870350561}
2023-01-03 23:13:01,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:01,621 INFO:     Epoch: 36
2023-01-03 23:13:03,249 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3889471580584844, 'Total loss': 0.3889471580584844} | train loss {'Reaction outcome loss': 0.25679787810528754, 'Total loss': 0.25679787810528754}
2023-01-03 23:13:03,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:03,249 INFO:     Epoch: 37
2023-01-03 23:13:04,852 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3740203728278478, 'Total loss': 0.3740203728278478} | train loss {'Reaction outcome loss': 0.25759013543167697, 'Total loss': 0.25759013543167697}
2023-01-03 23:13:04,852 INFO:     Found new best model at epoch 37
2023-01-03 23:13:04,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:04,853 INFO:     Epoch: 38
2023-01-03 23:13:06,434 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3777971511085828, 'Total loss': 0.3777971511085828} | train loss {'Reaction outcome loss': 0.25421630098931625, 'Total loss': 0.25421630098931625}
2023-01-03 23:13:06,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:06,434 INFO:     Epoch: 39
2023-01-03 23:13:08,058 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3766857186953227, 'Total loss': 0.3766857186953227} | train loss {'Reaction outcome loss': 0.251143712805927, 'Total loss': 0.251143712805927}
2023-01-03 23:13:08,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:08,058 INFO:     Epoch: 40
2023-01-03 23:13:09,641 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38654819230238596, 'Total loss': 0.38654819230238596} | train loss {'Reaction outcome loss': 0.2513730479841413, 'Total loss': 0.2513730479841413}
2023-01-03 23:13:09,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:09,641 INFO:     Epoch: 41
2023-01-03 23:13:11,268 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39542704323927563, 'Total loss': 0.39542704323927563} | train loss {'Reaction outcome loss': 0.24776659525312242, 'Total loss': 0.24776659525312242}
2023-01-03 23:13:11,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:11,269 INFO:     Epoch: 42
2023-01-03 23:13:12,835 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3904953509569168, 'Total loss': 0.3904953509569168} | train loss {'Reaction outcome loss': 0.24598575402925377, 'Total loss': 0.24598575402925377}
2023-01-03 23:13:12,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:12,835 INFO:     Epoch: 43
2023-01-03 23:13:14,450 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3932994206746419, 'Total loss': 0.3932994206746419} | train loss {'Reaction outcome loss': 0.24382476830041366, 'Total loss': 0.24382476830041366}
2023-01-03 23:13:14,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:14,450 INFO:     Epoch: 44
2023-01-03 23:13:16,074 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3776424980411927, 'Total loss': 0.3776424980411927} | train loss {'Reaction outcome loss': 0.23901736548015787, 'Total loss': 0.23901736548015787}
2023-01-03 23:13:16,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:16,074 INFO:     Epoch: 45
2023-01-03 23:13:17,674 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.381147430340449, 'Total loss': 0.381147430340449} | train loss {'Reaction outcome loss': 0.23873919157129764, 'Total loss': 0.23873919157129764}
2023-01-03 23:13:17,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:17,675 INFO:     Epoch: 46
2023-01-03 23:13:19,288 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38198114136854805, 'Total loss': 0.38198114136854805} | train loss {'Reaction outcome loss': 0.23764796248411874, 'Total loss': 0.23764796248411874}
2023-01-03 23:13:19,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:19,288 INFO:     Epoch: 47
2023-01-03 23:13:20,900 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3841161439816157, 'Total loss': 0.3841161439816157} | train loss {'Reaction outcome loss': 0.2337148314348627, 'Total loss': 0.2337148314348627}
2023-01-03 23:13:20,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:20,900 INFO:     Epoch: 48
2023-01-03 23:13:22,499 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3793527871370316, 'Total loss': 0.3793527871370316} | train loss {'Reaction outcome loss': 0.23191636386545986, 'Total loss': 0.23191636386545986}
2023-01-03 23:13:22,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:22,500 INFO:     Epoch: 49
2023-01-03 23:13:24,127 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38320449988047284, 'Total loss': 0.38320449988047284} | train loss {'Reaction outcome loss': 0.22732852037579143, 'Total loss': 0.22732852037579143}
2023-01-03 23:13:24,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:24,128 INFO:     Epoch: 50
2023-01-03 23:13:25,765 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38812586665153503, 'Total loss': 0.38812586665153503} | train loss {'Reaction outcome loss': 0.2288990719949941, 'Total loss': 0.2288990719949941}
2023-01-03 23:13:25,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:25,765 INFO:     Epoch: 51
2023-01-03 23:13:27,365 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.36891488085190455, 'Total loss': 0.36891488085190455} | train loss {'Reaction outcome loss': 0.228423970418609, 'Total loss': 0.228423970418609}
2023-01-03 23:13:27,365 INFO:     Found new best model at epoch 51
2023-01-03 23:13:27,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:27,366 INFO:     Epoch: 52
2023-01-03 23:13:28,996 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.37875979840755464, 'Total loss': 0.37875979840755464} | train loss {'Reaction outcome loss': 0.226639789418193, 'Total loss': 0.226639789418193}
2023-01-03 23:13:28,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:28,997 INFO:     Epoch: 53
2023-01-03 23:13:30,620 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3945225810011228, 'Total loss': 0.3945225810011228} | train loss {'Reaction outcome loss': 0.2233687367438194, 'Total loss': 0.2233687367438194}
2023-01-03 23:13:30,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:30,621 INFO:     Epoch: 54
2023-01-03 23:13:32,234 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3826955010493596, 'Total loss': 0.3826955010493596} | train loss {'Reaction outcome loss': 0.21924888545021898, 'Total loss': 0.21924888545021898}
2023-01-03 23:13:32,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:32,234 INFO:     Epoch: 55
2023-01-03 23:13:33,877 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38249613145987194, 'Total loss': 0.38249613145987194} | train loss {'Reaction outcome loss': 0.2170373507462684, 'Total loss': 0.2170373507462684}
2023-01-03 23:13:33,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:33,877 INFO:     Epoch: 56
2023-01-03 23:13:35,494 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3787960668404897, 'Total loss': 0.3787960668404897} | train loss {'Reaction outcome loss': 0.21764969603841056, 'Total loss': 0.21764969603841056}
2023-01-03 23:13:35,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:35,495 INFO:     Epoch: 57
2023-01-03 23:13:37,117 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4020174155632655, 'Total loss': 0.4020174155632655} | train loss {'Reaction outcome loss': 0.21767322510642265, 'Total loss': 0.21767322510642265}
2023-01-03 23:13:37,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:37,117 INFO:     Epoch: 58
2023-01-03 23:13:38,745 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3878356675306956, 'Total loss': 0.3878356675306956} | train loss {'Reaction outcome loss': 0.21551495389710265, 'Total loss': 0.21551495389710265}
2023-01-03 23:13:38,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:38,746 INFO:     Epoch: 59
2023-01-03 23:13:40,341 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39422711034615837, 'Total loss': 0.39422711034615837} | train loss {'Reaction outcome loss': 0.21295652663610903, 'Total loss': 0.21295652663610903}
2023-01-03 23:13:40,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:40,341 INFO:     Epoch: 60
2023-01-03 23:13:41,969 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3959709753592809, 'Total loss': 0.3959709753592809} | train loss {'Reaction outcome loss': 0.21209485986898738, 'Total loss': 0.21209485986898738}
2023-01-03 23:13:41,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:41,970 INFO:     Epoch: 61
2023-01-03 23:13:43,610 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3988174259662628, 'Total loss': 0.3988174259662628} | train loss {'Reaction outcome loss': 0.21287127106790077, 'Total loss': 0.21287127106790077}
2023-01-03 23:13:43,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:43,610 INFO:     Epoch: 62
2023-01-03 23:13:45,210 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3754118839899699, 'Total loss': 0.3754118839899699} | train loss {'Reaction outcome loss': 0.20700581349593852, 'Total loss': 0.20700581349593852}
2023-01-03 23:13:45,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:45,210 INFO:     Epoch: 63
2023-01-03 23:13:46,835 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3932654877503713, 'Total loss': 0.3932654877503713} | train loss {'Reaction outcome loss': 0.21077583656252938, 'Total loss': 0.21077583656252938}
2023-01-03 23:13:46,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:46,835 INFO:     Epoch: 64
2023-01-03 23:13:48,456 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4082398474216461, 'Total loss': 0.4082398474216461} | train loss {'Reaction outcome loss': 0.2059932548942764, 'Total loss': 0.2059932548942764}
2023-01-03 23:13:48,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:48,456 INFO:     Epoch: 65
2023-01-03 23:13:50,060 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40113533635934195, 'Total loss': 0.40113533635934195} | train loss {'Reaction outcome loss': 0.20544981762820633, 'Total loss': 0.20544981762820633}
2023-01-03 23:13:50,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:50,060 INFO:     Epoch: 66
2023-01-03 23:13:51,692 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.38887442549069723, 'Total loss': 0.38887442549069723} | train loss {'Reaction outcome loss': 0.20495913314905406, 'Total loss': 0.20495913314905406}
2023-01-03 23:13:51,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:51,692 INFO:     Epoch: 67
2023-01-03 23:13:53,318 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39710821757713954, 'Total loss': 0.39710821757713954} | train loss {'Reaction outcome loss': 0.20295772868265743, 'Total loss': 0.20295772868265743}
2023-01-03 23:13:53,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:53,319 INFO:     Epoch: 68
2023-01-03 23:13:54,921 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4173951784769694, 'Total loss': 0.4173951784769694} | train loss {'Reaction outcome loss': 0.20332672175302402, 'Total loss': 0.20332672175302402}
2023-01-03 23:13:54,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:54,921 INFO:     Epoch: 69
2023-01-03 23:13:56,553 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4029378846287727, 'Total loss': 0.4029378846287727} | train loss {'Reaction outcome loss': 0.20017946963383404, 'Total loss': 0.20017946963383404}
2023-01-03 23:13:56,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:56,553 INFO:     Epoch: 70
2023-01-03 23:13:58,132 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41266050140062965, 'Total loss': 0.41266050140062965} | train loss {'Reaction outcome loss': 0.19751365255524106, 'Total loss': 0.19751365255524106}
2023-01-03 23:13:58,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:58,132 INFO:     Epoch: 71
2023-01-03 23:13:59,768 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3812994480133057, 'Total loss': 0.3812994480133057} | train loss {'Reaction outcome loss': 0.1991742139863731, 'Total loss': 0.1991742139863731}
2023-01-03 23:13:59,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:13:59,769 INFO:     Epoch: 72
2023-01-03 23:14:01,386 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4081393818060557, 'Total loss': 0.4081393818060557} | train loss {'Reaction outcome loss': 0.1986218828317921, 'Total loss': 0.1986218828317921}
2023-01-03 23:14:01,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:01,386 INFO:     Epoch: 73
2023-01-03 23:14:02,990 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40213992198308307, 'Total loss': 0.40213992198308307} | train loss {'Reaction outcome loss': 0.19317907476898566, 'Total loss': 0.19317907476898566}
2023-01-03 23:14:02,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:02,990 INFO:     Epoch: 74
2023-01-03 23:14:04,597 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41282796760400137, 'Total loss': 0.41282796760400137} | train loss {'Reaction outcome loss': 0.19478842563295085, 'Total loss': 0.19478842563295085}
2023-01-03 23:14:04,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:04,597 INFO:     Epoch: 75
2023-01-03 23:14:06,206 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4123605122168859, 'Total loss': 0.4123605122168859} | train loss {'Reaction outcome loss': 0.19373113774973563, 'Total loss': 0.19373113774973563}
2023-01-03 23:14:06,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:06,206 INFO:     Epoch: 76
2023-01-03 23:14:07,806 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39477145075798037, 'Total loss': 0.39477145075798037} | train loss {'Reaction outcome loss': 0.1925022584597987, 'Total loss': 0.1925022584597987}
2023-01-03 23:14:07,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:07,807 INFO:     Epoch: 77
2023-01-03 23:14:09,435 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40264527797698973, 'Total loss': 0.40264527797698973} | train loss {'Reaction outcome loss': 0.19158548017836005, 'Total loss': 0.19158548017836005}
2023-01-03 23:14:09,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:09,435 INFO:     Epoch: 78
2023-01-03 23:14:11,065 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42031821310520173, 'Total loss': 0.42031821310520173} | train loss {'Reaction outcome loss': 0.18839905055286868, 'Total loss': 0.18839905055286868}
2023-01-03 23:14:11,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:11,065 INFO:     Epoch: 79
2023-01-03 23:14:12,656 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4037009318669637, 'Total loss': 0.4037009318669637} | train loss {'Reaction outcome loss': 0.19033166087007264, 'Total loss': 0.19033166087007264}
2023-01-03 23:14:12,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:12,657 INFO:     Epoch: 80
2023-01-03 23:14:14,263 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40428152680397034, 'Total loss': 0.40428152680397034} | train loss {'Reaction outcome loss': 0.18996898187089054, 'Total loss': 0.18996898187089054}
2023-01-03 23:14:14,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:14,263 INFO:     Epoch: 81
2023-01-03 23:14:15,865 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4165984630584717, 'Total loss': 0.4165984630584717} | train loss {'Reaction outcome loss': 0.18944685783788615, 'Total loss': 0.18944685783788615}
2023-01-03 23:14:15,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:15,865 INFO:     Epoch: 82
2023-01-03 23:14:17,458 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4212025076150894, 'Total loss': 0.4212025076150894} | train loss {'Reaction outcome loss': 0.18902288361146563, 'Total loss': 0.18902288361146563}
2023-01-03 23:14:17,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:17,458 INFO:     Epoch: 83
2023-01-03 23:14:19,089 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41519444684187573, 'Total loss': 0.41519444684187573} | train loss {'Reaction outcome loss': 0.18698767375617897, 'Total loss': 0.18698767375617897}
2023-01-03 23:14:19,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:19,089 INFO:     Epoch: 84
2023-01-03 23:14:20,705 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.409593074520429, 'Total loss': 0.409593074520429} | train loss {'Reaction outcome loss': 0.1858065576975096, 'Total loss': 0.1858065576975096}
2023-01-03 23:14:20,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:20,705 INFO:     Epoch: 85
2023-01-03 23:14:22,309 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4085659702618917, 'Total loss': 0.4085659702618917} | train loss {'Reaction outcome loss': 0.18803708424744622, 'Total loss': 0.18803708424744622}
2023-01-03 23:14:22,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:22,309 INFO:     Epoch: 86
2023-01-03 23:14:23,917 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.401589572429657, 'Total loss': 0.401589572429657} | train loss {'Reaction outcome loss': 0.18452307146163624, 'Total loss': 0.18452307146163624}
2023-01-03 23:14:23,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:23,918 INFO:     Epoch: 87
2023-01-03 23:14:25,509 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4171741376320521, 'Total loss': 0.4171741376320521} | train loss {'Reaction outcome loss': 0.1828049150991526, 'Total loss': 0.1828049150991526}
2023-01-03 23:14:25,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:25,509 INFO:     Epoch: 88
2023-01-03 23:14:27,113 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40800562302271526, 'Total loss': 0.40800562302271526} | train loss {'Reaction outcome loss': 0.1840146508888217, 'Total loss': 0.1840146508888217}
2023-01-03 23:14:27,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:27,113 INFO:     Epoch: 89
2023-01-03 23:14:28,719 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41175659994284314, 'Total loss': 0.41175659994284314} | train loss {'Reaction outcome loss': 0.1853482074000022, 'Total loss': 0.1853482074000022}
2023-01-03 23:14:28,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:28,720 INFO:     Epoch: 90
2023-01-03 23:14:30,319 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39138409594694773, 'Total loss': 0.39138409594694773} | train loss {'Reaction outcome loss': 0.18198146779318794, 'Total loss': 0.18198146779318794}
2023-01-03 23:14:30,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:30,319 INFO:     Epoch: 91
2023-01-03 23:14:31,929 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38343370258808135, 'Total loss': 0.38343370258808135} | train loss {'Reaction outcome loss': 0.18244802831446866, 'Total loss': 0.18244802831446866}
2023-01-03 23:14:31,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:31,929 INFO:     Epoch: 92
2023-01-03 23:14:33,564 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4170116345087687, 'Total loss': 0.4170116345087687} | train loss {'Reaction outcome loss': 0.17977929750074118, 'Total loss': 0.17977929750074118}
2023-01-03 23:14:33,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:33,564 INFO:     Epoch: 93
2023-01-03 23:14:35,170 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3980161597331365, 'Total loss': 0.3980161597331365} | train loss {'Reaction outcome loss': 0.17910446417568393, 'Total loss': 0.17910446417568393}
2023-01-03 23:14:35,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:35,170 INFO:     Epoch: 94
2023-01-03 23:14:36,798 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4200664301713308, 'Total loss': 0.4200664301713308} | train loss {'Reaction outcome loss': 0.18034516465228173, 'Total loss': 0.18034516465228173}
2023-01-03 23:14:36,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:36,799 INFO:     Epoch: 95
2023-01-03 23:14:38,427 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39588441848754885, 'Total loss': 0.39588441848754885} | train loss {'Reaction outcome loss': 0.18068234378384554, 'Total loss': 0.18068234378384554}
2023-01-03 23:14:38,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:38,427 INFO:     Epoch: 96
2023-01-03 23:14:40,003 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42301845947901406, 'Total loss': 0.42301845947901406} | train loss {'Reaction outcome loss': 0.17910508713298326, 'Total loss': 0.17910508713298326}
2023-01-03 23:14:40,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:40,003 INFO:     Epoch: 97
2023-01-03 23:14:41,630 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.417555488149325, 'Total loss': 0.417555488149325} | train loss {'Reaction outcome loss': 0.1747344086343416, 'Total loss': 0.1747344086343416}
2023-01-03 23:14:41,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:41,630 INFO:     Epoch: 98
2023-01-03 23:14:43,240 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41964166760444643, 'Total loss': 0.41964166760444643} | train loss {'Reaction outcome loss': 0.1762558716258525, 'Total loss': 0.1762558716258525}
2023-01-03 23:14:43,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:43,240 INFO:     Epoch: 99
2023-01-03 23:14:44,866 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4242813209692637, 'Total loss': 0.4242813209692637} | train loss {'Reaction outcome loss': 0.1786918973866245, 'Total loss': 0.1786918973866245}
2023-01-03 23:14:44,866 INFO:     Best model found after epoch 52 of 100.
2023-01-03 23:14:44,866 INFO:   Done with stage: TRAINING
2023-01-03 23:14:44,866 INFO:   Starting stage: EVALUATION
2023-01-03 23:14:44,989 INFO:   Done with stage: EVALUATION
2023-01-03 23:14:44,989 INFO:   Leaving out SEQ value Fold_7
2023-01-03 23:14:45,002 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-03 23:14:45,002 INFO:   Starting stage: FEATURE SCALING
2023-01-03 23:14:45,646 INFO:   Done with stage: FEATURE SCALING
2023-01-03 23:14:45,647 INFO:   Starting stage: SCALING TARGETS
2023-01-03 23:14:45,716 INFO:   Done with stage: SCALING TARGETS
2023-01-03 23:14:45,716 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:14:45,716 INFO:     No hyperparam tuning for this model
2023-01-03 23:14:45,716 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:14:45,716 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 23:14:45,717 INFO:     None feature selector for col prot
2023-01-03 23:14:45,717 INFO:     None feature selector for col prot
2023-01-03 23:14:45,717 INFO:     None feature selector for col prot
2023-01-03 23:14:45,717 INFO:     None feature selector for col chem
2023-01-03 23:14:45,717 INFO:     None feature selector for col chem
2023-01-03 23:14:45,717 INFO:     None feature selector for col chem
2023-01-03 23:14:45,718 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 23:14:45,718 INFO:   Starting stage: BUILD MODEL
2023-01-03 23:14:45,719 INFO:     Number of params in model 70141
2023-01-03 23:14:45,722 INFO:   Done with stage: BUILD MODEL
2023-01-03 23:14:45,722 INFO:   Starting stage: TRAINING
2023-01-03 23:14:45,765 INFO:     Val loss before train {'Reaction outcome loss': 1.0048131982485453, 'Total loss': 1.0048131982485453}
2023-01-03 23:14:45,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:45,766 INFO:     Epoch: 0
2023-01-03 23:14:47,353 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6235797345638275, 'Total loss': 0.6235797345638275} | train loss {'Reaction outcome loss': 0.8747881385902672, 'Total loss': 0.8747881385902672}
2023-01-03 23:14:47,353 INFO:     Found new best model at epoch 0
2023-01-03 23:14:47,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:47,353 INFO:     Epoch: 1
2023-01-03 23:14:48,986 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5439243157704671, 'Total loss': 0.5439243157704671} | train loss {'Reaction outcome loss': 0.6004071770188655, 'Total loss': 0.6004071770188655}
2023-01-03 23:14:48,986 INFO:     Found new best model at epoch 1
2023-01-03 23:14:48,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:48,987 INFO:     Epoch: 2
2023-01-03 23:14:50,614 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5133302013079325, 'Total loss': 0.5133302013079325} | train loss {'Reaction outcome loss': 0.5158571723335679, 'Total loss': 0.5158571723335679}
2023-01-03 23:14:50,614 INFO:     Found new best model at epoch 2
2023-01-03 23:14:50,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:50,615 INFO:     Epoch: 3
2023-01-03 23:14:52,238 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4839357525110245, 'Total loss': 0.4839357525110245} | train loss {'Reaction outcome loss': 0.4788634170224701, 'Total loss': 0.4788634170224701}
2023-01-03 23:14:52,238 INFO:     Found new best model at epoch 3
2023-01-03 23:14:52,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:52,239 INFO:     Epoch: 4
2023-01-03 23:14:53,863 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49187029600143434, 'Total loss': 0.49187029600143434} | train loss {'Reaction outcome loss': 0.4511759248865849, 'Total loss': 0.4511759248865849}
2023-01-03 23:14:53,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:53,863 INFO:     Epoch: 5
2023-01-03 23:14:55,489 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49062267939249676, 'Total loss': 0.49062267939249676} | train loss {'Reaction outcome loss': 0.4312504334375262, 'Total loss': 0.4312504334375262}
2023-01-03 23:14:55,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:55,490 INFO:     Epoch: 6
2023-01-03 23:14:57,076 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.467346602678299, 'Total loss': 0.467346602678299} | train loss {'Reaction outcome loss': 0.41632821507738443, 'Total loss': 0.41632821507738443}
2023-01-03 23:14:57,076 INFO:     Found new best model at epoch 6
2023-01-03 23:14:57,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:57,077 INFO:     Epoch: 7
2023-01-03 23:14:58,671 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45936788320541383, 'Total loss': 0.45936788320541383} | train loss {'Reaction outcome loss': 0.4023936247804027, 'Total loss': 0.4023936247804027}
2023-01-03 23:14:58,671 INFO:     Found new best model at epoch 7
2023-01-03 23:14:58,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:14:58,672 INFO:     Epoch: 8
2023-01-03 23:15:00,292 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45939332942167915, 'Total loss': 0.45939332942167915} | train loss {'Reaction outcome loss': 0.38859379773392627, 'Total loss': 0.38859379773392627}
2023-01-03 23:15:00,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:00,292 INFO:     Epoch: 9
2023-01-03 23:15:01,873 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4465288827816645, 'Total loss': 0.4465288827816645} | train loss {'Reaction outcome loss': 0.3748051385678675, 'Total loss': 0.3748051385678675}
2023-01-03 23:15:01,873 INFO:     Found new best model at epoch 9
2023-01-03 23:15:01,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:01,874 INFO:     Epoch: 10
2023-01-03 23:15:03,469 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45882813930511473, 'Total loss': 0.45882813930511473} | train loss {'Reaction outcome loss': 0.36418683366661053, 'Total loss': 0.36418683366661053}
2023-01-03 23:15:03,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:03,469 INFO:     Epoch: 11
2023-01-03 23:15:05,067 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43790881236394247, 'Total loss': 0.43790881236394247} | train loss {'Reaction outcome loss': 0.36449372943868674, 'Total loss': 0.36449372943868674}
2023-01-03 23:15:05,068 INFO:     Found new best model at epoch 11
2023-01-03 23:15:05,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:05,068 INFO:     Epoch: 12
2023-01-03 23:15:06,646 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4572501907745997, 'Total loss': 0.4572501907745997} | train loss {'Reaction outcome loss': 0.35194802710759465, 'Total loss': 0.35194802710759465}
2023-01-03 23:15:06,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:06,647 INFO:     Epoch: 13
2023-01-03 23:15:08,269 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44242040713628134, 'Total loss': 0.44242040713628134} | train loss {'Reaction outcome loss': 0.3437993197121482, 'Total loss': 0.3437993197121482}
2023-01-03 23:15:08,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:08,269 INFO:     Epoch: 14
2023-01-03 23:15:09,867 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43339173396428426, 'Total loss': 0.43339173396428426} | train loss {'Reaction outcome loss': 0.33308768847390363, 'Total loss': 0.33308768847390363}
2023-01-03 23:15:09,867 INFO:     Found new best model at epoch 14
2023-01-03 23:15:09,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:09,868 INFO:     Epoch: 15
2023-01-03 23:15:11,492 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4443715105454127, 'Total loss': 0.4443715105454127} | train loss {'Reaction outcome loss': 0.3211271910615218, 'Total loss': 0.3211271910615218}
2023-01-03 23:15:11,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:11,492 INFO:     Epoch: 16
2023-01-03 23:15:13,126 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4343290706475576, 'Total loss': 0.4343290706475576} | train loss {'Reaction outcome loss': 0.3160170876653865, 'Total loss': 0.3160170876653865}
2023-01-03 23:15:13,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:13,126 INFO:     Epoch: 17
2023-01-03 23:15:14,719 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4461640963951747, 'Total loss': 0.4461640963951747} | train loss {'Reaction outcome loss': 0.3092391560987934, 'Total loss': 0.3092391560987934}
2023-01-03 23:15:14,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:14,720 INFO:     Epoch: 18
2023-01-03 23:15:16,317 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44396496216456094, 'Total loss': 0.44396496216456094} | train loss {'Reaction outcome loss': 0.304387371354307, 'Total loss': 0.304387371354307}
2023-01-03 23:15:16,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:16,317 INFO:     Epoch: 19
2023-01-03 23:15:17,905 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4359152207771937, 'Total loss': 0.4359152207771937} | train loss {'Reaction outcome loss': 0.2967508139888683, 'Total loss': 0.2967508139888683}
2023-01-03 23:15:17,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:17,905 INFO:     Epoch: 20
2023-01-03 23:15:19,478 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4406884024540583, 'Total loss': 0.4406884024540583} | train loss {'Reaction outcome loss': 0.29566252002141613, 'Total loss': 0.29566252002141613}
2023-01-03 23:15:19,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:19,479 INFO:     Epoch: 21
2023-01-03 23:15:21,080 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41974134743213654, 'Total loss': 0.41974134743213654} | train loss {'Reaction outcome loss': 0.2913307345613999, 'Total loss': 0.2913307345613999}
2023-01-03 23:15:21,081 INFO:     Found new best model at epoch 21
2023-01-03 23:15:21,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:21,081 INFO:     Epoch: 22
2023-01-03 23:15:22,681 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43490809202194214, 'Total loss': 0.43490809202194214} | train loss {'Reaction outcome loss': 0.28382771548585617, 'Total loss': 0.28382771548585617}
2023-01-03 23:15:22,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:22,681 INFO:     Epoch: 23
2023-01-03 23:15:24,282 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44499975740909575, 'Total loss': 0.44499975740909575} | train loss {'Reaction outcome loss': 0.28155524065664067, 'Total loss': 0.28155524065664067}
2023-01-03 23:15:24,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:24,282 INFO:     Epoch: 24
2023-01-03 23:15:25,937 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4378099501132965, 'Total loss': 0.4378099501132965} | train loss {'Reaction outcome loss': 0.27499906841051375, 'Total loss': 0.27499906841051375}
2023-01-03 23:15:25,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:25,937 INFO:     Epoch: 25
2023-01-03 23:15:27,548 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4378644953171412, 'Total loss': 0.4378644953171412} | train loss {'Reaction outcome loss': 0.26859530215522787, 'Total loss': 0.26859530215522787}
2023-01-03 23:15:27,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:27,548 INFO:     Epoch: 26
2023-01-03 23:15:29,158 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43529310524463655, 'Total loss': 0.43529310524463655} | train loss {'Reaction outcome loss': 0.26432270455963747, 'Total loss': 0.26432270455963747}
2023-01-03 23:15:29,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:29,159 INFO:     Epoch: 27
2023-01-03 23:15:30,790 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44363963802655537, 'Total loss': 0.44363963802655537} | train loss {'Reaction outcome loss': 0.26275505785378156, 'Total loss': 0.26275505785378156}
2023-01-03 23:15:30,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:30,791 INFO:     Epoch: 28
2023-01-03 23:15:32,384 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43305194775263467, 'Total loss': 0.43305194775263467} | train loss {'Reaction outcome loss': 0.25755568309788307, 'Total loss': 0.25755568309788307}
2023-01-03 23:15:32,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:32,384 INFO:     Epoch: 29
2023-01-03 23:15:33,973 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46502196192741396, 'Total loss': 0.46502196192741396} | train loss {'Reaction outcome loss': 0.25723410875998787, 'Total loss': 0.25723410875998787}
2023-01-03 23:15:33,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:33,973 INFO:     Epoch: 30
2023-01-03 23:15:35,570 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42753293936451275, 'Total loss': 0.42753293936451275} | train loss {'Reaction outcome loss': 0.2506910354519884, 'Total loss': 0.2506910354519884}
2023-01-03 23:15:35,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:35,570 INFO:     Epoch: 31
2023-01-03 23:15:37,155 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4327907428145409, 'Total loss': 0.4327907428145409} | train loss {'Reaction outcome loss': 0.24903874981409108, 'Total loss': 0.24903874981409108}
2023-01-03 23:15:37,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:37,156 INFO:     Epoch: 32
2023-01-03 23:15:38,737 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43810110092163085, 'Total loss': 0.43810110092163085} | train loss {'Reaction outcome loss': 0.24505330013462168, 'Total loss': 0.24505330013462168}
2023-01-03 23:15:38,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:38,738 INFO:     Epoch: 33
2023-01-03 23:15:40,358 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4367040971914927, 'Total loss': 0.4367040971914927} | train loss {'Reaction outcome loss': 0.2440524168761339, 'Total loss': 0.2440524168761339}
2023-01-03 23:15:40,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:40,359 INFO:     Epoch: 34
2023-01-03 23:15:41,944 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4382089873154958, 'Total loss': 0.4382089873154958} | train loss {'Reaction outcome loss': 0.23934090569757932, 'Total loss': 0.23934090569757932}
2023-01-03 23:15:41,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:41,944 INFO:     Epoch: 35
2023-01-03 23:15:43,563 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4461794376373291, 'Total loss': 0.4461794376373291} | train loss {'Reaction outcome loss': 0.23773781247470743, 'Total loss': 0.23773781247470743}
2023-01-03 23:15:43,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:43,563 INFO:     Epoch: 36
2023-01-03 23:15:45,145 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4424929718176524, 'Total loss': 0.4424929718176524} | train loss {'Reaction outcome loss': 0.23516632266637646, 'Total loss': 0.23516632266637646}
2023-01-03 23:15:45,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:45,146 INFO:     Epoch: 37
2023-01-03 23:15:46,735 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4483862429857254, 'Total loss': 0.4483862429857254} | train loss {'Reaction outcome loss': 0.23936898354440928, 'Total loss': 0.23936898354440928}
2023-01-03 23:15:46,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:46,735 INFO:     Epoch: 38
2023-01-03 23:15:48,316 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44283329049746195, 'Total loss': 0.44283329049746195} | train loss {'Reaction outcome loss': 0.24416365437133683, 'Total loss': 0.24416365437133683}
2023-01-03 23:15:48,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:48,316 INFO:     Epoch: 39
2023-01-03 23:15:49,935 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4384956399599711, 'Total loss': 0.4384956399599711} | train loss {'Reaction outcome loss': 0.23035853414161914, 'Total loss': 0.23035853414161914}
2023-01-03 23:15:49,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:49,936 INFO:     Epoch: 40
2023-01-03 23:15:51,512 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4523865461349487, 'Total loss': 0.4523865461349487} | train loss {'Reaction outcome loss': 0.23006215675369554, 'Total loss': 0.23006215675369554}
2023-01-03 23:15:51,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:51,512 INFO:     Epoch: 41
2023-01-03 23:15:53,143 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4471482068300247, 'Total loss': 0.4471482068300247} | train loss {'Reaction outcome loss': 0.23917664355848092, 'Total loss': 0.23917664355848092}
2023-01-03 23:15:53,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:53,143 INFO:     Epoch: 42
2023-01-03 23:15:54,748 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44568631251653035, 'Total loss': 0.44568631251653035} | train loss {'Reaction outcome loss': 0.22112337659126607, 'Total loss': 0.22112337659126607}
2023-01-03 23:15:54,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:54,748 INFO:     Epoch: 43
2023-01-03 23:15:56,344 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43537165224552155, 'Total loss': 0.43537165224552155} | train loss {'Reaction outcome loss': 0.21903501304230935, 'Total loss': 0.21903501304230935}
2023-01-03 23:15:56,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:56,344 INFO:     Epoch: 44
2023-01-03 23:15:57,944 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44796156883239746, 'Total loss': 0.44796156883239746} | train loss {'Reaction outcome loss': 0.21949149807514387, 'Total loss': 0.21949149807514387}
2023-01-03 23:15:57,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:57,944 INFO:     Epoch: 45
2023-01-03 23:15:59,526 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42421455880006154, 'Total loss': 0.42421455880006154} | train loss {'Reaction outcome loss': 0.21845019008823446, 'Total loss': 0.21845019008823446}
2023-01-03 23:15:59,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:15:59,526 INFO:     Epoch: 46
2023-01-03 23:16:01,144 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46663868278264997, 'Total loss': 0.46663868278264997} | train loss {'Reaction outcome loss': 0.21602799552339633, 'Total loss': 0.21602799552339633}
2023-01-03 23:16:01,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:01,145 INFO:     Epoch: 47
2023-01-03 23:16:02,774 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41585363348325094, 'Total loss': 0.41585363348325094} | train loss {'Reaction outcome loss': 0.2162082426391704, 'Total loss': 0.2162082426391704}
2023-01-03 23:16:02,775 INFO:     Found new best model at epoch 47
2023-01-03 23:16:02,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:02,775 INFO:     Epoch: 48
2023-01-03 23:16:04,361 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4446049173672994, 'Total loss': 0.4446049173672994} | train loss {'Reaction outcome loss': 0.2129323286480149, 'Total loss': 0.2129323286480149}
2023-01-03 23:16:04,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:04,361 INFO:     Epoch: 49
2023-01-03 23:16:05,981 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44710098107655843, 'Total loss': 0.44710098107655843} | train loss {'Reaction outcome loss': 0.21435220205508496, 'Total loss': 0.21435220205508496}
2023-01-03 23:16:05,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:05,981 INFO:     Epoch: 50
2023-01-03 23:16:07,572 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4423476646343867, 'Total loss': 0.4423476646343867} | train loss {'Reaction outcome loss': 0.2151153040509941, 'Total loss': 0.2151153040509941}
2023-01-03 23:16:07,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:07,572 INFO:     Epoch: 51
2023-01-03 23:16:09,149 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43708826700846354, 'Total loss': 0.43708826700846354} | train loss {'Reaction outcome loss': 0.21587107009321882, 'Total loss': 0.21587107009321882}
2023-01-03 23:16:09,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:09,149 INFO:     Epoch: 52
2023-01-03 23:16:10,741 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45000958343346914, 'Total loss': 0.45000958343346914} | train loss {'Reaction outcome loss': 0.21026910001924937, 'Total loss': 0.21026910001924937}
2023-01-03 23:16:10,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:10,742 INFO:     Epoch: 53
2023-01-03 23:16:12,353 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.446222464243571, 'Total loss': 0.446222464243571} | train loss {'Reaction outcome loss': 0.2118965955283665, 'Total loss': 0.2118965955283665}
2023-01-03 23:16:12,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:12,354 INFO:     Epoch: 54
2023-01-03 23:16:13,935 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45947447915871936, 'Total loss': 0.45947447915871936} | train loss {'Reaction outcome loss': 0.20329092711632996, 'Total loss': 0.20329092711632996}
2023-01-03 23:16:13,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:13,935 INFO:     Epoch: 55
2023-01-03 23:16:15,531 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44673964381217957, 'Total loss': 0.44673964381217957} | train loss {'Reaction outcome loss': 0.20344672738323477, 'Total loss': 0.20344672738323477}
2023-01-03 23:16:15,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:15,532 INFO:     Epoch: 56
2023-01-03 23:16:17,123 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4352077494064967, 'Total loss': 0.4352077494064967} | train loss {'Reaction outcome loss': 0.19877232312456475, 'Total loss': 0.19877232312456475}
2023-01-03 23:16:17,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:17,123 INFO:     Epoch: 57
2023-01-03 23:16:18,729 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4369751433531443, 'Total loss': 0.4369751433531443} | train loss {'Reaction outcome loss': 0.2008461626668366, 'Total loss': 0.2008461626668366}
2023-01-03 23:16:18,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:18,729 INFO:     Epoch: 58
2023-01-03 23:16:20,323 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45315584937731423, 'Total loss': 0.45315584937731423} | train loss {'Reaction outcome loss': 0.196626633792682, 'Total loss': 0.196626633792682}
2023-01-03 23:16:20,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:20,324 INFO:     Epoch: 59
2023-01-03 23:16:21,917 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4329684232672056, 'Total loss': 0.4329684232672056} | train loss {'Reaction outcome loss': 0.19891027731284958, 'Total loss': 0.19891027731284958}
2023-01-03 23:16:21,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:21,917 INFO:     Epoch: 60
2023-01-03 23:16:23,541 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4512223169207573, 'Total loss': 0.4512223169207573} | train loss {'Reaction outcome loss': 0.1976784039786477, 'Total loss': 0.1976784039786477}
2023-01-03 23:16:23,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:23,542 INFO:     Epoch: 61
2023-01-03 23:16:25,166 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4398518512646357, 'Total loss': 0.4398518512646357} | train loss {'Reaction outcome loss': 0.19698896629473683, 'Total loss': 0.19698896629473683}
2023-01-03 23:16:25,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:25,167 INFO:     Epoch: 62
2023-01-03 23:16:26,757 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4933410237232844, 'Total loss': 0.4933410237232844} | train loss {'Reaction outcome loss': 0.21084312830066335, 'Total loss': 0.21084312830066335}
2023-01-03 23:16:26,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:26,758 INFO:     Epoch: 63
2023-01-03 23:16:28,355 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42689909040927887, 'Total loss': 0.42689909040927887} | train loss {'Reaction outcome loss': 0.20627837192412277, 'Total loss': 0.20627837192412277}
2023-01-03 23:16:28,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:28,355 INFO:     Epoch: 64
2023-01-03 23:16:29,951 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45001577933629355, 'Total loss': 0.45001577933629355} | train loss {'Reaction outcome loss': 0.1922474401037924, 'Total loss': 0.1922474401037924}
2023-01-03 23:16:29,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:29,951 INFO:     Epoch: 65
2023-01-03 23:16:31,552 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4446827868620555, 'Total loss': 0.4446827868620555} | train loss {'Reaction outcome loss': 0.19333565733193056, 'Total loss': 0.19333565733193056}
2023-01-03 23:16:31,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:31,553 INFO:     Epoch: 66
2023-01-03 23:16:33,149 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4309640417496363, 'Total loss': 0.4309640417496363} | train loss {'Reaction outcome loss': 0.19533133159890986, 'Total loss': 0.19533133159890986}
2023-01-03 23:16:33,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:33,149 INFO:     Epoch: 67
2023-01-03 23:16:34,766 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44428896605968476, 'Total loss': 0.44428896605968476} | train loss {'Reaction outcome loss': 0.19746141418874977, 'Total loss': 0.19746141418874977}
2023-01-03 23:16:34,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:34,766 INFO:     Epoch: 68
2023-01-03 23:16:36,352 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4423058291276296, 'Total loss': 0.4423058291276296} | train loss {'Reaction outcome loss': 0.18701486800199602, 'Total loss': 0.18701486800199602}
2023-01-03 23:16:36,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:36,352 INFO:     Epoch: 69
2023-01-03 23:16:37,948 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44502928157647453, 'Total loss': 0.44502928157647453} | train loss {'Reaction outcome loss': 0.18718655777711715, 'Total loss': 0.18718655777711715}
2023-01-03 23:16:37,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:37,949 INFO:     Epoch: 70
2023-01-03 23:16:39,535 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4385931114355723, 'Total loss': 0.4385931114355723} | train loss {'Reaction outcome loss': 0.18648364100996676, 'Total loss': 0.18648364100996676}
2023-01-03 23:16:39,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:39,536 INFO:     Epoch: 71
2023-01-03 23:16:41,153 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4656004240115484, 'Total loss': 0.4656004240115484} | train loss {'Reaction outcome loss': 0.18344316036165725, 'Total loss': 0.18344316036165725}
2023-01-03 23:16:41,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:41,153 INFO:     Epoch: 72
2023-01-03 23:16:42,775 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43796797494093576, 'Total loss': 0.43796797494093576} | train loss {'Reaction outcome loss': 0.18674122656871012, 'Total loss': 0.18674122656871012}
2023-01-03 23:16:42,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:42,776 INFO:     Epoch: 73
2023-01-03 23:16:44,372 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4318213641643524, 'Total loss': 0.4318213641643524} | train loss {'Reaction outcome loss': 0.18771511990495998, 'Total loss': 0.18771511990495998}
2023-01-03 23:16:44,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:44,372 INFO:     Epoch: 74
2023-01-03 23:16:45,969 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43365635673205055, 'Total loss': 0.43365635673205055} | train loss {'Reaction outcome loss': 0.1833364770585752, 'Total loss': 0.1833364770585752}
2023-01-03 23:16:45,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:45,969 INFO:     Epoch: 75
2023-01-03 23:16:47,589 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43735810617605847, 'Total loss': 0.43735810617605847} | train loss {'Reaction outcome loss': 0.18460185295966305, 'Total loss': 0.18460185295966305}
2023-01-03 23:16:47,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:47,589 INFO:     Epoch: 76
2023-01-03 23:16:49,195 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4434993306795756, 'Total loss': 0.4434993306795756} | train loss {'Reaction outcome loss': 0.18422637061398153, 'Total loss': 0.18422637061398153}
2023-01-03 23:16:49,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:49,196 INFO:     Epoch: 77
2023-01-03 23:16:50,815 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46417133659124377, 'Total loss': 0.46417133659124377} | train loss {'Reaction outcome loss': 0.18101659845569226, 'Total loss': 0.18101659845569226}
2023-01-03 23:16:50,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:50,816 INFO:     Epoch: 78
2023-01-03 23:16:52,432 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4678600976864497, 'Total loss': 0.4678600976864497} | train loss {'Reaction outcome loss': 0.18215594667455423, 'Total loss': 0.18215594667455423}
2023-01-03 23:16:52,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:52,432 INFO:     Epoch: 79
2023-01-03 23:16:54,032 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.448576853175958, 'Total loss': 0.448576853175958} | train loss {'Reaction outcome loss': 0.18750086922765427, 'Total loss': 0.18750086922765427}
2023-01-03 23:16:54,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:54,032 INFO:     Epoch: 80
2023-01-03 23:16:55,656 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4525834838549296, 'Total loss': 0.4525834838549296} | train loss {'Reaction outcome loss': 0.19088485330829155, 'Total loss': 0.19088485330829155}
2023-01-03 23:16:55,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:55,656 INFO:     Epoch: 81
2023-01-03 23:16:57,256 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46814729273319244, 'Total loss': 0.46814729273319244} | train loss {'Reaction outcome loss': 0.19270804640499578, 'Total loss': 0.19270804640499578}
2023-01-03 23:16:57,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:57,256 INFO:     Epoch: 82
2023-01-03 23:16:58,859 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4890426794687907, 'Total loss': 0.4890426794687907} | train loss {'Reaction outcome loss': 0.19523740453186675, 'Total loss': 0.19523740453186675}
2023-01-03 23:16:58,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:16:58,860 INFO:     Epoch: 83
2023-01-03 23:17:00,470 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45039643744627633, 'Total loss': 0.45039643744627633} | train loss {'Reaction outcome loss': 0.1936189936401417, 'Total loss': 0.1936189936401417}
2023-01-03 23:17:00,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:00,470 INFO:     Epoch: 84
2023-01-03 23:17:02,088 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4517678956190745, 'Total loss': 0.4517678956190745} | train loss {'Reaction outcome loss': 0.18431627410261528, 'Total loss': 0.18431627410261528}
2023-01-03 23:17:02,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:02,089 INFO:     Epoch: 85
2023-01-03 23:17:03,685 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49762115478515623, 'Total loss': 0.49762115478515623} | train loss {'Reaction outcome loss': 0.17980937570060976, 'Total loss': 0.17980937570060976}
2023-01-03 23:17:03,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:03,685 INFO:     Epoch: 86
2023-01-03 23:17:05,291 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48131346305211387, 'Total loss': 0.48131346305211387} | train loss {'Reaction outcome loss': 0.17683816421054688, 'Total loss': 0.17683816421054688}
2023-01-03 23:17:05,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:05,292 INFO:     Epoch: 87
2023-01-03 23:17:06,881 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44972805082798006, 'Total loss': 0.44972805082798006} | train loss {'Reaction outcome loss': 0.17893188799043064, 'Total loss': 0.17893188799043064}
2023-01-03 23:17:06,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:06,881 INFO:     Epoch: 88
2023-01-03 23:17:08,505 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4721556087334951, 'Total loss': 0.4721556087334951} | train loss {'Reaction outcome loss': 0.1753448751022507, 'Total loss': 0.1753448751022507}
2023-01-03 23:17:08,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:08,506 INFO:     Epoch: 89
2023-01-03 23:17:10,115 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49431566894054413, 'Total loss': 0.49431566894054413} | train loss {'Reaction outcome loss': 0.17536230507708303, 'Total loss': 0.17536230507708303}
2023-01-03 23:17:10,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:10,115 INFO:     Epoch: 90
2023-01-03 23:17:11,716 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4466909945011139, 'Total loss': 0.4466909945011139} | train loss {'Reaction outcome loss': 0.17381405045561868, 'Total loss': 0.17381405045561868}
2023-01-03 23:17:11,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:11,716 INFO:     Epoch: 91
2023-01-03 23:17:13,339 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45384489595890043, 'Total loss': 0.45384489595890043} | train loss {'Reaction outcome loss': 0.17576029140126184, 'Total loss': 0.17576029140126184}
2023-01-03 23:17:13,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:13,339 INFO:     Epoch: 92
2023-01-03 23:17:14,958 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45791541735331215, 'Total loss': 0.45791541735331215} | train loss {'Reaction outcome loss': 0.17315538099982555, 'Total loss': 0.17315538099982555}
2023-01-03 23:17:14,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:14,959 INFO:     Epoch: 93
2023-01-03 23:17:16,558 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48035951554775236, 'Total loss': 0.48035951554775236} | train loss {'Reaction outcome loss': 0.17363048872599998, 'Total loss': 0.17363048872599998}
2023-01-03 23:17:16,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:16,559 INFO:     Epoch: 94
2023-01-03 23:17:18,178 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4565783033768336, 'Total loss': 0.4565783033768336} | train loss {'Reaction outcome loss': 0.17992296991734832, 'Total loss': 0.17992296991734832}
2023-01-03 23:17:18,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:18,178 INFO:     Epoch: 95
2023-01-03 23:17:19,789 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4580361972252528, 'Total loss': 0.4580361972252528} | train loss {'Reaction outcome loss': 0.17150025606826894, 'Total loss': 0.17150025606826894}
2023-01-03 23:17:19,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:19,789 INFO:     Epoch: 96
2023-01-03 23:17:21,379 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47602740228176116, 'Total loss': 0.47602740228176116} | train loss {'Reaction outcome loss': 0.17036581239372553, 'Total loss': 0.17036581239372553}
2023-01-03 23:17:21,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:21,380 INFO:     Epoch: 97
2023-01-03 23:17:22,980 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.454771289229393, 'Total loss': 0.454771289229393} | train loss {'Reaction outcome loss': 0.16931505614920225, 'Total loss': 0.16931505614920225}
2023-01-03 23:17:22,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:22,980 INFO:     Epoch: 98
2023-01-03 23:17:24,585 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47764026125272113, 'Total loss': 0.47764026125272113} | train loss {'Reaction outcome loss': 0.16928235714600515, 'Total loss': 0.16928235714600515}
2023-01-03 23:17:24,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:24,585 INFO:     Epoch: 99
2023-01-03 23:17:26,190 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4754313627878825, 'Total loss': 0.4754313627878825} | train loss {'Reaction outcome loss': 0.16981625041344028, 'Total loss': 0.16981625041344028}
2023-01-03 23:17:26,190 INFO:     Best model found after epoch 48 of 100.
2023-01-03 23:17:26,190 INFO:   Done with stage: TRAINING
2023-01-03 23:17:26,191 INFO:   Starting stage: EVALUATION
2023-01-03 23:17:26,320 INFO:   Done with stage: EVALUATION
2023-01-03 23:17:26,320 INFO:   Leaving out SEQ value Fold_8
2023-01-03 23:17:26,333 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-03 23:17:26,333 INFO:   Starting stage: FEATURE SCALING
2023-01-03 23:17:26,979 INFO:   Done with stage: FEATURE SCALING
2023-01-03 23:17:26,979 INFO:   Starting stage: SCALING TARGETS
2023-01-03 23:17:27,049 INFO:   Done with stage: SCALING TARGETS
2023-01-03 23:17:27,049 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:17:27,049 INFO:     No hyperparam tuning for this model
2023-01-03 23:17:27,049 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:17:27,049 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 23:17:27,050 INFO:     None feature selector for col prot
2023-01-03 23:17:27,050 INFO:     None feature selector for col prot
2023-01-03 23:17:27,050 INFO:     None feature selector for col prot
2023-01-03 23:17:27,051 INFO:     None feature selector for col chem
2023-01-03 23:17:27,051 INFO:     None feature selector for col chem
2023-01-03 23:17:27,051 INFO:     None feature selector for col chem
2023-01-03 23:17:27,051 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 23:17:27,051 INFO:   Starting stage: BUILD MODEL
2023-01-03 23:17:27,052 INFO:     Number of params in model 70141
2023-01-03 23:17:27,055 INFO:   Done with stage: BUILD MODEL
2023-01-03 23:17:27,055 INFO:   Starting stage: TRAINING
2023-01-03 23:17:27,098 INFO:     Val loss before train {'Reaction outcome loss': 0.9205495397249858, 'Total loss': 0.9205495397249858}
2023-01-03 23:17:27,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:27,098 INFO:     Epoch: 0
2023-01-03 23:17:28,698 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6401347994804383, 'Total loss': 0.6401347994804383} | train loss {'Reaction outcome loss': 0.8623939073388127, 'Total loss': 0.8623939073388127}
2023-01-03 23:17:28,698 INFO:     Found new best model at epoch 0
2023-01-03 23:17:28,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:28,699 INFO:     Epoch: 1
2023-01-03 23:17:30,274 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.548162841796875, 'Total loss': 0.548162841796875} | train loss {'Reaction outcome loss': 0.6244819484182053, 'Total loss': 0.6244819484182053}
2023-01-03 23:17:30,274 INFO:     Found new best model at epoch 1
2023-01-03 23:17:30,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:30,275 INFO:     Epoch: 2
2023-01-03 23:17:31,887 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48694331844647726, 'Total loss': 0.48694331844647726} | train loss {'Reaction outcome loss': 0.5670482316526814, 'Total loss': 0.5670482316526814}
2023-01-03 23:17:31,887 INFO:     Found new best model at epoch 2
2023-01-03 23:17:31,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:31,888 INFO:     Epoch: 3
2023-01-03 23:17:33,493 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46026583909988406, 'Total loss': 0.46026583909988406} | train loss {'Reaction outcome loss': 0.4975338607918525, 'Total loss': 0.4975338607918525}
2023-01-03 23:17:33,493 INFO:     Found new best model at epoch 3
2023-01-03 23:17:33,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:33,494 INFO:     Epoch: 4
2023-01-03 23:17:35,110 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43734023769696556, 'Total loss': 0.43734023769696556} | train loss {'Reaction outcome loss': 0.4668763142713494, 'Total loss': 0.4668763142713494}
2023-01-03 23:17:35,110 INFO:     Found new best model at epoch 4
2023-01-03 23:17:35,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:35,111 INFO:     Epoch: 5
2023-01-03 23:17:36,732 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4265803933143616, 'Total loss': 0.4265803933143616} | train loss {'Reaction outcome loss': 0.44775618677553924, 'Total loss': 0.44775618677553924}
2023-01-03 23:17:36,732 INFO:     Found new best model at epoch 5
2023-01-03 23:17:36,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:36,733 INFO:     Epoch: 6
2023-01-03 23:17:38,305 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4388983309268951, 'Total loss': 0.4388983309268951} | train loss {'Reaction outcome loss': 0.43117397588988143, 'Total loss': 0.43117397588988143}
2023-01-03 23:17:38,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:38,306 INFO:     Epoch: 7
2023-01-03 23:17:39,896 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4191267162561417, 'Total loss': 0.4191267162561417} | train loss {'Reaction outcome loss': 0.4139906139875614, 'Total loss': 0.4139906139875614}
2023-01-03 23:17:39,896 INFO:     Found new best model at epoch 7
2023-01-03 23:17:39,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:39,897 INFO:     Epoch: 8
2023-01-03 23:17:41,493 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4143216282129288, 'Total loss': 0.4143216282129288} | train loss {'Reaction outcome loss': 0.40226889008899097, 'Total loss': 0.40226889008899097}
2023-01-03 23:17:41,493 INFO:     Found new best model at epoch 8
2023-01-03 23:17:41,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:41,494 INFO:     Epoch: 9
2023-01-03 23:17:43,079 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4002056747674942, 'Total loss': 0.4002056747674942} | train loss {'Reaction outcome loss': 0.3920861698579097, 'Total loss': 0.3920861698579097}
2023-01-03 23:17:43,079 INFO:     Found new best model at epoch 9
2023-01-03 23:17:43,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:43,080 INFO:     Epoch: 10
2023-01-03 23:17:44,673 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3952284693717957, 'Total loss': 0.3952284693717957} | train loss {'Reaction outcome loss': 0.38199999768139736, 'Total loss': 0.38199999768139736}
2023-01-03 23:17:44,674 INFO:     Found new best model at epoch 10
2023-01-03 23:17:44,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:44,675 INFO:     Epoch: 11
2023-01-03 23:17:46,263 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4105194826920827, 'Total loss': 0.4105194826920827} | train loss {'Reaction outcome loss': 0.3873680120576983, 'Total loss': 0.3873680120576983}
2023-01-03 23:17:46,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:46,263 INFO:     Epoch: 12
2023-01-03 23:17:47,845 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.386025873819987, 'Total loss': 0.386025873819987} | train loss {'Reaction outcome loss': 0.37656771576544945, 'Total loss': 0.37656771576544945}
2023-01-03 23:17:47,845 INFO:     Found new best model at epoch 12
2023-01-03 23:17:47,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:47,846 INFO:     Epoch: 13
2023-01-03 23:17:49,466 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41444597840309144, 'Total loss': 0.41444597840309144} | train loss {'Reaction outcome loss': 0.35993873272293614, 'Total loss': 0.35993873272293614}
2023-01-03 23:17:49,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:49,466 INFO:     Epoch: 14
2023-01-03 23:17:51,085 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3924480448166529, 'Total loss': 0.3924480448166529} | train loss {'Reaction outcome loss': 0.353207581310425, 'Total loss': 0.353207581310425}
2023-01-03 23:17:51,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:51,085 INFO:     Epoch: 15
2023-01-03 23:17:52,673 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3928092022736867, 'Total loss': 0.3928092022736867} | train loss {'Reaction outcome loss': 0.3473027268219216, 'Total loss': 0.3473027268219216}
2023-01-03 23:17:52,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:52,674 INFO:     Epoch: 16
2023-01-03 23:17:54,295 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.38098813394705455, 'Total loss': 0.38098813394705455} | train loss {'Reaction outcome loss': 0.34511749716340634, 'Total loss': 0.34511749716340634}
2023-01-03 23:17:54,295 INFO:     Found new best model at epoch 16
2023-01-03 23:17:54,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:54,296 INFO:     Epoch: 17
2023-01-03 23:17:55,901 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3863719860712687, 'Total loss': 0.3863719860712687} | train loss {'Reaction outcome loss': 0.3394134821849192, 'Total loss': 0.3394134821849192}
2023-01-03 23:17:55,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:55,902 INFO:     Epoch: 18
2023-01-03 23:17:57,487 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3969192365805308, 'Total loss': 0.3969192365805308} | train loss {'Reaction outcome loss': 0.32940490167432773, 'Total loss': 0.32940490167432773}
2023-01-03 23:17:57,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:57,488 INFO:     Epoch: 19
2023-01-03 23:17:59,094 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.37828959127267203, 'Total loss': 0.37828959127267203} | train loss {'Reaction outcome loss': 0.32777802705548814, 'Total loss': 0.32777802705548814}
2023-01-03 23:17:59,094 INFO:     Found new best model at epoch 19
2023-01-03 23:17:59,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:17:59,095 INFO:     Epoch: 20
2023-01-03 23:18:00,692 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.37956317961215974, 'Total loss': 0.37956317961215974} | train loss {'Reaction outcome loss': 0.3301224240736253, 'Total loss': 0.3301224240736253}
2023-01-03 23:18:00,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:00,692 INFO:     Epoch: 21
2023-01-03 23:18:02,315 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3954627772172292, 'Total loss': 0.3954627772172292} | train loss {'Reaction outcome loss': 0.33374503850127046, 'Total loss': 0.33374503850127046}
2023-01-03 23:18:02,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:02,315 INFO:     Epoch: 22
2023-01-03 23:18:03,927 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41448631485303244, 'Total loss': 0.41448631485303244} | train loss {'Reaction outcome loss': 0.31466041525878163, 'Total loss': 0.31466041525878163}
2023-01-03 23:18:03,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:03,928 INFO:     Epoch: 23
2023-01-03 23:18:05,523 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41665995319684346, 'Total loss': 0.41665995319684346} | train loss {'Reaction outcome loss': 0.3051264552331818, 'Total loss': 0.3051264552331818}
2023-01-03 23:18:05,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:05,523 INFO:     Epoch: 24
2023-01-03 23:18:07,141 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.389720626672109, 'Total loss': 0.389720626672109} | train loss {'Reaction outcome loss': 0.2993240563831903, 'Total loss': 0.2993240563831903}
2023-01-03 23:18:07,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:07,141 INFO:     Epoch: 25
2023-01-03 23:18:08,758 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.38925381054480873, 'Total loss': 0.38925381054480873} | train loss {'Reaction outcome loss': 0.2972628375217133, 'Total loss': 0.2972628375217133}
2023-01-03 23:18:08,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:08,759 INFO:     Epoch: 26
2023-01-03 23:18:10,341 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3719044556220373, 'Total loss': 0.3719044556220373} | train loss {'Reaction outcome loss': 0.29175734189271496, 'Total loss': 0.29175734189271496}
2023-01-03 23:18:10,342 INFO:     Found new best model at epoch 26
2023-01-03 23:18:10,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:10,343 INFO:     Epoch: 27
2023-01-03 23:18:11,926 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4020038038492203, 'Total loss': 0.4020038038492203} | train loss {'Reaction outcome loss': 0.28808887682996853, 'Total loss': 0.28808887682996853}
2023-01-03 23:18:11,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:11,926 INFO:     Epoch: 28
2023-01-03 23:18:13,547 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39403398931026457, 'Total loss': 0.39403398931026457} | train loss {'Reaction outcome loss': 0.28175094043178, 'Total loss': 0.28175094043178}
2023-01-03 23:18:13,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:13,547 INFO:     Epoch: 29
2023-01-03 23:18:15,129 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3783010428150495, 'Total loss': 0.3783010428150495} | train loss {'Reaction outcome loss': 0.2795278455596417, 'Total loss': 0.2795278455596417}
2023-01-03 23:18:15,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:15,130 INFO:     Epoch: 30
2023-01-03 23:18:16,724 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4185557981332143, 'Total loss': 0.4185557981332143} | train loss {'Reaction outcome loss': 0.2783417046016109, 'Total loss': 0.2783417046016109}
2023-01-03 23:18:16,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:16,725 INFO:     Epoch: 31
2023-01-03 23:18:18,304 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4004006346066793, 'Total loss': 0.4004006346066793} | train loss {'Reaction outcome loss': 0.281984033957786, 'Total loss': 0.281984033957786}
2023-01-03 23:18:18,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:18,304 INFO:     Epoch: 32
2023-01-03 23:18:19,929 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3899036089579264, 'Total loss': 0.3899036089579264} | train loss {'Reaction outcome loss': 0.2700320523429621, 'Total loss': 0.2700320523429621}
2023-01-03 23:18:19,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:19,930 INFO:     Epoch: 33
2023-01-03 23:18:21,554 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.397839418053627, 'Total loss': 0.397839418053627} | train loss {'Reaction outcome loss': 0.26673745520520903, 'Total loss': 0.26673745520520903}
2023-01-03 23:18:21,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:21,554 INFO:     Epoch: 34
2023-01-03 23:18:23,158 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40688641170660655, 'Total loss': 0.40688641170660655} | train loss {'Reaction outcome loss': 0.26080752933478873, 'Total loss': 0.26080752933478873}
2023-01-03 23:18:23,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:23,158 INFO:     Epoch: 35
2023-01-03 23:18:24,785 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3746347874403, 'Total loss': 0.3746347874403} | train loss {'Reaction outcome loss': 0.26098884636050335, 'Total loss': 0.26098884636050335}
2023-01-03 23:18:24,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:24,785 INFO:     Epoch: 36
2023-01-03 23:18:26,389 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3971614350875219, 'Total loss': 0.3971614350875219} | train loss {'Reaction outcome loss': 0.2599147681646265, 'Total loss': 0.2599147681646265}
2023-01-03 23:18:26,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:26,389 INFO:     Epoch: 37
2023-01-03 23:18:27,981 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38685459494590757, 'Total loss': 0.38685459494590757} | train loss {'Reaction outcome loss': 0.25250964627122047, 'Total loss': 0.25250964627122047}
2023-01-03 23:18:27,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:27,982 INFO:     Epoch: 38
2023-01-03 23:18:29,592 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3758504291375478, 'Total loss': 0.3758504291375478} | train loss {'Reaction outcome loss': 0.251961829609818, 'Total loss': 0.251961829609818}
2023-01-03 23:18:29,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:29,592 INFO:     Epoch: 39
2023-01-03 23:18:31,206 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3669504423936208, 'Total loss': 0.3669504423936208} | train loss {'Reaction outcome loss': 0.24942019081827047, 'Total loss': 0.24942019081827047}
2023-01-03 23:18:31,206 INFO:     Found new best model at epoch 39
2023-01-03 23:18:31,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:31,207 INFO:     Epoch: 40
2023-01-03 23:18:32,785 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39347340414921445, 'Total loss': 0.39347340414921445} | train loss {'Reaction outcome loss': 0.25328979944891256, 'Total loss': 0.25328979944891256}
2023-01-03 23:18:32,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:32,785 INFO:     Epoch: 41
2023-01-03 23:18:34,404 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38089847018321354, 'Total loss': 0.38089847018321354} | train loss {'Reaction outcome loss': 0.24700040491702763, 'Total loss': 0.24700040491702763}
2023-01-03 23:18:34,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:34,405 INFO:     Epoch: 42
2023-01-03 23:18:35,991 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3881468802690506, 'Total loss': 0.3881468802690506} | train loss {'Reaction outcome loss': 0.2575516277735216, 'Total loss': 0.2575516277735216}
2023-01-03 23:18:35,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:35,992 INFO:     Epoch: 43
2023-01-03 23:18:37,574 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3982440901299318, 'Total loss': 0.3982440901299318} | train loss {'Reaction outcome loss': 0.24879441477115388, 'Total loss': 0.24879441477115388}
2023-01-03 23:18:37,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:37,575 INFO:     Epoch: 44
2023-01-03 23:18:39,167 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3831380342443784, 'Total loss': 0.3831380342443784} | train loss {'Reaction outcome loss': 0.23634304036048875, 'Total loss': 0.23634304036048875}
2023-01-03 23:18:39,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:39,168 INFO:     Epoch: 45
2023-01-03 23:18:40,776 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39344618072112403, 'Total loss': 0.39344618072112403} | train loss {'Reaction outcome loss': 0.2335941068612147, 'Total loss': 0.2335941068612147}
2023-01-03 23:18:40,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:40,776 INFO:     Epoch: 46
2023-01-03 23:18:42,383 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38295045296351116, 'Total loss': 0.38295045296351116} | train loss {'Reaction outcome loss': 0.23333779351272876, 'Total loss': 0.23333779351272876}
2023-01-03 23:18:42,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:42,383 INFO:     Epoch: 47
2023-01-03 23:18:44,012 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3865973581870397, 'Total loss': 0.3865973581870397} | train loss {'Reaction outcome loss': 0.23350244836098905, 'Total loss': 0.23350244836098905}
2023-01-03 23:18:44,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:44,013 INFO:     Epoch: 48
2023-01-03 23:18:45,594 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.389389723042647, 'Total loss': 0.389389723042647} | train loss {'Reaction outcome loss': 0.22622818283675966, 'Total loss': 0.22622818283675966}
2023-01-03 23:18:45,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:45,596 INFO:     Epoch: 49
2023-01-03 23:18:47,221 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38057697713375094, 'Total loss': 0.38057697713375094} | train loss {'Reaction outcome loss': 0.22540555029189674, 'Total loss': 0.22540555029189674}
2023-01-03 23:18:47,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:47,222 INFO:     Epoch: 50
2023-01-03 23:18:48,816 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3612260123093923, 'Total loss': 0.3612260123093923} | train loss {'Reaction outcome loss': 0.2235165972315767, 'Total loss': 0.2235165972315767}
2023-01-03 23:18:48,816 INFO:     Found new best model at epoch 50
2023-01-03 23:18:48,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:48,817 INFO:     Epoch: 51
2023-01-03 23:18:50,409 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.38935399254163106, 'Total loss': 0.38935399254163106} | train loss {'Reaction outcome loss': 0.2240078077800032, 'Total loss': 0.2240078077800032}
2023-01-03 23:18:50,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:50,410 INFO:     Epoch: 52
2023-01-03 23:18:52,029 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3720382183790207, 'Total loss': 0.3720382183790207} | train loss {'Reaction outcome loss': 0.22161441579004715, 'Total loss': 0.22161441579004715}
2023-01-03 23:18:52,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:52,030 INFO:     Epoch: 53
2023-01-03 23:18:53,631 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38949074943860373, 'Total loss': 0.38949074943860373} | train loss {'Reaction outcome loss': 0.21655246189565977, 'Total loss': 0.21655246189565977}
2023-01-03 23:18:53,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:53,631 INFO:     Epoch: 54
2023-01-03 23:18:55,221 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3822090536355972, 'Total loss': 0.3822090536355972} | train loss {'Reaction outcome loss': 0.2169766082306919, 'Total loss': 0.2169766082306919}
2023-01-03 23:18:55,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:55,221 INFO:     Epoch: 55
2023-01-03 23:18:56,802 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3855147590239843, 'Total loss': 0.3855147590239843} | train loss {'Reaction outcome loss': 0.21559786047462537, 'Total loss': 0.21559786047462537}
2023-01-03 23:18:56,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:56,802 INFO:     Epoch: 56
2023-01-03 23:18:58,396 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4113130509853363, 'Total loss': 0.4113130509853363} | train loss {'Reaction outcome loss': 0.21016359077243513, 'Total loss': 0.21016359077243513}
2023-01-03 23:18:58,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:58,396 INFO:     Epoch: 57
2023-01-03 23:18:59,994 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40315364201863607, 'Total loss': 0.40315364201863607} | train loss {'Reaction outcome loss': 0.2116927643293056, 'Total loss': 0.2116927643293056}
2023-01-03 23:18:59,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:18:59,994 INFO:     Epoch: 58
2023-01-03 23:19:01,615 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39198373357454935, 'Total loss': 0.39198373357454935} | train loss {'Reaction outcome loss': 0.20929076063127824, 'Total loss': 0.20929076063127824}
2023-01-03 23:19:01,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:01,615 INFO:     Epoch: 59
2023-01-03 23:19:03,196 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3972095842162768, 'Total loss': 0.3972095842162768} | train loss {'Reaction outcome loss': 0.20823407405818664, 'Total loss': 0.20823407405818664}
2023-01-03 23:19:03,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:03,196 INFO:     Epoch: 60
2023-01-03 23:19:04,788 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4197019378344218, 'Total loss': 0.4197019378344218} | train loss {'Reaction outcome loss': 0.20450278682501052, 'Total loss': 0.20450278682501052}
2023-01-03 23:19:04,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:04,789 INFO:     Epoch: 61
2023-01-03 23:19:06,383 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3975011284152667, 'Total loss': 0.3975011284152667} | train loss {'Reaction outcome loss': 0.22051427377711819, 'Total loss': 0.22051427377711819}
2023-01-03 23:19:06,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:06,383 INFO:     Epoch: 62
2023-01-03 23:19:07,962 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40970269044240315, 'Total loss': 0.40970269044240315} | train loss {'Reaction outcome loss': 0.2430986256584984, 'Total loss': 0.2430986256584984}
2023-01-03 23:19:07,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:07,962 INFO:     Epoch: 63
2023-01-03 23:19:09,583 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44199234545230864, 'Total loss': 0.44199234545230864} | train loss {'Reaction outcome loss': 0.21003668030480976, 'Total loss': 0.21003668030480976}
2023-01-03 23:19:09,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:09,583 INFO:     Epoch: 64
2023-01-03 23:19:11,175 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.429540475209554, 'Total loss': 0.429540475209554} | train loss {'Reaction outcome loss': 0.2156096295794418, 'Total loss': 0.2156096295794418}
2023-01-03 23:19:11,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:11,175 INFO:     Epoch: 65
2023-01-03 23:19:12,768 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42327464719613395, 'Total loss': 0.42327464719613395} | train loss {'Reaction outcome loss': 0.20356019593157765, 'Total loss': 0.20356019593157765}
2023-01-03 23:19:12,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:12,769 INFO:     Epoch: 66
2023-01-03 23:19:14,391 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4188085695107778, 'Total loss': 0.4188085695107778} | train loss {'Reaction outcome loss': 0.20017026694938686, 'Total loss': 0.20017026694938686}
2023-01-03 23:19:14,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:14,391 INFO:     Epoch: 67
2023-01-03 23:19:15,985 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4227043608824412, 'Total loss': 0.4227043608824412} | train loss {'Reaction outcome loss': 0.19761152512196728, 'Total loss': 0.19761152512196728}
2023-01-03 23:19:15,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:15,985 INFO:     Epoch: 68
2023-01-03 23:19:17,561 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4172123814622561, 'Total loss': 0.4172123814622561} | train loss {'Reaction outcome loss': 0.19871331768400932, 'Total loss': 0.19871331768400932}
2023-01-03 23:19:17,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:17,561 INFO:     Epoch: 69
2023-01-03 23:19:19,179 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.433186133702596, 'Total loss': 0.433186133702596} | train loss {'Reaction outcome loss': 0.19475897563540417, 'Total loss': 0.19475897563540417}
2023-01-03 23:19:19,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:19,180 INFO:     Epoch: 70
2023-01-03 23:19:20,784 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4248234987258911, 'Total loss': 0.4248234987258911} | train loss {'Reaction outcome loss': 0.19595391528707914, 'Total loss': 0.19595391528707914}
2023-01-03 23:19:20,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:20,785 INFO:     Epoch: 71
2023-01-03 23:19:22,357 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40806707441806794, 'Total loss': 0.40806707441806794} | train loss {'Reaction outcome loss': 0.19529621967155, 'Total loss': 0.19529621967155}
2023-01-03 23:19:22,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:22,358 INFO:     Epoch: 72
2023-01-03 23:19:23,955 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41045701603094736, 'Total loss': 0.41045701603094736} | train loss {'Reaction outcome loss': 0.1947330127645662, 'Total loss': 0.1947330127645662}
2023-01-03 23:19:23,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:23,956 INFO:     Epoch: 73
2023-01-03 23:19:25,582 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3780776356657346, 'Total loss': 0.3780776356657346} | train loss {'Reaction outcome loss': 0.20694624394219727, 'Total loss': 0.20694624394219727}
2023-01-03 23:19:25,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:25,582 INFO:     Epoch: 74
2023-01-03 23:19:27,164 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3877859726548195, 'Total loss': 0.3877859726548195} | train loss {'Reaction outcome loss': 0.19203691475938642, 'Total loss': 0.19203691475938642}
2023-01-03 23:19:27,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:27,164 INFO:     Epoch: 75
2023-01-03 23:19:28,766 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4033371597528458, 'Total loss': 0.4033371597528458} | train loss {'Reaction outcome loss': 0.18860494432353164, 'Total loss': 0.18860494432353164}
2023-01-03 23:19:28,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:28,766 INFO:     Epoch: 76
2023-01-03 23:19:30,334 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4064047579964002, 'Total loss': 0.4064047579964002} | train loss {'Reaction outcome loss': 0.18816877604610677, 'Total loss': 0.18816877604610677}
2023-01-03 23:19:30,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:30,334 INFO:     Epoch: 77
2023-01-03 23:19:31,928 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41313638985157014, 'Total loss': 0.41313638985157014} | train loss {'Reaction outcome loss': 0.18834694561319074, 'Total loss': 0.18834694561319074}
2023-01-03 23:19:31,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:31,928 INFO:     Epoch: 78
2023-01-03 23:19:33,516 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41246434847513835, 'Total loss': 0.41246434847513835} | train loss {'Reaction outcome loss': 0.18552842547332926, 'Total loss': 0.18552842547332926}
2023-01-03 23:19:33,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:33,516 INFO:     Epoch: 79
2023-01-03 23:19:34,956 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4498881071805954, 'Total loss': 0.4498881071805954} | train loss {'Reaction outcome loss': 0.18599651753037758, 'Total loss': 0.18599651753037758}
2023-01-03 23:19:34,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:34,956 INFO:     Epoch: 80
2023-01-03 23:19:36,009 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3976468026638031, 'Total loss': 0.3976468026638031} | train loss {'Reaction outcome loss': 0.1852661631124067, 'Total loss': 0.1852661631124067}
2023-01-03 23:19:36,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:36,009 INFO:     Epoch: 81
2023-01-03 23:19:37,058 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39047774312396843, 'Total loss': 0.39047774312396843} | train loss {'Reaction outcome loss': 0.18225348317966986, 'Total loss': 0.18225348317966986}
2023-01-03 23:19:37,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:37,058 INFO:     Epoch: 82
2023-01-03 23:19:38,118 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41268183787663776, 'Total loss': 0.41268183787663776} | train loss {'Reaction outcome loss': 0.1823790863487849, 'Total loss': 0.1823790863487849}
2023-01-03 23:19:38,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:38,119 INFO:     Epoch: 83
2023-01-03 23:19:39,186 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4062200039625168, 'Total loss': 0.4062200039625168} | train loss {'Reaction outcome loss': 0.18016580646147212, 'Total loss': 0.18016580646147212}
2023-01-03 23:19:39,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:39,187 INFO:     Epoch: 84
2023-01-03 23:19:40,770 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.39273637533187866, 'Total loss': 0.39273637533187866} | train loss {'Reaction outcome loss': 0.18589028049314368, 'Total loss': 0.18589028049314368}
2023-01-03 23:19:40,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:40,771 INFO:     Epoch: 85
2023-01-03 23:19:42,363 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43629148105780285, 'Total loss': 0.43629148105780285} | train loss {'Reaction outcome loss': 0.19281074824127997, 'Total loss': 0.19281074824127997}
2023-01-03 23:19:42,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:42,363 INFO:     Epoch: 86
2023-01-03 23:19:43,954 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41768086949984234, 'Total loss': 0.41768086949984234} | train loss {'Reaction outcome loss': 0.17885979144931838, 'Total loss': 0.17885979144931838}
2023-01-03 23:19:43,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:43,955 INFO:     Epoch: 87
2023-01-03 23:19:45,536 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4114730879664421, 'Total loss': 0.4114730879664421} | train loss {'Reaction outcome loss': 0.17966652983306922, 'Total loss': 0.17966652983306922}
2023-01-03 23:19:45,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:45,536 INFO:     Epoch: 88
2023-01-03 23:19:47,133 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40864816506703694, 'Total loss': 0.40864816506703694} | train loss {'Reaction outcome loss': 0.17840165070990316, 'Total loss': 0.17840165070990316}
2023-01-03 23:19:47,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:47,133 INFO:     Epoch: 89
2023-01-03 23:19:48,707 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40975138247013093, 'Total loss': 0.40975138247013093} | train loss {'Reaction outcome loss': 0.17807037686952096, 'Total loss': 0.17807037686952096}
2023-01-03 23:19:48,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:48,707 INFO:     Epoch: 90
2023-01-03 23:19:50,301 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41825500279664996, 'Total loss': 0.41825500279664996} | train loss {'Reaction outcome loss': 0.17531099878846465, 'Total loss': 0.17531099878846465}
2023-01-03 23:19:50,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:50,302 INFO:     Epoch: 91
2023-01-03 23:19:51,893 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44521081149578096, 'Total loss': 0.44521081149578096} | train loss {'Reaction outcome loss': 0.17493413902306254, 'Total loss': 0.17493413902306254}
2023-01-03 23:19:51,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:51,895 INFO:     Epoch: 92
2023-01-03 23:19:53,487 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42318527201811473, 'Total loss': 0.42318527201811473} | train loss {'Reaction outcome loss': 0.1808091563736156, 'Total loss': 0.1808091563736156}
2023-01-03 23:19:53,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:53,487 INFO:     Epoch: 93
2023-01-03 23:19:55,065 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4278351187705994, 'Total loss': 0.4278351187705994} | train loss {'Reaction outcome loss': 0.17351409367731083, 'Total loss': 0.17351409367731083}
2023-01-03 23:19:55,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:55,065 INFO:     Epoch: 94
2023-01-03 23:19:56,660 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42008884449799855, 'Total loss': 0.42008884449799855} | train loss {'Reaction outcome loss': 0.17621234576508077, 'Total loss': 0.17621234576508077}
2023-01-03 23:19:56,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:56,661 INFO:     Epoch: 95
2023-01-03 23:19:58,232 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4474206765492757, 'Total loss': 0.4474206765492757} | train loss {'Reaction outcome loss': 0.17175003367499786, 'Total loss': 0.17175003367499786}
2023-01-03 23:19:58,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:58,233 INFO:     Epoch: 96
2023-01-03 23:19:59,819 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42915612359841665, 'Total loss': 0.42915612359841665} | train loss {'Reaction outcome loss': 0.1740958673114316, 'Total loss': 0.1740958673114316}
2023-01-03 23:19:59,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:19:59,819 INFO:     Epoch: 97
2023-01-03 23:20:01,439 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4470213532447815, 'Total loss': 0.4470213532447815} | train loss {'Reaction outcome loss': 0.17399998423575924, 'Total loss': 0.17399998423575924}
2023-01-03 23:20:01,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:01,440 INFO:     Epoch: 98
2023-01-03 23:20:03,063 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44428448577721913, 'Total loss': 0.44428448577721913} | train loss {'Reaction outcome loss': 0.18701857783805503, 'Total loss': 0.18701857783805503}
2023-01-03 23:20:03,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:03,063 INFO:     Epoch: 99
2023-01-03 23:20:04,663 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41985947688420616, 'Total loss': 0.41985947688420616} | train loss {'Reaction outcome loss': 0.1752283774599757, 'Total loss': 0.1752283774599757}
2023-01-03 23:20:04,663 INFO:     Best model found after epoch 51 of 100.
2023-01-03 23:20:04,663 INFO:   Done with stage: TRAINING
2023-01-03 23:20:04,663 INFO:   Starting stage: EVALUATION
2023-01-03 23:20:04,794 INFO:   Done with stage: EVALUATION
2023-01-03 23:20:04,794 INFO:   Leaving out SEQ value Fold_9
2023-01-03 23:20:04,807 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-03 23:20:04,807 INFO:   Starting stage: FEATURE SCALING
2023-01-03 23:20:05,457 INFO:   Done with stage: FEATURE SCALING
2023-01-03 23:20:05,457 INFO:   Starting stage: SCALING TARGETS
2023-01-03 23:20:05,526 INFO:   Done with stage: SCALING TARGETS
2023-01-03 23:20:05,527 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:20:05,527 INFO:     No hyperparam tuning for this model
2023-01-03 23:20:05,527 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:20:05,527 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 23:20:05,528 INFO:     None feature selector for col prot
2023-01-03 23:20:05,528 INFO:     None feature selector for col prot
2023-01-03 23:20:05,528 INFO:     None feature selector for col prot
2023-01-03 23:20:05,528 INFO:     None feature selector for col chem
2023-01-03 23:20:05,529 INFO:     None feature selector for col chem
2023-01-03 23:20:05,529 INFO:     None feature selector for col chem
2023-01-03 23:20:05,529 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 23:20:05,529 INFO:   Starting stage: BUILD MODEL
2023-01-03 23:20:05,530 INFO:     Number of params in model 70141
2023-01-03 23:20:05,533 INFO:   Done with stage: BUILD MODEL
2023-01-03 23:20:05,533 INFO:   Starting stage: TRAINING
2023-01-03 23:20:05,575 INFO:     Val loss before train {'Reaction outcome loss': 1.0552469690640767, 'Total loss': 1.0552469690640767}
2023-01-03 23:20:05,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:05,576 INFO:     Epoch: 0
2023-01-03 23:20:07,185 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7218005816141765, 'Total loss': 0.7218005816141765} | train loss {'Reaction outcome loss': 0.8671826989646407, 'Total loss': 0.8671826989646407}
2023-01-03 23:20:07,186 INFO:     Found new best model at epoch 0
2023-01-03 23:20:07,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:07,186 INFO:     Epoch: 1
2023-01-03 23:20:08,804 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5926555236180623, 'Total loss': 0.5926555236180623} | train loss {'Reaction outcome loss': 0.6170233672579554, 'Total loss': 0.6170233672579554}
2023-01-03 23:20:08,805 INFO:     Found new best model at epoch 1
2023-01-03 23:20:08,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:08,806 INFO:     Epoch: 2
2023-01-03 23:20:10,390 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5504168430964153, 'Total loss': 0.5504168430964153} | train loss {'Reaction outcome loss': 0.5392987241131671, 'Total loss': 0.5392987241131671}
2023-01-03 23:20:10,391 INFO:     Found new best model at epoch 2
2023-01-03 23:20:10,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:10,392 INFO:     Epoch: 3
2023-01-03 23:20:11,990 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5169962207476299, 'Total loss': 0.5169962207476299} | train loss {'Reaction outcome loss': 0.4996120647351811, 'Total loss': 0.4996120647351811}
2023-01-03 23:20:11,991 INFO:     Found new best model at epoch 3
2023-01-03 23:20:11,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:11,991 INFO:     Epoch: 4
2023-01-03 23:20:13,613 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5169907132784526, 'Total loss': 0.5169907132784526} | train loss {'Reaction outcome loss': 0.47347532483695104, 'Total loss': 0.47347532483695104}
2023-01-03 23:20:13,613 INFO:     Found new best model at epoch 4
2023-01-03 23:20:13,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:13,614 INFO:     Epoch: 5
2023-01-03 23:20:15,189 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5029083967208863, 'Total loss': 0.5029083967208863} | train loss {'Reaction outcome loss': 0.47760119969430176, 'Total loss': 0.47760119969430176}
2023-01-03 23:20:15,189 INFO:     Found new best model at epoch 5
2023-01-03 23:20:15,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:15,190 INFO:     Epoch: 6
2023-01-03 23:20:16,826 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49415543079376223, 'Total loss': 0.49415543079376223} | train loss {'Reaction outcome loss': 0.4429515084062797, 'Total loss': 0.4429515084062797}
2023-01-03 23:20:16,826 INFO:     Found new best model at epoch 6
2023-01-03 23:20:16,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:16,827 INFO:     Epoch: 7
2023-01-03 23:20:18,464 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48718096216519674, 'Total loss': 0.48718096216519674} | train loss {'Reaction outcome loss': 0.4227718997759782, 'Total loss': 0.4227718997759782}
2023-01-03 23:20:18,464 INFO:     Found new best model at epoch 7
2023-01-03 23:20:18,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:18,465 INFO:     Epoch: 8
2023-01-03 23:20:20,103 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4766260266304016, 'Total loss': 0.4766260266304016} | train loss {'Reaction outcome loss': 0.41600551720762596, 'Total loss': 0.41600551720762596}
2023-01-03 23:20:20,103 INFO:     Found new best model at epoch 8
2023-01-03 23:20:20,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:20,104 INFO:     Epoch: 9
2023-01-03 23:20:21,713 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4823478937149048, 'Total loss': 0.4823478937149048} | train loss {'Reaction outcome loss': 0.4056393160059562, 'Total loss': 0.4056393160059562}
2023-01-03 23:20:21,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:21,714 INFO:     Epoch: 10
2023-01-03 23:20:23,357 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4838747342427572, 'Total loss': 0.4838747342427572} | train loss {'Reaction outcome loss': 0.393226428254359, 'Total loss': 0.393226428254359}
2023-01-03 23:20:23,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:23,359 INFO:     Epoch: 11
2023-01-03 23:20:24,991 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4561229002972444, 'Total loss': 0.4561229002972444} | train loss {'Reaction outcome loss': 0.40728750187849655, 'Total loss': 0.40728750187849655}
2023-01-03 23:20:24,991 INFO:     Found new best model at epoch 11
2023-01-03 23:20:24,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:24,992 INFO:     Epoch: 12
2023-01-03 23:20:26,636 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47122332056363425, 'Total loss': 0.47122332056363425} | train loss {'Reaction outcome loss': 0.38422465103044023, 'Total loss': 0.38422465103044023}
2023-01-03 23:20:26,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:26,636 INFO:     Epoch: 13
2023-01-03 23:20:28,273 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4710718870162964, 'Total loss': 0.4710718870162964} | train loss {'Reaction outcome loss': 0.37869750049667084, 'Total loss': 0.37869750049667084}
2023-01-03 23:20:28,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:28,273 INFO:     Epoch: 14
2023-01-03 23:20:29,899 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45509675741195676, 'Total loss': 0.45509675741195676} | train loss {'Reaction outcome loss': 0.3702950055670479, 'Total loss': 0.3702950055670479}
2023-01-03 23:20:29,900 INFO:     Found new best model at epoch 14
2023-01-03 23:20:29,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:29,900 INFO:     Epoch: 15
2023-01-03 23:20:31,501 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4628006637096405, 'Total loss': 0.4628006637096405} | train loss {'Reaction outcome loss': 0.3594543904713962, 'Total loss': 0.3594543904713962}
2023-01-03 23:20:31,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:31,501 INFO:     Epoch: 16
2023-01-03 23:20:33,067 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4604118406772614, 'Total loss': 0.4604118406772614} | train loss {'Reaction outcome loss': 0.3523385390838392, 'Total loss': 0.3523385390838392}
2023-01-03 23:20:33,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:33,067 INFO:     Epoch: 17
2023-01-03 23:20:34,701 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4641117572784424, 'Total loss': 0.4641117572784424} | train loss {'Reaction outcome loss': 0.344923570630667, 'Total loss': 0.344923570630667}
2023-01-03 23:20:34,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:34,702 INFO:     Epoch: 18
2023-01-03 23:20:36,340 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4512378553549449, 'Total loss': 0.4512378553549449} | train loss {'Reaction outcome loss': 0.3403303199641717, 'Total loss': 0.3403303199641717}
2023-01-03 23:20:36,340 INFO:     Found new best model at epoch 18
2023-01-03 23:20:36,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:36,341 INFO:     Epoch: 19
2023-01-03 23:20:37,974 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4569785128037135, 'Total loss': 0.4569785128037135} | train loss {'Reaction outcome loss': 0.3364267102105246, 'Total loss': 0.3364267102105246}
2023-01-03 23:20:37,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:37,974 INFO:     Epoch: 20
2023-01-03 23:20:39,582 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4556760281324387, 'Total loss': 0.4556760281324387} | train loss {'Reaction outcome loss': 0.33047630451619625, 'Total loss': 0.33047630451619625}
2023-01-03 23:20:39,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:39,583 INFO:     Epoch: 21
2023-01-03 23:20:41,183 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45234805544217427, 'Total loss': 0.45234805544217427} | train loss {'Reaction outcome loss': 0.326281862596195, 'Total loss': 0.326281862596195}
2023-01-03 23:20:41,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:41,184 INFO:     Epoch: 22
2023-01-03 23:20:42,755 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4501363048950831, 'Total loss': 0.4501363048950831} | train loss {'Reaction outcome loss': 0.32120860325159045, 'Total loss': 0.32120860325159045}
2023-01-03 23:20:42,756 INFO:     Found new best model at epoch 22
2023-01-03 23:20:42,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:42,757 INFO:     Epoch: 23
2023-01-03 23:20:44,367 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4513785680135091, 'Total loss': 0.4513785680135091} | train loss {'Reaction outcome loss': 0.31786819055997656, 'Total loss': 0.31786819055997656}
2023-01-03 23:20:44,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:44,367 INFO:     Epoch: 24
2023-01-03 23:20:45,988 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43777640064557394, 'Total loss': 0.43777640064557394} | train loss {'Reaction outcome loss': 0.3118669247875611, 'Total loss': 0.3118669247875611}
2023-01-03 23:20:45,988 INFO:     Found new best model at epoch 24
2023-01-03 23:20:45,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:45,989 INFO:     Epoch: 25
2023-01-03 23:20:47,610 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4454393744468689, 'Total loss': 0.4454393744468689} | train loss {'Reaction outcome loss': 0.31374073835395, 'Total loss': 0.31374073835395}
2023-01-03 23:20:47,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:47,610 INFO:     Epoch: 26
2023-01-03 23:20:49,207 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44686567783355713, 'Total loss': 0.44686567783355713} | train loss {'Reaction outcome loss': 0.30582910498091276, 'Total loss': 0.30582910498091276}
2023-01-03 23:20:49,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:49,208 INFO:     Epoch: 27
2023-01-03 23:20:50,828 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4638887623945872, 'Total loss': 0.4638887623945872} | train loss {'Reaction outcome loss': 0.30286600162693555, 'Total loss': 0.30286600162693555}
2023-01-03 23:20:50,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:50,829 INFO:     Epoch: 28
2023-01-03 23:20:52,416 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43012794852256775, 'Total loss': 0.43012794852256775} | train loss {'Reaction outcome loss': 0.29683888611886516, 'Total loss': 0.29683888611886516}
2023-01-03 23:20:52,416 INFO:     Found new best model at epoch 28
2023-01-03 23:20:52,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:52,417 INFO:     Epoch: 29
2023-01-03 23:20:54,018 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4426641255617142, 'Total loss': 0.4426641255617142} | train loss {'Reaction outcome loss': 0.291761235804702, 'Total loss': 0.291761235804702}
2023-01-03 23:20:54,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:54,019 INFO:     Epoch: 30
2023-01-03 23:20:55,619 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44074174960454304, 'Total loss': 0.44074174960454304} | train loss {'Reaction outcome loss': 0.28765884442322387, 'Total loss': 0.28765884442322387}
2023-01-03 23:20:55,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:55,620 INFO:     Epoch: 31
2023-01-03 23:20:57,215 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4483722428480784, 'Total loss': 0.4483722428480784} | train loss {'Reaction outcome loss': 0.2832504929299804, 'Total loss': 0.2832504929299804}
2023-01-03 23:20:57,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:57,216 INFO:     Epoch: 32
2023-01-03 23:20:58,823 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42878894954919816, 'Total loss': 0.42878894954919816} | train loss {'Reaction outcome loss': 0.28331386099529005, 'Total loss': 0.28331386099529005}
2023-01-03 23:20:58,824 INFO:     Found new best model at epoch 32
2023-01-03 23:20:58,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:20:58,825 INFO:     Epoch: 33
2023-01-03 23:21:00,395 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4306151320536931, 'Total loss': 0.4306151320536931} | train loss {'Reaction outcome loss': 0.2914678036856155, 'Total loss': 0.2914678036856155}
2023-01-03 23:21:00,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:00,395 INFO:     Epoch: 34
2023-01-03 23:21:01,999 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.451141756772995, 'Total loss': 0.451141756772995} | train loss {'Reaction outcome loss': 0.27386239809836127, 'Total loss': 0.27386239809836127}
2023-01-03 23:21:01,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:02,000 INFO:     Epoch: 35
2023-01-03 23:21:03,607 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44924855629603067, 'Total loss': 0.44924855629603067} | train loss {'Reaction outcome loss': 0.2713955453718486, 'Total loss': 0.2713955453718486}
2023-01-03 23:21:03,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:03,608 INFO:     Epoch: 36
2023-01-03 23:21:05,192 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4390270471572876, 'Total loss': 0.4390270471572876} | train loss {'Reaction outcome loss': 0.26598800708956516, 'Total loss': 0.26598800708956516}
2023-01-03 23:21:05,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:05,193 INFO:     Epoch: 37
2023-01-03 23:21:06,760 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45733273923397066, 'Total loss': 0.45733273923397066} | train loss {'Reaction outcome loss': 0.26810852308636124, 'Total loss': 0.26810852308636124}
2023-01-03 23:21:06,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:06,761 INFO:     Epoch: 38
2023-01-03 23:21:08,381 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43888349731763204, 'Total loss': 0.43888349731763204} | train loss {'Reaction outcome loss': 0.27119996547159075, 'Total loss': 0.27119996547159075}
2023-01-03 23:21:08,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:08,381 INFO:     Epoch: 39
2023-01-03 23:21:09,957 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4621018826961517, 'Total loss': 0.4621018826961517} | train loss {'Reaction outcome loss': 0.2611652448173592, 'Total loss': 0.2611652448173592}
2023-01-03 23:21:09,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:09,957 INFO:     Epoch: 40
2023-01-03 23:21:11,574 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4582848439613978, 'Total loss': 0.4582848439613978} | train loss {'Reaction outcome loss': 0.25735220277304016, 'Total loss': 0.25735220277304016}
2023-01-03 23:21:11,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:11,574 INFO:     Epoch: 41
2023-01-03 23:21:13,191 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4643568793932597, 'Total loss': 0.4643568793932597} | train loss {'Reaction outcome loss': 0.2533937246147273, 'Total loss': 0.2533937246147273}
2023-01-03 23:21:13,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:13,191 INFO:     Epoch: 42
2023-01-03 23:21:14,829 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45484738945961, 'Total loss': 0.45484738945961} | train loss {'Reaction outcome loss': 0.255514320836443, 'Total loss': 0.255514320836443}
2023-01-03 23:21:14,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:14,830 INFO:     Epoch: 43
2023-01-03 23:21:16,444 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4598034063975016, 'Total loss': 0.4598034063975016} | train loss {'Reaction outcome loss': 0.24980420934161227, 'Total loss': 0.24980420934161227}
2023-01-03 23:21:16,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:16,444 INFO:     Epoch: 44
2023-01-03 23:21:18,049 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4614665110905965, 'Total loss': 0.4614665110905965} | train loss {'Reaction outcome loss': 0.2459634339447012, 'Total loss': 0.2459634339447012}
2023-01-03 23:21:18,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:18,050 INFO:     Epoch: 45
2023-01-03 23:21:19,642 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44690893987814584, 'Total loss': 0.44690893987814584} | train loss {'Reaction outcome loss': 0.24256185629907862, 'Total loss': 0.24256185629907862}
2023-01-03 23:21:19,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:19,643 INFO:     Epoch: 46
2023-01-03 23:21:21,242 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47902743617693583, 'Total loss': 0.47902743617693583} | train loss {'Reaction outcome loss': 0.24276964427764947, 'Total loss': 0.24276964427764947}
2023-01-03 23:21:21,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:21,242 INFO:     Epoch: 47
2023-01-03 23:21:22,840 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44986201922098795, 'Total loss': 0.44986201922098795} | train loss {'Reaction outcome loss': 0.24223266741561625, 'Total loss': 0.24223266741561625}
2023-01-03 23:21:22,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:22,840 INFO:     Epoch: 48
2023-01-03 23:21:24,424 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46771509349346163, 'Total loss': 0.46771509349346163} | train loss {'Reaction outcome loss': 0.24263785566216794, 'Total loss': 0.24263785566216794}
2023-01-03 23:21:24,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:24,424 INFO:     Epoch: 49
2023-01-03 23:21:26,054 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45205928683280944, 'Total loss': 0.45205928683280944} | train loss {'Reaction outcome loss': 0.24673115586980873, 'Total loss': 0.24673115586980873}
2023-01-03 23:21:26,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:26,054 INFO:     Epoch: 50
2023-01-03 23:21:27,632 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46329992612202964, 'Total loss': 0.46329992612202964} | train loss {'Reaction outcome loss': 0.23353691968035148, 'Total loss': 0.23353691968035148}
2023-01-03 23:21:27,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:27,632 INFO:     Epoch: 51
2023-01-03 23:21:29,233 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4491973012685776, 'Total loss': 0.4491973012685776} | train loss {'Reaction outcome loss': 0.23533516379910102, 'Total loss': 0.23533516379910102}
2023-01-03 23:21:29,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:29,233 INFO:     Epoch: 52
2023-01-03 23:21:30,832 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45584477186203004, 'Total loss': 0.45584477186203004} | train loss {'Reaction outcome loss': 0.2398226003607978, 'Total loss': 0.2398226003607978}
2023-01-03 23:21:30,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:30,833 INFO:     Epoch: 53
2023-01-03 23:21:32,429 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47326966325441994, 'Total loss': 0.47326966325441994} | train loss {'Reaction outcome loss': 0.23549483382004732, 'Total loss': 0.23549483382004732}
2023-01-03 23:21:32,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:32,429 INFO:     Epoch: 54
2023-01-03 23:21:34,035 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4715685953696569, 'Total loss': 0.4715685953696569} | train loss {'Reaction outcome loss': 0.22786096600896638, 'Total loss': 0.22786096600896638}
2023-01-03 23:21:34,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:34,036 INFO:     Epoch: 55
2023-01-03 23:21:35,646 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46068619688351947, 'Total loss': 0.46068619688351947} | train loss {'Reaction outcome loss': 0.22445837985656725, 'Total loss': 0.22445837985656725}
2023-01-03 23:21:35,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:35,646 INFO:     Epoch: 56
2023-01-03 23:21:37,257 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44937210033337277, 'Total loss': 0.44937210033337277} | train loss {'Reaction outcome loss': 0.22330476498852173, 'Total loss': 0.22330476498852173}
2023-01-03 23:21:37,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:37,257 INFO:     Epoch: 57
2023-01-03 23:21:38,883 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44263686537742614, 'Total loss': 0.44263686537742614} | train loss {'Reaction outcome loss': 0.22323851601095815, 'Total loss': 0.22323851601095815}
2023-01-03 23:21:38,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:38,883 INFO:     Epoch: 58
2023-01-03 23:21:40,503 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4696580449740092, 'Total loss': 0.4696580449740092} | train loss {'Reaction outcome loss': 0.21871817952858796, 'Total loss': 0.21871817952858796}
2023-01-03 23:21:40,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:40,504 INFO:     Epoch: 59
2023-01-03 23:21:42,121 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4460693746805191, 'Total loss': 0.4460693746805191} | train loss {'Reaction outcome loss': 0.22657348009069328, 'Total loss': 0.22657348009069328}
2023-01-03 23:21:42,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:42,121 INFO:     Epoch: 60
2023-01-03 23:21:43,704 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4701813817024231, 'Total loss': 0.4701813817024231} | train loss {'Reaction outcome loss': 0.22619267409343435, 'Total loss': 0.22619267409343435}
2023-01-03 23:21:43,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:43,704 INFO:     Epoch: 61
2023-01-03 23:21:45,286 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46624013980229695, 'Total loss': 0.46624013980229695} | train loss {'Reaction outcome loss': 0.22618329396768325, 'Total loss': 0.22618329396768325}
2023-01-03 23:21:45,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:45,286 INFO:     Epoch: 62
2023-01-03 23:21:46,916 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4643216222524643, 'Total loss': 0.4643216222524643} | train loss {'Reaction outcome loss': 0.21772541803564283, 'Total loss': 0.21772541803564283}
2023-01-03 23:21:46,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:46,916 INFO:     Epoch: 63
2023-01-03 23:21:48,545 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.472814687093099, 'Total loss': 0.472814687093099} | train loss {'Reaction outcome loss': 0.21717417622794924, 'Total loss': 0.21717417622794924}
2023-01-03 23:21:48,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:48,545 INFO:     Epoch: 64
2023-01-03 23:21:50,182 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4815382699171702, 'Total loss': 0.4815382699171702} | train loss {'Reaction outcome loss': 0.21155159573295942, 'Total loss': 0.21155159573295942}
2023-01-03 23:21:50,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:50,182 INFO:     Epoch: 65
2023-01-03 23:21:51,791 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.49241913557052613, 'Total loss': 0.49241913557052613} | train loss {'Reaction outcome loss': 0.21065531723223208, 'Total loss': 0.21065531723223208}
2023-01-03 23:21:51,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:51,791 INFO:     Epoch: 66
2023-01-03 23:21:53,411 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4606650779644648, 'Total loss': 0.4606650779644648} | train loss {'Reaction outcome loss': 0.20890869227308861, 'Total loss': 0.20890869227308861}
2023-01-03 23:21:53,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:53,412 INFO:     Epoch: 67
2023-01-03 23:21:55,010 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4694768259922663, 'Total loss': 0.4694768259922663} | train loss {'Reaction outcome loss': 0.2063651448790578, 'Total loss': 0.2063651448790578}
2023-01-03 23:21:55,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:55,010 INFO:     Epoch: 68
2023-01-03 23:21:56,610 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4676548997561137, 'Total loss': 0.4676548997561137} | train loss {'Reaction outcome loss': 0.2085544604485841, 'Total loss': 0.2085544604485841}
2023-01-03 23:21:56,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:56,610 INFO:     Epoch: 69
2023-01-03 23:21:58,209 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4750132958094279, 'Total loss': 0.4750132958094279} | train loss {'Reaction outcome loss': 0.20600401495956222, 'Total loss': 0.20600401495956222}
2023-01-03 23:21:58,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:58,209 INFO:     Epoch: 70
2023-01-03 23:21:59,809 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47146371205647786, 'Total loss': 0.47146371205647786} | train loss {'Reaction outcome loss': 0.20134970858782544, 'Total loss': 0.20134970858782544}
2023-01-03 23:21:59,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:21:59,809 INFO:     Epoch: 71
2023-01-03 23:22:01,386 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.489003582795461, 'Total loss': 0.489003582795461} | train loss {'Reaction outcome loss': 0.20111845639296033, 'Total loss': 0.20111845639296033}
2023-01-03 23:22:01,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:01,387 INFO:     Epoch: 72
2023-01-03 23:22:02,981 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4650866041580836, 'Total loss': 0.4650866041580836} | train loss {'Reaction outcome loss': 0.19952546402519278, 'Total loss': 0.19952546402519278}
2023-01-03 23:22:02,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:02,982 INFO:     Epoch: 73
2023-01-03 23:22:04,553 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46368292570114134, 'Total loss': 0.46368292570114134} | train loss {'Reaction outcome loss': 0.19951173545284648, 'Total loss': 0.19951173545284648}
2023-01-03 23:22:04,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:04,555 INFO:     Epoch: 74
2023-01-03 23:22:06,138 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4725530723730723, 'Total loss': 0.4725530723730723} | train loss {'Reaction outcome loss': 0.1991384681470294, 'Total loss': 0.1991384681470294}
2023-01-03 23:22:06,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:06,138 INFO:     Epoch: 75
2023-01-03 23:22:07,757 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47919174035390216, 'Total loss': 0.47919174035390216} | train loss {'Reaction outcome loss': 0.19715068660857007, 'Total loss': 0.19715068660857007}
2023-01-03 23:22:07,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:07,758 INFO:     Epoch: 76
2023-01-03 23:22:09,368 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4772984246412913, 'Total loss': 0.4772984246412913} | train loss {'Reaction outcome loss': 0.1973024108244673, 'Total loss': 0.1973024108244673}
2023-01-03 23:22:09,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:09,368 INFO:     Epoch: 77
2023-01-03 23:22:10,984 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49839603702227275, 'Total loss': 0.49839603702227275} | train loss {'Reaction outcome loss': 0.200091107343526, 'Total loss': 0.200091107343526}
2023-01-03 23:22:10,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:10,985 INFO:     Epoch: 78
2023-01-03 23:22:12,579 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47698034048080445, 'Total loss': 0.47698034048080445} | train loss {'Reaction outcome loss': 0.2064668459892003, 'Total loss': 0.2064668459892003}
2023-01-03 23:22:12,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:12,580 INFO:     Epoch: 79
2023-01-03 23:22:14,207 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46577504674593606, 'Total loss': 0.46577504674593606} | train loss {'Reaction outcome loss': 0.19310412003867078, 'Total loss': 0.19310412003867078}
2023-01-03 23:22:14,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:14,207 INFO:     Epoch: 80
2023-01-03 23:22:15,835 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4873178442319234, 'Total loss': 0.4873178442319234} | train loss {'Reaction outcome loss': 0.1914115915468479, 'Total loss': 0.1914115915468479}
2023-01-03 23:22:15,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:15,835 INFO:     Epoch: 81
2023-01-03 23:22:17,473 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4679984529813131, 'Total loss': 0.4679984529813131} | train loss {'Reaction outcome loss': 0.1940812739981018, 'Total loss': 0.1940812739981018}
2023-01-03 23:22:17,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:17,473 INFO:     Epoch: 82
2023-01-03 23:22:19,053 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45606403549512226, 'Total loss': 0.45606403549512226} | train loss {'Reaction outcome loss': 0.19087428475166604, 'Total loss': 0.19087428475166604}
2023-01-03 23:22:19,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:19,054 INFO:     Epoch: 83
2023-01-03 23:22:20,671 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4763170848290125, 'Total loss': 0.4763170848290125} | train loss {'Reaction outcome loss': 0.18827948621145074, 'Total loss': 0.18827948621145074}
2023-01-03 23:22:20,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:20,671 INFO:     Epoch: 84
2023-01-03 23:22:22,256 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4756599724292755, 'Total loss': 0.4756599724292755} | train loss {'Reaction outcome loss': 0.18838283477953813, 'Total loss': 0.18838283477953813}
2023-01-03 23:22:22,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:22,256 INFO:     Epoch: 85
2023-01-03 23:22:23,860 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48366156220436096, 'Total loss': 0.48366156220436096} | train loss {'Reaction outcome loss': 0.18653078159938255, 'Total loss': 0.18653078159938255}
2023-01-03 23:22:23,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:23,861 INFO:     Epoch: 86
2023-01-03 23:22:25,461 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47700705329577126, 'Total loss': 0.47700705329577126} | train loss {'Reaction outcome loss': 0.1892411621425392, 'Total loss': 0.1892411621425392}
2023-01-03 23:22:25,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:25,461 INFO:     Epoch: 87
2023-01-03 23:22:27,115 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48644111851851146, 'Total loss': 0.48644111851851146} | train loss {'Reaction outcome loss': 0.18729555626758657, 'Total loss': 0.18729555626758657}
2023-01-03 23:22:27,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:27,115 INFO:     Epoch: 88
2023-01-03 23:22:28,743 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47782677014668784, 'Total loss': 0.47782677014668784} | train loss {'Reaction outcome loss': 0.18964847152971703, 'Total loss': 0.18964847152971703}
2023-01-03 23:22:28,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:28,743 INFO:     Epoch: 89
2023-01-03 23:22:30,385 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48503646651903787, 'Total loss': 0.48503646651903787} | train loss {'Reaction outcome loss': 0.192443326399476, 'Total loss': 0.192443326399476}
2023-01-03 23:22:30,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:30,385 INFO:     Epoch: 90
2023-01-03 23:22:32,042 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4876357158025106, 'Total loss': 0.4876357158025106} | train loss {'Reaction outcome loss': 0.1852862324255208, 'Total loss': 0.1852862324255208}
2023-01-03 23:22:32,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:32,043 INFO:     Epoch: 91
2023-01-03 23:22:33,624 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.486233659585317, 'Total loss': 0.486233659585317} | train loss {'Reaction outcome loss': 0.18088002640507655, 'Total loss': 0.18088002640507655}
2023-01-03 23:22:33,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:33,624 INFO:     Epoch: 92
2023-01-03 23:22:35,263 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49323085248470305, 'Total loss': 0.49323085248470305} | train loss {'Reaction outcome loss': 0.182131507031137, 'Total loss': 0.182131507031137}
2023-01-03 23:22:35,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:35,264 INFO:     Epoch: 93
2023-01-03 23:22:36,833 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5143934398889541, 'Total loss': 0.5143934398889541} | train loss {'Reaction outcome loss': 0.1877975916435969, 'Total loss': 0.1877975916435969}
2023-01-03 23:22:36,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:36,834 INFO:     Epoch: 94
2023-01-03 23:22:38,433 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48695340553919475, 'Total loss': 0.48695340553919475} | train loss {'Reaction outcome loss': 0.1945935507391553, 'Total loss': 0.1945935507391553}
2023-01-03 23:22:38,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:38,433 INFO:     Epoch: 95
2023-01-03 23:22:40,026 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4909778654575348, 'Total loss': 0.4909778654575348} | train loss {'Reaction outcome loss': 0.17986481131283918, 'Total loss': 0.17986481131283918}
2023-01-03 23:22:40,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:40,026 INFO:     Epoch: 96
2023-01-03 23:22:41,666 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48198318580786387, 'Total loss': 0.48198318580786387} | train loss {'Reaction outcome loss': 0.18812150757530352, 'Total loss': 0.18812150757530352}
2023-01-03 23:22:41,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:41,667 INFO:     Epoch: 97
2023-01-03 23:22:43,281 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48462365567684174, 'Total loss': 0.48462365567684174} | train loss {'Reaction outcome loss': 0.17761043133382834, 'Total loss': 0.17761043133382834}
2023-01-03 23:22:43,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:43,281 INFO:     Epoch: 98
2023-01-03 23:22:44,918 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4779725621143977, 'Total loss': 0.4779725621143977} | train loss {'Reaction outcome loss': 0.17705981491430514, 'Total loss': 0.17705981491430514}
2023-01-03 23:22:44,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:44,919 INFO:     Epoch: 99
2023-01-03 23:22:46,516 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48423242767651875, 'Total loss': 0.48423242767651875} | train loss {'Reaction outcome loss': 0.17995320375252893, 'Total loss': 0.17995320375252893}
2023-01-03 23:22:46,516 INFO:     Best model found after epoch 33 of 100.
2023-01-03 23:22:46,516 INFO:   Done with stage: TRAINING
2023-01-03 23:22:46,516 INFO:   Starting stage: EVALUATION
2023-01-03 23:22:46,646 INFO:   Done with stage: EVALUATION
2023-01-03 23:22:46,654 INFO:   Leaving out SEQ value Fold_0
2023-01-03 23:22:46,666 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-03 23:22:46,666 INFO:   Starting stage: FEATURE SCALING
2023-01-03 23:22:47,305 INFO:   Done with stage: FEATURE SCALING
2023-01-03 23:22:47,306 INFO:   Starting stage: SCALING TARGETS
2023-01-03 23:22:47,374 INFO:   Done with stage: SCALING TARGETS
2023-01-03 23:22:47,374 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:22:47,374 INFO:     No hyperparam tuning for this model
2023-01-03 23:22:47,374 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:22:47,374 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 23:22:47,375 INFO:     None feature selector for col prot
2023-01-03 23:22:47,375 INFO:     None feature selector for col prot
2023-01-03 23:22:47,375 INFO:     None feature selector for col prot
2023-01-03 23:22:47,376 INFO:     None feature selector for col chem
2023-01-03 23:22:47,376 INFO:     None feature selector for col chem
2023-01-03 23:22:47,376 INFO:     None feature selector for col chem
2023-01-03 23:22:47,376 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 23:22:47,376 INFO:   Starting stage: BUILD MODEL
2023-01-03 23:22:47,377 INFO:     Number of params in model 70141
2023-01-03 23:22:47,380 INFO:   Done with stage: BUILD MODEL
2023-01-03 23:22:47,380 INFO:   Starting stage: TRAINING
2023-01-03 23:22:47,424 INFO:     Val loss before train {'Reaction outcome loss': 0.9705983221530914, 'Total loss': 0.9705983221530914}
2023-01-03 23:22:47,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:47,424 INFO:     Epoch: 0
2023-01-03 23:22:48,972 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6596719165643056, 'Total loss': 0.6596719165643056} | train loss {'Reaction outcome loss': 0.8470390425836908, 'Total loss': 0.8470390425836908}
2023-01-03 23:22:48,972 INFO:     Found new best model at epoch 0
2023-01-03 23:22:48,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:48,973 INFO:     Epoch: 1
2023-01-03 23:22:50,554 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5581003407637278, 'Total loss': 0.5581003407637278} | train loss {'Reaction outcome loss': 0.6345873124265143, 'Total loss': 0.6345873124265143}
2023-01-03 23:22:50,554 INFO:     Found new best model at epoch 1
2023-01-03 23:22:50,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:50,555 INFO:     Epoch: 2
2023-01-03 23:22:52,124 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4925427238146464, 'Total loss': 0.4925427238146464} | train loss {'Reaction outcome loss': 0.536530758566962, 'Total loss': 0.536530758566962}
2023-01-03 23:22:52,124 INFO:     Found new best model at epoch 2
2023-01-03 23:22:52,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:52,125 INFO:     Epoch: 3
2023-01-03 23:22:53,718 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5188563793897629, 'Total loss': 0.5188563793897629} | train loss {'Reaction outcome loss': 0.4907233575393353, 'Total loss': 0.4907233575393353}
2023-01-03 23:22:53,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:53,719 INFO:     Epoch: 4
2023-01-03 23:22:55,270 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44804691871007285, 'Total loss': 0.44804691871007285} | train loss {'Reaction outcome loss': 0.45799151414874734, 'Total loss': 0.45799151414874734}
2023-01-03 23:22:55,270 INFO:     Found new best model at epoch 4
2023-01-03 23:22:55,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:55,271 INFO:     Epoch: 5
2023-01-03 23:22:56,829 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44916451573371885, 'Total loss': 0.44916451573371885} | train loss {'Reaction outcome loss': 0.4371222483605916, 'Total loss': 0.4371222483605916}
2023-01-03 23:22:56,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:56,829 INFO:     Epoch: 6
2023-01-03 23:22:58,392 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4432988852262497, 'Total loss': 0.4432988852262497} | train loss {'Reaction outcome loss': 0.4165514891217995, 'Total loss': 0.4165514891217995}
2023-01-03 23:22:58,392 INFO:     Found new best model at epoch 6
2023-01-03 23:22:58,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:58,393 INFO:     Epoch: 7
2023-01-03 23:22:59,986 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4356363594532013, 'Total loss': 0.4356363594532013} | train loss {'Reaction outcome loss': 0.4075581219143533, 'Total loss': 0.4075581219143533}
2023-01-03 23:22:59,986 INFO:     Found new best model at epoch 7
2023-01-03 23:22:59,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:22:59,987 INFO:     Epoch: 8
2023-01-03 23:23:01,569 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4858688662449519, 'Total loss': 0.4858688662449519} | train loss {'Reaction outcome loss': 0.3895654001469102, 'Total loss': 0.3895654001469102}
2023-01-03 23:23:01,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:01,569 INFO:     Epoch: 9
2023-01-03 23:23:03,159 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4290854831536611, 'Total loss': 0.4290854831536611} | train loss {'Reaction outcome loss': 0.37815242681336136, 'Total loss': 0.37815242681336136}
2023-01-03 23:23:03,159 INFO:     Found new best model at epoch 9
2023-01-03 23:23:03,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:03,160 INFO:     Epoch: 10
2023-01-03 23:23:04,715 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46267867684364317, 'Total loss': 0.46267867684364317} | train loss {'Reaction outcome loss': 0.3715539230411783, 'Total loss': 0.3715539230411783}
2023-01-03 23:23:04,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:04,715 INFO:     Epoch: 11
2023-01-03 23:23:06,268 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41945228626330694, 'Total loss': 0.41945228626330694} | train loss {'Reaction outcome loss': 0.36189038097528514, 'Total loss': 0.36189038097528514}
2023-01-03 23:23:06,269 INFO:     Found new best model at epoch 11
2023-01-03 23:23:06,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:06,270 INFO:     Epoch: 12
2023-01-03 23:23:07,837 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4253814925750097, 'Total loss': 0.4253814925750097} | train loss {'Reaction outcome loss': 0.3520693187893977, 'Total loss': 0.3520693187893977}
2023-01-03 23:23:07,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:07,837 INFO:     Epoch: 13
2023-01-03 23:23:09,406 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45207911829153696, 'Total loss': 0.45207911829153696} | train loss {'Reaction outcome loss': 0.34489349220841575, 'Total loss': 0.34489349220841575}
2023-01-03 23:23:09,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:09,406 INFO:     Epoch: 14
2023-01-03 23:23:10,976 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4161822646856308, 'Total loss': 0.4161822646856308} | train loss {'Reaction outcome loss': 0.33635013982158746, 'Total loss': 0.33635013982158746}
2023-01-03 23:23:10,976 INFO:     Found new best model at epoch 14
2023-01-03 23:23:10,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:10,977 INFO:     Epoch: 15
2023-01-03 23:23:12,524 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4209879070520401, 'Total loss': 0.4209879070520401} | train loss {'Reaction outcome loss': 0.32770385989073897, 'Total loss': 0.32770385989073897}
2023-01-03 23:23:12,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:12,525 INFO:     Epoch: 16
2023-01-03 23:23:14,096 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41304414452364047, 'Total loss': 0.41304414452364047} | train loss {'Reaction outcome loss': 0.3226447352843971, 'Total loss': 0.3226447352843971}
2023-01-03 23:23:14,096 INFO:     Found new best model at epoch 16
2023-01-03 23:23:14,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:14,097 INFO:     Epoch: 17
2023-01-03 23:23:15,661 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42709840536117555, 'Total loss': 0.42709840536117555} | train loss {'Reaction outcome loss': 0.3197373125111045, 'Total loss': 0.3197373125111045}
2023-01-03 23:23:15,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:15,662 INFO:     Epoch: 18
2023-01-03 23:23:17,254 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4202420860528946, 'Total loss': 0.4202420860528946} | train loss {'Reaction outcome loss': 0.31282438302062093, 'Total loss': 0.31282438302062093}
2023-01-03 23:23:17,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:17,254 INFO:     Epoch: 19
2023-01-03 23:23:18,842 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40095172077417374, 'Total loss': 0.40095172077417374} | train loss {'Reaction outcome loss': 0.3078906560296062, 'Total loss': 0.3078906560296062}
2023-01-03 23:23:18,842 INFO:     Found new best model at epoch 19
2023-01-03 23:23:18,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:18,843 INFO:     Epoch: 20
2023-01-03 23:23:20,442 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44425838788350425, 'Total loss': 0.44425838788350425} | train loss {'Reaction outcome loss': 0.3020377821148102, 'Total loss': 0.3020377821148102}
2023-01-03 23:23:20,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:20,442 INFO:     Epoch: 21
2023-01-03 23:23:22,022 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4080244988203049, 'Total loss': 0.4080244988203049} | train loss {'Reaction outcome loss': 0.2969736941296236, 'Total loss': 0.2969736941296236}
2023-01-03 23:23:22,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:22,022 INFO:     Epoch: 22
2023-01-03 23:23:23,605 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41339599192142484, 'Total loss': 0.41339599192142484} | train loss {'Reaction outcome loss': 0.2929567616309187, 'Total loss': 0.2929567616309187}
2023-01-03 23:23:23,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:23,605 INFO:     Epoch: 23
2023-01-03 23:23:25,173 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4192830681800842, 'Total loss': 0.4192830681800842} | train loss {'Reaction outcome loss': 0.28883134922858095, 'Total loss': 0.28883134922858095}
2023-01-03 23:23:25,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:25,174 INFO:     Epoch: 24
2023-01-03 23:23:26,773 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40063578883806866, 'Total loss': 0.40063578883806866} | train loss {'Reaction outcome loss': 0.2840042145324809, 'Total loss': 0.2840042145324809}
2023-01-03 23:23:26,773 INFO:     Found new best model at epoch 24
2023-01-03 23:23:26,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:26,774 INFO:     Epoch: 25
2023-01-03 23:23:28,327 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40258135050535204, 'Total loss': 0.40258135050535204} | train loss {'Reaction outcome loss': 0.2815867036691011, 'Total loss': 0.2815867036691011}
2023-01-03 23:23:28,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:28,327 INFO:     Epoch: 26
2023-01-03 23:23:29,924 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4036116699377696, 'Total loss': 0.4036116699377696} | train loss {'Reaction outcome loss': 0.2773486295529397, 'Total loss': 0.2773486295529397}
2023-01-03 23:23:29,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:29,925 INFO:     Epoch: 27
2023-01-03 23:23:31,501 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43100128372510277, 'Total loss': 0.43100128372510277} | train loss {'Reaction outcome loss': 0.2724378550514524, 'Total loss': 0.2724378550514524}
2023-01-03 23:23:31,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:31,501 INFO:     Epoch: 28
2023-01-03 23:23:33,081 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43891745011011757, 'Total loss': 0.43891745011011757} | train loss {'Reaction outcome loss': 0.27127670197029397, 'Total loss': 0.27127670197029397}
2023-01-03 23:23:33,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:33,081 INFO:     Epoch: 29
2023-01-03 23:23:34,675 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4017240598797798, 'Total loss': 0.4017240598797798} | train loss {'Reaction outcome loss': 0.2665230154001405, 'Total loss': 0.2665230154001405}
2023-01-03 23:23:34,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:34,675 INFO:     Epoch: 30
2023-01-03 23:23:36,277 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42544559240341184, 'Total loss': 0.42544559240341184} | train loss {'Reaction outcome loss': 0.2635206469640521, 'Total loss': 0.2635206469640521}
2023-01-03 23:23:36,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:36,277 INFO:     Epoch: 31
2023-01-03 23:23:37,879 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41408073008060453, 'Total loss': 0.41408073008060453} | train loss {'Reaction outcome loss': 0.2624235828149363, 'Total loss': 0.2624235828149363}
2023-01-03 23:23:37,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:37,880 INFO:     Epoch: 32
2023-01-03 23:23:39,428 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42979243099689485, 'Total loss': 0.42979243099689485} | train loss {'Reaction outcome loss': 0.2566407322883606, 'Total loss': 0.2566407322883606}
2023-01-03 23:23:39,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:39,428 INFO:     Epoch: 33
2023-01-03 23:23:41,031 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41453529795010885, 'Total loss': 0.41453529795010885} | train loss {'Reaction outcome loss': 0.2523024600975188, 'Total loss': 0.2523024600975188}
2023-01-03 23:23:41,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:41,031 INFO:     Epoch: 34
2023-01-03 23:23:42,601 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.407751386364301, 'Total loss': 0.407751386364301} | train loss {'Reaction outcome loss': 0.2504465118105561, 'Total loss': 0.2504465118105561}
2023-01-03 23:23:42,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:42,601 INFO:     Epoch: 35
2023-01-03 23:23:44,160 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.412248021364212, 'Total loss': 0.412248021364212} | train loss {'Reaction outcome loss': 0.2471010167137943, 'Total loss': 0.2471010167137943}
2023-01-03 23:23:44,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:44,161 INFO:     Epoch: 36
2023-01-03 23:23:45,721 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4250439797838529, 'Total loss': 0.4250439797838529} | train loss {'Reaction outcome loss': 0.24583034383689786, 'Total loss': 0.24583034383689786}
2023-01-03 23:23:45,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:45,721 INFO:     Epoch: 37
2023-01-03 23:23:47,280 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4224360336860021, 'Total loss': 0.4224360336860021} | train loss {'Reaction outcome loss': 0.24275170496194126, 'Total loss': 0.24275170496194126}
2023-01-03 23:23:47,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:47,281 INFO:     Epoch: 38
2023-01-03 23:23:48,833 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.399832983314991, 'Total loss': 0.399832983314991} | train loss {'Reaction outcome loss': 0.2399715009554396, 'Total loss': 0.2399715009554396}
2023-01-03 23:23:48,833 INFO:     Found new best model at epoch 38
2023-01-03 23:23:48,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:48,834 INFO:     Epoch: 39
2023-01-03 23:23:50,388 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4157005528608958, 'Total loss': 0.4157005528608958} | train loss {'Reaction outcome loss': 0.23628846539452508, 'Total loss': 0.23628846539452508}
2023-01-03 23:23:50,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:50,389 INFO:     Epoch: 40
2023-01-03 23:23:51,965 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4187969624996185, 'Total loss': 0.4187969624996185} | train loss {'Reaction outcome loss': 0.23451184484818985, 'Total loss': 0.23451184484818985}
2023-01-03 23:23:51,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:51,965 INFO:     Epoch: 41
2023-01-03 23:23:53,548 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4381615360577901, 'Total loss': 0.4381615360577901} | train loss {'Reaction outcome loss': 0.23470752513056753, 'Total loss': 0.23470752513056753}
2023-01-03 23:23:53,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:53,549 INFO:     Epoch: 42
2023-01-03 23:23:55,140 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41500214835007987, 'Total loss': 0.41500214835007987} | train loss {'Reaction outcome loss': 0.23136655351222662, 'Total loss': 0.23136655351222662}
2023-01-03 23:23:55,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:55,140 INFO:     Epoch: 43
2023-01-03 23:23:56,737 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41347941557566326, 'Total loss': 0.41347941557566326} | train loss {'Reaction outcome loss': 0.22801506208647662, 'Total loss': 0.22801506208647662}
2023-01-03 23:23:56,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:56,738 INFO:     Epoch: 44
2023-01-03 23:23:58,298 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4102360924084981, 'Total loss': 0.4102360924084981} | train loss {'Reaction outcome loss': 0.22788169856331006, 'Total loss': 0.22788169856331006}
2023-01-03 23:23:58,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:58,299 INFO:     Epoch: 45
2023-01-03 23:23:59,878 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42893367211023964, 'Total loss': 0.42893367211023964} | train loss {'Reaction outcome loss': 0.22398554990789768, 'Total loss': 0.22398554990789768}
2023-01-03 23:23:59,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:23:59,878 INFO:     Epoch: 46
2023-01-03 23:24:01,441 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40643933713436126, 'Total loss': 0.40643933713436126} | train loss {'Reaction outcome loss': 0.22434522584080696, 'Total loss': 0.22434522584080696}
2023-01-03 23:24:01,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:01,442 INFO:     Epoch: 47
2023-01-03 23:24:03,013 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4185128209491571, 'Total loss': 0.4185128209491571} | train loss {'Reaction outcome loss': 0.22301501595171175, 'Total loss': 0.22301501595171175}
2023-01-03 23:24:03,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:03,013 INFO:     Epoch: 48
2023-01-03 23:24:04,582 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4109765440225601, 'Total loss': 0.4109765440225601} | train loss {'Reaction outcome loss': 0.2171361944964671, 'Total loss': 0.2171361944964671}
2023-01-03 23:24:04,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:04,583 INFO:     Epoch: 49
2023-01-03 23:24:06,143 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41725965589284897, 'Total loss': 0.41725965589284897} | train loss {'Reaction outcome loss': 0.2178180864238871, 'Total loss': 0.2178180864238871}
2023-01-03 23:24:06,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:06,144 INFO:     Epoch: 50
2023-01-03 23:24:07,728 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4386057068904241, 'Total loss': 0.4386057068904241} | train loss {'Reaction outcome loss': 0.21446654421871877, 'Total loss': 0.21446654421871877}
2023-01-03 23:24:07,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:07,728 INFO:     Epoch: 51
2023-01-03 23:24:09,304 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4210083733002345, 'Total loss': 0.4210083733002345} | train loss {'Reaction outcome loss': 0.21443740542414444, 'Total loss': 0.21443740542414444}
2023-01-03 23:24:09,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:09,304 INFO:     Epoch: 52
2023-01-03 23:24:10,868 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45886033177375796, 'Total loss': 0.45886033177375796} | train loss {'Reaction outcome loss': 0.21323577449330544, 'Total loss': 0.21323577449330544}
2023-01-03 23:24:10,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:10,868 INFO:     Epoch: 53
2023-01-03 23:24:12,431 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4587136487166087, 'Total loss': 0.4587136487166087} | train loss {'Reaction outcome loss': 0.20934042759322152, 'Total loss': 0.20934042759322152}
2023-01-03 23:24:12,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:12,432 INFO:     Epoch: 54
2023-01-03 23:24:13,992 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42164027988910674, 'Total loss': 0.42164027988910674} | train loss {'Reaction outcome loss': 0.20950624140536214, 'Total loss': 0.20950624140536214}
2023-01-03 23:24:13,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:13,993 INFO:     Epoch: 55
2023-01-03 23:24:15,542 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42103888392448424, 'Total loss': 0.42103888392448424} | train loss {'Reaction outcome loss': 0.21092249450318487, 'Total loss': 0.21092249450318487}
2023-01-03 23:24:15,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:15,542 INFO:     Epoch: 56
2023-01-03 23:24:17,142 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4160365362962087, 'Total loss': 0.4160365362962087} | train loss {'Reaction outcome loss': 0.20709794208517374, 'Total loss': 0.20709794208517374}
2023-01-03 23:24:17,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:17,142 INFO:     Epoch: 57
2023-01-03 23:24:18,684 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41854796210924783, 'Total loss': 0.41854796210924783} | train loss {'Reaction outcome loss': 0.20464408782575402, 'Total loss': 0.20464408782575402}
2023-01-03 23:24:18,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:18,685 INFO:     Epoch: 58
2023-01-03 23:24:20,248 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4584625601768494, 'Total loss': 0.4584625601768494} | train loss {'Reaction outcome loss': 0.20234657483127283, 'Total loss': 0.20234657483127283}
2023-01-03 23:24:20,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:20,248 INFO:     Epoch: 59
2023-01-03 23:24:21,841 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4450918912887573, 'Total loss': 0.4450918912887573} | train loss {'Reaction outcome loss': 0.20135053296356953, 'Total loss': 0.20135053296356953}
2023-01-03 23:24:21,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:21,841 INFO:     Epoch: 60
2023-01-03 23:24:23,432 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42593122919400533, 'Total loss': 0.42593122919400533} | train loss {'Reaction outcome loss': 0.2005162028891354, 'Total loss': 0.2005162028891354}
2023-01-03 23:24:23,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:23,433 INFO:     Epoch: 61
2023-01-03 23:24:24,990 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4633239895105362, 'Total loss': 0.4633239895105362} | train loss {'Reaction outcome loss': 0.19871412988106044, 'Total loss': 0.19871412988106044}
2023-01-03 23:24:24,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:24,990 INFO:     Epoch: 62
2023-01-03 23:24:26,554 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.425153852502505, 'Total loss': 0.425153852502505} | train loss {'Reaction outcome loss': 0.1988147393116432, 'Total loss': 0.1988147393116432}
2023-01-03 23:24:26,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:26,554 INFO:     Epoch: 63
2023-01-03 23:24:28,092 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43941233853499095, 'Total loss': 0.43941233853499095} | train loss {'Reaction outcome loss': 0.19416228099640226, 'Total loss': 0.19416228099640226}
2023-01-03 23:24:28,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:28,092 INFO:     Epoch: 64
2023-01-03 23:24:29,683 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5070055822531382, 'Total loss': 0.5070055822531382} | train loss {'Reaction outcome loss': 0.19508895188625008, 'Total loss': 0.19508895188625008}
2023-01-03 23:24:29,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:29,683 INFO:     Epoch: 65
2023-01-03 23:24:31,269 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4398611803849538, 'Total loss': 0.4398611803849538} | train loss {'Reaction outcome loss': 0.19236911239439272, 'Total loss': 0.19236911239439272}
2023-01-03 23:24:31,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:31,270 INFO:     Epoch: 66
2023-01-03 23:24:32,839 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4311914483706156, 'Total loss': 0.4311914483706156} | train loss {'Reaction outcome loss': 0.1910767548775981, 'Total loss': 0.1910767548775981}
2023-01-03 23:24:32,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:32,839 INFO:     Epoch: 67
2023-01-03 23:24:34,421 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42698519428571063, 'Total loss': 0.42698519428571063} | train loss {'Reaction outcome loss': 0.19143369578072505, 'Total loss': 0.19143369578072505}
2023-01-03 23:24:34,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:34,421 INFO:     Epoch: 68
2023-01-03 23:24:35,999 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43794980744520823, 'Total loss': 0.43794980744520823} | train loss {'Reaction outcome loss': 0.19016597201408494, 'Total loss': 0.19016597201408494}
2023-01-03 23:24:35,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:35,999 INFO:     Epoch: 69
2023-01-03 23:24:37,590 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4718597094217936, 'Total loss': 0.4718597094217936} | train loss {'Reaction outcome loss': 0.18860463244063827, 'Total loss': 0.18860463244063827}
2023-01-03 23:24:37,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:37,590 INFO:     Epoch: 70
2023-01-03 23:24:39,157 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.417790687084198, 'Total loss': 0.417790687084198} | train loss {'Reaction outcome loss': 0.18602178093884483, 'Total loss': 0.18602178093884483}
2023-01-03 23:24:39,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:39,157 INFO:     Epoch: 71
2023-01-03 23:24:40,748 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4249502678712209, 'Total loss': 0.4249502678712209} | train loss {'Reaction outcome loss': 0.18855895443623577, 'Total loss': 0.18855895443623577}
2023-01-03 23:24:40,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:40,748 INFO:     Epoch: 72
2023-01-03 23:24:42,322 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4366273691256841, 'Total loss': 0.4366273691256841} | train loss {'Reaction outcome loss': 0.18287485241340096, 'Total loss': 0.18287485241340096}
2023-01-03 23:24:42,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:42,322 INFO:     Epoch: 73
2023-01-03 23:24:43,925 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43666892051696776, 'Total loss': 0.43666892051696776} | train loss {'Reaction outcome loss': 0.1852237281365478, 'Total loss': 0.1852237281365478}
2023-01-03 23:24:43,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:43,926 INFO:     Epoch: 74
2023-01-03 23:24:45,481 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42740148852268856, 'Total loss': 0.42740148852268856} | train loss {'Reaction outcome loss': 0.1825533795661922, 'Total loss': 0.1825533795661922}
2023-01-03 23:24:45,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:45,481 INFO:     Epoch: 75
2023-01-03 23:24:47,063 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45958298643430073, 'Total loss': 0.45958298643430073} | train loss {'Reaction outcome loss': 0.18251340109098882, 'Total loss': 0.18251340109098882}
2023-01-03 23:24:47,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:47,064 INFO:     Epoch: 76
2023-01-03 23:24:48,665 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42327531973520915, 'Total loss': 0.42327531973520915} | train loss {'Reaction outcome loss': 0.18285976792943434, 'Total loss': 0.18285976792943434}
2023-01-03 23:24:48,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:48,665 INFO:     Epoch: 77
2023-01-03 23:24:50,269 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42298389226198196, 'Total loss': 0.42298389226198196} | train loss {'Reaction outcome loss': 0.1814378594147983, 'Total loss': 0.1814378594147983}
2023-01-03 23:24:50,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:50,270 INFO:     Epoch: 78
2023-01-03 23:24:51,838 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4405357261498769, 'Total loss': 0.4405357261498769} | train loss {'Reaction outcome loss': 0.17895308066833063, 'Total loss': 0.17895308066833063}
2023-01-03 23:24:51,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:51,838 INFO:     Epoch: 79
2023-01-03 23:24:53,408 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4543141817053159, 'Total loss': 0.4543141817053159} | train loss {'Reaction outcome loss': 0.17934509621060202, 'Total loss': 0.17934509621060202}
2023-01-03 23:24:53,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:53,409 INFO:     Epoch: 80
2023-01-03 23:24:54,976 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4419337610403697, 'Total loss': 0.4419337610403697} | train loss {'Reaction outcome loss': 0.17740562033059412, 'Total loss': 0.17740562033059412}
2023-01-03 23:24:54,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:54,976 INFO:     Epoch: 81
2023-01-03 23:24:56,582 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.435029332836469, 'Total loss': 0.435029332836469} | train loss {'Reaction outcome loss': 0.17511647637259917, 'Total loss': 0.17511647637259917}
2023-01-03 23:24:56,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:56,582 INFO:     Epoch: 82
2023-01-03 23:24:58,184 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42048347493012744, 'Total loss': 0.42048347493012744} | train loss {'Reaction outcome loss': 0.17644777419767257, 'Total loss': 0.17644777419767257}
2023-01-03 23:24:58,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:58,184 INFO:     Epoch: 83
2023-01-03 23:24:59,779 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42723205337921777, 'Total loss': 0.42723205337921777} | train loss {'Reaction outcome loss': 0.17378018213594093, 'Total loss': 0.17378018213594093}
2023-01-03 23:24:59,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:24:59,780 INFO:     Epoch: 84
2023-01-03 23:25:01,361 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4332321514685949, 'Total loss': 0.4332321514685949} | train loss {'Reaction outcome loss': 0.1745483054198682, 'Total loss': 0.1745483054198682}
2023-01-03 23:25:01,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:01,361 INFO:     Epoch: 85
2023-01-03 23:25:02,938 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41508607665697733, 'Total loss': 0.41508607665697733} | train loss {'Reaction outcome loss': 0.17444135460356505, 'Total loss': 0.17444135460356505}
2023-01-03 23:25:02,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:02,939 INFO:     Epoch: 86
2023-01-03 23:25:04,532 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.446086843808492, 'Total loss': 0.446086843808492} | train loss {'Reaction outcome loss': 0.16999697795900692, 'Total loss': 0.16999697795900692}
2023-01-03 23:25:04,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:04,532 INFO:     Epoch: 87
2023-01-03 23:25:06,139 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4886735121409098, 'Total loss': 0.4886735121409098} | train loss {'Reaction outcome loss': 0.17185474444194473, 'Total loss': 0.17185474444194473}
2023-01-03 23:25:06,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:06,139 INFO:     Epoch: 88
2023-01-03 23:25:07,758 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4220989535252253, 'Total loss': 0.4220989535252253} | train loss {'Reaction outcome loss': 0.1701710704452877, 'Total loss': 0.1701710704452877}
2023-01-03 23:25:07,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:07,758 INFO:     Epoch: 89
2023-01-03 23:25:09,311 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4266730094949404, 'Total loss': 0.4266730094949404} | train loss {'Reaction outcome loss': 0.1691956954881054, 'Total loss': 0.1691956954881054}
2023-01-03 23:25:09,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:09,311 INFO:     Epoch: 90
2023-01-03 23:25:10,380 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4193890949090322, 'Total loss': 0.4193890949090322} | train loss {'Reaction outcome loss': 0.1692369241693583, 'Total loss': 0.1692369241693583}
2023-01-03 23:25:10,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:10,380 INFO:     Epoch: 91
2023-01-03 23:25:11,440 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4503346939881643, 'Total loss': 0.4503346939881643} | train loss {'Reaction outcome loss': 0.1689464452631799, 'Total loss': 0.1689464452631799}
2023-01-03 23:25:11,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:11,440 INFO:     Epoch: 92
2023-01-03 23:25:12,485 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4110140790541967, 'Total loss': 0.4110140790541967} | train loss {'Reaction outcome loss': 0.16914758544648925, 'Total loss': 0.16914758544648925}
2023-01-03 23:25:12,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:12,485 INFO:     Epoch: 93
2023-01-03 23:25:13,551 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4383332411448161, 'Total loss': 0.4383332411448161} | train loss {'Reaction outcome loss': 0.16753206520282915, 'Total loss': 0.16753206520282915}
2023-01-03 23:25:13,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:13,551 INFO:     Epoch: 94
2023-01-03 23:25:15,151 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4325893004735311, 'Total loss': 0.4325893004735311} | train loss {'Reaction outcome loss': 0.16596337622959456, 'Total loss': 0.16596337622959456}
2023-01-03 23:25:15,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:15,151 INFO:     Epoch: 95
2023-01-03 23:25:16,742 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41115558544794717, 'Total loss': 0.41115558544794717} | train loss {'Reaction outcome loss': 0.16588269005017528, 'Total loss': 0.16588269005017528}
2023-01-03 23:25:16,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:16,742 INFO:     Epoch: 96
2023-01-03 23:25:18,292 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4353538453578949, 'Total loss': 0.4353538453578949} | train loss {'Reaction outcome loss': 0.1656096953953654, 'Total loss': 0.1656096953953654}
2023-01-03 23:25:18,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:18,293 INFO:     Epoch: 97
2023-01-03 23:25:19,839 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4156762888034185, 'Total loss': 0.4156762888034185} | train loss {'Reaction outcome loss': 0.16319503314875589, 'Total loss': 0.16319503314875589}
2023-01-03 23:25:19,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:19,840 INFO:     Epoch: 98
2023-01-03 23:25:21,404 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.397739643851916, 'Total loss': 0.397739643851916} | train loss {'Reaction outcome loss': 0.16390237863763232, 'Total loss': 0.16390237863763232}
2023-01-03 23:25:21,404 INFO:     Found new best model at epoch 98
2023-01-03 23:25:21,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:21,405 INFO:     Epoch: 99
2023-01-03 23:25:22,952 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47224581638971963, 'Total loss': 0.47224581638971963} | train loss {'Reaction outcome loss': 0.16106606919552127, 'Total loss': 0.16106606919552127}
2023-01-03 23:25:22,953 INFO:     Best model found after epoch 99 of 100.
2023-01-03 23:25:22,953 INFO:   Done with stage: TRAINING
2023-01-03 23:25:22,953 INFO:   Starting stage: EVALUATION
2023-01-03 23:25:23,101 INFO:   Done with stage: EVALUATION
2023-01-03 23:25:23,101 INFO:   Leaving out SEQ value Fold_1
2023-01-03 23:25:23,114 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-03 23:25:23,114 INFO:   Starting stage: FEATURE SCALING
2023-01-03 23:25:23,754 INFO:   Done with stage: FEATURE SCALING
2023-01-03 23:25:23,754 INFO:   Starting stage: SCALING TARGETS
2023-01-03 23:25:23,822 INFO:   Done with stage: SCALING TARGETS
2023-01-03 23:25:23,822 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:25:23,823 INFO:     No hyperparam tuning for this model
2023-01-03 23:25:23,823 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:25:23,823 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 23:25:23,823 INFO:     None feature selector for col prot
2023-01-03 23:25:23,823 INFO:     None feature selector for col prot
2023-01-03 23:25:23,824 INFO:     None feature selector for col prot
2023-01-03 23:25:23,824 INFO:     None feature selector for col chem
2023-01-03 23:25:23,824 INFO:     None feature selector for col chem
2023-01-03 23:25:23,824 INFO:     None feature selector for col chem
2023-01-03 23:25:23,824 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 23:25:23,824 INFO:   Starting stage: BUILD MODEL
2023-01-03 23:25:23,825 INFO:     Number of params in model 70141
2023-01-03 23:25:23,829 INFO:   Done with stage: BUILD MODEL
2023-01-03 23:25:23,829 INFO:   Starting stage: TRAINING
2023-01-03 23:25:23,873 INFO:     Val loss before train {'Reaction outcome loss': 1.0878039677937825, 'Total loss': 1.0878039677937825}
2023-01-03 23:25:23,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:23,873 INFO:     Epoch: 0
2023-01-03 23:25:25,490 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7248335282007853, 'Total loss': 0.7248335282007853} | train loss {'Reaction outcome loss': 0.8435758146578851, 'Total loss': 0.8435758146578851}
2023-01-03 23:25:25,490 INFO:     Found new best model at epoch 0
2023-01-03 23:25:25,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:25,491 INFO:     Epoch: 1
2023-01-03 23:25:27,117 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.600434947013855, 'Total loss': 0.600434947013855} | train loss {'Reaction outcome loss': 0.6327172479599856, 'Total loss': 0.6327172479599856}
2023-01-03 23:25:27,118 INFO:     Found new best model at epoch 1
2023-01-03 23:25:27,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:27,119 INFO:     Epoch: 2
2023-01-03 23:25:28,711 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5589750329653422, 'Total loss': 0.5589750329653422} | train loss {'Reaction outcome loss': 0.5439394429744477, 'Total loss': 0.5439394429744477}
2023-01-03 23:25:28,711 INFO:     Found new best model at epoch 2
2023-01-03 23:25:28,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:28,712 INFO:     Epoch: 3
2023-01-03 23:25:30,312 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5068588554859161, 'Total loss': 0.5068588554859161} | train loss {'Reaction outcome loss': 0.4974109727106448, 'Total loss': 0.4974109727106448}
2023-01-03 23:25:30,313 INFO:     Found new best model at epoch 3
2023-01-03 23:25:30,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:30,313 INFO:     Epoch: 4
2023-01-03 23:25:31,912 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4889289160569509, 'Total loss': 0.4889289160569509} | train loss {'Reaction outcome loss': 0.46716755250657815, 'Total loss': 0.46716755250657815}
2023-01-03 23:25:31,912 INFO:     Found new best model at epoch 4
2023-01-03 23:25:31,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:31,913 INFO:     Epoch: 5
2023-01-03 23:25:33,532 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4854876319567362, 'Total loss': 0.4854876319567362} | train loss {'Reaction outcome loss': 0.4434218647336398, 'Total loss': 0.4434218647336398}
2023-01-03 23:25:33,532 INFO:     Found new best model at epoch 5
2023-01-03 23:25:33,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:33,533 INFO:     Epoch: 6
2023-01-03 23:25:35,120 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45287177165349324, 'Total loss': 0.45287177165349324} | train loss {'Reaction outcome loss': 0.4248525943935024, 'Total loss': 0.4248525943935024}
2023-01-03 23:25:35,120 INFO:     Found new best model at epoch 6
2023-01-03 23:25:35,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:35,121 INFO:     Epoch: 7
2023-01-03 23:25:36,720 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45658232768376666, 'Total loss': 0.45658232768376666} | train loss {'Reaction outcome loss': 0.4083688563356797, 'Total loss': 0.4083688563356797}
2023-01-03 23:25:36,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:36,721 INFO:     Epoch: 8
2023-01-03 23:25:38,305 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46751333475112916, 'Total loss': 0.46751333475112916} | train loss {'Reaction outcome loss': 0.3975104330903918, 'Total loss': 0.3975104330903918}
2023-01-03 23:25:38,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:38,305 INFO:     Epoch: 9
2023-01-03 23:25:39,939 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4417320211728414, 'Total loss': 0.4417320211728414} | train loss {'Reaction outcome loss': 0.3860295329350924, 'Total loss': 0.3860295329350924}
2023-01-03 23:25:39,940 INFO:     Found new best model at epoch 9
2023-01-03 23:25:39,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:39,941 INFO:     Epoch: 10
2023-01-03 23:25:41,514 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4349110265572866, 'Total loss': 0.4349110265572866} | train loss {'Reaction outcome loss': 0.3774971802642171, 'Total loss': 0.3774971802642171}
2023-01-03 23:25:41,514 INFO:     Found new best model at epoch 10
2023-01-03 23:25:41,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:41,515 INFO:     Epoch: 11
2023-01-03 23:25:43,110 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4324141263961792, 'Total loss': 0.4324141263961792} | train loss {'Reaction outcome loss': 0.36751436213608424, 'Total loss': 0.36751436213608424}
2023-01-03 23:25:43,110 INFO:     Found new best model at epoch 11
2023-01-03 23:25:43,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:43,111 INFO:     Epoch: 12
2023-01-03 23:25:44,702 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42160308361053467, 'Total loss': 0.42160308361053467} | train loss {'Reaction outcome loss': 0.35889304319963505, 'Total loss': 0.35889304319963505}
2023-01-03 23:25:44,702 INFO:     Found new best model at epoch 12
2023-01-03 23:25:44,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:44,703 INFO:     Epoch: 13
2023-01-03 23:25:46,281 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4236514816681544, 'Total loss': 0.4236514816681544} | train loss {'Reaction outcome loss': 0.3498729829662952, 'Total loss': 0.3498729829662952}
2023-01-03 23:25:46,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:46,281 INFO:     Epoch: 14
2023-01-03 23:25:47,873 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.419988676905632, 'Total loss': 0.419988676905632} | train loss {'Reaction outcome loss': 0.3461459242009922, 'Total loss': 0.3461459242009922}
2023-01-03 23:25:47,874 INFO:     Found new best model at epoch 14
2023-01-03 23:25:47,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:47,874 INFO:     Epoch: 15
2023-01-03 23:25:49,456 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41729331215222676, 'Total loss': 0.41729331215222676} | train loss {'Reaction outcome loss': 0.3399000860804665, 'Total loss': 0.3399000860804665}
2023-01-03 23:25:49,456 INFO:     Found new best model at epoch 15
2023-01-03 23:25:49,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:49,457 INFO:     Epoch: 16
2023-01-03 23:25:51,069 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43182372450828554, 'Total loss': 0.43182372450828554} | train loss {'Reaction outcome loss': 0.3339678532835366, 'Total loss': 0.3339678532835366}
2023-01-03 23:25:51,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:51,070 INFO:     Epoch: 17
2023-01-03 23:25:52,701 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.415537769595782, 'Total loss': 0.415537769595782} | train loss {'Reaction outcome loss': 0.32816642501890875, 'Total loss': 0.32816642501890875}
2023-01-03 23:25:52,701 INFO:     Found new best model at epoch 17
2023-01-03 23:25:52,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:52,702 INFO:     Epoch: 18
2023-01-03 23:25:54,295 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43109924892584484, 'Total loss': 0.43109924892584484} | train loss {'Reaction outcome loss': 0.3197170033700008, 'Total loss': 0.3197170033700008}
2023-01-03 23:25:54,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:54,295 INFO:     Epoch: 19
2023-01-03 23:25:55,871 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41828631261984506, 'Total loss': 0.41828631261984506} | train loss {'Reaction outcome loss': 0.3168926114297431, 'Total loss': 0.3168926114297431}
2023-01-03 23:25:55,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:55,872 INFO:     Epoch: 20
2023-01-03 23:25:57,455 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42249690294265746, 'Total loss': 0.42249690294265746} | train loss {'Reaction outcome loss': 0.31148538063195924, 'Total loss': 0.31148538063195924}
2023-01-03 23:25:57,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:57,455 INFO:     Epoch: 21
2023-01-03 23:25:59,046 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4277391533056895, 'Total loss': 0.4277391533056895} | train loss {'Reaction outcome loss': 0.30418900165544904, 'Total loss': 0.30418900165544904}
2023-01-03 23:25:59,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:25:59,046 INFO:     Epoch: 22
2023-01-03 23:26:00,675 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4242762545744578, 'Total loss': 0.4242762545744578} | train loss {'Reaction outcome loss': 0.3006951015550589, 'Total loss': 0.3006951015550589}
2023-01-03 23:26:00,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:00,676 INFO:     Epoch: 23
2023-01-03 23:26:02,308 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41904929478963215, 'Total loss': 0.41904929478963215} | train loss {'Reaction outcome loss': 0.2979744120258028, 'Total loss': 0.2979744120258028}
2023-01-03 23:26:02,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:02,309 INFO:     Epoch: 24
2023-01-03 23:26:03,904 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4051162153482437, 'Total loss': 0.4051162153482437} | train loss {'Reaction outcome loss': 0.2927487265264642, 'Total loss': 0.2927487265264642}
2023-01-03 23:26:03,904 INFO:     Found new best model at epoch 24
2023-01-03 23:26:03,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:03,905 INFO:     Epoch: 25
2023-01-03 23:26:05,490 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43416601022084556, 'Total loss': 0.43416601022084556} | train loss {'Reaction outcome loss': 0.2862800483362398, 'Total loss': 0.2862800483362398}
2023-01-03 23:26:05,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:05,491 INFO:     Epoch: 26
2023-01-03 23:26:07,093 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4172659625609716, 'Total loss': 0.4172659625609716} | train loss {'Reaction outcome loss': 0.28167676688104437, 'Total loss': 0.28167676688104437}
2023-01-03 23:26:07,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:07,094 INFO:     Epoch: 27
2023-01-03 23:26:08,713 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4185024917125702, 'Total loss': 0.4185024917125702} | train loss {'Reaction outcome loss': 0.2775412287320132, 'Total loss': 0.2775412287320132}
2023-01-03 23:26:08,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:08,714 INFO:     Epoch: 28
2023-01-03 23:26:10,345 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4257416963577271, 'Total loss': 0.4257416963577271} | train loss {'Reaction outcome loss': 0.27354872921843204, 'Total loss': 0.27354872921843204}
2023-01-03 23:26:10,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:10,346 INFO:     Epoch: 29
2023-01-03 23:26:11,972 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3986809780200323, 'Total loss': 0.3986809780200323} | train loss {'Reaction outcome loss': 0.2698256632623573, 'Total loss': 0.2698256632623573}
2023-01-03 23:26:11,972 INFO:     Found new best model at epoch 29
2023-01-03 23:26:11,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:11,973 INFO:     Epoch: 30
2023-01-03 23:26:13,578 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3987904312709967, 'Total loss': 0.3987904312709967} | train loss {'Reaction outcome loss': 0.26558334415481577, 'Total loss': 0.26558334415481577}
2023-01-03 23:26:13,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:13,579 INFO:     Epoch: 31
2023-01-03 23:26:15,213 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4212380826473236, 'Total loss': 0.4212380826473236} | train loss {'Reaction outcome loss': 0.26433175796831865, 'Total loss': 0.26433175796831865}
2023-01-03 23:26:15,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:15,214 INFO:     Epoch: 32
2023-01-03 23:26:16,817 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3986645132303238, 'Total loss': 0.3986645132303238} | train loss {'Reaction outcome loss': 0.2628782134557116, 'Total loss': 0.2628782134557116}
2023-01-03 23:26:16,817 INFO:     Found new best model at epoch 32
2023-01-03 23:26:16,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:16,818 INFO:     Epoch: 33
2023-01-03 23:26:18,440 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43071291645367943, 'Total loss': 0.43071291645367943} | train loss {'Reaction outcome loss': 0.26244196329513425, 'Total loss': 0.26244196329513425}
2023-01-03 23:26:18,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:18,440 INFO:     Epoch: 34
2023-01-03 23:26:20,047 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42085636258125303, 'Total loss': 0.42085636258125303} | train loss {'Reaction outcome loss': 0.2546512445542907, 'Total loss': 0.2546512445542907}
2023-01-03 23:26:20,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:20,047 INFO:     Epoch: 35
2023-01-03 23:26:21,632 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42232480843861897, 'Total loss': 0.42232480843861897} | train loss {'Reaction outcome loss': 0.2556240323364087, 'Total loss': 0.2556240323364087}
2023-01-03 23:26:21,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:21,632 INFO:     Epoch: 36
2023-01-03 23:26:23,251 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4126315305630366, 'Total loss': 0.4126315305630366} | train loss {'Reaction outcome loss': 0.25678899944034417, 'Total loss': 0.25678899944034417}
2023-01-03 23:26:23,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:23,252 INFO:     Epoch: 37
2023-01-03 23:26:24,886 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4200790504614512, 'Total loss': 0.4200790504614512} | train loss {'Reaction outcome loss': 0.24362695124675182, 'Total loss': 0.24362695124675182}
2023-01-03 23:26:24,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:24,887 INFO:     Epoch: 38
2023-01-03 23:26:26,492 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4076393902301788, 'Total loss': 0.4076393902301788} | train loss {'Reaction outcome loss': 0.2422870956829486, 'Total loss': 0.2422870956829486}
2023-01-03 23:26:26,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:26,492 INFO:     Epoch: 39
2023-01-03 23:26:28,129 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3952262515823046, 'Total loss': 0.3952262515823046} | train loss {'Reaction outcome loss': 0.23812099053537933, 'Total loss': 0.23812099053537933}
2023-01-03 23:26:28,129 INFO:     Found new best model at epoch 39
2023-01-03 23:26:28,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:28,130 INFO:     Epoch: 40
2023-01-03 23:26:29,742 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40550023367007576, 'Total loss': 0.40550023367007576} | train loss {'Reaction outcome loss': 0.23739728885930558, 'Total loss': 0.23739728885930558}
2023-01-03 23:26:29,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:29,742 INFO:     Epoch: 41
2023-01-03 23:26:31,324 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40722398161888124, 'Total loss': 0.40722398161888124} | train loss {'Reaction outcome loss': 0.23401566654227782, 'Total loss': 0.23401566654227782}
2023-01-03 23:26:31,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:31,326 INFO:     Epoch: 42
2023-01-03 23:26:32,919 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41395018696784974, 'Total loss': 0.41395018696784974} | train loss {'Reaction outcome loss': 0.23952391577641602, 'Total loss': 0.23952391577641602}
2023-01-03 23:26:32,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:32,919 INFO:     Epoch: 43
2023-01-03 23:26:34,525 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4366807460784912, 'Total loss': 0.4366807460784912} | train loss {'Reaction outcome loss': 0.2332964480880511, 'Total loss': 0.2332964480880511}
2023-01-03 23:26:34,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:34,525 INFO:     Epoch: 44
2023-01-03 23:26:36,145 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4183447470267614, 'Total loss': 0.4183447470267614} | train loss {'Reaction outcome loss': 0.22813794353683275, 'Total loss': 0.22813794353683275}
2023-01-03 23:26:36,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:36,145 INFO:     Epoch: 45
2023-01-03 23:26:37,778 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43378997842470807, 'Total loss': 0.43378997842470807} | train loss {'Reaction outcome loss': 0.22372262132610532, 'Total loss': 0.22372262132610532}
2023-01-03 23:26:37,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:37,779 INFO:     Epoch: 46
2023-01-03 23:26:39,392 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4347838322321574, 'Total loss': 0.4347838322321574} | train loss {'Reaction outcome loss': 0.22503927375520646, 'Total loss': 0.22503927375520646}
2023-01-03 23:26:39,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:39,392 INFO:     Epoch: 47
2023-01-03 23:26:40,979 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42273920873800913, 'Total loss': 0.42273920873800913} | train loss {'Reaction outcome loss': 0.23432229945193167, 'Total loss': 0.23432229945193167}
2023-01-03 23:26:40,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:40,980 INFO:     Epoch: 48
2023-01-03 23:26:42,603 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4426185170809428, 'Total loss': 0.4426185170809428} | train loss {'Reaction outcome loss': 0.23724976742127235, 'Total loss': 0.23724976742127235}
2023-01-03 23:26:42,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:42,604 INFO:     Epoch: 49
2023-01-03 23:26:44,182 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4288829227288564, 'Total loss': 0.4288829227288564} | train loss {'Reaction outcome loss': 0.22412717886428532, 'Total loss': 0.22412717886428532}
2023-01-03 23:26:44,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:44,182 INFO:     Epoch: 50
2023-01-03 23:26:45,817 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4321036736170451, 'Total loss': 0.4321036736170451} | train loss {'Reaction outcome loss': 0.21575268213907123, 'Total loss': 0.21575268213907123}
2023-01-03 23:26:45,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:45,817 INFO:     Epoch: 51
2023-01-03 23:26:47,413 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.434265261888504, 'Total loss': 0.434265261888504} | train loss {'Reaction outcome loss': 0.21492686607424452, 'Total loss': 0.21492686607424452}
2023-01-03 23:26:47,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:47,413 INFO:     Epoch: 52
2023-01-03 23:26:48,992 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44545746544996895, 'Total loss': 0.44545746544996895} | train loss {'Reaction outcome loss': 0.21230886503379198, 'Total loss': 0.21230886503379198}
2023-01-03 23:26:48,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:48,992 INFO:     Epoch: 53
2023-01-03 23:26:50,631 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4283889273802439, 'Total loss': 0.4283889273802439} | train loss {'Reaction outcome loss': 0.21422238839938695, 'Total loss': 0.21422238839938695}
2023-01-03 23:26:50,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:50,631 INFO:     Epoch: 54
2023-01-03 23:26:52,230 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4481708864370982, 'Total loss': 0.4481708864370982} | train loss {'Reaction outcome loss': 0.21081043652858183, 'Total loss': 0.21081043652858183}
2023-01-03 23:26:52,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:52,230 INFO:     Epoch: 55
2023-01-03 23:26:53,850 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45287795464197794, 'Total loss': 0.45287795464197794} | train loss {'Reaction outcome loss': 0.20725212042368407, 'Total loss': 0.20725212042368407}
2023-01-03 23:26:53,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:53,850 INFO:     Epoch: 56
2023-01-03 23:26:55,484 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43114315072695414, 'Total loss': 0.43114315072695414} | train loss {'Reaction outcome loss': 0.2101549366311899, 'Total loss': 0.2101549366311899}
2023-01-03 23:26:55,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:55,484 INFO:     Epoch: 57
2023-01-03 23:26:57,107 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4704623440901438, 'Total loss': 0.4704623440901438} | train loss {'Reaction outcome loss': 0.22144609992054926, 'Total loss': 0.22144609992054926}
2023-01-03 23:26:57,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:57,107 INFO:     Epoch: 58
2023-01-03 23:26:58,685 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43998121122519174, 'Total loss': 0.43998121122519174} | train loss {'Reaction outcome loss': 0.22075788757923664, 'Total loss': 0.22075788757923664}
2023-01-03 23:26:58,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:26:58,685 INFO:     Epoch: 59
2023-01-03 23:27:00,285 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4453721841176351, 'Total loss': 0.4453721841176351} | train loss {'Reaction outcome loss': 0.19990129675125648, 'Total loss': 0.19990129675125648}
2023-01-03 23:27:00,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:00,285 INFO:     Epoch: 60
2023-01-03 23:27:01,859 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42551226715246837, 'Total loss': 0.42551226715246837} | train loss {'Reaction outcome loss': 0.1984672298122609, 'Total loss': 0.1984672298122609}
2023-01-03 23:27:01,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:01,859 INFO:     Epoch: 61
2023-01-03 23:27:03,496 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45691315134366356, 'Total loss': 0.45691315134366356} | train loss {'Reaction outcome loss': 0.19649495423136218, 'Total loss': 0.19649495423136218}
2023-01-03 23:27:03,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:03,497 INFO:     Epoch: 62
2023-01-03 23:27:05,133 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43176466822624204, 'Total loss': 0.43176466822624204} | train loss {'Reaction outcome loss': 0.19752493117329836, 'Total loss': 0.19752493117329836}
2023-01-03 23:27:05,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:05,134 INFO:     Epoch: 63
2023-01-03 23:27:06,745 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4286962429682414, 'Total loss': 0.4286962429682414} | train loss {'Reaction outcome loss': 0.1965716686070242, 'Total loss': 0.1965716686070242}
2023-01-03 23:27:06,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:06,746 INFO:     Epoch: 64
2023-01-03 23:27:08,364 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4462146172920863, 'Total loss': 0.4462146172920863} | train loss {'Reaction outcome loss': 0.1945016757544728, 'Total loss': 0.1945016757544728}
2023-01-03 23:27:08,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:08,365 INFO:     Epoch: 65
2023-01-03 23:27:10,004 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4430914163589478, 'Total loss': 0.4430914163589478} | train loss {'Reaction outcome loss': 0.19513618317095266, 'Total loss': 0.19513618317095266}
2023-01-03 23:27:10,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:10,004 INFO:     Epoch: 66
2023-01-03 23:27:11,608 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4421403606732686, 'Total loss': 0.4421403606732686} | train loss {'Reaction outcome loss': 0.19544117540341255, 'Total loss': 0.19544117540341255}
2023-01-03 23:27:11,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:11,609 INFO:     Epoch: 67
2023-01-03 23:27:13,232 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4284610738356908, 'Total loss': 0.4284610738356908} | train loss {'Reaction outcome loss': 0.19347204433659604, 'Total loss': 0.19347204433659604}
2023-01-03 23:27:13,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:13,233 INFO:     Epoch: 68
2023-01-03 23:27:14,867 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4342856228351593, 'Total loss': 0.4342856228351593} | train loss {'Reaction outcome loss': 0.1913484900622912, 'Total loss': 0.1913484900622912}
2023-01-03 23:27:14,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:14,867 INFO:     Epoch: 69
2023-01-03 23:27:16,460 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4299774944782257, 'Total loss': 0.4299774944782257} | train loss {'Reaction outcome loss': 0.19396855419430378, 'Total loss': 0.19396855419430378}
2023-01-03 23:27:16,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:16,460 INFO:     Epoch: 70
2023-01-03 23:27:18,094 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.439642596244812, 'Total loss': 0.439642596244812} | train loss {'Reaction outcome loss': 0.18839521654840413, 'Total loss': 0.18839521654840413}
2023-01-03 23:27:18,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:18,094 INFO:     Epoch: 71
2023-01-03 23:27:19,699 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43720628321170807, 'Total loss': 0.43720628321170807} | train loss {'Reaction outcome loss': 0.1906748459390972, 'Total loss': 0.1906748459390972}
2023-01-03 23:27:19,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:19,699 INFO:     Epoch: 72
2023-01-03 23:27:21,317 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4640892227490743, 'Total loss': 0.4640892227490743} | train loss {'Reaction outcome loss': 0.19287845396731584, 'Total loss': 0.19287845396731584}
2023-01-03 23:27:21,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:21,317 INFO:     Epoch: 73
2023-01-03 23:27:22,931 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45730744500954945, 'Total loss': 0.45730744500954945} | train loss {'Reaction outcome loss': 0.18432901362277757, 'Total loss': 0.18432901362277757}
2023-01-03 23:27:22,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:22,931 INFO:     Epoch: 74
2023-01-03 23:27:24,570 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4430738548437754, 'Total loss': 0.4430738548437754} | train loss {'Reaction outcome loss': 0.18910756457636665, 'Total loss': 0.18910756457636665}
2023-01-03 23:27:24,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:24,570 INFO:     Epoch: 75
2023-01-03 23:27:26,156 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4443584223588308, 'Total loss': 0.4443584223588308} | train loss {'Reaction outcome loss': 0.18482624500504005, 'Total loss': 0.18482624500504005}
2023-01-03 23:27:26,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:26,157 INFO:     Epoch: 76
2023-01-03 23:27:27,744 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4867912838856379, 'Total loss': 0.4867912838856379} | train loss {'Reaction outcome loss': 0.18416649072803368, 'Total loss': 0.18416649072803368}
2023-01-03 23:27:27,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:27,744 INFO:     Epoch: 77
2023-01-03 23:27:29,342 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45690273443857826, 'Total loss': 0.45690273443857826} | train loss {'Reaction outcome loss': 0.18129361467457045, 'Total loss': 0.18129361467457045}
2023-01-03 23:27:29,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:29,342 INFO:     Epoch: 78
2023-01-03 23:27:30,968 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4523770809173584, 'Total loss': 0.4523770809173584} | train loss {'Reaction outcome loss': 0.1831935590626149, 'Total loss': 0.1831935590626149}
2023-01-03 23:27:30,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:30,969 INFO:     Epoch: 79
2023-01-03 23:27:32,571 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4582254399855932, 'Total loss': 0.4582254399855932} | train loss {'Reaction outcome loss': 0.18019152771803024, 'Total loss': 0.18019152771803024}
2023-01-03 23:27:32,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:32,571 INFO:     Epoch: 80
2023-01-03 23:27:34,163 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42870582851270833, 'Total loss': 0.42870582851270833} | train loss {'Reaction outcome loss': 0.17983104194096033, 'Total loss': 0.17983104194096033}
2023-01-03 23:27:34,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:34,164 INFO:     Epoch: 81
2023-01-03 23:27:35,766 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46445714831352236, 'Total loss': 0.46445714831352236} | train loss {'Reaction outcome loss': 0.18415829877604678, 'Total loss': 0.18415829877604678}
2023-01-03 23:27:35,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:35,766 INFO:     Epoch: 82
2023-01-03 23:27:37,368 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46468685468037924, 'Total loss': 0.46468685468037924} | train loss {'Reaction outcome loss': 0.17975158281489342, 'Total loss': 0.17975158281489342}
2023-01-03 23:27:37,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:37,370 INFO:     Epoch: 83
2023-01-03 23:27:38,946 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4667750855286916, 'Total loss': 0.4667750855286916} | train loss {'Reaction outcome loss': 0.18261848884762055, 'Total loss': 0.18261848884762055}
2023-01-03 23:27:38,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:38,946 INFO:     Epoch: 84
2023-01-03 23:27:40,565 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43403132557868956, 'Total loss': 0.43403132557868956} | train loss {'Reaction outcome loss': 0.17724019015735973, 'Total loss': 0.17724019015735973}
2023-01-03 23:27:40,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:40,565 INFO:     Epoch: 85
2023-01-03 23:27:42,204 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4399501462777456, 'Total loss': 0.4399501462777456} | train loss {'Reaction outcome loss': 0.17688689726418344, 'Total loss': 0.17688689726418344}
2023-01-03 23:27:42,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:42,204 INFO:     Epoch: 86
2023-01-03 23:27:43,791 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46228500405947365, 'Total loss': 0.46228500405947365} | train loss {'Reaction outcome loss': 0.17573949179537865, 'Total loss': 0.17573949179537865}
2023-01-03 23:27:43,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:43,792 INFO:     Epoch: 87
2023-01-03 23:27:45,390 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4366392970085144, 'Total loss': 0.4366392970085144} | train loss {'Reaction outcome loss': 0.1746987317877727, 'Total loss': 0.1746987317877727}
2023-01-03 23:27:45,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:45,390 INFO:     Epoch: 88
2023-01-03 23:27:46,970 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46612521111965177, 'Total loss': 0.46612521111965177} | train loss {'Reaction outcome loss': 0.17427107787470036, 'Total loss': 0.17427107787470036}
2023-01-03 23:27:46,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:46,970 INFO:     Epoch: 89
2023-01-03 23:27:48,590 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45053619841734566, 'Total loss': 0.45053619841734566} | train loss {'Reaction outcome loss': 0.17442557929029714, 'Total loss': 0.17442557929029714}
2023-01-03 23:27:48,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:48,590 INFO:     Epoch: 90
2023-01-03 23:27:50,224 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4847670614719391, 'Total loss': 0.4847670614719391} | train loss {'Reaction outcome loss': 0.17557496340686013, 'Total loss': 0.17557496340686013}
2023-01-03 23:27:50,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:50,224 INFO:     Epoch: 91
2023-01-03 23:27:51,831 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44147985279560087, 'Total loss': 0.44147985279560087} | train loss {'Reaction outcome loss': 0.17141004537910887, 'Total loss': 0.17141004537910887}
2023-01-03 23:27:51,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:51,831 INFO:     Epoch: 92
2023-01-03 23:27:53,428 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45753070066372553, 'Total loss': 0.45753070066372553} | train loss {'Reaction outcome loss': 0.17184598139684185, 'Total loss': 0.17184598139684185}
2023-01-03 23:27:53,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:53,429 INFO:     Epoch: 93
2023-01-03 23:27:55,030 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4588484883308411, 'Total loss': 0.4588484883308411} | train loss {'Reaction outcome loss': 0.17225791752792682, 'Total loss': 0.17225791752792682}
2023-01-03 23:27:55,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:55,031 INFO:     Epoch: 94
2023-01-03 23:27:56,623 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4677343507607778, 'Total loss': 0.4677343507607778} | train loss {'Reaction outcome loss': 0.1693745980631755, 'Total loss': 0.1693745980631755}
2023-01-03 23:27:56,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:56,624 INFO:     Epoch: 95
2023-01-03 23:27:58,240 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4528919180234273, 'Total loss': 0.4528919180234273} | train loss {'Reaction outcome loss': 0.17009009017762594, 'Total loss': 0.17009009017762594}
2023-01-03 23:27:58,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:58,240 INFO:     Epoch: 96
2023-01-03 23:27:59,859 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4889074772596359, 'Total loss': 0.4889074772596359} | train loss {'Reaction outcome loss': 0.17110010768764355, 'Total loss': 0.17110010768764355}
2023-01-03 23:27:59,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:27:59,859 INFO:     Epoch: 97
2023-01-03 23:28:01,447 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48095049560070036, 'Total loss': 0.48095049560070036} | train loss {'Reaction outcome loss': 0.171171652576458, 'Total loss': 0.171171652576458}
2023-01-03 23:28:01,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:01,447 INFO:     Epoch: 98
2023-01-03 23:28:03,067 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4716057484348615, 'Total loss': 0.4716057484348615} | train loss {'Reaction outcome loss': 0.17124051802503457, 'Total loss': 0.17124051802503457}
2023-01-03 23:28:03,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:03,067 INFO:     Epoch: 99
2023-01-03 23:28:04,663 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4544379154841105, 'Total loss': 0.4544379154841105} | train loss {'Reaction outcome loss': 0.1669168692069302, 'Total loss': 0.1669168692069302}
2023-01-03 23:28:04,663 INFO:     Best model found after epoch 40 of 100.
2023-01-03 23:28:04,663 INFO:   Done with stage: TRAINING
2023-01-03 23:28:04,663 INFO:   Starting stage: EVALUATION
2023-01-03 23:28:04,790 INFO:   Done with stage: EVALUATION
2023-01-03 23:28:04,790 INFO:   Leaving out SEQ value Fold_2
2023-01-03 23:28:04,803 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-03 23:28:04,803 INFO:   Starting stage: FEATURE SCALING
2023-01-03 23:28:05,442 INFO:   Done with stage: FEATURE SCALING
2023-01-03 23:28:05,442 INFO:   Starting stage: SCALING TARGETS
2023-01-03 23:28:05,510 INFO:   Done with stage: SCALING TARGETS
2023-01-03 23:28:05,510 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:28:05,510 INFO:     No hyperparam tuning for this model
2023-01-03 23:28:05,510 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:28:05,510 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 23:28:05,511 INFO:     None feature selector for col prot
2023-01-03 23:28:05,511 INFO:     None feature selector for col prot
2023-01-03 23:28:05,511 INFO:     None feature selector for col prot
2023-01-03 23:28:05,512 INFO:     None feature selector for col chem
2023-01-03 23:28:05,512 INFO:     None feature selector for col chem
2023-01-03 23:28:05,512 INFO:     None feature selector for col chem
2023-01-03 23:28:05,512 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 23:28:05,512 INFO:   Starting stage: BUILD MODEL
2023-01-03 23:28:05,513 INFO:     Number of params in model 70141
2023-01-03 23:28:05,516 INFO:   Done with stage: BUILD MODEL
2023-01-03 23:28:05,516 INFO:   Starting stage: TRAINING
2023-01-03 23:28:05,560 INFO:     Val loss before train {'Reaction outcome loss': 1.1004011591275533, 'Total loss': 1.1004011591275533}
2023-01-03 23:28:05,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:05,560 INFO:     Epoch: 0
2023-01-03 23:28:07,161 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7895625352859497, 'Total loss': 0.7895625352859497} | train loss {'Reaction outcome loss': 0.8748579412481211, 'Total loss': 0.8748579412481211}
2023-01-03 23:28:07,161 INFO:     Found new best model at epoch 0
2023-01-03 23:28:07,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:07,162 INFO:     Epoch: 1
2023-01-03 23:28:08,730 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.635074786345164, 'Total loss': 0.635074786345164} | train loss {'Reaction outcome loss': 0.6196130439639091, 'Total loss': 0.6196130439639091}
2023-01-03 23:28:08,731 INFO:     Found new best model at epoch 1
2023-01-03 23:28:08,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:08,732 INFO:     Epoch: 2
2023-01-03 23:28:10,301 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5938333670298258, 'Total loss': 0.5938333670298258} | train loss {'Reaction outcome loss': 0.5377331701290868, 'Total loss': 0.5377331701290868}
2023-01-03 23:28:10,301 INFO:     Found new best model at epoch 2
2023-01-03 23:28:10,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:10,302 INFO:     Epoch: 3
2023-01-03 23:28:11,890 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5496527175108592, 'Total loss': 0.5496527175108592} | train loss {'Reaction outcome loss': 0.49326438560102975, 'Total loss': 0.49326438560102975}
2023-01-03 23:28:11,890 INFO:     Found new best model at epoch 3
2023-01-03 23:28:11,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:11,891 INFO:     Epoch: 4
2023-01-03 23:28:13,482 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5501323084036509, 'Total loss': 0.5501323084036509} | train loss {'Reaction outcome loss': 0.46360569925856415, 'Total loss': 0.46360569925856415}
2023-01-03 23:28:13,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:13,482 INFO:     Epoch: 5
2023-01-03 23:28:15,063 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5282382130622864, 'Total loss': 0.5282382130622864} | train loss {'Reaction outcome loss': 0.4425699994185545, 'Total loss': 0.4425699994185545}
2023-01-03 23:28:15,064 INFO:     Found new best model at epoch 5
2023-01-03 23:28:15,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:15,065 INFO:     Epoch: 6
2023-01-03 23:28:16,655 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5403928955396017, 'Total loss': 0.5403928955396017} | train loss {'Reaction outcome loss': 0.42424841812492287, 'Total loss': 0.42424841812492287}
2023-01-03 23:28:16,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:16,655 INFO:     Epoch: 7
2023-01-03 23:28:18,259 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5475124915440878, 'Total loss': 0.5475124915440878} | train loss {'Reaction outcome loss': 0.4096922083166394, 'Total loss': 0.4096922083166394}
2023-01-03 23:28:18,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:18,259 INFO:     Epoch: 8
2023-01-03 23:28:19,865 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5004630451401074, 'Total loss': 0.5004630451401074} | train loss {'Reaction outcome loss': 0.3966134716994571, 'Total loss': 0.3966134716994571}
2023-01-03 23:28:19,865 INFO:     Found new best model at epoch 8
2023-01-03 23:28:19,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:19,866 INFO:     Epoch: 9
2023-01-03 23:28:21,467 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5122381587823231, 'Total loss': 0.5122381587823231} | train loss {'Reaction outcome loss': 0.3878511126785383, 'Total loss': 0.3878511126785383}
2023-01-03 23:28:21,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:21,467 INFO:     Epoch: 10
2023-01-03 23:28:23,036 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.512572971979777, 'Total loss': 0.512572971979777} | train loss {'Reaction outcome loss': 0.37813833676768044, 'Total loss': 0.37813833676768044}
2023-01-03 23:28:23,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:23,036 INFO:     Epoch: 11
2023-01-03 23:28:24,596 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49126937985420227, 'Total loss': 0.49126937985420227} | train loss {'Reaction outcome loss': 0.37146489115527076, 'Total loss': 0.37146489115527076}
2023-01-03 23:28:24,596 INFO:     Found new best model at epoch 11
2023-01-03 23:28:24,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:24,597 INFO:     Epoch: 12
2023-01-03 23:28:26,180 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4988944133122762, 'Total loss': 0.4988944133122762} | train loss {'Reaction outcome loss': 0.3648008260957516, 'Total loss': 0.3648008260957516}
2023-01-03 23:28:26,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:26,180 INFO:     Epoch: 13
2023-01-03 23:28:27,775 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49288985729217527, 'Total loss': 0.49288985729217527} | train loss {'Reaction outcome loss': 0.3565842914972862, 'Total loss': 0.3565842914972862}
2023-01-03 23:28:27,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:27,776 INFO:     Epoch: 14
2023-01-03 23:28:29,372 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4957277442018191, 'Total loss': 0.4957277442018191} | train loss {'Reaction outcome loss': 0.34922376818900563, 'Total loss': 0.34922376818900563}
2023-01-03 23:28:29,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:29,372 INFO:     Epoch: 15
2023-01-03 23:28:30,974 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5034271399180095, 'Total loss': 0.5034271399180095} | train loss {'Reaction outcome loss': 0.34117848842139664, 'Total loss': 0.34117848842139664}
2023-01-03 23:28:30,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:30,974 INFO:     Epoch: 16
2023-01-03 23:28:32,564 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5103169858455658, 'Total loss': 0.5103169858455658} | train loss {'Reaction outcome loss': 0.33723797556692664, 'Total loss': 0.33723797556692664}
2023-01-03 23:28:32,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:32,564 INFO:     Epoch: 17
2023-01-03 23:28:34,173 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5034522632757823, 'Total loss': 0.5034522632757823} | train loss {'Reaction outcome loss': 0.32991284208141103, 'Total loss': 0.32991284208141103}
2023-01-03 23:28:34,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:34,173 INFO:     Epoch: 18
2023-01-03 23:28:35,775 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5068109373251597, 'Total loss': 0.5068109373251597} | train loss {'Reaction outcome loss': 0.3270461229457907, 'Total loss': 0.3270461229457907}
2023-01-03 23:28:35,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:35,775 INFO:     Epoch: 19
2023-01-03 23:28:37,365 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48895296454429626, 'Total loss': 0.48895296454429626} | train loss {'Reaction outcome loss': 0.3197641629644119, 'Total loss': 0.3197641629644119}
2023-01-03 23:28:37,365 INFO:     Found new best model at epoch 19
2023-01-03 23:28:37,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:37,366 INFO:     Epoch: 20
2023-01-03 23:28:38,925 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5077086865901947, 'Total loss': 0.5077086865901947} | train loss {'Reaction outcome loss': 0.3164738217627045, 'Total loss': 0.3164738217627045}
2023-01-03 23:28:38,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:38,927 INFO:     Epoch: 21
2023-01-03 23:28:40,474 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5364749550819397, 'Total loss': 0.5364749550819397} | train loss {'Reaction outcome loss': 0.30890409528774065, 'Total loss': 0.30890409528774065}
2023-01-03 23:28:40,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:40,474 INFO:     Epoch: 22
2023-01-03 23:28:42,073 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4779365027944247, 'Total loss': 0.4779365027944247} | train loss {'Reaction outcome loss': 0.3081120831252885, 'Total loss': 0.3081120831252885}
2023-01-03 23:28:42,073 INFO:     Found new best model at epoch 22
2023-01-03 23:28:42,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:42,074 INFO:     Epoch: 23
2023-01-03 23:28:43,672 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4908516436815262, 'Total loss': 0.4908516436815262} | train loss {'Reaction outcome loss': 0.30399276843688783, 'Total loss': 0.30399276843688783}
2023-01-03 23:28:43,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:43,672 INFO:     Epoch: 24
2023-01-03 23:28:45,249 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4810951630274455, 'Total loss': 0.4810951630274455} | train loss {'Reaction outcome loss': 0.29892002793885497, 'Total loss': 0.29892002793885497}
2023-01-03 23:28:45,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:45,250 INFO:     Epoch: 25
2023-01-03 23:28:46,834 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4839942236741384, 'Total loss': 0.4839942236741384} | train loss {'Reaction outcome loss': 0.2932551232893972, 'Total loss': 0.2932551232893972}
2023-01-03 23:28:46,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:46,834 INFO:     Epoch: 26
2023-01-03 23:28:48,451 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5092858612537384, 'Total loss': 0.5092858612537384} | train loss {'Reaction outcome loss': 0.2920931705212506, 'Total loss': 0.2920931705212506}
2023-01-03 23:28:48,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:48,451 INFO:     Epoch: 27
2023-01-03 23:28:50,041 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47233472764492035, 'Total loss': 0.47233472764492035} | train loss {'Reaction outcome loss': 0.28760571609230806, 'Total loss': 0.28760571609230806}
2023-01-03 23:28:50,041 INFO:     Found new best model at epoch 27
2023-01-03 23:28:50,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:50,042 INFO:     Epoch: 28
2023-01-03 23:28:51,660 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4893104990323385, 'Total loss': 0.4893104990323385} | train loss {'Reaction outcome loss': 0.2836861418301824, 'Total loss': 0.2836861418301824}
2023-01-03 23:28:51,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:51,660 INFO:     Epoch: 29
2023-01-03 23:28:53,249 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4909841865301132, 'Total loss': 0.4909841865301132} | train loss {'Reaction outcome loss': 0.2789776755673607, 'Total loss': 0.2789776755673607}
2023-01-03 23:28:53,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:53,249 INFO:     Epoch: 30
2023-01-03 23:28:54,837 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4866704126199087, 'Total loss': 0.4866704126199087} | train loss {'Reaction outcome loss': 0.2772517936834454, 'Total loss': 0.2772517936834454}
2023-01-03 23:28:54,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:54,837 INFO:     Epoch: 31
2023-01-03 23:28:56,427 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4813969969749451, 'Total loss': 0.4813969969749451} | train loss {'Reaction outcome loss': 0.27167796270146854, 'Total loss': 0.27167796270146854}
2023-01-03 23:28:56,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:56,428 INFO:     Epoch: 32
2023-01-03 23:28:58,012 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.491674542427063, 'Total loss': 0.491674542427063} | train loss {'Reaction outcome loss': 0.2695185556926214, 'Total loss': 0.2695185556926214}
2023-01-03 23:28:58,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:58,013 INFO:     Epoch: 33
2023-01-03 23:28:59,585 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5014235079288483, 'Total loss': 0.5014235079288483} | train loss {'Reaction outcome loss': 0.2660481420474766, 'Total loss': 0.2660481420474766}
2023-01-03 23:28:59,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:28:59,585 INFO:     Epoch: 34
2023-01-03 23:29:01,176 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4730029731988907, 'Total loss': 0.4730029731988907} | train loss {'Reaction outcome loss': 0.26452715240799596, 'Total loss': 0.26452715240799596}
2023-01-03 23:29:01,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:01,176 INFO:     Epoch: 35
2023-01-03 23:29:02,765 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49903465112050377, 'Total loss': 0.49903465112050377} | train loss {'Reaction outcome loss': 0.2605407945131951, 'Total loss': 0.2605407945131951}
2023-01-03 23:29:02,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:02,766 INFO:     Epoch: 36
2023-01-03 23:29:04,345 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5158902873595556, 'Total loss': 0.5158902873595556} | train loss {'Reaction outcome loss': 0.2573235929148258, 'Total loss': 0.2573235929148258}
2023-01-03 23:29:04,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:04,345 INFO:     Epoch: 37
2023-01-03 23:29:05,948 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.48601842125256856, 'Total loss': 0.48601842125256856} | train loss {'Reaction outcome loss': 0.2577330138887802, 'Total loss': 0.2577330138887802}
2023-01-03 23:29:05,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:05,948 INFO:     Epoch: 38
2023-01-03 23:29:07,513 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49392459193865457, 'Total loss': 0.49392459193865457} | train loss {'Reaction outcome loss': 0.25226319216898757, 'Total loss': 0.25226319216898757}
2023-01-03 23:29:07,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:07,513 INFO:     Epoch: 39
2023-01-03 23:29:09,094 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45802207191785177, 'Total loss': 0.45802207191785177} | train loss {'Reaction outcome loss': 0.24969714964284515, 'Total loss': 0.24969714964284515}
2023-01-03 23:29:09,095 INFO:     Found new best model at epoch 39
2023-01-03 23:29:09,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:09,096 INFO:     Epoch: 40
2023-01-03 23:29:10,684 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4849175741275152, 'Total loss': 0.4849175741275152} | train loss {'Reaction outcome loss': 0.25238673220368196, 'Total loss': 0.25238673220368196}
2023-01-03 23:29:10,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:10,684 INFO:     Epoch: 41
2023-01-03 23:29:12,269 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4907062699397405, 'Total loss': 0.4907062699397405} | train loss {'Reaction outcome loss': 0.24440895465549325, 'Total loss': 0.24440895465549325}
2023-01-03 23:29:12,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:12,269 INFO:     Epoch: 42
2023-01-03 23:29:13,846 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47192476789156595, 'Total loss': 0.47192476789156595} | train loss {'Reaction outcome loss': 0.24562599292419252, 'Total loss': 0.24562599292419252}
2023-01-03 23:29:13,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:13,846 INFO:     Epoch: 43
2023-01-03 23:29:15,431 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48743450244267783, 'Total loss': 0.48743450244267783} | train loss {'Reaction outcome loss': 0.2443857184563675, 'Total loss': 0.2443857184563675}
2023-01-03 23:29:15,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:15,432 INFO:     Epoch: 44
2023-01-03 23:29:17,009 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4921382308006287, 'Total loss': 0.4921382308006287} | train loss {'Reaction outcome loss': 0.23922646565050104, 'Total loss': 0.23922646565050104}
2023-01-03 23:29:17,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:17,010 INFO:     Epoch: 45
2023-01-03 23:29:18,597 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4889622628688812, 'Total loss': 0.4889622628688812} | train loss {'Reaction outcome loss': 0.2398468173605247, 'Total loss': 0.2398468173605247}
2023-01-03 23:29:18,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:18,597 INFO:     Epoch: 46
2023-01-03 23:29:20,181 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49838831424713137, 'Total loss': 0.49838831424713137} | train loss {'Reaction outcome loss': 0.2389002213540086, 'Total loss': 0.2389002213540086}
2023-01-03 23:29:20,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:20,182 INFO:     Epoch: 47
2023-01-03 23:29:21,743 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.49691517154375714, 'Total loss': 0.49691517154375714} | train loss {'Reaction outcome loss': 0.2335895660204174, 'Total loss': 0.2335895660204174}
2023-01-03 23:29:21,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:21,744 INFO:     Epoch: 48
2023-01-03 23:29:23,363 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4847819303472837, 'Total loss': 0.4847819303472837} | train loss {'Reaction outcome loss': 0.23363988000872363, 'Total loss': 0.23363988000872363}
2023-01-03 23:29:23,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:23,363 INFO:     Epoch: 49
2023-01-03 23:29:24,982 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5014681587616603, 'Total loss': 0.5014681587616603} | train loss {'Reaction outcome loss': 0.23267634297265624, 'Total loss': 0.23267634297265624}
2023-01-03 23:29:24,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:24,982 INFO:     Epoch: 50
2023-01-03 23:29:26,585 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48804119825363157, 'Total loss': 0.48804119825363157} | train loss {'Reaction outcome loss': 0.22979688110088345, 'Total loss': 0.22979688110088345}
2023-01-03 23:29:26,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:26,586 INFO:     Epoch: 51
2023-01-03 23:29:28,196 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49161741336186726, 'Total loss': 0.49161741336186726} | train loss {'Reaction outcome loss': 0.22696911572159206, 'Total loss': 0.22696911572159206}
2023-01-03 23:29:28,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:28,197 INFO:     Epoch: 52
2023-01-03 23:29:29,764 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4834453682104746, 'Total loss': 0.4834453682104746} | train loss {'Reaction outcome loss': 0.2292865195522343, 'Total loss': 0.2292865195522343}
2023-01-03 23:29:29,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:29,764 INFO:     Epoch: 53
2023-01-03 23:29:31,325 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.49483534892400105, 'Total loss': 0.49483534892400105} | train loss {'Reaction outcome loss': 0.22398360718014468, 'Total loss': 0.22398360718014468}
2023-01-03 23:29:31,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:31,325 INFO:     Epoch: 54
2023-01-03 23:29:32,935 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5052039076884588, 'Total loss': 0.5052039076884588} | train loss {'Reaction outcome loss': 0.22303835399802366, 'Total loss': 0.22303835399802366}
2023-01-03 23:29:32,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:32,935 INFO:     Epoch: 55
2023-01-03 23:29:34,509 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5055823375781378, 'Total loss': 0.5055823375781378} | train loss {'Reaction outcome loss': 0.22074858207989784, 'Total loss': 0.22074858207989784}
2023-01-03 23:29:34,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:34,509 INFO:     Epoch: 56
2023-01-03 23:29:36,116 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5238147834936778, 'Total loss': 0.5238147834936778} | train loss {'Reaction outcome loss': 0.22083573970590195, 'Total loss': 0.22083573970590195}
2023-01-03 23:29:36,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:36,116 INFO:     Epoch: 57
2023-01-03 23:29:37,727 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4877513309319814, 'Total loss': 0.4877513309319814} | train loss {'Reaction outcome loss': 0.22019438786826429, 'Total loss': 0.22019438786826429}
2023-01-03 23:29:37,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:37,727 INFO:     Epoch: 58
2023-01-03 23:29:39,321 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4913563072681427, 'Total loss': 0.4913563072681427} | train loss {'Reaction outcome loss': 0.2177012603267701, 'Total loss': 0.2177012603267701}
2023-01-03 23:29:39,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:39,321 INFO:     Epoch: 59
2023-01-03 23:29:40,942 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5412029097477595, 'Total loss': 0.5412029097477595} | train loss {'Reaction outcome loss': 0.21398001362018995, 'Total loss': 0.21398001362018995}
2023-01-03 23:29:40,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:40,943 INFO:     Epoch: 60
2023-01-03 23:29:42,563 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4963616947333018, 'Total loss': 0.4963616947333018} | train loss {'Reaction outcome loss': 0.2173024835948744, 'Total loss': 0.2173024835948744}
2023-01-03 23:29:42,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:42,563 INFO:     Epoch: 61
2023-01-03 23:29:44,157 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5072666257619858, 'Total loss': 0.5072666257619858} | train loss {'Reaction outcome loss': 0.21087777867478175, 'Total loss': 0.21087777867478175}
2023-01-03 23:29:44,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:44,157 INFO:     Epoch: 62
2023-01-03 23:29:45,769 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5091274936993917, 'Total loss': 0.5091274936993917} | train loss {'Reaction outcome loss': 0.21043757992341136, 'Total loss': 0.21043757992341136}
2023-01-03 23:29:45,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:45,770 INFO:     Epoch: 63
2023-01-03 23:29:47,381 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5275987486044565, 'Total loss': 0.5275987486044565} | train loss {'Reaction outcome loss': 0.21151580140810378, 'Total loss': 0.21151580140810378}
2023-01-03 23:29:47,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:47,381 INFO:     Epoch: 64
2023-01-03 23:29:48,989 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.504800162712733, 'Total loss': 0.504800162712733} | train loss {'Reaction outcome loss': 0.21126391268233313, 'Total loss': 0.21126391268233313}
2023-01-03 23:29:48,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:48,989 INFO:     Epoch: 65
2023-01-03 23:29:50,603 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5043909500042597, 'Total loss': 0.5043909500042597} | train loss {'Reaction outcome loss': 0.21057872025527224, 'Total loss': 0.21057872025527224}
2023-01-03 23:29:50,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:50,604 INFO:     Epoch: 66
2023-01-03 23:29:52,166 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5329756319522858, 'Total loss': 0.5329756319522858} | train loss {'Reaction outcome loss': 0.20638055287736612, 'Total loss': 0.20638055287736612}
2023-01-03 23:29:52,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:52,167 INFO:     Epoch: 67
2023-01-03 23:29:53,775 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5237924814224243, 'Total loss': 0.5237924814224243} | train loss {'Reaction outcome loss': 0.20638896177529636, 'Total loss': 0.20638896177529636}
2023-01-03 23:29:53,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:53,775 INFO:     Epoch: 68
2023-01-03 23:29:55,382 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5252686043580373, 'Total loss': 0.5252686043580373} | train loss {'Reaction outcome loss': 0.20370934911779243, 'Total loss': 0.20370934911779243}
2023-01-03 23:29:55,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:55,382 INFO:     Epoch: 69
2023-01-03 23:29:56,999 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4926171501477559, 'Total loss': 0.4926171501477559} | train loss {'Reaction outcome loss': 0.2032397700827161, 'Total loss': 0.2032397700827161}
2023-01-03 23:29:56,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:56,999 INFO:     Epoch: 70
2023-01-03 23:29:58,560 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5058018505573273, 'Total loss': 0.5058018505573273} | train loss {'Reaction outcome loss': 0.2039688374493679, 'Total loss': 0.2039688374493679}
2023-01-03 23:29:58,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:29:58,561 INFO:     Epoch: 71
2023-01-03 23:30:00,143 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5181756297747294, 'Total loss': 0.5181756297747294} | train loss {'Reaction outcome loss': 0.20128380436531818, 'Total loss': 0.20128380436531818}
2023-01-03 23:30:00,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:00,143 INFO:     Epoch: 72
2023-01-03 23:30:01,719 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.492785515387853, 'Total loss': 0.492785515387853} | train loss {'Reaction outcome loss': 0.20143147415216386, 'Total loss': 0.20143147415216386}
2023-01-03 23:30:01,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:01,720 INFO:     Epoch: 73
2023-01-03 23:30:03,328 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49847245713075, 'Total loss': 0.49847245713075} | train loss {'Reaction outcome loss': 0.19996487656540243, 'Total loss': 0.19996487656540243}
2023-01-03 23:30:03,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:03,329 INFO:     Epoch: 74
2023-01-03 23:30:04,895 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5258619368076325, 'Total loss': 0.5258619368076325} | train loss {'Reaction outcome loss': 0.19959415113349466, 'Total loss': 0.19959415113349466}
2023-01-03 23:30:04,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:04,896 INFO:     Epoch: 75
2023-01-03 23:30:06,454 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5345002710819244, 'Total loss': 0.5345002710819244} | train loss {'Reaction outcome loss': 0.19904884806813766, 'Total loss': 0.19904884806813766}
2023-01-03 23:30:06,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:06,454 INFO:     Epoch: 76
2023-01-03 23:30:08,065 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5585891524950664, 'Total loss': 0.5585891524950664} | train loss {'Reaction outcome loss': 0.1972124674289494, 'Total loss': 0.1972124674289494}
2023-01-03 23:30:08,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:08,066 INFO:     Epoch: 77
2023-01-03 23:30:09,642 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5495542248090108, 'Total loss': 0.5495542248090108} | train loss {'Reaction outcome loss': 0.1957795734306539, 'Total loss': 0.1957795734306539}
2023-01-03 23:30:09,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:09,642 INFO:     Epoch: 78
2023-01-03 23:30:11,230 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5193771481513977, 'Total loss': 0.5193771481513977} | train loss {'Reaction outcome loss': 0.19432900485711813, 'Total loss': 0.19432900485711813}
2023-01-03 23:30:11,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:11,230 INFO:     Epoch: 79
2023-01-03 23:30:12,850 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.506292262673378, 'Total loss': 0.506292262673378} | train loss {'Reaction outcome loss': 0.19368265826173509, 'Total loss': 0.19368265826173509}
2023-01-03 23:30:12,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:12,850 INFO:     Epoch: 80
2023-01-03 23:30:14,461 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5054765025774638, 'Total loss': 0.5054765025774638} | train loss {'Reaction outcome loss': 0.19271373047228277, 'Total loss': 0.19271373047228277}
2023-01-03 23:30:14,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:14,461 INFO:     Epoch: 81
2023-01-03 23:30:16,038 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.514321893453598, 'Total loss': 0.514321893453598} | train loss {'Reaction outcome loss': 0.19144969000854958, 'Total loss': 0.19144969000854958}
2023-01-03 23:30:16,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:16,040 INFO:     Epoch: 82
2023-01-03 23:30:17,609 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5353339513142904, 'Total loss': 0.5353339513142904} | train loss {'Reaction outcome loss': 0.18986592678366787, 'Total loss': 0.18986592678366787}
2023-01-03 23:30:17,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:17,609 INFO:     Epoch: 83
2023-01-03 23:30:19,201 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5412980318069458, 'Total loss': 0.5412980318069458} | train loss {'Reaction outcome loss': 0.1893014859707251, 'Total loss': 0.1893014859707251}
2023-01-03 23:30:19,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:19,201 INFO:     Epoch: 84
2023-01-03 23:30:20,783 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5421360025803248, 'Total loss': 0.5421360025803248} | train loss {'Reaction outcome loss': 0.18880296687520767, 'Total loss': 0.18880296687520767}
2023-01-03 23:30:20,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:20,784 INFO:     Epoch: 85
2023-01-03 23:30:22,367 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5142385562260946, 'Total loss': 0.5142385562260946} | train loss {'Reaction outcome loss': 0.19002562785779473, 'Total loss': 0.19002562785779473}
2023-01-03 23:30:22,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:22,368 INFO:     Epoch: 86
2023-01-03 23:30:23,950 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5237170636653901, 'Total loss': 0.5237170636653901} | train loss {'Reaction outcome loss': 0.18698567268268687, 'Total loss': 0.18698567268268687}
2023-01-03 23:30:23,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:23,950 INFO:     Epoch: 87
2023-01-03 23:30:25,516 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5318335811297099, 'Total loss': 0.5318335811297099} | train loss {'Reaction outcome loss': 0.18622841348151004, 'Total loss': 0.18622841348151004}
2023-01-03 23:30:25,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:25,516 INFO:     Epoch: 88
2023-01-03 23:30:27,125 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5267461776733399, 'Total loss': 0.5267461776733399} | train loss {'Reaction outcome loss': 0.18979236300028587, 'Total loss': 0.18979236300028587}
2023-01-03 23:30:27,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:27,125 INFO:     Epoch: 89
2023-01-03 23:30:28,702 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5436597307523091, 'Total loss': 0.5436597307523091} | train loss {'Reaction outcome loss': 0.18523371590804444, 'Total loss': 0.18523371590804444}
2023-01-03 23:30:28,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:28,702 INFO:     Epoch: 90
2023-01-03 23:30:30,284 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5339882036050161, 'Total loss': 0.5339882036050161} | train loss {'Reaction outcome loss': 0.18581868456608622, 'Total loss': 0.18581868456608622}
2023-01-03 23:30:30,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:30,285 INFO:     Epoch: 91
2023-01-03 23:30:31,878 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5384286731481552, 'Total loss': 0.5384286731481552} | train loss {'Reaction outcome loss': 0.184166724514896, 'Total loss': 0.184166724514896}
2023-01-03 23:30:31,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:31,878 INFO:     Epoch: 92
2023-01-03 23:30:33,455 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5156199753284454, 'Total loss': 0.5156199753284454} | train loss {'Reaction outcome loss': 0.18536663449702473, 'Total loss': 0.18536663449702473}
2023-01-03 23:30:33,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:33,455 INFO:     Epoch: 93
2023-01-03 23:30:35,038 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.520109415302674, 'Total loss': 0.520109415302674} | train loss {'Reaction outcome loss': 0.18264073481524948, 'Total loss': 0.18264073481524948}
2023-01-03 23:30:35,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:35,039 INFO:     Epoch: 94
2023-01-03 23:30:36,623 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5213450868924459, 'Total loss': 0.5213450868924459} | train loss {'Reaction outcome loss': 0.18403219040755156, 'Total loss': 0.18403219040755156}
2023-01-03 23:30:36,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:36,623 INFO:     Epoch: 95
2023-01-03 23:30:38,208 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5722251296043396, 'Total loss': 0.5722251296043396} | train loss {'Reaction outcome loss': 0.1809894603942215, 'Total loss': 0.1809894603942215}
2023-01-03 23:30:38,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:38,208 INFO:     Epoch: 96
2023-01-03 23:30:39,816 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5265873392422994, 'Total loss': 0.5265873392422994} | train loss {'Reaction outcome loss': 0.18071401865649833, 'Total loss': 0.18071401865649833}
2023-01-03 23:30:39,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:39,816 INFO:     Epoch: 97
2023-01-03 23:30:41,435 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5175964613755544, 'Total loss': 0.5175964613755544} | train loss {'Reaction outcome loss': 0.18020644136126676, 'Total loss': 0.18020644136126676}
2023-01-03 23:30:41,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:41,436 INFO:     Epoch: 98
2023-01-03 23:30:43,023 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5376184622446696, 'Total loss': 0.5376184622446696} | train loss {'Reaction outcome loss': 0.17960761099659506, 'Total loss': 0.17960761099659506}
2023-01-03 23:30:43,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:43,023 INFO:     Epoch: 99
2023-01-03 23:30:44,631 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5307803710301717, 'Total loss': 0.5307803710301717} | train loss {'Reaction outcome loss': 0.1801975574208437, 'Total loss': 0.1801975574208437}
2023-01-03 23:30:44,631 INFO:     Best model found after epoch 40 of 100.
2023-01-03 23:30:44,631 INFO:   Done with stage: TRAINING
2023-01-03 23:30:44,631 INFO:   Starting stage: EVALUATION
2023-01-03 23:30:44,766 INFO:   Done with stage: EVALUATION
2023-01-03 23:30:44,766 INFO:   Leaving out SEQ value Fold_3
2023-01-03 23:30:44,779 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-03 23:30:44,779 INFO:   Starting stage: FEATURE SCALING
2023-01-03 23:30:45,415 INFO:   Done with stage: FEATURE SCALING
2023-01-03 23:30:45,415 INFO:   Starting stage: SCALING TARGETS
2023-01-03 23:30:45,483 INFO:   Done with stage: SCALING TARGETS
2023-01-03 23:30:45,484 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:30:45,484 INFO:     No hyperparam tuning for this model
2023-01-03 23:30:45,484 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:30:45,484 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 23:30:45,484 INFO:     None feature selector for col prot
2023-01-03 23:30:45,485 INFO:     None feature selector for col prot
2023-01-03 23:30:45,485 INFO:     None feature selector for col prot
2023-01-03 23:30:45,485 INFO:     None feature selector for col chem
2023-01-03 23:30:45,485 INFO:     None feature selector for col chem
2023-01-03 23:30:45,485 INFO:     None feature selector for col chem
2023-01-03 23:30:45,485 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 23:30:45,485 INFO:   Starting stage: BUILD MODEL
2023-01-03 23:30:45,487 INFO:     Number of params in model 70141
2023-01-03 23:30:45,490 INFO:   Done with stage: BUILD MODEL
2023-01-03 23:30:45,490 INFO:   Starting stage: TRAINING
2023-01-03 23:30:45,532 INFO:     Val loss before train {'Reaction outcome loss': 0.9631373484929403, 'Total loss': 0.9631373484929403}
2023-01-03 23:30:45,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:45,533 INFO:     Epoch: 0
2023-01-03 23:30:47,109 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6774050613244375, 'Total loss': 0.6774050613244375} | train loss {'Reaction outcome loss': 0.8620528023103218, 'Total loss': 0.8620528023103218}
2023-01-03 23:30:47,110 INFO:     Found new best model at epoch 0
2023-01-03 23:30:47,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:47,111 INFO:     Epoch: 1
2023-01-03 23:30:48,688 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5856958985328674, 'Total loss': 0.5856958985328674} | train loss {'Reaction outcome loss': 0.6047722918319178, 'Total loss': 0.6047722918319178}
2023-01-03 23:30:48,688 INFO:     Found new best model at epoch 1
2023-01-03 23:30:48,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:48,689 INFO:     Epoch: 2
2023-01-03 23:30:50,268 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5516599078973135, 'Total loss': 0.5516599078973135} | train loss {'Reaction outcome loss': 0.5222284963061085, 'Total loss': 0.5222284963061085}
2023-01-03 23:30:50,268 INFO:     Found new best model at epoch 2
2023-01-03 23:30:50,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:50,269 INFO:     Epoch: 3
2023-01-03 23:30:51,857 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5489704648653666, 'Total loss': 0.5489704648653666} | train loss {'Reaction outcome loss': 0.484230780121171, 'Total loss': 0.484230780121171}
2023-01-03 23:30:51,857 INFO:     Found new best model at epoch 3
2023-01-03 23:30:51,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:51,858 INFO:     Epoch: 4
2023-01-03 23:30:53,443 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5252868274847666, 'Total loss': 0.5252868274847666} | train loss {'Reaction outcome loss': 0.45728304714728624, 'Total loss': 0.45728304714728624}
2023-01-03 23:30:53,444 INFO:     Found new best model at epoch 4
2023-01-03 23:30:53,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:53,445 INFO:     Epoch: 5
2023-01-03 23:30:55,002 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5113211075464884, 'Total loss': 0.5113211075464884} | train loss {'Reaction outcome loss': 0.44173863584742007, 'Total loss': 0.44173863584742007}
2023-01-03 23:30:55,003 INFO:     Found new best model at epoch 5
2023-01-03 23:30:55,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:55,003 INFO:     Epoch: 6
2023-01-03 23:30:56,581 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4937777131795883, 'Total loss': 0.4937777131795883} | train loss {'Reaction outcome loss': 0.4211636790971616, 'Total loss': 0.4211636790971616}
2023-01-03 23:30:56,581 INFO:     Found new best model at epoch 6
2023-01-03 23:30:56,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:56,582 INFO:     Epoch: 7
2023-01-03 23:30:58,194 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5107312341531117, 'Total loss': 0.5107312341531117} | train loss {'Reaction outcome loss': 0.4054384319582483, 'Total loss': 0.4054384319582483}
2023-01-03 23:30:58,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:58,194 INFO:     Epoch: 8
2023-01-03 23:30:59,785 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5093939433495204, 'Total loss': 0.5093939433495204} | train loss {'Reaction outcome loss': 0.3962174436766586, 'Total loss': 0.3962174436766586}
2023-01-03 23:30:59,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:30:59,785 INFO:     Epoch: 9
2023-01-03 23:31:01,354 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4905095020929972, 'Total loss': 0.4905095020929972} | train loss {'Reaction outcome loss': 0.3835763583648882, 'Total loss': 0.3835763583648882}
2023-01-03 23:31:01,354 INFO:     Found new best model at epoch 9
2023-01-03 23:31:01,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:01,355 INFO:     Epoch: 10
2023-01-03 23:31:02,926 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47917882800102235, 'Total loss': 0.47917882800102235} | train loss {'Reaction outcome loss': 0.3728867791347451, 'Total loss': 0.3728867791347451}
2023-01-03 23:31:02,926 INFO:     Found new best model at epoch 10
2023-01-03 23:31:02,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:02,927 INFO:     Epoch: 11
2023-01-03 23:31:04,487 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4937640885512034, 'Total loss': 0.4937640885512034} | train loss {'Reaction outcome loss': 0.36866404034279204, 'Total loss': 0.36866404034279204}
2023-01-03 23:31:04,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:04,487 INFO:     Epoch: 12
2023-01-03 23:31:06,086 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4649913728237152, 'Total loss': 0.4649913728237152} | train loss {'Reaction outcome loss': 0.3607342576150929, 'Total loss': 0.3607342576150929}
2023-01-03 23:31:06,087 INFO:     Found new best model at epoch 12
2023-01-03 23:31:06,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:06,088 INFO:     Epoch: 13
2023-01-03 23:31:07,666 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47656708359718325, 'Total loss': 0.47656708359718325} | train loss {'Reaction outcome loss': 0.3529860284520593, 'Total loss': 0.3529860284520593}
2023-01-03 23:31:07,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:07,666 INFO:     Epoch: 14
2023-01-03 23:31:09,225 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4780395527680715, 'Total loss': 0.4780395527680715} | train loss {'Reaction outcome loss': 0.34588827946028866, 'Total loss': 0.34588827946028866}
2023-01-03 23:31:09,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:09,225 INFO:     Epoch: 15
2023-01-03 23:31:10,824 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4792951683203379, 'Total loss': 0.4792951683203379} | train loss {'Reaction outcome loss': 0.33675407188443035, 'Total loss': 0.33675407188443035}
2023-01-03 23:31:10,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:10,825 INFO:     Epoch: 16
2023-01-03 23:31:12,428 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4805582374334335, 'Total loss': 0.4805582374334335} | train loss {'Reaction outcome loss': 0.3321462083444163, 'Total loss': 0.3321462083444163}
2023-01-03 23:31:12,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:12,428 INFO:     Epoch: 17
2023-01-03 23:31:14,014 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49254751404126484, 'Total loss': 0.49254751404126484} | train loss {'Reaction outcome loss': 0.327006927995018, 'Total loss': 0.327006927995018}
2023-01-03 23:31:14,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:14,014 INFO:     Epoch: 18
2023-01-03 23:31:15,621 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46774802009264627, 'Total loss': 0.46774802009264627} | train loss {'Reaction outcome loss': 0.32010071328926437, 'Total loss': 0.32010071328926437}
2023-01-03 23:31:15,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:15,621 INFO:     Epoch: 19
2023-01-03 23:31:17,201 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47664596935113274, 'Total loss': 0.47664596935113274} | train loss {'Reaction outcome loss': 0.3156784767414624, 'Total loss': 0.3156784767414624}
2023-01-03 23:31:17,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:17,201 INFO:     Epoch: 20
2023-01-03 23:31:18,761 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4853430946667989, 'Total loss': 0.4853430946667989} | train loss {'Reaction outcome loss': 0.3087359526818925, 'Total loss': 0.3087359526818925}
2023-01-03 23:31:18,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:18,761 INFO:     Epoch: 21
2023-01-03 23:31:20,366 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4580532401800156, 'Total loss': 0.4580532401800156} | train loss {'Reaction outcome loss': 0.30540598950761577, 'Total loss': 0.30540598950761577}
2023-01-03 23:31:20,366 INFO:     Found new best model at epoch 21
2023-01-03 23:31:20,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:20,367 INFO:     Epoch: 22
2023-01-03 23:31:21,926 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46522955000400545, 'Total loss': 0.46522955000400545} | train loss {'Reaction outcome loss': 0.29985313545980735, 'Total loss': 0.29985313545980735}
2023-01-03 23:31:21,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:21,926 INFO:     Epoch: 23
2023-01-03 23:31:23,537 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4386981103569269, 'Total loss': 0.4386981103569269} | train loss {'Reaction outcome loss': 0.29380466966401964, 'Total loss': 0.29380466966401964}
2023-01-03 23:31:23,538 INFO:     Found new best model at epoch 23
2023-01-03 23:31:23,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:23,539 INFO:     Epoch: 24
2023-01-03 23:31:25,115 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47250694036483765, 'Total loss': 0.47250694036483765} | train loss {'Reaction outcome loss': 0.2905551932015262, 'Total loss': 0.2905551932015262}
2023-01-03 23:31:25,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:25,116 INFO:     Epoch: 25
2023-01-03 23:31:26,711 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4637542227904002, 'Total loss': 0.4637542227904002} | train loss {'Reaction outcome loss': 0.2878880525901641, 'Total loss': 0.2878880525901641}
2023-01-03 23:31:26,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:26,712 INFO:     Epoch: 26
2023-01-03 23:31:28,275 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4597103108962377, 'Total loss': 0.4597103108962377} | train loss {'Reaction outcome loss': 0.28337520429175417, 'Total loss': 0.28337520429175417}
2023-01-03 23:31:28,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:28,276 INFO:     Epoch: 27
2023-01-03 23:31:29,849 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4520494967699051, 'Total loss': 0.4520494967699051} | train loss {'Reaction outcome loss': 0.2790526689299734, 'Total loss': 0.2790526689299734}
2023-01-03 23:31:29,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:29,850 INFO:     Epoch: 28
2023-01-03 23:31:31,424 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46710248390833536, 'Total loss': 0.46710248390833536} | train loss {'Reaction outcome loss': 0.27735221822619877, 'Total loss': 0.27735221822619877}
2023-01-03 23:31:31,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:31,425 INFO:     Epoch: 29
2023-01-03 23:31:33,019 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4293097178141276, 'Total loss': 0.4293097178141276} | train loss {'Reaction outcome loss': 0.27387306350709756, 'Total loss': 0.27387306350709756}
2023-01-03 23:31:33,019 INFO:     Found new best model at epoch 29
2023-01-03 23:31:33,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:33,020 INFO:     Epoch: 30
2023-01-03 23:31:34,588 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.443834321697553, 'Total loss': 0.443834321697553} | train loss {'Reaction outcome loss': 0.27081922680521625, 'Total loss': 0.27081922680521625}
2023-01-03 23:31:34,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:34,588 INFO:     Epoch: 31
2023-01-03 23:31:36,147 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4426663488149643, 'Total loss': 0.4426663488149643} | train loss {'Reaction outcome loss': 0.26788023987532533, 'Total loss': 0.26788023987532533}
2023-01-03 23:31:36,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:36,147 INFO:     Epoch: 32
2023-01-03 23:31:37,721 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45734503070513405, 'Total loss': 0.45734503070513405} | train loss {'Reaction outcome loss': 0.2629975163865657, 'Total loss': 0.2629975163865657}
2023-01-03 23:31:37,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:37,721 INFO:     Epoch: 33
2023-01-03 23:31:39,294 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47013702392578127, 'Total loss': 0.47013702392578127} | train loss {'Reaction outcome loss': 0.2609603694015807, 'Total loss': 0.2609603694015807}
2023-01-03 23:31:39,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:39,294 INFO:     Epoch: 34
2023-01-03 23:31:40,854 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4786552598079046, 'Total loss': 0.4786552598079046} | train loss {'Reaction outcome loss': 0.2581430135683699, 'Total loss': 0.2581430135683699}
2023-01-03 23:31:40,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:40,854 INFO:     Epoch: 35
2023-01-03 23:31:42,428 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4779041697581609, 'Total loss': 0.4779041697581609} | train loss {'Reaction outcome loss': 0.254994470284972, 'Total loss': 0.254994470284972}
2023-01-03 23:31:42,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:42,429 INFO:     Epoch: 36
2023-01-03 23:31:44,001 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4880516101916631, 'Total loss': 0.4880516101916631} | train loss {'Reaction outcome loss': 0.25216502343191877, 'Total loss': 0.25216502343191877}
2023-01-03 23:31:44,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:44,001 INFO:     Epoch: 37
2023-01-03 23:31:45,558 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4645473162333171, 'Total loss': 0.4645473162333171} | train loss {'Reaction outcome loss': 0.24970251974059549, 'Total loss': 0.24970251974059549}
2023-01-03 23:31:45,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:45,558 INFO:     Epoch: 38
2023-01-03 23:31:47,143 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4737897336483002, 'Total loss': 0.4737897336483002} | train loss {'Reaction outcome loss': 0.24702165330395157, 'Total loss': 0.24702165330395157}
2023-01-03 23:31:47,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:47,143 INFO:     Epoch: 39
2023-01-03 23:31:48,725 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4557644988099734, 'Total loss': 0.4557644988099734} | train loss {'Reaction outcome loss': 0.24376894855673933, 'Total loss': 0.24376894855673933}
2023-01-03 23:31:48,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:48,725 INFO:     Epoch: 40
2023-01-03 23:31:50,336 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45550034642219545, 'Total loss': 0.45550034642219545} | train loss {'Reaction outcome loss': 0.24313025884057357, 'Total loss': 0.24313025884057357}
2023-01-03 23:31:50,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:50,337 INFO:     Epoch: 41
2023-01-03 23:31:51,938 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43291652351617815, 'Total loss': 0.43291652351617815} | train loss {'Reaction outcome loss': 0.2408008717082359, 'Total loss': 0.2408008717082359}
2023-01-03 23:31:51,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:51,938 INFO:     Epoch: 42
2023-01-03 23:31:53,538 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45512977639834085, 'Total loss': 0.45512977639834085} | train loss {'Reaction outcome loss': 0.23996775979414964, 'Total loss': 0.23996775979414964}
2023-01-03 23:31:53,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:53,539 INFO:     Epoch: 43
2023-01-03 23:31:55,103 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43014510671297707, 'Total loss': 0.43014510671297707} | train loss {'Reaction outcome loss': 0.2371851945920223, 'Total loss': 0.2371851945920223}
2023-01-03 23:31:55,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:55,103 INFO:     Epoch: 44
2023-01-03 23:31:56,678 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4403890649477641, 'Total loss': 0.4403890649477641} | train loss {'Reaction outcome loss': 0.23262034887413838, 'Total loss': 0.23262034887413838}
2023-01-03 23:31:56,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:56,678 INFO:     Epoch: 45
2023-01-03 23:31:58,238 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4318403661251068, 'Total loss': 0.4318403661251068} | train loss {'Reaction outcome loss': 0.23089876472131238, 'Total loss': 0.23089876472131238}
2023-01-03 23:31:58,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:58,239 INFO:     Epoch: 46
2023-01-03 23:31:59,815 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44210183024406435, 'Total loss': 0.44210183024406435} | train loss {'Reaction outcome loss': 0.22672246648988006, 'Total loss': 0.22672246648988006}
2023-01-03 23:31:59,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:31:59,816 INFO:     Epoch: 47
2023-01-03 23:32:01,397 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4610146403312683, 'Total loss': 0.4610146403312683} | train loss {'Reaction outcome loss': 0.22756279334971757, 'Total loss': 0.22756279334971757}
2023-01-03 23:32:01,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:01,397 INFO:     Epoch: 48
2023-01-03 23:32:02,969 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4532054901123047, 'Total loss': 0.4532054901123047} | train loss {'Reaction outcome loss': 0.22456311537021081, 'Total loss': 0.22456311537021081}
2023-01-03 23:32:02,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:02,969 INFO:     Epoch: 49
2023-01-03 23:32:04,567 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4348261187473933, 'Total loss': 0.4348261187473933} | train loss {'Reaction outcome loss': 0.22218204177779594, 'Total loss': 0.22218204177779594}
2023-01-03 23:32:04,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:04,568 INFO:     Epoch: 50
2023-01-03 23:32:06,146 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45951911211013796, 'Total loss': 0.45951911211013796} | train loss {'Reaction outcome loss': 0.22457651802144207, 'Total loss': 0.22457651802144207}
2023-01-03 23:32:06,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:06,147 INFO:     Epoch: 51
2023-01-03 23:32:07,739 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4356064478556315, 'Total loss': 0.4356064478556315} | train loss {'Reaction outcome loss': 0.22254371083590574, 'Total loss': 0.22254371083590574}
2023-01-03 23:32:07,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:07,739 INFO:     Epoch: 52
2023-01-03 23:32:09,349 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45816361904144287, 'Total loss': 0.45816361904144287} | train loss {'Reaction outcome loss': 0.2195584333805374, 'Total loss': 0.2195584333805374}
2023-01-03 23:32:09,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:09,349 INFO:     Epoch: 53
2023-01-03 23:32:10,947 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47196182211240134, 'Total loss': 0.47196182211240134} | train loss {'Reaction outcome loss': 0.21812219482474712, 'Total loss': 0.21812219482474712}
2023-01-03 23:32:10,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:10,947 INFO:     Epoch: 54
2023-01-03 23:32:12,528 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45880235036214195, 'Total loss': 0.45880235036214195} | train loss {'Reaction outcome loss': 0.21524145282231844, 'Total loss': 0.21524145282231844}
2023-01-03 23:32:12,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:12,528 INFO:     Epoch: 55
2023-01-03 23:32:14,129 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4618120710055033, 'Total loss': 0.4618120710055033} | train loss {'Reaction outcome loss': 0.2146772582172638, 'Total loss': 0.2146772582172638}
2023-01-03 23:32:14,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:14,129 INFO:     Epoch: 56
2023-01-03 23:32:15,685 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42803524136543275, 'Total loss': 0.42803524136543275} | train loss {'Reaction outcome loss': 0.21487736510924804, 'Total loss': 0.21487736510924804}
2023-01-03 23:32:15,685 INFO:     Found new best model at epoch 56
2023-01-03 23:32:15,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:15,686 INFO:     Epoch: 57
2023-01-03 23:32:17,294 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4644642194112142, 'Total loss': 0.4644642194112142} | train loss {'Reaction outcome loss': 0.21112804008381708, 'Total loss': 0.21112804008381708}
2023-01-03 23:32:17,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:17,295 INFO:     Epoch: 58
2023-01-03 23:32:18,896 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44640846451123556, 'Total loss': 0.44640846451123556} | train loss {'Reaction outcome loss': 0.2086672404228331, 'Total loss': 0.2086672404228331}
2023-01-03 23:32:18,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:18,896 INFO:     Epoch: 59
2023-01-03 23:32:20,504 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43676798840363823, 'Total loss': 0.43676798840363823} | train loss {'Reaction outcome loss': 0.21063834180434546, 'Total loss': 0.21063834180434546}
2023-01-03 23:32:20,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:20,505 INFO:     Epoch: 60
2023-01-03 23:32:22,104 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4416262537240982, 'Total loss': 0.4416262537240982} | train loss {'Reaction outcome loss': 0.20564508165621742, 'Total loss': 0.20564508165621742}
2023-01-03 23:32:22,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:22,104 INFO:     Epoch: 61
2023-01-03 23:32:23,708 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45002996027469633, 'Total loss': 0.45002996027469633} | train loss {'Reaction outcome loss': 0.2060219969177421, 'Total loss': 0.2060219969177421}
2023-01-03 23:32:23,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:23,708 INFO:     Epoch: 62
2023-01-03 23:32:25,293 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42633729030688605, 'Total loss': 0.42633729030688605} | train loss {'Reaction outcome loss': 0.20417457426328472, 'Total loss': 0.20417457426328472}
2023-01-03 23:32:25,293 INFO:     Found new best model at epoch 62
2023-01-03 23:32:25,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:25,294 INFO:     Epoch: 63
2023-01-03 23:32:26,882 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4287868400414785, 'Total loss': 0.4287868400414785} | train loss {'Reaction outcome loss': 0.20272284950856323, 'Total loss': 0.20272284950856323}
2023-01-03 23:32:26,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:26,882 INFO:     Epoch: 64
2023-01-03 23:32:28,477 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4337249835332235, 'Total loss': 0.4337249835332235} | train loss {'Reaction outcome loss': 0.2043473036488989, 'Total loss': 0.2043473036488989}
2023-01-03 23:32:28,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:28,478 INFO:     Epoch: 65
2023-01-03 23:32:30,045 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43861866692701973, 'Total loss': 0.43861866692701973} | train loss {'Reaction outcome loss': 0.20117103528135863, 'Total loss': 0.20117103528135863}
2023-01-03 23:32:30,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:30,047 INFO:     Epoch: 66
2023-01-03 23:32:31,629 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43369242747624714, 'Total loss': 0.43369242747624714} | train loss {'Reaction outcome loss': 0.20155059448665097, 'Total loss': 0.20155059448665097}
2023-01-03 23:32:31,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:31,629 INFO:     Epoch: 67
2023-01-03 23:32:33,204 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44086870551109314, 'Total loss': 0.44086870551109314} | train loss {'Reaction outcome loss': 0.20185456416764103, 'Total loss': 0.20185456416764103}
2023-01-03 23:32:33,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:33,204 INFO:     Epoch: 68
2023-01-03 23:32:34,797 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42628846565882367, 'Total loss': 0.42628846565882367} | train loss {'Reaction outcome loss': 0.19962789939081932, 'Total loss': 0.19962789939081932}
2023-01-03 23:32:34,797 INFO:     Found new best model at epoch 68
2023-01-03 23:32:34,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:34,798 INFO:     Epoch: 69
2023-01-03 23:32:36,403 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4368915329376856, 'Total loss': 0.4368915329376856} | train loss {'Reaction outcome loss': 0.19655790328706577, 'Total loss': 0.19655790328706577}
2023-01-03 23:32:36,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:36,404 INFO:     Epoch: 70
2023-01-03 23:32:38,022 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4452664449810982, 'Total loss': 0.4452664449810982} | train loss {'Reaction outcome loss': 0.19335967639372462, 'Total loss': 0.19335967639372462}
2023-01-03 23:32:38,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:38,022 INFO:     Epoch: 71
2023-01-03 23:32:39,597 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4434061100085576, 'Total loss': 0.4434061100085576} | train loss {'Reaction outcome loss': 0.19871266786650424, 'Total loss': 0.19871266786650424}
2023-01-03 23:32:39,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:39,597 INFO:     Epoch: 72
2023-01-03 23:32:41,196 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4503041014075279, 'Total loss': 0.4503041014075279} | train loss {'Reaction outcome loss': 0.19391618980156197, 'Total loss': 0.19391618980156197}
2023-01-03 23:32:41,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:41,196 INFO:     Epoch: 73
2023-01-03 23:32:42,776 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4645952125390371, 'Total loss': 0.4645952125390371} | train loss {'Reaction outcome loss': 0.19421018262977127, 'Total loss': 0.19421018262977127}
2023-01-03 23:32:42,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:42,776 INFO:     Epoch: 74
2023-01-03 23:32:44,393 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48815579116344454, 'Total loss': 0.48815579116344454} | train loss {'Reaction outcome loss': 0.19438445337471508, 'Total loss': 0.19438445337471508}
2023-01-03 23:32:44,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:44,393 INFO:     Epoch: 75
2023-01-03 23:32:46,004 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43750443359216057, 'Total loss': 0.43750443359216057} | train loss {'Reaction outcome loss': 0.1922066979001075, 'Total loss': 0.1922066979001075}
2023-01-03 23:32:46,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:46,004 INFO:     Epoch: 76
2023-01-03 23:32:47,606 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45111016829808553, 'Total loss': 0.45111016829808553} | train loss {'Reaction outcome loss': 0.19373916088852472, 'Total loss': 0.19373916088852472}
2023-01-03 23:32:47,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:47,606 INFO:     Epoch: 77
2023-01-03 23:32:49,168 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.430966513355573, 'Total loss': 0.430966513355573} | train loss {'Reaction outcome loss': 0.19260854098686586, 'Total loss': 0.19260854098686586}
2023-01-03 23:32:49,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:49,169 INFO:     Epoch: 78
2023-01-03 23:32:50,780 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47022357682387034, 'Total loss': 0.47022357682387034} | train loss {'Reaction outcome loss': 0.18855478904711512, 'Total loss': 0.18855478904711512}
2023-01-03 23:32:50,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:50,780 INFO:     Epoch: 79
2023-01-03 23:32:52,347 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4803311149279276, 'Total loss': 0.4803311149279276} | train loss {'Reaction outcome loss': 0.18856659631207312, 'Total loss': 0.18856659631207312}
2023-01-03 23:32:52,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:52,348 INFO:     Epoch: 80
2023-01-03 23:32:53,952 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4597931643327077, 'Total loss': 0.4597931643327077} | train loss {'Reaction outcome loss': 0.18704238929018213, 'Total loss': 0.18704238929018213}
2023-01-03 23:32:53,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:53,952 INFO:     Epoch: 81
2023-01-03 23:32:55,544 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44612649430831275, 'Total loss': 0.44612649430831275} | train loss {'Reaction outcome loss': 0.18619592784607147, 'Total loss': 0.18619592784607147}
2023-01-03 23:32:55,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:55,544 INFO:     Epoch: 82
2023-01-03 23:32:57,123 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4723504145940145, 'Total loss': 0.4723504145940145} | train loss {'Reaction outcome loss': 0.18501741668352714, 'Total loss': 0.18501741668352714}
2023-01-03 23:32:57,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:57,124 INFO:     Epoch: 83
2023-01-03 23:32:58,728 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4832094003756841, 'Total loss': 0.4832094003756841} | train loss {'Reaction outcome loss': 0.183330786411033, 'Total loss': 0.183330786411033}
2023-01-03 23:32:58,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:32:58,729 INFO:     Epoch: 84
2023-01-03 23:33:00,330 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43956152598063153, 'Total loss': 0.43956152598063153} | train loss {'Reaction outcome loss': 0.18295142429133693, 'Total loss': 0.18295142429133693}
2023-01-03 23:33:00,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:00,330 INFO:     Epoch: 85
2023-01-03 23:33:01,923 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4438992977142334, 'Total loss': 0.4438992977142334} | train loss {'Reaction outcome loss': 0.18617305698917136, 'Total loss': 0.18617305698917136}
2023-01-03 23:33:01,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:01,923 INFO:     Epoch: 86
2023-01-03 23:33:03,535 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48473238746325176, 'Total loss': 0.48473238746325176} | train loss {'Reaction outcome loss': 0.18381934018034637, 'Total loss': 0.18381934018034637}
2023-01-03 23:33:03,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:03,535 INFO:     Epoch: 87
2023-01-03 23:33:05,130 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.49541860024134315, 'Total loss': 0.49541860024134315} | train loss {'Reaction outcome loss': 0.18212307511996, 'Total loss': 0.18212307511996}
2023-01-03 23:33:05,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:05,131 INFO:     Epoch: 88
2023-01-03 23:33:06,697 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4448036183913549, 'Total loss': 0.4448036183913549} | train loss {'Reaction outcome loss': 0.17933728351452194, 'Total loss': 0.17933728351452194}
2023-01-03 23:33:06,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:06,697 INFO:     Epoch: 89
2023-01-03 23:33:08,293 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46456841627756756, 'Total loss': 0.46456841627756756} | train loss {'Reaction outcome loss': 0.18388692071258803, 'Total loss': 0.18388692071258803}
2023-01-03 23:33:08,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:08,293 INFO:     Epoch: 90
2023-01-03 23:33:09,883 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46444693704446155, 'Total loss': 0.46444693704446155} | train loss {'Reaction outcome loss': 0.1796887936582277, 'Total loss': 0.1796887936582277}
2023-01-03 23:33:09,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:09,883 INFO:     Epoch: 91
2023-01-03 23:33:11,488 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4716201861699422, 'Total loss': 0.4716201861699422} | train loss {'Reaction outcome loss': 0.1779702246434741, 'Total loss': 0.1779702246434741}
2023-01-03 23:33:11,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:11,489 INFO:     Epoch: 92
2023-01-03 23:33:13,070 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4535793165365855, 'Total loss': 0.4535793165365855} | train loss {'Reaction outcome loss': 0.17692062253262097, 'Total loss': 0.17692062253262097}
2023-01-03 23:33:13,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:13,070 INFO:     Epoch: 93
2023-01-03 23:33:14,641 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4577250083287557, 'Total loss': 0.4577250083287557} | train loss {'Reaction outcome loss': 0.17704575255021945, 'Total loss': 0.17704575255021945}
2023-01-03 23:33:14,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:14,641 INFO:     Epoch: 94
2023-01-03 23:33:16,208 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4947168986002604, 'Total loss': 0.4947168986002604} | train loss {'Reaction outcome loss': 0.1813688258070758, 'Total loss': 0.1813688258070758}
2023-01-03 23:33:16,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:16,208 INFO:     Epoch: 95
2023-01-03 23:33:17,782 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5019665618737539, 'Total loss': 0.5019665618737539} | train loss {'Reaction outcome loss': 0.176551530448099, 'Total loss': 0.176551530448099}
2023-01-03 23:33:17,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:17,782 INFO:     Epoch: 96
2023-01-03 23:33:19,343 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45973739127318064, 'Total loss': 0.45973739127318064} | train loss {'Reaction outcome loss': 0.17416361182068402, 'Total loss': 0.17416361182068402}
2023-01-03 23:33:19,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:19,343 INFO:     Epoch: 97
2023-01-03 23:33:20,920 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5054243127504985, 'Total loss': 0.5054243127504985} | train loss {'Reaction outcome loss': 0.17349677369844563, 'Total loss': 0.17349677369844563}
2023-01-03 23:33:20,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:20,920 INFO:     Epoch: 98
2023-01-03 23:33:22,498 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44900484979152677, 'Total loss': 0.44900484979152677} | train loss {'Reaction outcome loss': 0.17484285054735213, 'Total loss': 0.17484285054735213}
2023-01-03 23:33:22,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:22,498 INFO:     Epoch: 99
2023-01-03 23:33:24,076 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4539242739478747, 'Total loss': 0.4539242739478747} | train loss {'Reaction outcome loss': 0.1732475113041781, 'Total loss': 0.1732475113041781}
2023-01-03 23:33:24,077 INFO:     Best model found after epoch 69 of 100.
2023-01-03 23:33:24,077 INFO:   Done with stage: TRAINING
2023-01-03 23:33:24,077 INFO:   Starting stage: EVALUATION
2023-01-03 23:33:24,219 INFO:   Done with stage: EVALUATION
2023-01-03 23:33:24,219 INFO:   Leaving out SEQ value Fold_4
2023-01-03 23:33:24,231 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-03 23:33:24,231 INFO:   Starting stage: FEATURE SCALING
2023-01-03 23:33:24,871 INFO:   Done with stage: FEATURE SCALING
2023-01-03 23:33:24,871 INFO:   Starting stage: SCALING TARGETS
2023-01-03 23:33:24,940 INFO:   Done with stage: SCALING TARGETS
2023-01-03 23:33:24,940 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:33:24,940 INFO:     No hyperparam tuning for this model
2023-01-03 23:33:24,940 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:33:24,940 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 23:33:24,941 INFO:     None feature selector for col prot
2023-01-03 23:33:24,941 INFO:     None feature selector for col prot
2023-01-03 23:33:24,941 INFO:     None feature selector for col prot
2023-01-03 23:33:24,941 INFO:     None feature selector for col chem
2023-01-03 23:33:24,942 INFO:     None feature selector for col chem
2023-01-03 23:33:24,942 INFO:     None feature selector for col chem
2023-01-03 23:33:24,942 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 23:33:24,942 INFO:   Starting stage: BUILD MODEL
2023-01-03 23:33:24,943 INFO:     Number of params in model 70141
2023-01-03 23:33:24,946 INFO:   Done with stage: BUILD MODEL
2023-01-03 23:33:24,946 INFO:   Starting stage: TRAINING
2023-01-03 23:33:24,990 INFO:     Val loss before train {'Reaction outcome loss': 1.0381916046142579, 'Total loss': 1.0381916046142579}
2023-01-03 23:33:24,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:24,990 INFO:     Epoch: 0
2023-01-03 23:33:26,598 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7126205146312714, 'Total loss': 0.7126205146312714} | train loss {'Reaction outcome loss': 0.8586155208792999, 'Total loss': 0.8586155208792999}
2023-01-03 23:33:26,598 INFO:     Found new best model at epoch 0
2023-01-03 23:33:26,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:26,599 INFO:     Epoch: 1
2023-01-03 23:33:28,183 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6042777856191, 'Total loss': 0.6042777856191} | train loss {'Reaction outcome loss': 0.6197306258182456, 'Total loss': 0.6197306258182456}
2023-01-03 23:33:28,183 INFO:     Found new best model at epoch 1
2023-01-03 23:33:28,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:28,184 INFO:     Epoch: 2
2023-01-03 23:33:29,801 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5641544044017792, 'Total loss': 0.5641544044017792} | train loss {'Reaction outcome loss': 0.5318479768551179, 'Total loss': 0.5318479768551179}
2023-01-03 23:33:29,801 INFO:     Found new best model at epoch 2
2023-01-03 23:33:29,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:29,802 INFO:     Epoch: 3
2023-01-03 23:33:31,408 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5249342759450276, 'Total loss': 0.5249342759450276} | train loss {'Reaction outcome loss': 0.49311529877629595, 'Total loss': 0.49311529877629595}
2023-01-03 23:33:31,408 INFO:     Found new best model at epoch 3
2023-01-03 23:33:31,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:31,409 INFO:     Epoch: 4
2023-01-03 23:33:32,992 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.511208309729894, 'Total loss': 0.511208309729894} | train loss {'Reaction outcome loss': 0.46180938845024494, 'Total loss': 0.46180938845024494}
2023-01-03 23:33:32,993 INFO:     Found new best model at epoch 4
2023-01-03 23:33:32,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:32,993 INFO:     Epoch: 5
2023-01-03 23:33:34,579 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5166189114252726, 'Total loss': 0.5166189114252726} | train loss {'Reaction outcome loss': 0.4397331803058186, 'Total loss': 0.4397331803058186}
2023-01-03 23:33:34,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:34,579 INFO:     Epoch: 6
2023-01-03 23:33:36,144 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49692917267481485, 'Total loss': 0.49692917267481485} | train loss {'Reaction outcome loss': 0.4243520736476801, 'Total loss': 0.4243520736476801}
2023-01-03 23:33:36,145 INFO:     Found new best model at epoch 6
2023-01-03 23:33:36,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:36,146 INFO:     Epoch: 7
2023-01-03 23:33:37,723 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48045408527056377, 'Total loss': 0.48045408527056377} | train loss {'Reaction outcome loss': 0.40725816710151896, 'Total loss': 0.40725816710151896}
2023-01-03 23:33:37,723 INFO:     Found new best model at epoch 7
2023-01-03 23:33:37,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:37,724 INFO:     Epoch: 8
2023-01-03 23:33:39,306 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49108781218528746, 'Total loss': 0.49108781218528746} | train loss {'Reaction outcome loss': 0.3959456664530465, 'Total loss': 0.3959456664530465}
2023-01-03 23:33:39,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:39,306 INFO:     Epoch: 9
2023-01-03 23:33:40,888 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4809393962224325, 'Total loss': 0.4809393962224325} | train loss {'Reaction outcome loss': 0.3844175672117811, 'Total loss': 0.3844175672117811}
2023-01-03 23:33:40,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:40,889 INFO:     Epoch: 10
2023-01-03 23:33:42,455 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4933933675289154, 'Total loss': 0.4933933675289154} | train loss {'Reaction outcome loss': 0.3769759214381232, 'Total loss': 0.3769759214381232}
2023-01-03 23:33:42,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:42,456 INFO:     Epoch: 11
2023-01-03 23:33:44,058 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47994338870048525, 'Total loss': 0.47994338870048525} | train loss {'Reaction outcome loss': 0.3673629116837996, 'Total loss': 0.3673629116837996}
2023-01-03 23:33:44,058 INFO:     Found new best model at epoch 11
2023-01-03 23:33:44,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:44,059 INFO:     Epoch: 12
2023-01-03 23:33:45,648 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4858563343683879, 'Total loss': 0.4858563343683879} | train loss {'Reaction outcome loss': 0.3581709832388119, 'Total loss': 0.3581709832388119}
2023-01-03 23:33:45,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:45,648 INFO:     Epoch: 13
2023-01-03 23:33:47,265 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5095297714074453, 'Total loss': 0.5095297714074453} | train loss {'Reaction outcome loss': 0.3489973442017162, 'Total loss': 0.3489973442017162}
2023-01-03 23:33:47,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:47,265 INFO:     Epoch: 14
2023-01-03 23:33:48,873 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5038836399714152, 'Total loss': 0.5038836399714152} | train loss {'Reaction outcome loss': 0.34182430907105005, 'Total loss': 0.34182430907105005}
2023-01-03 23:33:48,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:48,874 INFO:     Epoch: 15
2023-01-03 23:33:50,470 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4649893800417582, 'Total loss': 0.4649893800417582} | train loss {'Reaction outcome loss': 0.33513761760435834, 'Total loss': 0.33513761760435834}
2023-01-03 23:33:50,470 INFO:     Found new best model at epoch 15
2023-01-03 23:33:50,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:50,471 INFO:     Epoch: 16
2023-01-03 23:33:52,053 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4626442134380341, 'Total loss': 0.4626442134380341} | train loss {'Reaction outcome loss': 0.3294614111039325, 'Total loss': 0.3294614111039325}
2023-01-03 23:33:52,053 INFO:     Found new best model at epoch 16
2023-01-03 23:33:52,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:52,054 INFO:     Epoch: 17
2023-01-03 23:33:53,636 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4725388060013453, 'Total loss': 0.4725388060013453} | train loss {'Reaction outcome loss': 0.3224013285153974, 'Total loss': 0.3224013285153974}
2023-01-03 23:33:53,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:53,636 INFO:     Epoch: 18
2023-01-03 23:33:55,200 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4973724126815796, 'Total loss': 0.4973724126815796} | train loss {'Reaction outcome loss': 0.3163034358898001, 'Total loss': 0.3163034358898001}
2023-01-03 23:33:55,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:55,201 INFO:     Epoch: 19
2023-01-03 23:33:56,783 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4787773350874583, 'Total loss': 0.4787773350874583} | train loss {'Reaction outcome loss': 0.31007157138338054, 'Total loss': 0.31007157138338054}
2023-01-03 23:33:56,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:56,783 INFO:     Epoch: 20
2023-01-03 23:33:58,366 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44862019618352256, 'Total loss': 0.44862019618352256} | train loss {'Reaction outcome loss': 0.305760476330336, 'Total loss': 0.305760476330336}
2023-01-03 23:33:58,367 INFO:     Found new best model at epoch 20
2023-01-03 23:33:58,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:58,367 INFO:     Epoch: 21
2023-01-03 23:33:59,924 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4767809053262075, 'Total loss': 0.4767809053262075} | train loss {'Reaction outcome loss': 0.3019658734165404, 'Total loss': 0.3019658734165404}
2023-01-03 23:33:59,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:33:59,924 INFO:     Epoch: 22
2023-01-03 23:34:01,530 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47554915249347685, 'Total loss': 0.47554915249347685} | train loss {'Reaction outcome loss': 0.29768338731496874, 'Total loss': 0.29768338731496874}
2023-01-03 23:34:01,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:01,530 INFO:     Epoch: 23
2023-01-03 23:34:03,086 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4655521273612976, 'Total loss': 0.4655521273612976} | train loss {'Reaction outcome loss': 0.29390810889593005, 'Total loss': 0.29390810889593005}
2023-01-03 23:34:03,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:03,087 INFO:     Epoch: 24
2023-01-03 23:34:04,668 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4858295083045959, 'Total loss': 0.4858295083045959} | train loss {'Reaction outcome loss': 0.28777355167770036, 'Total loss': 0.28777355167770036}
2023-01-03 23:34:04,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:04,668 INFO:     Epoch: 25
2023-01-03 23:34:06,251 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4698726614316305, 'Total loss': 0.4698726614316305} | train loss {'Reaction outcome loss': 0.28520441520279344, 'Total loss': 0.28520441520279344}
2023-01-03 23:34:06,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:06,252 INFO:     Epoch: 26
2023-01-03 23:34:07,834 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45741799573103586, 'Total loss': 0.45741799573103586} | train loss {'Reaction outcome loss': 0.2812980531041857, 'Total loss': 0.2812980531041857}
2023-01-03 23:34:07,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:07,834 INFO:     Epoch: 27
2023-01-03 23:34:09,395 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.483685290813446, 'Total loss': 0.483685290813446} | train loss {'Reaction outcome loss': 0.2763181037820169, 'Total loss': 0.2763181037820169}
2023-01-03 23:34:09,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:09,395 INFO:     Epoch: 28
2023-01-03 23:34:11,002 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4554744998613993, 'Total loss': 0.4554744998613993} | train loss {'Reaction outcome loss': 0.2739541740530599, 'Total loss': 0.2739541740530599}
2023-01-03 23:34:11,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:11,003 INFO:     Epoch: 29
2023-01-03 23:34:12,590 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4676898191372553, 'Total loss': 0.4676898191372553} | train loss {'Reaction outcome loss': 0.27342093961626074, 'Total loss': 0.27342093961626074}
2023-01-03 23:34:12,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:12,591 INFO:     Epoch: 30
2023-01-03 23:34:14,186 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47212126553058625, 'Total loss': 0.47212126553058625} | train loss {'Reaction outcome loss': 0.2684795095374549, 'Total loss': 0.2684795095374549}
2023-01-03 23:34:14,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:14,186 INFO:     Epoch: 31
2023-01-03 23:34:15,767 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5147661834955215, 'Total loss': 0.5147661834955215} | train loss {'Reaction outcome loss': 0.26606257643251524, 'Total loss': 0.26606257643251524}
2023-01-03 23:34:15,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:15,767 INFO:     Epoch: 32
2023-01-03 23:34:17,343 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43869236558675767, 'Total loss': 0.43869236558675767} | train loss {'Reaction outcome loss': 0.2626063676591772, 'Total loss': 0.2626063676591772}
2023-01-03 23:34:17,343 INFO:     Found new best model at epoch 32
2023-01-03 23:34:17,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:17,344 INFO:     Epoch: 33
2023-01-03 23:34:18,926 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44849913418292997, 'Total loss': 0.44849913418292997} | train loss {'Reaction outcome loss': 0.26090738555266907, 'Total loss': 0.26090738555266907}
2023-01-03 23:34:18,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:18,927 INFO:     Epoch: 34
2023-01-03 23:34:20,508 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4377631405989329, 'Total loss': 0.4377631405989329} | train loss {'Reaction outcome loss': 0.25700926446240313, 'Total loss': 0.25700926446240313}
2023-01-03 23:34:20,508 INFO:     Found new best model at epoch 34
2023-01-03 23:34:20,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:20,509 INFO:     Epoch: 35
2023-01-03 23:34:22,075 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45378137230873106, 'Total loss': 0.45378137230873106} | train loss {'Reaction outcome loss': 0.2559433359462414, 'Total loss': 0.2559433359462414}
2023-01-03 23:34:22,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:22,075 INFO:     Epoch: 36
2023-01-03 23:34:23,662 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4512670377890269, 'Total loss': 0.4512670377890269} | train loss {'Reaction outcome loss': 0.2516219589016298, 'Total loss': 0.2516219589016298}
2023-01-03 23:34:23,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:23,663 INFO:     Epoch: 37
2023-01-03 23:34:25,245 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4431415359179179, 'Total loss': 0.4431415359179179} | train loss {'Reaction outcome loss': 0.2499936958842904, 'Total loss': 0.2499936958842904}
2023-01-03 23:34:25,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:25,245 INFO:     Epoch: 38
2023-01-03 23:34:26,820 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44608322183291116, 'Total loss': 0.44608322183291116} | train loss {'Reaction outcome loss': 0.24751589970703977, 'Total loss': 0.24751589970703977}
2023-01-03 23:34:26,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:26,820 INFO:     Epoch: 39
2023-01-03 23:34:28,392 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4429687182108561, 'Total loss': 0.4429687182108561} | train loss {'Reaction outcome loss': 0.2479796659636454, 'Total loss': 0.2479796659636454}
2023-01-03 23:34:28,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:28,392 INFO:     Epoch: 40
2023-01-03 23:34:29,981 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4723599563042323, 'Total loss': 0.4723599563042323} | train loss {'Reaction outcome loss': 0.24249249900670816, 'Total loss': 0.24249249900670816}
2023-01-03 23:34:29,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:29,981 INFO:     Epoch: 41
2023-01-03 23:34:31,571 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4369383712609609, 'Total loss': 0.4369383712609609} | train loss {'Reaction outcome loss': 0.2395936567064402, 'Total loss': 0.2395936567064402}
2023-01-03 23:34:31,571 INFO:     Found new best model at epoch 41
2023-01-03 23:34:31,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:31,572 INFO:     Epoch: 42
2023-01-03 23:34:33,162 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4683451513449351, 'Total loss': 0.4683451513449351} | train loss {'Reaction outcome loss': 0.236692871544918, 'Total loss': 0.236692871544918}
2023-01-03 23:34:33,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:33,162 INFO:     Epoch: 43
2023-01-03 23:34:34,749 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43824413369099297, 'Total loss': 0.43824413369099297} | train loss {'Reaction outcome loss': 0.2353506290836491, 'Total loss': 0.2353506290836491}
2023-01-03 23:34:34,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:34,750 INFO:     Epoch: 44
2023-01-03 23:34:35,864 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4616880416870117, 'Total loss': 0.4616880416870117} | train loss {'Reaction outcome loss': 0.23278065352109226, 'Total loss': 0.23278065352109226}
2023-01-03 23:34:35,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:35,865 INFO:     Epoch: 45
2023-01-03 23:34:36,917 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45960692365964256, 'Total loss': 0.45960692365964256} | train loss {'Reaction outcome loss': 0.23424589533331622, 'Total loss': 0.23424589533331622}
2023-01-03 23:34:36,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:36,919 INFO:     Epoch: 46
2023-01-03 23:34:37,980 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4527763863404592, 'Total loss': 0.4527763863404592} | train loss {'Reaction outcome loss': 0.2309295265479897, 'Total loss': 0.2309295265479897}
2023-01-03 23:34:37,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:37,981 INFO:     Epoch: 47
2023-01-03 23:34:39,036 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.446174015601476, 'Total loss': 0.446174015601476} | train loss {'Reaction outcome loss': 0.22822484694910747, 'Total loss': 0.22822484694910747}
2023-01-03 23:34:39,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:39,036 INFO:     Epoch: 48
2023-01-03 23:34:40,404 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45313104391098025, 'Total loss': 0.45313104391098025} | train loss {'Reaction outcome loss': 0.22719988569508504, 'Total loss': 0.22719988569508504}
2023-01-03 23:34:40,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:40,405 INFO:     Epoch: 49
2023-01-03 23:34:42,014 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4528850793838501, 'Total loss': 0.4528850793838501} | train loss {'Reaction outcome loss': 0.22546684474133663, 'Total loss': 0.22546684474133663}
2023-01-03 23:34:42,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:42,014 INFO:     Epoch: 50
2023-01-03 23:34:43,592 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44149877031644186, 'Total loss': 0.44149877031644186} | train loss {'Reaction outcome loss': 0.2219080415139668, 'Total loss': 0.2219080415139668}
2023-01-03 23:34:43,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:43,593 INFO:     Epoch: 51
2023-01-03 23:34:45,191 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45613428950309753, 'Total loss': 0.45613428950309753} | train loss {'Reaction outcome loss': 0.22169798299887755, 'Total loss': 0.22169798299887755}
2023-01-03 23:34:45,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:45,191 INFO:     Epoch: 52
2023-01-03 23:34:46,784 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45283144811789194, 'Total loss': 0.45283144811789194} | train loss {'Reaction outcome loss': 0.22083842264909814, 'Total loss': 0.22083842264909814}
2023-01-03 23:34:46,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:46,784 INFO:     Epoch: 53
2023-01-03 23:34:48,374 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4453052113453547, 'Total loss': 0.4453052113453547} | train loss {'Reaction outcome loss': 0.2182379447086884, 'Total loss': 0.2182379447086884}
2023-01-03 23:34:48,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:48,374 INFO:     Epoch: 54
2023-01-03 23:34:49,947 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46740267276763914, 'Total loss': 0.46740267276763914} | train loss {'Reaction outcome loss': 0.2165241498146614, 'Total loss': 0.2165241498146614}
2023-01-03 23:34:49,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:49,948 INFO:     Epoch: 55
2023-01-03 23:34:51,530 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45630497733751935, 'Total loss': 0.45630497733751935} | train loss {'Reaction outcome loss': 0.21528521017001492, 'Total loss': 0.21528521017001492}
2023-01-03 23:34:51,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:51,530 INFO:     Epoch: 56
2023-01-03 23:34:53,168 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.437362073858579, 'Total loss': 0.437362073858579} | train loss {'Reaction outcome loss': 0.2118238601833582, 'Total loss': 0.2118238601833582}
2023-01-03 23:34:53,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:53,168 INFO:     Epoch: 57
2023-01-03 23:34:54,749 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4509818037350973, 'Total loss': 0.4509818037350973} | train loss {'Reaction outcome loss': 0.21085797273383958, 'Total loss': 0.21085797273383958}
2023-01-03 23:34:54,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:54,749 INFO:     Epoch: 58
2023-01-03 23:34:56,324 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46283550063769024, 'Total loss': 0.46283550063769024} | train loss {'Reaction outcome loss': 0.21074574178315864, 'Total loss': 0.21074574178315864}
2023-01-03 23:34:56,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:56,325 INFO:     Epoch: 59
2023-01-03 23:34:57,889 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4631774087746938, 'Total loss': 0.4631774087746938} | train loss {'Reaction outcome loss': 0.2098144270262144, 'Total loss': 0.2098144270262144}
2023-01-03 23:34:57,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:57,890 INFO:     Epoch: 60
2023-01-03 23:34:59,485 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4591918796300888, 'Total loss': 0.4591918796300888} | train loss {'Reaction outcome loss': 0.2075142967684643, 'Total loss': 0.2075142967684643}
2023-01-03 23:34:59,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:34:59,485 INFO:     Epoch: 61
2023-01-03 23:35:01,079 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4478189339240392, 'Total loss': 0.4478189339240392} | train loss {'Reaction outcome loss': 0.20516629771322664, 'Total loss': 0.20516629771322664}
2023-01-03 23:35:01,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:01,079 INFO:     Epoch: 62
2023-01-03 23:35:02,699 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4294985050956408, 'Total loss': 0.4294985050956408} | train loss {'Reaction outcome loss': 0.20314458994208462, 'Total loss': 0.20314458994208462}
2023-01-03 23:35:02,699 INFO:     Found new best model at epoch 62
2023-01-03 23:35:02,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:02,700 INFO:     Epoch: 63
2023-01-03 23:35:04,263 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4510187774896622, 'Total loss': 0.4510187774896622} | train loss {'Reaction outcome loss': 0.20369213067647748, 'Total loss': 0.20369213067647748}
2023-01-03 23:35:04,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:04,263 INFO:     Epoch: 64
2023-01-03 23:35:05,847 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45241952538490293, 'Total loss': 0.45241952538490293} | train loss {'Reaction outcome loss': 0.20031947152430776, 'Total loss': 0.20031947152430776}
2023-01-03 23:35:05,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:05,847 INFO:     Epoch: 65
2023-01-03 23:35:07,430 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4511585235595703, 'Total loss': 0.4511585235595703} | train loss {'Reaction outcome loss': 0.1984169556738904, 'Total loss': 0.1984169556738904}
2023-01-03 23:35:07,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:07,430 INFO:     Epoch: 66
2023-01-03 23:35:09,018 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46695653200149534, 'Total loss': 0.46695653200149534} | train loss {'Reaction outcome loss': 0.19959912583721381, 'Total loss': 0.19959912583721381}
2023-01-03 23:35:09,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:09,019 INFO:     Epoch: 67
2023-01-03 23:35:10,606 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46084059377511344, 'Total loss': 0.46084059377511344} | train loss {'Reaction outcome loss': 0.19622047000775372, 'Total loss': 0.19622047000775372}
2023-01-03 23:35:10,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:10,606 INFO:     Epoch: 68
2023-01-03 23:35:12,181 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45646460851033527, 'Total loss': 0.45646460851033527} | train loss {'Reaction outcome loss': 0.19551252957134352, 'Total loss': 0.19551252957134352}
2023-01-03 23:35:12,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:12,181 INFO:     Epoch: 69
2023-01-03 23:35:13,756 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4757065673669179, 'Total loss': 0.4757065673669179} | train loss {'Reaction outcome loss': 0.1945274280669698, 'Total loss': 0.1945274280669698}
2023-01-03 23:35:13,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:13,758 INFO:     Epoch: 70
2023-01-03 23:35:15,337 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4946391642093658, 'Total loss': 0.4946391642093658} | train loss {'Reaction outcome loss': 0.19337260116734645, 'Total loss': 0.19337260116734645}
2023-01-03 23:35:15,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:15,337 INFO:     Epoch: 71
2023-01-03 23:35:16,932 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4538261036078135, 'Total loss': 0.4538261036078135} | train loss {'Reaction outcome loss': 0.19154657059124786, 'Total loss': 0.19154657059124786}
2023-01-03 23:35:16,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:16,932 INFO:     Epoch: 72
2023-01-03 23:35:18,552 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47731028993924457, 'Total loss': 0.47731028993924457} | train loss {'Reaction outcome loss': 0.18923141589782533, 'Total loss': 0.18923141589782533}
2023-01-03 23:35:18,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:18,553 INFO:     Epoch: 73
2023-01-03 23:35:20,167 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4671292463938395, 'Total loss': 0.4671292463938395} | train loss {'Reaction outcome loss': 0.19060420922010485, 'Total loss': 0.19060420922010485}
2023-01-03 23:35:20,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:20,168 INFO:     Epoch: 74
2023-01-03 23:35:21,746 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4387030750513077, 'Total loss': 0.4387030750513077} | train loss {'Reaction outcome loss': 0.18869027035841107, 'Total loss': 0.18869027035841107}
2023-01-03 23:35:21,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:21,746 INFO:     Epoch: 75
2023-01-03 23:35:23,325 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4685867746671041, 'Total loss': 0.4685867746671041} | train loss {'Reaction outcome loss': 0.18891893656258166, 'Total loss': 0.18891893656258166}
2023-01-03 23:35:23,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:23,325 INFO:     Epoch: 76
2023-01-03 23:35:24,889 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45651690314213433, 'Total loss': 0.45651690314213433} | train loss {'Reaction outcome loss': 0.18738933436463784, 'Total loss': 0.18738933436463784}
2023-01-03 23:35:24,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:24,889 INFO:     Epoch: 77
2023-01-03 23:35:26,464 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4543350358804067, 'Total loss': 0.4543350358804067} | train loss {'Reaction outcome loss': 0.1865855725550086, 'Total loss': 0.1865855725550086}
2023-01-03 23:35:26,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:26,464 INFO:     Epoch: 78
2023-01-03 23:35:28,039 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4826585024595261, 'Total loss': 0.4826585024595261} | train loss {'Reaction outcome loss': 0.18763670360628706, 'Total loss': 0.18763670360628706}
2023-01-03 23:35:28,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:28,040 INFO:     Epoch: 79
2023-01-03 23:35:29,616 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4861504892508189, 'Total loss': 0.4861504892508189} | train loss {'Reaction outcome loss': 0.18604601620540132, 'Total loss': 0.18604601620540132}
2023-01-03 23:35:29,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:29,616 INFO:     Epoch: 80
2023-01-03 23:35:31,183 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4540724853674571, 'Total loss': 0.4540724853674571} | train loss {'Reaction outcome loss': 0.18329843432798873, 'Total loss': 0.18329843432798873}
2023-01-03 23:35:31,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:31,183 INFO:     Epoch: 81
2023-01-03 23:35:32,762 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4521430492401123, 'Total loss': 0.4521430492401123} | train loss {'Reaction outcome loss': 0.1815703734007739, 'Total loss': 0.1815703734007739}
2023-01-03 23:35:32,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:32,763 INFO:     Epoch: 82
2023-01-03 23:35:34,325 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47349824706713356, 'Total loss': 0.47349824706713356} | train loss {'Reaction outcome loss': 0.18312640122416682, 'Total loss': 0.18312640122416682}
2023-01-03 23:35:34,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:34,325 INFO:     Epoch: 83
2023-01-03 23:35:35,928 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48022641440232594, 'Total loss': 0.48022641440232594} | train loss {'Reaction outcome loss': 0.18105428485730052, 'Total loss': 0.18105428485730052}
2023-01-03 23:35:35,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:35,928 INFO:     Epoch: 84
2023-01-03 23:35:37,498 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4907753070195516, 'Total loss': 0.4907753070195516} | train loss {'Reaction outcome loss': 0.1798365493950835, 'Total loss': 0.1798365493950835}
2023-01-03 23:35:37,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:37,498 INFO:     Epoch: 85
2023-01-03 23:35:39,086 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.468703963359197, 'Total loss': 0.468703963359197} | train loss {'Reaction outcome loss': 0.1804740729802934, 'Total loss': 0.1804740729802934}
2023-01-03 23:35:39,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:39,086 INFO:     Epoch: 86
2023-01-03 23:35:40,691 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4789709528287252, 'Total loss': 0.4789709528287252} | train loss {'Reaction outcome loss': 0.1802834369663666, 'Total loss': 0.1802834369663666}
2023-01-03 23:35:40,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:40,691 INFO:     Epoch: 87
2023-01-03 23:35:42,296 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5008046209812165, 'Total loss': 0.5008046209812165} | train loss {'Reaction outcome loss': 0.17678193334680403, 'Total loss': 0.17678193334680403}
2023-01-03 23:35:42,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:42,296 INFO:     Epoch: 88
2023-01-03 23:35:43,860 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47548162763317425, 'Total loss': 0.47548162763317425} | train loss {'Reaction outcome loss': 0.17581388826760716, 'Total loss': 0.17581388826760716}
2023-01-03 23:35:43,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:43,860 INFO:     Epoch: 89
2023-01-03 23:35:45,465 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4904665211836497, 'Total loss': 0.4904665211836497} | train loss {'Reaction outcome loss': 0.17639249244392136, 'Total loss': 0.17639249244392136}
2023-01-03 23:35:45,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:45,466 INFO:     Epoch: 90
2023-01-03 23:35:47,072 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48505156139532724, 'Total loss': 0.48505156139532724} | train loss {'Reaction outcome loss': 0.17485858415708924, 'Total loss': 0.17485858415708924}
2023-01-03 23:35:47,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:47,073 INFO:     Epoch: 91
2023-01-03 23:35:48,661 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5023444692293803, 'Total loss': 0.5023444692293803} | train loss {'Reaction outcome loss': 0.1730765845816936, 'Total loss': 0.1730765845816936}
2023-01-03 23:35:48,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:48,662 INFO:     Epoch: 92
2023-01-03 23:35:50,267 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.507910571495692, 'Total loss': 0.507910571495692} | train loss {'Reaction outcome loss': 0.17526144000028607, 'Total loss': 0.17526144000028607}
2023-01-03 23:35:50,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:50,267 INFO:     Epoch: 93
2023-01-03 23:35:51,850 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49047662218411764, 'Total loss': 0.49047662218411764} | train loss {'Reaction outcome loss': 0.17240336381687518, 'Total loss': 0.17240336381687518}
2023-01-03 23:35:51,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:51,850 INFO:     Epoch: 94
2023-01-03 23:35:53,417 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48227593501408894, 'Total loss': 0.48227593501408894} | train loss {'Reaction outcome loss': 0.17350736904862155, 'Total loss': 0.17350736904862155}
2023-01-03 23:35:53,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:53,417 INFO:     Epoch: 95
2023-01-03 23:35:55,030 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4695830136537552, 'Total loss': 0.4695830136537552} | train loss {'Reaction outcome loss': 0.17317457200728192, 'Total loss': 0.17317457200728192}
2023-01-03 23:35:55,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:55,031 INFO:     Epoch: 96
2023-01-03 23:35:56,640 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5081897099812825, 'Total loss': 0.5081897099812825} | train loss {'Reaction outcome loss': 0.1737139089182563, 'Total loss': 0.1737139089182563}
2023-01-03 23:35:56,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:56,640 INFO:     Epoch: 97
2023-01-03 23:35:58,201 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47168737749258677, 'Total loss': 0.47168737749258677} | train loss {'Reaction outcome loss': 0.17221979355697867, 'Total loss': 0.17221979355697867}
2023-01-03 23:35:58,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:58,201 INFO:     Epoch: 98
2023-01-03 23:35:59,796 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5041306525468826, 'Total loss': 0.5041306525468826} | train loss {'Reaction outcome loss': 0.17269601191591172, 'Total loss': 0.17269601191591172}
2023-01-03 23:35:59,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:35:59,796 INFO:     Epoch: 99
2023-01-03 23:36:01,362 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49494693080584207, 'Total loss': 0.49494693080584207} | train loss {'Reaction outcome loss': 0.170473404031546, 'Total loss': 0.170473404031546}
2023-01-03 23:36:01,362 INFO:     Best model found after epoch 63 of 100.
2023-01-03 23:36:01,362 INFO:   Done with stage: TRAINING
2023-01-03 23:36:01,362 INFO:   Starting stage: EVALUATION
2023-01-03 23:36:01,497 INFO:   Done with stage: EVALUATION
2023-01-03 23:36:01,497 INFO:   Leaving out SEQ value Fold_5
2023-01-03 23:36:01,510 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-03 23:36:01,510 INFO:   Starting stage: FEATURE SCALING
2023-01-03 23:36:02,158 INFO:   Done with stage: FEATURE SCALING
2023-01-03 23:36:02,158 INFO:   Starting stage: SCALING TARGETS
2023-01-03 23:36:02,227 INFO:   Done with stage: SCALING TARGETS
2023-01-03 23:36:02,228 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:36:02,228 INFO:     No hyperparam tuning for this model
2023-01-03 23:36:02,228 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:36:02,228 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 23:36:02,228 INFO:     None feature selector for col prot
2023-01-03 23:36:02,229 INFO:     None feature selector for col prot
2023-01-03 23:36:02,229 INFO:     None feature selector for col prot
2023-01-03 23:36:02,229 INFO:     None feature selector for col chem
2023-01-03 23:36:02,229 INFO:     None feature selector for col chem
2023-01-03 23:36:02,229 INFO:     None feature selector for col chem
2023-01-03 23:36:02,229 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 23:36:02,229 INFO:   Starting stage: BUILD MODEL
2023-01-03 23:36:02,230 INFO:     Number of params in model 70141
2023-01-03 23:36:02,234 INFO:   Done with stage: BUILD MODEL
2023-01-03 23:36:02,234 INFO:   Starting stage: TRAINING
2023-01-03 23:36:02,276 INFO:     Val loss before train {'Reaction outcome loss': 1.0958292682965596, 'Total loss': 1.0958292682965596}
2023-01-03 23:36:02,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:02,277 INFO:     Epoch: 0
2023-01-03 23:36:03,858 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.72069886525472, 'Total loss': 0.72069886525472} | train loss {'Reaction outcome loss': 0.8318476319805811, 'Total loss': 0.8318476319805811}
2023-01-03 23:36:03,858 INFO:     Found new best model at epoch 0
2023-01-03 23:36:03,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:03,859 INFO:     Epoch: 1
2023-01-03 23:36:05,458 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6117938101291657, 'Total loss': 0.6117938101291657} | train loss {'Reaction outcome loss': 0.5924719223293705, 'Total loss': 0.5924719223293705}
2023-01-03 23:36:05,459 INFO:     Found new best model at epoch 1
2023-01-03 23:36:05,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:05,459 INFO:     Epoch: 2
2023-01-03 23:36:07,068 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5595011631647746, 'Total loss': 0.5595011631647746} | train loss {'Reaction outcome loss': 0.5247140907652109, 'Total loss': 0.5247140907652109}
2023-01-03 23:36:07,069 INFO:     Found new best model at epoch 2
2023-01-03 23:36:07,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:07,070 INFO:     Epoch: 3
2023-01-03 23:36:08,674 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5302909294764201, 'Total loss': 0.5302909294764201} | train loss {'Reaction outcome loss': 0.48872264334594534, 'Total loss': 0.48872264334594534}
2023-01-03 23:36:08,674 INFO:     Found new best model at epoch 3
2023-01-03 23:36:08,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:08,675 INFO:     Epoch: 4
2023-01-03 23:36:10,272 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5318276286125183, 'Total loss': 0.5318276286125183} | train loss {'Reaction outcome loss': 0.486460466855678, 'Total loss': 0.486460466855678}
2023-01-03 23:36:10,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:10,272 INFO:     Epoch: 5
2023-01-03 23:36:11,888 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5057998915513356, 'Total loss': 0.5057998915513356} | train loss {'Reaction outcome loss': 0.44921288806675136, 'Total loss': 0.44921288806675136}
2023-01-03 23:36:11,888 INFO:     Found new best model at epoch 5
2023-01-03 23:36:11,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:11,889 INFO:     Epoch: 6
2023-01-03 23:36:13,502 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4918290595213572, 'Total loss': 0.4918290595213572} | train loss {'Reaction outcome loss': 0.4383040004666301, 'Total loss': 0.4383040004666301}
2023-01-03 23:36:13,503 INFO:     Found new best model at epoch 6
2023-01-03 23:36:13,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:13,504 INFO:     Epoch: 7
2023-01-03 23:36:15,076 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4790878236293793, 'Total loss': 0.4790878236293793} | train loss {'Reaction outcome loss': 0.42616345383567683, 'Total loss': 0.42616345383567683}
2023-01-03 23:36:15,076 INFO:     Found new best model at epoch 7
2023-01-03 23:36:15,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:15,077 INFO:     Epoch: 8
2023-01-03 23:36:16,665 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4772372514009476, 'Total loss': 0.4772372514009476} | train loss {'Reaction outcome loss': 0.4078773526070754, 'Total loss': 0.4078773526070754}
2023-01-03 23:36:16,665 INFO:     Found new best model at epoch 8
2023-01-03 23:36:16,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:16,666 INFO:     Epoch: 9
2023-01-03 23:36:18,236 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4693432589371999, 'Total loss': 0.4693432589371999} | train loss {'Reaction outcome loss': 0.40893357533259667, 'Total loss': 0.40893357533259667}
2023-01-03 23:36:18,237 INFO:     Found new best model at epoch 9
2023-01-03 23:36:18,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:18,237 INFO:     Epoch: 10
2023-01-03 23:36:19,851 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4685750365257263, 'Total loss': 0.4685750365257263} | train loss {'Reaction outcome loss': 0.40480050018084224, 'Total loss': 0.40480050018084224}
2023-01-03 23:36:19,852 INFO:     Found new best model at epoch 10
2023-01-03 23:36:19,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:19,853 INFO:     Epoch: 11
2023-01-03 23:36:21,469 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4570788105328878, 'Total loss': 0.4570788105328878} | train loss {'Reaction outcome loss': 0.3905519133136756, 'Total loss': 0.3905519133136756}
2023-01-03 23:36:21,469 INFO:     Found new best model at epoch 11
2023-01-03 23:36:21,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:21,470 INFO:     Epoch: 12
2023-01-03 23:36:23,089 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4556900749603907, 'Total loss': 0.4556900749603907} | train loss {'Reaction outcome loss': 0.37865755970119935, 'Total loss': 0.37865755970119935}
2023-01-03 23:36:23,089 INFO:     Found new best model at epoch 12
2023-01-03 23:36:23,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:23,090 INFO:     Epoch: 13
2023-01-03 23:36:24,663 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46438656449317933, 'Total loss': 0.46438656449317933} | train loss {'Reaction outcome loss': 0.370932803934683, 'Total loss': 0.370932803934683}
2023-01-03 23:36:24,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:24,664 INFO:     Epoch: 14
2023-01-03 23:36:26,252 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4687199135621389, 'Total loss': 0.4687199135621389} | train loss {'Reaction outcome loss': 0.36262300525508495, 'Total loss': 0.36262300525508495}
2023-01-03 23:36:26,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:26,253 INFO:     Epoch: 15
2023-01-03 23:36:27,828 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4513339002927144, 'Total loss': 0.4513339002927144} | train loss {'Reaction outcome loss': 0.3568290771538581, 'Total loss': 0.3568290771538581}
2023-01-03 23:36:27,828 INFO:     Found new best model at epoch 15
2023-01-03 23:36:27,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:27,829 INFO:     Epoch: 16
2023-01-03 23:36:29,417 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4482819060484568, 'Total loss': 0.4482819060484568} | train loss {'Reaction outcome loss': 0.3516739831454512, 'Total loss': 0.3516739831454512}
2023-01-03 23:36:29,418 INFO:     Found new best model at epoch 16
2023-01-03 23:36:29,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:29,419 INFO:     Epoch: 17
2023-01-03 23:36:31,008 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44466098050276437, 'Total loss': 0.44466098050276437} | train loss {'Reaction outcome loss': 0.3590378923530596, 'Total loss': 0.3590378923530596}
2023-01-03 23:36:31,008 INFO:     Found new best model at epoch 17
2023-01-03 23:36:31,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:31,009 INFO:     Epoch: 18
2023-01-03 23:36:32,581 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44347275495529176, 'Total loss': 0.44347275495529176} | train loss {'Reaction outcome loss': 0.3575551465016189, 'Total loss': 0.3575551465016189}
2023-01-03 23:36:32,581 INFO:     Found new best model at epoch 18
2023-01-03 23:36:32,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:32,582 INFO:     Epoch: 19
2023-01-03 23:36:34,160 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44175662597020465, 'Total loss': 0.44175662597020465} | train loss {'Reaction outcome loss': 0.34191833520173165, 'Total loss': 0.34191833520173165}
2023-01-03 23:36:34,161 INFO:     Found new best model at epoch 19
2023-01-03 23:36:34,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:34,161 INFO:     Epoch: 20
2023-01-03 23:36:35,728 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4483741998672485, 'Total loss': 0.4483741998672485} | train loss {'Reaction outcome loss': 0.33510602098059555, 'Total loss': 0.33510602098059555}
2023-01-03 23:36:35,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:35,728 INFO:     Epoch: 21
2023-01-03 23:36:37,321 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4405396580696106, 'Total loss': 0.4405396580696106} | train loss {'Reaction outcome loss': 0.3285803761387217, 'Total loss': 0.3285803761387217}
2023-01-03 23:36:37,321 INFO:     Found new best model at epoch 21
2023-01-03 23:36:37,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:37,322 INFO:     Epoch: 22
2023-01-03 23:36:38,912 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4246286690235138, 'Total loss': 0.4246286690235138} | train loss {'Reaction outcome loss': 0.32579497312722, 'Total loss': 0.32579497312722}
2023-01-03 23:36:38,913 INFO:     Found new best model at epoch 22
2023-01-03 23:36:38,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:38,914 INFO:     Epoch: 23
2023-01-03 23:36:40,504 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43396279215812683, 'Total loss': 0.43396279215812683} | train loss {'Reaction outcome loss': 0.32383364436311135, 'Total loss': 0.32383364436311135}
2023-01-03 23:36:40,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:40,504 INFO:     Epoch: 24
2023-01-03 23:36:42,081 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43055968880653384, 'Total loss': 0.43055968880653384} | train loss {'Reaction outcome loss': 0.31491887279902375, 'Total loss': 0.31491887279902375}
2023-01-03 23:36:42,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:42,081 INFO:     Epoch: 25
2023-01-03 23:36:43,669 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4275011440118154, 'Total loss': 0.4275011440118154} | train loss {'Reaction outcome loss': 0.31199608416552993, 'Total loss': 0.31199608416552993}
2023-01-03 23:36:43,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:43,670 INFO:     Epoch: 26
2023-01-03 23:36:45,269 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4220626721779505, 'Total loss': 0.4220626721779505} | train loss {'Reaction outcome loss': 0.31069493119758734, 'Total loss': 0.31069493119758734}
2023-01-03 23:36:45,269 INFO:     Found new best model at epoch 26
2023-01-03 23:36:45,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:45,270 INFO:     Epoch: 27
2023-01-03 23:36:46,865 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4295798897743225, 'Total loss': 0.4295798897743225} | train loss {'Reaction outcome loss': 0.3035077051785977, 'Total loss': 0.3035077051785977}
2023-01-03 23:36:46,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:46,865 INFO:     Epoch: 28
2023-01-03 23:36:48,486 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4208491841952006, 'Total loss': 0.4208491841952006} | train loss {'Reaction outcome loss': 0.29972147338929167, 'Total loss': 0.29972147338929167}
2023-01-03 23:36:48,486 INFO:     Found new best model at epoch 28
2023-01-03 23:36:48,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:48,487 INFO:     Epoch: 29
2023-01-03 23:36:50,105 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43706382711728414, 'Total loss': 0.43706382711728414} | train loss {'Reaction outcome loss': 0.2969804238528013, 'Total loss': 0.2969804238528013}
2023-01-03 23:36:50,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:50,106 INFO:     Epoch: 30
2023-01-03 23:36:51,686 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42228845655918124, 'Total loss': 0.42228845655918124} | train loss {'Reaction outcome loss': 0.29456492318211636, 'Total loss': 0.29456492318211636}
2023-01-03 23:36:51,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:51,687 INFO:     Epoch: 31
2023-01-03 23:36:53,276 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4275345176458359, 'Total loss': 0.4275345176458359} | train loss {'Reaction outcome loss': 0.28682546688292676, 'Total loss': 0.28682546688292676}
2023-01-03 23:36:53,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:53,276 INFO:     Epoch: 32
2023-01-03 23:36:54,858 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41448393861452737, 'Total loss': 0.41448393861452737} | train loss {'Reaction outcome loss': 0.28437744948314503, 'Total loss': 0.28437744948314503}
2023-01-03 23:36:54,858 INFO:     Found new best model at epoch 32
2023-01-03 23:36:54,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:54,859 INFO:     Epoch: 33
2023-01-03 23:36:56,453 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40434129039446515, 'Total loss': 0.40434129039446515} | train loss {'Reaction outcome loss': 0.281291299477638, 'Total loss': 0.281291299477638}
2023-01-03 23:36:56,454 INFO:     Found new best model at epoch 33
2023-01-03 23:36:56,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:56,455 INFO:     Epoch: 34
2023-01-03 23:36:58,074 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4231121664245923, 'Total loss': 0.4231121664245923} | train loss {'Reaction outcome loss': 0.2790789677418998, 'Total loss': 0.2790789677418998}
2023-01-03 23:36:58,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:58,074 INFO:     Epoch: 35
2023-01-03 23:36:59,671 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41238924364248913, 'Total loss': 0.41238924364248913} | train loss {'Reaction outcome loss': 0.2858548356841008, 'Total loss': 0.2858548356841008}
2023-01-03 23:36:59,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:36:59,671 INFO:     Epoch: 36
2023-01-03 23:37:01,291 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42761869728565216, 'Total loss': 0.42761869728565216} | train loss {'Reaction outcome loss': 0.2833006121876204, 'Total loss': 0.2833006121876204}
2023-01-03 23:37:01,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:01,292 INFO:     Epoch: 37
2023-01-03 23:37:02,882 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4031724840402603, 'Total loss': 0.4031724840402603} | train loss {'Reaction outcome loss': 0.2667713880385407, 'Total loss': 0.2667713880385407}
2023-01-03 23:37:02,882 INFO:     Found new best model at epoch 37
2023-01-03 23:37:02,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:02,883 INFO:     Epoch: 38
2023-01-03 23:37:04,502 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41010309557120006, 'Total loss': 0.41010309557120006} | train loss {'Reaction outcome loss': 0.26473150898000575, 'Total loss': 0.26473150898000575}
2023-01-03 23:37:04,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:04,502 INFO:     Epoch: 39
2023-01-03 23:37:06,123 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.38686781624952954, 'Total loss': 0.38686781624952954} | train loss {'Reaction outcome loss': 0.2595736515565701, 'Total loss': 0.2595736515565701}
2023-01-03 23:37:06,124 INFO:     Found new best model at epoch 39
2023-01-03 23:37:06,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:06,124 INFO:     Epoch: 40
2023-01-03 23:37:07,749 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4082056899865468, 'Total loss': 0.4082056899865468} | train loss {'Reaction outcome loss': 0.2574371930086931, 'Total loss': 0.2574371930086931}
2023-01-03 23:37:07,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:07,749 INFO:     Epoch: 41
2023-01-03 23:37:09,346 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4041610449552536, 'Total loss': 0.4041610449552536} | train loss {'Reaction outcome loss': 0.2557976502466245, 'Total loss': 0.2557976502466245}
2023-01-03 23:37:09,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:09,347 INFO:     Epoch: 42
2023-01-03 23:37:10,967 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4107408881187439, 'Total loss': 0.4107408881187439} | train loss {'Reaction outcome loss': 0.25356958633747656, 'Total loss': 0.25356958633747656}
2023-01-03 23:37:10,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:10,967 INFO:     Epoch: 43
2023-01-03 23:37:12,567 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.38658084472020465, 'Total loss': 0.38658084472020465} | train loss {'Reaction outcome loss': 0.2532472832961872, 'Total loss': 0.2532472832961872}
2023-01-03 23:37:12,567 INFO:     Found new best model at epoch 43
2023-01-03 23:37:12,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:12,568 INFO:     Epoch: 44
2023-01-03 23:37:14,194 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40392172733942666, 'Total loss': 0.40392172733942666} | train loss {'Reaction outcome loss': 0.24633407473321195, 'Total loss': 0.24633407473321195}
2023-01-03 23:37:14,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:14,194 INFO:     Epoch: 45
2023-01-03 23:37:15,810 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4241350471973419, 'Total loss': 0.4241350471973419} | train loss {'Reaction outcome loss': 0.2429917397507318, 'Total loss': 0.2429917397507318}
2023-01-03 23:37:15,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:15,810 INFO:     Epoch: 46
2023-01-03 23:37:17,413 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4067292588452498, 'Total loss': 0.4067292588452498} | train loss {'Reaction outcome loss': 0.24210049587882299, 'Total loss': 0.24210049587882299}
2023-01-03 23:37:17,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:17,413 INFO:     Epoch: 47
2023-01-03 23:37:19,035 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4151933411757151, 'Total loss': 0.4151933411757151} | train loss {'Reaction outcome loss': 0.24073140910300223, 'Total loss': 0.24073140910300223}
2023-01-03 23:37:19,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:19,035 INFO:     Epoch: 48
2023-01-03 23:37:20,638 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40277526577313744, 'Total loss': 0.40277526577313744} | train loss {'Reaction outcome loss': 0.2411074566155456, 'Total loss': 0.2411074566155456}
2023-01-03 23:37:20,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:20,638 INFO:     Epoch: 49
2023-01-03 23:37:22,241 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4192570408185323, 'Total loss': 0.4192570408185323} | train loss {'Reaction outcome loss': 0.23439514204063386, 'Total loss': 0.23439514204063386}
2023-01-03 23:37:22,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:22,241 INFO:     Epoch: 50
2023-01-03 23:37:23,848 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39695321023464203, 'Total loss': 0.39695321023464203} | train loss {'Reaction outcome loss': 0.23548261653227004, 'Total loss': 0.23548261653227004}
2023-01-03 23:37:23,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:23,848 INFO:     Epoch: 51
2023-01-03 23:37:25,463 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39224346180756886, 'Total loss': 0.39224346180756886} | train loss {'Reaction outcome loss': 0.22844831983514968, 'Total loss': 0.22844831983514968}
2023-01-03 23:37:25,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:25,463 INFO:     Epoch: 52
2023-01-03 23:37:27,066 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40838999251524605, 'Total loss': 0.40838999251524605} | train loss {'Reaction outcome loss': 0.2304019163231082, 'Total loss': 0.2304019163231082}
2023-01-03 23:37:27,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:27,067 INFO:     Epoch: 53
2023-01-03 23:37:28,693 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3954307715098063, 'Total loss': 0.3954307715098063} | train loss {'Reaction outcome loss': 0.22780422254135888, 'Total loss': 0.22780422254135888}
2023-01-03 23:37:28,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:28,693 INFO:     Epoch: 54
2023-01-03 23:37:30,283 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3910793383916219, 'Total loss': 0.3910793383916219} | train loss {'Reaction outcome loss': 0.22347600274403795, 'Total loss': 0.22347600274403795}
2023-01-03 23:37:30,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:30,283 INFO:     Epoch: 55
2023-01-03 23:37:31,892 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38093306024869283, 'Total loss': 0.38093306024869283} | train loss {'Reaction outcome loss': 0.22442435848432174, 'Total loss': 0.22442435848432174}
2023-01-03 23:37:31,892 INFO:     Found new best model at epoch 55
2023-01-03 23:37:31,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:31,893 INFO:     Epoch: 56
2023-01-03 23:37:33,512 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3880819737911224, 'Total loss': 0.3880819737911224} | train loss {'Reaction outcome loss': 0.23022199878334135, 'Total loss': 0.23022199878334135}
2023-01-03 23:37:33,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:33,513 INFO:     Epoch: 57
2023-01-03 23:37:35,128 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40342330634593965, 'Total loss': 0.40342330634593965} | train loss {'Reaction outcome loss': 0.2239077197972211, 'Total loss': 0.2239077197972211}
2023-01-03 23:37:35,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:35,128 INFO:     Epoch: 58
2023-01-03 23:37:36,734 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3955591142177582, 'Total loss': 0.3955591142177582} | train loss {'Reaction outcome loss': 0.21706744602574146, 'Total loss': 0.21706744602574146}
2023-01-03 23:37:36,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:36,734 INFO:     Epoch: 59
2023-01-03 23:37:38,354 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40002671380837757, 'Total loss': 0.40002671380837757} | train loss {'Reaction outcome loss': 0.2144518773167637, 'Total loss': 0.2144518773167637}
2023-01-03 23:37:38,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:38,354 INFO:     Epoch: 60
2023-01-03 23:37:39,945 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4021768828233083, 'Total loss': 0.4021768828233083} | train loss {'Reaction outcome loss': 0.2140753055261313, 'Total loss': 0.2140753055261313}
2023-01-03 23:37:39,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:39,945 INFO:     Epoch: 61
2023-01-03 23:37:41,572 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4018803675969442, 'Total loss': 0.4018803675969442} | train loss {'Reaction outcome loss': 0.2134931767688114, 'Total loss': 0.2134931767688114}
2023-01-03 23:37:41,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:41,572 INFO:     Epoch: 62
2023-01-03 23:37:43,199 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.38419475421930355, 'Total loss': 0.38419475421930355} | train loss {'Reaction outcome loss': 0.20981522572675612, 'Total loss': 0.20981522572675612}
2023-01-03 23:37:43,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:43,199 INFO:     Epoch: 63
2023-01-03 23:37:44,809 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41075295011202495, 'Total loss': 0.41075295011202495} | train loss {'Reaction outcome loss': 0.2084567024957969, 'Total loss': 0.2084567024957969}
2023-01-03 23:37:44,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:44,810 INFO:     Epoch: 64
2023-01-03 23:37:46,421 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4001716713110606, 'Total loss': 0.4001716713110606} | train loss {'Reaction outcome loss': 0.21320188343794882, 'Total loss': 0.21320188343794882}
2023-01-03 23:37:46,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:46,422 INFO:     Epoch: 65
2023-01-03 23:37:47,997 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3869330575068792, 'Total loss': 0.3869330575068792} | train loss {'Reaction outcome loss': 0.22511619934137317, 'Total loss': 0.22511619934137317}
2023-01-03 23:37:47,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:47,997 INFO:     Epoch: 66
2023-01-03 23:37:49,575 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40250287055969236, 'Total loss': 0.40250287055969236} | train loss {'Reaction outcome loss': 0.2045787625914048, 'Total loss': 0.2045787625914048}
2023-01-03 23:37:49,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:49,575 INFO:     Epoch: 67
2023-01-03 23:37:51,168 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3917769839366277, 'Total loss': 0.3917769839366277} | train loss {'Reaction outcome loss': 0.20259257706329928, 'Total loss': 0.20259257706329928}
2023-01-03 23:37:51,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:51,168 INFO:     Epoch: 68
2023-01-03 23:37:52,796 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38115395804246266, 'Total loss': 0.38115395804246266} | train loss {'Reaction outcome loss': 0.20170114725487362, 'Total loss': 0.20170114725487362}
2023-01-03 23:37:52,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:52,796 INFO:     Epoch: 69
2023-01-03 23:37:54,382 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3923780600229899, 'Total loss': 0.3923780600229899} | train loss {'Reaction outcome loss': 0.2010526519289419, 'Total loss': 0.2010526519289419}
2023-01-03 23:37:54,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:54,382 INFO:     Epoch: 70
2023-01-03 23:37:55,960 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38777128656705223, 'Total loss': 0.38777128656705223} | train loss {'Reaction outcome loss': 0.19940025187747779, 'Total loss': 0.19940025187747779}
2023-01-03 23:37:55,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:55,961 INFO:     Epoch: 71
2023-01-03 23:37:57,548 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38223063250382744, 'Total loss': 0.38223063250382744} | train loss {'Reaction outcome loss': 0.19650008282753886, 'Total loss': 0.19650008282753886}
2023-01-03 23:37:57,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:57,548 INFO:     Epoch: 72
2023-01-03 23:37:59,138 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3847663551568985, 'Total loss': 0.3847663551568985} | train loss {'Reaction outcome loss': 0.19632605517896687, 'Total loss': 0.19632605517896687}
2023-01-03 23:37:59,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:37:59,138 INFO:     Epoch: 73
2023-01-03 23:38:00,728 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3806439826885859, 'Total loss': 0.3806439826885859} | train loss {'Reaction outcome loss': 0.1963353897191827, 'Total loss': 0.1963353897191827}
2023-01-03 23:38:00,729 INFO:     Found new best model at epoch 73
2023-01-03 23:38:00,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:00,729 INFO:     Epoch: 74
2023-01-03 23:38:02,318 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39369552036126454, 'Total loss': 0.39369552036126454} | train loss {'Reaction outcome loss': 0.1949983743302848, 'Total loss': 0.1949983743302848}
2023-01-03 23:38:02,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:02,320 INFO:     Epoch: 75
2023-01-03 23:38:03,888 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3943983048200607, 'Total loss': 0.3943983048200607} | train loss {'Reaction outcome loss': 0.19753797723209354, 'Total loss': 0.19753797723209354}
2023-01-03 23:38:03,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:03,888 INFO:     Epoch: 76
2023-01-03 23:38:05,513 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3944505304098129, 'Total loss': 0.3944505304098129} | train loss {'Reaction outcome loss': 0.19367507604358805, 'Total loss': 0.19367507604358805}
2023-01-03 23:38:05,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:05,513 INFO:     Epoch: 77
2023-01-03 23:38:07,094 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38332006136576335, 'Total loss': 0.38332006136576335} | train loss {'Reaction outcome loss': 0.19393603003460896, 'Total loss': 0.19393603003460896}
2023-01-03 23:38:07,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:07,094 INFO:     Epoch: 78
2023-01-03 23:38:08,715 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39289539456367495, 'Total loss': 0.39289539456367495} | train loss {'Reaction outcome loss': 0.1901274268746558, 'Total loss': 0.1901274268746558}
2023-01-03 23:38:08,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:08,716 INFO:     Epoch: 79
2023-01-03 23:38:10,340 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3835021466016769, 'Total loss': 0.3835021466016769} | train loss {'Reaction outcome loss': 0.19193468083614024, 'Total loss': 0.19193468083614024}
2023-01-03 23:38:10,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:10,340 INFO:     Epoch: 80
2023-01-03 23:38:11,937 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3992082715034485, 'Total loss': 0.3992082715034485} | train loss {'Reaction outcome loss': 0.1886564699938838, 'Total loss': 0.1886564699938838}
2023-01-03 23:38:11,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:11,937 INFO:     Epoch: 81
2023-01-03 23:38:13,532 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40558623025814694, 'Total loss': 0.40558623025814694} | train loss {'Reaction outcome loss': 0.18861765415815593, 'Total loss': 0.18861765415815593}
2023-01-03 23:38:13,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:13,533 INFO:     Epoch: 82
2023-01-03 23:38:15,113 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3780714561541875, 'Total loss': 0.3780714561541875} | train loss {'Reaction outcome loss': 0.18836849942454137, 'Total loss': 0.18836849942454137}
2023-01-03 23:38:15,113 INFO:     Found new best model at epoch 82
2023-01-03 23:38:15,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:15,114 INFO:     Epoch: 83
2023-01-03 23:38:16,720 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40774298906326295, 'Total loss': 0.40774298906326295} | train loss {'Reaction outcome loss': 0.19379553258203078, 'Total loss': 0.19379553258203078}
2023-01-03 23:38:16,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:16,720 INFO:     Epoch: 84
2023-01-03 23:38:18,339 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38168550133705137, 'Total loss': 0.38168550133705137} | train loss {'Reaction outcome loss': 0.1936937283135861, 'Total loss': 0.1936937283135861}
2023-01-03 23:38:18,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:18,340 INFO:     Epoch: 85
2023-01-03 23:38:19,957 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3865684747695923, 'Total loss': 0.3865684747695923} | train loss {'Reaction outcome loss': 0.1861584002795955, 'Total loss': 0.1861584002795955}
2023-01-03 23:38:19,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:19,957 INFO:     Epoch: 86
2023-01-03 23:38:21,545 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38957542379697163, 'Total loss': 0.38957542379697163} | train loss {'Reaction outcome loss': 0.18265962199243865, 'Total loss': 0.18265962199243865}
2023-01-03 23:38:21,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:21,546 INFO:     Epoch: 87
2023-01-03 23:38:23,138 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39107078512509663, 'Total loss': 0.39107078512509663} | train loss {'Reaction outcome loss': 0.1850744396050805, 'Total loss': 0.1850744396050805}
2023-01-03 23:38:23,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:23,138 INFO:     Epoch: 88
2023-01-03 23:38:24,731 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38239497542381284, 'Total loss': 0.38239497542381284} | train loss {'Reaction outcome loss': 0.1847768721270478, 'Total loss': 0.1847768721270478}
2023-01-03 23:38:24,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:24,731 INFO:     Epoch: 89
2023-01-03 23:38:26,348 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3923035015662511, 'Total loss': 0.3923035015662511} | train loss {'Reaction outcome loss': 0.18124459210810237, 'Total loss': 0.18124459210810237}
2023-01-03 23:38:26,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:26,348 INFO:     Epoch: 90
2023-01-03 23:38:27,963 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40331151286760963, 'Total loss': 0.40331151286760963} | train loss {'Reaction outcome loss': 0.18181223890734027, 'Total loss': 0.18181223890734027}
2023-01-03 23:38:27,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:27,964 INFO:     Epoch: 91
2023-01-03 23:38:29,560 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3831180493036906, 'Total loss': 0.3831180493036906} | train loss {'Reaction outcome loss': 0.18472719488098568, 'Total loss': 0.18472719488098568}
2023-01-03 23:38:29,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:29,560 INFO:     Epoch: 92
2023-01-03 23:38:31,147 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3978592216968536, 'Total loss': 0.3978592216968536} | train loss {'Reaction outcome loss': 0.19656370509545779, 'Total loss': 0.19656370509545779}
2023-01-03 23:38:31,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:31,147 INFO:     Epoch: 93
2023-01-03 23:38:32,727 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3781738157073657, 'Total loss': 0.3781738157073657} | train loss {'Reaction outcome loss': 0.18096585022183295, 'Total loss': 0.18096585022183295}
2023-01-03 23:38:32,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:32,729 INFO:     Epoch: 94
2023-01-03 23:38:34,337 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38989415764808655, 'Total loss': 0.38989415764808655} | train loss {'Reaction outcome loss': 0.17675605416910833, 'Total loss': 0.17675605416910833}
2023-01-03 23:38:34,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:34,337 INFO:     Epoch: 95
2023-01-03 23:38:35,967 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3952579120794932, 'Total loss': 0.3952579120794932} | train loss {'Reaction outcome loss': 0.17782530885027803, 'Total loss': 0.17782530885027803}
2023-01-03 23:38:35,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:35,967 INFO:     Epoch: 96
2023-01-03 23:38:37,597 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3970649739106496, 'Total loss': 0.3970649739106496} | train loss {'Reaction outcome loss': 0.17790437816048338, 'Total loss': 0.17790437816048338}
2023-01-03 23:38:37,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:37,597 INFO:     Epoch: 97
2023-01-03 23:38:39,180 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38455667197704313, 'Total loss': 0.38455667197704313} | train loss {'Reaction outcome loss': 0.17852884823282628, 'Total loss': 0.17852884823282628}
2023-01-03 23:38:39,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:39,181 INFO:     Epoch: 98
2023-01-03 23:38:40,780 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3800603618224462, 'Total loss': 0.3800603618224462} | train loss {'Reaction outcome loss': 0.1737869041982465, 'Total loss': 0.1737869041982465}
2023-01-03 23:38:40,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:40,780 INFO:     Epoch: 99
2023-01-03 23:38:42,351 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39695951839288074, 'Total loss': 0.39695951839288074} | train loss {'Reaction outcome loss': 0.17422461124566413, 'Total loss': 0.17422461124566413}
2023-01-03 23:38:42,352 INFO:     Best model found after epoch 83 of 100.
2023-01-03 23:38:42,352 INFO:   Done with stage: TRAINING
2023-01-03 23:38:42,352 INFO:   Starting stage: EVALUATION
2023-01-03 23:38:42,481 INFO:   Done with stage: EVALUATION
2023-01-03 23:38:42,481 INFO:   Leaving out SEQ value Fold_6
2023-01-03 23:38:42,493 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-03 23:38:42,493 INFO:   Starting stage: FEATURE SCALING
2023-01-03 23:38:43,140 INFO:   Done with stage: FEATURE SCALING
2023-01-03 23:38:43,140 INFO:   Starting stage: SCALING TARGETS
2023-01-03 23:38:43,210 INFO:   Done with stage: SCALING TARGETS
2023-01-03 23:38:43,210 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:38:43,210 INFO:     No hyperparam tuning for this model
2023-01-03 23:38:43,210 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:38:43,210 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 23:38:43,211 INFO:     None feature selector for col prot
2023-01-03 23:38:43,211 INFO:     None feature selector for col prot
2023-01-03 23:38:43,211 INFO:     None feature selector for col prot
2023-01-03 23:38:43,211 INFO:     None feature selector for col chem
2023-01-03 23:38:43,211 INFO:     None feature selector for col chem
2023-01-03 23:38:43,212 INFO:     None feature selector for col chem
2023-01-03 23:38:43,212 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 23:38:43,212 INFO:   Starting stage: BUILD MODEL
2023-01-03 23:38:43,213 INFO:     Number of params in model 70141
2023-01-03 23:38:43,216 INFO:   Done with stage: BUILD MODEL
2023-01-03 23:38:43,216 INFO:   Starting stage: TRAINING
2023-01-03 23:38:43,261 INFO:     Val loss before train {'Reaction outcome loss': 1.0650955756505331, 'Total loss': 1.0650955756505331}
2023-01-03 23:38:43,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:43,262 INFO:     Epoch: 0
2023-01-03 23:38:44,859 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7621620118618011, 'Total loss': 0.7621620118618011} | train loss {'Reaction outcome loss': 0.8424163611356963, 'Total loss': 0.8424163611356963}
2023-01-03 23:38:44,860 INFO:     Found new best model at epoch 0
2023-01-03 23:38:44,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:44,860 INFO:     Epoch: 1
2023-01-03 23:38:46,451 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6263421992460887, 'Total loss': 0.6263421992460887} | train loss {'Reaction outcome loss': 0.6057691124372103, 'Total loss': 0.6057691124372103}
2023-01-03 23:38:46,451 INFO:     Found new best model at epoch 1
2023-01-03 23:38:46,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:46,452 INFO:     Epoch: 2
2023-01-03 23:38:48,027 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5930182099342346, 'Total loss': 0.5930182099342346} | train loss {'Reaction outcome loss': 0.5242668092788773, 'Total loss': 0.5242668092788773}
2023-01-03 23:38:48,028 INFO:     Found new best model at epoch 2
2023-01-03 23:38:48,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:48,028 INFO:     Epoch: 3
2023-01-03 23:38:49,628 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5752724329630534, 'Total loss': 0.5752724329630534} | train loss {'Reaction outcome loss': 0.4835000127984298, 'Total loss': 0.4835000127984298}
2023-01-03 23:38:49,628 INFO:     Found new best model at epoch 3
2023-01-03 23:38:49,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:49,629 INFO:     Epoch: 4
2023-01-03 23:38:51,218 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5508748292922974, 'Total loss': 0.5508748292922974} | train loss {'Reaction outcome loss': 0.4554822710662112, 'Total loss': 0.4554822710662112}
2023-01-03 23:38:51,219 INFO:     Found new best model at epoch 4
2023-01-03 23:38:51,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:51,220 INFO:     Epoch: 5
2023-01-03 23:38:52,822 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5429861366748809, 'Total loss': 0.5429861366748809} | train loss {'Reaction outcome loss': 0.43805395308814754, 'Total loss': 0.43805395308814754}
2023-01-03 23:38:52,822 INFO:     Found new best model at epoch 5
2023-01-03 23:38:52,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:52,823 INFO:     Epoch: 6
2023-01-03 23:38:54,427 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.535662317276001, 'Total loss': 0.535662317276001} | train loss {'Reaction outcome loss': 0.4183355540252334, 'Total loss': 0.4183355540252334}
2023-01-03 23:38:54,427 INFO:     Found new best model at epoch 6
2023-01-03 23:38:54,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:54,428 INFO:     Epoch: 7
2023-01-03 23:38:56,032 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5191100200017293, 'Total loss': 0.5191100200017293} | train loss {'Reaction outcome loss': 0.40465054039705534, 'Total loss': 0.40465054039705534}
2023-01-03 23:38:56,032 INFO:     Found new best model at epoch 7
2023-01-03 23:38:56,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:56,033 INFO:     Epoch: 8
2023-01-03 23:38:57,654 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4996167063713074, 'Total loss': 0.4996167063713074} | train loss {'Reaction outcome loss': 0.39369313752393, 'Total loss': 0.39369313752393}
2023-01-03 23:38:57,654 INFO:     Found new best model at epoch 8
2023-01-03 23:38:57,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:57,655 INFO:     Epoch: 9
2023-01-03 23:38:59,280 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5023040016492207, 'Total loss': 0.5023040016492207} | train loss {'Reaction outcome loss': 0.38287381887005556, 'Total loss': 0.38287381887005556}
2023-01-03 23:38:59,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:38:59,281 INFO:     Epoch: 10
2023-01-03 23:39:00,866 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5077216664950053, 'Total loss': 0.5077216664950053} | train loss {'Reaction outcome loss': 0.37450468793027236, 'Total loss': 0.37450468793027236}
2023-01-03 23:39:00,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:00,866 INFO:     Epoch: 11
2023-01-03 23:39:02,471 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5085300077994664, 'Total loss': 0.5085300077994664} | train loss {'Reaction outcome loss': 0.36728592286901784, 'Total loss': 0.36728592286901784}
2023-01-03 23:39:02,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:02,471 INFO:     Epoch: 12
2023-01-03 23:39:04,075 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5035705983638763, 'Total loss': 0.5035705983638763} | train loss {'Reaction outcome loss': 0.3580960737615286, 'Total loss': 0.3580960737615286}
2023-01-03 23:39:04,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:04,076 INFO:     Epoch: 13
2023-01-03 23:39:05,662 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4971610873937607, 'Total loss': 0.4971610873937607} | train loss {'Reaction outcome loss': 0.35076095881982833, 'Total loss': 0.35076095881982833}
2023-01-03 23:39:05,662 INFO:     Found new best model at epoch 13
2023-01-03 23:39:05,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:05,663 INFO:     Epoch: 14
2023-01-03 23:39:07,305 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49558433492978415, 'Total loss': 0.49558433492978415} | train loss {'Reaction outcome loss': 0.34589828012867524, 'Total loss': 0.34589828012867524}
2023-01-03 23:39:07,305 INFO:     Found new best model at epoch 14
2023-01-03 23:39:07,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:07,306 INFO:     Epoch: 15
2023-01-03 23:39:08,881 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5070827911297481, 'Total loss': 0.5070827911297481} | train loss {'Reaction outcome loss': 0.33836711190022284, 'Total loss': 0.33836711190022284}
2023-01-03 23:39:08,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:08,881 INFO:     Epoch: 16
2023-01-03 23:39:10,486 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4777056773503621, 'Total loss': 0.4777056773503621} | train loss {'Reaction outcome loss': 0.3336694516806396, 'Total loss': 0.3336694516806396}
2023-01-03 23:39:10,486 INFO:     Found new best model at epoch 16
2023-01-03 23:39:10,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:10,487 INFO:     Epoch: 17
2023-01-03 23:39:12,088 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49031325181325275, 'Total loss': 0.49031325181325275} | train loss {'Reaction outcome loss': 0.32594745350658677, 'Total loss': 0.32594745350658677}
2023-01-03 23:39:12,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:12,088 INFO:     Epoch: 18
2023-01-03 23:39:13,689 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4810024708509445, 'Total loss': 0.4810024708509445} | train loss {'Reaction outcome loss': 0.32137934422449943, 'Total loss': 0.32137934422449943}
2023-01-03 23:39:13,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:13,690 INFO:     Epoch: 19
2023-01-03 23:39:15,294 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4804615487655004, 'Total loss': 0.4804615487655004} | train loss {'Reaction outcome loss': 0.31715624214617355, 'Total loss': 0.31715624214617355}
2023-01-03 23:39:15,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:15,294 INFO:     Epoch: 20
2023-01-03 23:39:16,880 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4774496326843897, 'Total loss': 0.4774496326843897} | train loss {'Reaction outcome loss': 0.31151125978153965, 'Total loss': 0.31151125978153965}
2023-01-03 23:39:16,880 INFO:     Found new best model at epoch 20
2023-01-03 23:39:16,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:16,881 INFO:     Epoch: 21
2023-01-03 23:39:18,487 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4918009469906489, 'Total loss': 0.4918009469906489} | train loss {'Reaction outcome loss': 0.30654424453147483, 'Total loss': 0.30654424453147483}
2023-01-03 23:39:18,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:18,487 INFO:     Epoch: 22
2023-01-03 23:39:20,110 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4644192586342494, 'Total loss': 0.4644192586342494} | train loss {'Reaction outcome loss': 0.30290958922800176, 'Total loss': 0.30290958922800176}
2023-01-03 23:39:20,111 INFO:     Found new best model at epoch 22
2023-01-03 23:39:20,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:20,111 INFO:     Epoch: 23
2023-01-03 23:39:21,750 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4666849712530772, 'Total loss': 0.4666849712530772} | train loss {'Reaction outcome loss': 0.29979875849203513, 'Total loss': 0.29979875849203513}
2023-01-03 23:39:21,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:21,750 INFO:     Epoch: 24
2023-01-03 23:39:23,321 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4670763870080312, 'Total loss': 0.4670763870080312} | train loss {'Reaction outcome loss': 0.29522215206485364, 'Total loss': 0.29522215206485364}
2023-01-03 23:39:23,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:23,322 INFO:     Epoch: 25
2023-01-03 23:39:24,955 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.47833935419718426, 'Total loss': 0.47833935419718426} | train loss {'Reaction outcome loss': 0.29162882682648805, 'Total loss': 0.29162882682648805}
2023-01-03 23:39:24,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:24,955 INFO:     Epoch: 26
2023-01-03 23:39:26,530 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4753479142983755, 'Total loss': 0.4753479142983755} | train loss {'Reaction outcome loss': 0.2860909272993945, 'Total loss': 0.2860909272993945}
2023-01-03 23:39:26,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:26,531 INFO:     Epoch: 27
2023-01-03 23:39:28,136 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4757401873668035, 'Total loss': 0.4757401873668035} | train loss {'Reaction outcome loss': 0.2837812611127158, 'Total loss': 0.2837812611127158}
2023-01-03 23:39:28,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:28,136 INFO:     Epoch: 28
2023-01-03 23:39:29,741 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4652248760064443, 'Total loss': 0.4652248760064443} | train loss {'Reaction outcome loss': 0.27974231909651187, 'Total loss': 0.27974231909651187}
2023-01-03 23:39:29,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:29,741 INFO:     Epoch: 29
2023-01-03 23:39:31,345 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.451432541012764, 'Total loss': 0.451432541012764} | train loss {'Reaction outcome loss': 0.2751168485206387, 'Total loss': 0.2751168485206387}
2023-01-03 23:39:31,345 INFO:     Found new best model at epoch 29
2023-01-03 23:39:31,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:31,346 INFO:     Epoch: 30
2023-01-03 23:39:32,924 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48412186503410337, 'Total loss': 0.48412186503410337} | train loss {'Reaction outcome loss': 0.2712742782967831, 'Total loss': 0.2712742782967831}
2023-01-03 23:39:32,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:32,924 INFO:     Epoch: 31
2023-01-03 23:39:34,567 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4720174133777618, 'Total loss': 0.4720174133777618} | train loss {'Reaction outcome loss': 0.26988656757002705, 'Total loss': 0.26988656757002705}
2023-01-03 23:39:34,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:34,567 INFO:     Epoch: 32
2023-01-03 23:39:36,179 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4765350619951884, 'Total loss': 0.4765350619951884} | train loss {'Reaction outcome loss': 0.2681359966631831, 'Total loss': 0.2681359966631831}
2023-01-03 23:39:36,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:36,179 INFO:     Epoch: 33
2023-01-03 23:39:37,765 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47687341570854186, 'Total loss': 0.47687341570854186} | train loss {'Reaction outcome loss': 0.2621606223096916, 'Total loss': 0.2621606223096916}
2023-01-03 23:39:37,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:37,765 INFO:     Epoch: 34
2023-01-03 23:39:39,390 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47080331246058144, 'Total loss': 0.47080331246058144} | train loss {'Reaction outcome loss': 0.26047625794791573, 'Total loss': 0.26047625794791573}
2023-01-03 23:39:39,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:39,392 INFO:     Epoch: 35
2023-01-03 23:39:41,019 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44460375010967257, 'Total loss': 0.44460375010967257} | train loss {'Reaction outcome loss': 0.2562079826497644, 'Total loss': 0.2562079826497644}
2023-01-03 23:39:41,019 INFO:     Found new best model at epoch 35
2023-01-03 23:39:41,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:41,020 INFO:     Epoch: 36
2023-01-03 23:39:42,641 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46931227246920265, 'Total loss': 0.46931227246920265} | train loss {'Reaction outcome loss': 0.2525996661977002, 'Total loss': 0.2525996661977002}
2023-01-03 23:39:42,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:42,641 INFO:     Epoch: 37
2023-01-03 23:39:44,257 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4509295463562012, 'Total loss': 0.4509295463562012} | train loss {'Reaction outcome loss': 0.24776813280281176, 'Total loss': 0.24776813280281176}
2023-01-03 23:39:44,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:44,257 INFO:     Epoch: 38
2023-01-03 23:39:45,865 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4638291339079539, 'Total loss': 0.4638291339079539} | train loss {'Reaction outcome loss': 0.24752265613001606, 'Total loss': 0.24752265613001606}
2023-01-03 23:39:45,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:45,866 INFO:     Epoch: 39
2023-01-03 23:39:47,504 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4714480102062225, 'Total loss': 0.4714480102062225} | train loss {'Reaction outcome loss': 0.24484339711468142, 'Total loss': 0.24484339711468142}
2023-01-03 23:39:47,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:47,505 INFO:     Epoch: 40
2023-01-03 23:39:49,132 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45286565919717153, 'Total loss': 0.45286565919717153} | train loss {'Reaction outcome loss': 0.2435457127215845, 'Total loss': 0.2435457127215845}
2023-01-03 23:39:49,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:49,132 INFO:     Epoch: 41
2023-01-03 23:39:50,727 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4562807391087214, 'Total loss': 0.4562807391087214} | train loss {'Reaction outcome loss': 0.23901057665636394, 'Total loss': 0.23901057665636394}
2023-01-03 23:39:50,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:50,727 INFO:     Epoch: 42
2023-01-03 23:39:52,329 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4604658842086792, 'Total loss': 0.4604658842086792} | train loss {'Reaction outcome loss': 0.2372746626150522, 'Total loss': 0.2372746626150522}
2023-01-03 23:39:52,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:52,329 INFO:     Epoch: 43
2023-01-03 23:39:53,935 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45315205057462055, 'Total loss': 0.45315205057462055} | train loss {'Reaction outcome loss': 0.23639516723392673, 'Total loss': 0.23639516723392673}
2023-01-03 23:39:53,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:53,935 INFO:     Epoch: 44
2023-01-03 23:39:55,537 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4607442001501719, 'Total loss': 0.4607442001501719} | train loss {'Reaction outcome loss': 0.23059469243572076, 'Total loss': 0.23059469243572076}
2023-01-03 23:39:55,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:55,537 INFO:     Epoch: 45
2023-01-03 23:39:57,139 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44855158527692157, 'Total loss': 0.44855158527692157} | train loss {'Reaction outcome loss': 0.23021126827662172, 'Total loss': 0.23021126827662172}
2023-01-03 23:39:57,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:57,139 INFO:     Epoch: 46
2023-01-03 23:39:58,740 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.466967961192131, 'Total loss': 0.466967961192131} | train loss {'Reaction outcome loss': 0.22823563956450468, 'Total loss': 0.22823563956450468}
2023-01-03 23:39:58,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:39:58,741 INFO:     Epoch: 47
2023-01-03 23:40:00,345 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4622943103313446, 'Total loss': 0.4622943103313446} | train loss {'Reaction outcome loss': 0.22623864252671652, 'Total loss': 0.22623864252671652}
2023-01-03 23:40:00,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:00,345 INFO:     Epoch: 48
2023-01-03 23:40:01,983 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.447178981701533, 'Total loss': 0.447178981701533} | train loss {'Reaction outcome loss': 0.22468895864562008, 'Total loss': 0.22468895864562008}
2023-01-03 23:40:01,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:01,983 INFO:     Epoch: 49
2023-01-03 23:40:03,582 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4460022946198781, 'Total loss': 0.4460022946198781} | train loss {'Reaction outcome loss': 0.2224180499353994, 'Total loss': 0.2224180499353994}
2023-01-03 23:40:03,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:03,582 INFO:     Epoch: 50
2023-01-03 23:40:05,212 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4450370967388153, 'Total loss': 0.4450370967388153} | train loss {'Reaction outcome loss': 0.21713694706828154, 'Total loss': 0.21713694706828154}
2023-01-03 23:40:05,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:05,212 INFO:     Epoch: 51
2023-01-03 23:40:06,834 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44922994673252103, 'Total loss': 0.44922994673252103} | train loss {'Reaction outcome loss': 0.21559360826435073, 'Total loss': 0.21559360826435073}
2023-01-03 23:40:06,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:06,834 INFO:     Epoch: 52
2023-01-03 23:40:08,380 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4499282717704773, 'Total loss': 0.4499282717704773} | train loss {'Reaction outcome loss': 0.2142086669076436, 'Total loss': 0.2142086669076436}
2023-01-03 23:40:08,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:08,381 INFO:     Epoch: 53
2023-01-03 23:40:09,463 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4358305662870407, 'Total loss': 0.4358305662870407} | train loss {'Reaction outcome loss': 0.21323834194899252, 'Total loss': 0.21323834194899252}
2023-01-03 23:40:09,463 INFO:     Found new best model at epoch 53
2023-01-03 23:40:09,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:09,464 INFO:     Epoch: 54
2023-01-03 23:40:10,553 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4519366631905238, 'Total loss': 0.4519366631905238} | train loss {'Reaction outcome loss': 0.21291677075495358, 'Total loss': 0.21291677075495358}
2023-01-03 23:40:10,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:10,554 INFO:     Epoch: 55
2023-01-03 23:40:11,638 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4428261657555898, 'Total loss': 0.4428261657555898} | train loss {'Reaction outcome loss': 0.21233932828591187, 'Total loss': 0.21233932828591187}
2023-01-03 23:40:11,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:11,638 INFO:     Epoch: 56
2023-01-03 23:40:12,870 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43733423749605815, 'Total loss': 0.43733423749605815} | train loss {'Reaction outcome loss': 0.2066261391104989, 'Total loss': 0.2066261391104989}
2023-01-03 23:40:12,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:12,870 INFO:     Epoch: 57
2023-01-03 23:40:14,472 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44957703749338784, 'Total loss': 0.44957703749338784} | train loss {'Reaction outcome loss': 0.20728054123557432, 'Total loss': 0.20728054123557432}
2023-01-03 23:40:14,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:14,473 INFO:     Epoch: 58
2023-01-03 23:40:16,075 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4490678350130717, 'Total loss': 0.4490678350130717} | train loss {'Reaction outcome loss': 0.20601046539923776, 'Total loss': 0.20601046539923776}
2023-01-03 23:40:16,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:16,075 INFO:     Epoch: 59
2023-01-03 23:40:17,677 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44641582171122235, 'Total loss': 0.44641582171122235} | train loss {'Reaction outcome loss': 0.20304714496977064, 'Total loss': 0.20304714496977064}
2023-01-03 23:40:17,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:17,678 INFO:     Epoch: 60
2023-01-03 23:40:19,267 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4609804779291153, 'Total loss': 0.4609804779291153} | train loss {'Reaction outcome loss': 0.20308391388761224, 'Total loss': 0.20308391388761224}
2023-01-03 23:40:19,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:19,268 INFO:     Epoch: 61
2023-01-03 23:40:20,888 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44764336546262107, 'Total loss': 0.44764336546262107} | train loss {'Reaction outcome loss': 0.20223672569658782, 'Total loss': 0.20223672569658782}
2023-01-03 23:40:20,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:20,888 INFO:     Epoch: 62
2023-01-03 23:40:22,481 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4428296685218811, 'Total loss': 0.4428296685218811} | train loss {'Reaction outcome loss': 0.20069159744206533, 'Total loss': 0.20069159744206533}
2023-01-03 23:40:22,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:22,481 INFO:     Epoch: 63
2023-01-03 23:40:24,114 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.457125590244929, 'Total loss': 0.457125590244929} | train loss {'Reaction outcome loss': 0.200037487362266, 'Total loss': 0.200037487362266}
2023-01-03 23:40:24,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:24,115 INFO:     Epoch: 64
2023-01-03 23:40:25,720 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4303200334310532, 'Total loss': 0.4303200334310532} | train loss {'Reaction outcome loss': 0.19838049787261425, 'Total loss': 0.19838049787261425}
2023-01-03 23:40:25,720 INFO:     Found new best model at epoch 64
2023-01-03 23:40:25,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:25,721 INFO:     Epoch: 65
2023-01-03 23:40:27,300 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44990038871765137, 'Total loss': 0.44990038871765137} | train loss {'Reaction outcome loss': 0.19523264611617322, 'Total loss': 0.19523264611617322}
2023-01-03 23:40:27,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:27,300 INFO:     Epoch: 66
2023-01-03 23:40:28,900 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4325986593961716, 'Total loss': 0.4325986593961716} | train loss {'Reaction outcome loss': 0.19451248387567402, 'Total loss': 0.19451248387567402}
2023-01-03 23:40:28,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:28,900 INFO:     Epoch: 67
2023-01-03 23:40:30,515 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4421751469373703, 'Total loss': 0.4421751469373703} | train loss {'Reaction outcome loss': 0.19309604025381996, 'Total loss': 0.19309604025381996}
2023-01-03 23:40:30,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:30,516 INFO:     Epoch: 68
2023-01-03 23:40:32,161 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42313433686892193, 'Total loss': 0.42313433686892193} | train loss {'Reaction outcome loss': 0.19437467344508705, 'Total loss': 0.19437467344508705}
2023-01-03 23:40:32,161 INFO:     Found new best model at epoch 68
2023-01-03 23:40:32,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:32,162 INFO:     Epoch: 69
2023-01-03 23:40:33,748 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4392973482608795, 'Total loss': 0.4392973482608795} | train loss {'Reaction outcome loss': 0.19228012429462873, 'Total loss': 0.19228012429462873}
2023-01-03 23:40:33,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:33,748 INFO:     Epoch: 70
2023-01-03 23:40:35,372 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4514322727918625, 'Total loss': 0.4514322727918625} | train loss {'Reaction outcome loss': 0.1907759415732179, 'Total loss': 0.1907759415732179}
2023-01-03 23:40:35,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:35,372 INFO:     Epoch: 71
2023-01-03 23:40:36,965 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4277418002486229, 'Total loss': 0.4277418002486229} | train loss {'Reaction outcome loss': 0.18788405803674396, 'Total loss': 0.18788405803674396}
2023-01-03 23:40:36,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:36,965 INFO:     Epoch: 72
2023-01-03 23:40:38,563 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44374560117721557, 'Total loss': 0.44374560117721557} | train loss {'Reaction outcome loss': 0.187005982428305, 'Total loss': 0.187005982428305}
2023-01-03 23:40:38,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:38,563 INFO:     Epoch: 73
2023-01-03 23:40:40,151 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4347359885772069, 'Total loss': 0.4347359885772069} | train loss {'Reaction outcome loss': 0.1884673204918523, 'Total loss': 0.1884673204918523}
2023-01-03 23:40:40,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:40,152 INFO:     Epoch: 74
2023-01-03 23:40:41,768 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42404590745766957, 'Total loss': 0.42404590745766957} | train loss {'Reaction outcome loss': 0.18626108446867887, 'Total loss': 0.18626108446867887}
2023-01-03 23:40:41,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:41,769 INFO:     Epoch: 75
2023-01-03 23:40:43,390 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4173024594783783, 'Total loss': 0.4173024594783783} | train loss {'Reaction outcome loss': 0.18821049317556168, 'Total loss': 0.18821049317556168}
2023-01-03 23:40:43,390 INFO:     Found new best model at epoch 75
2023-01-03 23:40:43,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:43,391 INFO:     Epoch: 76
2023-01-03 23:40:44,982 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43057245165109637, 'Total loss': 0.43057245165109637} | train loss {'Reaction outcome loss': 0.1834511414762008, 'Total loss': 0.1834511414762008}
2023-01-03 23:40:44,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:44,982 INFO:     Epoch: 77
2023-01-03 23:40:46,582 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40754098892211915, 'Total loss': 0.40754098892211915} | train loss {'Reaction outcome loss': 0.18059696660575453, 'Total loss': 0.18059696660575453}
2023-01-03 23:40:46,582 INFO:     Found new best model at epoch 77
2023-01-03 23:40:46,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:46,583 INFO:     Epoch: 78
2023-01-03 23:40:48,205 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43658841053644815, 'Total loss': 0.43658841053644815} | train loss {'Reaction outcome loss': 0.1810522560931285, 'Total loss': 0.1810522560931285}
2023-01-03 23:40:48,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:48,206 INFO:     Epoch: 79
2023-01-03 23:40:49,830 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43755614161491396, 'Total loss': 0.43755614161491396} | train loss {'Reaction outcome loss': 0.18191394742430333, 'Total loss': 0.18191394742430333}
2023-01-03 23:40:49,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:49,830 INFO:     Epoch: 80
2023-01-03 23:40:51,447 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4367545227209727, 'Total loss': 0.4367545227209727} | train loss {'Reaction outcome loss': 0.180259863136585, 'Total loss': 0.180259863136585}
2023-01-03 23:40:51,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:51,447 INFO:     Epoch: 81
2023-01-03 23:40:53,042 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43893635471661885, 'Total loss': 0.43893635471661885} | train loss {'Reaction outcome loss': 0.17997928705429558, 'Total loss': 0.17997928705429558}
2023-01-03 23:40:53,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:53,042 INFO:     Epoch: 82
2023-01-03 23:40:54,663 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4359863340854645, 'Total loss': 0.4359863340854645} | train loss {'Reaction outcome loss': 0.17811561623312505, 'Total loss': 0.17811561623312505}
2023-01-03 23:40:54,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:54,663 INFO:     Epoch: 83
2023-01-03 23:40:56,296 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43966793616612754, 'Total loss': 0.43966793616612754} | train loss {'Reaction outcome loss': 0.17582893977446032, 'Total loss': 0.17582893977446032}
2023-01-03 23:40:56,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:56,296 INFO:     Epoch: 84
2023-01-03 23:40:57,925 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4360993107159932, 'Total loss': 0.4360993107159932} | train loss {'Reaction outcome loss': 0.17639692466611898, 'Total loss': 0.17639692466611898}
2023-01-03 23:40:57,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:57,925 INFO:     Epoch: 85
2023-01-03 23:40:59,553 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43238570789496106, 'Total loss': 0.43238570789496106} | train loss {'Reaction outcome loss': 0.1760779092229553, 'Total loss': 0.1760779092229553}
2023-01-03 23:40:59,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:40:59,553 INFO:     Epoch: 86
2023-01-03 23:41:01,188 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43130910595258076, 'Total loss': 0.43130910595258076} | train loss {'Reaction outcome loss': 0.17599030210223007, 'Total loss': 0.17599030210223007}
2023-01-03 23:41:01,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:01,189 INFO:     Epoch: 87
2023-01-03 23:41:02,821 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43567223449548087, 'Total loss': 0.43567223449548087} | train loss {'Reaction outcome loss': 0.17269667772582936, 'Total loss': 0.17269667772582936}
2023-01-03 23:41:02,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:02,821 INFO:     Epoch: 88
2023-01-03 23:41:04,452 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44146137436230976, 'Total loss': 0.44146137436230976} | train loss {'Reaction outcome loss': 0.17160720195258136, 'Total loss': 0.17160720195258136}
2023-01-03 23:41:04,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:04,453 INFO:     Epoch: 89
2023-01-03 23:41:06,080 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.455083592236042, 'Total loss': 0.455083592236042} | train loss {'Reaction outcome loss': 0.1735644145626642, 'Total loss': 0.1735644145626642}
2023-01-03 23:41:06,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:06,080 INFO:     Epoch: 90
2023-01-03 23:41:07,691 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4386560375491778, 'Total loss': 0.4386560375491778} | train loss {'Reaction outcome loss': 0.17285527381709767, 'Total loss': 0.17285527381709767}
2023-01-03 23:41:07,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:07,691 INFO:     Epoch: 91
2023-01-03 23:41:09,319 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4403897027174632, 'Total loss': 0.4403897027174632} | train loss {'Reaction outcome loss': 0.17040831647436758, 'Total loss': 0.17040831647436758}
2023-01-03 23:41:09,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:09,320 INFO:     Epoch: 92
2023-01-03 23:41:10,947 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4288701375325521, 'Total loss': 0.4288701375325521} | train loss {'Reaction outcome loss': 0.17055585624697192, 'Total loss': 0.17055585624697192}
2023-01-03 23:41:10,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:10,947 INFO:     Epoch: 93
2023-01-03 23:41:12,554 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46421907246112826, 'Total loss': 0.46421907246112826} | train loss {'Reaction outcome loss': 0.1709735946803747, 'Total loss': 0.1709735946803747}
2023-01-03 23:41:12,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:12,554 INFO:     Epoch: 94
2023-01-03 23:41:14,180 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4557391901810964, 'Total loss': 0.4557391901810964} | train loss {'Reaction outcome loss': 0.16826346591249486, 'Total loss': 0.16826346591249486}
2023-01-03 23:41:14,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:14,180 INFO:     Epoch: 95
2023-01-03 23:41:15,786 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45508324205875395, 'Total loss': 0.45508324205875395} | train loss {'Reaction outcome loss': 0.16812900553326315, 'Total loss': 0.16812900553326315}
2023-01-03 23:41:15,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:15,786 INFO:     Epoch: 96
2023-01-03 23:41:17,414 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43973056475321454, 'Total loss': 0.43973056475321454} | train loss {'Reaction outcome loss': 0.1669086600495805, 'Total loss': 0.1669086600495805}
2023-01-03 23:41:17,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:17,415 INFO:     Epoch: 97
2023-01-03 23:41:19,017 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44384844104448956, 'Total loss': 0.44384844104448956} | train loss {'Reaction outcome loss': 0.16867206768142834, 'Total loss': 0.16867206768142834}
2023-01-03 23:41:19,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:19,018 INFO:     Epoch: 98
2023-01-03 23:41:20,640 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4261357774337133, 'Total loss': 0.4261357774337133} | train loss {'Reaction outcome loss': 0.1659648066608484, 'Total loss': 0.1659648066608484}
2023-01-03 23:41:20,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:20,640 INFO:     Epoch: 99
2023-01-03 23:41:22,225 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43164796431859337, 'Total loss': 0.43164796431859337} | train loss {'Reaction outcome loss': 0.1664765824022491, 'Total loss': 0.1664765824022491}
2023-01-03 23:41:22,225 INFO:     Best model found after epoch 78 of 100.
2023-01-03 23:41:22,225 INFO:   Done with stage: TRAINING
2023-01-03 23:41:22,225 INFO:   Starting stage: EVALUATION
2023-01-03 23:41:22,348 INFO:   Done with stage: EVALUATION
2023-01-03 23:41:22,348 INFO:   Leaving out SEQ value Fold_7
2023-01-03 23:41:22,361 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-03 23:41:22,361 INFO:   Starting stage: FEATURE SCALING
2023-01-03 23:41:23,009 INFO:   Done with stage: FEATURE SCALING
2023-01-03 23:41:23,009 INFO:   Starting stage: SCALING TARGETS
2023-01-03 23:41:23,079 INFO:   Done with stage: SCALING TARGETS
2023-01-03 23:41:23,079 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:41:23,079 INFO:     No hyperparam tuning for this model
2023-01-03 23:41:23,079 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:41:23,079 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 23:41:23,080 INFO:     None feature selector for col prot
2023-01-03 23:41:23,080 INFO:     None feature selector for col prot
2023-01-03 23:41:23,080 INFO:     None feature selector for col prot
2023-01-03 23:41:23,081 INFO:     None feature selector for col chem
2023-01-03 23:41:23,081 INFO:     None feature selector for col chem
2023-01-03 23:41:23,081 INFO:     None feature selector for col chem
2023-01-03 23:41:23,081 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 23:41:23,081 INFO:   Starting stage: BUILD MODEL
2023-01-03 23:41:23,082 INFO:     Number of params in model 70141
2023-01-03 23:41:23,085 INFO:   Done with stage: BUILD MODEL
2023-01-03 23:41:23,085 INFO:   Starting stage: TRAINING
2023-01-03 23:41:23,129 INFO:     Val loss before train {'Reaction outcome loss': 1.0666646401087443, 'Total loss': 1.0666646401087443}
2023-01-03 23:41:23,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:23,130 INFO:     Epoch: 0
2023-01-03 23:41:24,722 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.74326451420784, 'Total loss': 0.74326451420784} | train loss {'Reaction outcome loss': 0.8505485083652318, 'Total loss': 0.8505485083652318}
2023-01-03 23:41:24,723 INFO:     Found new best model at epoch 0
2023-01-03 23:41:24,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:24,723 INFO:     Epoch: 1
2023-01-03 23:41:26,341 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6506214161713918, 'Total loss': 0.6506214161713918} | train loss {'Reaction outcome loss': 0.6283794222971162, 'Total loss': 0.6283794222971162}
2023-01-03 23:41:26,342 INFO:     Found new best model at epoch 1
2023-01-03 23:41:26,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:26,342 INFO:     Epoch: 2
2023-01-03 23:41:27,961 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6026882410049439, 'Total loss': 0.6026882410049439} | train loss {'Reaction outcome loss': 0.5264490187060532, 'Total loss': 0.5264490187060532}
2023-01-03 23:41:27,961 INFO:     Found new best model at epoch 2
2023-01-03 23:41:27,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:27,962 INFO:     Epoch: 3
2023-01-03 23:41:29,568 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5884741286436717, 'Total loss': 0.5884741286436717} | train loss {'Reaction outcome loss': 0.4799194150883368, 'Total loss': 0.4799194150883368}
2023-01-03 23:41:29,569 INFO:     Found new best model at epoch 3
2023-01-03 23:41:29,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:29,569 INFO:     Epoch: 4
2023-01-03 23:41:31,167 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5622941017150879, 'Total loss': 0.5622941017150879} | train loss {'Reaction outcome loss': 0.4516309110266207, 'Total loss': 0.4516309110266207}
2023-01-03 23:41:31,167 INFO:     Found new best model at epoch 4
2023-01-03 23:41:31,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:31,168 INFO:     Epoch: 5
2023-01-03 23:41:32,752 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5627182861169179, 'Total loss': 0.5627182861169179} | train loss {'Reaction outcome loss': 0.4305157066198463, 'Total loss': 0.4305157066198463}
2023-01-03 23:41:32,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:32,752 INFO:     Epoch: 6
2023-01-03 23:41:34,357 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5309098919232687, 'Total loss': 0.5309098919232687} | train loss {'Reaction outcome loss': 0.41691650477127046, 'Total loss': 0.41691650477127046}
2023-01-03 23:41:34,357 INFO:     Found new best model at epoch 6
2023-01-03 23:41:34,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:34,358 INFO:     Epoch: 7
2023-01-03 23:41:35,946 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5402539322773615, 'Total loss': 0.5402539322773615} | train loss {'Reaction outcome loss': 0.40064880588102, 'Total loss': 0.40064880588102}
2023-01-03 23:41:35,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:35,946 INFO:     Epoch: 8
2023-01-03 23:41:37,574 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5249204436937968, 'Total loss': 0.5249204436937968} | train loss {'Reaction outcome loss': 0.3907588773040565, 'Total loss': 0.3907588773040565}
2023-01-03 23:41:37,575 INFO:     Found new best model at epoch 8
2023-01-03 23:41:37,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:37,575 INFO:     Epoch: 9
2023-01-03 23:41:39,155 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5256072243054708, 'Total loss': 0.5256072243054708} | train loss {'Reaction outcome loss': 0.3818545340953751, 'Total loss': 0.3818545340953751}
2023-01-03 23:41:39,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:39,155 INFO:     Epoch: 10
2023-01-03 23:41:40,787 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5004060794909795, 'Total loss': 0.5004060794909795} | train loss {'Reaction outcome loss': 0.3708896080186651, 'Total loss': 0.3708896080186651}
2023-01-03 23:41:40,787 INFO:     Found new best model at epoch 10
2023-01-03 23:41:40,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:40,788 INFO:     Epoch: 11
2023-01-03 23:41:42,366 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5200273315111796, 'Total loss': 0.5200273315111796} | train loss {'Reaction outcome loss': 0.36334199385737687, 'Total loss': 0.36334199385737687}
2023-01-03 23:41:42,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:42,366 INFO:     Epoch: 12
2023-01-03 23:41:43,968 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5213962723811467, 'Total loss': 0.5213962723811467} | train loss {'Reaction outcome loss': 0.35712816103593537, 'Total loss': 0.35712816103593537}
2023-01-03 23:41:43,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:43,968 INFO:     Epoch: 13
2023-01-03 23:41:45,576 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5203306794166564, 'Total loss': 0.5203306794166564} | train loss {'Reaction outcome loss': 0.3497471282198111, 'Total loss': 0.3497471282198111}
2023-01-03 23:41:45,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:45,576 INFO:     Epoch: 14
2023-01-03 23:41:47,191 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4944671869277954, 'Total loss': 0.4944671869277954} | train loss {'Reaction outcome loss': 0.3438493191442765, 'Total loss': 0.3438493191442765}
2023-01-03 23:41:47,191 INFO:     Found new best model at epoch 14
2023-01-03 23:41:47,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:47,192 INFO:     Epoch: 15
2023-01-03 23:41:48,767 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.50932277739048, 'Total loss': 0.50932277739048} | train loss {'Reaction outcome loss': 0.3388481619986386, 'Total loss': 0.3388481619986386}
2023-01-03 23:41:48,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:48,767 INFO:     Epoch: 16
2023-01-03 23:41:50,394 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5283513406912486, 'Total loss': 0.5283513406912486} | train loss {'Reaction outcome loss': 0.3302364936535539, 'Total loss': 0.3302364936535539}
2023-01-03 23:41:50,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:50,394 INFO:     Epoch: 17
2023-01-03 23:41:51,989 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4998228708902995, 'Total loss': 0.4998228708902995} | train loss {'Reaction outcome loss': 0.32727220522690337, 'Total loss': 0.32727220522690337}
2023-01-03 23:41:51,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:51,991 INFO:     Epoch: 18
2023-01-03 23:41:53,595 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5034393588701884, 'Total loss': 0.5034393588701884} | train loss {'Reaction outcome loss': 0.32164070757933044, 'Total loss': 0.32164070757933044}
2023-01-03 23:41:53,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:53,595 INFO:     Epoch: 19
2023-01-03 23:41:55,201 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5133815109729767, 'Total loss': 0.5133815109729767} | train loss {'Reaction outcome loss': 0.3145627690889345, 'Total loss': 0.3145627690889345}
2023-01-03 23:41:55,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:55,201 INFO:     Epoch: 20
2023-01-03 23:41:56,817 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5074366887410482, 'Total loss': 0.5074366887410482} | train loss {'Reaction outcome loss': 0.3116265134852285, 'Total loss': 0.3116265134852285}
2023-01-03 23:41:56,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:56,817 INFO:     Epoch: 21
2023-01-03 23:41:58,417 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5091812789440155, 'Total loss': 0.5091812789440155} | train loss {'Reaction outcome loss': 0.3058546640059578, 'Total loss': 0.3058546640059578}
2023-01-03 23:41:58,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:41:58,418 INFO:     Epoch: 22
2023-01-03 23:42:00,022 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4929040769735972, 'Total loss': 0.4929040769735972} | train loss {'Reaction outcome loss': 0.3001628455971553, 'Total loss': 0.3001628455971553}
2023-01-03 23:42:00,022 INFO:     Found new best model at epoch 22
2023-01-03 23:42:00,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:00,023 INFO:     Epoch: 23
2023-01-03 23:42:01,611 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4747684965531031, 'Total loss': 0.4747684965531031} | train loss {'Reaction outcome loss': 0.29615032931097146, 'Total loss': 0.29615032931097146}
2023-01-03 23:42:01,611 INFO:     Found new best model at epoch 23
2023-01-03 23:42:01,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:01,612 INFO:     Epoch: 24
2023-01-03 23:42:03,210 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5046797037124634, 'Total loss': 0.5046797037124634} | train loss {'Reaction outcome loss': 0.2916431668540631, 'Total loss': 0.2916431668540631}
2023-01-03 23:42:03,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:03,211 INFO:     Epoch: 25
2023-01-03 23:42:04,832 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5131369272867838, 'Total loss': 0.5131369272867838} | train loss {'Reaction outcome loss': 0.2883325394256451, 'Total loss': 0.2883325394256451}
2023-01-03 23:42:04,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:04,832 INFO:     Epoch: 26
2023-01-03 23:42:06,413 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5048702418804168, 'Total loss': 0.5048702418804168} | train loss {'Reaction outcome loss': 0.2845455140870616, 'Total loss': 0.2845455140870616}
2023-01-03 23:42:06,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:06,413 INFO:     Epoch: 27
2023-01-03 23:42:08,041 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5313291470209758, 'Total loss': 0.5313291470209758} | train loss {'Reaction outcome loss': 0.2819976254974892, 'Total loss': 0.2819976254974892}
2023-01-03 23:42:08,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:08,041 INFO:     Epoch: 28
2023-01-03 23:42:09,640 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5098587900400162, 'Total loss': 0.5098587900400162} | train loss {'Reaction outcome loss': 0.2776559611466387, 'Total loss': 0.2776559611466387}
2023-01-03 23:42:09,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:09,640 INFO:     Epoch: 29
2023-01-03 23:42:11,252 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5095244904359182, 'Total loss': 0.5095244904359182} | train loss {'Reaction outcome loss': 0.2722236248345151, 'Total loss': 0.2722236248345151}
2023-01-03 23:42:11,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:11,253 INFO:     Epoch: 30
2023-01-03 23:42:12,860 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5011427223682403, 'Total loss': 0.5011427223682403} | train loss {'Reaction outcome loss': 0.27355562553939405, 'Total loss': 0.27355562553939405}
2023-01-03 23:42:12,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:12,860 INFO:     Epoch: 31
2023-01-03 23:42:14,493 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4947943776845932, 'Total loss': 0.4947943776845932} | train loss {'Reaction outcome loss': 0.2676918960112527, 'Total loss': 0.2676918960112527}
2023-01-03 23:42:14,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:14,493 INFO:     Epoch: 32
2023-01-03 23:42:16,083 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5100443263848623, 'Total loss': 0.5100443263848623} | train loss {'Reaction outcome loss': 0.265211768260071, 'Total loss': 0.265211768260071}
2023-01-03 23:42:16,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:16,083 INFO:     Epoch: 33
2023-01-03 23:42:17,691 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49697002371152244, 'Total loss': 0.49697002371152244} | train loss {'Reaction outcome loss': 0.26061298351210377, 'Total loss': 0.26061298351210377}
2023-01-03 23:42:17,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:17,691 INFO:     Epoch: 34
2023-01-03 23:42:19,286 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.49980057378609977, 'Total loss': 0.49980057378609977} | train loss {'Reaction outcome loss': 0.25766545633654303, 'Total loss': 0.25766545633654303}
2023-01-03 23:42:19,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:19,286 INFO:     Epoch: 35
2023-01-03 23:42:20,878 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5145288407802582, 'Total loss': 0.5145288407802582} | train loss {'Reaction outcome loss': 0.25779160292355163, 'Total loss': 0.25779160292355163}
2023-01-03 23:42:20,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:20,879 INFO:     Epoch: 36
2023-01-03 23:42:22,498 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47564309736092886, 'Total loss': 0.47564309736092886} | train loss {'Reaction outcome loss': 0.253915769313647, 'Total loss': 0.253915769313647}
2023-01-03 23:42:22,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:22,498 INFO:     Epoch: 37
2023-01-03 23:42:24,110 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4852519124746323, 'Total loss': 0.4852519124746323} | train loss {'Reaction outcome loss': 0.2492182602843653, 'Total loss': 0.2492182602843653}
2023-01-03 23:42:24,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:24,110 INFO:     Epoch: 38
2023-01-03 23:42:25,709 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4920174400011698, 'Total loss': 0.4920174400011698} | train loss {'Reaction outcome loss': 0.24819821610186074, 'Total loss': 0.24819821610186074}
2023-01-03 23:42:25,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:25,710 INFO:     Epoch: 39
2023-01-03 23:42:27,289 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48962975839773815, 'Total loss': 0.48962975839773815} | train loss {'Reaction outcome loss': 0.24583328320285044, 'Total loss': 0.24583328320285044}
2023-01-03 23:42:27,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:27,289 INFO:     Epoch: 40
2023-01-03 23:42:28,926 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5030923873186112, 'Total loss': 0.5030923873186112} | train loss {'Reaction outcome loss': 0.24299484959363077, 'Total loss': 0.24299484959363077}
2023-01-03 23:42:28,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:28,927 INFO:     Epoch: 41
2023-01-03 23:42:30,521 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5152159829934438, 'Total loss': 0.5152159829934438} | train loss {'Reaction outcome loss': 0.24198446915037797, 'Total loss': 0.24198446915037797}
2023-01-03 23:42:30,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:30,522 INFO:     Epoch: 42
2023-01-03 23:42:32,149 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5138002554575603, 'Total loss': 0.5138002554575603} | train loss {'Reaction outcome loss': 0.23815570713864767, 'Total loss': 0.23815570713864767}
2023-01-03 23:42:32,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:32,149 INFO:     Epoch: 43
2023-01-03 23:42:33,743 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5107661267121633, 'Total loss': 0.5107661267121633} | train loss {'Reaction outcome loss': 0.2370883465916026, 'Total loss': 0.2370883465916026}
2023-01-03 23:42:33,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:33,743 INFO:     Epoch: 44
2023-01-03 23:42:35,365 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5061053653558095, 'Total loss': 0.5061053653558095} | train loss {'Reaction outcome loss': 0.23539777332748746, 'Total loss': 0.23539777332748746}
2023-01-03 23:42:35,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:35,366 INFO:     Epoch: 45
2023-01-03 23:42:36,966 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4800629278024038, 'Total loss': 0.4800629278024038} | train loss {'Reaction outcome loss': 0.23029461164121592, 'Total loss': 0.23029461164121592}
2023-01-03 23:42:36,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:36,966 INFO:     Epoch: 46
2023-01-03 23:42:38,592 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4978690465291341, 'Total loss': 0.4978690465291341} | train loss {'Reaction outcome loss': 0.23030276085495519, 'Total loss': 0.23030276085495519}
2023-01-03 23:42:38,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:38,592 INFO:     Epoch: 47
2023-01-03 23:42:40,219 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5006106416384379, 'Total loss': 0.5006106416384379} | train loss {'Reaction outcome loss': 0.22868393267427542, 'Total loss': 0.22868393267427542}
2023-01-03 23:42:40,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:40,219 INFO:     Epoch: 48
2023-01-03 23:42:41,809 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49627606868743895, 'Total loss': 0.49627606868743895} | train loss {'Reaction outcome loss': 0.22683825546922667, 'Total loss': 0.22683825546922667}
2023-01-03 23:42:41,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:41,809 INFO:     Epoch: 49
2023-01-03 23:42:43,407 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48668203353881834, 'Total loss': 0.48668203353881834} | train loss {'Reaction outcome loss': 0.22449396362373544, 'Total loss': 0.22449396362373544}
2023-01-03 23:42:43,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:43,407 INFO:     Epoch: 50
2023-01-03 23:42:45,021 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48848840594291687, 'Total loss': 0.48848840594291687} | train loss {'Reaction outcome loss': 0.22345957311966358, 'Total loss': 0.22345957311966358}
2023-01-03 23:42:45,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:45,021 INFO:     Epoch: 51
2023-01-03 23:42:46,614 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5141063650449117, 'Total loss': 0.5141063650449117} | train loss {'Reaction outcome loss': 0.22100628463262256, 'Total loss': 0.22100628463262256}
2023-01-03 23:42:46,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:46,614 INFO:     Epoch: 52
2023-01-03 23:42:48,224 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.490337935090065, 'Total loss': 0.490337935090065} | train loss {'Reaction outcome loss': 0.21888613512584879, 'Total loss': 0.21888613512584879}
2023-01-03 23:42:48,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:48,225 INFO:     Epoch: 53
2023-01-03 23:42:49,835 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4947918544212977, 'Total loss': 0.4947918544212977} | train loss {'Reaction outcome loss': 0.218924606965337, 'Total loss': 0.218924606965337}
2023-01-03 23:42:49,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:49,836 INFO:     Epoch: 54
2023-01-03 23:42:51,497 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49446656703948977, 'Total loss': 0.49446656703948977} | train loss {'Reaction outcome loss': 0.214709251729052, 'Total loss': 0.214709251729052}
2023-01-03 23:42:51,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:51,497 INFO:     Epoch: 55
2023-01-03 23:42:53,118 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4850219289461772, 'Total loss': 0.4850219289461772} | train loss {'Reaction outcome loss': 0.21343395273984556, 'Total loss': 0.21343395273984556}
2023-01-03 23:42:53,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:53,118 INFO:     Epoch: 56
2023-01-03 23:42:54,723 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4858145703872045, 'Total loss': 0.4858145703872045} | train loss {'Reaction outcome loss': 0.21244544840488408, 'Total loss': 0.21244544840488408}
2023-01-03 23:42:54,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:54,723 INFO:     Epoch: 57
2023-01-03 23:42:56,332 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5037762741247813, 'Total loss': 0.5037762741247813} | train loss {'Reaction outcome loss': 0.2126744562484297, 'Total loss': 0.2126744562484297}
2023-01-03 23:42:56,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:56,332 INFO:     Epoch: 58
2023-01-03 23:42:57,951 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.502345210313797, 'Total loss': 0.502345210313797} | train loss {'Reaction outcome loss': 0.20955106794887932, 'Total loss': 0.20955106794887932}
2023-01-03 23:42:57,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:57,951 INFO:     Epoch: 59
2023-01-03 23:42:59,563 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49918842911720274, 'Total loss': 0.49918842911720274} | train loss {'Reaction outcome loss': 0.2078814835754973, 'Total loss': 0.2078814835754973}
2023-01-03 23:42:59,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:42:59,563 INFO:     Epoch: 60
2023-01-03 23:43:01,157 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48674848278363547, 'Total loss': 0.48674848278363547} | train loss {'Reaction outcome loss': 0.20469412398575015, 'Total loss': 0.20469412398575015}
2023-01-03 23:43:01,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:01,157 INFO:     Epoch: 61
2023-01-03 23:43:02,760 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4919387380282084, 'Total loss': 0.4919387380282084} | train loss {'Reaction outcome loss': 0.2053800771409639, 'Total loss': 0.2053800771409639}
2023-01-03 23:43:02,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:02,760 INFO:     Epoch: 62
2023-01-03 23:43:04,366 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48298682073752086, 'Total loss': 0.48298682073752086} | train loss {'Reaction outcome loss': 0.20427419340728853, 'Total loss': 0.20427419340728853}
2023-01-03 23:43:04,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:04,368 INFO:     Epoch: 63
2023-01-03 23:43:05,984 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.505509622891744, 'Total loss': 0.505509622891744} | train loss {'Reaction outcome loss': 0.20115668561968564, 'Total loss': 0.20115668561968564}
2023-01-03 23:43:05,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:05,984 INFO:     Epoch: 64
2023-01-03 23:43:07,575 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5003382405887048, 'Total loss': 0.5003382405887048} | train loss {'Reaction outcome loss': 0.2016743026969665, 'Total loss': 0.2016743026969665}
2023-01-03 23:43:07,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:07,575 INFO:     Epoch: 65
2023-01-03 23:43:09,174 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5302184621493021, 'Total loss': 0.5302184621493021} | train loss {'Reaction outcome loss': 0.19997906445488603, 'Total loss': 0.19997906445488603}
2023-01-03 23:43:09,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:09,175 INFO:     Epoch: 66
2023-01-03 23:43:10,780 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4788120150566101, 'Total loss': 0.4788120150566101} | train loss {'Reaction outcome loss': 0.19838382241850724, 'Total loss': 0.19838382241850724}
2023-01-03 23:43:10,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:10,781 INFO:     Epoch: 67
2023-01-03 23:43:12,368 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4892025207479795, 'Total loss': 0.4892025207479795} | train loss {'Reaction outcome loss': 0.19704741109095325, 'Total loss': 0.19704741109095325}
2023-01-03 23:43:12,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:12,368 INFO:     Epoch: 68
2023-01-03 23:43:13,981 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5178704847892125, 'Total loss': 0.5178704847892125} | train loss {'Reaction outcome loss': 0.19732263465058933, 'Total loss': 0.19732263465058933}
2023-01-03 23:43:13,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:13,981 INFO:     Epoch: 69
2023-01-03 23:43:15,591 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4888902713855108, 'Total loss': 0.4888902713855108} | train loss {'Reaction outcome loss': 0.1979461028526406, 'Total loss': 0.1979461028526406}
2023-01-03 23:43:15,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:15,591 INFO:     Epoch: 70
2023-01-03 23:43:17,202 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4956362674633662, 'Total loss': 0.4956362674633662} | train loss {'Reaction outcome loss': 0.19424836519123845, 'Total loss': 0.19424836519123845}
2023-01-03 23:43:17,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:17,202 INFO:     Epoch: 71
2023-01-03 23:43:18,791 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5056200981140136, 'Total loss': 0.5056200981140136} | train loss {'Reaction outcome loss': 0.19263421062259037, 'Total loss': 0.19263421062259037}
2023-01-03 23:43:18,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:18,792 INFO:     Epoch: 72
2023-01-03 23:43:20,426 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4913940985997518, 'Total loss': 0.4913940985997518} | train loss {'Reaction outcome loss': 0.1912319076244151, 'Total loss': 0.1912319076244151}
2023-01-03 23:43:20,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:20,427 INFO:     Epoch: 73
2023-01-03 23:43:22,028 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.484930952390035, 'Total loss': 0.484930952390035} | train loss {'Reaction outcome loss': 0.19122034714083164, 'Total loss': 0.19122034714083164}
2023-01-03 23:43:22,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:22,028 INFO:     Epoch: 74
2023-01-03 23:43:23,624 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5136926968892416, 'Total loss': 0.5136926968892416} | train loss {'Reaction outcome loss': 0.19133233568136873, 'Total loss': 0.19133233568136873}
2023-01-03 23:43:23,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:23,625 INFO:     Epoch: 75
2023-01-03 23:43:25,236 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5183108528455098, 'Total loss': 0.5183108528455098} | train loss {'Reaction outcome loss': 0.18994303289733638, 'Total loss': 0.18994303289733638}
2023-01-03 23:43:25,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:25,236 INFO:     Epoch: 76
2023-01-03 23:43:26,821 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5110664824644725, 'Total loss': 0.5110664824644725} | train loss {'Reaction outcome loss': 0.18693633627025444, 'Total loss': 0.18693633627025444}
2023-01-03 23:43:26,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:26,821 INFO:     Epoch: 77
2023-01-03 23:43:28,449 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5232344448566437, 'Total loss': 0.5232344448566437} | train loss {'Reaction outcome loss': 0.18731199393875977, 'Total loss': 0.18731199393875977}
2023-01-03 23:43:28,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:28,449 INFO:     Epoch: 78
2023-01-03 23:43:30,066 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5073564390341441, 'Total loss': 0.5073564390341441} | train loss {'Reaction outcome loss': 0.1876828051726956, 'Total loss': 0.1876828051726956}
2023-01-03 23:43:30,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:30,066 INFO:     Epoch: 79
2023-01-03 23:43:31,687 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49219620128472646, 'Total loss': 0.49219620128472646} | train loss {'Reaction outcome loss': 0.18704043897642125, 'Total loss': 0.18704043897642125}
2023-01-03 23:43:31,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:31,688 INFO:     Epoch: 80
2023-01-03 23:43:33,304 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49654856622219085, 'Total loss': 0.49654856622219085} | train loss {'Reaction outcome loss': 0.1826050615724889, 'Total loss': 0.1826050615724889}
2023-01-03 23:43:33,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:33,304 INFO:     Epoch: 81
2023-01-03 23:43:34,898 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5160573224226633, 'Total loss': 0.5160573224226633} | train loss {'Reaction outcome loss': 0.18340112030882696, 'Total loss': 0.18340112030882696}
2023-01-03 23:43:34,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:34,899 INFO:     Epoch: 82
2023-01-03 23:43:36,487 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5155917872985204, 'Total loss': 0.5155917872985204} | train loss {'Reaction outcome loss': 0.1865776626910974, 'Total loss': 0.1865776626910974}
2023-01-03 23:43:36,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:36,488 INFO:     Epoch: 83
2023-01-03 23:43:38,094 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5191967149575551, 'Total loss': 0.5191967149575551} | train loss {'Reaction outcome loss': 0.1808622721044703, 'Total loss': 0.1808622721044703}
2023-01-03 23:43:38,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:38,094 INFO:     Epoch: 84
2023-01-03 23:43:39,688 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5204138944546381, 'Total loss': 0.5204138944546381} | train loss {'Reaction outcome loss': 0.1810174159880472, 'Total loss': 0.1810174159880472}
2023-01-03 23:43:39,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:39,688 INFO:     Epoch: 85
2023-01-03 23:43:41,304 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5068560908238093, 'Total loss': 0.5068560908238093} | train loss {'Reaction outcome loss': 0.17951729500982305, 'Total loss': 0.17951729500982305}
2023-01-03 23:43:41,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:41,305 INFO:     Epoch: 86
2023-01-03 23:43:42,908 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5104394853115082, 'Total loss': 0.5104394853115082} | train loss {'Reaction outcome loss': 0.18094321947531364, 'Total loss': 0.18094321947531364}
2023-01-03 23:43:42,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:42,908 INFO:     Epoch: 87
2023-01-03 23:43:44,520 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4860575318336487, 'Total loss': 0.4860575318336487} | train loss {'Reaction outcome loss': 0.18215092119596066, 'Total loss': 0.18215092119596066}
2023-01-03 23:43:44,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:44,521 INFO:     Epoch: 88
2023-01-03 23:43:46,113 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5114838769038518, 'Total loss': 0.5114838769038518} | train loss {'Reaction outcome loss': 0.17908386087939412, 'Total loss': 0.17908386087939412}
2023-01-03 23:43:46,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:46,113 INFO:     Epoch: 89
2023-01-03 23:43:47,709 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5101570705572764, 'Total loss': 0.5101570705572764} | train loss {'Reaction outcome loss': 0.18002297799187017, 'Total loss': 0.18002297799187017}
2023-01-03 23:43:47,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:47,709 INFO:     Epoch: 90
2023-01-03 23:43:49,314 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49979010621706643, 'Total loss': 0.49979010621706643} | train loss {'Reaction outcome loss': 0.17819128966880188, 'Total loss': 0.17819128966880188}
2023-01-03 23:43:49,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:49,315 INFO:     Epoch: 91
2023-01-03 23:43:50,949 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5195163031419118, 'Total loss': 0.5195163031419118} | train loss {'Reaction outcome loss': 0.17732694827773296, 'Total loss': 0.17732694827773296}
2023-01-03 23:43:50,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:50,949 INFO:     Epoch: 92
2023-01-03 23:43:52,552 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.514079076051712, 'Total loss': 0.514079076051712} | train loss {'Reaction outcome loss': 0.1766198866223977, 'Total loss': 0.1766198866223977}
2023-01-03 23:43:52,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:52,552 INFO:     Epoch: 93
2023-01-03 23:43:54,142 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49707815249760945, 'Total loss': 0.49707815249760945} | train loss {'Reaction outcome loss': 0.1737320224825118, 'Total loss': 0.1737320224825118}
2023-01-03 23:43:54,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:54,143 INFO:     Epoch: 94
2023-01-03 23:43:55,750 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5256636639436086, 'Total loss': 0.5256636639436086} | train loss {'Reaction outcome loss': 0.1748579832614275, 'Total loss': 0.1748579832614275}
2023-01-03 23:43:55,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:55,750 INFO:     Epoch: 95
2023-01-03 23:43:57,361 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5183582554260889, 'Total loss': 0.5183582554260889} | train loss {'Reaction outcome loss': 0.17686706035656835, 'Total loss': 0.17686706035656835}
2023-01-03 23:43:57,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:57,361 INFO:     Epoch: 96
2023-01-03 23:43:58,966 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5052875419457753, 'Total loss': 0.5052875419457753} | train loss {'Reaction outcome loss': 0.17527499987276451, 'Total loss': 0.17527499987276451}
2023-01-03 23:43:58,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:43:58,966 INFO:     Epoch: 97
2023-01-03 23:44:00,570 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.536456526319186, 'Total loss': 0.536456526319186} | train loss {'Reaction outcome loss': 0.1760758366301279, 'Total loss': 0.1760758366301279}
2023-01-03 23:44:00,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:00,570 INFO:     Epoch: 98
2023-01-03 23:44:02,174 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5470656255880991, 'Total loss': 0.5470656255880991} | train loss {'Reaction outcome loss': 0.1745767572941763, 'Total loss': 0.1745767572941763}
2023-01-03 23:44:02,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:02,174 INFO:     Epoch: 99
2023-01-03 23:44:03,765 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49960605303446454, 'Total loss': 0.49960605303446454} | train loss {'Reaction outcome loss': 0.17363871467242603, 'Total loss': 0.17363871467242603}
2023-01-03 23:44:03,765 INFO:     Best model found after epoch 24 of 100.
2023-01-03 23:44:03,765 INFO:   Done with stage: TRAINING
2023-01-03 23:44:03,765 INFO:   Starting stage: EVALUATION
2023-01-03 23:44:03,888 INFO:   Done with stage: EVALUATION
2023-01-03 23:44:03,888 INFO:   Leaving out SEQ value Fold_8
2023-01-03 23:44:03,901 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-03 23:44:03,901 INFO:   Starting stage: FEATURE SCALING
2023-01-03 23:44:04,552 INFO:   Done with stage: FEATURE SCALING
2023-01-03 23:44:04,552 INFO:   Starting stage: SCALING TARGETS
2023-01-03 23:44:04,623 INFO:   Done with stage: SCALING TARGETS
2023-01-03 23:44:04,623 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:44:04,624 INFO:     No hyperparam tuning for this model
2023-01-03 23:44:04,624 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:44:04,624 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 23:44:04,624 INFO:     None feature selector for col prot
2023-01-03 23:44:04,625 INFO:     None feature selector for col prot
2023-01-03 23:44:04,625 INFO:     None feature selector for col prot
2023-01-03 23:44:04,625 INFO:     None feature selector for col chem
2023-01-03 23:44:04,625 INFO:     None feature selector for col chem
2023-01-03 23:44:04,625 INFO:     None feature selector for col chem
2023-01-03 23:44:04,625 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 23:44:04,625 INFO:   Starting stage: BUILD MODEL
2023-01-03 23:44:04,627 INFO:     Number of params in model 70141
2023-01-03 23:44:04,630 INFO:   Done with stage: BUILD MODEL
2023-01-03 23:44:04,630 INFO:   Starting stage: TRAINING
2023-01-03 23:44:04,676 INFO:     Val loss before train {'Reaction outcome loss': 1.1030291279157003, 'Total loss': 1.1030291279157003}
2023-01-03 23:44:04,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:04,676 INFO:     Epoch: 0
2023-01-03 23:44:06,256 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7201932648817698, 'Total loss': 0.7201932648817698} | train loss {'Reaction outcome loss': 0.8321279714936796, 'Total loss': 0.8321279714936796}
2023-01-03 23:44:06,257 INFO:     Found new best model at epoch 0
2023-01-03 23:44:06,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:06,259 INFO:     Epoch: 1
2023-01-03 23:44:07,880 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6137000143527984, 'Total loss': 0.6137000143527984} | train loss {'Reaction outcome loss': 0.579126079823228, 'Total loss': 0.579126079823228}
2023-01-03 23:44:07,881 INFO:     Found new best model at epoch 1
2023-01-03 23:44:07,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:07,881 INFO:     Epoch: 2
2023-01-03 23:44:09,475 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5721214671929677, 'Total loss': 0.5721214671929677} | train loss {'Reaction outcome loss': 0.5080282025957021, 'Total loss': 0.5080282025957021}
2023-01-03 23:44:09,476 INFO:     Found new best model at epoch 2
2023-01-03 23:44:09,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:09,476 INFO:     Epoch: 3
2023-01-03 23:44:11,085 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5566142002741495, 'Total loss': 0.5566142002741495} | train loss {'Reaction outcome loss': 0.4716132790039199, 'Total loss': 0.4716132790039199}
2023-01-03 23:44:11,085 INFO:     Found new best model at epoch 3
2023-01-03 23:44:11,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:11,086 INFO:     Epoch: 4
2023-01-03 23:44:12,671 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5390908161799113, 'Total loss': 0.5390908161799113} | train loss {'Reaction outcome loss': 0.44561296922789106, 'Total loss': 0.44561296922789106}
2023-01-03 23:44:12,672 INFO:     Found new best model at epoch 4
2023-01-03 23:44:12,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:12,673 INFO:     Epoch: 5
2023-01-03 23:44:14,293 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5274560729662577, 'Total loss': 0.5274560729662577} | train loss {'Reaction outcome loss': 0.4238123393928011, 'Total loss': 0.4238123393928011}
2023-01-03 23:44:14,293 INFO:     Found new best model at epoch 5
2023-01-03 23:44:14,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:14,294 INFO:     Epoch: 6
2023-01-03 23:44:15,899 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5015174329280854, 'Total loss': 0.5015174329280854} | train loss {'Reaction outcome loss': 0.40823425614929665, 'Total loss': 0.40823425614929665}
2023-01-03 23:44:15,899 INFO:     Found new best model at epoch 6
2023-01-03 23:44:15,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:15,900 INFO:     Epoch: 7
2023-01-03 23:44:17,495 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4858245591322581, 'Total loss': 0.4858245591322581} | train loss {'Reaction outcome loss': 0.3934540825801483, 'Total loss': 0.3934540825801483}
2023-01-03 23:44:17,495 INFO:     Found new best model at epoch 7
2023-01-03 23:44:17,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:17,496 INFO:     Epoch: 8
2023-01-03 23:44:19,100 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48645588755607605, 'Total loss': 0.48645588755607605} | train loss {'Reaction outcome loss': 0.38219311030790803, 'Total loss': 0.38219311030790803}
2023-01-03 23:44:19,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:19,101 INFO:     Epoch: 9
2023-01-03 23:44:20,697 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4764099215467771, 'Total loss': 0.4764099215467771} | train loss {'Reaction outcome loss': 0.3716984901906656, 'Total loss': 0.3716984901906656}
2023-01-03 23:44:20,697 INFO:     Found new best model at epoch 9
2023-01-03 23:44:20,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:20,698 INFO:     Epoch: 10
2023-01-03 23:44:22,307 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4945681671301524, 'Total loss': 0.4945681671301524} | train loss {'Reaction outcome loss': 0.3606593863620166, 'Total loss': 0.3606593863620166}
2023-01-03 23:44:22,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:22,307 INFO:     Epoch: 11
2023-01-03 23:44:23,885 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4772481719652812, 'Total loss': 0.4772481719652812} | train loss {'Reaction outcome loss': 0.35518150251827785, 'Total loss': 0.35518150251827785}
2023-01-03 23:44:23,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:23,886 INFO:     Epoch: 12
2023-01-03 23:44:25,496 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49599876006444293, 'Total loss': 0.49599876006444293} | train loss {'Reaction outcome loss': 0.3432556959206535, 'Total loss': 0.3432556959206535}
2023-01-03 23:44:25,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:25,497 INFO:     Epoch: 13
2023-01-03 23:44:27,100 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46417070627212526, 'Total loss': 0.46417070627212526} | train loss {'Reaction outcome loss': 0.33748501089335614, 'Total loss': 0.33748501089335614}
2023-01-03 23:44:27,100 INFO:     Found new best model at epoch 13
2023-01-03 23:44:27,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:27,101 INFO:     Epoch: 14
2023-01-03 23:44:28,711 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.495909317334493, 'Total loss': 0.495909317334493} | train loss {'Reaction outcome loss': 0.32982022787589393, 'Total loss': 0.32982022787589393}
2023-01-03 23:44:28,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:28,712 INFO:     Epoch: 15
2023-01-03 23:44:30,300 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.475996067126592, 'Total loss': 0.475996067126592} | train loss {'Reaction outcome loss': 0.32028606134480325, 'Total loss': 0.32028606134480325}
2023-01-03 23:44:30,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:30,301 INFO:     Epoch: 16
2023-01-03 23:44:31,900 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47391868631045025, 'Total loss': 0.47391868631045025} | train loss {'Reaction outcome loss': 0.3208003402620122, 'Total loss': 0.3208003402620122}
2023-01-03 23:44:31,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:31,900 INFO:     Epoch: 17
2023-01-03 23:44:33,486 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4508736550807953, 'Total loss': 0.4508736550807953} | train loss {'Reaction outcome loss': 0.3176370681663368, 'Total loss': 0.3176370681663368}
2023-01-03 23:44:33,486 INFO:     Found new best model at epoch 17
2023-01-03 23:44:33,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:33,487 INFO:     Epoch: 18
2023-01-03 23:44:35,119 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.449909778436025, 'Total loss': 0.449909778436025} | train loss {'Reaction outcome loss': 0.3047959632004031, 'Total loss': 0.3047959632004031}
2023-01-03 23:44:35,119 INFO:     Found new best model at epoch 18
2023-01-03 23:44:35,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:35,120 INFO:     Epoch: 19
2023-01-03 23:44:36,734 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44947634140650433, 'Total loss': 0.44947634140650433} | train loss {'Reaction outcome loss': 0.2997306241566126, 'Total loss': 0.2997306241566126}
2023-01-03 23:44:36,735 INFO:     Found new best model at epoch 19
2023-01-03 23:44:36,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:36,736 INFO:     Epoch: 20
2023-01-03 23:44:38,356 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4571979175011317, 'Total loss': 0.4571979175011317} | train loss {'Reaction outcome loss': 0.29274031311017124, 'Total loss': 0.29274031311017124}
2023-01-03 23:44:38,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:38,356 INFO:     Epoch: 21
2023-01-03 23:44:39,953 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45430592546860377, 'Total loss': 0.45430592546860377} | train loss {'Reaction outcome loss': 0.2885196524140564, 'Total loss': 0.2885196524140564}
2023-01-03 23:44:39,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:39,953 INFO:     Epoch: 22
2023-01-03 23:44:41,570 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4582832803328832, 'Total loss': 0.4582832803328832} | train loss {'Reaction outcome loss': 0.2847913542519445, 'Total loss': 0.2847913542519445}
2023-01-03 23:44:41,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:41,570 INFO:     Epoch: 23
2023-01-03 23:44:43,156 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45473376313845315, 'Total loss': 0.45473376313845315} | train loss {'Reaction outcome loss': 0.2814098193134735, 'Total loss': 0.2814098193134735}
2023-01-03 23:44:43,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:43,157 INFO:     Epoch: 24
2023-01-03 23:44:44,754 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4555608381827672, 'Total loss': 0.4555608381827672} | train loss {'Reaction outcome loss': 0.2803709347398304, 'Total loss': 0.2803709347398304}
2023-01-03 23:44:44,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:44,754 INFO:     Epoch: 25
2023-01-03 23:44:46,347 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45624634126822156, 'Total loss': 0.45624634126822156} | train loss {'Reaction outcome loss': 0.27415204304744967, 'Total loss': 0.27415204304744967}
2023-01-03 23:44:46,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:46,348 INFO:     Epoch: 26
2023-01-03 23:44:47,925 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44760034879048666, 'Total loss': 0.44760034879048666} | train loss {'Reaction outcome loss': 0.26851784996688366, 'Total loss': 0.26851784996688366}
2023-01-03 23:44:47,925 INFO:     Found new best model at epoch 26
2023-01-03 23:44:47,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:47,926 INFO:     Epoch: 27
2023-01-03 23:44:49,513 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46918413241704304, 'Total loss': 0.46918413241704304} | train loss {'Reaction outcome loss': 0.2725488871228004, 'Total loss': 0.2725488871228004}
2023-01-03 23:44:49,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:49,513 INFO:     Epoch: 28
2023-01-03 23:44:51,104 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4680442790190379, 'Total loss': 0.4680442790190379} | train loss {'Reaction outcome loss': 0.2723355859228489, 'Total loss': 0.2723355859228489}
2023-01-03 23:44:51,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:51,105 INFO:     Epoch: 29
2023-01-03 23:44:52,730 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45066458980242413, 'Total loss': 0.45066458980242413} | train loss {'Reaction outcome loss': 0.258960680793161, 'Total loss': 0.258960680793161}
2023-01-03 23:44:52,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:52,730 INFO:     Epoch: 30
2023-01-03 23:44:54,312 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45174593925476075, 'Total loss': 0.45174593925476075} | train loss {'Reaction outcome loss': 0.2544695726061774, 'Total loss': 0.2544695726061774}
2023-01-03 23:44:54,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:54,312 INFO:     Epoch: 31
2023-01-03 23:44:55,933 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4612414836883545, 'Total loss': 0.4612414836883545} | train loss {'Reaction outcome loss': 0.2492158939299322, 'Total loss': 0.2492158939299322}
2023-01-03 23:44:55,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:55,933 INFO:     Epoch: 32
2023-01-03 23:44:57,514 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46831355889638265, 'Total loss': 0.46831355889638265} | train loss {'Reaction outcome loss': 0.2474835546268825, 'Total loss': 0.2474835546268825}
2023-01-03 23:44:57,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:57,514 INFO:     Epoch: 33
2023-01-03 23:44:59,114 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4488016357024511, 'Total loss': 0.4488016357024511} | train loss {'Reaction outcome loss': 0.24719242190105328, 'Total loss': 0.24719242190105328}
2023-01-03 23:44:59,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:44:59,115 INFO:     Epoch: 34
2023-01-03 23:45:00,700 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47276128431161246, 'Total loss': 0.47276128431161246} | train loss {'Reaction outcome loss': 0.24585456260984243, 'Total loss': 0.24585456260984243}
2023-01-03 23:45:00,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:00,701 INFO:     Epoch: 35
2023-01-03 23:45:02,319 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4682088871796926, 'Total loss': 0.4682088871796926} | train loss {'Reaction outcome loss': 0.23986272157787386, 'Total loss': 0.23986272157787386}
2023-01-03 23:45:02,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:02,319 INFO:     Epoch: 36
2023-01-03 23:45:03,937 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47933088640371957, 'Total loss': 0.47933088640371957} | train loss {'Reaction outcome loss': 0.23452170968103778, 'Total loss': 0.23452170968103778}
2023-01-03 23:45:03,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:03,938 INFO:     Epoch: 37
2023-01-03 23:45:05,519 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4789290408293406, 'Total loss': 0.4789290408293406} | train loss {'Reaction outcome loss': 0.2330010358539015, 'Total loss': 0.2330010358539015}
2023-01-03 23:45:05,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:05,519 INFO:     Epoch: 38
2023-01-03 23:45:07,130 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4698720435301463, 'Total loss': 0.4698720435301463} | train loss {'Reaction outcome loss': 0.23248958290165267, 'Total loss': 0.23248958290165267}
2023-01-03 23:45:07,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:07,131 INFO:     Epoch: 39
2023-01-03 23:45:08,734 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46381072600682577, 'Total loss': 0.46381072600682577} | train loss {'Reaction outcome loss': 0.22924758494069017, 'Total loss': 0.22924758494069017}
2023-01-03 23:45:08,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:08,735 INFO:     Epoch: 40
2023-01-03 23:45:10,356 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46462985277175906, 'Total loss': 0.46462985277175906} | train loss {'Reaction outcome loss': 0.2289911001984813, 'Total loss': 0.2289911001984813}
2023-01-03 23:45:10,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:10,357 INFO:     Epoch: 41
2023-01-03 23:45:11,970 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45665599405765533, 'Total loss': 0.45665599405765533} | train loss {'Reaction outcome loss': 0.22551170978155258, 'Total loss': 0.22551170978155258}
2023-01-03 23:45:11,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:11,971 INFO:     Epoch: 42
2023-01-03 23:45:13,558 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4702523390452067, 'Total loss': 0.4702523390452067} | train loss {'Reaction outcome loss': 0.2237537535282014, 'Total loss': 0.2237537535282014}
2023-01-03 23:45:13,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:13,559 INFO:     Epoch: 43
2023-01-03 23:45:15,144 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.475549179315567, 'Total loss': 0.475549179315567} | train loss {'Reaction outcome loss': 0.2206269543137329, 'Total loss': 0.2206269543137329}
2023-01-03 23:45:15,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:15,145 INFO:     Epoch: 44
2023-01-03 23:45:16,735 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5094163080056509, 'Total loss': 0.5094163080056509} | train loss {'Reaction outcome loss': 0.21921916712755404, 'Total loss': 0.21921916712755404}
2023-01-03 23:45:16,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:16,736 INFO:     Epoch: 45
2023-01-03 23:45:18,317 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4735515981912613, 'Total loss': 0.4735515981912613} | train loss {'Reaction outcome loss': 0.2162774785531086, 'Total loss': 0.2162774785531086}
2023-01-03 23:45:18,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:18,317 INFO:     Epoch: 46
2023-01-03 23:45:19,909 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.494659224152565, 'Total loss': 0.494659224152565} | train loss {'Reaction outcome loss': 0.23226694211336799, 'Total loss': 0.23226694211336799}
2023-01-03 23:45:19,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:19,909 INFO:     Epoch: 47
2023-01-03 23:45:21,500 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47491942246754965, 'Total loss': 0.47491942246754965} | train loss {'Reaction outcome loss': 0.22647828639457948, 'Total loss': 0.22647828639457948}
2023-01-03 23:45:21,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:21,501 INFO:     Epoch: 48
2023-01-03 23:45:23,092 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4631637826561928, 'Total loss': 0.4631637826561928} | train loss {'Reaction outcome loss': 0.21180229788423394, 'Total loss': 0.21180229788423394}
2023-01-03 23:45:23,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:23,092 INFO:     Epoch: 49
2023-01-03 23:45:24,669 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4825840304295222, 'Total loss': 0.4825840304295222} | train loss {'Reaction outcome loss': 0.20890016097278483, 'Total loss': 0.20890016097278483}
2023-01-03 23:45:24,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:24,670 INFO:     Epoch: 50
2023-01-03 23:45:26,289 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48836785356203716, 'Total loss': 0.48836785356203716} | train loss {'Reaction outcome loss': 0.2079973515420283, 'Total loss': 0.2079973515420283}
2023-01-03 23:45:26,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:26,290 INFO:     Epoch: 51
2023-01-03 23:45:27,899 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48073747058709465, 'Total loss': 0.48073747058709465} | train loss {'Reaction outcome loss': 0.20633125219554105, 'Total loss': 0.20633125219554105}
2023-01-03 23:45:27,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:27,899 INFO:     Epoch: 52
2023-01-03 23:45:29,517 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4940547078847885, 'Total loss': 0.4940547078847885} | train loss {'Reaction outcome loss': 0.20522602743374696, 'Total loss': 0.20522602743374696}
2023-01-03 23:45:29,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:29,517 INFO:     Epoch: 53
2023-01-03 23:45:31,135 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4758835295836131, 'Total loss': 0.4758835295836131} | train loss {'Reaction outcome loss': 0.21341266377493268, 'Total loss': 0.21341266377493268}
2023-01-03 23:45:31,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:31,135 INFO:     Epoch: 54
2023-01-03 23:45:32,732 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4809826950232188, 'Total loss': 0.4809826950232188} | train loss {'Reaction outcome loss': 0.20391673574403799, 'Total loss': 0.20391673574403799}
2023-01-03 23:45:32,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:32,733 INFO:     Epoch: 55
2023-01-03 23:45:34,325 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4774985631306966, 'Total loss': 0.4774985631306966} | train loss {'Reaction outcome loss': 0.1989902226082252, 'Total loss': 0.1989902226082252}
2023-01-03 23:45:34,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:34,325 INFO:     Epoch: 56
2023-01-03 23:45:35,898 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4958152542511622, 'Total loss': 0.4958152542511622} | train loss {'Reaction outcome loss': 0.20036198492728188, 'Total loss': 0.20036198492728188}
2023-01-03 23:45:35,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:35,899 INFO:     Epoch: 57
2023-01-03 23:45:37,491 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4943347255388896, 'Total loss': 0.4943347255388896} | train loss {'Reaction outcome loss': 0.19662662436008838, 'Total loss': 0.19662662436008838}
2023-01-03 23:45:37,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:37,492 INFO:     Epoch: 58
2023-01-03 23:45:39,085 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.490334153175354, 'Total loss': 0.490334153175354} | train loss {'Reaction outcome loss': 0.19809781657164896, 'Total loss': 0.19809781657164896}
2023-01-03 23:45:39,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:39,085 INFO:     Epoch: 59
2023-01-03 23:45:40,678 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49155513644218446, 'Total loss': 0.49155513644218446} | train loss {'Reaction outcome loss': 0.19528226742688828, 'Total loss': 0.19528226742688828}
2023-01-03 23:45:40,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:40,678 INFO:     Epoch: 60
2023-01-03 23:45:42,266 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4722232421239217, 'Total loss': 0.4722232421239217} | train loss {'Reaction outcome loss': 0.19453546475869563, 'Total loss': 0.19453546475869563}
2023-01-03 23:45:42,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:42,266 INFO:     Epoch: 61
2023-01-03 23:45:43,854 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4916195054848989, 'Total loss': 0.4916195054848989} | train loss {'Reaction outcome loss': 0.1947549510657774, 'Total loss': 0.1947549510657774}
2023-01-03 23:45:43,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:43,855 INFO:     Epoch: 62
2023-01-03 23:45:45,432 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47061406771341957, 'Total loss': 0.47061406771341957} | train loss {'Reaction outcome loss': 0.19213008145179364, 'Total loss': 0.19213008145179364}
2023-01-03 23:45:45,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:45,432 INFO:     Epoch: 63
2023-01-03 23:45:47,028 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5071651081244151, 'Total loss': 0.5071651081244151} | train loss {'Reaction outcome loss': 0.18907704893027202, 'Total loss': 0.18907704893027202}
2023-01-03 23:45:47,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:47,028 INFO:     Epoch: 64
2023-01-03 23:45:48,683 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4856505145629247, 'Total loss': 0.4856505145629247} | train loss {'Reaction outcome loss': 0.18974144610346874, 'Total loss': 0.18974144610346874}
2023-01-03 23:45:48,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:48,683 INFO:     Epoch: 65
2023-01-03 23:45:50,343 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48043164412180583, 'Total loss': 0.48043164412180583} | train loss {'Reaction outcome loss': 0.19086216702851452, 'Total loss': 0.19086216702851452}
2023-01-03 23:45:50,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:50,343 INFO:     Epoch: 66
2023-01-03 23:45:51,954 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5053014020125072, 'Total loss': 0.5053014020125072} | train loss {'Reaction outcome loss': 0.18832035397476368, 'Total loss': 0.18832035397476368}
2023-01-03 23:45:51,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:51,954 INFO:     Epoch: 67
2023-01-03 23:45:53,539 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.501572048664093, 'Total loss': 0.501572048664093} | train loss {'Reaction outcome loss': 0.18649124990359112, 'Total loss': 0.18649124990359112}
2023-01-03 23:45:53,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:53,539 INFO:     Epoch: 68
2023-01-03 23:45:55,159 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4915034264326096, 'Total loss': 0.4915034264326096} | train loss {'Reaction outcome loss': 0.18603773621599312, 'Total loss': 0.18603773621599312}
2023-01-03 23:45:55,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:55,160 INFO:     Epoch: 69
2023-01-03 23:45:56,750 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49371166427930196, 'Total loss': 0.49371166427930196} | train loss {'Reaction outcome loss': 0.1868271379633739, 'Total loss': 0.1868271379633739}
2023-01-03 23:45:56,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:56,751 INFO:     Epoch: 70
2023-01-03 23:45:58,345 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5105518221855163, 'Total loss': 0.5105518221855163} | train loss {'Reaction outcome loss': 0.1848045724876009, 'Total loss': 0.1848045724876009}
2023-01-03 23:45:58,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:58,345 INFO:     Epoch: 71
2023-01-03 23:45:59,942 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4938250889380773, 'Total loss': 0.4938250889380773} | train loss {'Reaction outcome loss': 0.185773449370075, 'Total loss': 0.185773449370075}
2023-01-03 23:45:59,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:45:59,942 INFO:     Epoch: 72
2023-01-03 23:46:01,537 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4940117547909419, 'Total loss': 0.4940117547909419} | train loss {'Reaction outcome loss': 0.18235978442258993, 'Total loss': 0.18235978442258993}
2023-01-03 23:46:01,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:01,537 INFO:     Epoch: 73
2023-01-03 23:46:03,120 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4842855195204417, 'Total loss': 0.4842855195204417} | train loss {'Reaction outcome loss': 0.1793067451748673, 'Total loss': 0.1793067451748673}
2023-01-03 23:46:03,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:03,120 INFO:     Epoch: 74
2023-01-03 23:46:04,784 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4800473615527153, 'Total loss': 0.4800473615527153} | train loss {'Reaction outcome loss': 0.1805683877049149, 'Total loss': 0.1805683877049149}
2023-01-03 23:46:04,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:04,785 INFO:     Epoch: 75
2023-01-03 23:46:06,452 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5041490177313487, 'Total loss': 0.5041490177313487} | train loss {'Reaction outcome loss': 0.1795765319122069, 'Total loss': 0.1795765319122069}
2023-01-03 23:46:06,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:06,452 INFO:     Epoch: 76
2023-01-03 23:46:08,043 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5189271142085393, 'Total loss': 0.5189271142085393} | train loss {'Reaction outcome loss': 0.1790498342985908, 'Total loss': 0.1790498342985908}
2023-01-03 23:46:08,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:08,044 INFO:     Epoch: 77
2023-01-03 23:46:09,690 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4685137301683426, 'Total loss': 0.4685137301683426} | train loss {'Reaction outcome loss': 0.18693948464239668, 'Total loss': 0.18693948464239668}
2023-01-03 23:46:09,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:09,690 INFO:     Epoch: 78
2023-01-03 23:46:11,324 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5132466435432435, 'Total loss': 0.5132466435432435} | train loss {'Reaction outcome loss': 0.1909172124215874, 'Total loss': 0.1909172124215874}
2023-01-03 23:46:11,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:11,324 INFO:     Epoch: 79
2023-01-03 23:46:12,941 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.515346207221349, 'Total loss': 0.515346207221349} | train loss {'Reaction outcome loss': 0.1931504913852908, 'Total loss': 0.1931504913852908}
2023-01-03 23:46:12,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:12,942 INFO:     Epoch: 80
2023-01-03 23:46:14,565 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4841858774423599, 'Total loss': 0.4841858774423599} | train loss {'Reaction outcome loss': 0.17648774486682986, 'Total loss': 0.17648774486682986}
2023-01-03 23:46:14,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:14,566 INFO:     Epoch: 81
2023-01-03 23:46:16,166 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5266462683677673, 'Total loss': 0.5266462683677673} | train loss {'Reaction outcome loss': 0.18250958100501177, 'Total loss': 0.18250958100501177}
2023-01-03 23:46:16,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:16,166 INFO:     Epoch: 82
2023-01-03 23:46:17,755 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.495737025141716, 'Total loss': 0.495737025141716} | train loss {'Reaction outcome loss': 0.1760186665051151, 'Total loss': 0.1760186665051151}
2023-01-03 23:46:17,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:17,755 INFO:     Epoch: 83
2023-01-03 23:46:19,356 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48880958557128906, 'Total loss': 0.48880958557128906} | train loss {'Reaction outcome loss': 0.17111833534291046, 'Total loss': 0.17111833534291046}
2023-01-03 23:46:19,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:19,357 INFO:     Epoch: 84
2023-01-03 23:46:21,002 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4954622209072113, 'Total loss': 0.4954622209072113} | train loss {'Reaction outcome loss': 0.17227271622365495, 'Total loss': 0.17227271622365495}
2023-01-03 23:46:21,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:21,002 INFO:     Epoch: 85
2023-01-03 23:46:22,672 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.531766626238823, 'Total loss': 0.531766626238823} | train loss {'Reaction outcome loss': 0.17351196488648976, 'Total loss': 0.17351196488648976}
2023-01-03 23:46:22,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:22,673 INFO:     Epoch: 86
2023-01-03 23:46:24,268 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5154403040806452, 'Total loss': 0.5154403040806452} | train loss {'Reaction outcome loss': 0.1708705977913735, 'Total loss': 0.1708705977913735}
2023-01-03 23:46:24,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:24,269 INFO:     Epoch: 87
2023-01-03 23:46:25,938 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5260411242643992, 'Total loss': 0.5260411242643992} | train loss {'Reaction outcome loss': 0.17885399310161237, 'Total loss': 0.17885399310161237}
2023-01-03 23:46:25,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:25,938 INFO:     Epoch: 88
2023-01-03 23:46:27,553 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5408052464326223, 'Total loss': 0.5408052464326223} | train loss {'Reaction outcome loss': 0.18836202998848064, 'Total loss': 0.18836202998848064}
2023-01-03 23:46:27,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:27,554 INFO:     Epoch: 89
2023-01-03 23:46:29,146 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5043047805627187, 'Total loss': 0.5043047805627187} | train loss {'Reaction outcome loss': 0.17471295185964994, 'Total loss': 0.17471295185964994}
2023-01-03 23:46:29,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:29,146 INFO:     Epoch: 90
2023-01-03 23:46:30,766 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5243532568216324, 'Total loss': 0.5243532568216324} | train loss {'Reaction outcome loss': 0.1694134327882911, 'Total loss': 0.1694134327882911}
2023-01-03 23:46:30,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:30,766 INFO:     Epoch: 91
2023-01-03 23:46:32,392 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5154467046260833, 'Total loss': 0.5154467046260833} | train loss {'Reaction outcome loss': 0.16897324420763957, 'Total loss': 0.16897324420763957}
2023-01-03 23:46:32,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:32,392 INFO:     Epoch: 92
2023-01-03 23:46:34,015 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49628200829029084, 'Total loss': 0.49628200829029084} | train loss {'Reaction outcome loss': 0.16793512312237316, 'Total loss': 0.16793512312237316}
2023-01-03 23:46:34,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:34,015 INFO:     Epoch: 93
2023-01-03 23:46:35,615 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5323045412699382, 'Total loss': 0.5323045412699382} | train loss {'Reaction outcome loss': 0.16859663017564436, 'Total loss': 0.16859663017564436}
2023-01-03 23:46:35,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:35,615 INFO:     Epoch: 94
2023-01-03 23:46:37,205 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4973884403705597, 'Total loss': 0.4973884403705597} | train loss {'Reaction outcome loss': 0.16712230734908412, 'Total loss': 0.16712230734908412}
2023-01-03 23:46:37,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:37,205 INFO:     Epoch: 95
2023-01-03 23:46:38,791 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5291373158494631, 'Total loss': 0.5291373158494631} | train loss {'Reaction outcome loss': 0.16586558925603828, 'Total loss': 0.16586558925603828}
2023-01-03 23:46:38,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:38,791 INFO:     Epoch: 96
2023-01-03 23:46:40,386 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47309114833672844, 'Total loss': 0.47309114833672844} | train loss {'Reaction outcome loss': 0.166872640506736, 'Total loss': 0.166872640506736}
2023-01-03 23:46:40,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:40,386 INFO:     Epoch: 97
2023-01-03 23:46:41,981 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5212590982516606, 'Total loss': 0.5212590982516606} | train loss {'Reaction outcome loss': 0.16688086779153757, 'Total loss': 0.16688086779153757}
2023-01-03 23:46:41,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:41,981 INFO:     Epoch: 98
2023-01-03 23:46:43,599 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5133989870548248, 'Total loss': 0.5133989870548248} | train loss {'Reaction outcome loss': 0.16685913839161082, 'Total loss': 0.16685913839161082}
2023-01-03 23:46:43,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:43,600 INFO:     Epoch: 99
2023-01-03 23:46:45,189 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4968504786491394, 'Total loss': 0.4968504786491394} | train loss {'Reaction outcome loss': 0.16518875726235463, 'Total loss': 0.16518875726235463}
2023-01-03 23:46:45,190 INFO:     Best model found after epoch 27 of 100.
2023-01-03 23:46:45,190 INFO:   Done with stage: TRAINING
2023-01-03 23:46:45,190 INFO:   Starting stage: EVALUATION
2023-01-03 23:46:45,319 INFO:   Done with stage: EVALUATION
2023-01-03 23:46:45,319 INFO:   Leaving out SEQ value Fold_9
2023-01-03 23:46:45,332 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-03 23:46:45,332 INFO:   Starting stage: FEATURE SCALING
2023-01-03 23:46:45,982 INFO:   Done with stage: FEATURE SCALING
2023-01-03 23:46:45,982 INFO:   Starting stage: SCALING TARGETS
2023-01-03 23:46:46,054 INFO:   Done with stage: SCALING TARGETS
2023-01-03 23:46:46,054 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:46:46,054 INFO:     No hyperparam tuning for this model
2023-01-03 23:46:46,054 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:46:46,054 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 23:46:46,055 INFO:     None feature selector for col prot
2023-01-03 23:46:46,055 INFO:     None feature selector for col prot
2023-01-03 23:46:46,055 INFO:     None feature selector for col prot
2023-01-03 23:46:46,056 INFO:     None feature selector for col chem
2023-01-03 23:46:46,056 INFO:     None feature selector for col chem
2023-01-03 23:46:46,056 INFO:     None feature selector for col chem
2023-01-03 23:46:46,056 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 23:46:46,056 INFO:   Starting stage: BUILD MODEL
2023-01-03 23:46:46,057 INFO:     Number of params in model 70141
2023-01-03 23:46:46,060 INFO:   Done with stage: BUILD MODEL
2023-01-03 23:46:46,060 INFO:   Starting stage: TRAINING
2023-01-03 23:46:46,103 INFO:     Val loss before train {'Reaction outcome loss': 0.9966979225476583, 'Total loss': 0.9966979225476583}
2023-01-03 23:46:46,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:46,104 INFO:     Epoch: 0
2023-01-03 23:46:47,709 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6883225758870443, 'Total loss': 0.6883225758870443} | train loss {'Reaction outcome loss': 0.8401164347944707, 'Total loss': 0.8401164347944707}
2023-01-03 23:46:47,709 INFO:     Found new best model at epoch 0
2023-01-03 23:46:47,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:47,710 INFO:     Epoch: 1
2023-01-03 23:46:49,320 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5767106672128042, 'Total loss': 0.5767106672128042} | train loss {'Reaction outcome loss': 0.6250068231179826, 'Total loss': 0.6250068231179826}
2023-01-03 23:46:49,320 INFO:     Found new best model at epoch 1
2023-01-03 23:46:49,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:49,321 INFO:     Epoch: 2
2023-01-03 23:46:50,926 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5090168694655101, 'Total loss': 0.5090168694655101} | train loss {'Reaction outcome loss': 0.5475903042602195, 'Total loss': 0.5475903042602195}
2023-01-03 23:46:50,926 INFO:     Found new best model at epoch 2
2023-01-03 23:46:50,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:50,927 INFO:     Epoch: 3
2023-01-03 23:46:52,514 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4878100335597992, 'Total loss': 0.4878100335597992} | train loss {'Reaction outcome loss': 0.5066166694413884, 'Total loss': 0.5066166694413884}
2023-01-03 23:46:52,515 INFO:     Found new best model at epoch 3
2023-01-03 23:46:52,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:52,516 INFO:     Epoch: 4
2023-01-03 23:46:54,103 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4639889617760976, 'Total loss': 0.4639889617760976} | train loss {'Reaction outcome loss': 0.47736253640496773, 'Total loss': 0.47736253640496773}
2023-01-03 23:46:54,104 INFO:     Found new best model at epoch 4
2023-01-03 23:46:54,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:54,104 INFO:     Epoch: 5
2023-01-03 23:46:55,696 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4452266057332357, 'Total loss': 0.4452266057332357} | train loss {'Reaction outcome loss': 0.45688466539451794, 'Total loss': 0.45688466539451794}
2023-01-03 23:46:55,696 INFO:     Found new best model at epoch 5
2023-01-03 23:46:55,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:55,697 INFO:     Epoch: 6
2023-01-03 23:46:57,312 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4352160344521205, 'Total loss': 0.4352160344521205} | train loss {'Reaction outcome loss': 0.4388416045839606, 'Total loss': 0.4388416045839606}
2023-01-03 23:46:57,312 INFO:     Found new best model at epoch 6
2023-01-03 23:46:57,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:57,313 INFO:     Epoch: 7
2023-01-03 23:46:58,981 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4278320531050364, 'Total loss': 0.4278320531050364} | train loss {'Reaction outcome loss': 0.4234494009065284, 'Total loss': 0.4234494009065284}
2023-01-03 23:46:58,981 INFO:     Found new best model at epoch 7
2023-01-03 23:46:58,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:46:58,982 INFO:     Epoch: 8
2023-01-03 23:47:00,584 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4245855510234833, 'Total loss': 0.4245855510234833} | train loss {'Reaction outcome loss': 0.4082596383262627, 'Total loss': 0.4082596383262627}
2023-01-03 23:47:00,585 INFO:     Found new best model at epoch 8
2023-01-03 23:47:00,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:00,585 INFO:     Epoch: 9
2023-01-03 23:47:02,189 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4186770975589752, 'Total loss': 0.4186770975589752} | train loss {'Reaction outcome loss': 0.3972070092328619, 'Total loss': 0.3972070092328619}
2023-01-03 23:47:02,189 INFO:     Found new best model at epoch 9
2023-01-03 23:47:02,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:02,190 INFO:     Epoch: 10
2023-01-03 23:47:03,782 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4121845901012421, 'Total loss': 0.4121845901012421} | train loss {'Reaction outcome loss': 0.3888921123334217, 'Total loss': 0.3888921123334217}
2023-01-03 23:47:03,782 INFO:     Found new best model at epoch 10
2023-01-03 23:47:03,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:03,783 INFO:     Epoch: 11
2023-01-03 23:47:05,386 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3998428146044413, 'Total loss': 0.3998428146044413} | train loss {'Reaction outcome loss': 0.37751447616501405, 'Total loss': 0.37751447616501405}
2023-01-03 23:47:05,387 INFO:     Found new best model at epoch 11
2023-01-03 23:47:05,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:05,388 INFO:     Epoch: 12
2023-01-03 23:47:06,991 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40877908170223237, 'Total loss': 0.40877908170223237} | train loss {'Reaction outcome loss': 0.3680146543127535, 'Total loss': 0.3680146543127535}
2023-01-03 23:47:06,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:06,991 INFO:     Epoch: 13
2023-01-03 23:47:08,595 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3842927450935046, 'Total loss': 0.3842927450935046} | train loss {'Reaction outcome loss': 0.36355303270937306, 'Total loss': 0.36355303270937306}
2023-01-03 23:47:08,595 INFO:     Found new best model at epoch 13
2023-01-03 23:47:08,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:08,596 INFO:     Epoch: 14
2023-01-03 23:47:10,197 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.38993618537982305, 'Total loss': 0.38993618537982305} | train loss {'Reaction outcome loss': 0.35505335258878096, 'Total loss': 0.35505335258878096}
2023-01-03 23:47:10,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:10,197 INFO:     Epoch: 15
2023-01-03 23:47:11,798 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3858946522076925, 'Total loss': 0.3858946522076925} | train loss {'Reaction outcome loss': 0.34706926883773254, 'Total loss': 0.34706926883773254}
2023-01-03 23:47:11,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:11,798 INFO:     Epoch: 16
2023-01-03 23:47:13,405 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.383230604728063, 'Total loss': 0.383230604728063} | train loss {'Reaction outcome loss': 0.3405450540544324, 'Total loss': 0.3405450540544324}
2023-01-03 23:47:13,406 INFO:     Found new best model at epoch 16
2023-01-03 23:47:13,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:13,406 INFO:     Epoch: 17
2023-01-03 23:47:15,014 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38232606947422026, 'Total loss': 0.38232606947422026} | train loss {'Reaction outcome loss': 0.3340990035542512, 'Total loss': 0.3340990035542512}
2023-01-03 23:47:15,014 INFO:     Found new best model at epoch 17
2023-01-03 23:47:15,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:15,015 INFO:     Epoch: 18
2023-01-03 23:47:16,622 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3901851216952006, 'Total loss': 0.3901851216952006} | train loss {'Reaction outcome loss': 0.32997502822307906, 'Total loss': 0.32997502822307906}
2023-01-03 23:47:16,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:16,622 INFO:     Epoch: 19
2023-01-03 23:47:18,237 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3757267544666926, 'Total loss': 0.3757267544666926} | train loss {'Reaction outcome loss': 0.3235990196358856, 'Total loss': 0.3235990196358856}
2023-01-03 23:47:18,237 INFO:     Found new best model at epoch 19
2023-01-03 23:47:18,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:18,238 INFO:     Epoch: 20
2023-01-03 23:47:19,838 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3874515881141027, 'Total loss': 0.3874515881141027} | train loss {'Reaction outcome loss': 0.31845391393783723, 'Total loss': 0.31845391393783723}
2023-01-03 23:47:19,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:19,839 INFO:     Epoch: 21
2023-01-03 23:47:21,431 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3983126014471054, 'Total loss': 0.3983126014471054} | train loss {'Reaction outcome loss': 0.3144655913544906, 'Total loss': 0.3144655913544906}
2023-01-03 23:47:21,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:21,431 INFO:     Epoch: 22
2023-01-03 23:47:23,039 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41332758168379463, 'Total loss': 0.41332758168379463} | train loss {'Reaction outcome loss': 0.3093694831221112, 'Total loss': 0.3093694831221112}
2023-01-03 23:47:23,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:23,040 INFO:     Epoch: 23
2023-01-03 23:47:24,653 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4079573452472687, 'Total loss': 0.4079573452472687} | train loss {'Reaction outcome loss': 0.30613430818065407, 'Total loss': 0.30613430818065407}
2023-01-03 23:47:24,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:24,653 INFO:     Epoch: 24
2023-01-03 23:47:26,264 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3912203133106232, 'Total loss': 0.3912203133106232} | train loss {'Reaction outcome loss': 0.2998342325756266, 'Total loss': 0.2998342325756266}
2023-01-03 23:47:26,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:26,265 INFO:     Epoch: 25
2023-01-03 23:47:27,892 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39173960586388906, 'Total loss': 0.39173960586388906} | train loss {'Reaction outcome loss': 0.2961838132422754, 'Total loss': 0.2961838132422754}
2023-01-03 23:47:27,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:27,892 INFO:     Epoch: 26
2023-01-03 23:47:29,482 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3869375725587209, 'Total loss': 0.3869375725587209} | train loss {'Reaction outcome loss': 0.292382943501111, 'Total loss': 0.292382943501111}
2023-01-03 23:47:29,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:29,482 INFO:     Epoch: 27
2023-01-03 23:47:31,092 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39327542881170907, 'Total loss': 0.39327542881170907} | train loss {'Reaction outcome loss': 0.2861700656181638, 'Total loss': 0.2861700656181638}
2023-01-03 23:47:31,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:31,092 INFO:     Epoch: 28
2023-01-03 23:47:32,697 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40244117975234983, 'Total loss': 0.40244117975234983} | train loss {'Reaction outcome loss': 0.28366777661259857, 'Total loss': 0.28366777661259857}
2023-01-03 23:47:32,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:32,697 INFO:     Epoch: 29
2023-01-03 23:47:34,346 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39460838834444684, 'Total loss': 0.39460838834444684} | train loss {'Reaction outcome loss': 0.2801928204965075, 'Total loss': 0.2801928204965075}
2023-01-03 23:47:34,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:34,346 INFO:     Epoch: 30
2023-01-03 23:47:35,955 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40439717868963876, 'Total loss': 0.40439717868963876} | train loss {'Reaction outcome loss': 0.27733216192640553, 'Total loss': 0.27733216192640553}
2023-01-03 23:47:35,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:35,955 INFO:     Epoch: 31
2023-01-03 23:47:37,571 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39195123612880706, 'Total loss': 0.39195123612880706} | train loss {'Reaction outcome loss': 0.27414849346725517, 'Total loss': 0.27414849346725517}
2023-01-03 23:47:37,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:37,572 INFO:     Epoch: 32
2023-01-03 23:47:39,175 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39662863314151764, 'Total loss': 0.39662863314151764} | train loss {'Reaction outcome loss': 0.2695361082492537, 'Total loss': 0.2695361082492537}
2023-01-03 23:47:39,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:39,176 INFO:     Epoch: 33
2023-01-03 23:47:40,784 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38855071862538654, 'Total loss': 0.38855071862538654} | train loss {'Reaction outcome loss': 0.2684982288292599, 'Total loss': 0.2684982288292599}
2023-01-03 23:47:40,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:40,785 INFO:     Epoch: 34
2023-01-03 23:47:42,374 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40236745874087015, 'Total loss': 0.40236745874087015} | train loss {'Reaction outcome loss': 0.2657243004774789, 'Total loss': 0.2657243004774789}
2023-01-03 23:47:42,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:42,375 INFO:     Epoch: 35
2023-01-03 23:47:43,976 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3852178454399109, 'Total loss': 0.3852178454399109} | train loss {'Reaction outcome loss': 0.2599195985103342, 'Total loss': 0.2599195985103342}
2023-01-03 23:47:43,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:43,976 INFO:     Epoch: 36
2023-01-03 23:47:45,573 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40219620168209075, 'Total loss': 0.40219620168209075} | train loss {'Reaction outcome loss': 0.25807933430002483, 'Total loss': 0.25807933430002483}
2023-01-03 23:47:45,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:45,574 INFO:     Epoch: 37
2023-01-03 23:47:47,177 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4038190146287282, 'Total loss': 0.4038190146287282} | train loss {'Reaction outcome loss': 0.2557184111716945, 'Total loss': 0.2557184111716945}
2023-01-03 23:47:47,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:47,177 INFO:     Epoch: 38
2023-01-03 23:47:48,771 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4022730698188146, 'Total loss': 0.4022730698188146} | train loss {'Reaction outcome loss': 0.2518098525541569, 'Total loss': 0.2518098525541569}
2023-01-03 23:47:48,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:48,771 INFO:     Epoch: 39
2023-01-03 23:47:50,357 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4033295710881551, 'Total loss': 0.4033295710881551} | train loss {'Reaction outcome loss': 0.25118927061826746, 'Total loss': 0.25118927061826746}
2023-01-03 23:47:50,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:50,357 INFO:     Epoch: 40
2023-01-03 23:47:51,957 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.389919509490331, 'Total loss': 0.389919509490331} | train loss {'Reaction outcome loss': 0.2465468774741307, 'Total loss': 0.2465468774741307}
2023-01-03 23:47:51,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:51,957 INFO:     Epoch: 41
2023-01-03 23:47:53,557 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4010360906521479, 'Total loss': 0.4010360906521479} | train loss {'Reaction outcome loss': 0.24579276296474872, 'Total loss': 0.24579276296474872}
2023-01-03 23:47:53,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:53,557 INFO:     Epoch: 42
2023-01-03 23:47:55,185 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4130706051985423, 'Total loss': 0.4130706051985423} | train loss {'Reaction outcome loss': 0.24247304114785434, 'Total loss': 0.24247304114785434}
2023-01-03 23:47:55,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:55,186 INFO:     Epoch: 43
2023-01-03 23:47:56,777 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3882393538951874, 'Total loss': 0.3882393538951874} | train loss {'Reaction outcome loss': 0.2422024668984465, 'Total loss': 0.2422024668984465}
2023-01-03 23:47:56,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:56,778 INFO:     Epoch: 44
2023-01-03 23:47:58,408 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41539771457513175, 'Total loss': 0.41539771457513175} | train loss {'Reaction outcome loss': 0.23823814033547464, 'Total loss': 0.23823814033547464}
2023-01-03 23:47:58,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:47:58,408 INFO:     Epoch: 45
2023-01-03 23:48:00,013 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41090434094270073, 'Total loss': 0.41090434094270073} | train loss {'Reaction outcome loss': 0.23650338456357428, 'Total loss': 0.23650338456357428}
2023-01-03 23:48:00,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:00,014 INFO:     Epoch: 46
2023-01-03 23:48:01,641 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.407118300596873, 'Total loss': 0.407118300596873} | train loss {'Reaction outcome loss': 0.23422474954747982, 'Total loss': 0.23422474954747982}
2023-01-03 23:48:01,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:01,641 INFO:     Epoch: 47
2023-01-03 23:48:03,268 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39868817031383513, 'Total loss': 0.39868817031383513} | train loss {'Reaction outcome loss': 0.22996437177062035, 'Total loss': 0.22996437177062035}
2023-01-03 23:48:03,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:03,269 INFO:     Epoch: 48
2023-01-03 23:48:04,873 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4020722538232803, 'Total loss': 0.4020722538232803} | train loss {'Reaction outcome loss': 0.22923003695232774, 'Total loss': 0.22923003695232774}
2023-01-03 23:48:04,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:04,874 INFO:     Epoch: 49
2023-01-03 23:48:06,458 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42244141598542534, 'Total loss': 0.42244141598542534} | train loss {'Reaction outcome loss': 0.22598106855197073, 'Total loss': 0.22598106855197073}
2023-01-03 23:48:06,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:06,459 INFO:     Epoch: 50
2023-01-03 23:48:08,057 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43148204584916433, 'Total loss': 0.43148204584916433} | train loss {'Reaction outcome loss': 0.22384233421071126, 'Total loss': 0.22384233421071126}
2023-01-03 23:48:08,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:08,057 INFO:     Epoch: 51
2023-01-03 23:48:09,641 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4039387236038844, 'Total loss': 0.4039387236038844} | train loss {'Reaction outcome loss': 0.2222502743589964, 'Total loss': 0.2222502743589964}
2023-01-03 23:48:09,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:09,641 INFO:     Epoch: 52
2023-01-03 23:48:11,242 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41097821791966754, 'Total loss': 0.41097821791966754} | train loss {'Reaction outcome loss': 0.22184518019967991, 'Total loss': 0.22184518019967991}
2023-01-03 23:48:11,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:11,242 INFO:     Epoch: 53
2023-01-03 23:48:12,840 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41740730007489524, 'Total loss': 0.41740730007489524} | train loss {'Reaction outcome loss': 0.22043418049112984, 'Total loss': 0.22043418049112984}
2023-01-03 23:48:12,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:12,840 INFO:     Epoch: 54
2023-01-03 23:48:14,426 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4150306522846222, 'Total loss': 0.4150306522846222} | train loss {'Reaction outcome loss': 0.21791685431765306, 'Total loss': 0.21791685431765306}
2023-01-03 23:48:14,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:14,426 INFO:     Epoch: 55
2023-01-03 23:48:16,024 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4173770477374395, 'Total loss': 0.4173770477374395} | train loss {'Reaction outcome loss': 0.21567243700746164, 'Total loss': 0.21567243700746164}
2023-01-03 23:48:16,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:16,024 INFO:     Epoch: 56
2023-01-03 23:48:17,605 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4196394960085551, 'Total loss': 0.4196394960085551} | train loss {'Reaction outcome loss': 0.21635063767890422, 'Total loss': 0.21635063767890422}
2023-01-03 23:48:17,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:17,605 INFO:     Epoch: 57
2023-01-03 23:48:19,230 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4189024473230044, 'Total loss': 0.4189024473230044} | train loss {'Reaction outcome loss': 0.20995066549615524, 'Total loss': 0.20995066549615524}
2023-01-03 23:48:19,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:19,231 INFO:     Epoch: 58
2023-01-03 23:48:20,841 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42739343841870625, 'Total loss': 0.42739343841870625} | train loss {'Reaction outcome loss': 0.21386828710617573, 'Total loss': 0.21386828710617573}
2023-01-03 23:48:20,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:20,841 INFO:     Epoch: 59
2023-01-03 23:48:22,456 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42403441965579985, 'Total loss': 0.42403441965579985} | train loss {'Reaction outcome loss': 0.2127006900116855, 'Total loss': 0.2127006900116855}
2023-01-03 23:48:22,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:22,456 INFO:     Epoch: 60
2023-01-03 23:48:24,049 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.418940136830012, 'Total loss': 0.418940136830012} | train loss {'Reaction outcome loss': 0.20832859256745245, 'Total loss': 0.20832859256745245}
2023-01-03 23:48:24,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:24,050 INFO:     Epoch: 61
2023-01-03 23:48:25,652 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44850640892982485, 'Total loss': 0.44850640892982485} | train loss {'Reaction outcome loss': 0.2062540782030524, 'Total loss': 0.2062540782030524}
2023-01-03 23:48:25,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:25,652 INFO:     Epoch: 62
2023-01-03 23:48:27,258 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4251220355431239, 'Total loss': 0.4251220355431239} | train loss {'Reaction outcome loss': 0.20569567340644687, 'Total loss': 0.20569567340644687}
2023-01-03 23:48:27,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:27,258 INFO:     Epoch: 63
2023-01-03 23:48:28,861 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43112900853157043, 'Total loss': 0.43112900853157043} | train loss {'Reaction outcome loss': 0.2052388644444383, 'Total loss': 0.2052388644444383}
2023-01-03 23:48:28,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:28,861 INFO:     Epoch: 64
2023-01-03 23:48:30,490 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4430316130320231, 'Total loss': 0.4430316130320231} | train loss {'Reaction outcome loss': 0.2005413862799264, 'Total loss': 0.2005413862799264}
2023-01-03 23:48:30,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:30,490 INFO:     Epoch: 65
2023-01-03 23:48:32,084 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45195944607257843, 'Total loss': 0.45195944607257843} | train loss {'Reaction outcome loss': 0.20157116876128348, 'Total loss': 0.20157116876128348}
2023-01-03 23:48:32,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:32,086 INFO:     Epoch: 66
2023-01-03 23:48:33,694 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4413164565960566, 'Total loss': 0.4413164565960566} | train loss {'Reaction outcome loss': 0.19792591465724504, 'Total loss': 0.19792591465724504}
2023-01-03 23:48:33,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:33,695 INFO:     Epoch: 67
2023-01-03 23:48:35,265 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4423663546641668, 'Total loss': 0.4423663546641668} | train loss {'Reaction outcome loss': 0.19895957894488792, 'Total loss': 0.19895957894488792}
2023-01-03 23:48:35,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:35,265 INFO:     Epoch: 68
2023-01-03 23:48:36,888 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4583525617917379, 'Total loss': 0.4583525617917379} | train loss {'Reaction outcome loss': 0.1993664481579612, 'Total loss': 0.1993664481579612}
2023-01-03 23:48:36,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:36,889 INFO:     Epoch: 69
2023-01-03 23:48:38,525 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4243767817815145, 'Total loss': 0.4243767817815145} | train loss {'Reaction outcome loss': 0.20028811961493123, 'Total loss': 0.20028811961493123}
2023-01-03 23:48:38,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:38,526 INFO:     Epoch: 70
2023-01-03 23:48:40,129 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4479863593975703, 'Total loss': 0.4479863593975703} | train loss {'Reaction outcome loss': 0.19463644538155425, 'Total loss': 0.19463644538155425}
2023-01-03 23:48:40,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:40,129 INFO:     Epoch: 71
2023-01-03 23:48:41,727 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4374168207248052, 'Total loss': 0.4374168207248052} | train loss {'Reaction outcome loss': 0.192613466834441, 'Total loss': 0.192613466834441}
2023-01-03 23:48:41,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:41,727 INFO:     Epoch: 72
2023-01-03 23:48:43,337 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45755015015602113, 'Total loss': 0.45755015015602113} | train loss {'Reaction outcome loss': 0.1938078691544085, 'Total loss': 0.1938078691544085}
2023-01-03 23:48:43,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:43,337 INFO:     Epoch: 73
2023-01-03 23:48:44,946 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.458069971203804, 'Total loss': 0.458069971203804} | train loss {'Reaction outcome loss': 0.1907119511858651, 'Total loss': 0.1907119511858651}
2023-01-03 23:48:44,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:44,946 INFO:     Epoch: 74
2023-01-03 23:48:46,551 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4579772214094798, 'Total loss': 0.4579772214094798} | train loss {'Reaction outcome loss': 0.19304586955033484, 'Total loss': 0.19304586955033484}
2023-01-03 23:48:46,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:46,551 INFO:     Epoch: 75
2023-01-03 23:48:48,154 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4782688498497009, 'Total loss': 0.4782688498497009} | train loss {'Reaction outcome loss': 0.1899570089627044, 'Total loss': 0.1899570089627044}
2023-01-03 23:48:48,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:48,154 INFO:     Epoch: 76
2023-01-03 23:48:49,768 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45178282558918, 'Total loss': 0.45178282558918} | train loss {'Reaction outcome loss': 0.18786790962952998, 'Total loss': 0.18786790962952998}
2023-01-03 23:48:49,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:49,768 INFO:     Epoch: 77
2023-01-03 23:48:51,355 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4820105900367101, 'Total loss': 0.4820105900367101} | train loss {'Reaction outcome loss': 0.18774541413633403, 'Total loss': 0.18774541413633403}
2023-01-03 23:48:51,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:51,356 INFO:     Epoch: 78
2023-01-03 23:48:52,953 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47641968230406445, 'Total loss': 0.47641968230406445} | train loss {'Reaction outcome loss': 0.18918267789461551, 'Total loss': 0.18918267789461551}
2023-01-03 23:48:52,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:52,953 INFO:     Epoch: 79
2023-01-03 23:48:54,546 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4586070428291957, 'Total loss': 0.4586070428291957} | train loss {'Reaction outcome loss': 0.18515923515715324, 'Total loss': 0.18515923515715324}
2023-01-03 23:48:54,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:54,546 INFO:     Epoch: 80
2023-01-03 23:48:56,151 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44962699711322784, 'Total loss': 0.44962699711322784} | train loss {'Reaction outcome loss': 0.1875843093242994, 'Total loss': 0.1875843093242994}
2023-01-03 23:48:56,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:56,152 INFO:     Epoch: 81
2023-01-03 23:48:57,754 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.472763337691625, 'Total loss': 0.472763337691625} | train loss {'Reaction outcome loss': 0.1852226830104413, 'Total loss': 0.1852226830104413}
2023-01-03 23:48:57,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:57,755 INFO:     Epoch: 82
2023-01-03 23:48:59,341 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46991267800331116, 'Total loss': 0.46991267800331116} | train loss {'Reaction outcome loss': 0.18356316450593274, 'Total loss': 0.18356316450593274}
2023-01-03 23:48:59,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:48:59,341 INFO:     Epoch: 83
2023-01-03 23:49:00,956 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47255683441956836, 'Total loss': 0.47255683441956836} | train loss {'Reaction outcome loss': 0.18366449955676006, 'Total loss': 0.18366449955676006}
2023-01-03 23:49:00,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:00,957 INFO:     Epoch: 84
2023-01-03 23:49:02,569 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4811873932679494, 'Total loss': 0.4811873932679494} | train loss {'Reaction outcome loss': 0.1834985472746059, 'Total loss': 0.1834985472746059}
2023-01-03 23:49:02,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:02,570 INFO:     Epoch: 85
2023-01-03 23:49:04,188 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.476994455854098, 'Total loss': 0.476994455854098} | train loss {'Reaction outcome loss': 0.18415566746965858, 'Total loss': 0.18415566746965858}
2023-01-03 23:49:04,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:04,188 INFO:     Epoch: 86
2023-01-03 23:49:05,810 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47599723041057584, 'Total loss': 0.47599723041057584} | train loss {'Reaction outcome loss': 0.18245171871211124, 'Total loss': 0.18245171871211124}
2023-01-03 23:49:05,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:05,810 INFO:     Epoch: 87
2023-01-03 23:49:07,416 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4855941424767176, 'Total loss': 0.4855941424767176} | train loss {'Reaction outcome loss': 0.18005597469016962, 'Total loss': 0.18005597469016962}
2023-01-03 23:49:07,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:07,417 INFO:     Epoch: 88
2023-01-03 23:49:09,001 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5020654951532681, 'Total loss': 0.5020654951532681} | train loss {'Reaction outcome loss': 0.17817628508036962, 'Total loss': 0.17817628508036962}
2023-01-03 23:49:09,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:09,002 INFO:     Epoch: 89
2023-01-03 23:49:10,604 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46313005934158963, 'Total loss': 0.46313005934158963} | train loss {'Reaction outcome loss': 0.17675262484497758, 'Total loss': 0.17675262484497758}
2023-01-03 23:49:10,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:10,604 INFO:     Epoch: 90
2023-01-03 23:49:12,194 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4861211895942688, 'Total loss': 0.4861211895942688} | train loss {'Reaction outcome loss': 0.1788984360778536, 'Total loss': 0.1788984360778536}
2023-01-03 23:49:12,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:12,194 INFO:     Epoch: 91
2023-01-03 23:49:13,797 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46984421809514365, 'Total loss': 0.46984421809514365} | train loss {'Reaction outcome loss': 0.17718551371125538, 'Total loss': 0.17718551371125538}
2023-01-03 23:49:13,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:13,797 INFO:     Epoch: 92
2023-01-03 23:49:15,399 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4482957422733307, 'Total loss': 0.4482957422733307} | train loss {'Reaction outcome loss': 0.17825369437356287, 'Total loss': 0.17825369437356287}
2023-01-03 23:49:15,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:15,399 INFO:     Epoch: 93
2023-01-03 23:49:16,985 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4814174900452296, 'Total loss': 0.4814174900452296} | train loss {'Reaction outcome loss': 0.17594161912771983, 'Total loss': 0.17594161912771983}
2023-01-03 23:49:16,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:16,986 INFO:     Epoch: 94
2023-01-03 23:49:18,593 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46221993466218314, 'Total loss': 0.46221993466218314} | train loss {'Reaction outcome loss': 0.17634947641688778, 'Total loss': 0.17634947641688778}
2023-01-03 23:49:18,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:18,593 INFO:     Epoch: 95
2023-01-03 23:49:20,180 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4716272711753845, 'Total loss': 0.4716272711753845} | train loss {'Reaction outcome loss': 0.17524075553170826, 'Total loss': 0.17524075553170826}
2023-01-03 23:49:20,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:20,180 INFO:     Epoch: 96
2023-01-03 23:49:21,790 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45570313433806103, 'Total loss': 0.45570313433806103} | train loss {'Reaction outcome loss': 0.17382633170980408, 'Total loss': 0.17382633170980408}
2023-01-03 23:49:21,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:21,791 INFO:     Epoch: 97
2023-01-03 23:49:23,423 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48297637701034546, 'Total loss': 0.48297637701034546} | train loss {'Reaction outcome loss': 0.17484705345806018, 'Total loss': 0.17484705345806018}
2023-01-03 23:49:23,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:23,423 INFO:     Epoch: 98
2023-01-03 23:49:25,035 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4701686183611552, 'Total loss': 0.4701686183611552} | train loss {'Reaction outcome loss': 0.17365814750133224, 'Total loss': 0.17365814750133224}
2023-01-03 23:49:25,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:25,035 INFO:     Epoch: 99
2023-01-03 23:49:26,632 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4649370064338048, 'Total loss': 0.4649370064338048} | train loss {'Reaction outcome loss': 0.171316156668138, 'Total loss': 0.171316156668138}
2023-01-03 23:49:26,632 INFO:     Best model found after epoch 20 of 100.
2023-01-03 23:49:26,632 INFO:   Done with stage: TRAINING
2023-01-03 23:49:26,632 INFO:   Starting stage: EVALUATION
2023-01-03 23:49:26,757 INFO:   Done with stage: EVALUATION
2023-01-03 23:49:26,765 INFO:   Leaving out SEQ value Fold_0
2023-01-03 23:49:26,778 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-03 23:49:26,778 INFO:   Starting stage: FEATURE SCALING
2023-01-03 23:49:27,428 INFO:   Done with stage: FEATURE SCALING
2023-01-03 23:49:27,428 INFO:   Starting stage: SCALING TARGETS
2023-01-03 23:49:27,498 INFO:   Done with stage: SCALING TARGETS
2023-01-03 23:49:27,498 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:49:27,498 INFO:     No hyperparam tuning for this model
2023-01-03 23:49:27,498 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:49:27,498 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 23:49:27,499 INFO:     None feature selector for col prot
2023-01-03 23:49:27,499 INFO:     None feature selector for col prot
2023-01-03 23:49:27,499 INFO:     None feature selector for col prot
2023-01-03 23:49:27,499 INFO:     None feature selector for col chem
2023-01-03 23:49:27,500 INFO:     None feature selector for col chem
2023-01-03 23:49:27,500 INFO:     None feature selector for col chem
2023-01-03 23:49:27,500 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 23:49:27,500 INFO:   Starting stage: BUILD MODEL
2023-01-03 23:49:27,501 INFO:     Number of params in model 70141
2023-01-03 23:49:27,504 INFO:   Done with stage: BUILD MODEL
2023-01-03 23:49:27,504 INFO:   Starting stage: TRAINING
2023-01-03 23:49:27,548 INFO:     Val loss before train {'Reaction outcome loss': 0.9439705451329549, 'Total loss': 0.9439705451329549}
2023-01-03 23:49:27,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:27,549 INFO:     Epoch: 0
2023-01-03 23:49:29,122 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7078252315521241, 'Total loss': 0.7078252315521241} | train loss {'Reaction outcome loss': 0.8732707016441944, 'Total loss': 0.8732707016441944}
2023-01-03 23:49:29,122 INFO:     Found new best model at epoch 0
2023-01-03 23:49:29,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:29,123 INFO:     Epoch: 1
2023-01-03 23:49:30,712 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5635547856489818, 'Total loss': 0.5635547856489818} | train loss {'Reaction outcome loss': 0.6453021104535918, 'Total loss': 0.6453021104535918}
2023-01-03 23:49:30,712 INFO:     Found new best model at epoch 1
2023-01-03 23:49:30,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:30,713 INFO:     Epoch: 2
2023-01-03 23:49:32,298 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4985692342122396, 'Total loss': 0.4985692342122396} | train loss {'Reaction outcome loss': 0.5356113468534756, 'Total loss': 0.5356113468534756}
2023-01-03 23:49:32,298 INFO:     Found new best model at epoch 2
2023-01-03 23:49:32,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:32,299 INFO:     Epoch: 3
2023-01-03 23:49:33,884 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4862804214159648, 'Total loss': 0.4862804214159648} | train loss {'Reaction outcome loss': 0.4847899046148697, 'Total loss': 0.4847899046148697}
2023-01-03 23:49:33,885 INFO:     Found new best model at epoch 3
2023-01-03 23:49:33,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:33,886 INFO:     Epoch: 4
2023-01-03 23:49:35,148 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.506019667784373, 'Total loss': 0.506019667784373} | train loss {'Reaction outcome loss': 0.4593154110123206, 'Total loss': 0.4593154110123206}
2023-01-03 23:49:35,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:35,148 INFO:     Epoch: 5
2023-01-03 23:49:36,214 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4522980789343516, 'Total loss': 0.4522980789343516} | train loss {'Reaction outcome loss': 0.4414777942273739, 'Total loss': 0.4414777942273739}
2023-01-03 23:49:36,215 INFO:     Found new best model at epoch 5
2023-01-03 23:49:36,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:36,215 INFO:     Epoch: 6
2023-01-03 23:49:37,290 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4782974640528361, 'Total loss': 0.4782974640528361} | train loss {'Reaction outcome loss': 0.42394577363764285, 'Total loss': 0.42394577363764285}
2023-01-03 23:49:37,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:37,290 INFO:     Epoch: 7
2023-01-03 23:49:38,351 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.464669343829155, 'Total loss': 0.464669343829155} | train loss {'Reaction outcome loss': 0.4086882410040737, 'Total loss': 0.4086882410040737}
2023-01-03 23:49:38,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:38,352 INFO:     Epoch: 8
2023-01-03 23:49:39,565 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46353357036908466, 'Total loss': 0.46353357036908466} | train loss {'Reaction outcome loss': 0.39841914636484027, 'Total loss': 0.39841914636484027}
2023-01-03 23:49:39,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:39,565 INFO:     Epoch: 9
2023-01-03 23:49:41,154 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4521667023499807, 'Total loss': 0.4521667023499807} | train loss {'Reaction outcome loss': 0.3898826986551285, 'Total loss': 0.3898826986551285}
2023-01-03 23:49:41,155 INFO:     Found new best model at epoch 9
2023-01-03 23:49:41,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:41,156 INFO:     Epoch: 10
2023-01-03 23:49:42,761 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44770445028940836, 'Total loss': 0.44770445028940836} | train loss {'Reaction outcome loss': 0.3804005006477781, 'Total loss': 0.3804005006477781}
2023-01-03 23:49:42,761 INFO:     Found new best model at epoch 10
2023-01-03 23:49:42,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:42,762 INFO:     Epoch: 11
2023-01-03 23:49:44,322 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43542087574799854, 'Total loss': 0.43542087574799854} | train loss {'Reaction outcome loss': 0.37356923387324725, 'Total loss': 0.37356923387324725}
2023-01-03 23:49:44,322 INFO:     Found new best model at epoch 11
2023-01-03 23:49:44,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:44,323 INFO:     Epoch: 12
2023-01-03 23:49:45,900 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4433008144299189, 'Total loss': 0.4433008144299189} | train loss {'Reaction outcome loss': 0.3670002075768735, 'Total loss': 0.3670002075768735}
2023-01-03 23:49:45,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:45,901 INFO:     Epoch: 13
2023-01-03 23:49:47,491 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43369640707969664, 'Total loss': 0.43369640707969664} | train loss {'Reaction outcome loss': 0.3590371006977384, 'Total loss': 0.3590371006977384}
2023-01-03 23:49:47,491 INFO:     Found new best model at epoch 13
2023-01-03 23:49:47,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:47,492 INFO:     Epoch: 14
2023-01-03 23:49:49,082 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41862140397230785, 'Total loss': 0.41862140397230785} | train loss {'Reaction outcome loss': 0.352021477926169, 'Total loss': 0.352021477926169}
2023-01-03 23:49:49,082 INFO:     Found new best model at epoch 14
2023-01-03 23:49:49,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:49,083 INFO:     Epoch: 15
2023-01-03 23:49:50,733 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4242494364579519, 'Total loss': 0.4242494364579519} | train loss {'Reaction outcome loss': 0.3492391176358627, 'Total loss': 0.3492391176358627}
2023-01-03 23:49:50,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:50,734 INFO:     Epoch: 16
2023-01-03 23:49:52,393 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4314660410086314, 'Total loss': 0.4314660410086314} | train loss {'Reaction outcome loss': 0.34086323997182566, 'Total loss': 0.34086323997182566}
2023-01-03 23:49:52,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:52,393 INFO:     Epoch: 17
2023-01-03 23:49:54,034 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45843354761600497, 'Total loss': 0.45843354761600497} | train loss {'Reaction outcome loss': 0.3362857959620709, 'Total loss': 0.3362857959620709}
2023-01-03 23:49:54,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:54,035 INFO:     Epoch: 18
2023-01-03 23:49:55,687 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41895689964294436, 'Total loss': 0.41895689964294436} | train loss {'Reaction outcome loss': 0.32783833205917456, 'Total loss': 0.32783833205917456}
2023-01-03 23:49:55,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:55,687 INFO:     Epoch: 19
2023-01-03 23:49:57,336 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44482364455858864, 'Total loss': 0.44482364455858864} | train loss {'Reaction outcome loss': 0.3237578505038345, 'Total loss': 0.3237578505038345}
2023-01-03 23:49:57,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:57,336 INFO:     Epoch: 20
2023-01-03 23:49:58,960 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42240092853705086, 'Total loss': 0.42240092853705086} | train loss {'Reaction outcome loss': 0.321706360192412, 'Total loss': 0.321706360192412}
2023-01-03 23:49:58,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:49:58,960 INFO:     Epoch: 21
2023-01-03 23:50:00,588 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4292786161104838, 'Total loss': 0.4292786161104838} | train loss {'Reaction outcome loss': 0.3150960288153295, 'Total loss': 0.3150960288153295}
2023-01-03 23:50:00,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:00,589 INFO:     Epoch: 22
2023-01-03 23:50:02,219 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40403597205877306, 'Total loss': 0.40403597205877306} | train loss {'Reaction outcome loss': 0.3083079767814518, 'Total loss': 0.3083079767814518}
2023-01-03 23:50:02,220 INFO:     Found new best model at epoch 22
2023-01-03 23:50:02,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:02,220 INFO:     Epoch: 23
2023-01-03 23:50:03,844 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4226205329100291, 'Total loss': 0.4226205329100291} | train loss {'Reaction outcome loss': 0.3059564599916883, 'Total loss': 0.3059564599916883}
2023-01-03 23:50:03,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:03,844 INFO:     Epoch: 24
2023-01-03 23:50:05,498 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40643451710542045, 'Total loss': 0.40643451710542045} | train loss {'Reaction outcome loss': 0.30089360514968416, 'Total loss': 0.30089360514968416}
2023-01-03 23:50:05,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:05,499 INFO:     Epoch: 25
2023-01-03 23:50:07,113 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4163997371991475, 'Total loss': 0.4163997371991475} | train loss {'Reaction outcome loss': 0.2970723495920644, 'Total loss': 0.2970723495920644}
2023-01-03 23:50:07,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:07,113 INFO:     Epoch: 26
2023-01-03 23:50:08,734 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4215875198443731, 'Total loss': 0.4215875198443731} | train loss {'Reaction outcome loss': 0.2910505535801614, 'Total loss': 0.2910505535801614}
2023-01-03 23:50:08,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:08,736 INFO:     Epoch: 27
2023-01-03 23:50:10,374 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4361268997192383, 'Total loss': 0.4361268997192383} | train loss {'Reaction outcome loss': 0.28879423681510624, 'Total loss': 0.28879423681510624}
2023-01-03 23:50:10,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:10,374 INFO:     Epoch: 28
2023-01-03 23:50:12,003 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42410454948743187, 'Total loss': 0.42410454948743187} | train loss {'Reaction outcome loss': 0.2836491945505577, 'Total loss': 0.2836491945505577}
2023-01-03 23:50:12,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:12,003 INFO:     Epoch: 29
2023-01-03 23:50:13,661 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41620554625988004, 'Total loss': 0.41620554625988004} | train loss {'Reaction outcome loss': 0.2802366102862097, 'Total loss': 0.2802366102862097}
2023-01-03 23:50:13,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:13,661 INFO:     Epoch: 30
2023-01-03 23:50:15,296 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4105108479658763, 'Total loss': 0.4105108479658763} | train loss {'Reaction outcome loss': 0.2777776745467508, 'Total loss': 0.2777776745467508}
2023-01-03 23:50:15,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:15,297 INFO:     Epoch: 31
2023-01-03 23:50:16,913 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4051328092813492, 'Total loss': 0.4051328092813492} | train loss {'Reaction outcome loss': 0.2736322641862135, 'Total loss': 0.2736322641862135}
2023-01-03 23:50:16,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:16,913 INFO:     Epoch: 32
2023-01-03 23:50:18,538 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4067338844140371, 'Total loss': 0.4067338844140371} | train loss {'Reaction outcome loss': 0.27052902199164797, 'Total loss': 0.27052902199164797}
2023-01-03 23:50:18,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:18,538 INFO:     Epoch: 33
2023-01-03 23:50:20,182 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4269734521706899, 'Total loss': 0.4269734521706899} | train loss {'Reaction outcome loss': 0.2687507220102053, 'Total loss': 0.2687507220102053}
2023-01-03 23:50:20,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:20,183 INFO:     Epoch: 34
2023-01-03 23:50:21,758 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4084749122460683, 'Total loss': 0.4084749122460683} | train loss {'Reaction outcome loss': 0.2642262175842358, 'Total loss': 0.2642262175842358}
2023-01-03 23:50:21,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:21,758 INFO:     Epoch: 35
2023-01-03 23:50:23,343 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3968591103951136, 'Total loss': 0.3968591103951136} | train loss {'Reaction outcome loss': 0.2600272414512443, 'Total loss': 0.2600272414512443}
2023-01-03 23:50:23,343 INFO:     Found new best model at epoch 35
2023-01-03 23:50:23,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:23,344 INFO:     Epoch: 36
2023-01-03 23:50:24,914 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4273895929257075, 'Total loss': 0.4273895929257075} | train loss {'Reaction outcome loss': 0.2574252074543577, 'Total loss': 0.2574252074543577}
2023-01-03 23:50:24,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:24,915 INFO:     Epoch: 37
2023-01-03 23:50:26,494 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40719849268595376, 'Total loss': 0.40719849268595376} | train loss {'Reaction outcome loss': 0.2527486331298621, 'Total loss': 0.2527486331298621}
2023-01-03 23:50:26,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:26,494 INFO:     Epoch: 38
2023-01-03 23:50:28,071 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40291426380475365, 'Total loss': 0.40291426380475365} | train loss {'Reaction outcome loss': 0.25233108082609457, 'Total loss': 0.25233108082609457}
2023-01-03 23:50:28,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:28,072 INFO:     Epoch: 39
2023-01-03 23:50:29,673 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39344630440076195, 'Total loss': 0.39344630440076195} | train loss {'Reaction outcome loss': 0.24977374174734102, 'Total loss': 0.24977374174734102}
2023-01-03 23:50:29,673 INFO:     Found new best model at epoch 39
2023-01-03 23:50:29,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:29,674 INFO:     Epoch: 40
2023-01-03 23:50:31,247 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43726551135381064, 'Total loss': 0.43726551135381064} | train loss {'Reaction outcome loss': 0.2481614174797152, 'Total loss': 0.2481614174797152}
2023-01-03 23:50:31,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:31,247 INFO:     Epoch: 41
2023-01-03 23:50:32,828 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40386517842610675, 'Total loss': 0.40386517842610675} | train loss {'Reaction outcome loss': 0.2442896919066671, 'Total loss': 0.2442896919066671}
2023-01-03 23:50:32,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:32,828 INFO:     Epoch: 42
2023-01-03 23:50:34,400 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41484148502349855, 'Total loss': 0.41484148502349855} | train loss {'Reaction outcome loss': 0.24017512064128027, 'Total loss': 0.24017512064128027}
2023-01-03 23:50:34,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:34,401 INFO:     Epoch: 43
2023-01-03 23:50:35,983 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4178931603829066, 'Total loss': 0.4178931603829066} | train loss {'Reaction outcome loss': 0.2385166368725961, 'Total loss': 0.2385166368725961}
2023-01-03 23:50:35,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:35,983 INFO:     Epoch: 44
2023-01-03 23:50:37,567 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3920892318089803, 'Total loss': 0.3920892318089803} | train loss {'Reaction outcome loss': 0.2372838208166352, 'Total loss': 0.2372838208166352}
2023-01-03 23:50:37,567 INFO:     Found new best model at epoch 44
2023-01-03 23:50:37,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:37,568 INFO:     Epoch: 45
2023-01-03 23:50:39,156 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42374656796455384, 'Total loss': 0.42374656796455384} | train loss {'Reaction outcome loss': 0.23459811187791127, 'Total loss': 0.23459811187791127}
2023-01-03 23:50:39,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:39,156 INFO:     Epoch: 46
2023-01-03 23:50:40,820 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4097320348024368, 'Total loss': 0.4097320348024368} | train loss {'Reaction outcome loss': 0.23260299676526203, 'Total loss': 0.23260299676526203}
2023-01-03 23:50:40,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:40,820 INFO:     Epoch: 47
2023-01-03 23:50:42,417 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4171497642993927, 'Total loss': 0.4171497642993927} | train loss {'Reaction outcome loss': 0.23279401733383645, 'Total loss': 0.23279401733383645}
2023-01-03 23:50:42,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:42,417 INFO:     Epoch: 48
2023-01-03 23:50:44,041 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44355175495147703, 'Total loss': 0.44355175495147703} | train loss {'Reaction outcome loss': 0.2288101381574669, 'Total loss': 0.2288101381574669}
2023-01-03 23:50:44,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:44,041 INFO:     Epoch: 49
2023-01-03 23:50:45,654 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40618114670117694, 'Total loss': 0.40618114670117694} | train loss {'Reaction outcome loss': 0.22426953119137427, 'Total loss': 0.22426953119137427}
2023-01-03 23:50:45,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:45,656 INFO:     Epoch: 50
2023-01-03 23:50:47,318 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4242487410704295, 'Total loss': 0.4242487410704295} | train loss {'Reaction outcome loss': 0.22158024717040742, 'Total loss': 0.22158024717040742}
2023-01-03 23:50:47,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:47,318 INFO:     Epoch: 51
2023-01-03 23:50:48,940 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43813101251920067, 'Total loss': 0.43813101251920067} | train loss {'Reaction outcome loss': 0.22114084503293907, 'Total loss': 0.22114084503293907}
2023-01-03 23:50:48,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:48,940 INFO:     Epoch: 52
2023-01-03 23:50:50,600 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4182552715142568, 'Total loss': 0.4182552715142568} | train loss {'Reaction outcome loss': 0.22023575052782132, 'Total loss': 0.22023575052782132}
2023-01-03 23:50:50,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:50,600 INFO:     Epoch: 53
2023-01-03 23:50:52,195 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41251262625058494, 'Total loss': 0.41251262625058494} | train loss {'Reaction outcome loss': 0.21781737108572122, 'Total loss': 0.21781737108572122}
2023-01-03 23:50:52,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:52,196 INFO:     Epoch: 54
2023-01-03 23:50:53,806 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41862347920735676, 'Total loss': 0.41862347920735676} | train loss {'Reaction outcome loss': 0.215604973018822, 'Total loss': 0.215604973018822}
2023-01-03 23:50:53,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:53,806 INFO:     Epoch: 55
2023-01-03 23:50:55,465 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42982740302880607, 'Total loss': 0.42982740302880607} | train loss {'Reaction outcome loss': 0.2126540774275569, 'Total loss': 0.2126540774275569}
2023-01-03 23:50:55,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:55,465 INFO:     Epoch: 56
2023-01-03 23:50:57,066 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4165016124645869, 'Total loss': 0.4165016124645869} | train loss {'Reaction outcome loss': 0.21368559361537443, 'Total loss': 0.21368559361537443}
2023-01-03 23:50:57,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:57,066 INFO:     Epoch: 57
2023-01-03 23:50:58,675 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43907448252042136, 'Total loss': 0.43907448252042136} | train loss {'Reaction outcome loss': 0.21438444282070998, 'Total loss': 0.21438444282070998}
2023-01-03 23:50:58,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:50:58,676 INFO:     Epoch: 58
2023-01-03 23:51:00,333 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42343990604082743, 'Total loss': 0.42343990604082743} | train loss {'Reaction outcome loss': 0.20930893383376356, 'Total loss': 0.20930893383376356}
2023-01-03 23:51:00,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:00,333 INFO:     Epoch: 59
2023-01-03 23:51:01,920 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40053341289361316, 'Total loss': 0.40053341289361316} | train loss {'Reaction outcome loss': 0.20621154609605344, 'Total loss': 0.20621154609605344}
2023-01-03 23:51:01,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:01,921 INFO:     Epoch: 60
2023-01-03 23:51:03,528 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4224631816148758, 'Total loss': 0.4224631816148758} | train loss {'Reaction outcome loss': 0.20548874910676132, 'Total loss': 0.20548874910676132}
2023-01-03 23:51:03,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:03,528 INFO:     Epoch: 61
2023-01-03 23:51:05,169 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4244093398253123, 'Total loss': 0.4244093398253123} | train loss {'Reaction outcome loss': 0.204905577507006, 'Total loss': 0.204905577507006}
2023-01-03 23:51:05,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:05,170 INFO:     Epoch: 62
2023-01-03 23:51:06,791 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41566015779972076, 'Total loss': 0.41566015779972076} | train loss {'Reaction outcome loss': 0.20110768866963194, 'Total loss': 0.20110768866963194}
2023-01-03 23:51:06,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:06,792 INFO:     Epoch: 63
2023-01-03 23:51:08,450 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4151823356747627, 'Total loss': 0.4151823356747627} | train loss {'Reaction outcome loss': 0.2003931792004265, 'Total loss': 0.2003931792004265}
2023-01-03 23:51:08,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:08,451 INFO:     Epoch: 64
2023-01-03 23:51:10,065 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4202893078327179, 'Total loss': 0.4202893078327179} | train loss {'Reaction outcome loss': 0.20138350887101714, 'Total loss': 0.20138350887101714}
2023-01-03 23:51:10,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:10,065 INFO:     Epoch: 65
2023-01-03 23:51:11,643 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4326200822989146, 'Total loss': 0.4326200822989146} | train loss {'Reaction outcome loss': 0.19607493480545107, 'Total loss': 0.19607493480545107}
2023-01-03 23:51:11,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:11,643 INFO:     Epoch: 66
2023-01-03 23:51:13,228 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40187161415815353, 'Total loss': 0.40187161415815353} | train loss {'Reaction outcome loss': 0.19643435214584978, 'Total loss': 0.19643435214584978}
2023-01-03 23:51:13,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:13,228 INFO:     Epoch: 67
2023-01-03 23:51:14,839 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44973758459091184, 'Total loss': 0.44973758459091184} | train loss {'Reaction outcome loss': 0.19366513323174775, 'Total loss': 0.19366513323174775}
2023-01-03 23:51:14,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:14,839 INFO:     Epoch: 68
2023-01-03 23:51:16,420 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44426721235116323, 'Total loss': 0.44426721235116323} | train loss {'Reaction outcome loss': 0.19502286720395523, 'Total loss': 0.19502286720395523}
2023-01-03 23:51:16,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:16,420 INFO:     Epoch: 69
2023-01-03 23:51:18,001 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4441277841726939, 'Total loss': 0.4441277841726939} | train loss {'Reaction outcome loss': 0.19413678356221992, 'Total loss': 0.19413678356221992}
2023-01-03 23:51:18,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:18,001 INFO:     Epoch: 70
2023-01-03 23:51:19,561 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41275369624296826, 'Total loss': 0.41275369624296826} | train loss {'Reaction outcome loss': 0.19111968209137664, 'Total loss': 0.19111968209137664}
2023-01-03 23:51:19,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:19,561 INFO:     Epoch: 71
2023-01-03 23:51:21,173 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44255267481009164, 'Total loss': 0.44255267481009164} | train loss {'Reaction outcome loss': 0.19341874675294995, 'Total loss': 0.19341874675294995}
2023-01-03 23:51:21,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:21,174 INFO:     Epoch: 72
2023-01-03 23:51:22,782 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42585983375708264, 'Total loss': 0.42585983375708264} | train loss {'Reaction outcome loss': 0.19025368629580866, 'Total loss': 0.19025368629580866}
2023-01-03 23:51:22,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:22,783 INFO:     Epoch: 73
2023-01-03 23:51:24,373 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4282025992870331, 'Total loss': 0.4282025992870331} | train loss {'Reaction outcome loss': 0.18815308752177407, 'Total loss': 0.18815308752177407}
2023-01-03 23:51:24,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:24,373 INFO:     Epoch: 74
2023-01-03 23:51:25,961 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4401743988196055, 'Total loss': 0.4401743988196055} | train loss {'Reaction outcome loss': 0.18605237255675078, 'Total loss': 0.18605237255675078}
2023-01-03 23:51:25,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:25,961 INFO:     Epoch: 75
2023-01-03 23:51:27,571 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4373869796593984, 'Total loss': 0.4373869796593984} | train loss {'Reaction outcome loss': 0.18587122170295375, 'Total loss': 0.18587122170295375}
2023-01-03 23:51:27,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:27,572 INFO:     Epoch: 76
2023-01-03 23:51:29,132 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42238427450259525, 'Total loss': 0.42238427450259525} | train loss {'Reaction outcome loss': 0.18531124923296655, 'Total loss': 0.18531124923296655}
2023-01-03 23:51:29,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:29,133 INFO:     Epoch: 77
2023-01-03 23:51:30,733 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44114359666903813, 'Total loss': 0.44114359666903813} | train loss {'Reaction outcome loss': 0.18216286546611873, 'Total loss': 0.18216286546611873}
2023-01-03 23:51:30,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:30,733 INFO:     Epoch: 78
2023-01-03 23:51:32,346 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41320623805125556, 'Total loss': 0.41320623805125556} | train loss {'Reaction outcome loss': 0.18075459247903666, 'Total loss': 0.18075459247903666}
2023-01-03 23:51:32,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:32,346 INFO:     Epoch: 79
2023-01-03 23:51:33,933 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42777694861094157, 'Total loss': 0.42777694861094157} | train loss {'Reaction outcome loss': 0.18395476785563206, 'Total loss': 0.18395476785563206}
2023-01-03 23:51:33,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:33,934 INFO:     Epoch: 80
2023-01-03 23:51:35,548 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4437062213818232, 'Total loss': 0.4437062213818232} | train loss {'Reaction outcome loss': 0.18006870033640932, 'Total loss': 0.18006870033640932}
2023-01-03 23:51:35,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:35,548 INFO:     Epoch: 81
2023-01-03 23:51:37,130 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43349904417991636, 'Total loss': 0.43349904417991636} | train loss {'Reaction outcome loss': 0.17842488402813456, 'Total loss': 0.17842488402813456}
2023-01-03 23:51:37,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:37,130 INFO:     Epoch: 82
2023-01-03 23:51:38,708 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4309109310309092, 'Total loss': 0.4309109310309092} | train loss {'Reaction outcome loss': 0.18092799561274966, 'Total loss': 0.18092799561274966}
2023-01-03 23:51:38,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:38,708 INFO:     Epoch: 83
2023-01-03 23:51:40,321 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45219065646330514, 'Total loss': 0.45219065646330514} | train loss {'Reaction outcome loss': 0.17580529995752078, 'Total loss': 0.17580529995752078}
2023-01-03 23:51:40,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:40,322 INFO:     Epoch: 84
2023-01-03 23:51:41,902 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4441636443138123, 'Total loss': 0.4441636443138123} | train loss {'Reaction outcome loss': 0.17730306821066316, 'Total loss': 0.17730306821066316}
2023-01-03 23:51:41,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:41,902 INFO:     Epoch: 85
2023-01-03 23:51:43,503 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4577495902776718, 'Total loss': 0.4577495902776718} | train loss {'Reaction outcome loss': 0.17644507064055787, 'Total loss': 0.17644507064055787}
2023-01-03 23:51:43,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:43,503 INFO:     Epoch: 86
2023-01-03 23:51:45,073 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44534906148910525, 'Total loss': 0.44534906148910525} | train loss {'Reaction outcome loss': 0.1752904124326841, 'Total loss': 0.1752904124326841}
2023-01-03 23:51:45,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:45,074 INFO:     Epoch: 87
2023-01-03 23:51:46,658 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.441726982096831, 'Total loss': 0.441726982096831} | train loss {'Reaction outcome loss': 0.17301886228599797, 'Total loss': 0.17301886228599797}
2023-01-03 23:51:46,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:46,658 INFO:     Epoch: 88
2023-01-03 23:51:48,245 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4560166398684184, 'Total loss': 0.4560166398684184} | train loss {'Reaction outcome loss': 0.17246446515820976, 'Total loss': 0.17246446515820976}
2023-01-03 23:51:48,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:48,245 INFO:     Epoch: 89
2023-01-03 23:51:49,846 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42082207798957827, 'Total loss': 0.42082207798957827} | train loss {'Reaction outcome loss': 0.17299141185562106, 'Total loss': 0.17299141185562106}
2023-01-03 23:51:49,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:49,846 INFO:     Epoch: 90
2023-01-03 23:51:51,445 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4386028458674749, 'Total loss': 0.4386028458674749} | train loss {'Reaction outcome loss': 0.1723670323046237, 'Total loss': 0.1723670323046237}
2023-01-03 23:51:51,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:51,447 INFO:     Epoch: 91
2023-01-03 23:51:53,030 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45203707218170164, 'Total loss': 0.45203707218170164} | train loss {'Reaction outcome loss': 0.1707780891893445, 'Total loss': 0.1707780891893445}
2023-01-03 23:51:53,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:53,031 INFO:     Epoch: 92
2023-01-03 23:51:54,623 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41893849869569144, 'Total loss': 0.41893849869569144} | train loss {'Reaction outcome loss': 0.17033976716852753, 'Total loss': 0.17033976716852753}
2023-01-03 23:51:54,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:54,623 INFO:     Epoch: 93
2023-01-03 23:51:56,213 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44031704366207125, 'Total loss': 0.44031704366207125} | train loss {'Reaction outcome loss': 0.17296842126053397, 'Total loss': 0.17296842126053397}
2023-01-03 23:51:56,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:56,214 INFO:     Epoch: 94
2023-01-03 23:51:57,818 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4352221091588338, 'Total loss': 0.4352221091588338} | train loss {'Reaction outcome loss': 0.17262085013254716, 'Total loss': 0.17262085013254716}
2023-01-03 23:51:57,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:57,818 INFO:     Epoch: 95
2023-01-03 23:51:59,417 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41004691024621326, 'Total loss': 0.41004691024621326} | train loss {'Reaction outcome loss': 0.17003356869651998, 'Total loss': 0.17003356869651998}
2023-01-03 23:51:59,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:51:59,418 INFO:     Epoch: 96
2023-01-03 23:52:00,999 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43221644560496014, 'Total loss': 0.43221644560496014} | train loss {'Reaction outcome loss': 0.16667704236605307, 'Total loss': 0.16667704236605307}
2023-01-03 23:52:00,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:00,999 INFO:     Epoch: 97
2023-01-03 23:52:02,598 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4404001901547114, 'Total loss': 0.4404001901547114} | train loss {'Reaction outcome loss': 0.16729492645533958, 'Total loss': 0.16729492645533958}
2023-01-03 23:52:02,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:02,598 INFO:     Epoch: 98
2023-01-03 23:52:04,217 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43763247231642405, 'Total loss': 0.43763247231642405} | train loss {'Reaction outcome loss': 0.16611133778576542, 'Total loss': 0.16611133778576542}
2023-01-03 23:52:04,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:04,218 INFO:     Epoch: 99
2023-01-03 23:52:05,825 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43297817806402844, 'Total loss': 0.43297817806402844} | train loss {'Reaction outcome loss': 0.16565825975071774, 'Total loss': 0.16565825975071774}
2023-01-03 23:52:05,825 INFO:     Best model found after epoch 45 of 100.
2023-01-03 23:52:05,825 INFO:   Done with stage: TRAINING
2023-01-03 23:52:05,825 INFO:   Starting stage: EVALUATION
2023-01-03 23:52:05,962 INFO:   Done with stage: EVALUATION
2023-01-03 23:52:05,962 INFO:   Leaving out SEQ value Fold_1
2023-01-03 23:52:05,975 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-03 23:52:05,975 INFO:   Starting stage: FEATURE SCALING
2023-01-03 23:52:06,627 INFO:   Done with stage: FEATURE SCALING
2023-01-03 23:52:06,627 INFO:   Starting stage: SCALING TARGETS
2023-01-03 23:52:06,697 INFO:   Done with stage: SCALING TARGETS
2023-01-03 23:52:06,697 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:52:06,697 INFO:     No hyperparam tuning for this model
2023-01-03 23:52:06,697 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:52:06,697 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 23:52:06,698 INFO:     None feature selector for col prot
2023-01-03 23:52:06,698 INFO:     None feature selector for col prot
2023-01-03 23:52:06,698 INFO:     None feature selector for col prot
2023-01-03 23:52:06,699 INFO:     None feature selector for col chem
2023-01-03 23:52:06,699 INFO:     None feature selector for col chem
2023-01-03 23:52:06,699 INFO:     None feature selector for col chem
2023-01-03 23:52:06,699 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 23:52:06,699 INFO:   Starting stage: BUILD MODEL
2023-01-03 23:52:06,700 INFO:     Number of params in model 70141
2023-01-03 23:52:06,703 INFO:   Done with stage: BUILD MODEL
2023-01-03 23:52:06,703 INFO:   Starting stage: TRAINING
2023-01-03 23:52:06,746 INFO:     Val loss before train {'Reaction outcome loss': 1.0140069127082825, 'Total loss': 1.0140069127082825}
2023-01-03 23:52:06,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:06,746 INFO:     Epoch: 0
2023-01-03 23:52:08,323 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6663983762264252, 'Total loss': 0.6663983762264252} | train loss {'Reaction outcome loss': 0.8403617303089902, 'Total loss': 0.8403617303089902}
2023-01-03 23:52:08,324 INFO:     Found new best model at epoch 0
2023-01-03 23:52:08,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:08,324 INFO:     Epoch: 1
2023-01-03 23:52:09,916 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5510072767734527, 'Total loss': 0.5510072767734527} | train loss {'Reaction outcome loss': 0.5869056821639248, 'Total loss': 0.5869056821639248}
2023-01-03 23:52:09,917 INFO:     Found new best model at epoch 1
2023-01-03 23:52:09,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:09,918 INFO:     Epoch: 2
2023-01-03 23:52:11,506 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5189075748125712, 'Total loss': 0.5189075748125712} | train loss {'Reaction outcome loss': 0.5110963378995107, 'Total loss': 0.5110963378995107}
2023-01-03 23:52:11,506 INFO:     Found new best model at epoch 2
2023-01-03 23:52:11,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:11,507 INFO:     Epoch: 3
2023-01-03 23:52:13,069 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49909448126951855, 'Total loss': 0.49909448126951855} | train loss {'Reaction outcome loss': 0.47274559279869405, 'Total loss': 0.47274559279869405}
2023-01-03 23:52:13,069 INFO:     Found new best model at epoch 3
2023-01-03 23:52:13,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:13,070 INFO:     Epoch: 4
2023-01-03 23:52:14,649 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48632268110911053, 'Total loss': 0.48632268110911053} | train loss {'Reaction outcome loss': 0.4432400218675057, 'Total loss': 0.4432400218675057}
2023-01-03 23:52:14,649 INFO:     Found new best model at epoch 4
2023-01-03 23:52:14,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:14,650 INFO:     Epoch: 5
2023-01-03 23:52:16,225 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4796803335348765, 'Total loss': 0.4796803335348765} | train loss {'Reaction outcome loss': 0.4241339414761955, 'Total loss': 0.4241339414761955}
2023-01-03 23:52:16,225 INFO:     Found new best model at epoch 5
2023-01-03 23:52:16,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:16,226 INFO:     Epoch: 6
2023-01-03 23:52:17,791 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4941751539707184, 'Total loss': 0.4941751539707184} | train loss {'Reaction outcome loss': 0.4092826687926736, 'Total loss': 0.4092826687926736}
2023-01-03 23:52:17,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:17,791 INFO:     Epoch: 7
2023-01-03 23:52:19,355 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4596501807371775, 'Total loss': 0.4596501807371775} | train loss {'Reaction outcome loss': 0.3942673240970421, 'Total loss': 0.3942673240970421}
2023-01-03 23:52:19,355 INFO:     Found new best model at epoch 7
2023-01-03 23:52:19,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:19,356 INFO:     Epoch: 8
2023-01-03 23:52:20,953 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4757911423842112, 'Total loss': 0.4757911423842112} | train loss {'Reaction outcome loss': 0.38359024812814496, 'Total loss': 0.38359024812814496}
2023-01-03 23:52:20,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:20,953 INFO:     Epoch: 9
2023-01-03 23:52:22,522 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43384519616762796, 'Total loss': 0.43384519616762796} | train loss {'Reaction outcome loss': 0.37523632884245517, 'Total loss': 0.37523632884245517}
2023-01-03 23:52:22,523 INFO:     Found new best model at epoch 9
2023-01-03 23:52:22,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:22,524 INFO:     Epoch: 10
2023-01-03 23:52:24,116 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43001489688952765, 'Total loss': 0.43001489688952765} | train loss {'Reaction outcome loss': 0.36517754735981844, 'Total loss': 0.36517754735981844}
2023-01-03 23:52:24,117 INFO:     Found new best model at epoch 10
2023-01-03 23:52:24,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:24,117 INFO:     Epoch: 11
2023-01-03 23:52:25,723 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48849788506825764, 'Total loss': 0.48849788506825764} | train loss {'Reaction outcome loss': 0.35504475057235063, 'Total loss': 0.35504475057235063}
2023-01-03 23:52:25,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:25,723 INFO:     Epoch: 12
2023-01-03 23:52:27,283 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45413005650043486, 'Total loss': 0.45413005650043486} | train loss {'Reaction outcome loss': 0.34913327267249133, 'Total loss': 0.34913327267249133}
2023-01-03 23:52:27,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:27,283 INFO:     Epoch: 13
2023-01-03 23:52:28,854 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4165008724356691, 'Total loss': 0.4165008724356691} | train loss {'Reaction outcome loss': 0.3402128725474171, 'Total loss': 0.3402128725474171}
2023-01-03 23:52:28,855 INFO:     Found new best model at epoch 13
2023-01-03 23:52:28,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:28,856 INFO:     Epoch: 14
2023-01-03 23:52:30,428 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45800952315330506, 'Total loss': 0.45800952315330506} | train loss {'Reaction outcome loss': 0.3346535437551372, 'Total loss': 0.3346535437551372}
2023-01-03 23:52:30,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:30,428 INFO:     Epoch: 15
2023-01-03 23:52:31,987 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45910740494728086, 'Total loss': 0.45910740494728086} | train loss {'Reaction outcome loss': 0.3258950604448899, 'Total loss': 0.3258950604448899}
2023-01-03 23:52:31,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:31,987 INFO:     Epoch: 16
2023-01-03 23:52:33,561 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4413344273964564, 'Total loss': 0.4413344273964564} | train loss {'Reaction outcome loss': 0.3214950684691707, 'Total loss': 0.3214950684691707}
2023-01-03 23:52:33,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:33,561 INFO:     Epoch: 17
2023-01-03 23:52:35,125 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45272657573223113, 'Total loss': 0.45272657573223113} | train loss {'Reaction outcome loss': 0.314273415071498, 'Total loss': 0.314273415071498}
2023-01-03 23:52:35,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:35,125 INFO:     Epoch: 18
2023-01-03 23:52:36,674 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4672371059656143, 'Total loss': 0.4672371059656143} | train loss {'Reaction outcome loss': 0.30969437126523897, 'Total loss': 0.30969437126523897}
2023-01-03 23:52:36,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:36,674 INFO:     Epoch: 19
2023-01-03 23:52:38,276 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46857868631680805, 'Total loss': 0.46857868631680805} | train loss {'Reaction outcome loss': 0.3052246574986025, 'Total loss': 0.3052246574986025}
2023-01-03 23:52:38,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:38,277 INFO:     Epoch: 20
2023-01-03 23:52:39,847 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4483350147803625, 'Total loss': 0.4483350147803625} | train loss {'Reaction outcome loss': 0.29774543109635143, 'Total loss': 0.29774543109635143}
2023-01-03 23:52:39,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:39,847 INFO:     Epoch: 21
2023-01-03 23:52:41,408 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4540188918511073, 'Total loss': 0.4540188918511073} | train loss {'Reaction outcome loss': 0.29419986909166035, 'Total loss': 0.29419986909166035}
2023-01-03 23:52:41,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:41,409 INFO:     Epoch: 22
2023-01-03 23:52:42,979 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44454894761244457, 'Total loss': 0.44454894761244457} | train loss {'Reaction outcome loss': 0.286768962481365, 'Total loss': 0.286768962481365}
2023-01-03 23:52:42,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:42,980 INFO:     Epoch: 23
2023-01-03 23:52:44,563 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4556684096654256, 'Total loss': 0.4556684096654256} | train loss {'Reaction outcome loss': 0.28323160194382896, 'Total loss': 0.28323160194382896}
2023-01-03 23:52:44,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:44,563 INFO:     Epoch: 24
2023-01-03 23:52:46,125 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4202206591765086, 'Total loss': 0.4202206591765086} | train loss {'Reaction outcome loss': 0.2796507566562438, 'Total loss': 0.2796507566562438}
2023-01-03 23:52:46,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:46,125 INFO:     Epoch: 25
2023-01-03 23:52:47,696 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43390626112620034, 'Total loss': 0.43390626112620034} | train loss {'Reaction outcome loss': 0.27620800383856375, 'Total loss': 0.27620800383856375}
2023-01-03 23:52:47,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:47,697 INFO:     Epoch: 26
2023-01-03 23:52:49,283 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42443726733326914, 'Total loss': 0.42443726733326914} | train loss {'Reaction outcome loss': 0.2726507427727604, 'Total loss': 0.2726507427727604}
2023-01-03 23:52:49,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:49,283 INFO:     Epoch: 27
2023-01-03 23:52:50,858 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4195638964573542, 'Total loss': 0.4195638964573542} | train loss {'Reaction outcome loss': 0.26758254916025703, 'Total loss': 0.26758254916025703}
2023-01-03 23:52:50,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:50,858 INFO:     Epoch: 28
2023-01-03 23:52:52,478 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42274264295895897, 'Total loss': 0.42274264295895897} | train loss {'Reaction outcome loss': 0.2650286762861748, 'Total loss': 0.2650286762861748}
2023-01-03 23:52:52,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:52,480 INFO:     Epoch: 29
2023-01-03 23:52:54,087 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4413835177818934, 'Total loss': 0.4413835177818934} | train loss {'Reaction outcome loss': 0.2622710981327229, 'Total loss': 0.2622710981327229}
2023-01-03 23:52:54,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:54,087 INFO:     Epoch: 30
2023-01-03 23:52:55,726 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4400671904285749, 'Total loss': 0.4400671904285749} | train loss {'Reaction outcome loss': 0.2583365176986504, 'Total loss': 0.2583365176986504}
2023-01-03 23:52:55,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:55,726 INFO:     Epoch: 31
2023-01-03 23:52:57,394 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47419337431589764, 'Total loss': 0.47419337431589764} | train loss {'Reaction outcome loss': 0.2563078400586144, 'Total loss': 0.2563078400586144}
2023-01-03 23:52:57,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:57,394 INFO:     Epoch: 32
2023-01-03 23:52:59,033 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45254198312759397, 'Total loss': 0.45254198312759397} | train loss {'Reaction outcome loss': 0.25246330141691264, 'Total loss': 0.25246330141691264}
2023-01-03 23:52:59,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:52:59,034 INFO:     Epoch: 33
2023-01-03 23:53:00,679 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4347161402304967, 'Total loss': 0.4347161402304967} | train loss {'Reaction outcome loss': 0.24925585618978058, 'Total loss': 0.24925585618978058}
2023-01-03 23:53:00,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:00,679 INFO:     Epoch: 34
2023-01-03 23:53:02,321 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4392040391763051, 'Total loss': 0.4392040391763051} | train loss {'Reaction outcome loss': 0.24697927633004874, 'Total loss': 0.24697927633004874}
2023-01-03 23:53:02,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:02,321 INFO:     Epoch: 35
2023-01-03 23:53:03,940 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4456307391325633, 'Total loss': 0.4456307391325633} | train loss {'Reaction outcome loss': 0.24390719545063497, 'Total loss': 0.24390719545063497}
2023-01-03 23:53:03,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:03,940 INFO:     Epoch: 36
2023-01-03 23:53:05,583 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44991364975770315, 'Total loss': 0.44991364975770315} | train loss {'Reaction outcome loss': 0.24264848768381175, 'Total loss': 0.24264848768381175}
2023-01-03 23:53:05,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:05,583 INFO:     Epoch: 37
2023-01-03 23:53:07,229 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4412690157691638, 'Total loss': 0.4412690157691638} | train loss {'Reaction outcome loss': 0.23892411424664994, 'Total loss': 0.23892411424664994}
2023-01-03 23:53:07,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:07,230 INFO:     Epoch: 38
2023-01-03 23:53:08,796 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.457433674732844, 'Total loss': 0.457433674732844} | train loss {'Reaction outcome loss': 0.23629238180183837, 'Total loss': 0.23629238180183837}
2023-01-03 23:53:08,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:08,796 INFO:     Epoch: 39
2023-01-03 23:53:10,368 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4535172050197919, 'Total loss': 0.4535172050197919} | train loss {'Reaction outcome loss': 0.2343648139566073, 'Total loss': 0.2343648139566073}
2023-01-03 23:53:10,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:10,368 INFO:     Epoch: 40
2023-01-03 23:53:11,941 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44960499107837676, 'Total loss': 0.44960499107837676} | train loss {'Reaction outcome loss': 0.23136715173061484, 'Total loss': 0.23136715173061484}
2023-01-03 23:53:11,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:11,942 INFO:     Epoch: 41
2023-01-03 23:53:13,498 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4675779898961385, 'Total loss': 0.4675779898961385} | train loss {'Reaction outcome loss': 0.230992052979025, 'Total loss': 0.230992052979025}
2023-01-03 23:53:13,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:13,498 INFO:     Epoch: 42
2023-01-03 23:53:15,069 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43664718518654505, 'Total loss': 0.43664718518654505} | train loss {'Reaction outcome loss': 0.22845104635724062, 'Total loss': 0.22845104635724062}
2023-01-03 23:53:15,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:15,069 INFO:     Epoch: 43
2023-01-03 23:53:16,624 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41735169577101866, 'Total loss': 0.41735169577101866} | train loss {'Reaction outcome loss': 0.22706476066990092, 'Total loss': 0.22706476066990092}
2023-01-03 23:53:16,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:16,625 INFO:     Epoch: 44
2023-01-03 23:53:18,214 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45253945191701256, 'Total loss': 0.45253945191701256} | train loss {'Reaction outcome loss': 0.22418587631460046, 'Total loss': 0.22418587631460046}
2023-01-03 23:53:18,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:18,214 INFO:     Epoch: 45
2023-01-03 23:53:19,813 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4281531671682994, 'Total loss': 0.4281531671682994} | train loss {'Reaction outcome loss': 0.2206447964939684, 'Total loss': 0.2206447964939684}
2023-01-03 23:53:19,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:19,813 INFO:     Epoch: 46
2023-01-03 23:53:21,381 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4249344271918138, 'Total loss': 0.4249344271918138} | train loss {'Reaction outcome loss': 0.22112923613113672, 'Total loss': 0.22112923613113672}
2023-01-03 23:53:21,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:21,381 INFO:     Epoch: 47
2023-01-03 23:53:22,941 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45635966062545774, 'Total loss': 0.45635966062545774} | train loss {'Reaction outcome loss': 0.2190236556326551, 'Total loss': 0.2190236556326551}
2023-01-03 23:53:22,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:22,941 INFO:     Epoch: 48
2023-01-03 23:53:24,514 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45246355682611467, 'Total loss': 0.45246355682611467} | train loss {'Reaction outcome loss': 0.21609397563822155, 'Total loss': 0.21609397563822155}
2023-01-03 23:53:24,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:24,515 INFO:     Epoch: 49
2023-01-03 23:53:26,072 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46840497354666394, 'Total loss': 0.46840497354666394} | train loss {'Reaction outcome loss': 0.21583159003970367, 'Total loss': 0.21583159003970367}
2023-01-03 23:53:26,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:26,072 INFO:     Epoch: 50
2023-01-03 23:53:27,668 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4242294326424599, 'Total loss': 0.4242294326424599} | train loss {'Reaction outcome loss': 0.21327394448440673, 'Total loss': 0.21327394448440673}
2023-01-03 23:53:27,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:27,669 INFO:     Epoch: 51
2023-01-03 23:53:29,262 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4469430377086004, 'Total loss': 0.4469430377086004} | train loss {'Reaction outcome loss': 0.21259830136030802, 'Total loss': 0.21259830136030802}
2023-01-03 23:53:29,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:29,264 INFO:     Epoch: 52
2023-01-03 23:53:30,842 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.426549381390214, 'Total loss': 0.426549381390214} | train loss {'Reaction outcome loss': 0.20953761160071266, 'Total loss': 0.20953761160071266}
2023-01-03 23:53:30,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:30,843 INFO:     Epoch: 53
2023-01-03 23:53:32,433 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46077560981114707, 'Total loss': 0.46077560981114707} | train loss {'Reaction outcome loss': 0.21087155925501758, 'Total loss': 0.21087155925501758}
2023-01-03 23:53:32,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:32,434 INFO:     Epoch: 54
2023-01-03 23:53:34,031 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4558852046728134, 'Total loss': 0.4558852046728134} | train loss {'Reaction outcome loss': 0.20884977242603514, 'Total loss': 0.20884977242603514}
2023-01-03 23:53:34,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:34,031 INFO:     Epoch: 55
2023-01-03 23:53:35,574 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4361128926277161, 'Total loss': 0.4361128926277161} | train loss {'Reaction outcome loss': 0.2061294351336701, 'Total loss': 0.2061294351336701}
2023-01-03 23:53:35,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:35,575 INFO:     Epoch: 56
2023-01-03 23:53:37,134 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46911032994588214, 'Total loss': 0.46911032994588214} | train loss {'Reaction outcome loss': 0.2037264224677948, 'Total loss': 0.2037264224677948}
2023-01-03 23:53:37,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:37,134 INFO:     Epoch: 57
2023-01-03 23:53:38,697 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4298775186141332, 'Total loss': 0.4298775186141332} | train loss {'Reaction outcome loss': 0.20427840061458274, 'Total loss': 0.20427840061458274}
2023-01-03 23:53:38,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:38,698 INFO:     Epoch: 58
2023-01-03 23:53:40,247 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.432427878677845, 'Total loss': 0.432427878677845} | train loss {'Reaction outcome loss': 0.19956353163807156, 'Total loss': 0.19956353163807156}
2023-01-03 23:53:40,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:40,247 INFO:     Epoch: 59
2023-01-03 23:53:41,841 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4638127009073893, 'Total loss': 0.4638127009073893} | train loss {'Reaction outcome loss': 0.20172063886734393, 'Total loss': 0.20172063886734393}
2023-01-03 23:53:41,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:41,842 INFO:     Epoch: 60
2023-01-03 23:53:43,430 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47054611444473265, 'Total loss': 0.47054611444473265} | train loss {'Reaction outcome loss': 0.19848073827879456, 'Total loss': 0.19848073827879456}
2023-01-03 23:53:43,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:43,430 INFO:     Epoch: 61
2023-01-03 23:53:45,003 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4525664210319519, 'Total loss': 0.4525664210319519} | train loss {'Reaction outcome loss': 0.1983732442711772, 'Total loss': 0.1983732442711772}
2023-01-03 23:53:45,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:45,004 INFO:     Epoch: 62
2023-01-03 23:53:46,565 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.439357786377271, 'Total loss': 0.439357786377271} | train loss {'Reaction outcome loss': 0.19595863835755528, 'Total loss': 0.19595863835755528}
2023-01-03 23:53:46,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:46,565 INFO:     Epoch: 63
2023-01-03 23:53:48,162 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4667757570743561, 'Total loss': 0.4667757570743561} | train loss {'Reaction outcome loss': 0.19431758775097419, 'Total loss': 0.19431758775097419}
2023-01-03 23:53:48,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:48,163 INFO:     Epoch: 64
2023-01-03 23:53:49,736 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44234733978907265, 'Total loss': 0.44234733978907265} | train loss {'Reaction outcome loss': 0.19504007303269366, 'Total loss': 0.19504007303269366}
2023-01-03 23:53:49,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:49,736 INFO:     Epoch: 65
2023-01-03 23:53:51,310 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4942271500825882, 'Total loss': 0.4942271500825882} | train loss {'Reaction outcome loss': 0.19374039622085562, 'Total loss': 0.19374039622085562}
2023-01-03 23:53:51,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:51,311 INFO:     Epoch: 66
2023-01-03 23:53:52,870 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44649293820063274, 'Total loss': 0.44649293820063274} | train loss {'Reaction outcome loss': 0.19141288903091666, 'Total loss': 0.19141288903091666}
2023-01-03 23:53:52,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:52,870 INFO:     Epoch: 67
2023-01-03 23:53:54,467 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45172956387201946, 'Total loss': 0.45172956387201946} | train loss {'Reaction outcome loss': 0.19190009068903888, 'Total loss': 0.19190009068903888}
2023-01-03 23:53:54,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:54,467 INFO:     Epoch: 68
2023-01-03 23:53:56,063 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4640256593624751, 'Total loss': 0.4640256593624751} | train loss {'Reaction outcome loss': 0.189250776564833, 'Total loss': 0.189250776564833}
2023-01-03 23:53:56,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:56,064 INFO:     Epoch: 69
2023-01-03 23:53:57,645 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4216648757457733, 'Total loss': 0.4216648757457733} | train loss {'Reaction outcome loss': 0.18987760488699942, 'Total loss': 0.18987760488699942}
2023-01-03 23:53:57,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:57,645 INFO:     Epoch: 70
2023-01-03 23:53:59,248 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45220740834871925, 'Total loss': 0.45220740834871925} | train loss {'Reaction outcome loss': 0.1869857535865914, 'Total loss': 0.1869857535865914}
2023-01-03 23:53:59,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:53:59,248 INFO:     Epoch: 71
2023-01-03 23:54:00,851 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4339222843448321, 'Total loss': 0.4339222843448321} | train loss {'Reaction outcome loss': 0.1870709212146342, 'Total loss': 0.1870709212146342}
2023-01-03 23:54:00,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:00,852 INFO:     Epoch: 72
2023-01-03 23:54:02,406 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4354389141003291, 'Total loss': 0.4354389141003291} | train loss {'Reaction outcome loss': 0.184101125562213, 'Total loss': 0.184101125562213}
2023-01-03 23:54:02,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:02,406 INFO:     Epoch: 73
2023-01-03 23:54:03,972 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4460338036219279, 'Total loss': 0.4460338036219279} | train loss {'Reaction outcome loss': 0.18362106561550795, 'Total loss': 0.18362106561550795}
2023-01-03 23:54:03,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:03,972 INFO:     Epoch: 74
2023-01-03 23:54:05,534 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46403683423995973, 'Total loss': 0.46403683423995973} | train loss {'Reaction outcome loss': 0.18365195848570098, 'Total loss': 0.18365195848570098}
2023-01-03 23:54:05,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:05,535 INFO:     Epoch: 75
2023-01-03 23:54:07,081 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45834194819132484, 'Total loss': 0.45834194819132484} | train loss {'Reaction outcome loss': 0.18586874335344428, 'Total loss': 0.18586874335344428}
2023-01-03 23:54:07,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:07,082 INFO:     Epoch: 76
2023-01-03 23:54:08,646 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44588581919670106, 'Total loss': 0.44588581919670106} | train loss {'Reaction outcome loss': 0.18144710171569098, 'Total loss': 0.18144710171569098}
2023-01-03 23:54:08,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:08,646 INFO:     Epoch: 77
2023-01-03 23:54:10,210 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4384316942344109, 'Total loss': 0.4384316942344109} | train loss {'Reaction outcome loss': 0.1816701420627507, 'Total loss': 0.1816701420627507}
2023-01-03 23:54:10,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:10,210 INFO:     Epoch: 78
2023-01-03 23:54:11,791 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4420332709948222, 'Total loss': 0.4420332709948222} | train loss {'Reaction outcome loss': 0.18004279209788876, 'Total loss': 0.18004279209788876}
2023-01-03 23:54:11,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:11,791 INFO:     Epoch: 79
2023-01-03 23:54:13,367 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45023732880751294, 'Total loss': 0.45023732880751294} | train loss {'Reaction outcome loss': 0.17872433117642395, 'Total loss': 0.17872433117642395}
2023-01-03 23:54:13,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:13,367 INFO:     Epoch: 80
2023-01-03 23:54:14,921 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4796716034412384, 'Total loss': 0.4796716034412384} | train loss {'Reaction outcome loss': 0.18069624827274317, 'Total loss': 0.18069624827274317}
2023-01-03 23:54:14,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:14,921 INFO:     Epoch: 81
2023-01-03 23:54:16,495 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4520493964354197, 'Total loss': 0.4520493964354197} | train loss {'Reaction outcome loss': 0.17655289857699863, 'Total loss': 0.17655289857699863}
2023-01-03 23:54:16,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:16,495 INFO:     Epoch: 82
2023-01-03 23:54:18,093 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4542441636323929, 'Total loss': 0.4542441636323929} | train loss {'Reaction outcome loss': 0.17543851991091267, 'Total loss': 0.17543851991091267}
2023-01-03 23:54:18,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:18,093 INFO:     Epoch: 83
2023-01-03 23:54:19,667 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4437172830104828, 'Total loss': 0.4437172830104828} | train loss {'Reaction outcome loss': 0.1785440297103126, 'Total loss': 0.1785440297103126}
2023-01-03 23:54:19,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:19,668 INFO:     Epoch: 84
2023-01-03 23:54:21,256 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48340023358662926, 'Total loss': 0.48340023358662926} | train loss {'Reaction outcome loss': 0.17388748430485435, 'Total loss': 0.17388748430485435}
2023-01-03 23:54:21,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:21,256 INFO:     Epoch: 85
2023-01-03 23:54:22,842 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47866991261641184, 'Total loss': 0.47866991261641184} | train loss {'Reaction outcome loss': 0.17585990557316483, 'Total loss': 0.17585990557316483}
2023-01-03 23:54:22,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:22,842 INFO:     Epoch: 86
2023-01-03 23:54:24,421 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45518600245316826, 'Total loss': 0.45518600245316826} | train loss {'Reaction outcome loss': 0.17399752891976455, 'Total loss': 0.17399752891976455}
2023-01-03 23:54:24,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:24,421 INFO:     Epoch: 87
2023-01-03 23:54:26,015 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4610204656918844, 'Total loss': 0.4610204656918844} | train loss {'Reaction outcome loss': 0.1734861105721705, 'Total loss': 0.1734861105721705}
2023-01-03 23:54:26,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:26,016 INFO:     Epoch: 88
2023-01-03 23:54:27,616 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4462910046180089, 'Total loss': 0.4462910046180089} | train loss {'Reaction outcome loss': 0.17302741020972878, 'Total loss': 0.17302741020972878}
2023-01-03 23:54:27,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:27,616 INFO:     Epoch: 89
2023-01-03 23:54:29,196 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44933824936548866, 'Total loss': 0.44933824936548866} | train loss {'Reaction outcome loss': 0.17336536451789286, 'Total loss': 0.17336536451789286}
2023-01-03 23:54:29,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:29,196 INFO:     Epoch: 90
2023-01-03 23:54:30,803 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4566592474778493, 'Total loss': 0.4566592474778493} | train loss {'Reaction outcome loss': 0.1749324024108503, 'Total loss': 0.1749324024108503}
2023-01-03 23:54:30,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:30,803 INFO:     Epoch: 91
2023-01-03 23:54:32,407 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43311821619669594, 'Total loss': 0.43311821619669594} | train loss {'Reaction outcome loss': 0.17276749104206413, 'Total loss': 0.17276749104206413}
2023-01-03 23:54:32,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:32,408 INFO:     Epoch: 92
2023-01-03 23:54:33,965 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4765595535437266, 'Total loss': 0.4765595535437266} | train loss {'Reaction outcome loss': 0.1692407729578414, 'Total loss': 0.1692407729578414}
2023-01-03 23:54:33,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:33,965 INFO:     Epoch: 93
2023-01-03 23:54:35,569 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4345801085233688, 'Total loss': 0.4345801085233688} | train loss {'Reaction outcome loss': 0.1694934282905501, 'Total loss': 0.1694934282905501}
2023-01-03 23:54:35,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:35,571 INFO:     Epoch: 94
2023-01-03 23:54:37,149 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4453316003084183, 'Total loss': 0.4453316003084183} | train loss {'Reaction outcome loss': 0.170993031494017, 'Total loss': 0.170993031494017}
2023-01-03 23:54:37,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:37,150 INFO:     Epoch: 95
2023-01-03 23:54:38,729 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47483965555826824, 'Total loss': 0.47483965555826824} | train loss {'Reaction outcome loss': 0.1701285967129073, 'Total loss': 0.1701285967129073}
2023-01-03 23:54:38,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:38,730 INFO:     Epoch: 96
2023-01-03 23:54:40,318 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4431551188230515, 'Total loss': 0.4431551188230515} | train loss {'Reaction outcome loss': 0.1678889424392328, 'Total loss': 0.1678889424392328}
2023-01-03 23:54:40,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:40,318 INFO:     Epoch: 97
2023-01-03 23:54:41,920 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44499805172284446, 'Total loss': 0.44499805172284446} | train loss {'Reaction outcome loss': 0.16822296341131973, 'Total loss': 0.16822296341131973}
2023-01-03 23:54:41,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:41,921 INFO:     Epoch: 98
2023-01-03 23:54:43,488 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47161713739236194, 'Total loss': 0.47161713739236194} | train loss {'Reaction outcome loss': 0.16805142548443866, 'Total loss': 0.16805142548443866}
2023-01-03 23:54:43,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:43,488 INFO:     Epoch: 99
2023-01-03 23:54:45,089 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46450071533521015, 'Total loss': 0.46450071533521015} | train loss {'Reaction outcome loss': 0.16531600709660907, 'Total loss': 0.16531600709660907}
2023-01-03 23:54:45,089 INFO:     Best model found after epoch 14 of 100.
2023-01-03 23:54:45,089 INFO:   Done with stage: TRAINING
2023-01-03 23:54:45,089 INFO:   Starting stage: EVALUATION
2023-01-03 23:54:45,238 INFO:   Done with stage: EVALUATION
2023-01-03 23:54:45,238 INFO:   Leaving out SEQ value Fold_2
2023-01-03 23:54:45,251 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-03 23:54:45,252 INFO:   Starting stage: FEATURE SCALING
2023-01-03 23:54:45,913 INFO:   Done with stage: FEATURE SCALING
2023-01-03 23:54:45,914 INFO:   Starting stage: SCALING TARGETS
2023-01-03 23:54:45,985 INFO:   Done with stage: SCALING TARGETS
2023-01-03 23:54:45,985 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:54:45,985 INFO:     No hyperparam tuning for this model
2023-01-03 23:54:45,985 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:54:45,985 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 23:54:45,986 INFO:     None feature selector for col prot
2023-01-03 23:54:45,986 INFO:     None feature selector for col prot
2023-01-03 23:54:45,986 INFO:     None feature selector for col prot
2023-01-03 23:54:45,987 INFO:     None feature selector for col chem
2023-01-03 23:54:45,987 INFO:     None feature selector for col chem
2023-01-03 23:54:45,987 INFO:     None feature selector for col chem
2023-01-03 23:54:45,987 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 23:54:45,987 INFO:   Starting stage: BUILD MODEL
2023-01-03 23:54:45,988 INFO:     Number of params in model 70141
2023-01-03 23:54:45,991 INFO:   Done with stage: BUILD MODEL
2023-01-03 23:54:45,991 INFO:   Starting stage: TRAINING
2023-01-03 23:54:46,035 INFO:     Val loss before train {'Reaction outcome loss': 0.9712339321772258, 'Total loss': 0.9712339321772258}
2023-01-03 23:54:46,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:46,035 INFO:     Epoch: 0
2023-01-03 23:54:47,628 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.59948956767718, 'Total loss': 0.59948956767718} | train loss {'Reaction outcome loss': 0.8434079328308934, 'Total loss': 0.8434079328308934}
2023-01-03 23:54:47,628 INFO:     Found new best model at epoch 0
2023-01-03 23:54:47,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:47,629 INFO:     Epoch: 1
2023-01-03 23:54:49,226 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4970850239197413, 'Total loss': 0.4970850239197413} | train loss {'Reaction outcome loss': 0.6085070203179899, 'Total loss': 0.6085070203179899}
2023-01-03 23:54:49,226 INFO:     Found new best model at epoch 1
2023-01-03 23:54:49,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:49,227 INFO:     Epoch: 2
2023-01-03 23:54:50,826 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4962669263283412, 'Total loss': 0.4962669263283412} | train loss {'Reaction outcome loss': 0.5229333265455932, 'Total loss': 0.5229333265455932}
2023-01-03 23:54:50,827 INFO:     Found new best model at epoch 2
2023-01-03 23:54:50,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:50,827 INFO:     Epoch: 3
2023-01-03 23:54:52,432 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45835161407788594, 'Total loss': 0.45835161407788594} | train loss {'Reaction outcome loss': 0.4846332662374429, 'Total loss': 0.4846332662374429}
2023-01-03 23:54:52,432 INFO:     Found new best model at epoch 3
2023-01-03 23:54:52,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:52,433 INFO:     Epoch: 4
2023-01-03 23:54:54,039 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4653012603521347, 'Total loss': 0.4653012603521347} | train loss {'Reaction outcome loss': 0.4761984915189121, 'Total loss': 0.4761984915189121}
2023-01-03 23:54:54,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:54,040 INFO:     Epoch: 5
2023-01-03 23:54:55,641 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4489827970663706, 'Total loss': 0.4489827970663706} | train loss {'Reaction outcome loss': 0.4426508618491715, 'Total loss': 0.4426508618491715}
2023-01-03 23:54:55,641 INFO:     Found new best model at epoch 5
2023-01-03 23:54:55,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:55,642 INFO:     Epoch: 6
2023-01-03 23:54:57,246 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4517144640286764, 'Total loss': 0.4517144640286764} | train loss {'Reaction outcome loss': 0.42569716376465955, 'Total loss': 0.42569716376465955}
2023-01-03 23:54:57,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:57,247 INFO:     Epoch: 7
2023-01-03 23:54:58,869 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44344934821128845, 'Total loss': 0.44344934821128845} | train loss {'Reaction outcome loss': 0.4137688714848912, 'Total loss': 0.4137688714848912}
2023-01-03 23:54:58,869 INFO:     Found new best model at epoch 7
2023-01-03 23:54:58,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:54:58,870 INFO:     Epoch: 8
2023-01-03 23:55:00,469 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4458459258079529, 'Total loss': 0.4458459258079529} | train loss {'Reaction outcome loss': 0.4040983455676157, 'Total loss': 0.4040983455676157}
2023-01-03 23:55:00,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:00,469 INFO:     Epoch: 9
2023-01-03 23:55:02,090 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42710070411364237, 'Total loss': 0.42710070411364237} | train loss {'Reaction outcome loss': 0.38976343640166783, 'Total loss': 0.38976343640166783}
2023-01-03 23:55:02,090 INFO:     Found new best model at epoch 9
2023-01-03 23:55:02,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:02,091 INFO:     Epoch: 10
2023-01-03 23:55:03,703 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42992189625898997, 'Total loss': 0.42992189625898997} | train loss {'Reaction outcome loss': 0.3864067018190669, 'Total loss': 0.3864067018190669}
2023-01-03 23:55:03,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:03,703 INFO:     Epoch: 11
2023-01-03 23:55:05,319 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4289934794108073, 'Total loss': 0.4289934794108073} | train loss {'Reaction outcome loss': 0.37230733693644835, 'Total loss': 0.37230733693644835}
2023-01-03 23:55:05,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:05,319 INFO:     Epoch: 12
2023-01-03 23:55:06,956 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43904751936594644, 'Total loss': 0.43904751936594644} | train loss {'Reaction outcome loss': 0.36511203153160116, 'Total loss': 0.36511203153160116}
2023-01-03 23:55:06,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:06,957 INFO:     Epoch: 13
2023-01-03 23:55:08,561 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4227993667125702, 'Total loss': 0.4227993667125702} | train loss {'Reaction outcome loss': 0.35947326156378223, 'Total loss': 0.35947326156378223}
2023-01-03 23:55:08,561 INFO:     Found new best model at epoch 13
2023-01-03 23:55:08,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:08,562 INFO:     Epoch: 14
2023-01-03 23:55:09,922 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4271172891060511, 'Total loss': 0.4271172891060511} | train loss {'Reaction outcome loss': 0.3549115150015733, 'Total loss': 0.3549115150015733}
2023-01-03 23:55:09,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:09,922 INFO:     Epoch: 15
2023-01-03 23:55:11,005 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4192962964375814, 'Total loss': 0.4192962964375814} | train loss {'Reaction outcome loss': 0.34754029765347205, 'Total loss': 0.34754029765347205}
2023-01-03 23:55:11,005 INFO:     Found new best model at epoch 15
2023-01-03 23:55:11,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:11,006 INFO:     Epoch: 16
2023-01-03 23:55:12,125 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41945881048838296, 'Total loss': 0.41945881048838296} | train loss {'Reaction outcome loss': 0.3423014812283953, 'Total loss': 0.3423014812283953}
2023-01-03 23:55:12,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:12,125 INFO:     Epoch: 17
2023-01-03 23:55:13,247 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42015934785207115, 'Total loss': 0.42015934785207115} | train loss {'Reaction outcome loss': 0.33763569317744585, 'Total loss': 0.33763569317744585}
2023-01-03 23:55:13,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:13,248 INFO:     Epoch: 18
2023-01-03 23:55:14,681 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4433602352937063, 'Total loss': 0.4433602352937063} | train loss {'Reaction outcome loss': 0.3303700787102993, 'Total loss': 0.3303700787102993}
2023-01-03 23:55:14,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:14,682 INFO:     Epoch: 19
2023-01-03 23:55:16,304 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41384143034617105, 'Total loss': 0.41384143034617105} | train loss {'Reaction outcome loss': 0.325849830645366, 'Total loss': 0.325849830645366}
2023-01-03 23:55:16,304 INFO:     Found new best model at epoch 19
2023-01-03 23:55:16,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:16,305 INFO:     Epoch: 20
2023-01-03 23:55:17,923 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4349715451399485, 'Total loss': 0.4349715451399485} | train loss {'Reaction outcome loss': 0.3195958974352781, 'Total loss': 0.3195958974352781}
2023-01-03 23:55:17,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:17,924 INFO:     Epoch: 21
2023-01-03 23:55:19,533 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40933253467082975, 'Total loss': 0.40933253467082975} | train loss {'Reaction outcome loss': 0.3148909470039433, 'Total loss': 0.3148909470039433}
2023-01-03 23:55:19,533 INFO:     Found new best model at epoch 21
2023-01-03 23:55:19,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:19,534 INFO:     Epoch: 22
2023-01-03 23:55:21,139 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4223729153474172, 'Total loss': 0.4223729153474172} | train loss {'Reaction outcome loss': 0.3108724874116993, 'Total loss': 0.3108724874116993}
2023-01-03 23:55:21,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:21,139 INFO:     Epoch: 23
2023-01-03 23:55:22,758 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41324721574783324, 'Total loss': 0.41324721574783324} | train loss {'Reaction outcome loss': 0.3074098495746274, 'Total loss': 0.3074098495746274}
2023-01-03 23:55:22,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:22,759 INFO:     Epoch: 24
2023-01-03 23:55:24,352 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4311081161101659, 'Total loss': 0.4311081161101659} | train loss {'Reaction outcome loss': 0.3020557400358603, 'Total loss': 0.3020557400358603}
2023-01-03 23:55:24,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:24,352 INFO:     Epoch: 25
2023-01-03 23:55:25,949 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41920863290627797, 'Total loss': 0.41920863290627797} | train loss {'Reaction outcome loss': 0.29660894229427737, 'Total loss': 0.29660894229427737}
2023-01-03 23:55:25,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:25,950 INFO:     Epoch: 26
2023-01-03 23:55:27,547 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4186394115289052, 'Total loss': 0.4186394115289052} | train loss {'Reaction outcome loss': 0.29400283557302115, 'Total loss': 0.29400283557302115}
2023-01-03 23:55:27,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:27,547 INFO:     Epoch: 27
2023-01-03 23:55:29,147 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40079550743103026, 'Total loss': 0.40079550743103026} | train loss {'Reaction outcome loss': 0.2870322843514589, 'Total loss': 0.2870322843514589}
2023-01-03 23:55:29,147 INFO:     Found new best model at epoch 27
2023-01-03 23:55:29,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:29,148 INFO:     Epoch: 28
2023-01-03 23:55:30,762 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40917909344037373, 'Total loss': 0.40917909344037373} | train loss {'Reaction outcome loss': 0.28509662469656655, 'Total loss': 0.28509662469656655}
2023-01-03 23:55:30,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:30,762 INFO:     Epoch: 29
2023-01-03 23:55:32,356 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40880575875441233, 'Total loss': 0.40880575875441233} | train loss {'Reaction outcome loss': 0.2893122433266346, 'Total loss': 0.2893122433266346}
2023-01-03 23:55:32,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:32,356 INFO:     Epoch: 30
2023-01-03 23:55:33,972 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40700657765070597, 'Total loss': 0.40700657765070597} | train loss {'Reaction outcome loss': 0.27922255698375514, 'Total loss': 0.27922255698375514}
2023-01-03 23:55:33,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:33,972 INFO:     Epoch: 31
2023-01-03 23:55:35,595 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4072974185148875, 'Total loss': 0.4072974185148875} | train loss {'Reaction outcome loss': 0.27297475872615323, 'Total loss': 0.27297475872615323}
2023-01-03 23:55:35,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:35,596 INFO:     Epoch: 32
2023-01-03 23:55:37,212 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3896556834379832, 'Total loss': 0.3896556834379832} | train loss {'Reaction outcome loss': 0.2710287292636391, 'Total loss': 0.2710287292636391}
2023-01-03 23:55:37,212 INFO:     Found new best model at epoch 32
2023-01-03 23:55:37,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:37,213 INFO:     Epoch: 33
2023-01-03 23:55:38,799 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4197433849175771, 'Total loss': 0.4197433849175771} | train loss {'Reaction outcome loss': 0.2657040880496978, 'Total loss': 0.2657040880496978}
2023-01-03 23:55:38,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:38,799 INFO:     Epoch: 34
2023-01-03 23:55:40,404 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4123268147309621, 'Total loss': 0.4123268147309621} | train loss {'Reaction outcome loss': 0.2702995330041301, 'Total loss': 0.2702995330041301}
2023-01-03 23:55:40,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:40,405 INFO:     Epoch: 35
2023-01-03 23:55:41,988 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3959878782431285, 'Total loss': 0.3959878782431285} | train loss {'Reaction outcome loss': 0.26740156408345356, 'Total loss': 0.26740156408345356}
2023-01-03 23:55:41,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:41,990 INFO:     Epoch: 36
2023-01-03 23:55:43,584 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39829474687576294, 'Total loss': 0.39829474687576294} | train loss {'Reaction outcome loss': 0.25943765089344367, 'Total loss': 0.25943765089344367}
2023-01-03 23:55:43,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:43,584 INFO:     Epoch: 37
2023-01-03 23:55:45,200 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43101448913415275, 'Total loss': 0.43101448913415275} | train loss {'Reaction outcome loss': 0.25776016124206985, 'Total loss': 0.25776016124206985}
2023-01-03 23:55:45,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:45,201 INFO:     Epoch: 38
2023-01-03 23:55:46,818 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41189553439617155, 'Total loss': 0.41189553439617155} | train loss {'Reaction outcome loss': 0.2523679129070302, 'Total loss': 0.2523679129070302}
2023-01-03 23:55:46,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:46,818 INFO:     Epoch: 39
2023-01-03 23:55:48,413 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40754029204448067, 'Total loss': 0.40754029204448067} | train loss {'Reaction outcome loss': 0.2505572901484455, 'Total loss': 0.2505572901484455}
2023-01-03 23:55:48,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:48,413 INFO:     Epoch: 40
2023-01-03 23:55:49,997 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41511654456456504, 'Total loss': 0.41511654456456504} | train loss {'Reaction outcome loss': 0.24834875683840094, 'Total loss': 0.24834875683840094}
2023-01-03 23:55:49,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:49,997 INFO:     Epoch: 41
2023-01-03 23:55:51,596 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42837822834650674, 'Total loss': 0.42837822834650674} | train loss {'Reaction outcome loss': 0.24601191253168508, 'Total loss': 0.24601191253168508}
2023-01-03 23:55:51,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:51,596 INFO:     Epoch: 42
2023-01-03 23:55:53,196 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3995414545138677, 'Total loss': 0.3995414545138677} | train loss {'Reaction outcome loss': 0.24359189104881437, 'Total loss': 0.24359189104881437}
2023-01-03 23:55:53,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:53,197 INFO:     Epoch: 43
2023-01-03 23:55:54,806 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4203229894240697, 'Total loss': 0.4203229894240697} | train loss {'Reaction outcome loss': 0.24451941116780473, 'Total loss': 0.24451941116780473}
2023-01-03 23:55:54,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:54,806 INFO:     Epoch: 44
2023-01-03 23:55:56,409 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40289286375045774, 'Total loss': 0.40289286375045774} | train loss {'Reaction outcome loss': 0.24051707819951157, 'Total loss': 0.24051707819951157}
2023-01-03 23:55:56,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:56,410 INFO:     Epoch: 45
2023-01-03 23:55:58,010 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3950653443733851, 'Total loss': 0.3950653443733851} | train loss {'Reaction outcome loss': 0.2349158506271572, 'Total loss': 0.2349158506271572}
2023-01-03 23:55:58,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:58,010 INFO:     Epoch: 46
2023-01-03 23:55:59,606 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42197495698928833, 'Total loss': 0.42197495698928833} | train loss {'Reaction outcome loss': 0.23481090677861188, 'Total loss': 0.23481090677861188}
2023-01-03 23:55:59,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:55:59,606 INFO:     Epoch: 47
2023-01-03 23:56:01,203 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4344665924708048, 'Total loss': 0.4344665924708048} | train loss {'Reaction outcome loss': 0.23692632770246785, 'Total loss': 0.23692632770246785}
2023-01-03 23:56:01,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:01,204 INFO:     Epoch: 48
2023-01-03 23:56:02,815 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3933078547318776, 'Total loss': 0.3933078547318776} | train loss {'Reaction outcome loss': 0.23718718474433906, 'Total loss': 0.23718718474433906}
2023-01-03 23:56:02,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:02,815 INFO:     Epoch: 49
2023-01-03 23:56:04,422 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40448648830254874, 'Total loss': 0.40448648830254874} | train loss {'Reaction outcome loss': 0.22825472828931295, 'Total loss': 0.22825472828931295}
2023-01-03 23:56:04,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:04,423 INFO:     Epoch: 50
2023-01-03 23:56:06,021 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40995377699534097, 'Total loss': 0.40995377699534097} | train loss {'Reaction outcome loss': 0.2250954476421348, 'Total loss': 0.2250954476421348}
2023-01-03 23:56:06,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:06,021 INFO:     Epoch: 51
2023-01-03 23:56:07,637 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.425124063094457, 'Total loss': 0.425124063094457} | train loss {'Reaction outcome loss': 0.22323630804928235, 'Total loss': 0.22323630804928235}
2023-01-03 23:56:07,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:07,638 INFO:     Epoch: 52
2023-01-03 23:56:09,236 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4073103835185369, 'Total loss': 0.4073103835185369} | train loss {'Reaction outcome loss': 0.22471362811797935, 'Total loss': 0.22471362811797935}
2023-01-03 23:56:09,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:09,237 INFO:     Epoch: 53
2023-01-03 23:56:10,868 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4040241718292236, 'Total loss': 0.4040241718292236} | train loss {'Reaction outcome loss': 0.2207065138639376, 'Total loss': 0.2207065138639376}
2023-01-03 23:56:10,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:10,869 INFO:     Epoch: 54
2023-01-03 23:56:12,480 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4243412127097448, 'Total loss': 0.4243412127097448} | train loss {'Reaction outcome loss': 0.21803643572501893, 'Total loss': 0.21803643572501893}
2023-01-03 23:56:12,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:12,481 INFO:     Epoch: 55
2023-01-03 23:56:14,101 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.448504239320755, 'Total loss': 0.448504239320755} | train loss {'Reaction outcome loss': 0.21901815289364068, 'Total loss': 0.21901815289364068}
2023-01-03 23:56:14,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:14,101 INFO:     Epoch: 56
2023-01-03 23:56:15,700 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41803432603677115, 'Total loss': 0.41803432603677115} | train loss {'Reaction outcome loss': 0.21695697126721125, 'Total loss': 0.21695697126721125}
2023-01-03 23:56:15,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:15,700 INFO:     Epoch: 57
2023-01-03 23:56:17,294 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4375153422355652, 'Total loss': 0.4375153422355652} | train loss {'Reaction outcome loss': 0.21509782782337372, 'Total loss': 0.21509782782337372}
2023-01-03 23:56:17,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:17,294 INFO:     Epoch: 58
2023-01-03 23:56:18,918 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4388633261124293, 'Total loss': 0.4388633261124293} | train loss {'Reaction outcome loss': 0.2151593729259743, 'Total loss': 0.2151593729259743}
2023-01-03 23:56:18,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:18,919 INFO:     Epoch: 59
2023-01-03 23:56:20,509 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4120491176843643, 'Total loss': 0.4120491176843643} | train loss {'Reaction outcome loss': 0.21222457017722554, 'Total loss': 0.21222457017722554}
2023-01-03 23:56:20,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:20,509 INFO:     Epoch: 60
2023-01-03 23:56:22,128 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4045430382092794, 'Total loss': 0.4045430382092794} | train loss {'Reaction outcome loss': 0.2111930822978046, 'Total loss': 0.2111930822978046}
2023-01-03 23:56:22,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:22,129 INFO:     Epoch: 61
2023-01-03 23:56:23,723 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4255348205566406, 'Total loss': 0.4255348205566406} | train loss {'Reaction outcome loss': 0.2089305745713595, 'Total loss': 0.2089305745713595}
2023-01-03 23:56:23,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:23,723 INFO:     Epoch: 62
2023-01-03 23:56:25,330 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42105235482255615, 'Total loss': 0.42105235482255615} | train loss {'Reaction outcome loss': 0.2079678856636114, 'Total loss': 0.2079678856636114}
2023-01-03 23:56:25,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:25,330 INFO:     Epoch: 63
2023-01-03 23:56:26,936 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4283496568600337, 'Total loss': 0.4283496568600337} | train loss {'Reaction outcome loss': 0.20429627338012654, 'Total loss': 0.20429627338012654}
2023-01-03 23:56:26,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:26,936 INFO:     Epoch: 64
2023-01-03 23:56:28,569 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43740389744440716, 'Total loss': 0.43740389744440716} | train loss {'Reaction outcome loss': 0.20610194216135205, 'Total loss': 0.20610194216135205}
2023-01-03 23:56:28,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:28,569 INFO:     Epoch: 65
2023-01-03 23:56:30,203 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43773635029792785, 'Total loss': 0.43773635029792785} | train loss {'Reaction outcome loss': 0.20186556460174726, 'Total loss': 0.20186556460174726}
2023-01-03 23:56:30,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:30,204 INFO:     Epoch: 66
2023-01-03 23:56:31,833 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4510605752468109, 'Total loss': 0.4510605752468109} | train loss {'Reaction outcome loss': 0.20269561383495296, 'Total loss': 0.20269561383495296}
2023-01-03 23:56:31,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:31,834 INFO:     Epoch: 67
2023-01-03 23:56:33,441 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4081617554028829, 'Total loss': 0.4081617554028829} | train loss {'Reaction outcome loss': 0.1994080156386506, 'Total loss': 0.1994080156386506}
2023-01-03 23:56:33,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:33,442 INFO:     Epoch: 68
2023-01-03 23:56:35,043 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4433920760949453, 'Total loss': 0.4433920760949453} | train loss {'Reaction outcome loss': 0.19931013782785367, 'Total loss': 0.19931013782785367}
2023-01-03 23:56:35,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:35,043 INFO:     Epoch: 69
2023-01-03 23:56:36,652 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4506192912658056, 'Total loss': 0.4506192912658056} | train loss {'Reaction outcome loss': 0.20110896285758287, 'Total loss': 0.20110896285758287}
2023-01-03 23:56:36,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:36,652 INFO:     Epoch: 70
2023-01-03 23:56:38,276 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4297048439582189, 'Total loss': 0.4297048439582189} | train loss {'Reaction outcome loss': 0.19965610312119944, 'Total loss': 0.19965610312119944}
2023-01-03 23:56:38,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:38,276 INFO:     Epoch: 71
2023-01-03 23:56:39,905 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4254574735959371, 'Total loss': 0.4254574735959371} | train loss {'Reaction outcome loss': 0.19367019780126968, 'Total loss': 0.19367019780126968}
2023-01-03 23:56:39,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:39,905 INFO:     Epoch: 72
2023-01-03 23:56:41,537 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43738245268662773, 'Total loss': 0.43738245268662773} | train loss {'Reaction outcome loss': 0.1944623058343891, 'Total loss': 0.1944623058343891}
2023-01-03 23:56:41,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:41,537 INFO:     Epoch: 73
2023-01-03 23:56:43,121 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4665788610776265, 'Total loss': 0.4665788610776265} | train loss {'Reaction outcome loss': 0.19486998182222032, 'Total loss': 0.19486998182222032}
2023-01-03 23:56:43,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:43,122 INFO:     Epoch: 74
2023-01-03 23:56:44,722 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47944105764230094, 'Total loss': 0.47944105764230094} | train loss {'Reaction outcome loss': 0.1911198448092825, 'Total loss': 0.1911198448092825}
2023-01-03 23:56:44,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:44,722 INFO:     Epoch: 75
2023-01-03 23:56:46,344 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4768769423166911, 'Total loss': 0.4768769423166911} | train loss {'Reaction outcome loss': 0.19499176883044234, 'Total loss': 0.19499176883044234}
2023-01-03 23:56:46,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:46,345 INFO:     Epoch: 76
2023-01-03 23:56:47,972 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4344117393096288, 'Total loss': 0.4344117393096288} | train loss {'Reaction outcome loss': 0.1992737086408812, 'Total loss': 0.1992737086408812}
2023-01-03 23:56:47,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:47,972 INFO:     Epoch: 77
2023-01-03 23:56:49,575 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4483611027399699, 'Total loss': 0.4483611027399699} | train loss {'Reaction outcome loss': 0.21373456748931305, 'Total loss': 0.21373456748931305}
2023-01-03 23:56:49,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:49,576 INFO:     Epoch: 78
2023-01-03 23:56:51,172 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4634978403647741, 'Total loss': 0.4634978403647741} | train loss {'Reaction outcome loss': 0.1882388642631101, 'Total loss': 0.1882388642631101}
2023-01-03 23:56:51,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:51,172 INFO:     Epoch: 79
2023-01-03 23:56:52,795 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45856330593427025, 'Total loss': 0.45856330593427025} | train loss {'Reaction outcome loss': 0.1852316733642036, 'Total loss': 0.1852316733642036}
2023-01-03 23:56:52,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:52,795 INFO:     Epoch: 80
2023-01-03 23:56:54,383 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4813255806763967, 'Total loss': 0.4813255806763967} | train loss {'Reaction outcome loss': 0.18495730977451455, 'Total loss': 0.18495730977451455}
2023-01-03 23:56:54,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:54,383 INFO:     Epoch: 81
2023-01-03 23:56:56,014 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4900843034187953, 'Total loss': 0.4900843034187953} | train loss {'Reaction outcome loss': 0.1842910476332137, 'Total loss': 0.1842910476332137}
2023-01-03 23:56:56,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:56,015 INFO:     Epoch: 82
2023-01-03 23:56:57,615 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41453644235928855, 'Total loss': 0.41453644235928855} | train loss {'Reaction outcome loss': 0.18586022418964168, 'Total loss': 0.18586022418964168}
2023-01-03 23:56:57,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:57,616 INFO:     Epoch: 83
2023-01-03 23:56:59,225 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46394154131412507, 'Total loss': 0.46394154131412507} | train loss {'Reaction outcome loss': 0.19133380603085717, 'Total loss': 0.19133380603085717}
2023-01-03 23:56:59,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:56:59,225 INFO:     Epoch: 84
2023-01-03 23:57:00,830 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4354491616288821, 'Total loss': 0.4354491616288821} | train loss {'Reaction outcome loss': 0.18235893711802867, 'Total loss': 0.18235893711802867}
2023-01-03 23:57:00,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:00,830 INFO:     Epoch: 85
2023-01-03 23:57:02,416 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47290862947702406, 'Total loss': 0.47290862947702406} | train loss {'Reaction outcome loss': 0.1802840868578009, 'Total loss': 0.1802840868578009}
2023-01-03 23:57:02,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:02,416 INFO:     Epoch: 86
2023-01-03 23:57:04,050 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5003890126943589, 'Total loss': 0.5003890126943589} | train loss {'Reaction outcome loss': 0.18436880191312294, 'Total loss': 0.18436880191312294}
2023-01-03 23:57:04,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:04,050 INFO:     Epoch: 87
2023-01-03 23:57:05,656 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.447950337578853, 'Total loss': 0.447950337578853} | train loss {'Reaction outcome loss': 0.1791936313424283, 'Total loss': 0.1791936313424283}
2023-01-03 23:57:05,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:05,656 INFO:     Epoch: 88
2023-01-03 23:57:07,288 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44635680317878723, 'Total loss': 0.44635680317878723} | train loss {'Reaction outcome loss': 0.17840785918878796, 'Total loss': 0.17840785918878796}
2023-01-03 23:57:07,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:07,288 INFO:     Epoch: 89
2023-01-03 23:57:08,887 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4672662268082301, 'Total loss': 0.4672662268082301} | train loss {'Reaction outcome loss': 0.1760831147354717, 'Total loss': 0.1760831147354717}
2023-01-03 23:57:08,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:08,888 INFO:     Epoch: 90
2023-01-03 23:57:10,514 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4808945337931315, 'Total loss': 0.4808945337931315} | train loss {'Reaction outcome loss': 0.17321256607976757, 'Total loss': 0.17321256607976757}
2023-01-03 23:57:10,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:10,514 INFO:     Epoch: 91
2023-01-03 23:57:12,108 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47153111894925437, 'Total loss': 0.47153111894925437} | train loss {'Reaction outcome loss': 0.17645639754356007, 'Total loss': 0.17645639754356007}
2023-01-03 23:57:12,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:12,109 INFO:     Epoch: 92
2023-01-03 23:57:13,733 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4677969614664714, 'Total loss': 0.4677969614664714} | train loss {'Reaction outcome loss': 0.17389664198339416, 'Total loss': 0.17389664198339416}
2023-01-03 23:57:13,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:13,733 INFO:     Epoch: 93
2023-01-03 23:57:15,333 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4803216646114985, 'Total loss': 0.4803216646114985} | train loss {'Reaction outcome loss': 0.17453622888643766, 'Total loss': 0.17453622888643766}
2023-01-03 23:57:15,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:15,334 INFO:     Epoch: 94
2023-01-03 23:57:16,952 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4565115928649902, 'Total loss': 0.4565115928649902} | train loss {'Reaction outcome loss': 0.17299017067774042, 'Total loss': 0.17299017067774042}
2023-01-03 23:57:16,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:16,952 INFO:     Epoch: 95
2023-01-03 23:57:18,549 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45731843411922457, 'Total loss': 0.45731843411922457} | train loss {'Reaction outcome loss': 0.1724070210530794, 'Total loss': 0.1724070210530794}
2023-01-03 23:57:18,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:18,549 INFO:     Epoch: 96
2023-01-03 23:57:20,153 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44475655059019725, 'Total loss': 0.44475655059019725} | train loss {'Reaction outcome loss': 0.16954565356802737, 'Total loss': 0.16954565356802737}
2023-01-03 23:57:20,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:20,154 INFO:     Epoch: 97
2023-01-03 23:57:21,763 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4620278348525365, 'Total loss': 0.4620278348525365} | train loss {'Reaction outcome loss': 0.17116974851418543, 'Total loss': 0.17116974851418543}
2023-01-03 23:57:21,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:21,763 INFO:     Epoch: 98
2023-01-03 23:57:23,390 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4474134907126427, 'Total loss': 0.4474134907126427} | train loss {'Reaction outcome loss': 0.16949042697492783, 'Total loss': 0.16949042697492783}
2023-01-03 23:57:23,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:23,390 INFO:     Epoch: 99
2023-01-03 23:57:25,009 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43336651970942813, 'Total loss': 0.43336651970942813} | train loss {'Reaction outcome loss': 0.17057904972033863, 'Total loss': 0.17057904972033863}
2023-01-03 23:57:25,010 INFO:     Best model found after epoch 33 of 100.
2023-01-03 23:57:25,010 INFO:   Done with stage: TRAINING
2023-01-03 23:57:25,010 INFO:   Starting stage: EVALUATION
2023-01-03 23:57:25,140 INFO:   Done with stage: EVALUATION
2023-01-03 23:57:25,140 INFO:   Leaving out SEQ value Fold_3
2023-01-03 23:57:25,153 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-03 23:57:25,153 INFO:   Starting stage: FEATURE SCALING
2023-01-03 23:57:25,793 INFO:   Done with stage: FEATURE SCALING
2023-01-03 23:57:25,794 INFO:   Starting stage: SCALING TARGETS
2023-01-03 23:57:25,863 INFO:   Done with stage: SCALING TARGETS
2023-01-03 23:57:25,863 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:57:25,863 INFO:     No hyperparam tuning for this model
2023-01-03 23:57:25,863 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-03 23:57:25,864 INFO:   Starting stage: FEATURE SELECTION
2023-01-03 23:57:25,864 INFO:     None feature selector for col prot
2023-01-03 23:57:25,864 INFO:     None feature selector for col prot
2023-01-03 23:57:25,864 INFO:     None feature selector for col prot
2023-01-03 23:57:25,865 INFO:     None feature selector for col chem
2023-01-03 23:57:25,865 INFO:     None feature selector for col chem
2023-01-03 23:57:25,865 INFO:     None feature selector for col chem
2023-01-03 23:57:25,865 INFO:   Done with stage: FEATURE SELECTION
2023-01-03 23:57:25,865 INFO:   Starting stage: BUILD MODEL
2023-01-03 23:57:25,866 INFO:     Number of params in model 70141
2023-01-03 23:57:25,870 INFO:   Done with stage: BUILD MODEL
2023-01-03 23:57:25,870 INFO:   Starting stage: TRAINING
2023-01-03 23:57:25,915 INFO:     Val loss before train {'Reaction outcome loss': 1.0418184796969097, 'Total loss': 1.0418184796969097}
2023-01-03 23:57:25,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:25,915 INFO:     Epoch: 0
2023-01-03 23:57:27,483 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7061268806457519, 'Total loss': 0.7061268806457519} | train loss {'Reaction outcome loss': 0.8262153175069299, 'Total loss': 0.8262153175069299}
2023-01-03 23:57:27,483 INFO:     Found new best model at epoch 0
2023-01-03 23:57:27,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:27,484 INFO:     Epoch: 1
2023-01-03 23:57:29,058 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5720020651817321, 'Total loss': 0.5720020651817321} | train loss {'Reaction outcome loss': 0.5851291698086393, 'Total loss': 0.5851291698086393}
2023-01-03 23:57:29,058 INFO:     Found new best model at epoch 1
2023-01-03 23:57:29,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:29,059 INFO:     Epoch: 2
2023-01-03 23:57:30,640 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5109949231147766, 'Total loss': 0.5109949231147766} | train loss {'Reaction outcome loss': 0.5114492588427477, 'Total loss': 0.5114492588427477}
2023-01-03 23:57:30,640 INFO:     Found new best model at epoch 2
2023-01-03 23:57:30,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:30,641 INFO:     Epoch: 3
2023-01-03 23:57:32,237 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4842603867252668, 'Total loss': 0.4842603867252668} | train loss {'Reaction outcome loss': 0.47208302934746166, 'Total loss': 0.47208302934746166}
2023-01-03 23:57:32,238 INFO:     Found new best model at epoch 3
2023-01-03 23:57:32,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:32,239 INFO:     Epoch: 4
2023-01-03 23:57:33,828 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45098989208539325, 'Total loss': 0.45098989208539325} | train loss {'Reaction outcome loss': 0.4423233905445525, 'Total loss': 0.4423233905445525}
2023-01-03 23:57:33,828 INFO:     Found new best model at epoch 4
2023-01-03 23:57:33,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:33,829 INFO:     Epoch: 5
2023-01-03 23:57:35,428 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4607542783021927, 'Total loss': 0.4607542783021927} | train loss {'Reaction outcome loss': 0.4258602494612718, 'Total loss': 0.4258602494612718}
2023-01-03 23:57:35,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:35,428 INFO:     Epoch: 6
2023-01-03 23:57:37,007 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4632536113262177, 'Total loss': 0.4632536113262177} | train loss {'Reaction outcome loss': 0.40671436930750754, 'Total loss': 0.40671436930750754}
2023-01-03 23:57:37,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:37,007 INFO:     Epoch: 7
2023-01-03 23:57:38,595 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4550376375516256, 'Total loss': 0.4550376375516256} | train loss {'Reaction outcome loss': 0.3947346052734843, 'Total loss': 0.3947346052734843}
2023-01-03 23:57:38,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:38,595 INFO:     Epoch: 8
2023-01-03 23:57:40,191 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46187855501969655, 'Total loss': 0.46187855501969655} | train loss {'Reaction outcome loss': 0.3832598187629775, 'Total loss': 0.3832598187629775}
2023-01-03 23:57:40,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:40,191 INFO:     Epoch: 9
2023-01-03 23:57:41,773 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4587148457765579, 'Total loss': 0.4587148457765579} | train loss {'Reaction outcome loss': 0.3750443291942497, 'Total loss': 0.3750443291942497}
2023-01-03 23:57:41,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:41,773 INFO:     Epoch: 10
2023-01-03 23:57:43,365 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44522605935732523, 'Total loss': 0.44522605935732523} | train loss {'Reaction outcome loss': 0.3654082573049671, 'Total loss': 0.3654082573049671}
2023-01-03 23:57:43,365 INFO:     Found new best model at epoch 10
2023-01-03 23:57:43,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:43,366 INFO:     Epoch: 11
2023-01-03 23:57:44,941 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4388149748245875, 'Total loss': 0.4388149748245875} | train loss {'Reaction outcome loss': 0.35799002953064746, 'Total loss': 0.35799002953064746}
2023-01-03 23:57:44,941 INFO:     Found new best model at epoch 11
2023-01-03 23:57:44,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:44,942 INFO:     Epoch: 12
2023-01-03 23:57:46,541 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44388909737269083, 'Total loss': 0.44388909737269083} | train loss {'Reaction outcome loss': 0.3491086023740279, 'Total loss': 0.3491086023740279}
2023-01-03 23:57:46,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:46,541 INFO:     Epoch: 13
2023-01-03 23:57:48,125 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4452467570702235, 'Total loss': 0.4452467570702235} | train loss {'Reaction outcome loss': 0.34200684355073796, 'Total loss': 0.34200684355073796}
2023-01-03 23:57:48,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:48,125 INFO:     Epoch: 14
2023-01-03 23:57:49,730 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43166051506996156, 'Total loss': 0.43166051506996156} | train loss {'Reaction outcome loss': 0.3355001898912283, 'Total loss': 0.3355001898912283}
2023-01-03 23:57:49,730 INFO:     Found new best model at epoch 14
2023-01-03 23:57:49,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:49,731 INFO:     Epoch: 15
2023-01-03 23:57:51,335 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4190995544195175, 'Total loss': 0.4190995544195175} | train loss {'Reaction outcome loss': 0.32850334179270396, 'Total loss': 0.32850334179270396}
2023-01-03 23:57:51,335 INFO:     Found new best model at epoch 15
2023-01-03 23:57:51,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:51,336 INFO:     Epoch: 16
2023-01-03 23:57:52,930 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4432366261879603, 'Total loss': 0.4432366261879603} | train loss {'Reaction outcome loss': 0.3237486902228642, 'Total loss': 0.3237486902228642}
2023-01-03 23:57:52,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:52,930 INFO:     Epoch: 17
2023-01-03 23:57:54,499 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41746642999351025, 'Total loss': 0.41746642999351025} | train loss {'Reaction outcome loss': 0.3186710191406173, 'Total loss': 0.3186710191406173}
2023-01-03 23:57:54,500 INFO:     Found new best model at epoch 17
2023-01-03 23:57:54,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:54,500 INFO:     Epoch: 18
2023-01-03 23:57:56,092 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4436829090118408, 'Total loss': 0.4436829090118408} | train loss {'Reaction outcome loss': 0.31570917775943164, 'Total loss': 0.31570917775943164}
2023-01-03 23:57:56,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:56,093 INFO:     Epoch: 19
2023-01-03 23:57:57,679 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4440397024154663, 'Total loss': 0.4440397024154663} | train loss {'Reaction outcome loss': 0.30892549201354874, 'Total loss': 0.30892549201354874}
2023-01-03 23:57:57,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:57,679 INFO:     Epoch: 20
2023-01-03 23:57:59,288 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44416106939315797, 'Total loss': 0.44416106939315797} | train loss {'Reaction outcome loss': 0.3032325402502612, 'Total loss': 0.3032325402502612}
2023-01-03 23:57:59,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:57:59,289 INFO:     Epoch: 21
2023-01-03 23:58:00,878 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43490930199623107, 'Total loss': 0.43490930199623107} | train loss {'Reaction outcome loss': 0.2980514858259168, 'Total loss': 0.2980514858259168}
2023-01-03 23:58:00,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:00,879 INFO:     Epoch: 22
2023-01-03 23:58:02,477 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45581321318944296, 'Total loss': 0.45581321318944296} | train loss {'Reaction outcome loss': 0.29206170632944, 'Total loss': 0.29206170632944}
2023-01-03 23:58:02,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:02,478 INFO:     Epoch: 23
2023-01-03 23:58:04,067 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42336903313795726, 'Total loss': 0.42336903313795726} | train loss {'Reaction outcome loss': 0.29162068845151545, 'Total loss': 0.29162068845151545}
2023-01-03 23:58:04,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:04,067 INFO:     Epoch: 24
2023-01-03 23:58:05,650 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4297165671984355, 'Total loss': 0.4297165671984355} | train loss {'Reaction outcome loss': 0.2887736405535932, 'Total loss': 0.2887736405535932}
2023-01-03 23:58:05,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:05,650 INFO:     Epoch: 25
2023-01-03 23:58:07,230 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4516394148270289, 'Total loss': 0.4516394148270289} | train loss {'Reaction outcome loss': 0.28404654496973686, 'Total loss': 0.28404654496973686}
2023-01-03 23:58:07,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:07,230 INFO:     Epoch: 26
2023-01-03 23:58:08,844 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4245194176832835, 'Total loss': 0.4245194176832835} | train loss {'Reaction outcome loss': 0.2770096019401655, 'Total loss': 0.2770096019401655}
2023-01-03 23:58:08,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:08,844 INFO:     Epoch: 27
2023-01-03 23:58:10,451 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4537534932295481, 'Total loss': 0.4537534932295481} | train loss {'Reaction outcome loss': 0.27409405172580764, 'Total loss': 0.27409405172580764}
2023-01-03 23:58:10,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:10,451 INFO:     Epoch: 28
2023-01-03 23:58:12,039 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4318981428941091, 'Total loss': 0.4318981428941091} | train loss {'Reaction outcome loss': 0.27030021053203296, 'Total loss': 0.27030021053203296}
2023-01-03 23:58:12,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:12,039 INFO:     Epoch: 29
2023-01-03 23:58:13,621 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4149502545595169, 'Total loss': 0.4149502545595169} | train loss {'Reaction outcome loss': 0.2684497199270315, 'Total loss': 0.2684497199270315}
2023-01-03 23:58:13,621 INFO:     Found new best model at epoch 29
2023-01-03 23:58:13,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:13,622 INFO:     Epoch: 30
2023-01-03 23:58:15,203 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4264856626590093, 'Total loss': 0.4264856626590093} | train loss {'Reaction outcome loss': 0.2657210387344107, 'Total loss': 0.2657210387344107}
2023-01-03 23:58:15,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:15,204 INFO:     Epoch: 31
2023-01-03 23:58:16,795 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44547704855600995, 'Total loss': 0.44547704855600995} | train loss {'Reaction outcome loss': 0.25963150749440156, 'Total loss': 0.25963150749440156}
2023-01-03 23:58:16,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:16,796 INFO:     Epoch: 32
2023-01-03 23:58:18,406 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4257637361685435, 'Total loss': 0.4257637361685435} | train loss {'Reaction outcome loss': 0.25946631058777647, 'Total loss': 0.25946631058777647}
2023-01-03 23:58:18,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:18,406 INFO:     Epoch: 33
2023-01-03 23:58:20,012 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42763133148352306, 'Total loss': 0.42763133148352306} | train loss {'Reaction outcome loss': 0.25582718265143944, 'Total loss': 0.25582718265143944}
2023-01-03 23:58:20,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:20,012 INFO:     Epoch: 34
2023-01-03 23:58:21,585 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43531986872355144, 'Total loss': 0.43531986872355144} | train loss {'Reaction outcome loss': 0.25450371256296017, 'Total loss': 0.25450371256296017}
2023-01-03 23:58:21,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:21,585 INFO:     Epoch: 35
2023-01-03 23:58:23,167 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41802534212668735, 'Total loss': 0.41802534212668735} | train loss {'Reaction outcome loss': 0.25216733388630025, 'Total loss': 0.25216733388630025}
2023-01-03 23:58:23,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:23,167 INFO:     Epoch: 36
2023-01-03 23:58:24,772 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43871419032414755, 'Total loss': 0.43871419032414755} | train loss {'Reaction outcome loss': 0.24790667679038023, 'Total loss': 0.24790667679038023}
2023-01-03 23:58:24,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:24,772 INFO:     Epoch: 37
2023-01-03 23:58:26,386 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4287871360778809, 'Total loss': 0.4287871360778809} | train loss {'Reaction outcome loss': 0.24669509078120136, 'Total loss': 0.24669509078120136}
2023-01-03 23:58:26,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:26,386 INFO:     Epoch: 38
2023-01-03 23:58:28,005 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42713878452777865, 'Total loss': 0.42713878452777865} | train loss {'Reaction outcome loss': 0.24271538766312512, 'Total loss': 0.24271538766312512}
2023-01-03 23:58:28,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:28,005 INFO:     Epoch: 39
2023-01-03 23:58:29,593 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4032221019268036, 'Total loss': 0.4032221019268036} | train loss {'Reaction outcome loss': 0.23989066489777722, 'Total loss': 0.23989066489777722}
2023-01-03 23:58:29,593 INFO:     Found new best model at epoch 39
2023-01-03 23:58:29,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:29,594 INFO:     Epoch: 40
2023-01-03 23:58:31,165 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.433092392484347, 'Total loss': 0.433092392484347} | train loss {'Reaction outcome loss': 0.23586007894013392, 'Total loss': 0.23586007894013392}
2023-01-03 23:58:31,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:31,166 INFO:     Epoch: 41
2023-01-03 23:58:32,730 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4514450172583262, 'Total loss': 0.4514450172583262} | train loss {'Reaction outcome loss': 0.2363376375628915, 'Total loss': 0.2363376375628915}
2023-01-03 23:58:32,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:32,731 INFO:     Epoch: 42
2023-01-03 23:58:34,317 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4282367835442225, 'Total loss': 0.4282367835442225} | train loss {'Reaction outcome loss': 0.23628039420633526, 'Total loss': 0.23628039420633526}
2023-01-03 23:58:34,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:34,317 INFO:     Epoch: 43
2023-01-03 23:58:35,902 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43277421543995537, 'Total loss': 0.43277421543995537} | train loss {'Reaction outcome loss': 0.23298129570353163, 'Total loss': 0.23298129570353163}
2023-01-03 23:58:35,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:35,902 INFO:     Epoch: 44
2023-01-03 23:58:37,509 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4401153306166331, 'Total loss': 0.4401153306166331} | train loss {'Reaction outcome loss': 0.2287681318150881, 'Total loss': 0.2287681318150881}
2023-01-03 23:58:37,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:37,510 INFO:     Epoch: 45
2023-01-03 23:58:39,063 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41359874308109285, 'Total loss': 0.41359874308109285} | train loss {'Reaction outcome loss': 0.22832091514280428, 'Total loss': 0.22832091514280428}
2023-01-03 23:58:39,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:39,063 INFO:     Epoch: 46
2023-01-03 23:58:40,668 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4341130336125692, 'Total loss': 0.4341130336125692} | train loss {'Reaction outcome loss': 0.22692098325261703, 'Total loss': 0.22692098325261703}
2023-01-03 23:58:40,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:40,668 INFO:     Epoch: 47
2023-01-03 23:58:42,249 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43310256699721017, 'Total loss': 0.43310256699721017} | train loss {'Reaction outcome loss': 0.2259729717049625, 'Total loss': 0.2259729717049625}
2023-01-03 23:58:42,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:42,249 INFO:     Epoch: 48
2023-01-03 23:58:43,856 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4374533732732137, 'Total loss': 0.4374533732732137} | train loss {'Reaction outcome loss': 0.22152337710280995, 'Total loss': 0.22152337710280995}
2023-01-03 23:58:43,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:43,856 INFO:     Epoch: 49
2023-01-03 23:58:45,462 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4209358483552933, 'Total loss': 0.4209358483552933} | train loss {'Reaction outcome loss': 0.22243933641648556, 'Total loss': 0.22243933641648556}
2023-01-03 23:58:45,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:45,462 INFO:     Epoch: 50
2023-01-03 23:58:47,069 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4225785225629807, 'Total loss': 0.4225785225629807} | train loss {'Reaction outcome loss': 0.21785604193697483, 'Total loss': 0.21785604193697483}
2023-01-03 23:58:47,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:47,069 INFO:     Epoch: 51
2023-01-03 23:58:48,639 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41026743948459626, 'Total loss': 0.41026743948459626} | train loss {'Reaction outcome loss': 0.21750011724921373, 'Total loss': 0.21750011724921373}
2023-01-03 23:58:48,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:48,639 INFO:     Epoch: 52
2023-01-03 23:58:50,200 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4213328550259272, 'Total loss': 0.4213328550259272} | train loss {'Reaction outcome loss': 0.21632854603640325, 'Total loss': 0.21632854603640325}
2023-01-03 23:58:50,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:50,201 INFO:     Epoch: 53
2023-01-03 23:58:51,807 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44369195302327474, 'Total loss': 0.44369195302327474} | train loss {'Reaction outcome loss': 0.21268818991415667, 'Total loss': 0.21268818991415667}
2023-01-03 23:58:51,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:51,807 INFO:     Epoch: 54
2023-01-03 23:58:53,412 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.461850768327713, 'Total loss': 0.461850768327713} | train loss {'Reaction outcome loss': 0.21182784593694812, 'Total loss': 0.21182784593694812}
2023-01-03 23:58:53,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:53,412 INFO:     Epoch: 55
2023-01-03 23:58:54,983 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4438080668449402, 'Total loss': 0.4438080668449402} | train loss {'Reaction outcome loss': 0.21495059131211414, 'Total loss': 0.21495059131211414}
2023-01-03 23:58:54,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:54,983 INFO:     Epoch: 56
2023-01-03 23:58:56,587 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.439159519970417, 'Total loss': 0.439159519970417} | train loss {'Reaction outcome loss': 0.21061051166838124, 'Total loss': 0.21061051166838124}
2023-01-03 23:58:56,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:56,588 INFO:     Epoch: 57
2023-01-03 23:58:58,159 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43166760802268983, 'Total loss': 0.43166760802268983} | train loss {'Reaction outcome loss': 0.20621774755691216, 'Total loss': 0.20621774755691216}
2023-01-03 23:58:58,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:58,160 INFO:     Epoch: 58
2023-01-03 23:58:59,742 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4361320157845815, 'Total loss': 0.4361320157845815} | train loss {'Reaction outcome loss': 0.20799885499171722, 'Total loss': 0.20799885499171722}
2023-01-03 23:58:59,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:58:59,742 INFO:     Epoch: 59
2023-01-03 23:59:01,341 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4491562316815058, 'Total loss': 0.4491562316815058} | train loss {'Reaction outcome loss': 0.2134860343003011, 'Total loss': 0.2134860343003011}
2023-01-03 23:59:01,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:01,342 INFO:     Epoch: 60
2023-01-03 23:59:02,940 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4084796855847041, 'Total loss': 0.4084796855847041} | train loss {'Reaction outcome loss': 0.2030805884058768, 'Total loss': 0.2030805884058768}
2023-01-03 23:59:02,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:02,940 INFO:     Epoch: 61
2023-01-03 23:59:04,547 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4681734085083008, 'Total loss': 0.4681734085083008} | train loss {'Reaction outcome loss': 0.2045410820675311, 'Total loss': 0.2045410820675311}
2023-01-03 23:59:04,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:04,547 INFO:     Epoch: 62
2023-01-03 23:59:06,127 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43233994841575624, 'Total loss': 0.43233994841575624} | train loss {'Reaction outcome loss': 0.20270739688159345, 'Total loss': 0.20270739688159345}
2023-01-03 23:59:06,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:06,127 INFO:     Epoch: 63
2023-01-03 23:59:07,734 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4403093049923579, 'Total loss': 0.4403093049923579} | train loss {'Reaction outcome loss': 0.20227163185403024, 'Total loss': 0.20227163185403024}
2023-01-03 23:59:07,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:07,735 INFO:     Epoch: 64
2023-01-03 23:59:09,304 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46344580153624215, 'Total loss': 0.46344580153624215} | train loss {'Reaction outcome loss': 0.20031670803006316, 'Total loss': 0.20031670803006316}
2023-01-03 23:59:09,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:09,304 INFO:     Epoch: 65
2023-01-03 23:59:10,912 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4425820171833038, 'Total loss': 0.4425820171833038} | train loss {'Reaction outcome loss': 0.19641916730847114, 'Total loss': 0.19641916730847114}
2023-01-03 23:59:10,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:10,912 INFO:     Epoch: 66
2023-01-03 23:59:12,523 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4392252594232559, 'Total loss': 0.4392252594232559} | train loss {'Reaction outcome loss': 0.19674031998136596, 'Total loss': 0.19674031998136596}
2023-01-03 23:59:12,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:12,523 INFO:     Epoch: 67
2023-01-03 23:59:14,133 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45174062848091123, 'Total loss': 0.45174062848091123} | train loss {'Reaction outcome loss': 0.19342516571447088, 'Total loss': 0.19342516571447088}
2023-01-03 23:59:14,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:14,134 INFO:     Epoch: 68
2023-01-03 23:59:15,711 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4573090136051178, 'Total loss': 0.4573090136051178} | train loss {'Reaction outcome loss': 0.19382643332575267, 'Total loss': 0.19382643332575267}
2023-01-03 23:59:15,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:15,711 INFO:     Epoch: 69
2023-01-03 23:59:17,269 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46701052188873293, 'Total loss': 0.46701052188873293} | train loss {'Reaction outcome loss': 0.19401332305491845, 'Total loss': 0.19401332305491845}
2023-01-03 23:59:17,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:17,269 INFO:     Epoch: 70
2023-01-03 23:59:18,877 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44423361321290333, 'Total loss': 0.44423361321290333} | train loss {'Reaction outcome loss': 0.1964393735969023, 'Total loss': 0.1964393735969023}
2023-01-03 23:59:18,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:18,877 INFO:     Epoch: 71
2023-01-03 23:59:20,487 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42973742286364236, 'Total loss': 0.42973742286364236} | train loss {'Reaction outcome loss': 0.19373323611451157, 'Total loss': 0.19373323611451157}
2023-01-03 23:59:20,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:20,488 INFO:     Epoch: 72
2023-01-03 23:59:22,088 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4361039032538732, 'Total loss': 0.4361039032538732} | train loss {'Reaction outcome loss': 0.18827052284782622, 'Total loss': 0.18827052284782622}
2023-01-03 23:59:22,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:22,088 INFO:     Epoch: 73
2023-01-03 23:59:23,691 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4256772090991338, 'Total loss': 0.4256772090991338} | train loss {'Reaction outcome loss': 0.18884876732042422, 'Total loss': 0.18884876732042422}
2023-01-03 23:59:23,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:23,692 INFO:     Epoch: 74
2023-01-03 23:59:25,259 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46158018708229065, 'Total loss': 0.46158018708229065} | train loss {'Reaction outcome loss': 0.18975220742079366, 'Total loss': 0.18975220742079366}
2023-01-03 23:59:25,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:25,259 INFO:     Epoch: 75
2023-01-03 23:59:26,820 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4531380295753479, 'Total loss': 0.4531380295753479} | train loss {'Reaction outcome loss': 0.18587851680596887, 'Total loss': 0.18587851680596887}
2023-01-03 23:59:26,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:26,820 INFO:     Epoch: 76
2023-01-03 23:59:28,429 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45553504129250844, 'Total loss': 0.45553504129250844} | train loss {'Reaction outcome loss': 0.18551615872949143, 'Total loss': 0.18551615872949143}
2023-01-03 23:59:28,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:28,429 INFO:     Epoch: 77
2023-01-03 23:59:30,013 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4708516736825307, 'Total loss': 0.4708516736825307} | train loss {'Reaction outcome loss': 0.18769516149747284, 'Total loss': 0.18769516149747284}
2023-01-03 23:59:30,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:30,013 INFO:     Epoch: 78
2023-01-03 23:59:31,622 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43291435365875564, 'Total loss': 0.43291435365875564} | train loss {'Reaction outcome loss': 0.18384974752808667, 'Total loss': 0.18384974752808667}
2023-01-03 23:59:31,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:31,622 INFO:     Epoch: 79
2023-01-03 23:59:33,210 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4610482811927795, 'Total loss': 0.4610482811927795} | train loss {'Reaction outcome loss': 0.18241594431601166, 'Total loss': 0.18241594431601166}
2023-01-03 23:59:33,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:33,210 INFO:     Epoch: 80
2023-01-03 23:59:34,787 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45150880217552186, 'Total loss': 0.45150880217552186} | train loss {'Reaction outcome loss': 0.18414026517898607, 'Total loss': 0.18414026517898607}
2023-01-03 23:59:34,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:34,787 INFO:     Epoch: 81
2023-01-03 23:59:36,346 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4821684807538986, 'Total loss': 0.4821684807538986} | train loss {'Reaction outcome loss': 0.18267743198726422, 'Total loss': 0.18267743198726422}
2023-01-03 23:59:36,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:36,346 INFO:     Epoch: 82
2023-01-03 23:59:37,923 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44818536440531415, 'Total loss': 0.44818536440531415} | train loss {'Reaction outcome loss': 0.17940854333040915, 'Total loss': 0.17940854333040915}
2023-01-03 23:59:37,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:37,924 INFO:     Epoch: 83
2023-01-03 23:59:39,501 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4438804298639297, 'Total loss': 0.4438804298639297} | train loss {'Reaction outcome loss': 0.18112180482309598, 'Total loss': 0.18112180482309598}
2023-01-03 23:59:39,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:39,501 INFO:     Epoch: 84
2023-01-03 23:59:41,079 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4354074609776338, 'Total loss': 0.4354074609776338} | train loss {'Reaction outcome loss': 0.17859479660106883, 'Total loss': 0.17859479660106883}
2023-01-03 23:59:41,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:41,079 INFO:     Epoch: 85
2023-01-03 23:59:42,653 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44434279253085457, 'Total loss': 0.44434279253085457} | train loss {'Reaction outcome loss': 0.18054500100758922, 'Total loss': 0.18054500100758922}
2023-01-03 23:59:42,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:42,654 INFO:     Epoch: 86
2023-01-03 23:59:44,243 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.456686994433403, 'Total loss': 0.456686994433403} | train loss {'Reaction outcome loss': 0.17897266141333423, 'Total loss': 0.17897266141333423}
2023-01-03 23:59:44,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:44,244 INFO:     Epoch: 87
2023-01-03 23:59:45,822 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45874903599421185, 'Total loss': 0.45874903599421185} | train loss {'Reaction outcome loss': 0.17995637226440422, 'Total loss': 0.17995637226440422}
2023-01-03 23:59:45,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:45,822 INFO:     Epoch: 88
2023-01-03 23:59:47,403 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45430813630421957, 'Total loss': 0.45430813630421957} | train loss {'Reaction outcome loss': 0.17431941661717637, 'Total loss': 0.17431941661717637}
2023-01-03 23:59:47,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:47,403 INFO:     Epoch: 89
2023-01-03 23:59:48,984 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48323024312655133, 'Total loss': 0.48323024312655133} | train loss {'Reaction outcome loss': 0.1751864092636021, 'Total loss': 0.1751864092636021}
2023-01-03 23:59:48,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:48,985 INFO:     Epoch: 90
2023-01-03 23:59:50,560 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44493671258290607, 'Total loss': 0.44493671258290607} | train loss {'Reaction outcome loss': 0.1752727173214212, 'Total loss': 0.1752727173214212}
2023-01-03 23:59:50,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:50,560 INFO:     Epoch: 91
2023-01-03 23:59:52,136 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43332514222711327, 'Total loss': 0.43332514222711327} | train loss {'Reaction outcome loss': 0.17139492241577023, 'Total loss': 0.17139492241577023}
2023-01-03 23:59:52,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:52,136 INFO:     Epoch: 92
2023-01-03 23:59:53,696 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44493419031302134, 'Total loss': 0.44493419031302134} | train loss {'Reaction outcome loss': 0.17598333886582337, 'Total loss': 0.17598333886582337}
2023-01-03 23:59:53,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:53,696 INFO:     Epoch: 93
2023-01-03 23:59:55,278 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48064877490202584, 'Total loss': 0.48064877490202584} | train loss {'Reaction outcome loss': 0.172461628054197, 'Total loss': 0.172461628054197}
2023-01-03 23:59:55,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:55,279 INFO:     Epoch: 94
2023-01-03 23:59:56,860 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45219165707627934, 'Total loss': 0.45219165707627934} | train loss {'Reaction outcome loss': 0.17220962046894617, 'Total loss': 0.17220962046894617}
2023-01-03 23:59:56,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:56,861 INFO:     Epoch: 95
2023-01-03 23:59:58,443 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49123643736044564, 'Total loss': 0.49123643736044564} | train loss {'Reaction outcome loss': 0.17095288871565745, 'Total loss': 0.17095288871565745}
2023-01-03 23:59:58,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-03 23:59:58,443 INFO:     Epoch: 96
2023-01-04 00:00:00,025 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4533897707859675, 'Total loss': 0.4533897707859675} | train loss {'Reaction outcome loss': 0.17504552157165912, 'Total loss': 0.17504552157165912}
2023-01-04 00:00:00,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:00,025 INFO:     Epoch: 97
2023-01-04 00:00:01,604 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46129307746887205, 'Total loss': 0.46129307746887205} | train loss {'Reaction outcome loss': 0.16827389096752518, 'Total loss': 0.16827389096752518}
2023-01-04 00:00:01,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:01,604 INFO:     Epoch: 98
2023-01-04 00:00:03,175 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4348500698804855, 'Total loss': 0.4348500698804855} | train loss {'Reaction outcome loss': 0.16733237746216, 'Total loss': 0.16733237746216}
2023-01-04 00:00:03,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:03,175 INFO:     Epoch: 99
2023-01-04 00:00:04,755 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4486585815747579, 'Total loss': 0.4486585815747579} | train loss {'Reaction outcome loss': 0.16986148675473836, 'Total loss': 0.16986148675473836}
2023-01-04 00:00:04,755 INFO:     Best model found after epoch 40 of 100.
2023-01-04 00:00:04,755 INFO:   Done with stage: TRAINING
2023-01-04 00:00:04,756 INFO:   Starting stage: EVALUATION
2023-01-04 00:00:04,896 INFO:   Done with stage: EVALUATION
2023-01-04 00:00:04,911 INFO:   Leaving out SEQ value Fold_4
2023-01-04 00:00:04,924 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 00:00:04,924 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:00:05,569 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:00:05,570 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:00:05,640 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:00:05,640 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:00:05,640 INFO:     No hyperparam tuning for this model
2023-01-04 00:00:05,640 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:00:05,640 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:00:05,641 INFO:     None feature selector for col prot
2023-01-04 00:00:05,641 INFO:     None feature selector for col prot
2023-01-04 00:00:05,641 INFO:     None feature selector for col prot
2023-01-04 00:00:05,641 INFO:     None feature selector for col chem
2023-01-04 00:00:05,641 INFO:     None feature selector for col chem
2023-01-04 00:00:05,642 INFO:     None feature selector for col chem
2023-01-04 00:00:05,642 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:00:05,642 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:00:05,643 INFO:     Number of params in model 70141
2023-01-04 00:00:05,646 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:00:05,646 INFO:   Starting stage: TRAINING
2023-01-04 00:00:05,692 INFO:     Val loss before train {'Reaction outcome loss': 1.0578578988711038, 'Total loss': 1.0578578988711038}
2023-01-04 00:00:05,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:05,692 INFO:     Epoch: 0
2023-01-04 00:00:07,305 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7009191354115804, 'Total loss': 0.7009191354115804} | train loss {'Reaction outcome loss': 0.8486776588625856, 'Total loss': 0.8486776588625856}
2023-01-04 00:00:07,305 INFO:     Found new best model at epoch 0
2023-01-04 00:00:07,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:07,306 INFO:     Epoch: 1
2023-01-04 00:00:08,893 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6070891777674358, 'Total loss': 0.6070891777674358} | train loss {'Reaction outcome loss': 0.6102719154168552, 'Total loss': 0.6102719154168552}
2023-01-04 00:00:08,895 INFO:     Found new best model at epoch 1
2023-01-04 00:00:08,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:08,896 INFO:     Epoch: 2
2023-01-04 00:00:10,489 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5815723359584808, 'Total loss': 0.5815723359584808} | train loss {'Reaction outcome loss': 0.5429350735908811, 'Total loss': 0.5429350735908811}
2023-01-04 00:00:10,489 INFO:     Found new best model at epoch 2
2023-01-04 00:00:10,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:10,490 INFO:     Epoch: 3
2023-01-04 00:00:12,078 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5705525517463684, 'Total loss': 0.5705525517463684} | train loss {'Reaction outcome loss': 0.5074012678398983, 'Total loss': 0.5074012678398983}
2023-01-04 00:00:12,078 INFO:     Found new best model at epoch 3
2023-01-04 00:00:12,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:12,079 INFO:     Epoch: 4
2023-01-04 00:00:13,681 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5376489758491516, 'Total loss': 0.5376489758491516} | train loss {'Reaction outcome loss': 0.47597828297623657, 'Total loss': 0.47597828297623657}
2023-01-04 00:00:13,681 INFO:     Found new best model at epoch 4
2023-01-04 00:00:13,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:13,682 INFO:     Epoch: 5
2023-01-04 00:00:15,286 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5232316732406617, 'Total loss': 0.5232316732406617} | train loss {'Reaction outcome loss': 0.4554555662487388, 'Total loss': 0.4554555662487388}
2023-01-04 00:00:15,287 INFO:     Found new best model at epoch 5
2023-01-04 00:00:15,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:15,288 INFO:     Epoch: 6
2023-01-04 00:00:16,891 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5081526696681976, 'Total loss': 0.5081526696681976} | train loss {'Reaction outcome loss': 0.4372870809657479, 'Total loss': 0.4372870809657479}
2023-01-04 00:00:16,891 INFO:     Found new best model at epoch 6
2023-01-04 00:00:16,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:16,892 INFO:     Epoch: 7
2023-01-04 00:00:18,490 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.501300964752833, 'Total loss': 0.501300964752833} | train loss {'Reaction outcome loss': 0.4204389217313016, 'Total loss': 0.4204389217313016}
2023-01-04 00:00:18,490 INFO:     Found new best model at epoch 7
2023-01-04 00:00:18,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:18,491 INFO:     Epoch: 8
2023-01-04 00:00:20,074 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5043456037839253, 'Total loss': 0.5043456037839253} | train loss {'Reaction outcome loss': 0.4101656206248039, 'Total loss': 0.4101656206248039}
2023-01-04 00:00:20,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:20,074 INFO:     Epoch: 9
2023-01-04 00:00:21,706 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48317246039708456, 'Total loss': 0.48317246039708456} | train loss {'Reaction outcome loss': 0.3965837162001469, 'Total loss': 0.3965837162001469}
2023-01-04 00:00:21,706 INFO:     Found new best model at epoch 9
2023-01-04 00:00:21,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:21,707 INFO:     Epoch: 10
2023-01-04 00:00:23,340 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48447398145993553, 'Total loss': 0.48447398145993553} | train loss {'Reaction outcome loss': 0.3865759643837003, 'Total loss': 0.3865759643837003}
2023-01-04 00:00:23,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:23,340 INFO:     Epoch: 11
2023-01-04 00:00:24,973 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46851919690767924, 'Total loss': 0.46851919690767924} | train loss {'Reaction outcome loss': 0.3773124624137844, 'Total loss': 0.3773124624137844}
2023-01-04 00:00:24,973 INFO:     Found new best model at epoch 11
2023-01-04 00:00:24,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:24,974 INFO:     Epoch: 12
2023-01-04 00:00:26,570 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46299984157085416, 'Total loss': 0.46299984157085416} | train loss {'Reaction outcome loss': 0.36818166553221027, 'Total loss': 0.36818166553221027}
2023-01-04 00:00:26,570 INFO:     Found new best model at epoch 12
2023-01-04 00:00:26,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:26,571 INFO:     Epoch: 13
2023-01-04 00:00:28,188 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4622133791446686, 'Total loss': 0.4622133791446686} | train loss {'Reaction outcome loss': 0.36000644316096597, 'Total loss': 0.36000644316096597}
2023-01-04 00:00:28,189 INFO:     Found new best model at epoch 13
2023-01-04 00:00:28,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:28,190 INFO:     Epoch: 14
2023-01-04 00:00:29,771 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4661863307158152, 'Total loss': 0.4661863307158152} | train loss {'Reaction outcome loss': 0.3536673799049553, 'Total loss': 0.3536673799049553}
2023-01-04 00:00:29,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:29,771 INFO:     Epoch: 15
2023-01-04 00:00:31,398 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4663859248161316, 'Total loss': 0.4663859248161316} | train loss {'Reaction outcome loss': 0.34824376924481204, 'Total loss': 0.34824376924481204}
2023-01-04 00:00:31,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:31,398 INFO:     Epoch: 16
2023-01-04 00:00:33,023 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46088341772556307, 'Total loss': 0.46088341772556307} | train loss {'Reaction outcome loss': 0.3395151183923659, 'Total loss': 0.3395151183923659}
2023-01-04 00:00:33,023 INFO:     Found new best model at epoch 16
2023-01-04 00:00:33,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:33,024 INFO:     Epoch: 17
2023-01-04 00:00:34,655 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47636315822601316, 'Total loss': 0.47636315822601316} | train loss {'Reaction outcome loss': 0.33544269185311526, 'Total loss': 0.33544269185311526}
2023-01-04 00:00:34,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:34,655 INFO:     Epoch: 18
2023-01-04 00:00:36,269 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45853371620178224, 'Total loss': 0.45853371620178224} | train loss {'Reaction outcome loss': 0.3278318498592945, 'Total loss': 0.3278318498592945}
2023-01-04 00:00:36,270 INFO:     Found new best model at epoch 18
2023-01-04 00:00:36,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:36,270 INFO:     Epoch: 19
2023-01-04 00:00:37,859 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4529971758524577, 'Total loss': 0.4529971758524577} | train loss {'Reaction outcome loss': 0.3229256505785436, 'Total loss': 0.3229256505785436}
2023-01-04 00:00:37,859 INFO:     Found new best model at epoch 19
2023-01-04 00:00:37,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:37,860 INFO:     Epoch: 20
2023-01-04 00:00:39,498 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46462348600228626, 'Total loss': 0.46462348600228626} | train loss {'Reaction outcome loss': 0.3167712215320728, 'Total loss': 0.3167712215320728}
2023-01-04 00:00:39,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:39,499 INFO:     Epoch: 21
2023-01-04 00:00:41,133 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45536627372105914, 'Total loss': 0.45536627372105914} | train loss {'Reaction outcome loss': 0.30915442075486216, 'Total loss': 0.30915442075486216}
2023-01-04 00:00:41,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:41,133 INFO:     Epoch: 22
2023-01-04 00:00:42,747 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47733537554740907, 'Total loss': 0.47733537554740907} | train loss {'Reaction outcome loss': 0.30651494726162093, 'Total loss': 0.30651494726162093}
2023-01-04 00:00:42,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:42,747 INFO:     Epoch: 23
2023-01-04 00:00:44,376 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46405049959818523, 'Total loss': 0.46405049959818523} | train loss {'Reaction outcome loss': 0.30340194694079214, 'Total loss': 0.30340194694079214}
2023-01-04 00:00:44,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:44,376 INFO:     Epoch: 24
2023-01-04 00:00:45,981 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4362174034118652, 'Total loss': 0.4362174034118652} | train loss {'Reaction outcome loss': 0.29803670186966336, 'Total loss': 0.29803670186966336}
2023-01-04 00:00:45,982 INFO:     Found new best model at epoch 24
2023-01-04 00:00:45,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:45,983 INFO:     Epoch: 25
2023-01-04 00:00:47,575 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.442736675341924, 'Total loss': 0.442736675341924} | train loss {'Reaction outcome loss': 0.29125567114094963, 'Total loss': 0.29125567114094963}
2023-01-04 00:00:47,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:47,576 INFO:     Epoch: 26
2023-01-04 00:00:49,201 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44139450788497925, 'Total loss': 0.44139450788497925} | train loss {'Reaction outcome loss': 0.28889187886665446, 'Total loss': 0.28889187886665446}
2023-01-04 00:00:49,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:49,201 INFO:     Epoch: 27
2023-01-04 00:00:50,861 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46367269158363345, 'Total loss': 0.46367269158363345} | train loss {'Reaction outcome loss': 0.28304256826961943, 'Total loss': 0.28304256826961943}
2023-01-04 00:00:50,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:50,862 INFO:     Epoch: 28
2023-01-04 00:00:52,466 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44074761867523193, 'Total loss': 0.44074761867523193} | train loss {'Reaction outcome loss': 0.2805714069963147, 'Total loss': 0.2805714069963147}
2023-01-04 00:00:52,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:52,466 INFO:     Epoch: 29
2023-01-04 00:00:54,062 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43339201509952546, 'Total loss': 0.43339201509952546} | train loss {'Reaction outcome loss': 0.27803580994156296, 'Total loss': 0.27803580994156296}
2023-01-04 00:00:54,063 INFO:     Found new best model at epoch 29
2023-01-04 00:00:54,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:54,063 INFO:     Epoch: 30
2023-01-04 00:00:55,690 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42166599035263064, 'Total loss': 0.42166599035263064} | train loss {'Reaction outcome loss': 0.2724559142082822, 'Total loss': 0.2724559142082822}
2023-01-04 00:00:55,690 INFO:     Found new best model at epoch 30
2023-01-04 00:00:55,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:55,691 INFO:     Epoch: 31
2023-01-04 00:00:57,279 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4264901280403137, 'Total loss': 0.4264901280403137} | train loss {'Reaction outcome loss': 0.2692235730292565, 'Total loss': 0.2692235730292565}
2023-01-04 00:00:57,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:57,280 INFO:     Epoch: 32
2023-01-04 00:00:58,914 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4407750417788823, 'Total loss': 0.4407750417788823} | train loss {'Reaction outcome loss': 0.26668228071841954, 'Total loss': 0.26668228071841954}
2023-01-04 00:00:58,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:00:58,915 INFO:     Epoch: 33
2023-01-04 00:01:00,526 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43639407455921175, 'Total loss': 0.43639407455921175} | train loss {'Reaction outcome loss': 0.26407741475514124, 'Total loss': 0.26407741475514124}
2023-01-04 00:01:00,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:00,526 INFO:     Epoch: 34
2023-01-04 00:01:02,149 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43364882866541543, 'Total loss': 0.43364882866541543} | train loss {'Reaction outcome loss': 0.261202225132109, 'Total loss': 0.261202225132109}
2023-01-04 00:01:02,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:02,149 INFO:     Epoch: 35
2023-01-04 00:01:03,760 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4655951976776123, 'Total loss': 0.4655951976776123} | train loss {'Reaction outcome loss': 0.25578532168903934, 'Total loss': 0.25578532168903934}
2023-01-04 00:01:03,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:03,761 INFO:     Epoch: 36
2023-01-04 00:01:05,370 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43401549408833184, 'Total loss': 0.43401549408833184} | train loss {'Reaction outcome loss': 0.2549237061278484, 'Total loss': 0.2549237061278484}
2023-01-04 00:01:05,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:05,371 INFO:     Epoch: 37
2023-01-04 00:01:06,987 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4212863822778066, 'Total loss': 0.4212863822778066} | train loss {'Reaction outcome loss': 0.2542365919462395, 'Total loss': 0.2542365919462395}
2023-01-04 00:01:06,987 INFO:     Found new best model at epoch 37
2023-01-04 00:01:06,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:06,988 INFO:     Epoch: 38
2023-01-04 00:01:08,615 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43469878832499187, 'Total loss': 0.43469878832499187} | train loss {'Reaction outcome loss': 0.2489293118676554, 'Total loss': 0.2489293118676554}
2023-01-04 00:01:08,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:08,615 INFO:     Epoch: 39
2023-01-04 00:01:10,258 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4450689315795898, 'Total loss': 0.4450689315795898} | train loss {'Reaction outcome loss': 0.24630792853203923, 'Total loss': 0.24630792853203923}
2023-01-04 00:01:10,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:10,259 INFO:     Epoch: 40
2023-01-04 00:01:11,850 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4204797863960266, 'Total loss': 0.4204797863960266} | train loss {'Reaction outcome loss': 0.2439078035014631, 'Total loss': 0.2439078035014631}
2023-01-04 00:01:11,850 INFO:     Found new best model at epoch 40
2023-01-04 00:01:11,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:11,851 INFO:     Epoch: 41
2023-01-04 00:01:13,475 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43821921249230705, 'Total loss': 0.43821921249230705} | train loss {'Reaction outcome loss': 0.24190057257345007, 'Total loss': 0.24190057257345007}
2023-01-04 00:01:13,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:13,475 INFO:     Epoch: 42
2023-01-04 00:01:15,069 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45062602162361143, 'Total loss': 0.45062602162361143} | train loss {'Reaction outcome loss': 0.2395166500273164, 'Total loss': 0.2395166500273164}
2023-01-04 00:01:15,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:15,069 INFO:     Epoch: 43
2023-01-04 00:01:16,674 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43491580883661907, 'Total loss': 0.43491580883661907} | train loss {'Reaction outcome loss': 0.23695953449886628, 'Total loss': 0.23695953449886628}
2023-01-04 00:01:16,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:16,675 INFO:     Epoch: 44
2023-01-04 00:01:18,300 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41898157993952434, 'Total loss': 0.41898157993952434} | train loss {'Reaction outcome loss': 0.2345981094918957, 'Total loss': 0.2345981094918957}
2023-01-04 00:01:18,300 INFO:     Found new best model at epoch 44
2023-01-04 00:01:18,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:18,301 INFO:     Epoch: 45
2023-01-04 00:01:19,900 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4450484057267507, 'Total loss': 0.4450484057267507} | train loss {'Reaction outcome loss': 0.23450959758960813, 'Total loss': 0.23450959758960813}
2023-01-04 00:01:19,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:19,900 INFO:     Epoch: 46
2023-01-04 00:01:21,500 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4274150977532069, 'Total loss': 0.4274150977532069} | train loss {'Reaction outcome loss': 0.23319084351942856, 'Total loss': 0.23319084351942856}
2023-01-04 00:01:21,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:21,500 INFO:     Epoch: 47
2023-01-04 00:01:23,114 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43117891401052477, 'Total loss': 0.43117891401052477} | train loss {'Reaction outcome loss': 0.22851214934449765, 'Total loss': 0.22851214934449765}
2023-01-04 00:01:23,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:23,115 INFO:     Epoch: 48
2023-01-04 00:01:24,763 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4142551213502884, 'Total loss': 0.4142551213502884} | train loss {'Reaction outcome loss': 0.22570463810586758, 'Total loss': 0.22570463810586758}
2023-01-04 00:01:24,763 INFO:     Found new best model at epoch 48
2023-01-04 00:01:24,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:24,764 INFO:     Epoch: 49
2023-01-04 00:01:26,398 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4361362814903259, 'Total loss': 0.4361362814903259} | train loss {'Reaction outcome loss': 0.22718125889716595, 'Total loss': 0.22718125889716595}
2023-01-04 00:01:26,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:26,398 INFO:     Epoch: 50
2023-01-04 00:01:28,030 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41850110292434695, 'Total loss': 0.41850110292434695} | train loss {'Reaction outcome loss': 0.2247125198022338, 'Total loss': 0.2247125198022338}
2023-01-04 00:01:28,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:28,030 INFO:     Epoch: 51
2023-01-04 00:01:29,638 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43072711328665414, 'Total loss': 0.43072711328665414} | train loss {'Reaction outcome loss': 0.2246779848280151, 'Total loss': 0.2246779848280151}
2023-01-04 00:01:29,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:29,639 INFO:     Epoch: 52
2023-01-04 00:01:31,256 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45912789901097617, 'Total loss': 0.45912789901097617} | train loss {'Reaction outcome loss': 0.22186776624474716, 'Total loss': 0.22186776624474716}
2023-01-04 00:01:31,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:31,256 INFO:     Epoch: 53
2023-01-04 00:01:32,857 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4582151581843694, 'Total loss': 0.4582151581843694} | train loss {'Reaction outcome loss': 0.21893168751836253, 'Total loss': 0.21893168751836253}
2023-01-04 00:01:32,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:32,857 INFO:     Epoch: 54
2023-01-04 00:01:34,504 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4299580131967862, 'Total loss': 0.4299580131967862} | train loss {'Reaction outcome loss': 0.21897318561154583, 'Total loss': 0.21897318561154583}
2023-01-04 00:01:34,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:34,505 INFO:     Epoch: 55
2023-01-04 00:01:36,120 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4367594579855601, 'Total loss': 0.4367594579855601} | train loss {'Reaction outcome loss': 0.21582170442715018, 'Total loss': 0.21582170442715018}
2023-01-04 00:01:36,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:36,120 INFO:     Epoch: 56
2023-01-04 00:01:37,705 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4493667831023534, 'Total loss': 0.4493667831023534} | train loss {'Reaction outcome loss': 0.21378161431380988, 'Total loss': 0.21378161431380988}
2023-01-04 00:01:37,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:37,706 INFO:     Epoch: 57
2023-01-04 00:01:39,301 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42951394319534303, 'Total loss': 0.42951394319534303} | train loss {'Reaction outcome loss': 0.21227048057726575, 'Total loss': 0.21227048057726575}
2023-01-04 00:01:39,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:39,302 INFO:     Epoch: 58
2023-01-04 00:01:40,944 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4486751769979795, 'Total loss': 0.4486751769979795} | train loss {'Reaction outcome loss': 0.2109748583408039, 'Total loss': 0.2109748583408039}
2023-01-04 00:01:40,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:40,946 INFO:     Epoch: 59
2023-01-04 00:01:42,555 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4337878356377284, 'Total loss': 0.4337878356377284} | train loss {'Reaction outcome loss': 0.2089419784528684, 'Total loss': 0.2089419784528684}
2023-01-04 00:01:42,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:42,556 INFO:     Epoch: 60
2023-01-04 00:01:44,192 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.434050452709198, 'Total loss': 0.434050452709198} | train loss {'Reaction outcome loss': 0.2067149851726711, 'Total loss': 0.2067149851726711}
2023-01-04 00:01:44,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:44,192 INFO:     Epoch: 61
2023-01-04 00:01:45,834 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45545230209827425, 'Total loss': 0.45545230209827425} | train loss {'Reaction outcome loss': 0.20684664978877731, 'Total loss': 0.20684664978877731}
2023-01-04 00:01:45,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:45,834 INFO:     Epoch: 62
2023-01-04 00:01:47,456 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44829279830058416, 'Total loss': 0.44829279830058416} | train loss {'Reaction outcome loss': 0.20542798898038236, 'Total loss': 0.20542798898038236}
2023-01-04 00:01:47,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:47,457 INFO:     Epoch: 63
2023-01-04 00:01:49,037 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45302472909291586, 'Total loss': 0.45302472909291586} | train loss {'Reaction outcome loss': 0.2044013623511318, 'Total loss': 0.2044013623511318}
2023-01-04 00:01:49,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:49,037 INFO:     Epoch: 64
2023-01-04 00:01:50,642 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4469661941130956, 'Total loss': 0.4469661941130956} | train loss {'Reaction outcome loss': 0.20196125329562903, 'Total loss': 0.20196125329562903}
2023-01-04 00:01:50,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:50,642 INFO:     Epoch: 65
2023-01-04 00:01:52,274 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4354471137126287, 'Total loss': 0.4354471137126287} | train loss {'Reaction outcome loss': 0.20403371386848632, 'Total loss': 0.20403371386848632}
2023-01-04 00:01:52,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:52,274 INFO:     Epoch: 66
2023-01-04 00:01:53,900 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4374052494764328, 'Total loss': 0.4374052494764328} | train loss {'Reaction outcome loss': 0.1991119011429673, 'Total loss': 0.1991119011429673}
2023-01-04 00:01:53,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:53,901 INFO:     Epoch: 67
2023-01-04 00:01:55,540 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45140289266904193, 'Total loss': 0.45140289266904193} | train loss {'Reaction outcome loss': 0.2006095042620325, 'Total loss': 0.2006095042620325}
2023-01-04 00:01:55,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:55,540 INFO:     Epoch: 68
2023-01-04 00:01:57,148 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45493869682153065, 'Total loss': 0.45493869682153065} | train loss {'Reaction outcome loss': 0.2015291668662956, 'Total loss': 0.2015291668662956}
2023-01-04 00:01:57,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:57,148 INFO:     Epoch: 69
2023-01-04 00:01:58,774 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4429855585098267, 'Total loss': 0.4429855585098267} | train loss {'Reaction outcome loss': 0.1965761492667646, 'Total loss': 0.1965761492667646}
2023-01-04 00:01:58,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:01:58,775 INFO:     Epoch: 70
2023-01-04 00:02:00,355 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46359064082304635, 'Total loss': 0.46359064082304635} | train loss {'Reaction outcome loss': 0.19644720483544392, 'Total loss': 0.19644720483544392}
2023-01-04 00:02:00,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:00,356 INFO:     Epoch: 71
2023-01-04 00:02:01,958 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4525100847085317, 'Total loss': 0.4525100847085317} | train loss {'Reaction outcome loss': 0.19312181218866836, 'Total loss': 0.19312181218866836}
2023-01-04 00:02:01,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:01,958 INFO:     Epoch: 72
2023-01-04 00:02:03,560 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44525380233923595, 'Total loss': 0.44525380233923595} | train loss {'Reaction outcome loss': 0.19175261969170415, 'Total loss': 0.19175261969170415}
2023-01-04 00:02:03,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:03,560 INFO:     Epoch: 73
2023-01-04 00:02:05,159 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42779452552398045, 'Total loss': 0.42779452552398045} | train loss {'Reaction outcome loss': 0.19416183018081887, 'Total loss': 0.19416183018081887}
2023-01-04 00:02:05,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:05,160 INFO:     Epoch: 74
2023-01-04 00:02:06,759 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4506521910429001, 'Total loss': 0.4506521910429001} | train loss {'Reaction outcome loss': 0.19182266285542116, 'Total loss': 0.19182266285542116}
2023-01-04 00:02:06,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:06,759 INFO:     Epoch: 75
2023-01-04 00:02:08,339 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4403968920310338, 'Total loss': 0.4403968920310338} | train loss {'Reaction outcome loss': 0.18990762755678234, 'Total loss': 0.18990762755678234}
2023-01-04 00:02:08,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:08,340 INFO:     Epoch: 76
2023-01-04 00:02:09,978 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44735500613848367, 'Total loss': 0.44735500613848367} | train loss {'Reaction outcome loss': 0.18930127415200865, 'Total loss': 0.18930127415200865}
2023-01-04 00:02:09,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:09,978 INFO:     Epoch: 77
2023-01-04 00:02:11,612 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47636291682720183, 'Total loss': 0.47636291682720183} | train loss {'Reaction outcome loss': 0.19001127049891742, 'Total loss': 0.19001127049891742}
2023-01-04 00:02:11,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:11,613 INFO:     Epoch: 78
2023-01-04 00:02:13,249 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4335279067357381, 'Total loss': 0.4335279067357381} | train loss {'Reaction outcome loss': 0.18924284339731134, 'Total loss': 0.18924284339731134}
2023-01-04 00:02:13,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:13,249 INFO:     Epoch: 79
2023-01-04 00:02:14,865 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4464498827854792, 'Total loss': 0.4464498827854792} | train loss {'Reaction outcome loss': 0.18788625905122136, 'Total loss': 0.18788625905122136}
2023-01-04 00:02:14,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:14,865 INFO:     Epoch: 80
2023-01-04 00:02:16,496 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44819157881041366, 'Total loss': 0.44819157881041366} | train loss {'Reaction outcome loss': 0.18823772473832331, 'Total loss': 0.18823772473832331}
2023-01-04 00:02:16,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:16,496 INFO:     Epoch: 81
2023-01-04 00:02:18,112 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4337422450383504, 'Total loss': 0.4337422450383504} | train loss {'Reaction outcome loss': 0.18964797021007496, 'Total loss': 0.18964797021007496}
2023-01-04 00:02:18,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:18,112 INFO:     Epoch: 82
2023-01-04 00:02:19,744 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46353556513786315, 'Total loss': 0.46353556513786315} | train loss {'Reaction outcome loss': 0.18551686470689327, 'Total loss': 0.18551686470689327}
2023-01-04 00:02:19,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:19,745 INFO:     Epoch: 83
2023-01-04 00:02:21,380 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4363069196542104, 'Total loss': 0.4363069196542104} | train loss {'Reaction outcome loss': 0.18456835172640074, 'Total loss': 0.18456835172640074}
2023-01-04 00:02:21,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:21,380 INFO:     Epoch: 84
2023-01-04 00:02:23,015 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46483306884765624, 'Total loss': 0.46483306884765624} | train loss {'Reaction outcome loss': 0.1826708115072457, 'Total loss': 0.1826708115072457}
2023-01-04 00:02:23,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:23,016 INFO:     Epoch: 85
2023-01-04 00:02:24,624 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4511512110630671, 'Total loss': 0.4511512110630671} | train loss {'Reaction outcome loss': 0.18225417669445598, 'Total loss': 0.18225417669445598}
2023-01-04 00:02:24,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:24,624 INFO:     Epoch: 86
2023-01-04 00:02:26,210 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46069639722506206, 'Total loss': 0.46069639722506206} | train loss {'Reaction outcome loss': 0.18106313243454544, 'Total loss': 0.18106313243454544}
2023-01-04 00:02:26,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:26,211 INFO:     Epoch: 87
2023-01-04 00:02:27,829 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4313649003704389, 'Total loss': 0.4313649003704389} | train loss {'Reaction outcome loss': 0.17921604509280475, 'Total loss': 0.17921604509280475}
2023-01-04 00:02:27,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:27,829 INFO:     Epoch: 88
2023-01-04 00:02:29,476 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.480057555437088, 'Total loss': 0.480057555437088} | train loss {'Reaction outcome loss': 0.1783444073676579, 'Total loss': 0.1783444073676579}
2023-01-04 00:02:29,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:29,476 INFO:     Epoch: 89
2023-01-04 00:02:31,116 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4340771387020747, 'Total loss': 0.4340771387020747} | train loss {'Reaction outcome loss': 0.1796195297249818, 'Total loss': 0.1796195297249818}
2023-01-04 00:02:31,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:31,117 INFO:     Epoch: 90
2023-01-04 00:02:32,705 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4603469789028168, 'Total loss': 0.4603469789028168} | train loss {'Reaction outcome loss': 0.18100239661949205, 'Total loss': 0.18100239661949205}
2023-01-04 00:02:32,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:32,706 INFO:     Epoch: 91
2023-01-04 00:02:34,275 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48606550296147666, 'Total loss': 0.48606550296147666} | train loss {'Reaction outcome loss': 0.1786910960726467, 'Total loss': 0.1786910960726467}
2023-01-04 00:02:34,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:34,276 INFO:     Epoch: 92
2023-01-04 00:02:35,855 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4726536770661672, 'Total loss': 0.4726536770661672} | train loss {'Reaction outcome loss': 0.179927939750819, 'Total loss': 0.179927939750819}
2023-01-04 00:02:35,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:35,855 INFO:     Epoch: 93
2023-01-04 00:02:37,463 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43899791141351063, 'Total loss': 0.43899791141351063} | train loss {'Reaction outcome loss': 0.17542976288911669, 'Total loss': 0.17542976288911669}
2023-01-04 00:02:37,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:37,463 INFO:     Epoch: 94
2023-01-04 00:02:39,057 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4546628495057424, 'Total loss': 0.4546628495057424} | train loss {'Reaction outcome loss': 0.17656085696676577, 'Total loss': 0.17656085696676577}
2023-01-04 00:02:39,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:39,057 INFO:     Epoch: 95
2023-01-04 00:02:40,686 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4705253342787425, 'Total loss': 0.4705253342787425} | train loss {'Reaction outcome loss': 0.1770035659201739, 'Total loss': 0.1770035659201739}
2023-01-04 00:02:40,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:40,686 INFO:     Epoch: 96
2023-01-04 00:02:42,276 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4527612934509913, 'Total loss': 0.4527612934509913} | train loss {'Reaction outcome loss': 0.17485398048743445, 'Total loss': 0.17485398048743445}
2023-01-04 00:02:42,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:42,277 INFO:     Epoch: 97
2023-01-04 00:02:43,890 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4712152739365896, 'Total loss': 0.4712152739365896} | train loss {'Reaction outcome loss': 0.1764836227016974, 'Total loss': 0.1764836227016974}
2023-01-04 00:02:43,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:43,891 INFO:     Epoch: 98
2023-01-04 00:02:45,501 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44165509144465126, 'Total loss': 0.44165509144465126} | train loss {'Reaction outcome loss': 0.17205942526379, 'Total loss': 0.17205942526379}
2023-01-04 00:02:45,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:45,501 INFO:     Epoch: 99
2023-01-04 00:02:47,143 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4754476914803187, 'Total loss': 0.4754476914803187} | train loss {'Reaction outcome loss': 0.17283903215658794, 'Total loss': 0.17283903215658794}
2023-01-04 00:02:47,143 INFO:     Best model found after epoch 49 of 100.
2023-01-04 00:02:47,143 INFO:   Done with stage: TRAINING
2023-01-04 00:02:47,143 INFO:   Starting stage: EVALUATION
2023-01-04 00:02:47,267 INFO:   Done with stage: EVALUATION
2023-01-04 00:02:47,267 INFO:   Leaving out SEQ value Fold_5
2023-01-04 00:02:47,280 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 00:02:47,280 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:02:47,937 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:02:47,937 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:02:48,008 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:02:48,008 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:02:48,008 INFO:     No hyperparam tuning for this model
2023-01-04 00:02:48,008 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:02:48,008 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:02:48,009 INFO:     None feature selector for col prot
2023-01-04 00:02:48,009 INFO:     None feature selector for col prot
2023-01-04 00:02:48,009 INFO:     None feature selector for col prot
2023-01-04 00:02:48,010 INFO:     None feature selector for col chem
2023-01-04 00:02:48,010 INFO:     None feature selector for col chem
2023-01-04 00:02:48,010 INFO:     None feature selector for col chem
2023-01-04 00:02:48,010 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:02:48,010 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:02:48,011 INFO:     Number of params in model 70141
2023-01-04 00:02:48,015 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:02:48,015 INFO:   Starting stage: TRAINING
2023-01-04 00:02:48,058 INFO:     Val loss before train {'Reaction outcome loss': 1.040237553914388, 'Total loss': 1.040237553914388}
2023-01-04 00:02:48,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:48,058 INFO:     Epoch: 0
2023-01-04 00:02:49,685 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7540726701418559, 'Total loss': 0.7540726701418559} | train loss {'Reaction outcome loss': 0.8614303561170464, 'Total loss': 0.8614303561170464}
2023-01-04 00:02:49,686 INFO:     Found new best model at epoch 0
2023-01-04 00:02:49,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:49,687 INFO:     Epoch: 1
2023-01-04 00:02:51,269 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6054201205571492, 'Total loss': 0.6054201205571492} | train loss {'Reaction outcome loss': 0.624962403973821, 'Total loss': 0.624962403973821}
2023-01-04 00:02:51,269 INFO:     Found new best model at epoch 1
2023-01-04 00:02:51,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:51,270 INFO:     Epoch: 2
2023-01-04 00:02:52,870 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5382347087065379, 'Total loss': 0.5382347087065379} | train loss {'Reaction outcome loss': 0.5411080355094611, 'Total loss': 0.5411080355094611}
2023-01-04 00:02:52,871 INFO:     Found new best model at epoch 2
2023-01-04 00:02:52,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:52,871 INFO:     Epoch: 3
2023-01-04 00:02:54,458 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5340636531511943, 'Total loss': 0.5340636531511943} | train loss {'Reaction outcome loss': 0.49893088053415896, 'Total loss': 0.49893088053415896}
2023-01-04 00:02:54,458 INFO:     Found new best model at epoch 3
2023-01-04 00:02:54,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:54,459 INFO:     Epoch: 4
2023-01-04 00:02:56,046 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5006045420964559, 'Total loss': 0.5006045420964559} | train loss {'Reaction outcome loss': 0.4703417895226807, 'Total loss': 0.4703417895226807}
2023-01-04 00:02:56,046 INFO:     Found new best model at epoch 4
2023-01-04 00:02:56,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:56,047 INFO:     Epoch: 5
2023-01-04 00:02:57,638 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48846595287322997, 'Total loss': 0.48846595287322997} | train loss {'Reaction outcome loss': 0.4469440994569964, 'Total loss': 0.4469440994569964}
2023-01-04 00:02:57,638 INFO:     Found new best model at epoch 5
2023-01-04 00:02:57,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:57,639 INFO:     Epoch: 6
2023-01-04 00:02:59,228 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4830035507678986, 'Total loss': 0.4830035507678986} | train loss {'Reaction outcome loss': 0.42759706149471627, 'Total loss': 0.42759706149471627}
2023-01-04 00:02:59,229 INFO:     Found new best model at epoch 6
2023-01-04 00:02:59,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:02:59,229 INFO:     Epoch: 7
2023-01-04 00:03:00,828 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.470379576086998, 'Total loss': 0.470379576086998} | train loss {'Reaction outcome loss': 0.4138568852879647, 'Total loss': 0.4138568852879647}
2023-01-04 00:03:00,828 INFO:     Found new best model at epoch 7
2023-01-04 00:03:00,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:00,829 INFO:     Epoch: 8
2023-01-04 00:03:02,419 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4809707045555115, 'Total loss': 0.4809707045555115} | train loss {'Reaction outcome loss': 0.40253854913475073, 'Total loss': 0.40253854913475073}
2023-01-04 00:03:02,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:02,420 INFO:     Epoch: 9
2023-01-04 00:03:04,029 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46939864456653596, 'Total loss': 0.46939864456653596} | train loss {'Reaction outcome loss': 0.39436109250654344, 'Total loss': 0.39436109250654344}
2023-01-04 00:03:04,029 INFO:     Found new best model at epoch 9
2023-01-04 00:03:04,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:04,030 INFO:     Epoch: 10
2023-01-04 00:03:05,633 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4536086509625117, 'Total loss': 0.4536086509625117} | train loss {'Reaction outcome loss': 0.3834172053181607, 'Total loss': 0.3834172053181607}
2023-01-04 00:03:05,633 INFO:     Found new best model at epoch 10
2023-01-04 00:03:05,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:05,634 INFO:     Epoch: 11
2023-01-04 00:03:07,249 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4460991193850835, 'Total loss': 0.4460991193850835} | train loss {'Reaction outcome loss': 0.371038859371818, 'Total loss': 0.371038859371818}
2023-01-04 00:03:07,249 INFO:     Found new best model at epoch 11
2023-01-04 00:03:07,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:07,250 INFO:     Epoch: 12
2023-01-04 00:03:08,844 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45464862485726676, 'Total loss': 0.45464862485726676} | train loss {'Reaction outcome loss': 0.36269013550717966, 'Total loss': 0.36269013550717966}
2023-01-04 00:03:08,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:08,844 INFO:     Epoch: 13
2023-01-04 00:03:10,448 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.455180432399114, 'Total loss': 0.455180432399114} | train loss {'Reaction outcome loss': 0.3644972193338301, 'Total loss': 0.3644972193338301}
2023-01-04 00:03:10,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:10,449 INFO:     Epoch: 14
2023-01-04 00:03:12,050 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4498439719279607, 'Total loss': 0.4498439719279607} | train loss {'Reaction outcome loss': 0.35402355666366825, 'Total loss': 0.35402355666366825}
2023-01-04 00:03:12,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:12,051 INFO:     Epoch: 15
2023-01-04 00:03:13,672 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45035437643527987, 'Total loss': 0.45035437643527987} | train loss {'Reaction outcome loss': 0.3448614600667919, 'Total loss': 0.3448614600667919}
2023-01-04 00:03:13,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:13,674 INFO:     Epoch: 16
2023-01-04 00:03:15,297 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4456975976626078, 'Total loss': 0.4456975976626078} | train loss {'Reaction outcome loss': 0.33435760657674685, 'Total loss': 0.33435760657674685}
2023-01-04 00:03:15,297 INFO:     Found new best model at epoch 16
2023-01-04 00:03:15,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:15,298 INFO:     Epoch: 17
2023-01-04 00:03:16,925 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4361535529295603, 'Total loss': 0.4361535529295603} | train loss {'Reaction outcome loss': 0.3298743971272547, 'Total loss': 0.3298743971272547}
2023-01-04 00:03:16,925 INFO:     Found new best model at epoch 17
2023-01-04 00:03:16,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:16,925 INFO:     Epoch: 18
2023-01-04 00:03:18,525 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4488177925348282, 'Total loss': 0.4488177925348282} | train loss {'Reaction outcome loss': 0.3257339765951274, 'Total loss': 0.3257339765951274}
2023-01-04 00:03:18,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:18,525 INFO:     Epoch: 19
2023-01-04 00:03:20,125 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4517234265804291, 'Total loss': 0.4517234265804291} | train loss {'Reaction outcome loss': 0.3218530002117589, 'Total loss': 0.3218530002117589}
2023-01-04 00:03:20,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:20,126 INFO:     Epoch: 20
2023-01-04 00:03:21,723 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44589970509211224, 'Total loss': 0.44589970509211224} | train loss {'Reaction outcome loss': 0.31499774061587127, 'Total loss': 0.31499774061587127}
2023-01-04 00:03:21,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:21,723 INFO:     Epoch: 21
2023-01-04 00:03:23,358 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.423012775182724, 'Total loss': 0.423012775182724} | train loss {'Reaction outcome loss': 0.3122699841640998, 'Total loss': 0.3122699841640998}
2023-01-04 00:03:23,358 INFO:     Found new best model at epoch 21
2023-01-04 00:03:23,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:23,359 INFO:     Epoch: 22
2023-01-04 00:03:24,978 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47197500665982567, 'Total loss': 0.47197500665982567} | train loss {'Reaction outcome loss': 0.3075390327181937, 'Total loss': 0.3075390327181937}
2023-01-04 00:03:24,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:24,978 INFO:     Epoch: 23
2023-01-04 00:03:26,545 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42789232134819033, 'Total loss': 0.42789232134819033} | train loss {'Reaction outcome loss': 0.30513746534352715, 'Total loss': 0.30513746534352715}
2023-01-04 00:03:26,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:26,546 INFO:     Epoch: 24
2023-01-04 00:03:28,156 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43227588136990863, 'Total loss': 0.43227588136990863} | train loss {'Reaction outcome loss': 0.29663202263738797, 'Total loss': 0.29663202263738797}
2023-01-04 00:03:28,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:28,157 INFO:     Epoch: 25
2023-01-04 00:03:29,760 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42858572701613107, 'Total loss': 0.42858572701613107} | train loss {'Reaction outcome loss': 0.293904060516228, 'Total loss': 0.293904060516228}
2023-01-04 00:03:29,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:29,760 INFO:     Epoch: 26
2023-01-04 00:03:31,385 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44071099360783894, 'Total loss': 0.44071099360783894} | train loss {'Reaction outcome loss': 0.2883019671991359, 'Total loss': 0.2883019671991359}
2023-01-04 00:03:31,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:31,385 INFO:     Epoch: 27
2023-01-04 00:03:32,962 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43262262841065724, 'Total loss': 0.43262262841065724} | train loss {'Reaction outcome loss': 0.2847527724326305, 'Total loss': 0.2847527724326305}
2023-01-04 00:03:32,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:32,963 INFO:     Epoch: 28
2023-01-04 00:03:34,578 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.444937926530838, 'Total loss': 0.444937926530838} | train loss {'Reaction outcome loss': 0.28419364735052205, 'Total loss': 0.28419364735052205}
2023-01-04 00:03:34,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:34,578 INFO:     Epoch: 29
2023-01-04 00:03:36,190 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43353502452373505, 'Total loss': 0.43353502452373505} | train loss {'Reaction outcome loss': 0.2792479941592741, 'Total loss': 0.2792479941592741}
2023-01-04 00:03:36,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:36,191 INFO:     Epoch: 30
2023-01-04 00:03:37,817 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4461319327354431, 'Total loss': 0.4461319327354431} | train loss {'Reaction outcome loss': 0.2758454305399884, 'Total loss': 0.2758454305399884}
2023-01-04 00:03:37,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:37,817 INFO:     Epoch: 31
2023-01-04 00:03:39,398 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43378136108318965, 'Total loss': 0.43378136108318965} | train loss {'Reaction outcome loss': 0.2701488396830256, 'Total loss': 0.2701488396830256}
2023-01-04 00:03:39,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:39,399 INFO:     Epoch: 32
2023-01-04 00:03:41,009 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4321021556854248, 'Total loss': 0.4321021556854248} | train loss {'Reaction outcome loss': 0.2673053238119093, 'Total loss': 0.2673053238119093}
2023-01-04 00:03:41,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:41,009 INFO:     Epoch: 33
2023-01-04 00:03:42,597 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43552845815817515, 'Total loss': 0.43552845815817515} | train loss {'Reaction outcome loss': 0.2655955035158474, 'Total loss': 0.2655955035158474}
2023-01-04 00:03:42,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:42,597 INFO:     Epoch: 34
2023-01-04 00:03:44,216 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4311513950427373, 'Total loss': 0.4311513950427373} | train loss {'Reaction outcome loss': 0.2653883872418732, 'Total loss': 0.2653883872418732}
2023-01-04 00:03:44,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:44,216 INFO:     Epoch: 35
2023-01-04 00:03:45,782 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4506753752628962, 'Total loss': 0.4506753752628962} | train loss {'Reaction outcome loss': 0.26277702473475656, 'Total loss': 0.26277702473475656}
2023-01-04 00:03:45,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:45,782 INFO:     Epoch: 36
2023-01-04 00:03:47,383 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43919480840365094, 'Total loss': 0.43919480840365094} | train loss {'Reaction outcome loss': 0.27224825862525165, 'Total loss': 0.27224825862525165}
2023-01-04 00:03:47,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:47,383 INFO:     Epoch: 37
2023-01-04 00:03:49,007 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4357047100861867, 'Total loss': 0.4357047100861867} | train loss {'Reaction outcome loss': 0.265121782373804, 'Total loss': 0.265121782373804}
2023-01-04 00:03:49,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:49,009 INFO:     Epoch: 38
2023-01-04 00:03:50,625 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44278180797894795, 'Total loss': 0.44278180797894795} | train loss {'Reaction outcome loss': 0.25083958564758085, 'Total loss': 0.25083958564758085}
2023-01-04 00:03:50,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:50,625 INFO:     Epoch: 39
2023-01-04 00:03:52,259 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4406020333369573, 'Total loss': 0.4406020333369573} | train loss {'Reaction outcome loss': 0.2483769900655202, 'Total loss': 0.2483769900655202}
2023-01-04 00:03:52,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:52,259 INFO:     Epoch: 40
2023-01-04 00:03:53,865 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43819404641787213, 'Total loss': 0.43819404641787213} | train loss {'Reaction outcome loss': 0.2459900835984508, 'Total loss': 0.2459900835984508}
2023-01-04 00:03:53,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:53,865 INFO:     Epoch: 41
2023-01-04 00:03:55,484 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4438813229401906, 'Total loss': 0.4438813229401906} | train loss {'Reaction outcome loss': 0.24307809155974267, 'Total loss': 0.24307809155974267}
2023-01-04 00:03:55,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:55,485 INFO:     Epoch: 42
2023-01-04 00:03:57,079 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.445015216867129, 'Total loss': 0.445015216867129} | train loss {'Reaction outcome loss': 0.24070885300571335, 'Total loss': 0.24070885300571335}
2023-01-04 00:03:57,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:57,080 INFO:     Epoch: 43
2023-01-04 00:03:58,657 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4528654267390569, 'Total loss': 0.4528654267390569} | train loss {'Reaction outcome loss': 0.24020638924254023, 'Total loss': 0.24020638924254023}
2023-01-04 00:03:58,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:03:58,657 INFO:     Epoch: 44
2023-01-04 00:04:00,276 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4260095864534378, 'Total loss': 0.4260095864534378} | train loss {'Reaction outcome loss': 0.2396510286416742, 'Total loss': 0.2396510286416742}
2023-01-04 00:04:00,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:00,276 INFO:     Epoch: 45
2023-01-04 00:04:01,906 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4569645891586939, 'Total loss': 0.4569645891586939} | train loss {'Reaction outcome loss': 0.23405758363019297, 'Total loss': 0.23405758363019297}
2023-01-04 00:04:01,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:01,906 INFO:     Epoch: 46
2023-01-04 00:04:03,478 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4320906082789103, 'Total loss': 0.4320906082789103} | train loss {'Reaction outcome loss': 0.23475739421943823, 'Total loss': 0.23475739421943823}
2023-01-04 00:04:03,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:03,479 INFO:     Epoch: 47
2023-01-04 00:04:05,079 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4481667309999466, 'Total loss': 0.4481667309999466} | train loss {'Reaction outcome loss': 0.23321875130784683, 'Total loss': 0.23321875130784683}
2023-01-04 00:04:05,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:05,079 INFO:     Epoch: 48
2023-01-04 00:04:06,675 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4368130366007487, 'Total loss': 0.4368130366007487} | train loss {'Reaction outcome loss': 0.22798246890053395, 'Total loss': 0.22798246890053395}
2023-01-04 00:04:06,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:06,675 INFO:     Epoch: 49
2023-01-04 00:04:08,283 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43125205437342323, 'Total loss': 0.43125205437342323} | train loss {'Reaction outcome loss': 0.23138298655765643, 'Total loss': 0.23138298655765643}
2023-01-04 00:04:08,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:08,284 INFO:     Epoch: 50
2023-01-04 00:04:09,868 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4542815128962199, 'Total loss': 0.4542815128962199} | train loss {'Reaction outcome loss': 0.23542022790280642, 'Total loss': 0.23542022790280642}
2023-01-04 00:04:09,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:09,869 INFO:     Epoch: 51
2023-01-04 00:04:11,474 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4591906810800234, 'Total loss': 0.4591906810800234} | train loss {'Reaction outcome loss': 0.22458935692367854, 'Total loss': 0.22458935692367854}
2023-01-04 00:04:11,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:11,474 INFO:     Epoch: 52
2023-01-04 00:04:13,097 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4358578721682231, 'Total loss': 0.4358578721682231} | train loss {'Reaction outcome loss': 0.22213798630499418, 'Total loss': 0.22213798630499418}
2023-01-04 00:04:13,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:13,097 INFO:     Epoch: 53
2023-01-04 00:04:14,678 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4159093181292216, 'Total loss': 0.4159093181292216} | train loss {'Reaction outcome loss': 0.21988565930961698, 'Total loss': 0.21988565930961698}
2023-01-04 00:04:14,678 INFO:     Found new best model at epoch 53
2023-01-04 00:04:14,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:14,679 INFO:     Epoch: 54
2023-01-04 00:04:16,314 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4192718297243118, 'Total loss': 0.4192718297243118} | train loss {'Reaction outcome loss': 0.21965758641506883, 'Total loss': 0.21965758641506883}
2023-01-04 00:04:16,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:16,314 INFO:     Epoch: 55
2023-01-04 00:04:17,956 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4362646053234736, 'Total loss': 0.4362646053234736} | train loss {'Reaction outcome loss': 0.21414105113734072, 'Total loss': 0.21414105113734072}
2023-01-04 00:04:17,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:17,957 INFO:     Epoch: 56
2023-01-04 00:04:19,598 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43262784282366434, 'Total loss': 0.43262784282366434} | train loss {'Reaction outcome loss': 0.21273089653223523, 'Total loss': 0.21273089653223523}
2023-01-04 00:04:19,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:19,598 INFO:     Epoch: 57
2023-01-04 00:04:21,170 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45037295718987785, 'Total loss': 0.45037295718987785} | train loss {'Reaction outcome loss': 0.20922309590041285, 'Total loss': 0.20922309590041285}
2023-01-04 00:04:21,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:21,171 INFO:     Epoch: 58
2023-01-04 00:04:22,749 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4399384876092275, 'Total loss': 0.4399384876092275} | train loss {'Reaction outcome loss': 0.23672281396642758, 'Total loss': 0.23672281396642758}
2023-01-04 00:04:22,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:22,749 INFO:     Epoch: 59
2023-01-04 00:04:24,327 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4459813117980957, 'Total loss': 0.4459813117980957} | train loss {'Reaction outcome loss': 0.2091426939403628, 'Total loss': 0.2091426939403628}
2023-01-04 00:04:24,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:24,329 INFO:     Epoch: 60
2023-01-04 00:04:25,918 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4443150132894516, 'Total loss': 0.4443150132894516} | train loss {'Reaction outcome loss': 0.20843748731792494, 'Total loss': 0.20843748731792494}
2023-01-04 00:04:25,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:25,919 INFO:     Epoch: 61
2023-01-04 00:04:27,513 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44086768527825676, 'Total loss': 0.44086768527825676} | train loss {'Reaction outcome loss': 0.20747009316540282, 'Total loss': 0.20747009316540282}
2023-01-04 00:04:27,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:27,513 INFO:     Epoch: 62
2023-01-04 00:04:29,107 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43556341727574666, 'Total loss': 0.43556341727574666} | train loss {'Reaction outcome loss': 0.2173018396049198, 'Total loss': 0.2173018396049198}
2023-01-04 00:04:29,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:29,107 INFO:     Epoch: 63
2023-01-04 00:04:30,688 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4430286397536596, 'Total loss': 0.4430286397536596} | train loss {'Reaction outcome loss': 0.2046699058728468, 'Total loss': 0.2046699058728468}
2023-01-04 00:04:30,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:30,689 INFO:     Epoch: 64
2023-01-04 00:04:32,255 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45061390747626623, 'Total loss': 0.45061390747626623} | train loss {'Reaction outcome loss': 0.20063414149995695, 'Total loss': 0.20063414149995695}
2023-01-04 00:04:32,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:32,255 INFO:     Epoch: 65
2023-01-04 00:04:33,871 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45838928123315176, 'Total loss': 0.45838928123315176} | train loss {'Reaction outcome loss': 0.20336485733750506, 'Total loss': 0.20336485733750506}
2023-01-04 00:04:33,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:33,871 INFO:     Epoch: 66
2023-01-04 00:04:35,490 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4619042744239171, 'Total loss': 0.4619042744239171} | train loss {'Reaction outcome loss': 0.2066154195730949, 'Total loss': 0.2066154195730949}
2023-01-04 00:04:35,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:35,490 INFO:     Epoch: 67
2023-01-04 00:04:37,087 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46215535899003346, 'Total loss': 0.46215535899003346} | train loss {'Reaction outcome loss': 0.21101306106868215, 'Total loss': 0.21101306106868215}
2023-01-04 00:04:37,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:37,087 INFO:     Epoch: 68
2023-01-04 00:04:38,593 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4529283871253332, 'Total loss': 0.4529283871253332} | train loss {'Reaction outcome loss': 0.2103425050277967, 'Total loss': 0.2103425050277967}
2023-01-04 00:04:38,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:38,593 INFO:     Epoch: 69
2023-01-04 00:04:39,653 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46668638586997985, 'Total loss': 0.46668638586997985} | train loss {'Reaction outcome loss': 0.20284789222953975, 'Total loss': 0.20284789222953975}
2023-01-04 00:04:39,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:39,653 INFO:     Epoch: 70
2023-01-04 00:04:40,721 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4425516963005066, 'Total loss': 0.4425516963005066} | train loss {'Reaction outcome loss': 0.2045984777539253, 'Total loss': 0.2045984777539253}
2023-01-04 00:04:40,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:40,721 INFO:     Epoch: 71
2023-01-04 00:04:41,776 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49944902062416074, 'Total loss': 0.49944902062416074} | train loss {'Reaction outcome loss': 0.20027420009769822, 'Total loss': 0.20027420009769822}
2023-01-04 00:04:41,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:41,776 INFO:     Epoch: 72
2023-01-04 00:04:42,842 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46653082470099133, 'Total loss': 0.46653082470099133} | train loss {'Reaction outcome loss': 0.19959108775567627, 'Total loss': 0.19959108775567627}
2023-01-04 00:04:42,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:42,842 INFO:     Epoch: 73
2023-01-04 00:04:44,424 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4758206377426783, 'Total loss': 0.4758206377426783} | train loss {'Reaction outcome loss': 0.18862635643236517, 'Total loss': 0.18862635643236517}
2023-01-04 00:04:44,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:44,424 INFO:     Epoch: 74
2023-01-04 00:04:46,018 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46498456597328186, 'Total loss': 0.46498456597328186} | train loss {'Reaction outcome loss': 0.18826769886916314, 'Total loss': 0.18826769886916314}
2023-01-04 00:04:46,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:46,018 INFO:     Epoch: 75
2023-01-04 00:04:47,585 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4824173708756765, 'Total loss': 0.4824173708756765} | train loss {'Reaction outcome loss': 0.19009662733372787, 'Total loss': 0.19009662733372787}
2023-01-04 00:04:47,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:47,585 INFO:     Epoch: 76
2023-01-04 00:04:49,204 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46592262089252473, 'Total loss': 0.46592262089252473} | train loss {'Reaction outcome loss': 0.18807892393037354, 'Total loss': 0.18807892393037354}
2023-01-04 00:04:49,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:49,204 INFO:     Epoch: 77
2023-01-04 00:04:50,825 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47872360746065773, 'Total loss': 0.47872360746065773} | train loss {'Reaction outcome loss': 0.18662745241222117, 'Total loss': 0.18662745241222117}
2023-01-04 00:04:50,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:50,826 INFO:     Epoch: 78
2023-01-04 00:04:52,390 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45901052256425223, 'Total loss': 0.45901052256425223} | train loss {'Reaction outcome loss': 0.1859279577046687, 'Total loss': 0.1859279577046687}
2023-01-04 00:04:52,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:52,390 INFO:     Epoch: 79
2023-01-04 00:04:54,012 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4491720120112101, 'Total loss': 0.4491720120112101} | train loss {'Reaction outcome loss': 0.18439252041128423, 'Total loss': 0.18439252041128423}
2023-01-04 00:04:54,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:54,013 INFO:     Epoch: 80
2023-01-04 00:04:55,632 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45458915730317434, 'Total loss': 0.45458915730317434} | train loss {'Reaction outcome loss': 0.18503272084458527, 'Total loss': 0.18503272084458527}
2023-01-04 00:04:55,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:55,634 INFO:     Epoch: 81
2023-01-04 00:04:57,226 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44695380578438443, 'Total loss': 0.44695380578438443} | train loss {'Reaction outcome loss': 0.18398917232493198, 'Total loss': 0.18398917232493198}
2023-01-04 00:04:57,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:57,226 INFO:     Epoch: 82
2023-01-04 00:04:58,847 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4544987728198369, 'Total loss': 0.4544987728198369} | train loss {'Reaction outcome loss': 0.18108932634358793, 'Total loss': 0.18108932634358793}
2023-01-04 00:04:58,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:04:58,847 INFO:     Epoch: 83
2023-01-04 00:05:00,470 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46221254964669545, 'Total loss': 0.46221254964669545} | train loss {'Reaction outcome loss': 0.1825190228966834, 'Total loss': 0.1825190228966834}
2023-01-04 00:05:00,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:00,471 INFO:     Epoch: 84
2023-01-04 00:05:02,041 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4780435462792714, 'Total loss': 0.4780435462792714} | train loss {'Reaction outcome loss': 0.18229629537559808, 'Total loss': 0.18229629537559808}
2023-01-04 00:05:02,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:02,042 INFO:     Epoch: 85
2023-01-04 00:05:03,654 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4619215925534566, 'Total loss': 0.4619215925534566} | train loss {'Reaction outcome loss': 0.1788187998117528, 'Total loss': 0.1788187998117528}
2023-01-04 00:05:03,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:03,654 INFO:     Epoch: 86
2023-01-04 00:05:05,275 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46384896636009215, 'Total loss': 0.46384896636009215} | train loss {'Reaction outcome loss': 0.18263611234758265, 'Total loss': 0.18263611234758265}
2023-01-04 00:05:05,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:05,275 INFO:     Epoch: 87
2023-01-04 00:05:06,852 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5002176702022553, 'Total loss': 0.5002176702022553} | train loss {'Reaction outcome loss': 0.17914762226459774, 'Total loss': 0.17914762226459774}
2023-01-04 00:05:06,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:06,853 INFO:     Epoch: 88
2023-01-04 00:05:08,472 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4706924885511398, 'Total loss': 0.4706924885511398} | train loss {'Reaction outcome loss': 0.19064566664451707, 'Total loss': 0.19064566664451707}
2023-01-04 00:05:08,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:08,473 INFO:     Epoch: 89
2023-01-04 00:05:10,038 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45406296849250793, 'Total loss': 0.45406296849250793} | train loss {'Reaction outcome loss': 0.20048224063509185, 'Total loss': 0.20048224063509185}
2023-01-04 00:05:10,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:10,038 INFO:     Epoch: 90
2023-01-04 00:05:11,651 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44950548708438876, 'Total loss': 0.44950548708438876} | train loss {'Reaction outcome loss': 0.1778139072213916, 'Total loss': 0.1778139072213916}
2023-01-04 00:05:11,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:11,651 INFO:     Epoch: 91
2023-01-04 00:05:13,281 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47181432247161864, 'Total loss': 0.47181432247161864} | train loss {'Reaction outcome loss': 0.179254822783928, 'Total loss': 0.179254822783928}
2023-01-04 00:05:13,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:13,282 INFO:     Epoch: 92
2023-01-04 00:05:14,888 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45929878354072573, 'Total loss': 0.45929878354072573} | train loss {'Reaction outcome loss': 0.20180371075031767, 'Total loss': 0.20180371075031767}
2023-01-04 00:05:14,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:14,889 INFO:     Epoch: 93
2023-01-04 00:05:16,510 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4928487767775854, 'Total loss': 0.4928487767775854} | train loss {'Reaction outcome loss': 0.17358503533498573, 'Total loss': 0.17358503533498573}
2023-01-04 00:05:16,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:16,510 INFO:     Epoch: 94
2023-01-04 00:05:18,144 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4948094626267751, 'Total loss': 0.4948094626267751} | train loss {'Reaction outcome loss': 0.17379965487381685, 'Total loss': 0.17379965487381685}
2023-01-04 00:05:18,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:18,144 INFO:     Epoch: 95
2023-01-04 00:05:19,744 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.484954959154129, 'Total loss': 0.484954959154129} | train loss {'Reaction outcome loss': 0.17216005458607653, 'Total loss': 0.17216005458607653}
2023-01-04 00:05:19,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:19,744 INFO:     Epoch: 96
2023-01-04 00:05:21,341 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47350727021694183, 'Total loss': 0.47350727021694183} | train loss {'Reaction outcome loss': 0.1698351746089284, 'Total loss': 0.1698351746089284}
2023-01-04 00:05:21,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:21,341 INFO:     Epoch: 97
2023-01-04 00:05:22,937 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4779971400896708, 'Total loss': 0.4779971400896708} | train loss {'Reaction outcome loss': 0.17005352500342744, 'Total loss': 0.17005352500342744}
2023-01-04 00:05:22,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:22,937 INFO:     Epoch: 98
2023-01-04 00:05:24,519 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48637672464052834, 'Total loss': 0.48637672464052834} | train loss {'Reaction outcome loss': 0.16640109004304354, 'Total loss': 0.16640109004304354}
2023-01-04 00:05:24,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:24,519 INFO:     Epoch: 99
2023-01-04 00:05:26,135 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46279376645882925, 'Total loss': 0.46279376645882925} | train loss {'Reaction outcome loss': 0.17098955669190627, 'Total loss': 0.17098955669190627}
2023-01-04 00:05:26,135 INFO:     Best model found after epoch 54 of 100.
2023-01-04 00:05:26,135 INFO:   Done with stage: TRAINING
2023-01-04 00:05:26,135 INFO:   Starting stage: EVALUATION
2023-01-04 00:05:26,265 INFO:   Done with stage: EVALUATION
2023-01-04 00:05:26,265 INFO:   Leaving out SEQ value Fold_6
2023-01-04 00:05:26,279 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 00:05:26,279 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:05:26,927 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:05:26,928 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:05:26,998 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:05:26,998 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:05:26,998 INFO:     No hyperparam tuning for this model
2023-01-04 00:05:26,998 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:05:26,998 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:05:26,999 INFO:     None feature selector for col prot
2023-01-04 00:05:26,999 INFO:     None feature selector for col prot
2023-01-04 00:05:26,999 INFO:     None feature selector for col prot
2023-01-04 00:05:27,000 INFO:     None feature selector for col chem
2023-01-04 00:05:27,000 INFO:     None feature selector for col chem
2023-01-04 00:05:27,000 INFO:     None feature selector for col chem
2023-01-04 00:05:27,000 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:05:27,000 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:05:27,001 INFO:     Number of params in model 70141
2023-01-04 00:05:27,004 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:05:27,004 INFO:   Starting stage: TRAINING
2023-01-04 00:05:27,047 INFO:     Val loss before train {'Reaction outcome loss': 0.9708901047706604, 'Total loss': 0.9708901047706604}
2023-01-04 00:05:27,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:27,048 INFO:     Epoch: 0
2023-01-04 00:05:28,629 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7010575811068217, 'Total loss': 0.7010575811068217} | train loss {'Reaction outcome loss': 0.8436821635664585, 'Total loss': 0.8436821635664585}
2023-01-04 00:05:28,629 INFO:     Found new best model at epoch 0
2023-01-04 00:05:28,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:28,630 INFO:     Epoch: 1
2023-01-04 00:05:30,227 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.588144306341807, 'Total loss': 0.588144306341807} | train loss {'Reaction outcome loss': 0.6076520723341174, 'Total loss': 0.6076520723341174}
2023-01-04 00:05:30,227 INFO:     Found new best model at epoch 1
2023-01-04 00:05:30,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:30,228 INFO:     Epoch: 2
2023-01-04 00:05:31,824 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5405640165011089, 'Total loss': 0.5405640165011089} | train loss {'Reaction outcome loss': 0.5319879801695098, 'Total loss': 0.5319879801695098}
2023-01-04 00:05:31,825 INFO:     Found new best model at epoch 2
2023-01-04 00:05:31,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:31,826 INFO:     Epoch: 3
2023-01-04 00:05:33,408 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5119668463865916, 'Total loss': 0.5119668463865916} | train loss {'Reaction outcome loss': 0.489256469620264, 'Total loss': 0.489256469620264}
2023-01-04 00:05:33,408 INFO:     Found new best model at epoch 3
2023-01-04 00:05:33,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:33,409 INFO:     Epoch: 4
2023-01-04 00:05:35,007 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49521513978640236, 'Total loss': 0.49521513978640236} | train loss {'Reaction outcome loss': 0.4624125628533777, 'Total loss': 0.4624125628533777}
2023-01-04 00:05:35,008 INFO:     Found new best model at epoch 4
2023-01-04 00:05:35,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:35,008 INFO:     Epoch: 5
2023-01-04 00:05:36,594 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47208297848701475, 'Total loss': 0.47208297848701475} | train loss {'Reaction outcome loss': 0.43992420245594066, 'Total loss': 0.43992420245594066}
2023-01-04 00:05:36,594 INFO:     Found new best model at epoch 5
2023-01-04 00:05:36,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:36,595 INFO:     Epoch: 6
2023-01-04 00:05:38,180 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4785703162352244, 'Total loss': 0.4785703162352244} | train loss {'Reaction outcome loss': 0.4235583768101806, 'Total loss': 0.4235583768101806}
2023-01-04 00:05:38,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:38,181 INFO:     Epoch: 7
2023-01-04 00:05:39,786 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4565515776475271, 'Total loss': 0.4565515776475271} | train loss {'Reaction outcome loss': 0.4104461165864545, 'Total loss': 0.4104461165864545}
2023-01-04 00:05:39,786 INFO:     Found new best model at epoch 7
2023-01-04 00:05:39,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:39,787 INFO:     Epoch: 8
2023-01-04 00:05:41,373 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44347187876701355, 'Total loss': 0.44347187876701355} | train loss {'Reaction outcome loss': 0.39738321933720516, 'Total loss': 0.39738321933720516}
2023-01-04 00:05:41,373 INFO:     Found new best model at epoch 8
2023-01-04 00:05:41,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:41,374 INFO:     Epoch: 9
2023-01-04 00:05:42,975 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4473999261856079, 'Total loss': 0.4473999261856079} | train loss {'Reaction outcome loss': 0.3895076256420208, 'Total loss': 0.3895076256420208}
2023-01-04 00:05:42,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:42,975 INFO:     Epoch: 10
2023-01-04 00:05:44,576 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.448945544163386, 'Total loss': 0.448945544163386} | train loss {'Reaction outcome loss': 0.3804346334848163, 'Total loss': 0.3804346334848163}
2023-01-04 00:05:44,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:44,577 INFO:     Epoch: 11
2023-01-04 00:05:46,162 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4479530990123749, 'Total loss': 0.4479530990123749} | train loss {'Reaction outcome loss': 0.37236800359474626, 'Total loss': 0.37236800359474626}
2023-01-04 00:05:46,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:46,162 INFO:     Epoch: 12
2023-01-04 00:05:47,794 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4462667127450307, 'Total loss': 0.4462667127450307} | train loss {'Reaction outcome loss': 0.3648620349513064, 'Total loss': 0.3648620349513064}
2023-01-04 00:05:47,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:47,794 INFO:     Epoch: 13
2023-01-04 00:05:49,420 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43250206907590233, 'Total loss': 0.43250206907590233} | train loss {'Reaction outcome loss': 0.3568381358354961, 'Total loss': 0.3568381358354961}
2023-01-04 00:05:49,420 INFO:     Found new best model at epoch 13
2023-01-04 00:05:49,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:49,421 INFO:     Epoch: 14
2023-01-04 00:05:51,009 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43589521050453184, 'Total loss': 0.43589521050453184} | train loss {'Reaction outcome loss': 0.3499253546072688, 'Total loss': 0.3499253546072688}
2023-01-04 00:05:51,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:51,010 INFO:     Epoch: 15
2023-01-04 00:05:52,646 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4362160682678223, 'Total loss': 0.4362160682678223} | train loss {'Reaction outcome loss': 0.3435019191475551, 'Total loss': 0.3435019191475551}
2023-01-04 00:05:52,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:52,647 INFO:     Epoch: 16
2023-01-04 00:05:54,275 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42906941175460817, 'Total loss': 0.42906941175460817} | train loss {'Reaction outcome loss': 0.3397513072843586, 'Total loss': 0.3397513072843586}
2023-01-04 00:05:54,275 INFO:     Found new best model at epoch 16
2023-01-04 00:05:54,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:54,276 INFO:     Epoch: 17
2023-01-04 00:05:55,895 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4395562360684077, 'Total loss': 0.4395562360684077} | train loss {'Reaction outcome loss': 0.3346869255876713, 'Total loss': 0.3346869255876713}
2023-01-04 00:05:55,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:55,896 INFO:     Epoch: 18
2023-01-04 00:05:57,521 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43366551399230957, 'Total loss': 0.43366551399230957} | train loss {'Reaction outcome loss': 0.32976757312724736, 'Total loss': 0.32976757312724736}
2023-01-04 00:05:57,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:57,521 INFO:     Epoch: 19
2023-01-04 00:05:59,116 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43280875285466514, 'Total loss': 0.43280875285466514} | train loss {'Reaction outcome loss': 0.3261330663781304, 'Total loss': 0.3261330663781304}
2023-01-04 00:05:59,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:05:59,116 INFO:     Epoch: 20
2023-01-04 00:06:00,748 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4253153661886851, 'Total loss': 0.4253153661886851} | train loss {'Reaction outcome loss': 0.3200658673306234, 'Total loss': 0.3200658673306234}
2023-01-04 00:06:00,749 INFO:     Found new best model at epoch 20
2023-01-04 00:06:00,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:00,749 INFO:     Epoch: 21
2023-01-04 00:06:02,383 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4359626640876134, 'Total loss': 0.4359626640876134} | train loss {'Reaction outcome loss': 0.31469229331730936, 'Total loss': 0.31469229331730936}
2023-01-04 00:06:02,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:02,384 INFO:     Epoch: 22
2023-01-04 00:06:03,995 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41809218426545464, 'Total loss': 0.41809218426545464} | train loss {'Reaction outcome loss': 0.31137074715716745, 'Total loss': 0.31137074715716745}
2023-01-04 00:06:03,996 INFO:     Found new best model at epoch 22
2023-01-04 00:06:03,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:03,996 INFO:     Epoch: 23
2023-01-04 00:06:05,599 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42662663211425145, 'Total loss': 0.42662663211425145} | train loss {'Reaction outcome loss': 0.30899640667632167, 'Total loss': 0.30899640667632167}
2023-01-04 00:06:05,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:05,600 INFO:     Epoch: 24
2023-01-04 00:06:07,241 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42438574035962423, 'Total loss': 0.42438574035962423} | train loss {'Reaction outcome loss': 0.30243459187232846, 'Total loss': 0.30243459187232846}
2023-01-04 00:06:07,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:07,242 INFO:     Epoch: 25
2023-01-04 00:06:08,829 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42113909423351287, 'Total loss': 0.42113909423351287} | train loss {'Reaction outcome loss': 0.2996651820219811, 'Total loss': 0.2996651820219811}
2023-01-04 00:06:08,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:08,829 INFO:     Epoch: 26
2023-01-04 00:06:10,471 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43254482944806416, 'Total loss': 0.43254482944806416} | train loss {'Reaction outcome loss': 0.29490675196212984, 'Total loss': 0.29490675196212984}
2023-01-04 00:06:10,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:10,471 INFO:     Epoch: 27
2023-01-04 00:06:12,101 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41899022459983826, 'Total loss': 0.41899022459983826} | train loss {'Reaction outcome loss': 0.29244748901051304, 'Total loss': 0.29244748901051304}
2023-01-04 00:06:12,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:12,101 INFO:     Epoch: 28
2023-01-04 00:06:13,707 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43643512030442555, 'Total loss': 0.43643512030442555} | train loss {'Reaction outcome loss': 0.2886277278515406, 'Total loss': 0.2886277278515406}
2023-01-04 00:06:13,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:13,708 INFO:     Epoch: 29
2023-01-04 00:06:15,354 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4268600821495056, 'Total loss': 0.4268600821495056} | train loss {'Reaction outcome loss': 0.28530910207691607, 'Total loss': 0.28530910207691607}
2023-01-04 00:06:15,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:15,354 INFO:     Epoch: 30
2023-01-04 00:06:16,990 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4347106277942657, 'Total loss': 0.4347106277942657} | train loss {'Reaction outcome loss': 0.28012750685107407, 'Total loss': 0.28012750685107407}
2023-01-04 00:06:16,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:16,990 INFO:     Epoch: 31
2023-01-04 00:06:18,608 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4353246122598648, 'Total loss': 0.4353246122598648} | train loss {'Reaction outcome loss': 0.280181439721197, 'Total loss': 0.280181439721197}
2023-01-04 00:06:18,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:18,608 INFO:     Epoch: 32
2023-01-04 00:06:20,245 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4386401732762655, 'Total loss': 0.4386401732762655} | train loss {'Reaction outcome loss': 0.27525170611399175, 'Total loss': 0.27525170611399175}
2023-01-04 00:06:20,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:20,245 INFO:     Epoch: 33
2023-01-04 00:06:21,829 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44068751732508343, 'Total loss': 0.44068751732508343} | train loss {'Reaction outcome loss': 0.2757333759689159, 'Total loss': 0.2757333759689159}
2023-01-04 00:06:21,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:21,829 INFO:     Epoch: 34
2023-01-04 00:06:23,464 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4416557172934214, 'Total loss': 0.4416557172934214} | train loss {'Reaction outcome loss': 0.26985755429640146, 'Total loss': 0.26985755429640146}
2023-01-04 00:06:23,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:23,464 INFO:     Epoch: 35
2023-01-04 00:06:25,110 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43780778447786967, 'Total loss': 0.43780778447786967} | train loss {'Reaction outcome loss': 0.26544164989937086, 'Total loss': 0.26544164989937086}
2023-01-04 00:06:25,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:25,110 INFO:     Epoch: 36
2023-01-04 00:06:26,726 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45096744696299235, 'Total loss': 0.45096744696299235} | train loss {'Reaction outcome loss': 0.26530545762998964, 'Total loss': 0.26530545762998964}
2023-01-04 00:06:26,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:26,727 INFO:     Epoch: 37
2023-01-04 00:06:28,355 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47316173116366067, 'Total loss': 0.47316173116366067} | train loss {'Reaction outcome loss': 0.26360853212727536, 'Total loss': 0.26360853212727536}
2023-01-04 00:06:28,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:28,356 INFO:     Epoch: 38
2023-01-04 00:06:29,937 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4461575826009115, 'Total loss': 0.4461575826009115} | train loss {'Reaction outcome loss': 0.25889158131897666, 'Total loss': 0.25889158131897666}
2023-01-04 00:06:29,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:29,938 INFO:     Epoch: 39
2023-01-04 00:06:31,545 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4577602912982305, 'Total loss': 0.4577602912982305} | train loss {'Reaction outcome loss': 0.25562863197137303, 'Total loss': 0.25562863197137303}
2023-01-04 00:06:31,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:31,545 INFO:     Epoch: 40
2023-01-04 00:06:33,185 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44343402882417043, 'Total loss': 0.44343402882417043} | train loss {'Reaction outcome loss': 0.2535600530568658, 'Total loss': 0.2535600530568658}
2023-01-04 00:06:33,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:33,185 INFO:     Epoch: 41
2023-01-04 00:06:34,828 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4609513362248739, 'Total loss': 0.4609513362248739} | train loss {'Reaction outcome loss': 0.2504916179938652, 'Total loss': 0.2504916179938652}
2023-01-04 00:06:34,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:34,828 INFO:     Epoch: 42
2023-01-04 00:06:36,441 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4479969680309296, 'Total loss': 0.4479969680309296} | train loss {'Reaction outcome loss': 0.24907837590263207, 'Total loss': 0.24907837590263207}
2023-01-04 00:06:36,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:36,441 INFO:     Epoch: 43
2023-01-04 00:06:38,083 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4459931363662084, 'Total loss': 0.4459931363662084} | train loss {'Reaction outcome loss': 0.24518959197326687, 'Total loss': 0.24518959197326687}
2023-01-04 00:06:38,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:38,084 INFO:     Epoch: 44
2023-01-04 00:06:39,692 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44919591546058657, 'Total loss': 0.44919591546058657} | train loss {'Reaction outcome loss': 0.24341872690870875, 'Total loss': 0.24341872690870875}
2023-01-04 00:06:39,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:39,692 INFO:     Epoch: 45
2023-01-04 00:06:41,295 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4484504779179891, 'Total loss': 0.4484504779179891} | train loss {'Reaction outcome loss': 0.24413177875351388, 'Total loss': 0.24413177875351388}
2023-01-04 00:06:41,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:41,295 INFO:     Epoch: 46
2023-01-04 00:06:42,897 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4427845040957133, 'Total loss': 0.4427845040957133} | train loss {'Reaction outcome loss': 0.24062952642675342, 'Total loss': 0.24062952642675342}
2023-01-04 00:06:42,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:42,897 INFO:     Epoch: 47
2023-01-04 00:06:44,478 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45742105146249135, 'Total loss': 0.45742105146249135} | train loss {'Reaction outcome loss': 0.23648492604601684, 'Total loss': 0.23648492604601684}
2023-01-04 00:06:44,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:44,479 INFO:     Epoch: 48
2023-01-04 00:06:46,081 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46704136530558266, 'Total loss': 0.46704136530558266} | train loss {'Reaction outcome loss': 0.23655744276214594, 'Total loss': 0.23655744276214594}
2023-01-04 00:06:46,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:46,081 INFO:     Epoch: 49
2023-01-04 00:06:47,684 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4386361688375473, 'Total loss': 0.4386361688375473} | train loss {'Reaction outcome loss': 0.23313188113083907, 'Total loss': 0.23313188113083907}
2023-01-04 00:06:47,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:47,684 INFO:     Epoch: 50
2023-01-04 00:06:49,267 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43769070456425346, 'Total loss': 0.43769070456425346} | train loss {'Reaction outcome loss': 0.23268883078214495, 'Total loss': 0.23268883078214495}
2023-01-04 00:06:49,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:49,267 INFO:     Epoch: 51
2023-01-04 00:06:50,895 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44186431765556333, 'Total loss': 0.44186431765556333} | train loss {'Reaction outcome loss': 0.23056017536172368, 'Total loss': 0.23056017536172368}
2023-01-04 00:06:50,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:50,895 INFO:     Epoch: 52
2023-01-04 00:06:52,516 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4609555721282959, 'Total loss': 0.4609555721282959} | train loss {'Reaction outcome loss': 0.22747648340592747, 'Total loss': 0.22747648340592747}
2023-01-04 00:06:52,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:52,516 INFO:     Epoch: 53
2023-01-04 00:06:54,123 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44783802529176076, 'Total loss': 0.44783802529176076} | train loss {'Reaction outcome loss': 0.2262537939615198, 'Total loss': 0.2262537939615198}
2023-01-04 00:06:54,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:54,124 INFO:     Epoch: 54
2023-01-04 00:06:55,763 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45855411887168884, 'Total loss': 0.45855411887168884} | train loss {'Reaction outcome loss': 0.22509505299831126, 'Total loss': 0.22509505299831126}
2023-01-04 00:06:55,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:55,763 INFO:     Epoch: 55
2023-01-04 00:06:57,398 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48634699881076815, 'Total loss': 0.48634699881076815} | train loss {'Reaction outcome loss': 0.22260210169512873, 'Total loss': 0.22260210169512873}
2023-01-04 00:06:57,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:57,399 INFO:     Epoch: 56
2023-01-04 00:06:58,994 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44595958590507506, 'Total loss': 0.44595958590507506} | train loss {'Reaction outcome loss': 0.22266623380489728, 'Total loss': 0.22266623380489728}
2023-01-04 00:06:58,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:06:58,994 INFO:     Epoch: 57
2023-01-04 00:07:00,591 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45316794713338215, 'Total loss': 0.45316794713338215} | train loss {'Reaction outcome loss': 0.2206221190062671, 'Total loss': 0.2206221190062671}
2023-01-04 00:07:00,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:00,591 INFO:     Epoch: 58
2023-01-04 00:07:02,189 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46143061816692355, 'Total loss': 0.46143061816692355} | train loss {'Reaction outcome loss': 0.2168593087001613, 'Total loss': 0.2168593087001613}
2023-01-04 00:07:02,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:02,189 INFO:     Epoch: 59
2023-01-04 00:07:03,781 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45599084595839184, 'Total loss': 0.45599084595839184} | train loss {'Reaction outcome loss': 0.21610479308325892, 'Total loss': 0.21610479308325892}
2023-01-04 00:07:03,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:03,781 INFO:     Epoch: 60
2023-01-04 00:07:05,387 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4775842547416687, 'Total loss': 0.4775842547416687} | train loss {'Reaction outcome loss': 0.2154568727615723, 'Total loss': 0.2154568727615723}
2023-01-04 00:07:05,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:05,387 INFO:     Epoch: 61
2023-01-04 00:07:06,973 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4546722749869029, 'Total loss': 0.4546722749869029} | train loss {'Reaction outcome loss': 0.21216516016515152, 'Total loss': 0.21216516016515152}
2023-01-04 00:07:06,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:06,974 INFO:     Epoch: 62
2023-01-04 00:07:08,579 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.455026180545489, 'Total loss': 0.455026180545489} | train loss {'Reaction outcome loss': 0.21353655543837308, 'Total loss': 0.21353655543837308}
2023-01-04 00:07:08,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:08,580 INFO:     Epoch: 63
2023-01-04 00:07:10,182 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4521884242693583, 'Total loss': 0.4521884242693583} | train loss {'Reaction outcome loss': 0.21045061394518463, 'Total loss': 0.21045061394518463}
2023-01-04 00:07:10,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:10,183 INFO:     Epoch: 64
2023-01-04 00:07:11,767 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4530611793200175, 'Total loss': 0.4530611793200175} | train loss {'Reaction outcome loss': 0.2087022907332608, 'Total loss': 0.2087022907332608}
2023-01-04 00:07:11,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:11,768 INFO:     Epoch: 65
2023-01-04 00:07:13,372 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48525886138280233, 'Total loss': 0.48525886138280233} | train loss {'Reaction outcome loss': 0.2078044147832514, 'Total loss': 0.2078044147832514}
2023-01-04 00:07:13,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:13,373 INFO:     Epoch: 66
2023-01-04 00:07:14,978 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45616805652777354, 'Total loss': 0.45616805652777354} | train loss {'Reaction outcome loss': 0.20663484644534785, 'Total loss': 0.20663484644534785}
2023-01-04 00:07:14,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:14,979 INFO:     Epoch: 67
2023-01-04 00:07:16,583 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4517076184352239, 'Total loss': 0.4517076184352239} | train loss {'Reaction outcome loss': 0.20390917290849375, 'Total loss': 0.20390917290849375}
2023-01-04 00:07:16,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:16,583 INFO:     Epoch: 68
2023-01-04 00:07:18,200 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4507929474115372, 'Total loss': 0.4507929474115372} | train loss {'Reaction outcome loss': 0.20167189356383433, 'Total loss': 0.20167189356383433}
2023-01-04 00:07:18,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:18,201 INFO:     Epoch: 69
2023-01-04 00:07:19,827 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45209280649820965, 'Total loss': 0.45209280649820965} | train loss {'Reaction outcome loss': 0.20403603231702472, 'Total loss': 0.20403603231702472}
2023-01-04 00:07:19,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:19,828 INFO:     Epoch: 70
2023-01-04 00:07:21,437 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4748369097709656, 'Total loss': 0.4748369097709656} | train loss {'Reaction outcome loss': 0.20402872273261366, 'Total loss': 0.20402872273261366}
2023-01-04 00:07:21,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:21,438 INFO:     Epoch: 71
2023-01-04 00:07:23,071 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.454419951637586, 'Total loss': 0.454419951637586} | train loss {'Reaction outcome loss': 0.19920441552673868, 'Total loss': 0.19920441552673868}
2023-01-04 00:07:23,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:23,071 INFO:     Epoch: 72
2023-01-04 00:07:24,687 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4611283282438914, 'Total loss': 0.4611283282438914} | train loss {'Reaction outcome loss': 0.19850527739912163, 'Total loss': 0.19850527739912163}
2023-01-04 00:07:24,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:24,687 INFO:     Epoch: 73
2023-01-04 00:07:26,291 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46380617991089823, 'Total loss': 0.46380617991089823} | train loss {'Reaction outcome loss': 0.19929898438793658, 'Total loss': 0.19929898438793658}
2023-01-04 00:07:26,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:26,291 INFO:     Epoch: 74
2023-01-04 00:07:27,896 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46286563177903495, 'Total loss': 0.46286563177903495} | train loss {'Reaction outcome loss': 0.1953040585728759, 'Total loss': 0.1953040585728759}
2023-01-04 00:07:27,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:27,897 INFO:     Epoch: 75
2023-01-04 00:07:29,483 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.471960053841273, 'Total loss': 0.471960053841273} | train loss {'Reaction outcome loss': 0.19491190262246433, 'Total loss': 0.19491190262246433}
2023-01-04 00:07:29,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:29,483 INFO:     Epoch: 76
2023-01-04 00:07:31,088 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45203188558419544, 'Total loss': 0.45203188558419544} | train loss {'Reaction outcome loss': 0.19372395500002784, 'Total loss': 0.19372395500002784}
2023-01-04 00:07:31,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:31,088 INFO:     Epoch: 77
2023-01-04 00:07:32,695 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4518224100271861, 'Total loss': 0.4518224100271861} | train loss {'Reaction outcome loss': 0.19416211883029783, 'Total loss': 0.19416211883029783}
2023-01-04 00:07:32,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:32,695 INFO:     Epoch: 78
2023-01-04 00:07:34,281 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4712875783443451, 'Total loss': 0.4712875783443451} | train loss {'Reaction outcome loss': 0.19161928749041438, 'Total loss': 0.19161928749041438}
2023-01-04 00:07:34,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:34,281 INFO:     Epoch: 79
2023-01-04 00:07:35,884 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44924603154261905, 'Total loss': 0.44924603154261905} | train loss {'Reaction outcome loss': 0.19049579558712482, 'Total loss': 0.19049579558712482}
2023-01-04 00:07:35,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:35,884 INFO:     Epoch: 80
2023-01-04 00:07:37,512 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4774942268927892, 'Total loss': 0.4774942268927892} | train loss {'Reaction outcome loss': 0.1894203112578349, 'Total loss': 0.1894203112578349}
2023-01-04 00:07:37,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:37,512 INFO:     Epoch: 81
2023-01-04 00:07:39,101 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46980862617492675, 'Total loss': 0.46980862617492675} | train loss {'Reaction outcome loss': 0.1914064688372698, 'Total loss': 0.1914064688372698}
2023-01-04 00:07:39,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:39,101 INFO:     Epoch: 82
2023-01-04 00:07:40,717 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4728940983613332, 'Total loss': 0.4728940983613332} | train loss {'Reaction outcome loss': 0.18925780993936725, 'Total loss': 0.18925780993936725}
2023-01-04 00:07:40,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:40,718 INFO:     Epoch: 83
2023-01-04 00:07:42,288 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45930356085300444, 'Total loss': 0.45930356085300444} | train loss {'Reaction outcome loss': 0.1883750480569442, 'Total loss': 0.1883750480569442}
2023-01-04 00:07:42,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:42,288 INFO:     Epoch: 84
2023-01-04 00:07:43,916 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45819209615389506, 'Total loss': 0.45819209615389506} | train loss {'Reaction outcome loss': 0.18373015608356102, 'Total loss': 0.18373015608356102}
2023-01-04 00:07:43,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:43,916 INFO:     Epoch: 85
2023-01-04 00:07:45,537 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46096085707346596, 'Total loss': 0.46096085707346596} | train loss {'Reaction outcome loss': 0.1866242821842755, 'Total loss': 0.1866242821842755}
2023-01-04 00:07:45,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:45,539 INFO:     Epoch: 86
2023-01-04 00:07:47,131 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4818631847699483, 'Total loss': 0.4818631847699483} | train loss {'Reaction outcome loss': 0.18627941759054412, 'Total loss': 0.18627941759054412}
2023-01-04 00:07:47,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:47,131 INFO:     Epoch: 87
2023-01-04 00:07:48,728 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4863961507876714, 'Total loss': 0.4863961507876714} | train loss {'Reaction outcome loss': 0.18595064217594556, 'Total loss': 0.18595064217594556}
2023-01-04 00:07:48,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:48,729 INFO:     Epoch: 88
2023-01-04 00:07:50,350 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46060097515583037, 'Total loss': 0.46060097515583037} | train loss {'Reaction outcome loss': 0.18425932477836898, 'Total loss': 0.18425932477836898}
2023-01-04 00:07:50,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:50,350 INFO:     Epoch: 89
2023-01-04 00:07:51,929 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46125319401423137, 'Total loss': 0.46125319401423137} | train loss {'Reaction outcome loss': 0.18264481947094954, 'Total loss': 0.18264481947094954}
2023-01-04 00:07:51,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:51,930 INFO:     Epoch: 90
2023-01-04 00:07:53,572 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4577850967645645, 'Total loss': 0.4577850967645645} | train loss {'Reaction outcome loss': 0.18361369802848526, 'Total loss': 0.18361369802848526}
2023-01-04 00:07:53,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:53,572 INFO:     Epoch: 91
2023-01-04 00:07:55,210 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47234243551890054, 'Total loss': 0.47234243551890054} | train loss {'Reaction outcome loss': 0.18080679289593163, 'Total loss': 0.18080679289593163}
2023-01-04 00:07:55,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:55,210 INFO:     Epoch: 92
2023-01-04 00:07:56,814 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4912575721740723, 'Total loss': 0.4912575721740723} | train loss {'Reaction outcome loss': 0.17784291360567622, 'Total loss': 0.17784291360567622}
2023-01-04 00:07:56,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:56,814 INFO:     Epoch: 93
2023-01-04 00:07:58,439 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47869666417439777, 'Total loss': 0.47869666417439777} | train loss {'Reaction outcome loss': 0.18027711569563576, 'Total loss': 0.18027711569563576}
2023-01-04 00:07:58,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:07:58,439 INFO:     Epoch: 94
2023-01-04 00:08:00,073 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4729773978392283, 'Total loss': 0.4729773978392283} | train loss {'Reaction outcome loss': 0.17821735043132456, 'Total loss': 0.17821735043132456}
2023-01-04 00:08:00,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:00,073 INFO:     Epoch: 95
2023-01-04 00:08:01,681 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47848611573378247, 'Total loss': 0.47848611573378247} | train loss {'Reaction outcome loss': 0.1786460564522214, 'Total loss': 0.1786460564522214}
2023-01-04 00:08:01,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:01,681 INFO:     Epoch: 96
2023-01-04 00:08:03,307 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4817950427532196, 'Total loss': 0.4817950427532196} | train loss {'Reaction outcome loss': 0.17508375715961955, 'Total loss': 0.17508375715961955}
2023-01-04 00:08:03,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:03,307 INFO:     Epoch: 97
2023-01-04 00:08:04,902 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4710429032643636, 'Total loss': 0.4710429032643636} | train loss {'Reaction outcome loss': 0.17728878425884764, 'Total loss': 0.17728878425884764}
2023-01-04 00:08:04,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:04,903 INFO:     Epoch: 98
2023-01-04 00:08:06,511 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4709177792072296, 'Total loss': 0.4709177792072296} | train loss {'Reaction outcome loss': 0.17752622480131014, 'Total loss': 0.17752622480131014}
2023-01-04 00:08:06,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:06,511 INFO:     Epoch: 99
2023-01-04 00:08:08,153 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47685960431893665, 'Total loss': 0.47685960431893665} | train loss {'Reaction outcome loss': 0.1734894940407698, 'Total loss': 0.1734894940407698}
2023-01-04 00:08:08,153 INFO:     Best model found after epoch 23 of 100.
2023-01-04 00:08:08,153 INFO:   Done with stage: TRAINING
2023-01-04 00:08:08,153 INFO:   Starting stage: EVALUATION
2023-01-04 00:08:08,276 INFO:   Done with stage: EVALUATION
2023-01-04 00:08:08,277 INFO:   Leaving out SEQ value Fold_7
2023-01-04 00:08:08,289 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 00:08:08,289 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:08:08,931 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:08:08,932 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:08:09,000 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:08:09,000 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:08:09,000 INFO:     No hyperparam tuning for this model
2023-01-04 00:08:09,000 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:08:09,000 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:08:09,001 INFO:     None feature selector for col prot
2023-01-04 00:08:09,001 INFO:     None feature selector for col prot
2023-01-04 00:08:09,001 INFO:     None feature selector for col prot
2023-01-04 00:08:09,002 INFO:     None feature selector for col chem
2023-01-04 00:08:09,002 INFO:     None feature selector for col chem
2023-01-04 00:08:09,002 INFO:     None feature selector for col chem
2023-01-04 00:08:09,002 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:08:09,002 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:08:09,003 INFO:     Number of params in model 70141
2023-01-04 00:08:09,006 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:08:09,007 INFO:   Starting stage: TRAINING
2023-01-04 00:08:09,051 INFO:     Val loss before train {'Reaction outcome loss': 1.0551106293996175, 'Total loss': 1.0551106293996175}
2023-01-04 00:08:09,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:09,051 INFO:     Epoch: 0
2023-01-04 00:08:10,662 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6816325187683105, 'Total loss': 0.6816325187683105} | train loss {'Reaction outcome loss': 0.8502881695536801, 'Total loss': 0.8502881695536801}
2023-01-04 00:08:10,662 INFO:     Found new best model at epoch 0
2023-01-04 00:08:10,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:10,663 INFO:     Epoch: 1
2023-01-04 00:08:12,244 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5750909924507142, 'Total loss': 0.5750909924507142} | train loss {'Reaction outcome loss': 0.6281861829279113, 'Total loss': 0.6281861829279113}
2023-01-04 00:08:12,244 INFO:     Found new best model at epoch 1
2023-01-04 00:08:12,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:12,245 INFO:     Epoch: 2
2023-01-04 00:08:13,834 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5229394197463989, 'Total loss': 0.5229394197463989} | train loss {'Reaction outcome loss': 0.5453422623720482, 'Total loss': 0.5453422623720482}
2023-01-04 00:08:13,834 INFO:     Found new best model at epoch 2
2023-01-04 00:08:13,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:13,835 INFO:     Epoch: 3
2023-01-04 00:08:15,415 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4668570667505264, 'Total loss': 0.4668570667505264} | train loss {'Reaction outcome loss': 0.49974696990782325, 'Total loss': 0.49974696990782325}
2023-01-04 00:08:15,415 INFO:     Found new best model at epoch 3
2023-01-04 00:08:15,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:15,416 INFO:     Epoch: 4
2023-01-04 00:08:17,003 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4743565003077189, 'Total loss': 0.4743565003077189} | train loss {'Reaction outcome loss': 0.47014790963735026, 'Total loss': 0.47014790963735026}
2023-01-04 00:08:17,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:17,003 INFO:     Epoch: 5
2023-01-04 00:08:18,575 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4715767204761505, 'Total loss': 0.4715767204761505} | train loss {'Reaction outcome loss': 0.44779281524846154, 'Total loss': 0.44779281524846154}
2023-01-04 00:08:18,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:18,575 INFO:     Epoch: 6
2023-01-04 00:08:20,164 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4250427891810735, 'Total loss': 0.4250427891810735} | train loss {'Reaction outcome loss': 0.43021029125164895, 'Total loss': 0.43021029125164895}
2023-01-04 00:08:20,164 INFO:     Found new best model at epoch 6
2023-01-04 00:08:20,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:20,165 INFO:     Epoch: 7
2023-01-04 00:08:21,757 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4218042721350988, 'Total loss': 0.4218042721350988} | train loss {'Reaction outcome loss': 0.4190315695574684, 'Total loss': 0.4190315695574684}
2023-01-04 00:08:21,758 INFO:     Found new best model at epoch 7
2023-01-04 00:08:21,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:21,759 INFO:     Epoch: 8
2023-01-04 00:08:23,329 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4122026443481445, 'Total loss': 0.4122026443481445} | train loss {'Reaction outcome loss': 0.4072946281219921, 'Total loss': 0.4072946281219921}
2023-01-04 00:08:23,329 INFO:     Found new best model at epoch 8
2023-01-04 00:08:23,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:23,330 INFO:     Epoch: 9
2023-01-04 00:08:24,910 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.418889719247818, 'Total loss': 0.418889719247818} | train loss {'Reaction outcome loss': 0.39860523274562654, 'Total loss': 0.39860523274562654}
2023-01-04 00:08:24,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:24,910 INFO:     Epoch: 10
2023-01-04 00:08:26,486 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40134274363517763, 'Total loss': 0.40134274363517763} | train loss {'Reaction outcome loss': 0.3856150954961777, 'Total loss': 0.3856150954961777}
2023-01-04 00:08:26,486 INFO:     Found new best model at epoch 10
2023-01-04 00:08:26,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:26,487 INFO:     Epoch: 11
2023-01-04 00:08:28,058 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41144368747870125, 'Total loss': 0.41144368747870125} | train loss {'Reaction outcome loss': 0.3784043831601195, 'Total loss': 0.3784043831601195}
2023-01-04 00:08:28,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:28,059 INFO:     Epoch: 12
2023-01-04 00:08:29,646 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4121039807796478, 'Total loss': 0.4121039807796478} | train loss {'Reaction outcome loss': 0.3717651701919789, 'Total loss': 0.3717651701919789}
2023-01-04 00:08:29,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:29,646 INFO:     Epoch: 13
2023-01-04 00:08:31,236 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39593036770820617, 'Total loss': 0.39593036770820617} | train loss {'Reaction outcome loss': 0.36394518472417425, 'Total loss': 0.36394518472417425}
2023-01-04 00:08:31,236 INFO:     Found new best model at epoch 13
2023-01-04 00:08:31,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:31,237 INFO:     Epoch: 14
2023-01-04 00:08:32,811 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3966164221366247, 'Total loss': 0.3966164221366247} | train loss {'Reaction outcome loss': 0.35615641316466956, 'Total loss': 0.35615641316466956}
2023-01-04 00:08:32,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:32,811 INFO:     Epoch: 15
2023-01-04 00:08:34,402 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3982986052831014, 'Total loss': 0.3982986052831014} | train loss {'Reaction outcome loss': 0.3486904735493399, 'Total loss': 0.3486904735493399}
2023-01-04 00:08:34,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:34,402 INFO:     Epoch: 16
2023-01-04 00:08:35,967 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39710385402043663, 'Total loss': 0.39710385402043663} | train loss {'Reaction outcome loss': 0.3421076008655729, 'Total loss': 0.3421076008655729}
2023-01-04 00:08:35,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:35,967 INFO:     Epoch: 17
2023-01-04 00:08:37,579 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39408182601133984, 'Total loss': 0.39408182601133984} | train loss {'Reaction outcome loss': 0.33813419182152643, 'Total loss': 0.33813419182152643}
2023-01-04 00:08:37,579 INFO:     Found new best model at epoch 17
2023-01-04 00:08:37,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:37,580 INFO:     Epoch: 18
2023-01-04 00:08:39,176 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3973170558611552, 'Total loss': 0.3973170558611552} | train loss {'Reaction outcome loss': 0.33127468049417447, 'Total loss': 0.33127468049417447}
2023-01-04 00:08:39,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:39,177 INFO:     Epoch: 19
2023-01-04 00:08:40,776 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38103689849376676, 'Total loss': 0.38103689849376676} | train loss {'Reaction outcome loss': 0.3234928122510875, 'Total loss': 0.3234928122510875}
2023-01-04 00:08:40,777 INFO:     Found new best model at epoch 19
2023-01-04 00:08:40,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:40,778 INFO:     Epoch: 20
2023-01-04 00:08:42,393 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39901587267716726, 'Total loss': 0.39901587267716726} | train loss {'Reaction outcome loss': 0.3195803146129542, 'Total loss': 0.3195803146129542}
2023-01-04 00:08:42,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:42,393 INFO:     Epoch: 21
2023-01-04 00:08:43,997 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3881520966688792, 'Total loss': 0.3881520966688792} | train loss {'Reaction outcome loss': 0.3162885203576871, 'Total loss': 0.3162885203576871}
2023-01-04 00:08:43,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:43,997 INFO:     Epoch: 22
2023-01-04 00:08:45,567 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.406172255674998, 'Total loss': 0.406172255674998} | train loss {'Reaction outcome loss': 0.31213170836550475, 'Total loss': 0.31213170836550475}
2023-01-04 00:08:45,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:45,567 INFO:     Epoch: 23
2023-01-04 00:08:47,188 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3812261054913203, 'Total loss': 0.3812261054913203} | train loss {'Reaction outcome loss': 0.3060875631950415, 'Total loss': 0.3060875631950415}
2023-01-04 00:08:47,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:47,188 INFO:     Epoch: 24
2023-01-04 00:08:48,789 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38071645696957906, 'Total loss': 0.38071645696957906} | train loss {'Reaction outcome loss': 0.301256514324324, 'Total loss': 0.301256514324324}
2023-01-04 00:08:48,789 INFO:     Found new best model at epoch 24
2023-01-04 00:08:48,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:48,790 INFO:     Epoch: 25
2023-01-04 00:08:50,374 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3665514051914215, 'Total loss': 0.3665514051914215} | train loss {'Reaction outcome loss': 0.2948031124597701, 'Total loss': 0.2948031124597701}
2023-01-04 00:08:50,374 INFO:     Found new best model at epoch 25
2023-01-04 00:08:50,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:50,375 INFO:     Epoch: 26
2023-01-04 00:08:51,992 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3696683347225189, 'Total loss': 0.3696683347225189} | train loss {'Reaction outcome loss': 0.29254257532149336, 'Total loss': 0.29254257532149336}
2023-01-04 00:08:51,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:51,993 INFO:     Epoch: 27
2023-01-04 00:08:53,610 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39812324742476146, 'Total loss': 0.39812324742476146} | train loss {'Reaction outcome loss': 0.28766153089321445, 'Total loss': 0.28766153089321445}
2023-01-04 00:08:53,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:53,610 INFO:     Epoch: 28
2023-01-04 00:08:55,185 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.37919342319170635, 'Total loss': 0.37919342319170635} | train loss {'Reaction outcome loss': 0.2857898433223693, 'Total loss': 0.2857898433223693}
2023-01-04 00:08:55,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:55,185 INFO:     Epoch: 29
2023-01-04 00:08:56,775 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38669920961062115, 'Total loss': 0.38669920961062115} | train loss {'Reaction outcome loss': 0.2791660775287743, 'Total loss': 0.2791660775287743}
2023-01-04 00:08:56,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:56,776 INFO:     Epoch: 30
2023-01-04 00:08:58,364 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3704293717940648, 'Total loss': 0.3704293717940648} | train loss {'Reaction outcome loss': 0.2743444597199015, 'Total loss': 0.2743444597199015}
2023-01-04 00:08:58,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:58,364 INFO:     Epoch: 31
2023-01-04 00:08:59,955 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4010646233956019, 'Total loss': 0.4010646233956019} | train loss {'Reaction outcome loss': 0.2719703129472306, 'Total loss': 0.2719703129472306}
2023-01-04 00:08:59,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:08:59,956 INFO:     Epoch: 32
2023-01-04 00:09:01,563 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4144286553064982, 'Total loss': 0.4144286553064982} | train loss {'Reaction outcome loss': 0.26702763961396947, 'Total loss': 0.26702763961396947}
2023-01-04 00:09:01,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:01,563 INFO:     Epoch: 33
2023-01-04 00:09:03,148 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3686366617679596, 'Total loss': 0.3686366617679596} | train loss {'Reaction outcome loss': 0.2632686891151171, 'Total loss': 0.2632686891151171}
2023-01-04 00:09:03,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:03,148 INFO:     Epoch: 34
2023-01-04 00:09:04,720 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.379541344443957, 'Total loss': 0.379541344443957} | train loss {'Reaction outcome loss': 0.26082933588075813, 'Total loss': 0.26082933588075813}
2023-01-04 00:09:04,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:04,720 INFO:     Epoch: 35
2023-01-04 00:09:06,334 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4036503871281942, 'Total loss': 0.4036503871281942} | train loss {'Reaction outcome loss': 0.25528619748397463, 'Total loss': 0.25528619748397463}
2023-01-04 00:09:06,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:06,334 INFO:     Epoch: 36
2023-01-04 00:09:07,912 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3663410651187102, 'Total loss': 0.3663410651187102} | train loss {'Reaction outcome loss': 0.25373442813645314, 'Total loss': 0.25373442813645314}
2023-01-04 00:09:07,912 INFO:     Found new best model at epoch 36
2023-01-04 00:09:07,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:07,913 INFO:     Epoch: 37
2023-01-04 00:09:09,500 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3789417386054993, 'Total loss': 0.3789417386054993} | train loss {'Reaction outcome loss': 0.25050268307273843, 'Total loss': 0.25050268307273843}
2023-01-04 00:09:09,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:09,500 INFO:     Epoch: 38
2023-01-04 00:09:11,088 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.38194250464439394, 'Total loss': 0.38194250464439394} | train loss {'Reaction outcome loss': 0.2479985373869647, 'Total loss': 0.2479985373869647}
2023-01-04 00:09:11,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:11,088 INFO:     Epoch: 39
2023-01-04 00:09:12,647 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.37217028041680655, 'Total loss': 0.37217028041680655} | train loss {'Reaction outcome loss': 0.24712214979213953, 'Total loss': 0.24712214979213953}
2023-01-04 00:09:12,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:12,647 INFO:     Epoch: 40
2023-01-04 00:09:14,261 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38571702837944033, 'Total loss': 0.38571702837944033} | train loss {'Reaction outcome loss': 0.24035077010464928, 'Total loss': 0.24035077010464928}
2023-01-04 00:09:14,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:14,262 INFO:     Epoch: 41
2023-01-04 00:09:15,870 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38363341937462486, 'Total loss': 0.38363341937462486} | train loss {'Reaction outcome loss': 0.23685055882771955, 'Total loss': 0.23685055882771955}
2023-01-04 00:09:15,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:15,871 INFO:     Epoch: 42
2023-01-04 00:09:17,468 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.388221400976181, 'Total loss': 0.388221400976181} | train loss {'Reaction outcome loss': 0.23384322120678902, 'Total loss': 0.23384322120678902}
2023-01-04 00:09:17,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:17,468 INFO:     Epoch: 43
2023-01-04 00:09:19,085 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40341495275497435, 'Total loss': 0.40341495275497435} | train loss {'Reaction outcome loss': 0.2354319172836568, 'Total loss': 0.2354319172836568}
2023-01-04 00:09:19,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:19,086 INFO:     Epoch: 44
2023-01-04 00:09:20,694 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38762067407369616, 'Total loss': 0.38762067407369616} | train loss {'Reaction outcome loss': 0.23073879254125332, 'Total loss': 0.23073879254125332}
2023-01-04 00:09:20,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:20,694 INFO:     Epoch: 45
2023-01-04 00:09:22,297 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38004059592882794, 'Total loss': 0.38004059592882794} | train loss {'Reaction outcome loss': 0.22927896958524294, 'Total loss': 0.22927896958524294}
2023-01-04 00:09:22,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:22,298 INFO:     Epoch: 46
2023-01-04 00:09:23,914 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3924811522165934, 'Total loss': 0.3924811522165934} | train loss {'Reaction outcome loss': 0.22617632417130645, 'Total loss': 0.22617632417130645}
2023-01-04 00:09:23,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:23,915 INFO:     Epoch: 47
2023-01-04 00:09:25,532 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39944360852241517, 'Total loss': 0.39944360852241517} | train loss {'Reaction outcome loss': 0.22613377987413946, 'Total loss': 0.22613377987413946}
2023-01-04 00:09:25,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:25,533 INFO:     Epoch: 48
2023-01-04 00:09:27,108 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4088312824567159, 'Total loss': 0.4088312824567159} | train loss {'Reaction outcome loss': 0.22376469495522716, 'Total loss': 0.22376469495522716}
2023-01-04 00:09:27,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:27,109 INFO:     Epoch: 49
2023-01-04 00:09:28,725 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38037408192952477, 'Total loss': 0.38037408192952477} | train loss {'Reaction outcome loss': 0.22010481849747854, 'Total loss': 0.22010481849747854}
2023-01-04 00:09:28,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:28,725 INFO:     Epoch: 50
2023-01-04 00:09:30,316 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.398601766427358, 'Total loss': 0.398601766427358} | train loss {'Reaction outcome loss': 0.21809537790335007, 'Total loss': 0.21809537790335007}
2023-01-04 00:09:30,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:30,316 INFO:     Epoch: 51
2023-01-04 00:09:31,929 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3973967840274175, 'Total loss': 0.3973967840274175} | train loss {'Reaction outcome loss': 0.2208138666775105, 'Total loss': 0.2208138666775105}
2023-01-04 00:09:31,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:31,929 INFO:     Epoch: 52
2023-01-04 00:09:33,542 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.37897519717613853, 'Total loss': 0.37897519717613853} | train loss {'Reaction outcome loss': 0.216202854960613, 'Total loss': 0.216202854960613}
2023-01-04 00:09:33,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:33,543 INFO:     Epoch: 53
2023-01-04 00:09:35,108 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4075416048367818, 'Total loss': 0.4075416048367818} | train loss {'Reaction outcome loss': 0.2143460237794984, 'Total loss': 0.2143460237794984}
2023-01-04 00:09:35,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:35,108 INFO:     Epoch: 54
2023-01-04 00:09:36,695 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3966630587975184, 'Total loss': 0.3966630587975184} | train loss {'Reaction outcome loss': 0.21247385563260882, 'Total loss': 0.21247385563260882}
2023-01-04 00:09:36,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:36,695 INFO:     Epoch: 55
2023-01-04 00:09:38,283 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39954765637715656, 'Total loss': 0.39954765637715656} | train loss {'Reaction outcome loss': 0.21226967601989308, 'Total loss': 0.21226967601989308}
2023-01-04 00:09:38,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:38,283 INFO:     Epoch: 56
2023-01-04 00:09:39,857 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4087854961554209, 'Total loss': 0.4087854961554209} | train loss {'Reaction outcome loss': 0.21091350787965052, 'Total loss': 0.21091350787965052}
2023-01-04 00:09:39,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:39,857 INFO:     Epoch: 57
2023-01-04 00:09:41,462 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4165708263715108, 'Total loss': 0.4165708263715108} | train loss {'Reaction outcome loss': 0.20807166326872623, 'Total loss': 0.20807166326872623}
2023-01-04 00:09:41,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:41,463 INFO:     Epoch: 58
2023-01-04 00:09:43,086 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38971150318781533, 'Total loss': 0.38971150318781533} | train loss {'Reaction outcome loss': 0.20586305510007988, 'Total loss': 0.20586305510007988}
2023-01-04 00:09:43,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:43,086 INFO:     Epoch: 59
2023-01-04 00:09:44,680 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41558065712451936, 'Total loss': 0.41558065712451936} | train loss {'Reaction outcome loss': 0.20545657261879774, 'Total loss': 0.20545657261879774}
2023-01-04 00:09:44,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:44,680 INFO:     Epoch: 60
2023-01-04 00:09:46,294 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37460062305132547, 'Total loss': 0.37460062305132547} | train loss {'Reaction outcome loss': 0.20331754057538987, 'Total loss': 0.20331754057538987}
2023-01-04 00:09:46,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:46,295 INFO:     Epoch: 61
2023-01-04 00:09:47,882 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4077257464329402, 'Total loss': 0.4077257464329402} | train loss {'Reaction outcome loss': 0.20224286626045504, 'Total loss': 0.20224286626045504}
2023-01-04 00:09:47,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:47,883 INFO:     Epoch: 62
2023-01-04 00:09:49,467 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40111169815063474, 'Total loss': 0.40111169815063474} | train loss {'Reaction outcome loss': 0.20181021819666137, 'Total loss': 0.20181021819666137}
2023-01-04 00:09:49,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:49,468 INFO:     Epoch: 63
2023-01-04 00:09:51,066 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4014185090859731, 'Total loss': 0.4014185090859731} | train loss {'Reaction outcome loss': 0.20178639230719447, 'Total loss': 0.20178639230719447}
2023-01-04 00:09:51,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:51,066 INFO:     Epoch: 64
2023-01-04 00:09:52,684 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3924866884946823, 'Total loss': 0.3924866884946823} | train loss {'Reaction outcome loss': 0.20003954239570312, 'Total loss': 0.20003954239570312}
2023-01-04 00:09:52,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:52,684 INFO:     Epoch: 65
2023-01-04 00:09:54,293 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43376978635787966, 'Total loss': 0.43376978635787966} | train loss {'Reaction outcome loss': 0.19989249546651858, 'Total loss': 0.19989249546651858}
2023-01-04 00:09:54,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:54,293 INFO:     Epoch: 66
2023-01-04 00:09:55,904 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4169206788142522, 'Total loss': 0.4169206788142522} | train loss {'Reaction outcome loss': 0.19681427643437238, 'Total loss': 0.19681427643437238}
2023-01-04 00:09:55,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:55,905 INFO:     Epoch: 67
2023-01-04 00:09:57,502 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41753433644771576, 'Total loss': 0.41753433644771576} | train loss {'Reaction outcome loss': 0.19872203733037858, 'Total loss': 0.19872203733037858}
2023-01-04 00:09:57,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:57,504 INFO:     Epoch: 68
2023-01-04 00:09:59,116 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41276051302750905, 'Total loss': 0.41276051302750905} | train loss {'Reaction outcome loss': 0.19457431163394104, 'Total loss': 0.19457431163394104}
2023-01-04 00:09:59,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:09:59,116 INFO:     Epoch: 69
2023-01-04 00:10:00,732 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40785154402256013, 'Total loss': 0.40785154402256013} | train loss {'Reaction outcome loss': 0.19407840112536928, 'Total loss': 0.19407840112536928}
2023-01-04 00:10:00,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:00,732 INFO:     Epoch: 70
2023-01-04 00:10:02,328 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4363579491774241, 'Total loss': 0.4363579491774241} | train loss {'Reaction outcome loss': 0.19271438825114148, 'Total loss': 0.19271438825114148}
2023-01-04 00:10:02,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:02,328 INFO:     Epoch: 71
2023-01-04 00:10:03,942 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42512320379416146, 'Total loss': 0.42512320379416146} | train loss {'Reaction outcome loss': 0.19127788298158316, 'Total loss': 0.19127788298158316}
2023-01-04 00:10:03,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:03,943 INFO:     Epoch: 72
2023-01-04 00:10:05,565 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4317220350106557, 'Total loss': 0.4317220350106557} | train loss {'Reaction outcome loss': 0.19091030794882427, 'Total loss': 0.19091030794882427}
2023-01-04 00:10:05,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:05,566 INFO:     Epoch: 73
2023-01-04 00:10:07,154 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40012703935305277, 'Total loss': 0.40012703935305277} | train loss {'Reaction outcome loss': 0.1903053696817943, 'Total loss': 0.1903053696817943}
2023-01-04 00:10:07,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:07,154 INFO:     Epoch: 74
2023-01-04 00:10:08,815 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40450316270192466, 'Total loss': 0.40450316270192466} | train loss {'Reaction outcome loss': 0.1889697745523966, 'Total loss': 0.1889697745523966}
2023-01-04 00:10:08,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:08,815 INFO:     Epoch: 75
2023-01-04 00:10:10,427 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4219513843456904, 'Total loss': 0.4219513843456904} | train loss {'Reaction outcome loss': 0.18883720777901639, 'Total loss': 0.18883720777901639}
2023-01-04 00:10:10,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:10,428 INFO:     Epoch: 76
2023-01-04 00:10:11,769 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43515261461337407, 'Total loss': 0.43515261461337407} | train loss {'Reaction outcome loss': 0.18696802704982515, 'Total loss': 0.18696802704982515}
2023-01-04 00:10:11,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:11,769 INFO:     Epoch: 77
2023-01-04 00:10:12,852 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4233660956223806, 'Total loss': 0.4233660956223806} | train loss {'Reaction outcome loss': 0.1866817390410243, 'Total loss': 0.1866817390410243}
2023-01-04 00:10:12,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:12,852 INFO:     Epoch: 78
2023-01-04 00:10:13,932 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4054399311542511, 'Total loss': 0.4054399311542511} | train loss {'Reaction outcome loss': 0.18802419508786966, 'Total loss': 0.18802419508786966}
2023-01-04 00:10:13,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:13,932 INFO:     Epoch: 79
2023-01-04 00:10:15,001 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41079213519891106, 'Total loss': 0.41079213519891106} | train loss {'Reaction outcome loss': 0.18499081898616612, 'Total loss': 0.18499081898616612}
2023-01-04 00:10:15,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:15,001 INFO:     Epoch: 80
2023-01-04 00:10:16,428 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42746505240599314, 'Total loss': 0.42746505240599314} | train loss {'Reaction outcome loss': 0.18257193416900877, 'Total loss': 0.18257193416900877}
2023-01-04 00:10:16,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:16,429 INFO:     Epoch: 81
2023-01-04 00:10:18,026 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4298482338587443, 'Total loss': 0.4298482338587443} | train loss {'Reaction outcome loss': 0.1804468006874523, 'Total loss': 0.1804468006874523}
2023-01-04 00:10:18,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:18,026 INFO:     Epoch: 82
2023-01-04 00:10:19,641 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4029923309882482, 'Total loss': 0.4029923309882482} | train loss {'Reaction outcome loss': 0.17981970058686106, 'Total loss': 0.17981970058686106}
2023-01-04 00:10:19,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:19,641 INFO:     Epoch: 83
2023-01-04 00:10:21,227 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41507200996081034, 'Total loss': 0.41507200996081034} | train loss {'Reaction outcome loss': 0.18162576786249224, 'Total loss': 0.18162576786249224}
2023-01-04 00:10:21,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:21,227 INFO:     Epoch: 84
2023-01-04 00:10:22,810 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.405681045850118, 'Total loss': 0.405681045850118} | train loss {'Reaction outcome loss': 0.18183031580308928, 'Total loss': 0.18183031580308928}
2023-01-04 00:10:22,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:22,810 INFO:     Epoch: 85
2023-01-04 00:10:24,382 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41237515906492866, 'Total loss': 0.41237515906492866} | train loss {'Reaction outcome loss': 0.18109194502016923, 'Total loss': 0.18109194502016923}
2023-01-04 00:10:24,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:24,382 INFO:     Epoch: 86
2023-01-04 00:10:25,989 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.429108660419782, 'Total loss': 0.429108660419782} | train loss {'Reaction outcome loss': 0.17983982625016331, 'Total loss': 0.17983982625016331}
2023-01-04 00:10:25,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:25,989 INFO:     Epoch: 87
2023-01-04 00:10:27,587 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4097591256101926, 'Total loss': 0.4097591256101926} | train loss {'Reaction outcome loss': 0.17832800966898238, 'Total loss': 0.17832800966898238}
2023-01-04 00:10:27,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:27,587 INFO:     Epoch: 88
2023-01-04 00:10:29,167 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4107162455717723, 'Total loss': 0.4107162455717723} | train loss {'Reaction outcome loss': 0.1778170371659263, 'Total loss': 0.1778170371659263}
2023-01-04 00:10:29,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:29,168 INFO:     Epoch: 89
2023-01-04 00:10:30,750 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43431181808312735, 'Total loss': 0.43431181808312735} | train loss {'Reaction outcome loss': 0.17766462202544195, 'Total loss': 0.17766462202544195}
2023-01-04 00:10:30,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:30,750 INFO:     Epoch: 90
2023-01-04 00:10:32,349 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39738351504007974, 'Total loss': 0.39738351504007974} | train loss {'Reaction outcome loss': 0.17806038778465594, 'Total loss': 0.17806038778465594}
2023-01-04 00:10:32,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:32,349 INFO:     Epoch: 91
2023-01-04 00:10:33,941 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4182279646396637, 'Total loss': 0.4182279646396637} | train loss {'Reaction outcome loss': 0.1762759147252697, 'Total loss': 0.1762759147252697}
2023-01-04 00:10:33,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:33,943 INFO:     Epoch: 92
2023-01-04 00:10:35,525 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4258573591709137, 'Total loss': 0.4258573591709137} | train loss {'Reaction outcome loss': 0.1766305080050752, 'Total loss': 0.1766305080050752}
2023-01-04 00:10:35,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:35,525 INFO:     Epoch: 93
2023-01-04 00:10:37,113 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43796150585015614, 'Total loss': 0.43796150585015614} | train loss {'Reaction outcome loss': 0.17631752405614748, 'Total loss': 0.17631752405614748}
2023-01-04 00:10:37,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:37,113 INFO:     Epoch: 94
2023-01-04 00:10:38,701 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43451810876528424, 'Total loss': 0.43451810876528424} | train loss {'Reaction outcome loss': 0.17549901578004343, 'Total loss': 0.17549901578004343}
2023-01-04 00:10:38,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:38,701 INFO:     Epoch: 95
2023-01-04 00:10:40,268 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4275615572929382, 'Total loss': 0.4275615572929382} | train loss {'Reaction outcome loss': 0.1761836851301202, 'Total loss': 0.1761836851301202}
2023-01-04 00:10:40,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:40,269 INFO:     Epoch: 96
2023-01-04 00:10:41,844 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4623189906279246, 'Total loss': 0.4623189906279246} | train loss {'Reaction outcome loss': 0.17353291082175543, 'Total loss': 0.17353291082175543}
2023-01-04 00:10:41,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:41,845 INFO:     Epoch: 97
2023-01-04 00:10:43,434 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4056752820809682, 'Total loss': 0.4056752820809682} | train loss {'Reaction outcome loss': 0.17437396152284892, 'Total loss': 0.17437396152284892}
2023-01-04 00:10:43,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:43,434 INFO:     Epoch: 98
2023-01-04 00:10:45,050 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4059699724117915, 'Total loss': 0.4059699724117915} | train loss {'Reaction outcome loss': 0.17275017977141552, 'Total loss': 0.17275017977141552}
2023-01-04 00:10:45,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:45,050 INFO:     Epoch: 99
2023-01-04 00:10:46,656 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4239119976758957, 'Total loss': 0.4239119976758957} | train loss {'Reaction outcome loss': 0.17394099857005543, 'Total loss': 0.17394099857005543}
2023-01-04 00:10:46,656 INFO:     Best model found after epoch 37 of 100.
2023-01-04 00:10:46,656 INFO:   Done with stage: TRAINING
2023-01-04 00:10:46,656 INFO:   Starting stage: EVALUATION
2023-01-04 00:10:46,793 INFO:   Done with stage: EVALUATION
2023-01-04 00:10:46,793 INFO:   Leaving out SEQ value Fold_8
2023-01-04 00:10:46,805 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 00:10:46,805 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:10:47,456 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:10:47,456 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:10:47,526 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:10:47,526 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:10:47,526 INFO:     No hyperparam tuning for this model
2023-01-04 00:10:47,526 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:10:47,526 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:10:47,527 INFO:     None feature selector for col prot
2023-01-04 00:10:47,527 INFO:     None feature selector for col prot
2023-01-04 00:10:47,527 INFO:     None feature selector for col prot
2023-01-04 00:10:47,528 INFO:     None feature selector for col chem
2023-01-04 00:10:47,528 INFO:     None feature selector for col chem
2023-01-04 00:10:47,528 INFO:     None feature selector for col chem
2023-01-04 00:10:47,528 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:10:47,528 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:10:47,529 INFO:     Number of params in model 70141
2023-01-04 00:10:47,532 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:10:47,532 INFO:   Starting stage: TRAINING
2023-01-04 00:10:47,576 INFO:     Val loss before train {'Reaction outcome loss': 0.9520800828933715, 'Total loss': 0.9520800828933715}
2023-01-04 00:10:47,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:47,576 INFO:     Epoch: 0
2023-01-04 00:10:49,164 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5915126959482829, 'Total loss': 0.5915126959482829} | train loss {'Reaction outcome loss': 0.8333297289558266, 'Total loss': 0.8333297289558266}
2023-01-04 00:10:49,164 INFO:     Found new best model at epoch 0
2023-01-04 00:10:49,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:49,165 INFO:     Epoch: 1
2023-01-04 00:10:50,782 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4768086651961009, 'Total loss': 0.4768086651961009} | train loss {'Reaction outcome loss': 0.6013487505353314, 'Total loss': 0.6013487505353314}
2023-01-04 00:10:50,782 INFO:     Found new best model at epoch 1
2023-01-04 00:10:50,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:50,783 INFO:     Epoch: 2
2023-01-04 00:10:52,380 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4608301083246867, 'Total loss': 0.4608301083246867} | train loss {'Reaction outcome loss': 0.5271144302205488, 'Total loss': 0.5271144302205488}
2023-01-04 00:10:52,381 INFO:     Found new best model at epoch 2
2023-01-04 00:10:52,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:52,382 INFO:     Epoch: 3
2023-01-04 00:10:54,000 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4316873202721278, 'Total loss': 0.4316873202721278} | train loss {'Reaction outcome loss': 0.4809626557121208, 'Total loss': 0.4809626557121208}
2023-01-04 00:10:54,000 INFO:     Found new best model at epoch 3
2023-01-04 00:10:54,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:54,001 INFO:     Epoch: 4
2023-01-04 00:10:55,625 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.42230570514996846, 'Total loss': 0.42230570514996846} | train loss {'Reaction outcome loss': 0.4536547981444679, 'Total loss': 0.4536547981444679}
2023-01-04 00:10:55,625 INFO:     Found new best model at epoch 4
2023-01-04 00:10:55,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:55,626 INFO:     Epoch: 5
2023-01-04 00:10:57,250 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.417352290948232, 'Total loss': 0.417352290948232} | train loss {'Reaction outcome loss': 0.43199487885843546, 'Total loss': 0.43199487885843546}
2023-01-04 00:10:57,250 INFO:     Found new best model at epoch 5
2023-01-04 00:10:57,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:57,251 INFO:     Epoch: 6
2023-01-04 00:10:58,851 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4127918243408203, 'Total loss': 0.4127918243408203} | train loss {'Reaction outcome loss': 0.41332097464520146, 'Total loss': 0.41332097464520146}
2023-01-04 00:10:58,852 INFO:     Found new best model at epoch 6
2023-01-04 00:10:58,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:10:58,852 INFO:     Epoch: 7
2023-01-04 00:11:00,458 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40763800740242007, 'Total loss': 0.40763800740242007} | train loss {'Reaction outcome loss': 0.4020832746898224, 'Total loss': 0.4020832746898224}
2023-01-04 00:11:00,459 INFO:     Found new best model at epoch 7
2023-01-04 00:11:00,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:00,459 INFO:     Epoch: 8
2023-01-04 00:11:02,075 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3993040462334951, 'Total loss': 0.3993040462334951} | train loss {'Reaction outcome loss': 0.39092183021646976, 'Total loss': 0.39092183021646976}
2023-01-04 00:11:02,075 INFO:     Found new best model at epoch 8
2023-01-04 00:11:02,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:02,076 INFO:     Epoch: 9
2023-01-04 00:11:03,681 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3835763901472092, 'Total loss': 0.3835763901472092} | train loss {'Reaction outcome loss': 0.37866808159364257, 'Total loss': 0.37866808159364257}
2023-01-04 00:11:03,681 INFO:     Found new best model at epoch 9
2023-01-04 00:11:03,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:03,682 INFO:     Epoch: 10
2023-01-04 00:11:05,289 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.38322516679763796, 'Total loss': 0.38322516679763796} | train loss {'Reaction outcome loss': 0.368041489259861, 'Total loss': 0.368041489259861}
2023-01-04 00:11:05,290 INFO:     Found new best model at epoch 10
2023-01-04 00:11:05,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:05,291 INFO:     Epoch: 11
2023-01-04 00:11:06,876 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3849984496831894, 'Total loss': 0.3849984496831894} | train loss {'Reaction outcome loss': 0.35993413845016636, 'Total loss': 0.35993413845016636}
2023-01-04 00:11:06,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:06,876 INFO:     Epoch: 12
2023-01-04 00:11:08,509 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.37666933139165243, 'Total loss': 0.37666933139165243} | train loss {'Reaction outcome loss': 0.354910449323241, 'Total loss': 0.354910449323241}
2023-01-04 00:11:08,509 INFO:     Found new best model at epoch 12
2023-01-04 00:11:08,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:08,510 INFO:     Epoch: 13
2023-01-04 00:11:10,109 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3957277437051137, 'Total loss': 0.3957277437051137} | train loss {'Reaction outcome loss': 0.3428780183680221, 'Total loss': 0.3428780183680221}
2023-01-04 00:11:10,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:10,110 INFO:     Epoch: 14
2023-01-04 00:11:11,731 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3831639568010966, 'Total loss': 0.3831639568010966} | train loss {'Reaction outcome loss': 0.3352171053524913, 'Total loss': 0.3352171053524913}
2023-01-04 00:11:11,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:11,732 INFO:     Epoch: 15
2023-01-04 00:11:13,349 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.38751101394494375, 'Total loss': 0.38751101394494375} | train loss {'Reaction outcome loss': 0.32930257362364, 'Total loss': 0.32930257362364}
2023-01-04 00:11:13,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:13,349 INFO:     Epoch: 16
2023-01-04 00:11:14,975 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39954617818196614, 'Total loss': 0.39954617818196614} | train loss {'Reaction outcome loss': 0.3239277912176043, 'Total loss': 0.3239277912176043}
2023-01-04 00:11:14,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:14,975 INFO:     Epoch: 17
2023-01-04 00:11:16,564 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3953622003396352, 'Total loss': 0.3953622003396352} | train loss {'Reaction outcome loss': 0.31889213557062596, 'Total loss': 0.31889213557062596}
2023-01-04 00:11:16,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:16,565 INFO:     Epoch: 18
2023-01-04 00:11:18,153 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4070479363203049, 'Total loss': 0.4070479363203049} | train loss {'Reaction outcome loss': 0.31074935031066303, 'Total loss': 0.31074935031066303}
2023-01-04 00:11:18,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:18,153 INFO:     Epoch: 19
2023-01-04 00:11:19,777 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3975507378578186, 'Total loss': 0.3975507378578186} | train loss {'Reaction outcome loss': 0.30620435103505095, 'Total loss': 0.30620435103505095}
2023-01-04 00:11:19,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:19,778 INFO:     Epoch: 20
2023-01-04 00:11:21,406 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3928804208834966, 'Total loss': 0.3928804208834966} | train loss {'Reaction outcome loss': 0.300069478552264, 'Total loss': 0.300069478552264}
2023-01-04 00:11:21,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:21,406 INFO:     Epoch: 21
2023-01-04 00:11:23,040 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3976192166407903, 'Total loss': 0.3976192166407903} | train loss {'Reaction outcome loss': 0.2952540429167799, 'Total loss': 0.2952540429167799}
2023-01-04 00:11:23,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:23,040 INFO:     Epoch: 22
2023-01-04 00:11:24,647 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4263704280058543, 'Total loss': 0.4263704280058543} | train loss {'Reaction outcome loss': 0.2890663538329868, 'Total loss': 0.2890663538329868}
2023-01-04 00:11:24,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:24,648 INFO:     Epoch: 23
2023-01-04 00:11:26,249 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3979508449633916, 'Total loss': 0.3979508449633916} | train loss {'Reaction outcome loss': 0.28571224664522854, 'Total loss': 0.28571224664522854}
2023-01-04 00:11:26,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:26,249 INFO:     Epoch: 24
2023-01-04 00:11:27,848 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38895609180132545, 'Total loss': 0.38895609180132545} | train loss {'Reaction outcome loss': 0.2830888680871643, 'Total loss': 0.2830888680871643}
2023-01-04 00:11:27,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:27,848 INFO:     Epoch: 25
2023-01-04 00:11:29,478 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3915190726518631, 'Total loss': 0.3915190726518631} | train loss {'Reaction outcome loss': 0.2783029999193947, 'Total loss': 0.2783029999193947}
2023-01-04 00:11:29,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:29,478 INFO:     Epoch: 26
2023-01-04 00:11:31,098 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40849310557047525, 'Total loss': 0.40849310557047525} | train loss {'Reaction outcome loss': 0.27429894175017355, 'Total loss': 0.27429894175017355}
2023-01-04 00:11:31,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:31,099 INFO:     Epoch: 27
2023-01-04 00:11:32,726 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4026108423868815, 'Total loss': 0.4026108423868815} | train loss {'Reaction outcome loss': 0.27145316443718726, 'Total loss': 0.27145316443718726}
2023-01-04 00:11:32,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:32,726 INFO:     Epoch: 28
2023-01-04 00:11:34,314 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4029272774855296, 'Total loss': 0.4029272774855296} | train loss {'Reaction outcome loss': 0.26907947557282363, 'Total loss': 0.26907947557282363}
2023-01-04 00:11:34,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:34,315 INFO:     Epoch: 29
2023-01-04 00:11:35,912 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40998714963595073, 'Total loss': 0.40998714963595073} | train loss {'Reaction outcome loss': 0.26475163541115576, 'Total loss': 0.26475163541115576}
2023-01-04 00:11:35,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:35,912 INFO:     Epoch: 30
2023-01-04 00:11:37,521 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39775531689325966, 'Total loss': 0.39775531689325966} | train loss {'Reaction outcome loss': 0.262015702680345, 'Total loss': 0.262015702680345}
2023-01-04 00:11:37,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:37,521 INFO:     Epoch: 31
2023-01-04 00:11:39,148 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40443290074666344, 'Total loss': 0.40443290074666344} | train loss {'Reaction outcome loss': 0.25927626064538095, 'Total loss': 0.25927626064538095}
2023-01-04 00:11:39,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:39,148 INFO:     Epoch: 32
2023-01-04 00:11:40,773 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40822740594546, 'Total loss': 0.40822740594546} | train loss {'Reaction outcome loss': 0.25594250642650823, 'Total loss': 0.25594250642650823}
2023-01-04 00:11:40,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:40,774 INFO:     Epoch: 33
2023-01-04 00:11:42,393 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4153110335270564, 'Total loss': 0.4153110335270564} | train loss {'Reaction outcome loss': 0.25177696561070984, 'Total loss': 0.25177696561070984}
2023-01-04 00:11:42,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:42,393 INFO:     Epoch: 34
2023-01-04 00:11:43,977 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40682230989138285, 'Total loss': 0.40682230989138285} | train loss {'Reaction outcome loss': 0.24984374201254725, 'Total loss': 0.24984374201254725}
2023-01-04 00:11:43,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:43,978 INFO:     Epoch: 35
2023-01-04 00:11:45,566 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40896572520335517, 'Total loss': 0.40896572520335517} | train loss {'Reaction outcome loss': 0.24808068866656574, 'Total loss': 0.24808068866656574}
2023-01-04 00:11:45,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:45,566 INFO:     Epoch: 36
2023-01-04 00:11:47,194 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4191186646620432, 'Total loss': 0.4191186646620432} | train loss {'Reaction outcome loss': 0.24801349204154652, 'Total loss': 0.24801349204154652}
2023-01-04 00:11:47,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:47,195 INFO:     Epoch: 37
2023-01-04 00:11:48,820 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40570681989192964, 'Total loss': 0.40570681989192964} | train loss {'Reaction outcome loss': 0.24351794641155627, 'Total loss': 0.24351794641155627}
2023-01-04 00:11:48,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:48,821 INFO:     Epoch: 38
2023-01-04 00:11:50,450 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41599085330963137, 'Total loss': 0.41599085330963137} | train loss {'Reaction outcome loss': 0.24028939799496413, 'Total loss': 0.24028939799496413}
2023-01-04 00:11:50,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:50,451 INFO:     Epoch: 39
2023-01-04 00:11:52,048 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41646212140719097, 'Total loss': 0.41646212140719097} | train loss {'Reaction outcome loss': 0.23910482867960464, 'Total loss': 0.23910482867960464}
2023-01-04 00:11:52,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:52,048 INFO:     Epoch: 40
2023-01-04 00:11:53,652 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4198619167009989, 'Total loss': 0.4198619167009989} | train loss {'Reaction outcome loss': 0.23632735975543945, 'Total loss': 0.23632735975543945}
2023-01-04 00:11:53,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:53,652 INFO:     Epoch: 41
2023-01-04 00:11:55,261 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4196762705842654, 'Total loss': 0.4196762705842654} | train loss {'Reaction outcome loss': 0.2345523462909869, 'Total loss': 0.2345523462909869}
2023-01-04 00:11:55,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:55,261 INFO:     Epoch: 42
2023-01-04 00:11:56,896 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4090123275915782, 'Total loss': 0.4090123275915782} | train loss {'Reaction outcome loss': 0.23183841029659505, 'Total loss': 0.23183841029659505}
2023-01-04 00:11:56,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:56,896 INFO:     Epoch: 43
2023-01-04 00:11:58,531 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4094624698162079, 'Total loss': 0.4094624698162079} | train loss {'Reaction outcome loss': 0.22732734690934742, 'Total loss': 0.22732734690934742}
2023-01-04 00:11:58,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:11:58,531 INFO:     Epoch: 44
2023-01-04 00:12:00,157 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4182210663954417, 'Total loss': 0.4182210663954417} | train loss {'Reaction outcome loss': 0.2277358252326504, 'Total loss': 0.2277358252326504}
2023-01-04 00:12:00,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:00,157 INFO:     Epoch: 45
2023-01-04 00:12:01,742 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4371087819337845, 'Total loss': 0.4371087819337845} | train loss {'Reaction outcome loss': 0.2267747192781432, 'Total loss': 0.2267747192781432}
2023-01-04 00:12:01,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:01,742 INFO:     Epoch: 46
2023-01-04 00:12:03,330 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43181661814451217, 'Total loss': 0.43181661814451217} | train loss {'Reaction outcome loss': 0.2251126083548749, 'Total loss': 0.2251126083548749}
2023-01-04 00:12:03,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:03,330 INFO:     Epoch: 47
2023-01-04 00:12:04,959 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41773863434791564, 'Total loss': 0.41773863434791564} | train loss {'Reaction outcome loss': 0.2229730374842129, 'Total loss': 0.2229730374842129}
2023-01-04 00:12:04,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:04,959 INFO:     Epoch: 48
2023-01-04 00:12:06,584 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4251541564861933, 'Total loss': 0.4251541564861933} | train loss {'Reaction outcome loss': 0.22252185415436215, 'Total loss': 0.22252185415436215}
2023-01-04 00:12:06,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:06,584 INFO:     Epoch: 49
2023-01-04 00:12:08,212 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4299119273821513, 'Total loss': 0.4299119273821513} | train loss {'Reaction outcome loss': 0.2196658990994795, 'Total loss': 0.2196658990994795}
2023-01-04 00:12:08,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:08,212 INFO:     Epoch: 50
2023-01-04 00:12:09,821 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4212120115756989, 'Total loss': 0.4212120115756989} | train loss {'Reaction outcome loss': 0.21847406960351373, 'Total loss': 0.21847406960351373}
2023-01-04 00:12:09,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:09,821 INFO:     Epoch: 51
2023-01-04 00:12:11,423 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43873865753412244, 'Total loss': 0.43873865753412244} | train loss {'Reaction outcome loss': 0.21725592788456793, 'Total loss': 0.21725592788456793}
2023-01-04 00:12:11,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:11,425 INFO:     Epoch: 52
2023-01-04 00:12:13,030 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43969149788220724, 'Total loss': 0.43969149788220724} | train loss {'Reaction outcome loss': 0.21354793590436344, 'Total loss': 0.21354793590436344}
2023-01-04 00:12:13,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:13,030 INFO:     Epoch: 53
2023-01-04 00:12:14,658 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4390220840771993, 'Total loss': 0.4390220840771993} | train loss {'Reaction outcome loss': 0.21529433041111656, 'Total loss': 0.21529433041111656}
2023-01-04 00:12:14,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:14,658 INFO:     Epoch: 54
2023-01-04 00:12:16,285 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45108505586783093, 'Total loss': 0.45108505586783093} | train loss {'Reaction outcome loss': 0.21229176431732918, 'Total loss': 0.21229176431732918}
2023-01-04 00:12:16,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:16,285 INFO:     Epoch: 55
2023-01-04 00:12:17,912 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4203134556611379, 'Total loss': 0.4203134556611379} | train loss {'Reaction outcome loss': 0.21101750207506792, 'Total loss': 0.21101750207506792}
2023-01-04 00:12:17,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:17,914 INFO:     Epoch: 56
2023-01-04 00:12:19,520 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45248060425122577, 'Total loss': 0.45248060425122577} | train loss {'Reaction outcome loss': 0.20915490105775075, 'Total loss': 0.20915490105775075}
2023-01-04 00:12:19,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:19,521 INFO:     Epoch: 57
2023-01-04 00:12:21,131 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42789912124474844, 'Total loss': 0.42789912124474844} | train loss {'Reaction outcome loss': 0.2078616099721258, 'Total loss': 0.2078616099721258}
2023-01-04 00:12:21,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:21,132 INFO:     Epoch: 58
2023-01-04 00:12:22,747 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4227251797914505, 'Total loss': 0.4227251797914505} | train loss {'Reaction outcome loss': 0.20561399173650502, 'Total loss': 0.20561399173650502}
2023-01-04 00:12:22,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:22,747 INFO:     Epoch: 59
2023-01-04 00:12:24,374 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.442407363653183, 'Total loss': 0.442407363653183} | train loss {'Reaction outcome loss': 0.20438807706486448, 'Total loss': 0.20438807706486448}
2023-01-04 00:12:24,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:24,374 INFO:     Epoch: 60
2023-01-04 00:12:26,001 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4298201322555542, 'Total loss': 0.4298201322555542} | train loss {'Reaction outcome loss': 0.20568479678933155, 'Total loss': 0.20568479678933155}
2023-01-04 00:12:26,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:26,001 INFO:     Epoch: 61
2023-01-04 00:12:27,623 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.433518119653066, 'Total loss': 0.433518119653066} | train loss {'Reaction outcome loss': 0.20332153097790287, 'Total loss': 0.20332153097790287}
2023-01-04 00:12:27,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:27,623 INFO:     Epoch: 62
2023-01-04 00:12:29,214 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43922642717758814, 'Total loss': 0.43922642717758814} | train loss {'Reaction outcome loss': 0.20363266078842676, 'Total loss': 0.20363266078842676}
2023-01-04 00:12:29,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:29,214 INFO:     Epoch: 63
2023-01-04 00:12:30,823 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4540730853875478, 'Total loss': 0.4540730853875478} | train loss {'Reaction outcome loss': 0.2019361075323196, 'Total loss': 0.2019361075323196}
2023-01-04 00:12:30,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:30,824 INFO:     Epoch: 64
2023-01-04 00:12:32,445 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44873100717862446, 'Total loss': 0.44873100717862446} | train loss {'Reaction outcome loss': 0.20196935982991426, 'Total loss': 0.20196935982991426}
2023-01-04 00:12:32,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:32,445 INFO:     Epoch: 65
2023-01-04 00:12:34,072 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43048176566759744, 'Total loss': 0.43048176566759744} | train loss {'Reaction outcome loss': 0.19958891794892425, 'Total loss': 0.19958891794892425}
2023-01-04 00:12:34,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:34,072 INFO:     Epoch: 66
2023-01-04 00:12:35,676 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41928407152493796, 'Total loss': 0.41928407152493796} | train loss {'Reaction outcome loss': 0.20092021988617384, 'Total loss': 0.20092021988617384}
2023-01-04 00:12:35,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:35,676 INFO:     Epoch: 67
2023-01-04 00:12:37,280 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44662296076615654, 'Total loss': 0.44662296076615654} | train loss {'Reaction outcome loss': 0.19634658481508815, 'Total loss': 0.19634658481508815}
2023-01-04 00:12:37,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:37,280 INFO:     Epoch: 68
2023-01-04 00:12:38,905 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4243580381075541, 'Total loss': 0.4243580381075541} | train loss {'Reaction outcome loss': 0.1971831688596884, 'Total loss': 0.1971831688596884}
2023-01-04 00:12:38,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:38,906 INFO:     Epoch: 69
2023-01-04 00:12:40,514 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43642127712567647, 'Total loss': 0.43642127712567647} | train loss {'Reaction outcome loss': 0.1958133604928905, 'Total loss': 0.1958133604928905}
2023-01-04 00:12:40,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:40,514 INFO:     Epoch: 70
2023-01-04 00:12:42,141 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43369525571664175, 'Total loss': 0.43369525571664175} | train loss {'Reaction outcome loss': 0.19632940155719592, 'Total loss': 0.19632940155719592}
2023-01-04 00:12:42,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:42,143 INFO:     Epoch: 71
2023-01-04 00:12:43,769 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44453687270482384, 'Total loss': 0.44453687270482384} | train loss {'Reaction outcome loss': 0.19236508561869822, 'Total loss': 0.19236508561869822}
2023-01-04 00:12:43,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:43,769 INFO:     Epoch: 72
2023-01-04 00:12:45,397 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4467038889726003, 'Total loss': 0.4467038889726003} | train loss {'Reaction outcome loss': 0.1918148543981546, 'Total loss': 0.1918148543981546}
2023-01-04 00:12:45,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:45,397 INFO:     Epoch: 73
2023-01-04 00:12:46,990 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4479671001434326, 'Total loss': 0.4479671001434326} | train loss {'Reaction outcome loss': 0.19108988939101945, 'Total loss': 0.19108988939101945}
2023-01-04 00:12:46,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:46,990 INFO:     Epoch: 74
2023-01-04 00:12:48,594 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44628386745850246, 'Total loss': 0.44628386745850246} | train loss {'Reaction outcome loss': 0.18958952732464898, 'Total loss': 0.18958952732464898}
2023-01-04 00:12:48,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:48,595 INFO:     Epoch: 75
2023-01-04 00:12:50,220 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44527505040168763, 'Total loss': 0.44527505040168763} | train loss {'Reaction outcome loss': 0.19024994841605317, 'Total loss': 0.19024994841605317}
2023-01-04 00:12:50,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:50,220 INFO:     Epoch: 76
2023-01-04 00:12:51,847 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4298024564981461, 'Total loss': 0.4298024564981461} | train loss {'Reaction outcome loss': 0.18976380146152275, 'Total loss': 0.18976380146152275}
2023-01-04 00:12:51,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:51,847 INFO:     Epoch: 77
2023-01-04 00:12:53,482 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4447300304969152, 'Total loss': 0.4447300304969152} | train loss {'Reaction outcome loss': 0.18866282150767985, 'Total loss': 0.18866282150767985}
2023-01-04 00:12:53,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:53,482 INFO:     Epoch: 78
2023-01-04 00:12:55,088 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4619946519533793, 'Total loss': 0.4619946519533793} | train loss {'Reaction outcome loss': 0.18830981402782326, 'Total loss': 0.18830981402782326}
2023-01-04 00:12:55,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:55,088 INFO:     Epoch: 79
2023-01-04 00:12:56,710 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47277630468209586, 'Total loss': 0.47277630468209586} | train loss {'Reaction outcome loss': 0.18739548529286462, 'Total loss': 0.18739548529286462}
2023-01-04 00:12:56,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:56,710 INFO:     Epoch: 80
2023-01-04 00:12:58,315 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4704921712478002, 'Total loss': 0.4704921712478002} | train loss {'Reaction outcome loss': 0.18769970023164034, 'Total loss': 0.18769970023164034}
2023-01-04 00:12:58,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:58,316 INFO:     Epoch: 81
2023-01-04 00:12:59,941 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44539867440859476, 'Total loss': 0.44539867440859476} | train loss {'Reaction outcome loss': 0.183947085998011, 'Total loss': 0.183947085998011}
2023-01-04 00:12:59,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:12:59,941 INFO:     Epoch: 82
2023-01-04 00:13:01,568 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43706784546375277, 'Total loss': 0.43706784546375277} | train loss {'Reaction outcome loss': 0.18478851414383105, 'Total loss': 0.18478851414383105}
2023-01-04 00:13:01,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:01,569 INFO:     Epoch: 83
2023-01-04 00:13:03,200 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42770051062107084, 'Total loss': 0.42770051062107084} | train loss {'Reaction outcome loss': 0.18541154028034168, 'Total loss': 0.18541154028034168}
2023-01-04 00:13:03,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:03,200 INFO:     Epoch: 84
2023-01-04 00:13:04,805 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43901703556378685, 'Total loss': 0.43901703556378685} | train loss {'Reaction outcome loss': 0.18535874192249904, 'Total loss': 0.18535874192249904}
2023-01-04 00:13:04,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:04,806 INFO:     Epoch: 85
2023-01-04 00:13:06,415 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4613450060288111, 'Total loss': 0.4613450060288111} | train loss {'Reaction outcome loss': 0.18175105855460633, 'Total loss': 0.18175105855460633}
2023-01-04 00:13:06,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:06,415 INFO:     Epoch: 86
2023-01-04 00:13:08,039 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4578389366467794, 'Total loss': 0.4578389366467794} | train loss {'Reaction outcome loss': 0.17879626710330968, 'Total loss': 0.17879626710330968}
2023-01-04 00:13:08,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:08,039 INFO:     Epoch: 87
2023-01-04 00:13:09,661 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45698214173316953, 'Total loss': 0.45698214173316953} | train loss {'Reaction outcome loss': 0.18375474253555066, 'Total loss': 0.18375474253555066}
2023-01-04 00:13:09,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:09,661 INFO:     Epoch: 88
2023-01-04 00:13:11,269 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45525249739487966, 'Total loss': 0.45525249739487966} | train loss {'Reaction outcome loss': 0.1823290153860454, 'Total loss': 0.1823290153860454}
2023-01-04 00:13:11,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:11,269 INFO:     Epoch: 89
2023-01-04 00:13:12,866 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4598533709843953, 'Total loss': 0.4598533709843953} | train loss {'Reaction outcome loss': 0.1810581109113319, 'Total loss': 0.1810581109113319}
2023-01-04 00:13:12,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:12,867 INFO:     Epoch: 90
2023-01-04 00:13:14,474 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4682076096534729, 'Total loss': 0.4682076096534729} | train loss {'Reaction outcome loss': 0.17924936174916017, 'Total loss': 0.17924936174916017}
2023-01-04 00:13:14,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:14,474 INFO:     Epoch: 91
2023-01-04 00:13:16,081 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44342784881591796, 'Total loss': 0.44342784881591796} | train loss {'Reaction outcome loss': 0.175476362619428, 'Total loss': 0.175476362619428}
2023-01-04 00:13:16,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:16,082 INFO:     Epoch: 92
2023-01-04 00:13:17,703 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4438821390271187, 'Total loss': 0.4438821390271187} | train loss {'Reaction outcome loss': 0.18133528359799178, 'Total loss': 0.18133528359799178}
2023-01-04 00:13:17,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:17,703 INFO:     Epoch: 93
2023-01-04 00:13:19,308 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46306443909804024, 'Total loss': 0.46306443909804024} | train loss {'Reaction outcome loss': 0.17867768748027915, 'Total loss': 0.17867768748027915}
2023-01-04 00:13:19,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:19,309 INFO:     Epoch: 94
2023-01-04 00:13:20,930 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45532421420017877, 'Total loss': 0.45532421420017877} | train loss {'Reaction outcome loss': 0.17536097354783478, 'Total loss': 0.17536097354783478}
2023-01-04 00:13:20,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:20,931 INFO:     Epoch: 95
2023-01-04 00:13:22,526 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4667490099867185, 'Total loss': 0.4667490099867185} | train loss {'Reaction outcome loss': 0.17709163885012216, 'Total loss': 0.17709163885012216}
2023-01-04 00:13:22,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:22,526 INFO:     Epoch: 96
2023-01-04 00:13:24,151 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46504026651382446, 'Total loss': 0.46504026651382446} | train loss {'Reaction outcome loss': 0.17483401104861648, 'Total loss': 0.17483401104861648}
2023-01-04 00:13:24,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:24,152 INFO:     Epoch: 97
2023-01-04 00:13:25,740 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4603843202193578, 'Total loss': 0.4603843202193578} | train loss {'Reaction outcome loss': 0.17638133596023714, 'Total loss': 0.17638133596023714}
2023-01-04 00:13:25,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:25,740 INFO:     Epoch: 98
2023-01-04 00:13:27,347 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4380575766166051, 'Total loss': 0.4380575766166051} | train loss {'Reaction outcome loss': 0.17584874835336037, 'Total loss': 0.17584874835336037}
2023-01-04 00:13:27,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:27,347 INFO:     Epoch: 99
2023-01-04 00:13:28,968 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4513359159231186, 'Total loss': 0.4513359159231186} | train loss {'Reaction outcome loss': 0.1751186909147333, 'Total loss': 0.1751186909147333}
2023-01-04 00:13:28,968 INFO:     Best model found after epoch 13 of 100.
2023-01-04 00:13:28,968 INFO:   Done with stage: TRAINING
2023-01-04 00:13:28,968 INFO:   Starting stage: EVALUATION
2023-01-04 00:13:29,091 INFO:   Done with stage: EVALUATION
2023-01-04 00:13:29,091 INFO:   Leaving out SEQ value Fold_9
2023-01-04 00:13:29,104 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 00:13:29,104 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:13:29,750 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:13:29,750 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:13:29,820 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:13:29,820 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:13:29,820 INFO:     No hyperparam tuning for this model
2023-01-04 00:13:29,820 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:13:29,820 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:13:29,821 INFO:     None feature selector for col prot
2023-01-04 00:13:29,821 INFO:     None feature selector for col prot
2023-01-04 00:13:29,821 INFO:     None feature selector for col prot
2023-01-04 00:13:29,822 INFO:     None feature selector for col chem
2023-01-04 00:13:29,822 INFO:     None feature selector for col chem
2023-01-04 00:13:29,822 INFO:     None feature selector for col chem
2023-01-04 00:13:29,822 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:13:29,822 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:13:29,823 INFO:     Number of params in model 70141
2023-01-04 00:13:29,826 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:13:29,826 INFO:   Starting stage: TRAINING
2023-01-04 00:13:29,870 INFO:     Val loss before train {'Reaction outcome loss': 0.9774166345596313, 'Total loss': 0.9774166345596313}
2023-01-04 00:13:29,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:29,870 INFO:     Epoch: 0
2023-01-04 00:13:31,453 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7429064810276031, 'Total loss': 0.7429064810276031} | train loss {'Reaction outcome loss': 0.8932888398986256, 'Total loss': 0.8932888398986256}
2023-01-04 00:13:31,454 INFO:     Found new best model at epoch 0
2023-01-04 00:13:31,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:31,455 INFO:     Epoch: 1
2023-01-04 00:13:33,038 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5990760326385498, 'Total loss': 0.5990760326385498} | train loss {'Reaction outcome loss': 0.6320811381371206, 'Total loss': 0.6320811381371206}
2023-01-04 00:13:33,038 INFO:     Found new best model at epoch 1
2023-01-04 00:13:33,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:33,039 INFO:     Epoch: 2
2023-01-04 00:13:34,634 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5447006165981293, 'Total loss': 0.5447006165981293} | train loss {'Reaction outcome loss': 0.5380143796281882, 'Total loss': 0.5380143796281882}
2023-01-04 00:13:34,634 INFO:     Found new best model at epoch 2
2023-01-04 00:13:34,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:34,635 INFO:     Epoch: 3
2023-01-04 00:13:36,235 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5163758744796118, 'Total loss': 0.5163758744796118} | train loss {'Reaction outcome loss': 0.4993826582002035, 'Total loss': 0.4993826582002035}
2023-01-04 00:13:36,235 INFO:     Found new best model at epoch 3
2023-01-04 00:13:36,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:36,236 INFO:     Epoch: 4
2023-01-04 00:13:37,855 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5131215453147888, 'Total loss': 0.5131215453147888} | train loss {'Reaction outcome loss': 0.47459140563032765, 'Total loss': 0.47459140563032765}
2023-01-04 00:13:37,855 INFO:     Found new best model at epoch 4
2023-01-04 00:13:37,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:37,856 INFO:     Epoch: 5
2023-01-04 00:13:39,436 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4826358119646708, 'Total loss': 0.4826358119646708} | train loss {'Reaction outcome loss': 0.45252245680793474, 'Total loss': 0.45252245680793474}
2023-01-04 00:13:39,436 INFO:     Found new best model at epoch 5
2023-01-04 00:13:39,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:39,437 INFO:     Epoch: 6
2023-01-04 00:13:41,036 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5011824270089468, 'Total loss': 0.5011824270089468} | train loss {'Reaction outcome loss': 0.43632721376564837, 'Total loss': 0.43632721376564837}
2023-01-04 00:13:41,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:41,036 INFO:     Epoch: 7
2023-01-04 00:13:42,617 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4793969412644704, 'Total loss': 0.4793969412644704} | train loss {'Reaction outcome loss': 0.4241069907295531, 'Total loss': 0.4241069907295531}
2023-01-04 00:13:42,617 INFO:     Found new best model at epoch 7
2023-01-04 00:13:42,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:42,618 INFO:     Epoch: 8
2023-01-04 00:13:44,227 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4738355775674184, 'Total loss': 0.4738355775674184} | train loss {'Reaction outcome loss': 0.4278260602251343, 'Total loss': 0.4278260602251343}
2023-01-04 00:13:44,229 INFO:     Found new best model at epoch 8
2023-01-04 00:13:44,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:44,229 INFO:     Epoch: 9
2023-01-04 00:13:45,848 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4605214595794678, 'Total loss': 0.4605214595794678} | train loss {'Reaction outcome loss': 0.4063259013017397, 'Total loss': 0.4063259013017397}
2023-01-04 00:13:45,848 INFO:     Found new best model at epoch 9
2023-01-04 00:13:45,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:45,849 INFO:     Epoch: 10
2023-01-04 00:13:47,472 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4608152170976003, 'Total loss': 0.4608152170976003} | train loss {'Reaction outcome loss': 0.39313565390361677, 'Total loss': 0.39313565390361677}
2023-01-04 00:13:47,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:47,472 INFO:     Epoch: 11
2023-01-04 00:13:49,064 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4667627066373825, 'Total loss': 0.4667627066373825} | train loss {'Reaction outcome loss': 0.38682773988187796, 'Total loss': 0.38682773988187796}
2023-01-04 00:13:49,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:49,065 INFO:     Epoch: 12
2023-01-04 00:13:50,658 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4711516261100769, 'Total loss': 0.4711516261100769} | train loss {'Reaction outcome loss': 0.37814959318147623, 'Total loss': 0.37814959318147623}
2023-01-04 00:13:50,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:50,659 INFO:     Epoch: 13
2023-01-04 00:13:52,268 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4692007601261139, 'Total loss': 0.4692007601261139} | train loss {'Reaction outcome loss': 0.3737097521412922, 'Total loss': 0.3737097521412922}
2023-01-04 00:13:52,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:52,268 INFO:     Epoch: 14
2023-01-04 00:13:53,932 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47400281627972923, 'Total loss': 0.47400281627972923} | train loss {'Reaction outcome loss': 0.3691801775408828, 'Total loss': 0.3691801775408828}
2023-01-04 00:13:53,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:53,932 INFO:     Epoch: 15
2023-01-04 00:13:55,550 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45754544734954833, 'Total loss': 0.45754544734954833} | train loss {'Reaction outcome loss': 0.36347167790475965, 'Total loss': 0.36347167790475965}
2023-01-04 00:13:55,550 INFO:     Found new best model at epoch 15
2023-01-04 00:13:55,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:55,551 INFO:     Epoch: 16
2023-01-04 00:13:57,214 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43991428514321645, 'Total loss': 0.43991428514321645} | train loss {'Reaction outcome loss': 0.3575772146526277, 'Total loss': 0.3575772146526277}
2023-01-04 00:13:57,214 INFO:     Found new best model at epoch 16
2023-01-04 00:13:57,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:57,215 INFO:     Epoch: 17
2023-01-04 00:13:58,831 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44823192358016967, 'Total loss': 0.44823192358016967} | train loss {'Reaction outcome loss': 0.34867215747742547, 'Total loss': 0.34867215747742547}
2023-01-04 00:13:58,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:13:58,832 INFO:     Epoch: 18
2023-01-04 00:14:00,430 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4561869978904724, 'Total loss': 0.4561869978904724} | train loss {'Reaction outcome loss': 0.34377212393556494, 'Total loss': 0.34377212393556494}
2023-01-04 00:14:00,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:00,430 INFO:     Epoch: 19
2023-01-04 00:14:02,027 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44666290084520976, 'Total loss': 0.44666290084520976} | train loss {'Reaction outcome loss': 0.33864072926234506, 'Total loss': 0.33864072926234506}
2023-01-04 00:14:02,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:02,027 INFO:     Epoch: 20
2023-01-04 00:14:03,628 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4445965389410655, 'Total loss': 0.4445965389410655} | train loss {'Reaction outcome loss': 0.3378256443294062, 'Total loss': 0.3378256443294062}
2023-01-04 00:14:03,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:03,629 INFO:     Epoch: 21
2023-01-04 00:14:05,231 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45343617896238964, 'Total loss': 0.45343617896238964} | train loss {'Reaction outcome loss': 0.3284904066181364, 'Total loss': 0.3284904066181364}
2023-01-04 00:14:05,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:05,231 INFO:     Epoch: 22
2023-01-04 00:14:06,819 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44200881322224933, 'Total loss': 0.44200881322224933} | train loss {'Reaction outcome loss': 0.3243510054518887, 'Total loss': 0.3243510054518887}
2023-01-04 00:14:06,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:06,819 INFO:     Epoch: 23
2023-01-04 00:14:08,422 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4607626845439275, 'Total loss': 0.4607626845439275} | train loss {'Reaction outcome loss': 0.3156751999564037, 'Total loss': 0.3156751999564037}
2023-01-04 00:14:08,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:08,423 INFO:     Epoch: 24
2023-01-04 00:14:09,993 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.446842614809672, 'Total loss': 0.446842614809672} | train loss {'Reaction outcome loss': 0.31355336044857657, 'Total loss': 0.31355336044857657}
2023-01-04 00:14:09,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:09,993 INFO:     Epoch: 25
2023-01-04 00:14:11,616 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4387490351994832, 'Total loss': 0.4387490351994832} | train loss {'Reaction outcome loss': 0.3180143509492062, 'Total loss': 0.3180143509492062}
2023-01-04 00:14:11,616 INFO:     Found new best model at epoch 25
2023-01-04 00:14:11,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:11,617 INFO:     Epoch: 26
2023-01-04 00:14:13,213 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45804910163084667, 'Total loss': 0.45804910163084667} | train loss {'Reaction outcome loss': 0.3147330610039374, 'Total loss': 0.3147330610039374}
2023-01-04 00:14:13,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:13,214 INFO:     Epoch: 27
2023-01-04 00:14:14,838 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4345386356115341, 'Total loss': 0.4345386356115341} | train loss {'Reaction outcome loss': 0.30357762510507397, 'Total loss': 0.30357762510507397}
2023-01-04 00:14:14,838 INFO:     Found new best model at epoch 27
2023-01-04 00:14:14,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:14,839 INFO:     Epoch: 28
2023-01-04 00:14:16,425 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4373047997554143, 'Total loss': 0.4373047997554143} | train loss {'Reaction outcome loss': 0.30050923983714933, 'Total loss': 0.30050923983714933}
2023-01-04 00:14:16,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:16,425 INFO:     Epoch: 29
2023-01-04 00:14:18,019 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4459945211807887, 'Total loss': 0.4459945211807887} | train loss {'Reaction outcome loss': 0.2947345198928446, 'Total loss': 0.2947345198928446}
2023-01-04 00:14:18,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:18,019 INFO:     Epoch: 30
2023-01-04 00:14:19,632 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44826439718405403, 'Total loss': 0.44826439718405403} | train loss {'Reaction outcome loss': 0.29925859446866787, 'Total loss': 0.29925859446866787}
2023-01-04 00:14:19,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:19,633 INFO:     Epoch: 31
2023-01-04 00:14:21,251 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45459380249182385, 'Total loss': 0.45459380249182385} | train loss {'Reaction outcome loss': 0.29485381669972255, 'Total loss': 0.29485381669972255}
2023-01-04 00:14:21,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:21,252 INFO:     Epoch: 32
2023-01-04 00:14:22,860 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4653652916351954, 'Total loss': 0.4653652916351954} | train loss {'Reaction outcome loss': 0.28439748593297304, 'Total loss': 0.28439748593297304}
2023-01-04 00:14:22,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:22,860 INFO:     Epoch: 33
2023-01-04 00:14:24,422 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4346492280562719, 'Total loss': 0.4346492280562719} | train loss {'Reaction outcome loss': 0.28196589107476716, 'Total loss': 0.28196589107476716}
2023-01-04 00:14:24,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:24,422 INFO:     Epoch: 34
2023-01-04 00:14:26,038 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44660142858823143, 'Total loss': 0.44660142858823143} | train loss {'Reaction outcome loss': 0.2791812248862065, 'Total loss': 0.2791812248862065}
2023-01-04 00:14:26,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:26,038 INFO:     Epoch: 35
2023-01-04 00:14:27,611 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47241030434767406, 'Total loss': 0.47241030434767406} | train loss {'Reaction outcome loss': 0.281849362819955, 'Total loss': 0.281849362819955}
2023-01-04 00:14:27,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:27,612 INFO:     Epoch: 36
2023-01-04 00:14:29,243 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4470870554447174, 'Total loss': 0.4470870554447174} | train loss {'Reaction outcome loss': 0.27860405884406436, 'Total loss': 0.27860405884406436}
2023-01-04 00:14:29,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:29,243 INFO:     Epoch: 37
2023-01-04 00:14:30,863 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4438556929429372, 'Total loss': 0.4438556929429372} | train loss {'Reaction outcome loss': 0.27287874848622345, 'Total loss': 0.27287874848622345}
2023-01-04 00:14:30,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:30,863 INFO:     Epoch: 38
2023-01-04 00:14:32,481 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44217804074287415, 'Total loss': 0.44217804074287415} | train loss {'Reaction outcome loss': 0.27071231670645607, 'Total loss': 0.27071231670645607}
2023-01-04 00:14:32,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:32,481 INFO:     Epoch: 39
2023-01-04 00:14:34,090 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.469388093551, 'Total loss': 0.469388093551} | train loss {'Reaction outcome loss': 0.2637351940156541, 'Total loss': 0.2637351940156541}
2023-01-04 00:14:34,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:34,090 INFO:     Epoch: 40
2023-01-04 00:14:35,696 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4410727769136429, 'Total loss': 0.4410727769136429} | train loss {'Reaction outcome loss': 0.26387251450585714, 'Total loss': 0.26387251450585714}
2023-01-04 00:14:35,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:35,696 INFO:     Epoch: 41
2023-01-04 00:14:37,287 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4441572984059652, 'Total loss': 0.4441572984059652} | train loss {'Reaction outcome loss': 0.26240563523301913, 'Total loss': 0.26240563523301913}
2023-01-04 00:14:37,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:37,287 INFO:     Epoch: 42
2023-01-04 00:14:38,914 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45425567626953123, 'Total loss': 0.45425567626953123} | train loss {'Reaction outcome loss': 0.25863752003921114, 'Total loss': 0.25863752003921114}
2023-01-04 00:14:38,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:38,915 INFO:     Epoch: 43
2023-01-04 00:14:40,526 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46318155924479165, 'Total loss': 0.46318155924479165} | train loss {'Reaction outcome loss': 0.2718088491887286, 'Total loss': 0.2718088491887286}
2023-01-04 00:14:40,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:40,526 INFO:     Epoch: 44
2023-01-04 00:14:42,145 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43827337125937144, 'Total loss': 0.43827337125937144} | train loss {'Reaction outcome loss': 0.261748682640061, 'Total loss': 0.261748682640061}
2023-01-04 00:14:42,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:42,146 INFO:     Epoch: 45
2023-01-04 00:14:43,746 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4343118886152903, 'Total loss': 0.4343118886152903} | train loss {'Reaction outcome loss': 0.25167377375781647, 'Total loss': 0.25167377375781647}
2023-01-04 00:14:43,747 INFO:     Found new best model at epoch 45
2023-01-04 00:14:43,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:43,747 INFO:     Epoch: 46
2023-01-04 00:14:45,339 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44405193130175274, 'Total loss': 0.44405193130175274} | train loss {'Reaction outcome loss': 0.24945093933627874, 'Total loss': 0.24945093933627874}
2023-01-04 00:14:45,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:45,340 INFO:     Epoch: 47
2023-01-04 00:14:46,975 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44462975263595583, 'Total loss': 0.44462975263595583} | train loss {'Reaction outcome loss': 0.24555604481070803, 'Total loss': 0.24555604481070803}
2023-01-04 00:14:46,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:46,975 INFO:     Epoch: 48
2023-01-04 00:14:48,581 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45920958121617633, 'Total loss': 0.45920958121617633} | train loss {'Reaction outcome loss': 0.24677867758124933, 'Total loss': 0.24677867758124933}
2023-01-04 00:14:48,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:48,582 INFO:     Epoch: 49
2023-01-04 00:14:50,184 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44478625257809956, 'Total loss': 0.44478625257809956} | train loss {'Reaction outcome loss': 0.2416029205761742, 'Total loss': 0.2416029205761742}
2023-01-04 00:14:50,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:50,184 INFO:     Epoch: 50
2023-01-04 00:14:51,774 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4456728825966517, 'Total loss': 0.4456728825966517} | train loss {'Reaction outcome loss': 0.2436773732483414, 'Total loss': 0.2436773732483414}
2023-01-04 00:14:51,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:51,774 INFO:     Epoch: 51
2023-01-04 00:14:53,395 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4417647769053777, 'Total loss': 0.4417647769053777} | train loss {'Reaction outcome loss': 0.23977354160466557, 'Total loss': 0.23977354160466557}
2023-01-04 00:14:53,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:53,395 INFO:     Epoch: 52
2023-01-04 00:14:54,993 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4543991724650065, 'Total loss': 0.4543991724650065} | train loss {'Reaction outcome loss': 0.23470894699119896, 'Total loss': 0.23470894699119896}
2023-01-04 00:14:54,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:54,994 INFO:     Epoch: 53
2023-01-04 00:14:56,607 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4382534275452296, 'Total loss': 0.4382534275452296} | train loss {'Reaction outcome loss': 0.23448650741382784, 'Total loss': 0.23448650741382784}
2023-01-04 00:14:56,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:56,608 INFO:     Epoch: 54
2023-01-04 00:14:58,231 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45557470122973126, 'Total loss': 0.45557470122973126} | train loss {'Reaction outcome loss': 0.23255612523348976, 'Total loss': 0.23255612523348976}
2023-01-04 00:14:58,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:58,231 INFO:     Epoch: 55
2023-01-04 00:14:59,851 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4504555920759837, 'Total loss': 0.4504555920759837} | train loss {'Reaction outcome loss': 0.23195328812479324, 'Total loss': 0.23195328812479324}
2023-01-04 00:14:59,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:14:59,851 INFO:     Epoch: 56
2023-01-04 00:15:01,433 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44181651969750724, 'Total loss': 0.44181651969750724} | train loss {'Reaction outcome loss': 0.2279820124347917, 'Total loss': 0.2279820124347917}
2023-01-04 00:15:01,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:01,434 INFO:     Epoch: 57
2023-01-04 00:15:03,047 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4487745712200801, 'Total loss': 0.4487745712200801} | train loss {'Reaction outcome loss': 0.2345185020290639, 'Total loss': 0.2345185020290639}
2023-01-04 00:15:03,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:03,048 INFO:     Epoch: 58
2023-01-04 00:15:04,625 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44319376051425935, 'Total loss': 0.44319376051425935} | train loss {'Reaction outcome loss': 0.24583145425371503, 'Total loss': 0.24583145425371503}
2023-01-04 00:15:04,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:04,625 INFO:     Epoch: 59
2023-01-04 00:15:06,242 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45531121889750165, 'Total loss': 0.45531121889750165} | train loss {'Reaction outcome loss': 0.23162053240652103, 'Total loss': 0.23162053240652103}
2023-01-04 00:15:06,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:06,242 INFO:     Epoch: 60
2023-01-04 00:15:07,857 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4314557909965515, 'Total loss': 0.4314557909965515} | train loss {'Reaction outcome loss': 0.2299792363892134, 'Total loss': 0.2299792363892134}
2023-01-04 00:15:07,857 INFO:     Found new best model at epoch 60
2023-01-04 00:15:07,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:07,858 INFO:     Epoch: 61
2023-01-04 00:15:09,435 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4295492221911748, 'Total loss': 0.4295492221911748} | train loss {'Reaction outcome loss': 0.22206876432829775, 'Total loss': 0.22206876432829775}
2023-01-04 00:15:09,435 INFO:     Found new best model at epoch 61
2023-01-04 00:15:09,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:09,436 INFO:     Epoch: 62
2023-01-04 00:15:11,048 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4377798895041148, 'Total loss': 0.4377798895041148} | train loss {'Reaction outcome loss': 0.22230598276128413, 'Total loss': 0.22230598276128413}
2023-01-04 00:15:11,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:11,048 INFO:     Epoch: 63
2023-01-04 00:15:12,639 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44377041260401406, 'Total loss': 0.44377041260401406} | train loss {'Reaction outcome loss': 0.21863165952137037, 'Total loss': 0.21863165952137037}
2023-01-04 00:15:12,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:12,639 INFO:     Epoch: 64
2023-01-04 00:15:14,235 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4418380876382192, 'Total loss': 0.4418380876382192} | train loss {'Reaction outcome loss': 0.21876373525330986, 'Total loss': 0.21876373525330986}
2023-01-04 00:15:14,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:14,236 INFO:     Epoch: 65
2023-01-04 00:15:15,833 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44579166372617085, 'Total loss': 0.44579166372617085} | train loss {'Reaction outcome loss': 0.22016774524219226, 'Total loss': 0.22016774524219226}
2023-01-04 00:15:15,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:15,834 INFO:     Epoch: 66
2023-01-04 00:15:17,432 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4844264715909958, 'Total loss': 0.4844264715909958} | train loss {'Reaction outcome loss': 0.23471302402786154, 'Total loss': 0.23471302402786154}
2023-01-04 00:15:17,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:17,433 INFO:     Epoch: 67
2023-01-04 00:15:19,012 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43961218496163684, 'Total loss': 0.43961218496163684} | train loss {'Reaction outcome loss': 0.23471469140332518, 'Total loss': 0.23471469140332518}
2023-01-04 00:15:19,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:19,013 INFO:     Epoch: 68
2023-01-04 00:15:20,609 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4483173946539561, 'Total loss': 0.4483173946539561} | train loss {'Reaction outcome loss': 0.21478834186943815, 'Total loss': 0.21478834186943815}
2023-01-04 00:15:20,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:20,609 INFO:     Epoch: 69
2023-01-04 00:15:22,197 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45255601704120635, 'Total loss': 0.45255601704120635} | train loss {'Reaction outcome loss': 0.21040004826036107, 'Total loss': 0.21040004826036107}
2023-01-04 00:15:22,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:22,197 INFO:     Epoch: 70
2023-01-04 00:15:23,813 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4289225056767464, 'Total loss': 0.4289225056767464} | train loss {'Reaction outcome loss': 0.20995208290127187, 'Total loss': 0.20995208290127187}
2023-01-04 00:15:23,813 INFO:     Found new best model at epoch 70
2023-01-04 00:15:23,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:23,814 INFO:     Epoch: 71
2023-01-04 00:15:25,419 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4410794546206792, 'Total loss': 0.4410794546206792} | train loss {'Reaction outcome loss': 0.20640892560418317, 'Total loss': 0.20640892560418317}
2023-01-04 00:15:25,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:25,420 INFO:     Epoch: 72
2023-01-04 00:15:27,035 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43199351727962493, 'Total loss': 0.43199351727962493} | train loss {'Reaction outcome loss': 0.2063875736321147, 'Total loss': 0.2063875736321147}
2023-01-04 00:15:27,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:27,035 INFO:     Epoch: 73
2023-01-04 00:15:28,623 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4503339409828186, 'Total loss': 0.4503339409828186} | train loss {'Reaction outcome loss': 0.2076740882669886, 'Total loss': 0.2076740882669886}
2023-01-04 00:15:28,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:28,623 INFO:     Epoch: 74
2023-01-04 00:15:30,200 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4488162393371264, 'Total loss': 0.4488162393371264} | train loss {'Reaction outcome loss': 0.20768598512380698, 'Total loss': 0.20768598512380698}
2023-01-04 00:15:30,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:30,200 INFO:     Epoch: 75
2023-01-04 00:15:31,816 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4551680242021879, 'Total loss': 0.4551680242021879} | train loss {'Reaction outcome loss': 0.20212650884465236, 'Total loss': 0.20212650884465236}
2023-01-04 00:15:31,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:31,817 INFO:     Epoch: 76
2023-01-04 00:15:33,443 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46922530432542164, 'Total loss': 0.46922530432542164} | train loss {'Reaction outcome loss': 0.20249440298125526, 'Total loss': 0.20249440298125526}
2023-01-04 00:15:33,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:33,444 INFO:     Epoch: 77
2023-01-04 00:15:35,069 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4308395703633626, 'Total loss': 0.4308395703633626} | train loss {'Reaction outcome loss': 0.19936313111785517, 'Total loss': 0.19936313111785517}
2023-01-04 00:15:35,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:35,070 INFO:     Epoch: 78
2023-01-04 00:15:36,656 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42711924215157826, 'Total loss': 0.42711924215157826} | train loss {'Reaction outcome loss': 0.20152819575404451, 'Total loss': 0.20152819575404451}
2023-01-04 00:15:36,656 INFO:     Found new best model at epoch 78
2023-01-04 00:15:36,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:36,657 INFO:     Epoch: 79
2023-01-04 00:15:38,247 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4379207064708074, 'Total loss': 0.4379207064708074} | train loss {'Reaction outcome loss': 0.20373366600361423, 'Total loss': 0.20373366600361423}
2023-01-04 00:15:38,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:38,247 INFO:     Epoch: 80
2023-01-04 00:15:39,849 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4308009922504425, 'Total loss': 0.4308009922504425} | train loss {'Reaction outcome loss': 0.2056085873324343, 'Total loss': 0.2056085873324343}
2023-01-04 00:15:39,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:39,849 INFO:     Epoch: 81
2023-01-04 00:15:41,471 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4671897212664286, 'Total loss': 0.4671897212664286} | train loss {'Reaction outcome loss': 0.19832846650894245, 'Total loss': 0.19832846650894245}
2023-01-04 00:15:41,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:41,471 INFO:     Epoch: 82
2023-01-04 00:15:43,093 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4398685177167257, 'Total loss': 0.4398685177167257} | train loss {'Reaction outcome loss': 0.19543816723479182, 'Total loss': 0.19543816723479182}
2023-01-04 00:15:43,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:43,093 INFO:     Epoch: 83
2023-01-04 00:15:44,718 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4454290876785914, 'Total loss': 0.4454290876785914} | train loss {'Reaction outcome loss': 0.19501092221479918, 'Total loss': 0.19501092221479918}
2023-01-04 00:15:44,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:44,719 INFO:     Epoch: 84
2023-01-04 00:15:46,300 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4288154433170954, 'Total loss': 0.4288154433170954} | train loss {'Reaction outcome loss': 0.19237871969011577, 'Total loss': 0.19237871969011577}
2023-01-04 00:15:46,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:46,301 INFO:     Epoch: 85
2023-01-04 00:15:47,924 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47002945095300674, 'Total loss': 0.47002945095300674} | train loss {'Reaction outcome loss': 0.19177653580429277, 'Total loss': 0.19177653580429277}
2023-01-04 00:15:47,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:47,924 INFO:     Epoch: 86
2023-01-04 00:15:49,524 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42790054976940156, 'Total loss': 0.42790054976940156} | train loss {'Reaction outcome loss': 0.19272377180523373, 'Total loss': 0.19272377180523373}
2023-01-04 00:15:49,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:49,525 INFO:     Epoch: 87
2023-01-04 00:15:51,149 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4590231587489446, 'Total loss': 0.4590231587489446} | train loss {'Reaction outcome loss': 0.20206490082099385, 'Total loss': 0.20206490082099385}
2023-01-04 00:15:51,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:51,150 INFO:     Epoch: 88
2023-01-04 00:15:52,751 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4402968555688858, 'Total loss': 0.4402968555688858} | train loss {'Reaction outcome loss': 0.21594028300909407, 'Total loss': 0.21594028300909407}
2023-01-04 00:15:52,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:52,752 INFO:     Epoch: 89
2023-01-04 00:15:54,338 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43049224217732746, 'Total loss': 0.43049224217732746} | train loss {'Reaction outcome loss': 0.19336480214702612, 'Total loss': 0.19336480214702612}
2023-01-04 00:15:54,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:54,338 INFO:     Epoch: 90
2023-01-04 00:15:55,954 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4521886209646861, 'Total loss': 0.4521886209646861} | train loss {'Reaction outcome loss': 0.19058397231434565, 'Total loss': 0.19058397231434565}
2023-01-04 00:15:55,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:55,956 INFO:     Epoch: 91
2023-01-04 00:15:57,554 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4500234544277191, 'Total loss': 0.4500234544277191} | train loss {'Reaction outcome loss': 0.18787412519602673, 'Total loss': 0.18787412519602673}
2023-01-04 00:15:57,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:57,554 INFO:     Epoch: 92
2023-01-04 00:15:59,150 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4589193214972814, 'Total loss': 0.4589193214972814} | train loss {'Reaction outcome loss': 0.1876943210307323, 'Total loss': 0.1876943210307323}
2023-01-04 00:15:59,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:15:59,150 INFO:     Epoch: 93
2023-01-04 00:16:00,747 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43718640406926473, 'Total loss': 0.43718640406926473} | train loss {'Reaction outcome loss': 0.18603547053804714, 'Total loss': 0.18603547053804714}
2023-01-04 00:16:00,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:00,747 INFO:     Epoch: 94
2023-01-04 00:16:02,344 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43311965763568877, 'Total loss': 0.43311965763568877} | train loss {'Reaction outcome loss': 0.18356593183673703, 'Total loss': 0.18356593183673703}
2023-01-04 00:16:02,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:02,345 INFO:     Epoch: 95
2023-01-04 00:16:03,926 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43302185436089835, 'Total loss': 0.43302185436089835} | train loss {'Reaction outcome loss': 0.1839489146756629, 'Total loss': 0.1839489146756629}
2023-01-04 00:16:03,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:03,926 INFO:     Epoch: 96
2023-01-04 00:16:05,522 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46285170515378316, 'Total loss': 0.46285170515378316} | train loss {'Reaction outcome loss': 0.1879920744256157, 'Total loss': 0.1879920744256157}
2023-01-04 00:16:05,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:05,522 INFO:     Epoch: 97
2023-01-04 00:16:07,126 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4663411815961202, 'Total loss': 0.4663411815961202} | train loss {'Reaction outcome loss': 0.1959092859853653, 'Total loss': 0.1959092859853653}
2023-01-04 00:16:07,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:07,126 INFO:     Epoch: 98
2023-01-04 00:16:08,762 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4445240994294484, 'Total loss': 0.4445240994294484} | train loss {'Reaction outcome loss': 0.18182523500096673, 'Total loss': 0.18182523500096673}
2023-01-04 00:16:08,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:08,762 INFO:     Epoch: 99
2023-01-04 00:16:10,381 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4649299999078115, 'Total loss': 0.4649299999078115} | train loss {'Reaction outcome loss': 0.18050938678409337, 'Total loss': 0.18050938678409337}
2023-01-04 00:16:10,381 INFO:     Best model found after epoch 79 of 100.
2023-01-04 00:16:10,381 INFO:   Done with stage: TRAINING
2023-01-04 00:16:10,382 INFO:   Starting stage: EVALUATION
2023-01-04 00:16:10,513 INFO:   Done with stage: EVALUATION
2023-01-04 00:16:10,521 INFO:   Leaving out SEQ value Fold_0
2023-01-04 00:16:10,534 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 00:16:10,534 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:16:11,181 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:16:11,182 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:16:11,251 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:16:11,252 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:16:11,252 INFO:     No hyperparam tuning for this model
2023-01-04 00:16:11,252 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:16:11,252 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:16:11,252 INFO:     None feature selector for col prot
2023-01-04 00:16:11,253 INFO:     None feature selector for col prot
2023-01-04 00:16:11,253 INFO:     None feature selector for col prot
2023-01-04 00:16:11,253 INFO:     None feature selector for col chem
2023-01-04 00:16:11,253 INFO:     None feature selector for col chem
2023-01-04 00:16:11,253 INFO:     None feature selector for col chem
2023-01-04 00:16:11,253 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:16:11,253 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:16:11,255 INFO:     Number of params in model 70141
2023-01-04 00:16:11,258 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:16:11,258 INFO:   Starting stage: TRAINING
2023-01-04 00:16:11,301 INFO:     Val loss before train {'Reaction outcome loss': 1.0108143528302511, 'Total loss': 1.0108143528302511}
2023-01-04 00:16:11,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:11,301 INFO:     Epoch: 0
2023-01-04 00:16:12,859 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7437762935956319, 'Total loss': 0.7437762935956319} | train loss {'Reaction outcome loss': 0.8755316819152693, 'Total loss': 0.8755316819152693}
2023-01-04 00:16:12,859 INFO:     Found new best model at epoch 0
2023-01-04 00:16:12,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:12,860 INFO:     Epoch: 1
2023-01-04 00:16:14,465 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5762501855691274, 'Total loss': 0.5762501855691274} | train loss {'Reaction outcome loss': 0.6452218028206895, 'Total loss': 0.6452218028206895}
2023-01-04 00:16:14,466 INFO:     Found new best model at epoch 1
2023-01-04 00:16:14,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:14,467 INFO:     Epoch: 2
2023-01-04 00:16:16,051 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5200144509474437, 'Total loss': 0.5200144509474437} | train loss {'Reaction outcome loss': 0.5384917146098005, 'Total loss': 0.5384917146098005}
2023-01-04 00:16:16,051 INFO:     Found new best model at epoch 2
2023-01-04 00:16:16,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:16,052 INFO:     Epoch: 3
2023-01-04 00:16:17,633 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4838014463583628, 'Total loss': 0.4838014463583628} | train loss {'Reaction outcome loss': 0.49365975424973635, 'Total loss': 0.49365975424973635}
2023-01-04 00:16:17,634 INFO:     Found new best model at epoch 3
2023-01-04 00:16:17,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:17,635 INFO:     Epoch: 4
2023-01-04 00:16:19,253 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4758292774359385, 'Total loss': 0.4758292774359385} | train loss {'Reaction outcome loss': 0.4671509472558098, 'Total loss': 0.4671509472558098}
2023-01-04 00:16:19,253 INFO:     Found new best model at epoch 4
2023-01-04 00:16:19,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:19,254 INFO:     Epoch: 5
2023-01-04 00:16:20,819 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.451303560535113, 'Total loss': 0.451303560535113} | train loss {'Reaction outcome loss': 0.4497036981212832, 'Total loss': 0.4497036981212832}
2023-01-04 00:16:20,819 INFO:     Found new best model at epoch 5
2023-01-04 00:16:20,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:20,820 INFO:     Epoch: 6
2023-01-04 00:16:22,395 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44979141354560853, 'Total loss': 0.44979141354560853} | train loss {'Reaction outcome loss': 0.4330025148326463, 'Total loss': 0.4330025148326463}
2023-01-04 00:16:22,395 INFO:     Found new best model at epoch 6
2023-01-04 00:16:22,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:22,396 INFO:     Epoch: 7
2023-01-04 00:16:23,962 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4360340654850006, 'Total loss': 0.4360340654850006} | train loss {'Reaction outcome loss': 0.4200481961134577, 'Total loss': 0.4200481961134577}
2023-01-04 00:16:23,962 INFO:     Found new best model at epoch 7
2023-01-04 00:16:23,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:23,963 INFO:     Epoch: 8
2023-01-04 00:16:25,582 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4432656168937683, 'Total loss': 0.4432656168937683} | train loss {'Reaction outcome loss': 0.40694498858095085, 'Total loss': 0.40694498858095085}
2023-01-04 00:16:25,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:25,582 INFO:     Epoch: 9
2023-01-04 00:16:27,197 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4451745311419169, 'Total loss': 0.4451745311419169} | train loss {'Reaction outcome loss': 0.39884182065725327, 'Total loss': 0.39884182065725327}
2023-01-04 00:16:27,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:27,197 INFO:     Epoch: 10
2023-01-04 00:16:28,811 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43200822472572326, 'Total loss': 0.43200822472572326} | train loss {'Reaction outcome loss': 0.390252103879504, 'Total loss': 0.390252103879504}
2023-01-04 00:16:28,811 INFO:     Found new best model at epoch 10
2023-01-04 00:16:28,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:28,812 INFO:     Epoch: 11
2023-01-04 00:16:30,386 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4391624053319295, 'Total loss': 0.4391624053319295} | train loss {'Reaction outcome loss': 0.379732137342004, 'Total loss': 0.379732137342004}
2023-01-04 00:16:30,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:30,386 INFO:     Epoch: 12
2023-01-04 00:16:31,969 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4316538731257121, 'Total loss': 0.4316538731257121} | train loss {'Reaction outcome loss': 0.37387221534974385, 'Total loss': 0.37387221534974385}
2023-01-04 00:16:31,970 INFO:     Found new best model at epoch 12
2023-01-04 00:16:31,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:31,971 INFO:     Epoch: 13
2023-01-04 00:16:33,535 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42867939670880634, 'Total loss': 0.42867939670880634} | train loss {'Reaction outcome loss': 0.3665273356502944, 'Total loss': 0.3665273356502944}
2023-01-04 00:16:33,535 INFO:     Found new best model at epoch 13
2023-01-04 00:16:33,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:33,536 INFO:     Epoch: 14
2023-01-04 00:16:35,118 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4283550649881363, 'Total loss': 0.4283550649881363} | train loss {'Reaction outcome loss': 0.35820257913892284, 'Total loss': 0.35820257913892284}
2023-01-04 00:16:35,118 INFO:     Found new best model at epoch 14
2023-01-04 00:16:35,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:35,119 INFO:     Epoch: 15
2023-01-04 00:16:36,699 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4226153612136841, 'Total loss': 0.4226153612136841} | train loss {'Reaction outcome loss': 0.35514191804576095, 'Total loss': 0.35514191804576095}
2023-01-04 00:16:36,699 INFO:     Found new best model at epoch 15
2023-01-04 00:16:36,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:36,700 INFO:     Epoch: 16
2023-01-04 00:16:38,282 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.429773211479187, 'Total loss': 0.429773211479187} | train loss {'Reaction outcome loss': 0.34640344683706326, 'Total loss': 0.34640344683706326}
2023-01-04 00:16:38,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:38,283 INFO:     Epoch: 17
2023-01-04 00:16:39,875 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42255308429400124, 'Total loss': 0.42255308429400124} | train loss {'Reaction outcome loss': 0.3424036807931253, 'Total loss': 0.3424036807931253}
2023-01-04 00:16:39,875 INFO:     Found new best model at epoch 17
2023-01-04 00:16:39,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:39,876 INFO:     Epoch: 18
2023-01-04 00:16:41,473 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4091610689957937, 'Total loss': 0.4091610689957937} | train loss {'Reaction outcome loss': 0.3359155689712858, 'Total loss': 0.3359155689712858}
2023-01-04 00:16:41,473 INFO:     Found new best model at epoch 18
2023-01-04 00:16:41,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:41,474 INFO:     Epoch: 19
2023-01-04 00:16:43,052 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41599461336930593, 'Total loss': 0.41599461336930593} | train loss {'Reaction outcome loss': 0.3315114230733283, 'Total loss': 0.3315114230733283}
2023-01-04 00:16:43,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:43,052 INFO:     Epoch: 20
2023-01-04 00:16:44,672 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40890551507472994, 'Total loss': 0.40890551507472994} | train loss {'Reaction outcome loss': 0.3252529464662075, 'Total loss': 0.3252529464662075}
2023-01-04 00:16:44,672 INFO:     Found new best model at epoch 20
2023-01-04 00:16:44,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:44,673 INFO:     Epoch: 21
2023-01-04 00:16:46,288 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41590276658535, 'Total loss': 0.41590276658535} | train loss {'Reaction outcome loss': 0.31891410985458507, 'Total loss': 0.31891410985458507}
2023-01-04 00:16:46,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:46,288 INFO:     Epoch: 22
2023-01-04 00:16:47,847 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.430487056573232, 'Total loss': 0.430487056573232} | train loss {'Reaction outcome loss': 0.3171657690384092, 'Total loss': 0.3171657690384092}
2023-01-04 00:16:47,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:47,847 INFO:     Epoch: 23
2023-01-04 00:16:49,430 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42488927841186525, 'Total loss': 0.42488927841186525} | train loss {'Reaction outcome loss': 0.3104149660326704, 'Total loss': 0.3104149660326704}
2023-01-04 00:16:49,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:49,431 INFO:     Epoch: 24
2023-01-04 00:16:51,000 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4184441129366557, 'Total loss': 0.4184441129366557} | train loss {'Reaction outcome loss': 0.30660775752506986, 'Total loss': 0.30660775752506986}
2023-01-04 00:16:51,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:51,001 INFO:     Epoch: 25
2023-01-04 00:16:52,594 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40555664847294487, 'Total loss': 0.40555664847294487} | train loss {'Reaction outcome loss': 0.3030126550826278, 'Total loss': 0.3030126550826278}
2023-01-04 00:16:52,594 INFO:     Found new best model at epoch 25
2023-01-04 00:16:52,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:52,595 INFO:     Epoch: 26
2023-01-04 00:16:54,190 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4220081011454264, 'Total loss': 0.4220081011454264} | train loss {'Reaction outcome loss': 0.3008135256432269, 'Total loss': 0.3008135256432269}
2023-01-04 00:16:54,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:54,190 INFO:     Epoch: 27
2023-01-04 00:16:55,804 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41028307874997455, 'Total loss': 0.41028307874997455} | train loss {'Reaction outcome loss': 0.29490519105626717, 'Total loss': 0.29490519105626717}
2023-01-04 00:16:55,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:55,804 INFO:     Epoch: 28
2023-01-04 00:16:57,370 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4269392788410187, 'Total loss': 0.4269392788410187} | train loss {'Reaction outcome loss': 0.2888360792485467, 'Total loss': 0.2888360792485467}
2023-01-04 00:16:57,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:57,370 INFO:     Epoch: 29
2023-01-04 00:16:58,952 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42896310389041903, 'Total loss': 0.42896310389041903} | train loss {'Reaction outcome loss': 0.28622325536978505, 'Total loss': 0.28622325536978505}
2023-01-04 00:16:58,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:16:58,952 INFO:     Epoch: 30
2023-01-04 00:17:00,516 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4093921105066935, 'Total loss': 0.4093921105066935} | train loss {'Reaction outcome loss': 0.2805900175641053, 'Total loss': 0.2805900175641053}
2023-01-04 00:17:00,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:00,517 INFO:     Epoch: 31
2023-01-04 00:17:02,101 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41804934839407604, 'Total loss': 0.41804934839407604} | train loss {'Reaction outcome loss': 0.27681197198855617, 'Total loss': 0.27681197198855617}
2023-01-04 00:17:02,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:02,101 INFO:     Epoch: 32
2023-01-04 00:17:03,685 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4017524937788645, 'Total loss': 0.4017524937788645} | train loss {'Reaction outcome loss': 0.27435213147941295, 'Total loss': 0.27435213147941295}
2023-01-04 00:17:03,686 INFO:     Found new best model at epoch 32
2023-01-04 00:17:03,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:03,687 INFO:     Epoch: 33
2023-01-04 00:17:05,269 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4303236067295074, 'Total loss': 0.4303236067295074} | train loss {'Reaction outcome loss': 0.2707645509419215, 'Total loss': 0.2707645509419215}
2023-01-04 00:17:05,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:05,269 INFO:     Epoch: 34
2023-01-04 00:17:06,839 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4057040214538574, 'Total loss': 0.4057040214538574} | train loss {'Reaction outcome loss': 0.26795408540289767, 'Total loss': 0.26795408540289767}
2023-01-04 00:17:06,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:06,839 INFO:     Epoch: 35
2023-01-04 00:17:08,421 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.421455176671346, 'Total loss': 0.421455176671346} | train loss {'Reaction outcome loss': 0.26660578056191003, 'Total loss': 0.26660578056191003}
2023-01-04 00:17:08,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:08,421 INFO:     Epoch: 36
2023-01-04 00:17:10,016 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4080075711011887, 'Total loss': 0.4080075711011887} | train loss {'Reaction outcome loss': 0.2613495153504132, 'Total loss': 0.2613495153504132}
2023-01-04 00:17:10,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:10,017 INFO:     Epoch: 37
2023-01-04 00:17:11,627 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.432732758919398, 'Total loss': 0.432732758919398} | train loss {'Reaction outcome loss': 0.2583034163626441, 'Total loss': 0.2583034163626441}
2023-01-04 00:17:11,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:11,627 INFO:     Epoch: 38
2023-01-04 00:17:13,244 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40118934363126757, 'Total loss': 0.40118934363126757} | train loss {'Reaction outcome loss': 0.2550368528731548, 'Total loss': 0.2550368528731548}
2023-01-04 00:17:13,244 INFO:     Found new best model at epoch 38
2023-01-04 00:17:13,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:13,245 INFO:     Epoch: 39
2023-01-04 00:17:14,839 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4095839887857437, 'Total loss': 0.4095839887857437} | train loss {'Reaction outcome loss': 0.2545965613838095, 'Total loss': 0.2545965613838095}
2023-01-04 00:17:14,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:14,839 INFO:     Epoch: 40
2023-01-04 00:17:16,457 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40209874014059704, 'Total loss': 0.40209874014059704} | train loss {'Reaction outcome loss': 0.25022558661272926, 'Total loss': 0.25022558661272926}
2023-01-04 00:17:16,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:16,457 INFO:     Epoch: 41
2023-01-04 00:17:18,022 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4210300832986832, 'Total loss': 0.4210300832986832} | train loss {'Reaction outcome loss': 0.2460765569151318, 'Total loss': 0.2460765569151318}
2023-01-04 00:17:18,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:18,022 INFO:     Epoch: 42
2023-01-04 00:17:19,636 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4311478704214096, 'Total loss': 0.4311478704214096} | train loss {'Reaction outcome loss': 0.24708066311032667, 'Total loss': 0.24708066311032667}
2023-01-04 00:17:19,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:19,637 INFO:     Epoch: 43
2023-01-04 00:17:21,217 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4240111917257309, 'Total loss': 0.4240111917257309} | train loss {'Reaction outcome loss': 0.24335129537286548, 'Total loss': 0.24335129537286548}
2023-01-04 00:17:21,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:21,218 INFO:     Epoch: 44
2023-01-04 00:17:22,826 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4242722153663635, 'Total loss': 0.4242722153663635} | train loss {'Reaction outcome loss': 0.2378910303007077, 'Total loss': 0.2378910303007077}
2023-01-04 00:17:22,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:22,827 INFO:     Epoch: 45
2023-01-04 00:17:24,406 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4070788631836573, 'Total loss': 0.4070788631836573} | train loss {'Reaction outcome loss': 0.2370110167883826, 'Total loss': 0.2370110167883826}
2023-01-04 00:17:24,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:24,406 INFO:     Epoch: 46
2023-01-04 00:17:25,990 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4196825126806895, 'Total loss': 0.4196825126806895} | train loss {'Reaction outcome loss': 0.23740205480071314, 'Total loss': 0.23740205480071314}
2023-01-04 00:17:25,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:25,990 INFO:     Epoch: 47
2023-01-04 00:17:27,573 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4393087824185689, 'Total loss': 0.4393087824185689} | train loss {'Reaction outcome loss': 0.2355087225726486, 'Total loss': 0.2355087225726486}
2023-01-04 00:17:27,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:27,574 INFO:     Epoch: 48
2023-01-04 00:17:29,177 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4365385880072912, 'Total loss': 0.4365385880072912} | train loss {'Reaction outcome loss': 0.23145582945677487, 'Total loss': 0.23145582945677487}
2023-01-04 00:17:29,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:29,177 INFO:     Epoch: 49
2023-01-04 00:17:30,786 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43622687260309856, 'Total loss': 0.43622687260309856} | train loss {'Reaction outcome loss': 0.22981321830710355, 'Total loss': 0.22981321830710355}
2023-01-04 00:17:30,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:30,786 INFO:     Epoch: 50
2023-01-04 00:17:32,380 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44171469608942665, 'Total loss': 0.44171469608942665} | train loss {'Reaction outcome loss': 0.22643422699757737, 'Total loss': 0.22643422699757737}
2023-01-04 00:17:32,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:32,381 INFO:     Epoch: 51
2023-01-04 00:17:33,948 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42266716857751213, 'Total loss': 0.42266716857751213} | train loss {'Reaction outcome loss': 0.22534353030424048, 'Total loss': 0.22534353030424048}
2023-01-04 00:17:33,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:33,949 INFO:     Epoch: 52
2023-01-04 00:17:35,510 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.420048388838768, 'Total loss': 0.420048388838768} | train loss {'Reaction outcome loss': 0.22218297193520262, 'Total loss': 0.22218297193520262}
2023-01-04 00:17:35,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:35,510 INFO:     Epoch: 53
2023-01-04 00:17:37,121 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.427794936299324, 'Total loss': 0.427794936299324} | train loss {'Reaction outcome loss': 0.22102493911057058, 'Total loss': 0.22102493911057058}
2023-01-04 00:17:37,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:37,121 INFO:     Epoch: 54
2023-01-04 00:17:38,743 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42077096303304035, 'Total loss': 0.42077096303304035} | train loss {'Reaction outcome loss': 0.21953890872371457, 'Total loss': 0.21953890872371457}
2023-01-04 00:17:38,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:38,744 INFO:     Epoch: 55
2023-01-04 00:17:40,313 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41087139944235485, 'Total loss': 0.41087139944235485} | train loss {'Reaction outcome loss': 0.21630875128627258, 'Total loss': 0.21630875128627258}
2023-01-04 00:17:40,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:40,314 INFO:     Epoch: 56
2023-01-04 00:17:41,900 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.417183992266655, 'Total loss': 0.417183992266655} | train loss {'Reaction outcome loss': 0.21273915110713373, 'Total loss': 0.21273915110713373}
2023-01-04 00:17:41,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:41,900 INFO:     Epoch: 57
2023-01-04 00:17:43,478 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41444916526476544, 'Total loss': 0.41444916526476544} | train loss {'Reaction outcome loss': 0.21336802811681355, 'Total loss': 0.21336802811681355}
2023-01-04 00:17:43,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:43,478 INFO:     Epoch: 58
2023-01-04 00:17:45,043 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4247957428296407, 'Total loss': 0.4247957428296407} | train loss {'Reaction outcome loss': 0.21163512847936936, 'Total loss': 0.21163512847936936}
2023-01-04 00:17:45,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:45,044 INFO:     Epoch: 59
2023-01-04 00:17:46,632 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4210876430074374, 'Total loss': 0.4210876430074374} | train loss {'Reaction outcome loss': 0.2122215912643358, 'Total loss': 0.2122215912643358}
2023-01-04 00:17:46,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:46,633 INFO:     Epoch: 60
2023-01-04 00:17:48,247 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42590091029802957, 'Total loss': 0.42590091029802957} | train loss {'Reaction outcome loss': 0.20727219864943602, 'Total loss': 0.20727219864943602}
2023-01-04 00:17:48,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:48,247 INFO:     Epoch: 61
2023-01-04 00:17:49,867 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4216353197892507, 'Total loss': 0.4216353197892507} | train loss {'Reaction outcome loss': 0.20576447502703127, 'Total loss': 0.20576447502703127}
2023-01-04 00:17:49,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:49,867 INFO:     Epoch: 62
2023-01-04 00:17:51,419 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42563139597574867, 'Total loss': 0.42563139597574867} | train loss {'Reaction outcome loss': 0.2048912392453338, 'Total loss': 0.2048912392453338}
2023-01-04 00:17:51,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:51,419 INFO:     Epoch: 63
2023-01-04 00:17:53,027 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41949518273274106, 'Total loss': 0.41949518273274106} | train loss {'Reaction outcome loss': 0.20308047240722354, 'Total loss': 0.20308047240722354}
2023-01-04 00:17:53,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:53,028 INFO:     Epoch: 64
2023-01-04 00:17:54,616 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4302389472723007, 'Total loss': 0.4302389472723007} | train loss {'Reaction outcome loss': 0.20219024606592897, 'Total loss': 0.20219024606592897}
2023-01-04 00:17:54,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:54,617 INFO:     Epoch: 65
2023-01-04 00:17:56,204 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4368729015191396, 'Total loss': 0.4368729015191396} | train loss {'Reaction outcome loss': 0.20320053266728447, 'Total loss': 0.20320053266728447}
2023-01-04 00:17:56,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:56,204 INFO:     Epoch: 66
2023-01-04 00:17:57,816 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4160030633211136, 'Total loss': 0.4160030633211136} | train loss {'Reaction outcome loss': 0.19828080826432165, 'Total loss': 0.19828080826432165}
2023-01-04 00:17:57,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:57,817 INFO:     Epoch: 67
2023-01-04 00:17:59,424 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42141613364219666, 'Total loss': 0.42141613364219666} | train loss {'Reaction outcome loss': 0.1996329105085265, 'Total loss': 0.1996329105085265}
2023-01-04 00:17:59,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:17:59,424 INFO:     Epoch: 68
2023-01-04 00:18:00,985 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.445652120312055, 'Total loss': 0.445652120312055} | train loss {'Reaction outcome loss': 0.19556818659804817, 'Total loss': 0.19556818659804817}
2023-01-04 00:18:00,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:00,986 INFO:     Epoch: 69
2023-01-04 00:18:02,575 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4029205327232679, 'Total loss': 0.4029205327232679} | train loss {'Reaction outcome loss': 0.19336020276222352, 'Total loss': 0.19336020276222352}
2023-01-04 00:18:02,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:02,576 INFO:     Epoch: 70
2023-01-04 00:18:04,197 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46345412929852803, 'Total loss': 0.46345412929852803} | train loss {'Reaction outcome loss': 0.1929939654553785, 'Total loss': 0.1929939654553785}
2023-01-04 00:18:04,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:04,197 INFO:     Epoch: 71
2023-01-04 00:18:05,821 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4192815572023392, 'Total loss': 0.4192815572023392} | train loss {'Reaction outcome loss': 0.1937573154314156, 'Total loss': 0.1937573154314156}
2023-01-04 00:18:05,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:05,822 INFO:     Epoch: 72
2023-01-04 00:18:07,442 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41058865090211233, 'Total loss': 0.41058865090211233} | train loss {'Reaction outcome loss': 0.1927119346376318, 'Total loss': 0.1927119346376318}
2023-01-04 00:18:07,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:07,442 INFO:     Epoch: 73
2023-01-04 00:18:09,006 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4479241559902827, 'Total loss': 0.4479241559902827} | train loss {'Reaction outcome loss': 0.19141001036784944, 'Total loss': 0.19141001036784944}
2023-01-04 00:18:09,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:09,007 INFO:     Epoch: 74
2023-01-04 00:18:10,594 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.403810774286588, 'Total loss': 0.403810774286588} | train loss {'Reaction outcome loss': 0.18939556844913177, 'Total loss': 0.18939556844913177}
2023-01-04 00:18:10,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:10,594 INFO:     Epoch: 75
2023-01-04 00:18:12,164 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4192617545525233, 'Total loss': 0.4192617545525233} | train loss {'Reaction outcome loss': 0.1897604354541667, 'Total loss': 0.1897604354541667}
2023-01-04 00:18:12,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:12,164 INFO:     Epoch: 76
2023-01-04 00:18:13,752 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44924891789754234, 'Total loss': 0.44924891789754234} | train loss {'Reaction outcome loss': 0.18885689035710626, 'Total loss': 0.18885689035710626}
2023-01-04 00:18:13,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:13,753 INFO:     Epoch: 77
2023-01-04 00:18:15,341 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43170974651972455, 'Total loss': 0.43170974651972455} | train loss {'Reaction outcome loss': 0.18586806245963938, 'Total loss': 0.18586806245963938}
2023-01-04 00:18:15,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:15,342 INFO:     Epoch: 78
2023-01-04 00:18:16,929 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4387267013390859, 'Total loss': 0.4387267013390859} | train loss {'Reaction outcome loss': 0.18453379214680107, 'Total loss': 0.18453379214680107}
2023-01-04 00:18:16,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:16,929 INFO:     Epoch: 79
2023-01-04 00:18:18,500 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4091473065316677, 'Total loss': 0.4091473065316677} | train loss {'Reaction outcome loss': 0.18404374980660032, 'Total loss': 0.18404374980660032}
2023-01-04 00:18:18,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:18,500 INFO:     Epoch: 80
2023-01-04 00:18:20,088 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4147742599248886, 'Total loss': 0.4147742599248886} | train loss {'Reaction outcome loss': 0.18025677114126892, 'Total loss': 0.18025677114126892}
2023-01-04 00:18:20,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:20,089 INFO:     Epoch: 81
2023-01-04 00:18:21,657 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42789906164010366, 'Total loss': 0.42789906164010366} | train loss {'Reaction outcome loss': 0.18157129258216514, 'Total loss': 0.18157129258216514}
2023-01-04 00:18:21,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:21,657 INFO:     Epoch: 82
2023-01-04 00:18:23,245 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4283499300479889, 'Total loss': 0.4283499300479889} | train loss {'Reaction outcome loss': 0.18112998850045414, 'Total loss': 0.18112998850045414}
2023-01-04 00:18:23,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:23,245 INFO:     Epoch: 83
2023-01-04 00:18:24,832 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43430192619562147, 'Total loss': 0.43430192619562147} | train loss {'Reaction outcome loss': 0.18061886700618007, 'Total loss': 0.18061886700618007}
2023-01-04 00:18:24,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:24,832 INFO:     Epoch: 84
2023-01-04 00:18:26,406 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4335577577352524, 'Total loss': 0.4335577577352524} | train loss {'Reaction outcome loss': 0.1797195639134976, 'Total loss': 0.1797195639134976}
2023-01-04 00:18:26,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:26,406 INFO:     Epoch: 85
2023-01-04 00:18:27,993 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4431924561659495, 'Total loss': 0.4431924561659495} | train loss {'Reaction outcome loss': 0.17715370791019314, 'Total loss': 0.17715370791019314}
2023-01-04 00:18:27,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:27,994 INFO:     Epoch: 86
2023-01-04 00:18:29,566 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42720971554517745, 'Total loss': 0.42720971554517745} | train loss {'Reaction outcome loss': 0.17736940231364573, 'Total loss': 0.17736940231364573}
2023-01-04 00:18:29,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:29,566 INFO:     Epoch: 87
2023-01-04 00:18:31,183 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4289027919371923, 'Total loss': 0.4289027919371923} | train loss {'Reaction outcome loss': 0.17524693061318927, 'Total loss': 0.17524693061318927}
2023-01-04 00:18:31,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:31,183 INFO:     Epoch: 88
2023-01-04 00:18:32,796 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4289603094259898, 'Total loss': 0.4289603094259898} | train loss {'Reaction outcome loss': 0.17332274164922917, 'Total loss': 0.17332274164922917}
2023-01-04 00:18:32,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:32,796 INFO:     Epoch: 89
2023-01-04 00:18:34,409 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4356531769037247, 'Total loss': 0.4356531769037247} | train loss {'Reaction outcome loss': 0.17402480804381798, 'Total loss': 0.17402480804381798}
2023-01-04 00:18:34,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:34,410 INFO:     Epoch: 90
2023-01-04 00:18:35,985 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4663826326529185, 'Total loss': 0.4663826326529185} | train loss {'Reaction outcome loss': 0.17244972203633863, 'Total loss': 0.17244972203633863}
2023-01-04 00:18:35,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:35,985 INFO:     Epoch: 91
2023-01-04 00:18:37,568 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4368426849444707, 'Total loss': 0.4368426849444707} | train loss {'Reaction outcome loss': 0.17187210742085085, 'Total loss': 0.17187210742085085}
2023-01-04 00:18:37,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:37,569 INFO:     Epoch: 92
2023-01-04 00:18:39,148 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43880327343940734, 'Total loss': 0.43880327343940734} | train loss {'Reaction outcome loss': 0.17394538809728882, 'Total loss': 0.17394538809728882}
2023-01-04 00:18:39,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:39,148 INFO:     Epoch: 93
2023-01-04 00:18:40,764 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4328437238931656, 'Total loss': 0.4328437238931656} | train loss {'Reaction outcome loss': 0.16958358477338822, 'Total loss': 0.16958358477338822}
2023-01-04 00:18:40,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:40,764 INFO:     Epoch: 94
2023-01-04 00:18:42,384 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43079010049502053, 'Total loss': 0.43079010049502053} | train loss {'Reaction outcome loss': 0.17357304855419772, 'Total loss': 0.17357304855419772}
2023-01-04 00:18:42,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:42,385 INFO:     Epoch: 95
2023-01-04 00:18:43,997 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4388263632853826, 'Total loss': 0.4388263632853826} | train loss {'Reaction outcome loss': 0.1693620187821832, 'Total loss': 0.1693620187821832}
2023-01-04 00:18:43,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:43,997 INFO:     Epoch: 96
2023-01-04 00:18:45,559 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4586557149887085, 'Total loss': 0.4586557149887085} | train loss {'Reaction outcome loss': 0.16875198750627518, 'Total loss': 0.16875198750627518}
2023-01-04 00:18:45,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:45,560 INFO:     Epoch: 97
2023-01-04 00:18:47,154 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4511418879032135, 'Total loss': 0.4511418879032135} | train loss {'Reaction outcome loss': 0.16970209125429392, 'Total loss': 0.16970209125429392}
2023-01-04 00:18:47,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:47,154 INFO:     Epoch: 98
2023-01-04 00:18:48,717 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43153321941693623, 'Total loss': 0.43153321941693623} | train loss {'Reaction outcome loss': 0.16885423981822537, 'Total loss': 0.16885423981822537}
2023-01-04 00:18:48,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:48,717 INFO:     Epoch: 99
2023-01-04 00:18:50,295 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42814201513926187, 'Total loss': 0.42814201513926187} | train loss {'Reaction outcome loss': 0.1701272628440039, 'Total loss': 0.1701272628440039}
2023-01-04 00:18:50,295 INFO:     Best model found after epoch 39 of 100.
2023-01-04 00:18:50,295 INFO:   Done with stage: TRAINING
2023-01-04 00:18:50,295 INFO:   Starting stage: EVALUATION
2023-01-04 00:18:50,431 INFO:   Done with stage: EVALUATION
2023-01-04 00:18:50,431 INFO:   Leaving out SEQ value Fold_1
2023-01-04 00:18:50,444 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 00:18:50,444 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:18:51,091 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:18:51,091 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:18:51,160 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:18:51,160 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:18:51,160 INFO:     No hyperparam tuning for this model
2023-01-04 00:18:51,160 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:18:51,160 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:18:51,161 INFO:     None feature selector for col prot
2023-01-04 00:18:51,161 INFO:     None feature selector for col prot
2023-01-04 00:18:51,161 INFO:     None feature selector for col prot
2023-01-04 00:18:51,162 INFO:     None feature selector for col chem
2023-01-04 00:18:51,162 INFO:     None feature selector for col chem
2023-01-04 00:18:51,162 INFO:     None feature selector for col chem
2023-01-04 00:18:51,162 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:18:51,162 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:18:51,163 INFO:     Number of params in model 70141
2023-01-04 00:18:51,167 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:18:51,167 INFO:   Starting stage: TRAINING
2023-01-04 00:18:51,211 INFO:     Val loss before train {'Reaction outcome loss': 0.9920816818873087, 'Total loss': 0.9920816818873087}
2023-01-04 00:18:51,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:51,212 INFO:     Epoch: 0
2023-01-04 00:18:52,788 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6300615986188253, 'Total loss': 0.6300615986188253} | train loss {'Reaction outcome loss': 0.8455587868055288, 'Total loss': 0.8455587868055288}
2023-01-04 00:18:52,788 INFO:     Found new best model at epoch 0
2023-01-04 00:18:52,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:52,789 INFO:     Epoch: 1
2023-01-04 00:18:54,372 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5300967435042063, 'Total loss': 0.5300967435042063} | train loss {'Reaction outcome loss': 0.5840878504579955, 'Total loss': 0.5840878504579955}
2023-01-04 00:18:54,373 INFO:     Found new best model at epoch 1
2023-01-04 00:18:54,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:54,373 INFO:     Epoch: 2
2023-01-04 00:18:55,976 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5119166692097982, 'Total loss': 0.5119166692097982} | train loss {'Reaction outcome loss': 0.509671341709412, 'Total loss': 0.509671341709412}
2023-01-04 00:18:55,976 INFO:     Found new best model at epoch 2
2023-01-04 00:18:55,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:55,977 INFO:     Epoch: 3
2023-01-04 00:18:57,562 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46498760680357615, 'Total loss': 0.46498760680357615} | train loss {'Reaction outcome loss': 0.4709300037718167, 'Total loss': 0.4709300037718167}
2023-01-04 00:18:57,562 INFO:     Found new best model at epoch 3
2023-01-04 00:18:57,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:57,563 INFO:     Epoch: 4
2023-01-04 00:18:59,172 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45950653553009035, 'Total loss': 0.45950653553009035} | train loss {'Reaction outcome loss': 0.4458789632376963, 'Total loss': 0.4458789632376963}
2023-01-04 00:18:59,173 INFO:     Found new best model at epoch 4
2023-01-04 00:18:59,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:18:59,173 INFO:     Epoch: 5
2023-01-04 00:19:00,758 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4467651257912318, 'Total loss': 0.4467651257912318} | train loss {'Reaction outcome loss': 0.43001896567153236, 'Total loss': 0.43001896567153236}
2023-01-04 00:19:00,758 INFO:     Found new best model at epoch 5
2023-01-04 00:19:00,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:00,759 INFO:     Epoch: 6
2023-01-04 00:19:02,343 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45127971371014913, 'Total loss': 0.45127971371014913} | train loss {'Reaction outcome loss': 0.4095152356002453, 'Total loss': 0.4095152356002453}
2023-01-04 00:19:02,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:02,343 INFO:     Epoch: 7
2023-01-04 00:19:03,936 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4160547912120819, 'Total loss': 0.4160547912120819} | train loss {'Reaction outcome loss': 0.3975326074627194, 'Total loss': 0.3975326074627194}
2023-01-04 00:19:03,936 INFO:     Found new best model at epoch 7
2023-01-04 00:19:03,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:03,937 INFO:     Epoch: 8
2023-01-04 00:19:05,515 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4333985269069672, 'Total loss': 0.4333985269069672} | train loss {'Reaction outcome loss': 0.38545580776612254, 'Total loss': 0.38545580776612254}
2023-01-04 00:19:05,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:05,516 INFO:     Epoch: 9
2023-01-04 00:19:07,122 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42163093785444894, 'Total loss': 0.42163093785444894} | train loss {'Reaction outcome loss': 0.3702995517175563, 'Total loss': 0.3702995517175563}
2023-01-04 00:19:07,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:07,122 INFO:     Epoch: 10
2023-01-04 00:19:08,735 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41742550730705263, 'Total loss': 0.41742550730705263} | train loss {'Reaction outcome loss': 0.36360223629396327, 'Total loss': 0.36360223629396327}
2023-01-04 00:19:08,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:08,736 INFO:     Epoch: 11
2023-01-04 00:19:10,346 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4255549987157186, 'Total loss': 0.4255549987157186} | train loss {'Reaction outcome loss': 0.3541918906525974, 'Total loss': 0.3541918906525974}
2023-01-04 00:19:10,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:10,346 INFO:     Epoch: 12
2023-01-04 00:19:11,925 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40450692077477773, 'Total loss': 0.40450692077477773} | train loss {'Reaction outcome loss': 0.34530687256016, 'Total loss': 0.34530687256016}
2023-01-04 00:19:11,925 INFO:     Found new best model at epoch 12
2023-01-04 00:19:11,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:11,926 INFO:     Epoch: 13
2023-01-04 00:19:13,505 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3961397737264633, 'Total loss': 0.3961397737264633} | train loss {'Reaction outcome loss': 0.33632393562010604, 'Total loss': 0.33632393562010604}
2023-01-04 00:19:13,505 INFO:     Found new best model at epoch 13
2023-01-04 00:19:13,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:13,506 INFO:     Epoch: 14
2023-01-04 00:19:15,079 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4081715777516365, 'Total loss': 0.4081715777516365} | train loss {'Reaction outcome loss': 0.3316999352707045, 'Total loss': 0.3316999352707045}
2023-01-04 00:19:15,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:15,079 INFO:     Epoch: 15
2023-01-04 00:19:16,688 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40214015046755475, 'Total loss': 0.40214015046755475} | train loss {'Reaction outcome loss': 0.32394814975287795, 'Total loss': 0.32394814975287795}
2023-01-04 00:19:16,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:16,689 INFO:     Epoch: 16
2023-01-04 00:19:18,259 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40822019974390666, 'Total loss': 0.40822019974390666} | train loss {'Reaction outcome loss': 0.31913480407347644, 'Total loss': 0.31913480407347644}
2023-01-04 00:19:18,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:18,259 INFO:     Epoch: 17
2023-01-04 00:19:19,867 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41906546950340273, 'Total loss': 0.41906546950340273} | train loss {'Reaction outcome loss': 0.31179441179889833, 'Total loss': 0.31179441179889833}
2023-01-04 00:19:19,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:19,867 INFO:     Epoch: 18
2023-01-04 00:19:21,433 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4210855454206467, 'Total loss': 0.4210855454206467} | train loss {'Reaction outcome loss': 0.30776439786609944, 'Total loss': 0.30776439786609944}
2023-01-04 00:19:21,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:21,433 INFO:     Epoch: 19
2023-01-04 00:19:23,008 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42164440552393595, 'Total loss': 0.42164440552393595} | train loss {'Reaction outcome loss': 0.29992278477680073, 'Total loss': 0.29992278477680073}
2023-01-04 00:19:23,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:23,009 INFO:     Epoch: 20
2023-01-04 00:19:24,603 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40760727822780607, 'Total loss': 0.40760727822780607} | train loss {'Reaction outcome loss': 0.2955181376369548, 'Total loss': 0.2955181376369548}
2023-01-04 00:19:24,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:24,603 INFO:     Epoch: 21
2023-01-04 00:19:26,212 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40212159355481464, 'Total loss': 0.40212159355481464} | train loss {'Reaction outcome loss': 0.2900610622698373, 'Total loss': 0.2900610622698373}
2023-01-04 00:19:26,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:26,212 INFO:     Epoch: 22
2023-01-04 00:19:27,813 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40413141548633574, 'Total loss': 0.40413141548633574} | train loss {'Reaction outcome loss': 0.28727610624075806, 'Total loss': 0.28727610624075806}
2023-01-04 00:19:27,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:27,814 INFO:     Epoch: 23
2023-01-04 00:19:29,376 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4135682284832001, 'Total loss': 0.4135682284832001} | train loss {'Reaction outcome loss': 0.28192392285287815, 'Total loss': 0.28192392285287815}
2023-01-04 00:19:29,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:29,376 INFO:     Epoch: 24
2023-01-04 00:19:30,951 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41471544206142424, 'Total loss': 0.41471544206142424} | train loss {'Reaction outcome loss': 0.27952256801463393, 'Total loss': 0.27952256801463393}
2023-01-04 00:19:30,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:30,951 INFO:     Epoch: 25
2023-01-04 00:19:32,537 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39151083628336586, 'Total loss': 0.39151083628336586} | train loss {'Reaction outcome loss': 0.2746312335731774, 'Total loss': 0.2746312335731774}
2023-01-04 00:19:32,537 INFO:     Found new best model at epoch 25
2023-01-04 00:19:32,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:32,538 INFO:     Epoch: 26
2023-01-04 00:19:34,117 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3934021125237147, 'Total loss': 0.3934021125237147} | train loss {'Reaction outcome loss': 0.2707538702355249, 'Total loss': 0.2707538702355249}
2023-01-04 00:19:34,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:34,117 INFO:     Epoch: 27
2023-01-04 00:19:35,696 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39875601331392924, 'Total loss': 0.39875601331392924} | train loss {'Reaction outcome loss': 0.2667625840399822, 'Total loss': 0.2667625840399822}
2023-01-04 00:19:35,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:35,697 INFO:     Epoch: 28
2023-01-04 00:19:37,277 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4140194763739904, 'Total loss': 0.4140194763739904} | train loss {'Reaction outcome loss': 0.2643355434882815, 'Total loss': 0.2643355434882815}
2023-01-04 00:19:37,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:37,277 INFO:     Epoch: 29
2023-01-04 00:19:38,540 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41860231359799704, 'Total loss': 0.41860231359799704} | train loss {'Reaction outcome loss': 0.26104156482611257, 'Total loss': 0.26104156482611257}
2023-01-04 00:19:38,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:38,541 INFO:     Epoch: 30
2023-01-04 00:19:39,584 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40028077363967896, 'Total loss': 0.40028077363967896} | train loss {'Reaction outcome loss': 0.2580621379978248, 'Total loss': 0.2580621379978248}
2023-01-04 00:19:39,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:39,585 INFO:     Epoch: 31
2023-01-04 00:19:40,641 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4161500136057536, 'Total loss': 0.4161500136057536} | train loss {'Reaction outcome loss': 0.25636246888796344, 'Total loss': 0.25636246888796344}
2023-01-04 00:19:40,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:40,641 INFO:     Epoch: 32
2023-01-04 00:19:41,689 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.411242401599884, 'Total loss': 0.411242401599884} | train loss {'Reaction outcome loss': 0.2520161665377826, 'Total loss': 0.2520161665377826}
2023-01-04 00:19:41,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:41,690 INFO:     Epoch: 33
2023-01-04 00:19:42,888 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41775226990381875, 'Total loss': 0.41775226990381875} | train loss {'Reaction outcome loss': 0.24855459164692104, 'Total loss': 0.24855459164692104}
2023-01-04 00:19:42,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:42,888 INFO:     Epoch: 34
2023-01-04 00:19:44,469 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3784530977408091, 'Total loss': 0.3784530977408091} | train loss {'Reaction outcome loss': 0.24664327086214602, 'Total loss': 0.24664327086214602}
2023-01-04 00:19:44,469 INFO:     Found new best model at epoch 34
2023-01-04 00:19:44,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:44,470 INFO:     Epoch: 35
2023-01-04 00:19:46,076 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4088981032371521, 'Total loss': 0.4088981032371521} | train loss {'Reaction outcome loss': 0.24219836879276882, 'Total loss': 0.24219836879276882}
2023-01-04 00:19:46,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:46,076 INFO:     Epoch: 36
2023-01-04 00:19:47,649 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4097793777783712, 'Total loss': 0.4097793777783712} | train loss {'Reaction outcome loss': 0.24146457663635268, 'Total loss': 0.24146457663635268}
2023-01-04 00:19:47,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:47,650 INFO:     Epoch: 37
2023-01-04 00:19:49,251 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39897879560788474, 'Total loss': 0.39897879560788474} | train loss {'Reaction outcome loss': 0.2388479877127348, 'Total loss': 0.2388479877127348}
2023-01-04 00:19:49,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:49,251 INFO:     Epoch: 38
2023-01-04 00:19:50,859 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4289643257856369, 'Total loss': 0.4289643257856369} | train loss {'Reaction outcome loss': 0.2366570489630647, 'Total loss': 0.2366570489630647}
2023-01-04 00:19:50,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:50,860 INFO:     Epoch: 39
2023-01-04 00:19:52,444 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39375078678131104, 'Total loss': 0.39375078678131104} | train loss {'Reaction outcome loss': 0.23446557685787225, 'Total loss': 0.23446557685787225}
2023-01-04 00:19:52,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:52,446 INFO:     Epoch: 40
2023-01-04 00:19:54,016 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4103026648362478, 'Total loss': 0.4103026648362478} | train loss {'Reaction outcome loss': 0.22953915343123632, 'Total loss': 0.22953915343123632}
2023-01-04 00:19:54,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:54,017 INFO:     Epoch: 41
2023-01-04 00:19:55,624 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39249717990557353, 'Total loss': 0.39249717990557353} | train loss {'Reaction outcome loss': 0.23000007688346571, 'Total loss': 0.23000007688346571}
2023-01-04 00:19:55,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:55,624 INFO:     Epoch: 42
2023-01-04 00:19:57,185 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3945602851298948, 'Total loss': 0.3945602851298948} | train loss {'Reaction outcome loss': 0.2248540938743492, 'Total loss': 0.2248540938743492}
2023-01-04 00:19:57,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:57,186 INFO:     Epoch: 43
2023-01-04 00:19:58,796 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44128487408161166, 'Total loss': 0.44128487408161166} | train loss {'Reaction outcome loss': 0.227007167345851, 'Total loss': 0.227007167345851}
2023-01-04 00:19:58,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:19:58,797 INFO:     Epoch: 44
2023-01-04 00:20:00,364 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41755687693754834, 'Total loss': 0.41755687693754834} | train loss {'Reaction outcome loss': 0.22148952688885867, 'Total loss': 0.22148952688885867}
2023-01-04 00:20:00,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:00,364 INFO:     Epoch: 45
2023-01-04 00:20:01,946 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3785480206211408, 'Total loss': 0.3785480206211408} | train loss {'Reaction outcome loss': 0.22276064506086118, 'Total loss': 0.22276064506086118}
2023-01-04 00:20:01,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:01,947 INFO:     Epoch: 46
2023-01-04 00:20:03,541 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40855788414676986, 'Total loss': 0.40855788414676986} | train loss {'Reaction outcome loss': 0.21818049544346158, 'Total loss': 0.21818049544346158}
2023-01-04 00:20:03,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:03,541 INFO:     Epoch: 47
2023-01-04 00:20:05,148 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3815865037341913, 'Total loss': 0.3815865037341913} | train loss {'Reaction outcome loss': 0.21771099163477656, 'Total loss': 0.21771099163477656}
2023-01-04 00:20:05,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:05,148 INFO:     Epoch: 48
2023-01-04 00:20:06,736 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4216968595981598, 'Total loss': 0.4216968595981598} | train loss {'Reaction outcome loss': 0.2147238728501936, 'Total loss': 0.2147238728501936}
2023-01-04 00:20:06,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:06,736 INFO:     Epoch: 49
2023-01-04 00:20:08,347 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4096597174803416, 'Total loss': 0.4096597174803416} | train loss {'Reaction outcome loss': 0.21330565662823453, 'Total loss': 0.21330565662823453}
2023-01-04 00:20:08,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:08,347 INFO:     Epoch: 50
2023-01-04 00:20:09,939 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41335472265879314, 'Total loss': 0.41335472265879314} | train loss {'Reaction outcome loss': 0.21097925057920225, 'Total loss': 0.21097925057920225}
2023-01-04 00:20:09,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:09,939 INFO:     Epoch: 51
2023-01-04 00:20:11,526 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4144116928180059, 'Total loss': 0.4144116928180059} | train loss {'Reaction outcome loss': 0.2091025777813727, 'Total loss': 0.2091025777813727}
2023-01-04 00:20:11,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:11,527 INFO:     Epoch: 52
2023-01-04 00:20:13,113 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42474125425020853, 'Total loss': 0.42474125425020853} | train loss {'Reaction outcome loss': 0.2087836851141531, 'Total loss': 0.2087836851141531}
2023-01-04 00:20:13,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:13,113 INFO:     Epoch: 53
2023-01-04 00:20:14,682 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4178748001654943, 'Total loss': 0.4178748001654943} | train loss {'Reaction outcome loss': 0.20510888813457784, 'Total loss': 0.20510888813457784}
2023-01-04 00:20:14,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:14,683 INFO:     Epoch: 54
2023-01-04 00:20:16,268 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41264735609292985, 'Total loss': 0.41264735609292985} | train loss {'Reaction outcome loss': 0.2038795470946679, 'Total loss': 0.2038795470946679}
2023-01-04 00:20:16,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:16,268 INFO:     Epoch: 55
2023-01-04 00:20:17,878 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4183036029338837, 'Total loss': 0.4183036029338837} | train loss {'Reaction outcome loss': 0.2034550407140033, 'Total loss': 0.2034550407140033}
2023-01-04 00:20:17,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:17,878 INFO:     Epoch: 56
2023-01-04 00:20:19,450 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4153594175974528, 'Total loss': 0.4153594175974528} | train loss {'Reaction outcome loss': 0.20172024578753397, 'Total loss': 0.20172024578753397}
2023-01-04 00:20:19,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:19,451 INFO:     Epoch: 57
2023-01-04 00:20:21,033 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42530973156293234, 'Total loss': 0.42530973156293234} | train loss {'Reaction outcome loss': 0.19963856921089393, 'Total loss': 0.19963856921089393}
2023-01-04 00:20:21,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:21,033 INFO:     Epoch: 58
2023-01-04 00:20:22,612 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42092775205771127, 'Total loss': 0.42092775205771127} | train loss {'Reaction outcome loss': 0.20000052971452692, 'Total loss': 0.20000052971452692}
2023-01-04 00:20:22,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:22,612 INFO:     Epoch: 59
2023-01-04 00:20:24,193 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4281663010517756, 'Total loss': 0.4281663010517756} | train loss {'Reaction outcome loss': 0.1990062323106575, 'Total loss': 0.1990062323106575}
2023-01-04 00:20:24,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:24,195 INFO:     Epoch: 60
2023-01-04 00:20:25,764 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41012305493156115, 'Total loss': 0.41012305493156115} | train loss {'Reaction outcome loss': 0.19596224142252094, 'Total loss': 0.19596224142252094}
2023-01-04 00:20:25,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:25,764 INFO:     Epoch: 61
2023-01-04 00:20:27,366 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4045566956202189, 'Total loss': 0.4045566956202189} | train loss {'Reaction outcome loss': 0.1939819692396117, 'Total loss': 0.1939819692396117}
2023-01-04 00:20:27,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:27,367 INFO:     Epoch: 62
2023-01-04 00:20:28,944 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4223132664958636, 'Total loss': 0.4223132664958636} | train loss {'Reaction outcome loss': 0.1914199534803629, 'Total loss': 0.1914199534803629}
2023-01-04 00:20:28,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:28,944 INFO:     Epoch: 63
2023-01-04 00:20:30,530 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43145485321680704, 'Total loss': 0.43145485321680704} | train loss {'Reaction outcome loss': 0.19101871486182195, 'Total loss': 0.19101871486182195}
2023-01-04 00:20:30,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:30,531 INFO:     Epoch: 64
2023-01-04 00:20:32,125 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42085748066504797, 'Total loss': 0.42085748066504797} | train loss {'Reaction outcome loss': 0.19067737182779035, 'Total loss': 0.19067737182779035}
2023-01-04 00:20:32,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:32,125 INFO:     Epoch: 65
2023-01-04 00:20:33,693 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40356018642584485, 'Total loss': 0.40356018642584485} | train loss {'Reaction outcome loss': 0.1909628000627034, 'Total loss': 0.1909628000627034}
2023-01-04 00:20:33,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:33,693 INFO:     Epoch: 66
2023-01-04 00:20:35,281 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39356348911921185, 'Total loss': 0.39356348911921185} | train loss {'Reaction outcome loss': 0.18908175839668642, 'Total loss': 0.18908175839668642}
2023-01-04 00:20:35,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:35,281 INFO:     Epoch: 67
2023-01-04 00:20:36,853 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39438480337460835, 'Total loss': 0.39438480337460835} | train loss {'Reaction outcome loss': 0.18604247208113653, 'Total loss': 0.18604247208113653}
2023-01-04 00:20:36,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:36,853 INFO:     Epoch: 68
2023-01-04 00:20:38,441 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4035625507434209, 'Total loss': 0.4035625507434209} | train loss {'Reaction outcome loss': 0.185759440676248, 'Total loss': 0.185759440676248}
2023-01-04 00:20:38,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:38,442 INFO:     Epoch: 69
2023-01-04 00:20:40,027 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4220097800095876, 'Total loss': 0.4220097800095876} | train loss {'Reaction outcome loss': 0.18651065926482208, 'Total loss': 0.18651065926482208}
2023-01-04 00:20:40,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:40,027 INFO:     Epoch: 70
2023-01-04 00:20:41,612 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43145071615775427, 'Total loss': 0.43145071615775427} | train loss {'Reaction outcome loss': 0.18392356823667558, 'Total loss': 0.18392356823667558}
2023-01-04 00:20:41,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:41,613 INFO:     Epoch: 71
2023-01-04 00:20:43,201 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3935588225722313, 'Total loss': 0.3935588225722313} | train loss {'Reaction outcome loss': 0.18430840723678796, 'Total loss': 0.18430840723678796}
2023-01-04 00:20:43,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:43,202 INFO:     Epoch: 72
2023-01-04 00:20:44,788 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.442200118303299, 'Total loss': 0.442200118303299} | train loss {'Reaction outcome loss': 0.18348583551871517, 'Total loss': 0.18348583551871517}
2023-01-04 00:20:44,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:44,789 INFO:     Epoch: 73
2023-01-04 00:20:46,358 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42771225968996684, 'Total loss': 0.42771225968996684} | train loss {'Reaction outcome loss': 0.1803126112170463, 'Total loss': 0.1803126112170463}
2023-01-04 00:20:46,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:46,358 INFO:     Epoch: 74
2023-01-04 00:20:47,945 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39361322422822315, 'Total loss': 0.39361322422822315} | train loss {'Reaction outcome loss': 0.18089909429396808, 'Total loss': 0.18089909429396808}
2023-01-04 00:20:47,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:47,945 INFO:     Epoch: 75
2023-01-04 00:20:49,531 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4156136691570282, 'Total loss': 0.4156136691570282} | train loss {'Reaction outcome loss': 0.18031561695528728, 'Total loss': 0.18031561695528728}
2023-01-04 00:20:49,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:49,531 INFO:     Epoch: 76
2023-01-04 00:20:51,105 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4208662182092667, 'Total loss': 0.4208662182092667} | train loss {'Reaction outcome loss': 0.17665629379831962, 'Total loss': 0.17665629379831962}
2023-01-04 00:20:51,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:51,105 INFO:     Epoch: 77
2023-01-04 00:20:52,711 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3982335428396861, 'Total loss': 0.3982335428396861} | train loss {'Reaction outcome loss': 0.17745743013483328, 'Total loss': 0.17745743013483328}
2023-01-04 00:20:52,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:52,712 INFO:     Epoch: 78
2023-01-04 00:20:54,321 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39431617856025697, 'Total loss': 0.39431617856025697} | train loss {'Reaction outcome loss': 0.17564867806695675, 'Total loss': 0.17564867806695675}
2023-01-04 00:20:54,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:54,322 INFO:     Epoch: 79
2023-01-04 00:20:55,920 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4204171021779378, 'Total loss': 0.4204171021779378} | train loss {'Reaction outcome loss': 0.17465085823116075, 'Total loss': 0.17465085823116075}
2023-01-04 00:20:55,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:55,920 INFO:     Epoch: 80
2023-01-04 00:20:57,539 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3920161385089159, 'Total loss': 0.3920161385089159} | train loss {'Reaction outcome loss': 0.17212793223532666, 'Total loss': 0.17212793223532666}
2023-01-04 00:20:57,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:57,540 INFO:     Epoch: 81
2023-01-04 00:20:59,138 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39569715708494185, 'Total loss': 0.39569715708494185} | train loss {'Reaction outcome loss': 0.1746838320672077, 'Total loss': 0.1746838320672077}
2023-01-04 00:20:59,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:20:59,139 INFO:     Epoch: 82
2023-01-04 00:21:00,725 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42273806830247246, 'Total loss': 0.42273806830247246} | train loss {'Reaction outcome loss': 0.17484591069909997, 'Total loss': 0.17484591069909997}
2023-01-04 00:21:00,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:00,725 INFO:     Epoch: 83
2023-01-04 00:21:02,319 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41781978607177733, 'Total loss': 0.41781978607177733} | train loss {'Reaction outcome loss': 0.17440801705267742, 'Total loss': 0.17440801705267742}
2023-01-04 00:21:02,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:02,319 INFO:     Epoch: 84
2023-01-04 00:21:03,886 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42185092667738594, 'Total loss': 0.42185092667738594} | train loss {'Reaction outcome loss': 0.17117052180624573, 'Total loss': 0.17117052180624573}
2023-01-04 00:21:03,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:03,886 INFO:     Epoch: 85
2023-01-04 00:21:05,490 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43601350088914237, 'Total loss': 0.43601350088914237} | train loss {'Reaction outcome loss': 0.1693968243393911, 'Total loss': 0.1693968243393911}
2023-01-04 00:21:05,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:05,491 INFO:     Epoch: 86
2023-01-04 00:21:07,097 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41344504555066425, 'Total loss': 0.41344504555066425} | train loss {'Reaction outcome loss': 0.17122859479927452, 'Total loss': 0.17122859479927452}
2023-01-04 00:21:07,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:07,098 INFO:     Epoch: 87
2023-01-04 00:21:08,676 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4534981777270635, 'Total loss': 0.4534981777270635} | train loss {'Reaction outcome loss': 0.17103433428182654, 'Total loss': 0.17103433428182654}
2023-01-04 00:21:08,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:08,677 INFO:     Epoch: 88
2023-01-04 00:21:10,291 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4459431042273839, 'Total loss': 0.4459431042273839} | train loss {'Reaction outcome loss': 0.16744868659897008, 'Total loss': 0.16744868659897008}
2023-01-04 00:21:10,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:10,291 INFO:     Epoch: 89
2023-01-04 00:21:11,909 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4133446524540583, 'Total loss': 0.4133446524540583} | train loss {'Reaction outcome loss': 0.16895305885369108, 'Total loss': 0.16895305885369108}
2023-01-04 00:21:11,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:11,909 INFO:     Epoch: 90
2023-01-04 00:21:13,461 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4224426438411077, 'Total loss': 0.4224426438411077} | train loss {'Reaction outcome loss': 0.16889142143764418, 'Total loss': 0.16889142143764418}
2023-01-04 00:21:13,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:13,461 INFO:     Epoch: 91
2023-01-04 00:21:15,061 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4324453383684158, 'Total loss': 0.4324453383684158} | train loss {'Reaction outcome loss': 0.16650331345978228, 'Total loss': 0.16650331345978228}
2023-01-04 00:21:15,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:15,061 INFO:     Epoch: 92
2023-01-04 00:21:16,679 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4414048487941424, 'Total loss': 0.4414048487941424} | train loss {'Reaction outcome loss': 0.16638808811668063, 'Total loss': 0.16638808811668063}
2023-01-04 00:21:16,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:16,679 INFO:     Epoch: 93
2023-01-04 00:21:18,271 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40412369097272555, 'Total loss': 0.40412369097272555} | train loss {'Reaction outcome loss': 0.1675290641422472, 'Total loss': 0.1675290641422472}
2023-01-04 00:21:18,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:18,272 INFO:     Epoch: 94
2023-01-04 00:21:19,889 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43802714347839355, 'Total loss': 0.43802714347839355} | train loss {'Reaction outcome loss': 0.16647049823408797, 'Total loss': 0.16647049823408797}
2023-01-04 00:21:19,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:19,889 INFO:     Epoch: 95
2023-01-04 00:21:21,492 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3961767221490542, 'Total loss': 0.3961767221490542} | train loss {'Reaction outcome loss': 0.16572659633999323, 'Total loss': 0.16572659633999323}
2023-01-04 00:21:21,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:21,492 INFO:     Epoch: 96
2023-01-04 00:21:23,112 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40904689729213717, 'Total loss': 0.40904689729213717} | train loss {'Reaction outcome loss': 0.16653087036344258, 'Total loss': 0.16653087036344258}
2023-01-04 00:21:23,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:23,112 INFO:     Epoch: 97
2023-01-04 00:21:24,717 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44128768642743427, 'Total loss': 0.44128768642743427} | train loss {'Reaction outcome loss': 0.16513893637044805, 'Total loss': 0.16513893637044805}
2023-01-04 00:21:24,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:24,717 INFO:     Epoch: 98
2023-01-04 00:21:26,331 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41202440013488134, 'Total loss': 0.41202440013488134} | train loss {'Reaction outcome loss': 0.1622328637847609, 'Total loss': 0.1622328637847609}
2023-01-04 00:21:26,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:26,331 INFO:     Epoch: 99
2023-01-04 00:21:27,918 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4547229717175166, 'Total loss': 0.4547229717175166} | train loss {'Reaction outcome loss': 0.1624269149381749, 'Total loss': 0.1624269149381749}
2023-01-04 00:21:27,918 INFO:     Best model found after epoch 35 of 100.
2023-01-04 00:21:27,918 INFO:   Done with stage: TRAINING
2023-01-04 00:21:27,918 INFO:   Starting stage: EVALUATION
2023-01-04 00:21:28,053 INFO:   Done with stage: EVALUATION
2023-01-04 00:21:28,053 INFO:   Leaving out SEQ value Fold_2
2023-01-04 00:21:28,065 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 00:21:28,066 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:21:28,712 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:21:28,712 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:21:28,781 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:21:28,781 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:21:28,781 INFO:     No hyperparam tuning for this model
2023-01-04 00:21:28,781 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:21:28,781 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:21:28,782 INFO:     None feature selector for col prot
2023-01-04 00:21:28,782 INFO:     None feature selector for col prot
2023-01-04 00:21:28,782 INFO:     None feature selector for col prot
2023-01-04 00:21:28,783 INFO:     None feature selector for col chem
2023-01-04 00:21:28,783 INFO:     None feature selector for col chem
2023-01-04 00:21:28,783 INFO:     None feature selector for col chem
2023-01-04 00:21:28,783 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:21:28,783 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:21:28,784 INFO:     Number of params in model 70141
2023-01-04 00:21:28,788 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:21:28,788 INFO:   Starting stage: TRAINING
2023-01-04 00:21:28,832 INFO:     Val loss before train {'Reaction outcome loss': 0.9742387612660726, 'Total loss': 0.9742387612660726}
2023-01-04 00:21:28,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:28,832 INFO:     Epoch: 0
2023-01-04 00:21:30,420 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6659665524959564, 'Total loss': 0.6659665524959564} | train loss {'Reaction outcome loss': 0.8514098587405422, 'Total loss': 0.8514098587405422}
2023-01-04 00:21:30,421 INFO:     Found new best model at epoch 0
2023-01-04 00:21:30,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:30,422 INFO:     Epoch: 1
2023-01-04 00:21:32,024 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5590684076150259, 'Total loss': 0.5590684076150259} | train loss {'Reaction outcome loss': 0.6171216670244695, 'Total loss': 0.6171216670244695}
2023-01-04 00:21:32,024 INFO:     Found new best model at epoch 1
2023-01-04 00:21:32,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:32,025 INFO:     Epoch: 2
2023-01-04 00:21:33,629 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5519049366315206, 'Total loss': 0.5519049366315206} | train loss {'Reaction outcome loss': 0.5578143045414186, 'Total loss': 0.5578143045414186}
2023-01-04 00:21:33,629 INFO:     Found new best model at epoch 2
2023-01-04 00:21:33,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:33,630 INFO:     Epoch: 3
2023-01-04 00:21:35,208 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5299081722895305, 'Total loss': 0.5299081722895305} | train loss {'Reaction outcome loss': 0.5044023002073105, 'Total loss': 0.5044023002073105}
2023-01-04 00:21:35,208 INFO:     Found new best model at epoch 3
2023-01-04 00:21:35,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:35,209 INFO:     Epoch: 4
2023-01-04 00:21:36,825 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4993088781833649, 'Total loss': 0.4993088781833649} | train loss {'Reaction outcome loss': 0.4737600451875208, 'Total loss': 0.4737600451875208}
2023-01-04 00:21:36,826 INFO:     Found new best model at epoch 4
2023-01-04 00:21:36,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:36,827 INFO:     Epoch: 5
2023-01-04 00:21:38,488 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.500623173515002, 'Total loss': 0.500623173515002} | train loss {'Reaction outcome loss': 0.45419210665251897, 'Total loss': 0.45419210665251897}
2023-01-04 00:21:38,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:38,488 INFO:     Epoch: 6
2023-01-04 00:21:40,113 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48750625948111215, 'Total loss': 0.48750625948111215} | train loss {'Reaction outcome loss': 0.43668578957221, 'Total loss': 0.43668578957221}
2023-01-04 00:21:40,113 INFO:     Found new best model at epoch 6
2023-01-04 00:21:40,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:40,114 INFO:     Epoch: 7
2023-01-04 00:21:41,737 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48872730930646263, 'Total loss': 0.48872730930646263} | train loss {'Reaction outcome loss': 0.42307562937460624, 'Total loss': 0.42307562937460624}
2023-01-04 00:21:41,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:41,738 INFO:     Epoch: 8
2023-01-04 00:21:43,369 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47262855569521584, 'Total loss': 0.47262855569521584} | train loss {'Reaction outcome loss': 0.4128177203103036, 'Total loss': 0.4128177203103036}
2023-01-04 00:21:43,369 INFO:     Found new best model at epoch 8
2023-01-04 00:21:43,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:43,370 INFO:     Epoch: 9
2023-01-04 00:21:44,973 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48604238430658975, 'Total loss': 0.48604238430658975} | train loss {'Reaction outcome loss': 0.40510690212249756, 'Total loss': 0.40510690212249756}
2023-01-04 00:21:44,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:44,973 INFO:     Epoch: 10
2023-01-04 00:21:46,604 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4840536971886953, 'Total loss': 0.4840536971886953} | train loss {'Reaction outcome loss': 0.39518837568027887, 'Total loss': 0.39518837568027887}
2023-01-04 00:21:46,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:46,604 INFO:     Epoch: 11
2023-01-04 00:21:48,196 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4660167296727498, 'Total loss': 0.4660167296727498} | train loss {'Reaction outcome loss': 0.3822607920754809, 'Total loss': 0.3822607920754809}
2023-01-04 00:21:48,196 INFO:     Found new best model at epoch 11
2023-01-04 00:21:48,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:48,197 INFO:     Epoch: 12
2023-01-04 00:21:49,784 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4839879671732585, 'Total loss': 0.4839879671732585} | train loss {'Reaction outcome loss': 0.3804853473236595, 'Total loss': 0.3804853473236595}
2023-01-04 00:21:49,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:49,786 INFO:     Epoch: 13
2023-01-04 00:21:51,409 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4603836437066396, 'Total loss': 0.4603836437066396} | train loss {'Reaction outcome loss': 0.37142611662114877, 'Total loss': 0.37142611662114877}
2023-01-04 00:21:51,409 INFO:     Found new best model at epoch 13
2023-01-04 00:21:51,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:51,410 INFO:     Epoch: 14
2023-01-04 00:21:53,043 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4526046395301819, 'Total loss': 0.4526046395301819} | train loss {'Reaction outcome loss': 0.36423031165116077, 'Total loss': 0.36423031165116077}
2023-01-04 00:21:53,043 INFO:     Found new best model at epoch 14
2023-01-04 00:21:53,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:53,044 INFO:     Epoch: 15
2023-01-04 00:21:54,649 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45543944935003916, 'Total loss': 0.45543944935003916} | train loss {'Reaction outcome loss': 0.3547889628134199, 'Total loss': 0.3547889628134199}
2023-01-04 00:21:54,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:54,650 INFO:     Epoch: 16
2023-01-04 00:21:56,271 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4838841199874878, 'Total loss': 0.4838841199874878} | train loss {'Reaction outcome loss': 0.34948978136779496, 'Total loss': 0.34948978136779496}
2023-01-04 00:21:56,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:56,272 INFO:     Epoch: 17
2023-01-04 00:21:57,870 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4727145473162333, 'Total loss': 0.4727145473162333} | train loss {'Reaction outcome loss': 0.3422129666599611, 'Total loss': 0.3422129666599611}
2023-01-04 00:21:57,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:57,870 INFO:     Epoch: 18
2023-01-04 00:21:59,482 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4697282632191976, 'Total loss': 0.4697282632191976} | train loss {'Reaction outcome loss': 0.33526049867488333, 'Total loss': 0.33526049867488333}
2023-01-04 00:21:59,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:21:59,483 INFO:     Epoch: 19
2023-01-04 00:22:01,094 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45819102923075355, 'Total loss': 0.45819102923075355} | train loss {'Reaction outcome loss': 0.334373721866396, 'Total loss': 0.334373721866396}
2023-01-04 00:22:01,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:01,094 INFO:     Epoch: 20
2023-01-04 00:22:02,670 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4616860826810201, 'Total loss': 0.4616860826810201} | train loss {'Reaction outcome loss': 0.32696322847049736, 'Total loss': 0.32696322847049736}
2023-01-04 00:22:02,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:02,670 INFO:     Epoch: 21
2023-01-04 00:22:04,293 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4777038703362147, 'Total loss': 0.4777038703362147} | train loss {'Reaction outcome loss': 0.3235168855640897, 'Total loss': 0.3235168855640897}
2023-01-04 00:22:04,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:04,293 INFO:     Epoch: 22
2023-01-04 00:22:05,943 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47074552774429324, 'Total loss': 0.47074552774429324} | train loss {'Reaction outcome loss': 0.32550851360935235, 'Total loss': 0.32550851360935235}
2023-01-04 00:22:05,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:05,945 INFO:     Epoch: 23
2023-01-04 00:22:07,573 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.468395984172821, 'Total loss': 0.468395984172821} | train loss {'Reaction outcome loss': 0.3220587567142818, 'Total loss': 0.3220587567142818}
2023-01-04 00:22:07,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:07,574 INFO:     Epoch: 24
2023-01-04 00:22:09,223 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4754849443833033, 'Total loss': 0.4754849443833033} | train loss {'Reaction outcome loss': 0.30970637053479033, 'Total loss': 0.30970637053479033}
2023-01-04 00:22:09,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:09,223 INFO:     Epoch: 25
2023-01-04 00:22:10,873 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4648232897122701, 'Total loss': 0.4648232897122701} | train loss {'Reaction outcome loss': 0.30424440895085747, 'Total loss': 0.30424440895085747}
2023-01-04 00:22:10,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:10,873 INFO:     Epoch: 26
2023-01-04 00:22:12,471 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4743316908677419, 'Total loss': 0.4743316908677419} | train loss {'Reaction outcome loss': 0.3009732358732963, 'Total loss': 0.3009732358732963}
2023-01-04 00:22:12,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:12,472 INFO:     Epoch: 27
2023-01-04 00:22:14,046 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5029613296190898, 'Total loss': 0.5029613296190898} | train loss {'Reaction outcome loss': 0.2951855537974262, 'Total loss': 0.2951855537974262}
2023-01-04 00:22:14,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:14,046 INFO:     Epoch: 28
2023-01-04 00:22:15,682 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46817624270915986, 'Total loss': 0.46817624270915986} | train loss {'Reaction outcome loss': 0.29511753188959067, 'Total loss': 0.29511753188959067}
2023-01-04 00:22:15,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:15,682 INFO:     Epoch: 29
2023-01-04 00:22:17,257 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47452769776185355, 'Total loss': 0.47452769776185355} | train loss {'Reaction outcome loss': 0.29298217871995724, 'Total loss': 0.29298217871995724}
2023-01-04 00:22:17,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:17,257 INFO:     Epoch: 30
2023-01-04 00:22:18,864 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4584282865126928, 'Total loss': 0.4584282865126928} | train loss {'Reaction outcome loss': 0.28586063608932105, 'Total loss': 0.28586063608932105}
2023-01-04 00:22:18,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:18,865 INFO:     Epoch: 31
2023-01-04 00:22:20,476 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4451913207769394, 'Total loss': 0.4451913207769394} | train loss {'Reaction outcome loss': 0.2815826473541666, 'Total loss': 0.2815826473541666}
2023-01-04 00:22:20,477 INFO:     Found new best model at epoch 31
2023-01-04 00:22:20,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:20,477 INFO:     Epoch: 32
2023-01-04 00:22:22,057 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47860092322031655, 'Total loss': 0.47860092322031655} | train loss {'Reaction outcome loss': 0.28415337445187394, 'Total loss': 0.28415337445187394}
2023-01-04 00:22:22,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:22,058 INFO:     Epoch: 33
2023-01-04 00:22:23,644 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4597261865933736, 'Total loss': 0.4597261865933736} | train loss {'Reaction outcome loss': 0.2874545192318982, 'Total loss': 0.2874545192318982}
2023-01-04 00:22:23,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:23,644 INFO:     Epoch: 34
2023-01-04 00:22:25,213 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4582209885120392, 'Total loss': 0.4582209885120392} | train loss {'Reaction outcome loss': 0.2842893389503276, 'Total loss': 0.2842893389503276}
2023-01-04 00:22:25,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:25,214 INFO:     Epoch: 35
2023-01-04 00:22:26,816 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4591638743877411, 'Total loss': 0.4591638743877411} | train loss {'Reaction outcome loss': 0.2716358949032113, 'Total loss': 0.2716358949032113}
2023-01-04 00:22:26,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:26,816 INFO:     Epoch: 36
2023-01-04 00:22:28,393 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4767344613869985, 'Total loss': 0.4767344613869985} | train loss {'Reaction outcome loss': 0.266746797490919, 'Total loss': 0.266746797490919}
2023-01-04 00:22:28,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:28,394 INFO:     Epoch: 37
2023-01-04 00:22:29,983 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47330518762270607, 'Total loss': 0.47330518762270607} | train loss {'Reaction outcome loss': 0.2653452626031324, 'Total loss': 0.2653452626031324}
2023-01-04 00:22:29,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:29,983 INFO:     Epoch: 38
2023-01-04 00:22:31,570 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4544619798660278, 'Total loss': 0.4544619798660278} | train loss {'Reaction outcome loss': 0.26124740063307295, 'Total loss': 0.26124740063307295}
2023-01-04 00:22:31,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:31,570 INFO:     Epoch: 39
2023-01-04 00:22:33,149 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46817106008529663, 'Total loss': 0.46817106008529663} | train loss {'Reaction outcome loss': 0.25683125518802286, 'Total loss': 0.25683125518802286}
2023-01-04 00:22:33,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:33,150 INFO:     Epoch: 40
2023-01-04 00:22:34,728 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.49681439201037086, 'Total loss': 0.49681439201037086} | train loss {'Reaction outcome loss': 0.25646626860986504, 'Total loss': 0.25646626860986504}
2023-01-04 00:22:34,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:34,728 INFO:     Epoch: 41
2023-01-04 00:22:36,349 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49492368698120115, 'Total loss': 0.49492368698120115} | train loss {'Reaction outcome loss': 0.2586315264115515, 'Total loss': 0.2586315264115515}
2023-01-04 00:22:36,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:36,350 INFO:     Epoch: 42
2023-01-04 00:22:37,938 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4415335794289907, 'Total loss': 0.4415335794289907} | train loss {'Reaction outcome loss': 0.2592137740617888, 'Total loss': 0.2592137740617888}
2023-01-04 00:22:37,938 INFO:     Found new best model at epoch 42
2023-01-04 00:22:37,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:37,939 INFO:     Epoch: 43
2023-01-04 00:22:39,519 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47411237359046937, 'Total loss': 0.47411237359046937} | train loss {'Reaction outcome loss': 0.24889127742094191, 'Total loss': 0.24889127742094191}
2023-01-04 00:22:39,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:39,519 INFO:     Epoch: 44
2023-01-04 00:22:41,140 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.478960257768631, 'Total loss': 0.478960257768631} | train loss {'Reaction outcome loss': 0.2461650002936738, 'Total loss': 0.2461650002936738}
2023-01-04 00:22:41,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:41,141 INFO:     Epoch: 45
2023-01-04 00:22:42,727 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.466451159119606, 'Total loss': 0.466451159119606} | train loss {'Reaction outcome loss': 0.2450806192928871, 'Total loss': 0.2450806192928871}
2023-01-04 00:22:42,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:42,728 INFO:     Epoch: 46
2023-01-04 00:22:44,301 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4721519152323405, 'Total loss': 0.4721519152323405} | train loss {'Reaction outcome loss': 0.2405498544692924, 'Total loss': 0.2405498544692924}
2023-01-04 00:22:44,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:44,302 INFO:     Epoch: 47
2023-01-04 00:22:45,879 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4558123489220937, 'Total loss': 0.4558123489220937} | train loss {'Reaction outcome loss': 0.24142646217597244, 'Total loss': 0.24142646217597244}
2023-01-04 00:22:45,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:45,879 INFO:     Epoch: 48
2023-01-04 00:22:47,476 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4938881814479828, 'Total loss': 0.4938881814479828} | train loss {'Reaction outcome loss': 0.25814318744654674, 'Total loss': 0.25814318744654674}
2023-01-04 00:22:47,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:47,476 INFO:     Epoch: 49
2023-01-04 00:22:49,054 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4853443334499995, 'Total loss': 0.4853443334499995} | train loss {'Reaction outcome loss': 0.25002384110205417, 'Total loss': 0.25002384110205417}
2023-01-04 00:22:49,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:49,054 INFO:     Epoch: 50
2023-01-04 00:22:50,670 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.471780185898145, 'Total loss': 0.471780185898145} | train loss {'Reaction outcome loss': 0.23761916342123912, 'Total loss': 0.23761916342123912}
2023-01-04 00:22:50,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:50,670 INFO:     Epoch: 51
2023-01-04 00:22:52,254 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4709902743498484, 'Total loss': 0.4709902743498484} | train loss {'Reaction outcome loss': 0.23544732524432999, 'Total loss': 0.23544732524432999}
2023-01-04 00:22:52,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:52,254 INFO:     Epoch: 52
2023-01-04 00:22:53,877 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47287657459576926, 'Total loss': 0.47287657459576926} | train loss {'Reaction outcome loss': 0.23975419813929044, 'Total loss': 0.23975419813929044}
2023-01-04 00:22:53,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:53,877 INFO:     Epoch: 53
2023-01-04 00:22:55,483 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4863343258698781, 'Total loss': 0.4863343258698781} | train loss {'Reaction outcome loss': 0.2309391058549501, 'Total loss': 0.2309391058549501}
2023-01-04 00:22:55,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:55,484 INFO:     Epoch: 54
2023-01-04 00:22:57,077 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4739666720231374, 'Total loss': 0.4739666720231374} | train loss {'Reaction outcome loss': 0.2340070869038333, 'Total loss': 0.2340070869038333}
2023-01-04 00:22:57,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:57,078 INFO:     Epoch: 55
2023-01-04 00:22:58,701 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5042181293169657, 'Total loss': 0.5042181293169657} | train loss {'Reaction outcome loss': 0.2260052238766482, 'Total loss': 0.2260052238766482}
2023-01-04 00:22:58,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:22:58,701 INFO:     Epoch: 56
2023-01-04 00:23:00,281 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.49167246619860333, 'Total loss': 0.49167246619860333} | train loss {'Reaction outcome loss': 0.22769231501244602, 'Total loss': 0.22769231501244602}
2023-01-04 00:23:00,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:00,281 INFO:     Epoch: 57
2023-01-04 00:23:01,913 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4832561850547791, 'Total loss': 0.4832561850547791} | train loss {'Reaction outcome loss': 0.24195035586160593, 'Total loss': 0.24195035586160593}
2023-01-04 00:23:01,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:01,913 INFO:     Epoch: 58
2023-01-04 00:23:03,518 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47452767690022785, 'Total loss': 0.47452767690022785} | train loss {'Reaction outcome loss': 0.22522206255934035, 'Total loss': 0.22522206255934035}
2023-01-04 00:23:03,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:03,518 INFO:     Epoch: 59
2023-01-04 00:23:05,092 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47169380163153013, 'Total loss': 0.47169380163153013} | train loss {'Reaction outcome loss': 0.220402748985351, 'Total loss': 0.220402748985351}
2023-01-04 00:23:05,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:05,092 INFO:     Epoch: 60
2023-01-04 00:23:06,682 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4975719024737676, 'Total loss': 0.4975719024737676} | train loss {'Reaction outcome loss': 0.23420615850583368, 'Total loss': 0.23420615850583368}
2023-01-04 00:23:06,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:06,682 INFO:     Epoch: 61
2023-01-04 00:23:08,274 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49109853704770406, 'Total loss': 0.49109853704770406} | train loss {'Reaction outcome loss': 0.22905258722333371, 'Total loss': 0.22905258722333371}
2023-01-04 00:23:08,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:08,276 INFO:     Epoch: 62
2023-01-04 00:23:09,869 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.49001888235410057, 'Total loss': 0.49001888235410057} | train loss {'Reaction outcome loss': 0.2207171368966068, 'Total loss': 0.2207171368966068}
2023-01-04 00:23:09,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:09,869 INFO:     Epoch: 63
2023-01-04 00:23:11,484 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4764705240726471, 'Total loss': 0.4764705240726471} | train loss {'Reaction outcome loss': 0.21812472344817765, 'Total loss': 0.21812472344817765}
2023-01-04 00:23:11,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:11,485 INFO:     Epoch: 64
2023-01-04 00:23:13,067 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49288695454597475, 'Total loss': 0.49288695454597475} | train loss {'Reaction outcome loss': 0.2136122229360584, 'Total loss': 0.2136122229360584}
2023-01-04 00:23:13,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:13,068 INFO:     Epoch: 65
2023-01-04 00:23:14,654 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4967095593611399, 'Total loss': 0.4967095593611399} | train loss {'Reaction outcome loss': 0.2179215488874394, 'Total loss': 0.2179215488874394}
2023-01-04 00:23:14,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:14,655 INFO:     Epoch: 66
2023-01-04 00:23:16,263 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47425441940625507, 'Total loss': 0.47425441940625507} | train loss {'Reaction outcome loss': 0.2380317998915047, 'Total loss': 0.2380317998915047}
2023-01-04 00:23:16,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:16,263 INFO:     Epoch: 67
2023-01-04 00:23:17,878 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4878425012032191, 'Total loss': 0.4878425012032191} | train loss {'Reaction outcome loss': 0.21226113014415823, 'Total loss': 0.21226113014415823}
2023-01-04 00:23:17,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:17,878 INFO:     Epoch: 68
2023-01-04 00:23:19,479 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48196163574854534, 'Total loss': 0.48196163574854534} | train loss {'Reaction outcome loss': 0.21239918816423017, 'Total loss': 0.21239918816423017}
2023-01-04 00:23:19,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:19,479 INFO:     Epoch: 69
2023-01-04 00:23:21,094 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4912244896094004, 'Total loss': 0.4912244896094004} | train loss {'Reaction outcome loss': 0.20803562357036423, 'Total loss': 0.20803562357036423}
2023-01-04 00:23:21,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:21,095 INFO:     Epoch: 70
2023-01-04 00:23:22,714 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.49238323271274564, 'Total loss': 0.49238323271274564} | train loss {'Reaction outcome loss': 0.2076114156128218, 'Total loss': 0.2076114156128218}
2023-01-04 00:23:22,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:22,714 INFO:     Epoch: 71
2023-01-04 00:23:24,318 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47776437203089395, 'Total loss': 0.47776437203089395} | train loss {'Reaction outcome loss': 0.206416420618526, 'Total loss': 0.206416420618526}
2023-01-04 00:23:24,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:24,318 INFO:     Epoch: 72
2023-01-04 00:23:25,939 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.481859756509463, 'Total loss': 0.481859756509463} | train loss {'Reaction outcome loss': 0.2033957783114338, 'Total loss': 0.2033957783114338}
2023-01-04 00:23:25,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:25,939 INFO:     Epoch: 73
2023-01-04 00:23:27,536 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4951862951119741, 'Total loss': 0.4951862951119741} | train loss {'Reaction outcome loss': 0.20250710944030975, 'Total loss': 0.20250710944030975}
2023-01-04 00:23:27,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:27,537 INFO:     Epoch: 74
2023-01-04 00:23:29,129 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48228777150313057, 'Total loss': 0.48228777150313057} | train loss {'Reaction outcome loss': 0.20060577426438217, 'Total loss': 0.20060577426438217}
2023-01-04 00:23:29,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:29,129 INFO:     Epoch: 75
2023-01-04 00:23:30,723 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4991024449467659, 'Total loss': 0.4991024449467659} | train loss {'Reaction outcome loss': 0.20000466963434863, 'Total loss': 0.20000466963434863}
2023-01-04 00:23:30,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:30,724 INFO:     Epoch: 76
2023-01-04 00:23:32,299 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5033044427633285, 'Total loss': 0.5033044427633285} | train loss {'Reaction outcome loss': 0.2053873234603932, 'Total loss': 0.2053873234603932}
2023-01-04 00:23:32,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:32,299 INFO:     Epoch: 77
2023-01-04 00:23:33,907 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49237497796614965, 'Total loss': 0.49237497796614965} | train loss {'Reaction outcome loss': 0.2113965375456905, 'Total loss': 0.2113965375456905}
2023-01-04 00:23:33,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:33,907 INFO:     Epoch: 78
2023-01-04 00:23:35,526 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4899024724960327, 'Total loss': 0.4899024724960327} | train loss {'Reaction outcome loss': 0.202974251397224, 'Total loss': 0.202974251397224}
2023-01-04 00:23:35,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:35,526 INFO:     Epoch: 79
2023-01-04 00:23:37,101 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48333370784918467, 'Total loss': 0.48333370784918467} | train loss {'Reaction outcome loss': 0.19491727951158216, 'Total loss': 0.19491727951158216}
2023-01-04 00:23:37,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:37,101 INFO:     Epoch: 80
2023-01-04 00:23:38,716 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5116513927777608, 'Total loss': 0.5116513927777608} | train loss {'Reaction outcome loss': 0.1946319609815491, 'Total loss': 0.1946319609815491}
2023-01-04 00:23:38,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:38,716 INFO:     Epoch: 81
2023-01-04 00:23:40,331 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5145978430906931, 'Total loss': 0.5145978430906931} | train loss {'Reaction outcome loss': 0.19282198397685651, 'Total loss': 0.19282198397685651}
2023-01-04 00:23:40,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:40,331 INFO:     Epoch: 82
2023-01-04 00:23:41,912 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4889114320278168, 'Total loss': 0.4889114320278168} | train loss {'Reaction outcome loss': 0.19414023937913927, 'Total loss': 0.19414023937913927}
2023-01-04 00:23:41,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:41,912 INFO:     Epoch: 83
2023-01-04 00:23:43,520 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4962101638317108, 'Total loss': 0.4962101638317108} | train loss {'Reaction outcome loss': 0.19002107303611515, 'Total loss': 0.19002107303611515}
2023-01-04 00:23:43,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:43,521 INFO:     Epoch: 84
2023-01-04 00:23:45,110 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49739961624145507, 'Total loss': 0.49739961624145507} | train loss {'Reaction outcome loss': 0.1909252656623721, 'Total loss': 0.1909252656623721}
2023-01-04 00:23:45,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:45,111 INFO:     Epoch: 85
2023-01-04 00:23:46,728 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5048709173997243, 'Total loss': 0.5048709173997243} | train loss {'Reaction outcome loss': 0.1894226494393703, 'Total loss': 0.1894226494393703}
2023-01-04 00:23:46,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:46,728 INFO:     Epoch: 86
2023-01-04 00:23:48,353 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49295851588249207, 'Total loss': 0.49295851588249207} | train loss {'Reaction outcome loss': 0.19407944310691877, 'Total loss': 0.19407944310691877}
2023-01-04 00:23:48,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:48,353 INFO:     Epoch: 87
2023-01-04 00:23:49,974 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5155245204766591, 'Total loss': 0.5155245204766591} | train loss {'Reaction outcome loss': 0.19057729126686446, 'Total loss': 0.19057729126686446}
2023-01-04 00:23:49,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:49,975 INFO:     Epoch: 88
2023-01-04 00:23:51,549 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49571385284264885, 'Total loss': 0.49571385284264885} | train loss {'Reaction outcome loss': 0.18953475812315076, 'Total loss': 0.18953475812315076}
2023-01-04 00:23:51,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:51,549 INFO:     Epoch: 89
2023-01-04 00:23:53,160 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5177098135153453, 'Total loss': 0.5177098135153453} | train loss {'Reaction outcome loss': 0.18494489243712978, 'Total loss': 0.18494489243712978}
2023-01-04 00:23:53,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:53,160 INFO:     Epoch: 90
2023-01-04 00:23:54,765 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5217222770055135, 'Total loss': 0.5217222770055135} | train loss {'Reaction outcome loss': 0.18909855569986772, 'Total loss': 0.18909855569986772}
2023-01-04 00:23:54,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:54,765 INFO:     Epoch: 91
2023-01-04 00:23:56,385 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.531828926006953, 'Total loss': 0.531828926006953} | train loss {'Reaction outcome loss': 0.18523286917606246, 'Total loss': 0.18523286917606246}
2023-01-04 00:23:56,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:56,385 INFO:     Epoch: 92
2023-01-04 00:23:58,010 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5024492671092351, 'Total loss': 0.5024492671092351} | train loss {'Reaction outcome loss': 0.18243030095990156, 'Total loss': 0.18243030095990156}
2023-01-04 00:23:58,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:58,010 INFO:     Epoch: 93
2023-01-04 00:23:59,615 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.522756157318751, 'Total loss': 0.522756157318751} | train loss {'Reaction outcome loss': 0.18193832712679886, 'Total loss': 0.18193832712679886}
2023-01-04 00:23:59,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:23:59,615 INFO:     Epoch: 94
2023-01-04 00:24:01,233 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5032942205667496, 'Total loss': 0.5032942205667496} | train loss {'Reaction outcome loss': 0.18385995518200207, 'Total loss': 0.18385995518200207}
2023-01-04 00:24:01,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:01,233 INFO:     Epoch: 95
2023-01-04 00:24:02,833 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5175245881080628, 'Total loss': 0.5175245881080628} | train loss {'Reaction outcome loss': 0.18430851379652385, 'Total loss': 0.18430851379652385}
2023-01-04 00:24:02,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:02,834 INFO:     Epoch: 96
2023-01-04 00:24:04,412 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5354798376560211, 'Total loss': 0.5354798376560211} | train loss {'Reaction outcome loss': 0.19361476684529064, 'Total loss': 0.19361476684529064}
2023-01-04 00:24:04,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:04,412 INFO:     Epoch: 97
2023-01-04 00:24:06,006 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5218653698762258, 'Total loss': 0.5218653698762258} | train loss {'Reaction outcome loss': 0.2018174917757542, 'Total loss': 0.2018174917757542}
2023-01-04 00:24:06,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:06,007 INFO:     Epoch: 98
2023-01-04 00:24:07,600 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5247810542583465, 'Total loss': 0.5247810542583465} | train loss {'Reaction outcome loss': 0.17955738064947713, 'Total loss': 0.17955738064947713}
2023-01-04 00:24:07,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:07,600 INFO:     Epoch: 99
2023-01-04 00:24:09,192 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5153206050395965, 'Total loss': 0.5153206050395965} | train loss {'Reaction outcome loss': 0.17894050503230613, 'Total loss': 0.17894050503230613}
2023-01-04 00:24:09,192 INFO:     Best model found after epoch 43 of 100.
2023-01-04 00:24:09,192 INFO:   Done with stage: TRAINING
2023-01-04 00:24:09,192 INFO:   Starting stage: EVALUATION
2023-01-04 00:24:09,322 INFO:   Done with stage: EVALUATION
2023-01-04 00:24:09,322 INFO:   Leaving out SEQ value Fold_3
2023-01-04 00:24:09,334 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 00:24:09,335 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:24:09,972 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:24:09,972 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:24:10,041 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:24:10,041 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:24:10,041 INFO:     No hyperparam tuning for this model
2023-01-04 00:24:10,041 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:24:10,041 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:24:10,042 INFO:     None feature selector for col prot
2023-01-04 00:24:10,042 INFO:     None feature selector for col prot
2023-01-04 00:24:10,042 INFO:     None feature selector for col prot
2023-01-04 00:24:10,043 INFO:     None feature selector for col chem
2023-01-04 00:24:10,043 INFO:     None feature selector for col chem
2023-01-04 00:24:10,043 INFO:     None feature selector for col chem
2023-01-04 00:24:10,043 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:24:10,043 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:24:10,044 INFO:     Number of params in model 70141
2023-01-04 00:24:10,047 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:24:10,048 INFO:   Starting stage: TRAINING
2023-01-04 00:24:10,091 INFO:     Val loss before train {'Reaction outcome loss': 1.0259313742319742, 'Total loss': 1.0259313742319742}
2023-01-04 00:24:10,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:10,091 INFO:     Epoch: 0
2023-01-04 00:24:11,672 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6948681692282359, 'Total loss': 0.6948681692282359} | train loss {'Reaction outcome loss': 0.8391950563901532, 'Total loss': 0.8391950563901532}
2023-01-04 00:24:11,672 INFO:     Found new best model at epoch 0
2023-01-04 00:24:11,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:11,673 INFO:     Epoch: 1
2023-01-04 00:24:13,260 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5999904076258341, 'Total loss': 0.5999904076258341} | train loss {'Reaction outcome loss': 0.6097780352961408, 'Total loss': 0.6097780352961408}
2023-01-04 00:24:13,260 INFO:     Found new best model at epoch 1
2023-01-04 00:24:13,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:13,261 INFO:     Epoch: 2
2023-01-04 00:24:14,846 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5622554103533427, 'Total loss': 0.5622554103533427} | train loss {'Reaction outcome loss': 0.5244715128936907, 'Total loss': 0.5244715128936907}
2023-01-04 00:24:14,846 INFO:     Found new best model at epoch 2
2023-01-04 00:24:14,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:14,847 INFO:     Epoch: 3
2023-01-04 00:24:16,429 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5366718451182048, 'Total loss': 0.5366718451182048} | train loss {'Reaction outcome loss': 0.48528237744186914, 'Total loss': 0.48528237744186914}
2023-01-04 00:24:16,429 INFO:     Found new best model at epoch 3
2023-01-04 00:24:16,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:16,430 INFO:     Epoch: 4
2023-01-04 00:24:18,023 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5225931545098622, 'Total loss': 0.5225931545098622} | train loss {'Reaction outcome loss': 0.45653904223964165, 'Total loss': 0.45653904223964165}
2023-01-04 00:24:18,023 INFO:     Found new best model at epoch 4
2023-01-04 00:24:18,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:18,024 INFO:     Epoch: 5
2023-01-04 00:24:19,647 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.521541706720988, 'Total loss': 0.521541706720988} | train loss {'Reaction outcome loss': 0.4388676996539979, 'Total loss': 0.4388676996539979}
2023-01-04 00:24:19,649 INFO:     Found new best model at epoch 5
2023-01-04 00:24:19,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:19,649 INFO:     Epoch: 6
2023-01-04 00:24:21,215 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5036954859892527, 'Total loss': 0.5036954859892527} | train loss {'Reaction outcome loss': 0.42112135849077337, 'Total loss': 0.42112135849077337}
2023-01-04 00:24:21,215 INFO:     Found new best model at epoch 6
2023-01-04 00:24:21,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:21,216 INFO:     Epoch: 7
2023-01-04 00:24:22,802 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5000079989433288, 'Total loss': 0.5000079989433288} | train loss {'Reaction outcome loss': 0.4073689535368968, 'Total loss': 0.4073689535368968}
2023-01-04 00:24:22,802 INFO:     Found new best model at epoch 7
2023-01-04 00:24:22,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:22,803 INFO:     Epoch: 8
2023-01-04 00:24:24,388 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45670880377292633, 'Total loss': 0.45670880377292633} | train loss {'Reaction outcome loss': 0.39700773048357374, 'Total loss': 0.39700773048357374}
2023-01-04 00:24:24,388 INFO:     Found new best model at epoch 8
2023-01-04 00:24:24,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:24,389 INFO:     Epoch: 9
2023-01-04 00:24:25,960 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4533376216888428, 'Total loss': 0.4533376216888428} | train loss {'Reaction outcome loss': 0.3841975451494655, 'Total loss': 0.3841975451494655}
2023-01-04 00:24:25,961 INFO:     Found new best model at epoch 9
2023-01-04 00:24:25,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:25,962 INFO:     Epoch: 10
2023-01-04 00:24:27,571 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44540297190348305, 'Total loss': 0.44540297190348305} | train loss {'Reaction outcome loss': 0.37306437570683276, 'Total loss': 0.37306437570683276}
2023-01-04 00:24:27,571 INFO:     Found new best model at epoch 10
2023-01-04 00:24:27,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:27,572 INFO:     Epoch: 11
2023-01-04 00:24:29,134 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47051536043485004, 'Total loss': 0.47051536043485004} | train loss {'Reaction outcome loss': 0.36211250738723433, 'Total loss': 0.36211250738723433}
2023-01-04 00:24:29,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:29,134 INFO:     Epoch: 12
2023-01-04 00:24:30,695 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46887513597806296, 'Total loss': 0.46887513597806296} | train loss {'Reaction outcome loss': 0.3551595327954223, 'Total loss': 0.3551595327954223}
2023-01-04 00:24:30,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:30,695 INFO:     Epoch: 13
2023-01-04 00:24:32,299 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4296744113167127, 'Total loss': 0.4296744113167127} | train loss {'Reaction outcome loss': 0.35156038115276905, 'Total loss': 0.35156038115276905}
2023-01-04 00:24:32,299 INFO:     Found new best model at epoch 13
2023-01-04 00:24:32,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:32,300 INFO:     Epoch: 14
2023-01-04 00:24:33,867 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4460998465617498, 'Total loss': 0.4460998465617498} | train loss {'Reaction outcome loss': 0.34007487875701736, 'Total loss': 0.34007487875701736}
2023-01-04 00:24:33,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:33,867 INFO:     Epoch: 15
2023-01-04 00:24:35,456 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43660403192043307, 'Total loss': 0.43660403192043307} | train loss {'Reaction outcome loss': 0.3338653311459687, 'Total loss': 0.3338653311459687}
2023-01-04 00:24:35,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:35,456 INFO:     Epoch: 16
2023-01-04 00:24:37,079 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4310296714305878, 'Total loss': 0.4310296714305878} | train loss {'Reaction outcome loss': 0.327389146615989, 'Total loss': 0.327389146615989}
2023-01-04 00:24:37,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:37,079 INFO:     Epoch: 17
2023-01-04 00:24:38,673 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43577842315038046, 'Total loss': 0.43577842315038046} | train loss {'Reaction outcome loss': 0.3198087629012383, 'Total loss': 0.3198087629012383}
2023-01-04 00:24:38,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:38,674 INFO:     Epoch: 18
2023-01-04 00:24:40,269 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4239213913679123, 'Total loss': 0.4239213913679123} | train loss {'Reaction outcome loss': 0.31261785241374135, 'Total loss': 0.31261785241374135}
2023-01-04 00:24:40,269 INFO:     Found new best model at epoch 18
2023-01-04 00:24:40,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:40,270 INFO:     Epoch: 19
2023-01-04 00:24:41,885 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40698991318543754, 'Total loss': 0.40698991318543754} | train loss {'Reaction outcome loss': 0.3109440756485845, 'Total loss': 0.3109440756485845}
2023-01-04 00:24:41,886 INFO:     Found new best model at epoch 19
2023-01-04 00:24:41,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:41,886 INFO:     Epoch: 20
2023-01-04 00:24:43,501 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4190046141544978, 'Total loss': 0.4190046141544978} | train loss {'Reaction outcome loss': 0.30486854921727286, 'Total loss': 0.30486854921727286}
2023-01-04 00:24:43,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:43,501 INFO:     Epoch: 21
2023-01-04 00:24:45,065 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4259758174419403, 'Total loss': 0.4259758174419403} | train loss {'Reaction outcome loss': 0.29663656015683265, 'Total loss': 0.29663656015683265}
2023-01-04 00:24:45,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:45,065 INFO:     Epoch: 22
2023-01-04 00:24:46,647 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43586771885553993, 'Total loss': 0.43586771885553993} | train loss {'Reaction outcome loss': 0.29400699566641864, 'Total loss': 0.29400699566641864}
2023-01-04 00:24:46,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:46,647 INFO:     Epoch: 23
2023-01-04 00:24:48,211 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4301286220550537, 'Total loss': 0.4301286220550537} | train loss {'Reaction outcome loss': 0.29102765564827154, 'Total loss': 0.29102765564827154}
2023-01-04 00:24:48,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:48,211 INFO:     Epoch: 24
2023-01-04 00:24:49,795 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39716202318668364, 'Total loss': 0.39716202318668364} | train loss {'Reaction outcome loss': 0.2851092693579458, 'Total loss': 0.2851092693579458}
2023-01-04 00:24:49,795 INFO:     Found new best model at epoch 24
2023-01-04 00:24:49,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:49,796 INFO:     Epoch: 25
2023-01-04 00:24:51,376 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4218457221984863, 'Total loss': 0.4218457221984863} | train loss {'Reaction outcome loss': 0.280237563987718, 'Total loss': 0.280237563987718}
2023-01-04 00:24:51,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:51,376 INFO:     Epoch: 26
2023-01-04 00:24:52,944 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40674777925014494, 'Total loss': 0.40674777925014494} | train loss {'Reaction outcome loss': 0.2788810167651977, 'Total loss': 0.2788810167651977}
2023-01-04 00:24:52,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:52,944 INFO:     Epoch: 27
2023-01-04 00:24:54,508 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41830610831578574, 'Total loss': 0.41830610831578574} | train loss {'Reaction outcome loss': 0.2751413676479872, 'Total loss': 0.2751413676479872}
2023-01-04 00:24:54,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:54,510 INFO:     Epoch: 28
2023-01-04 00:24:56,076 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4231351633866628, 'Total loss': 0.4231351633866628} | train loss {'Reaction outcome loss': 0.2699735547640245, 'Total loss': 0.2699735547640245}
2023-01-04 00:24:56,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:56,076 INFO:     Epoch: 29
2023-01-04 00:24:57,640 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40901728669802345, 'Total loss': 0.40901728669802345} | train loss {'Reaction outcome loss': 0.26746967970563545, 'Total loss': 0.26746967970563545}
2023-01-04 00:24:57,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:57,640 INFO:     Epoch: 30
2023-01-04 00:24:59,224 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41727790037790935, 'Total loss': 0.41727790037790935} | train loss {'Reaction outcome loss': 0.26207055866609524, 'Total loss': 0.26207055866609524}
2023-01-04 00:24:59,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:24:59,224 INFO:     Epoch: 31
2023-01-04 00:25:00,807 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41825199127197266, 'Total loss': 0.41825199127197266} | train loss {'Reaction outcome loss': 0.2605851050466299, 'Total loss': 0.2605851050466299}
2023-01-04 00:25:00,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:00,808 INFO:     Epoch: 32
2023-01-04 00:25:02,367 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4284318248430888, 'Total loss': 0.4284318248430888} | train loss {'Reaction outcome loss': 0.25803844399587084, 'Total loss': 0.25803844399587084}
2023-01-04 00:25:02,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:02,368 INFO:     Epoch: 33
2023-01-04 00:25:03,951 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4197768916686376, 'Total loss': 0.4197768916686376} | train loss {'Reaction outcome loss': 0.2556723359374017, 'Total loss': 0.2556723359374017}
2023-01-04 00:25:03,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:03,951 INFO:     Epoch: 34
2023-01-04 00:25:05,517 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4337522566318512, 'Total loss': 0.4337522566318512} | train loss {'Reaction outcome loss': 0.2492672264657534, 'Total loss': 0.2492672264657534}
2023-01-04 00:25:05,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:05,517 INFO:     Epoch: 35
2023-01-04 00:25:07,099 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4180783450603485, 'Total loss': 0.4180783450603485} | train loss {'Reaction outcome loss': 0.24704235544713743, 'Total loss': 0.24704235544713743}
2023-01-04 00:25:07,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:07,099 INFO:     Epoch: 36
2023-01-04 00:25:08,680 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4003374755382538, 'Total loss': 0.4003374755382538} | train loss {'Reaction outcome loss': 0.24471653989740533, 'Total loss': 0.24471653989740533}
2023-01-04 00:25:08,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:08,680 INFO:     Epoch: 37
2023-01-04 00:25:10,255 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41858769158522285, 'Total loss': 0.41858769158522285} | train loss {'Reaction outcome loss': 0.24207213622973348, 'Total loss': 0.24207213622973348}
2023-01-04 00:25:10,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:10,255 INFO:     Epoch: 38
2023-01-04 00:25:11,358 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4096909433603287, 'Total loss': 0.4096909433603287} | train loss {'Reaction outcome loss': 0.23987971974985442, 'Total loss': 0.23987971974985442}
2023-01-04 00:25:11,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:11,358 INFO:     Epoch: 39
2023-01-04 00:25:12,414 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39693151116371156, 'Total loss': 0.39693151116371156} | train loss {'Reaction outcome loss': 0.23489931654049098, 'Total loss': 0.23489931654049098}
2023-01-04 00:25:12,414 INFO:     Found new best model at epoch 39
2023-01-04 00:25:12,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:12,415 INFO:     Epoch: 40
2023-01-04 00:25:13,489 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.391963474949201, 'Total loss': 0.391963474949201} | train loss {'Reaction outcome loss': 0.23269466041539708, 'Total loss': 0.23269466041539708}
2023-01-04 00:25:13,490 INFO:     Found new best model at epoch 40
2023-01-04 00:25:13,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:13,491 INFO:     Epoch: 41
2023-01-04 00:25:14,590 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4101148774226507, 'Total loss': 0.4101148774226507} | train loss {'Reaction outcome loss': 0.23146897790287316, 'Total loss': 0.23146897790287316}
2023-01-04 00:25:14,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:14,591 INFO:     Epoch: 42
2023-01-04 00:25:16,188 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.410291584332784, 'Total loss': 0.410291584332784} | train loss {'Reaction outcome loss': 0.22933488847674244, 'Total loss': 0.22933488847674244}
2023-01-04 00:25:16,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:16,189 INFO:     Epoch: 43
2023-01-04 00:25:17,762 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4053167094786962, 'Total loss': 0.4053167094786962} | train loss {'Reaction outcome loss': 0.2276122569222085, 'Total loss': 0.2276122569222085}
2023-01-04 00:25:17,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:17,762 INFO:     Epoch: 44
2023-01-04 00:25:19,365 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41466260751088463, 'Total loss': 0.41466260751088463} | train loss {'Reaction outcome loss': 0.22476499217025336, 'Total loss': 0.22476499217025336}
2023-01-04 00:25:19,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:19,365 INFO:     Epoch: 45
2023-01-04 00:25:20,966 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4174841781457265, 'Total loss': 0.4174841781457265} | train loss {'Reaction outcome loss': 0.22361163552986443, 'Total loss': 0.22361163552986443}
2023-01-04 00:25:20,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:20,966 INFO:     Epoch: 46
2023-01-04 00:25:22,542 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4119445065657298, 'Total loss': 0.4119445065657298} | train loss {'Reaction outcome loss': 0.21671776738643211, 'Total loss': 0.21671776738643211}
2023-01-04 00:25:22,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:22,543 INFO:     Epoch: 47
2023-01-04 00:25:24,110 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41604548891385396, 'Total loss': 0.41604548891385396} | train loss {'Reaction outcome loss': 0.22069943151062857, 'Total loss': 0.22069943151062857}
2023-01-04 00:25:24,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:24,110 INFO:     Epoch: 48
2023-01-04 00:25:25,698 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4052991857131322, 'Total loss': 0.4052991857131322} | train loss {'Reaction outcome loss': 0.2174670098036745, 'Total loss': 0.2174670098036745}
2023-01-04 00:25:25,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:25,699 INFO:     Epoch: 49
2023-01-04 00:25:27,285 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41213547587394717, 'Total loss': 0.41213547587394717} | train loss {'Reaction outcome loss': 0.21579195829584216, 'Total loss': 0.21579195829584216}
2023-01-04 00:25:27,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:27,286 INFO:     Epoch: 50
2023-01-04 00:25:28,874 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40385516583919523, 'Total loss': 0.40385516583919523} | train loss {'Reaction outcome loss': 0.21095451344158092, 'Total loss': 0.21095451344158092}
2023-01-04 00:25:28,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:28,874 INFO:     Epoch: 51
2023-01-04 00:25:30,448 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4193915029366811, 'Total loss': 0.4193915029366811} | train loss {'Reaction outcome loss': 0.211132862747912, 'Total loss': 0.211132862747912}
2023-01-04 00:25:30,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:30,448 INFO:     Epoch: 52
2023-01-04 00:25:32,036 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4050679087638855, 'Total loss': 0.4050679087638855} | train loss {'Reaction outcome loss': 0.21059336789278654, 'Total loss': 0.21059336789278654}
2023-01-04 00:25:32,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:32,037 INFO:     Epoch: 53
2023-01-04 00:25:33,604 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40990054110685986, 'Total loss': 0.40990054110685986} | train loss {'Reaction outcome loss': 0.20818117124293625, 'Total loss': 0.20818117124293625}
2023-01-04 00:25:33,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:33,604 INFO:     Epoch: 54
2023-01-04 00:25:35,191 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4430553048849106, 'Total loss': 0.4430553048849106} | train loss {'Reaction outcome loss': 0.204977144262869, 'Total loss': 0.204977144262869}
2023-01-04 00:25:35,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:35,192 INFO:     Epoch: 55
2023-01-04 00:25:36,815 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4067074696222941, 'Total loss': 0.4067074696222941} | train loss {'Reaction outcome loss': 0.2050063023683581, 'Total loss': 0.2050063023683581}
2023-01-04 00:25:36,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:36,815 INFO:     Epoch: 56
2023-01-04 00:25:38,421 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4191744973262151, 'Total loss': 0.4191744973262151} | train loss {'Reaction outcome loss': 0.20091241925791667, 'Total loss': 0.20091241925791667}
2023-01-04 00:25:38,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:38,422 INFO:     Epoch: 57
2023-01-04 00:25:40,007 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4251816064119339, 'Total loss': 0.4251816064119339} | train loss {'Reaction outcome loss': 0.20244192646095788, 'Total loss': 0.20244192646095788}
2023-01-04 00:25:40,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:40,008 INFO:     Epoch: 58
2023-01-04 00:25:41,599 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44615981380144754, 'Total loss': 0.44615981380144754} | train loss {'Reaction outcome loss': 0.20086092821383564, 'Total loss': 0.20086092821383564}
2023-01-04 00:25:41,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:41,599 INFO:     Epoch: 59
2023-01-04 00:25:43,212 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4060141851504644, 'Total loss': 0.4060141851504644} | train loss {'Reaction outcome loss': 0.1983376432781237, 'Total loss': 0.1983376432781237}
2023-01-04 00:25:43,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:43,212 INFO:     Epoch: 60
2023-01-04 00:25:44,805 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39944992810487745, 'Total loss': 0.39944992810487745} | train loss {'Reaction outcome loss': 0.19887229342040788, 'Total loss': 0.19887229342040788}
2023-01-04 00:25:44,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:44,806 INFO:     Epoch: 61
2023-01-04 00:25:46,401 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.426733128229777, 'Total loss': 0.426733128229777} | train loss {'Reaction outcome loss': 0.19721702015856757, 'Total loss': 0.19721702015856757}
2023-01-04 00:25:46,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:46,401 INFO:     Epoch: 62
2023-01-04 00:25:48,005 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4038866599400838, 'Total loss': 0.4038866599400838} | train loss {'Reaction outcome loss': 0.19470121945342878, 'Total loss': 0.19470121945342878}
2023-01-04 00:25:48,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:48,005 INFO:     Epoch: 63
2023-01-04 00:25:49,600 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4326081017653147, 'Total loss': 0.4326081017653147} | train loss {'Reaction outcome loss': 0.1929545593821872, 'Total loss': 0.1929545593821872}
2023-01-04 00:25:49,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:49,601 INFO:     Epoch: 64
2023-01-04 00:25:51,180 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39604335129261015, 'Total loss': 0.39604335129261015} | train loss {'Reaction outcome loss': 0.19349865890685877, 'Total loss': 0.19349865890685877}
2023-01-04 00:25:51,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:51,180 INFO:     Epoch: 65
2023-01-04 00:25:52,795 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.431200930972894, 'Total loss': 0.431200930972894} | train loss {'Reaction outcome loss': 0.19165912496918527, 'Total loss': 0.19165912496918527}
2023-01-04 00:25:52,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:52,795 INFO:     Epoch: 66
2023-01-04 00:25:54,415 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42046141922473906, 'Total loss': 0.42046141922473906} | train loss {'Reaction outcome loss': 0.19029013362516017, 'Total loss': 0.19029013362516017}
2023-01-04 00:25:54,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:54,415 INFO:     Epoch: 67
2023-01-04 00:25:56,020 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4268095910549164, 'Total loss': 0.4268095910549164} | train loss {'Reaction outcome loss': 0.18768760234960458, 'Total loss': 0.18768760234960458}
2023-01-04 00:25:56,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:56,021 INFO:     Epoch: 68
2023-01-04 00:25:57,580 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41213607490062715, 'Total loss': 0.41213607490062715} | train loss {'Reaction outcome loss': 0.18796222217816072, 'Total loss': 0.18796222217816072}
2023-01-04 00:25:57,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:57,580 INFO:     Epoch: 69
2023-01-04 00:25:59,192 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4214619566996892, 'Total loss': 0.4214619566996892} | train loss {'Reaction outcome loss': 0.1847023553874371, 'Total loss': 0.1847023553874371}
2023-01-04 00:25:59,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:25:59,192 INFO:     Epoch: 70
2023-01-04 00:26:00,755 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43102099051078163, 'Total loss': 0.43102099051078163} | train loss {'Reaction outcome loss': 0.18557521405826954, 'Total loss': 0.18557521405826954}
2023-01-04 00:26:00,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:00,755 INFO:     Epoch: 71
2023-01-04 00:26:02,334 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43010854025681816, 'Total loss': 0.43010854025681816} | train loss {'Reaction outcome loss': 0.18299704987256632, 'Total loss': 0.18299704987256632}
2023-01-04 00:26:02,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:02,335 INFO:     Epoch: 72
2023-01-04 00:26:03,914 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46240934332211814, 'Total loss': 0.46240934332211814} | train loss {'Reaction outcome loss': 0.18390311249089938, 'Total loss': 0.18390311249089938}
2023-01-04 00:26:03,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:03,914 INFO:     Epoch: 73
2023-01-04 00:26:05,494 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41963375906149547, 'Total loss': 0.41963375906149547} | train loss {'Reaction outcome loss': 0.18240340873870972, 'Total loss': 0.18240340873870972}
2023-01-04 00:26:05,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:05,494 INFO:     Epoch: 74
2023-01-04 00:26:07,062 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4542141675949097, 'Total loss': 0.4542141675949097} | train loss {'Reaction outcome loss': 0.18094199431557073, 'Total loss': 0.18094199431557073}
2023-01-04 00:26:07,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:07,062 INFO:     Epoch: 75
2023-01-04 00:26:08,628 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4428318361441294, 'Total loss': 0.4428318361441294} | train loss {'Reaction outcome loss': 0.1779309527091954, 'Total loss': 0.1779309527091954}
2023-01-04 00:26:08,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:08,628 INFO:     Epoch: 76
2023-01-04 00:26:10,243 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4084687848885854, 'Total loss': 0.4084687848885854} | train loss {'Reaction outcome loss': 0.18049808123223757, 'Total loss': 0.18049808123223757}
2023-01-04 00:26:10,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:10,243 INFO:     Epoch: 77
2023-01-04 00:26:11,856 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44062857031822206, 'Total loss': 0.44062857031822206} | train loss {'Reaction outcome loss': 0.1792269798716272, 'Total loss': 0.1792269798716272}
2023-01-04 00:26:11,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:11,857 INFO:     Epoch: 78
2023-01-04 00:26:13,472 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4378168304761251, 'Total loss': 0.4378168304761251} | train loss {'Reaction outcome loss': 0.18107507683771806, 'Total loss': 0.18107507683771806}
2023-01-04 00:26:13,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:13,472 INFO:     Epoch: 79
2023-01-04 00:26:15,056 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43551265771190323, 'Total loss': 0.43551265771190323} | train loss {'Reaction outcome loss': 0.17862345695658757, 'Total loss': 0.17862345695658757}
2023-01-04 00:26:15,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:15,057 INFO:     Epoch: 80
2023-01-04 00:26:16,632 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4387030601501465, 'Total loss': 0.4387030601501465} | train loss {'Reaction outcome loss': 0.17743719977591813, 'Total loss': 0.17743719977591813}
2023-01-04 00:26:16,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:16,632 INFO:     Epoch: 81
2023-01-04 00:26:18,199 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4348187873760859, 'Total loss': 0.4348187873760859} | train loss {'Reaction outcome loss': 0.1764582859379423, 'Total loss': 0.1764582859379423}
2023-01-04 00:26:18,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:18,199 INFO:     Epoch: 82
2023-01-04 00:26:19,799 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4403605421384176, 'Total loss': 0.4403605421384176} | train loss {'Reaction outcome loss': 0.17614085175586444, 'Total loss': 0.17614085175586444}
2023-01-04 00:26:19,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:19,799 INFO:     Epoch: 83
2023-01-04 00:26:21,408 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4660961041847865, 'Total loss': 0.4660961041847865} | train loss {'Reaction outcome loss': 0.1738251520415945, 'Total loss': 0.1738251520415945}
2023-01-04 00:26:21,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:21,408 INFO:     Epoch: 84
2023-01-04 00:26:23,011 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42704124252001446, 'Total loss': 0.42704124252001446} | train loss {'Reaction outcome loss': 0.17233827192145978, 'Total loss': 0.17233827192145978}
2023-01-04 00:26:23,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:23,011 INFO:     Epoch: 85
2023-01-04 00:26:24,589 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44706679979960123, 'Total loss': 0.44706679979960123} | train loss {'Reaction outcome loss': 0.1706968681397338, 'Total loss': 0.1706968681397338}
2023-01-04 00:26:24,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:24,589 INFO:     Epoch: 86
2023-01-04 00:26:26,197 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44647773702939353, 'Total loss': 0.44647773702939353} | train loss {'Reaction outcome loss': 0.17229350821461772, 'Total loss': 0.17229350821461772}
2023-01-04 00:26:26,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:26,197 INFO:     Epoch: 87
2023-01-04 00:26:27,792 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4709311366081238, 'Total loss': 0.4709311366081238} | train loss {'Reaction outcome loss': 0.17097978428495628, 'Total loss': 0.17097978428495628}
2023-01-04 00:26:27,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:27,793 INFO:     Epoch: 88
2023-01-04 00:26:29,406 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44631180465221404, 'Total loss': 0.44631180465221404} | train loss {'Reaction outcome loss': 0.17107453679897056, 'Total loss': 0.17107453679897056}
2023-01-04 00:26:29,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:29,407 INFO:     Epoch: 89
2023-01-04 00:26:31,021 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4342133641242981, 'Total loss': 0.4342133641242981} | train loss {'Reaction outcome loss': 0.16927572509722552, 'Total loss': 0.16927572509722552}
2023-01-04 00:26:31,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:31,021 INFO:     Epoch: 90
2023-01-04 00:26:32,639 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43702085117499034, 'Total loss': 0.43702085117499034} | train loss {'Reaction outcome loss': 0.16943120311293072, 'Total loss': 0.16943120311293072}
2023-01-04 00:26:32,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:32,639 INFO:     Epoch: 91
2023-01-04 00:26:34,206 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4308259844779968, 'Total loss': 0.4308259844779968} | train loss {'Reaction outcome loss': 0.16745964245340467, 'Total loss': 0.16745964245340467}
2023-01-04 00:26:34,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:34,206 INFO:     Epoch: 92
2023-01-04 00:26:35,779 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4307033856709798, 'Total loss': 0.4307033856709798} | train loss {'Reaction outcome loss': 0.16842731678464118, 'Total loss': 0.16842731678464118}
2023-01-04 00:26:35,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:35,780 INFO:     Epoch: 93
2023-01-04 00:26:37,368 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43791305720806123, 'Total loss': 0.43791305720806123} | train loss {'Reaction outcome loss': 0.16499316697790675, 'Total loss': 0.16499316697790675}
2023-01-04 00:26:37,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:37,368 INFO:     Epoch: 94
2023-01-04 00:26:38,981 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4432336871822675, 'Total loss': 0.4432336871822675} | train loss {'Reaction outcome loss': 0.1657773706803683, 'Total loss': 0.1657773706803683}
2023-01-04 00:26:38,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:38,981 INFO:     Epoch: 95
2023-01-04 00:26:40,591 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.472528616587321, 'Total loss': 0.472528616587321} | train loss {'Reaction outcome loss': 0.16757769670582165, 'Total loss': 0.16757769670582165}
2023-01-04 00:26:40,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:40,591 INFO:     Epoch: 96
2023-01-04 00:26:42,187 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46887803872426354, 'Total loss': 0.46887803872426354} | train loss {'Reaction outcome loss': 0.16420667484593, 'Total loss': 0.16420667484593}
2023-01-04 00:26:42,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:42,187 INFO:     Epoch: 97
2023-01-04 00:26:43,795 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44838691751162213, 'Total loss': 0.44838691751162213} | train loss {'Reaction outcome loss': 0.1641044452120244, 'Total loss': 0.1641044452120244}
2023-01-04 00:26:43,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:43,795 INFO:     Epoch: 98
2023-01-04 00:26:45,374 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4666647404432297, 'Total loss': 0.4666647404432297} | train loss {'Reaction outcome loss': 0.1634999629089704, 'Total loss': 0.1634999629089704}
2023-01-04 00:26:45,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:45,375 INFO:     Epoch: 99
2023-01-04 00:26:46,968 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44181387027104696, 'Total loss': 0.44181387027104696} | train loss {'Reaction outcome loss': 0.163376696938037, 'Total loss': 0.163376696938037}
2023-01-04 00:26:46,969 INFO:     Best model found after epoch 41 of 100.
2023-01-04 00:26:46,969 INFO:   Done with stage: TRAINING
2023-01-04 00:26:46,969 INFO:   Starting stage: EVALUATION
2023-01-04 00:26:47,105 INFO:   Done with stage: EVALUATION
2023-01-04 00:26:47,105 INFO:   Leaving out SEQ value Fold_4
2023-01-04 00:26:47,118 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 00:26:47,118 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:26:47,760 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:26:47,760 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:26:47,829 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:26:47,829 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:26:47,830 INFO:     No hyperparam tuning for this model
2023-01-04 00:26:47,830 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:26:47,830 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:26:47,830 INFO:     None feature selector for col prot
2023-01-04 00:26:47,831 INFO:     None feature selector for col prot
2023-01-04 00:26:47,831 INFO:     None feature selector for col prot
2023-01-04 00:26:47,831 INFO:     None feature selector for col chem
2023-01-04 00:26:47,831 INFO:     None feature selector for col chem
2023-01-04 00:26:47,831 INFO:     None feature selector for col chem
2023-01-04 00:26:47,831 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:26:47,831 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:26:47,832 INFO:     Number of params in model 70141
2023-01-04 00:26:47,836 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:26:47,836 INFO:   Starting stage: TRAINING
2023-01-04 00:26:47,881 INFO:     Val loss before train {'Reaction outcome loss': 0.8305250525474548, 'Total loss': 0.8305250525474548}
2023-01-04 00:26:47,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:47,881 INFO:     Epoch: 0
2023-01-04 00:26:49,472 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6046855231126149, 'Total loss': 0.6046855231126149} | train loss {'Reaction outcome loss': 0.8491429484354845, 'Total loss': 0.8491429484354845}
2023-01-04 00:26:49,472 INFO:     Found new best model at epoch 0
2023-01-04 00:26:49,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:49,473 INFO:     Epoch: 1
2023-01-04 00:26:51,047 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5152548611164093, 'Total loss': 0.5152548611164093} | train loss {'Reaction outcome loss': 0.6023533073240432, 'Total loss': 0.6023533073240432}
2023-01-04 00:26:51,047 INFO:     Found new best model at epoch 1
2023-01-04 00:26:51,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:51,048 INFO:     Epoch: 2
2023-01-04 00:26:52,640 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46611498792966205, 'Total loss': 0.46611498792966205} | train loss {'Reaction outcome loss': 0.5323103564319815, 'Total loss': 0.5323103564319815}
2023-01-04 00:26:52,641 INFO:     Found new best model at epoch 2
2023-01-04 00:26:52,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:52,641 INFO:     Epoch: 3
2023-01-04 00:26:54,238 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46046082576115926, 'Total loss': 0.46046082576115926} | train loss {'Reaction outcome loss': 0.4885479289215004, 'Total loss': 0.4885479289215004}
2023-01-04 00:26:54,238 INFO:     Found new best model at epoch 3
2023-01-04 00:26:54,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:54,239 INFO:     Epoch: 4
2023-01-04 00:26:55,865 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4450791895389557, 'Total loss': 0.4450791895389557} | train loss {'Reaction outcome loss': 0.45922895942045294, 'Total loss': 0.45922895942045294}
2023-01-04 00:26:55,866 INFO:     Found new best model at epoch 4
2023-01-04 00:26:55,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:55,866 INFO:     Epoch: 5
2023-01-04 00:26:57,471 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4264081726471583, 'Total loss': 0.4264081726471583} | train loss {'Reaction outcome loss': 0.44690148235447164, 'Total loss': 0.44690148235447164}
2023-01-04 00:26:57,471 INFO:     Found new best model at epoch 5
2023-01-04 00:26:57,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:57,472 INFO:     Epoch: 6
2023-01-04 00:26:59,071 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4382556219895681, 'Total loss': 0.4382556219895681} | train loss {'Reaction outcome loss': 0.42243570523957413, 'Total loss': 0.42243570523957413}
2023-01-04 00:26:59,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:26:59,072 INFO:     Epoch: 7
2023-01-04 00:27:00,653 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4083605835835139, 'Total loss': 0.4083605835835139} | train loss {'Reaction outcome loss': 0.4051775778554155, 'Total loss': 0.4051775778554155}
2023-01-04 00:27:00,653 INFO:     Found new best model at epoch 7
2023-01-04 00:27:00,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:00,654 INFO:     Epoch: 8
2023-01-04 00:27:02,242 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4314435452222824, 'Total loss': 0.4314435452222824} | train loss {'Reaction outcome loss': 0.3931250575891075, 'Total loss': 0.3931250575891075}
2023-01-04 00:27:02,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:02,244 INFO:     Epoch: 9
2023-01-04 00:27:03,827 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40686966975529987, 'Total loss': 0.40686966975529987} | train loss {'Reaction outcome loss': 0.3838146697135939, 'Total loss': 0.3838146697135939}
2023-01-04 00:27:03,827 INFO:     Found new best model at epoch 9
2023-01-04 00:27:03,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:03,828 INFO:     Epoch: 10
2023-01-04 00:27:05,416 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41271927654743196, 'Total loss': 0.41271927654743196} | train loss {'Reaction outcome loss': 0.375457756076197, 'Total loss': 0.375457756076197}
2023-01-04 00:27:05,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:05,416 INFO:     Epoch: 11
2023-01-04 00:27:07,006 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41993591785430906, 'Total loss': 0.41993591785430906} | train loss {'Reaction outcome loss': 0.36857058811153326, 'Total loss': 0.36857058811153326}
2023-01-04 00:27:07,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:07,006 INFO:     Epoch: 12
2023-01-04 00:27:08,608 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41343549489974973, 'Total loss': 0.41343549489974973} | train loss {'Reaction outcome loss': 0.364832842182638, 'Total loss': 0.364832842182638}
2023-01-04 00:27:08,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:08,609 INFO:     Epoch: 13
2023-01-04 00:27:10,204 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3985820531845093, 'Total loss': 0.3985820531845093} | train loss {'Reaction outcome loss': 0.35532593781446875, 'Total loss': 0.35532593781446875}
2023-01-04 00:27:10,204 INFO:     Found new best model at epoch 13
2023-01-04 00:27:10,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:10,205 INFO:     Epoch: 14
2023-01-04 00:27:11,790 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39671687682469686, 'Total loss': 0.39671687682469686} | train loss {'Reaction outcome loss': 0.34640863841649255, 'Total loss': 0.34640863841649255}
2023-01-04 00:27:11,790 INFO:     Found new best model at epoch 14
2023-01-04 00:27:11,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:11,791 INFO:     Epoch: 15
2023-01-04 00:27:13,386 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40372153123219806, 'Total loss': 0.40372153123219806} | train loss {'Reaction outcome loss': 0.33862115027032036, 'Total loss': 0.33862115027032036}
2023-01-04 00:27:13,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:13,387 INFO:     Epoch: 16
2023-01-04 00:27:14,983 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40980552732944486, 'Total loss': 0.40980552732944486} | train loss {'Reaction outcome loss': 0.33589108096424275, 'Total loss': 0.33589108096424275}
2023-01-04 00:27:14,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:14,983 INFO:     Epoch: 17
2023-01-04 00:27:16,580 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4079245318969091, 'Total loss': 0.4079245318969091} | train loss {'Reaction outcome loss': 0.32778043338718515, 'Total loss': 0.32778043338718515}
2023-01-04 00:27:16,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:16,581 INFO:     Epoch: 18
2023-01-04 00:27:18,166 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.405520361661911, 'Total loss': 0.405520361661911} | train loss {'Reaction outcome loss': 0.3227132263473586, 'Total loss': 0.3227132263473586}
2023-01-04 00:27:18,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:18,166 INFO:     Epoch: 19
2023-01-04 00:27:19,790 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39625502228736875, 'Total loss': 0.39625502228736875} | train loss {'Reaction outcome loss': 0.31522673850312183, 'Total loss': 0.31522673850312183}
2023-01-04 00:27:19,791 INFO:     Found new best model at epoch 19
2023-01-04 00:27:19,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:19,791 INFO:     Epoch: 20
2023-01-04 00:27:21,376 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39484458963076274, 'Total loss': 0.39484458963076274} | train loss {'Reaction outcome loss': 0.3120905889528871, 'Total loss': 0.3120905889528871}
2023-01-04 00:27:21,376 INFO:     Found new best model at epoch 20
2023-01-04 00:27:21,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:21,377 INFO:     Epoch: 21
2023-01-04 00:27:22,975 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.38741106788317364, 'Total loss': 0.38741106788317364} | train loss {'Reaction outcome loss': 0.30881700535183365, 'Total loss': 0.30881700535183365}
2023-01-04 00:27:22,975 INFO:     Found new best model at epoch 21
2023-01-04 00:27:22,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:22,976 INFO:     Epoch: 22
2023-01-04 00:27:24,577 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3993554542462031, 'Total loss': 0.3993554542462031} | train loss {'Reaction outcome loss': 0.3023969204151544, 'Total loss': 0.3023969204151544}
2023-01-04 00:27:24,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:24,577 INFO:     Epoch: 23
2023-01-04 00:27:26,177 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3862217624982198, 'Total loss': 0.3862217624982198} | train loss {'Reaction outcome loss': 0.3025963123941767, 'Total loss': 0.3025963123941767}
2023-01-04 00:27:26,177 INFO:     Found new best model at epoch 23
2023-01-04 00:27:26,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:26,178 INFO:     Epoch: 24
2023-01-04 00:27:27,759 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.375662895043691, 'Total loss': 0.375662895043691} | train loss {'Reaction outcome loss': 0.30864195587734383, 'Total loss': 0.30864195587734383}
2023-01-04 00:27:27,759 INFO:     Found new best model at epoch 24
2023-01-04 00:27:27,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:27,760 INFO:     Epoch: 25
2023-01-04 00:27:29,335 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3835880527893702, 'Total loss': 0.3835880527893702} | train loss {'Reaction outcome loss': 0.2939755807430787, 'Total loss': 0.2939755807430787}
2023-01-04 00:27:29,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:29,335 INFO:     Epoch: 26
2023-01-04 00:27:30,961 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3787176668643951, 'Total loss': 0.3787176668643951} | train loss {'Reaction outcome loss': 0.28589316551232763, 'Total loss': 0.28589316551232763}
2023-01-04 00:27:30,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:30,961 INFO:     Epoch: 27
2023-01-04 00:27:32,599 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3857156723737717, 'Total loss': 0.3857156723737717} | train loss {'Reaction outcome loss': 0.2884293259863836, 'Total loss': 0.2884293259863836}
2023-01-04 00:27:32,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:32,599 INFO:     Epoch: 28
2023-01-04 00:27:34,219 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3740679999192556, 'Total loss': 0.3740679999192556} | train loss {'Reaction outcome loss': 0.28413842859415284, 'Total loss': 0.28413842859415284}
2023-01-04 00:27:34,219 INFO:     Found new best model at epoch 28
2023-01-04 00:27:34,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:34,220 INFO:     Epoch: 29
2023-01-04 00:27:35,829 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3612232635418574, 'Total loss': 0.3612232635418574} | train loss {'Reaction outcome loss': 0.27808483776406967, 'Total loss': 0.27808483776406967}
2023-01-04 00:27:35,829 INFO:     Found new best model at epoch 29
2023-01-04 00:27:35,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:35,830 INFO:     Epoch: 30
2023-01-04 00:27:37,455 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3647364427646001, 'Total loss': 0.3647364427646001} | train loss {'Reaction outcome loss': 0.27348687304254493, 'Total loss': 0.27348687304254493}
2023-01-04 00:27:37,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:37,456 INFO:     Epoch: 31
2023-01-04 00:27:39,051 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3749155133962631, 'Total loss': 0.3749155133962631} | train loss {'Reaction outcome loss': 0.2702359440489723, 'Total loss': 0.2702359440489723}
2023-01-04 00:27:39,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:39,053 INFO:     Epoch: 32
2023-01-04 00:27:40,669 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3683135767777761, 'Total loss': 0.3683135767777761} | train loss {'Reaction outcome loss': 0.26722933476233174, 'Total loss': 0.26722933476233174}
2023-01-04 00:27:40,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:40,669 INFO:     Epoch: 33
2023-01-04 00:27:42,268 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.36726682086785634, 'Total loss': 0.36726682086785634} | train loss {'Reaction outcome loss': 0.2667521227259135, 'Total loss': 0.2667521227259135}
2023-01-04 00:27:42,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:42,269 INFO:     Epoch: 34
2023-01-04 00:27:43,883 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3599193731943766, 'Total loss': 0.3599193731943766} | train loss {'Reaction outcome loss': 0.26786406403677404, 'Total loss': 0.26786406403677404}
2023-01-04 00:27:43,884 INFO:     Found new best model at epoch 34
2023-01-04 00:27:43,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:43,885 INFO:     Epoch: 35
2023-01-04 00:27:45,472 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3426558921734492, 'Total loss': 0.3426558921734492} | train loss {'Reaction outcome loss': 0.2613649595943465, 'Total loss': 0.2613649595943465}
2023-01-04 00:27:45,473 INFO:     Found new best model at epoch 35
2023-01-04 00:27:45,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:45,474 INFO:     Epoch: 36
2023-01-04 00:27:47,083 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3651286900043488, 'Total loss': 0.3651286900043488} | train loss {'Reaction outcome loss': 0.2587780979583445, 'Total loss': 0.2587780979583445}
2023-01-04 00:27:47,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:47,083 INFO:     Epoch: 37
2023-01-04 00:27:48,688 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3601758768161138, 'Total loss': 0.3601758768161138} | train loss {'Reaction outcome loss': 0.25505311708500655, 'Total loss': 0.25505311708500655}
2023-01-04 00:27:48,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:48,688 INFO:     Epoch: 38
2023-01-04 00:27:50,313 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.36575966427723566, 'Total loss': 0.36575966427723566} | train loss {'Reaction outcome loss': 0.2533083103691646, 'Total loss': 0.2533083103691646}
2023-01-04 00:27:50,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:50,313 INFO:     Epoch: 39
2023-01-04 00:27:51,936 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.36021791597207387, 'Total loss': 0.36021791597207387} | train loss {'Reaction outcome loss': 0.2494578525736975, 'Total loss': 0.2494578525736975}
2023-01-04 00:27:51,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:51,936 INFO:     Epoch: 40
2023-01-04 00:27:53,563 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3867469370365143, 'Total loss': 0.3867469370365143} | train loss {'Reaction outcome loss': 0.25132615900719946, 'Total loss': 0.25132615900719946}
2023-01-04 00:27:53,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:53,563 INFO:     Epoch: 41
2023-01-04 00:27:55,160 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.37680552899837494, 'Total loss': 0.37680552899837494} | train loss {'Reaction outcome loss': 0.2523252861034395, 'Total loss': 0.2523252861034395}
2023-01-04 00:27:55,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:55,160 INFO:     Epoch: 42
2023-01-04 00:27:56,760 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3897040774424871, 'Total loss': 0.3897040774424871} | train loss {'Reaction outcome loss': 0.2458731930199302, 'Total loss': 0.2458731930199302}
2023-01-04 00:27:56,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:56,761 INFO:     Epoch: 43
2023-01-04 00:27:58,375 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.365261231859525, 'Total loss': 0.365261231859525} | train loss {'Reaction outcome loss': 0.23990442790721095, 'Total loss': 0.23990442790721095}
2023-01-04 00:27:58,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:58,376 INFO:     Epoch: 44
2023-01-04 00:27:59,976 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3696879674990972, 'Total loss': 0.3696879674990972} | train loss {'Reaction outcome loss': 0.2387627636721911, 'Total loss': 0.2387627636721911}
2023-01-04 00:27:59,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:27:59,976 INFO:     Epoch: 45
2023-01-04 00:28:01,577 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3552046279112498, 'Total loss': 0.3552046279112498} | train loss {'Reaction outcome loss': 0.23524675275468962, 'Total loss': 0.23524675275468962}
2023-01-04 00:28:01,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:01,578 INFO:     Epoch: 46
2023-01-04 00:28:03,179 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3678615162769953, 'Total loss': 0.3678615162769953} | train loss {'Reaction outcome loss': 0.23409279698229302, 'Total loss': 0.23409279698229302}
2023-01-04 00:28:03,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:03,180 INFO:     Epoch: 47
2023-01-04 00:28:04,758 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.37364495992660524, 'Total loss': 0.37364495992660524} | train loss {'Reaction outcome loss': 0.23220582496665132, 'Total loss': 0.23220582496665132}
2023-01-04 00:28:04,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:04,759 INFO:     Epoch: 48
2023-01-04 00:28:06,358 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3618117064237595, 'Total loss': 0.3618117064237595} | train loss {'Reaction outcome loss': 0.23032531421631575, 'Total loss': 0.23032531421631575}
2023-01-04 00:28:06,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:06,358 INFO:     Epoch: 49
2023-01-04 00:28:07,987 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.36055727551380795, 'Total loss': 0.36055727551380795} | train loss {'Reaction outcome loss': 0.2283552471899252, 'Total loss': 0.2283552471899252}
2023-01-04 00:28:07,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:07,987 INFO:     Epoch: 50
2023-01-04 00:28:09,618 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3608583321173986, 'Total loss': 0.3608583321173986} | train loss {'Reaction outcome loss': 0.22944439162392224, 'Total loss': 0.22944439162392224}
2023-01-04 00:28:09,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:09,618 INFO:     Epoch: 51
2023-01-04 00:28:11,235 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3608268663287163, 'Total loss': 0.3608268663287163} | train loss {'Reaction outcome loss': 0.2245712266674778, 'Total loss': 0.2245712266674778}
2023-01-04 00:28:11,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:11,235 INFO:     Epoch: 52
2023-01-04 00:28:12,824 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36630492508411405, 'Total loss': 0.36630492508411405} | train loss {'Reaction outcome loss': 0.22198706977655672, 'Total loss': 0.22198706977655672}
2023-01-04 00:28:12,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:12,824 INFO:     Epoch: 53
2023-01-04 00:28:14,402 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37004049321015675, 'Total loss': 0.37004049321015675} | train loss {'Reaction outcome loss': 0.22295557948957034, 'Total loss': 0.22295557948957034}
2023-01-04 00:28:14,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:14,404 INFO:     Epoch: 54
2023-01-04 00:28:16,031 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3530476043621699, 'Total loss': 0.3530476043621699} | train loss {'Reaction outcome loss': 0.222264007847854, 'Total loss': 0.222264007847854}
2023-01-04 00:28:16,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:16,032 INFO:     Epoch: 55
2023-01-04 00:28:17,641 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3676863978306452, 'Total loss': 0.3676863978306452} | train loss {'Reaction outcome loss': 0.22196735911395238, 'Total loss': 0.22196735911395238}
2023-01-04 00:28:17,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:17,641 INFO:     Epoch: 56
2023-01-04 00:28:19,259 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3667162706454595, 'Total loss': 0.3667162706454595} | train loss {'Reaction outcome loss': 0.22347748115738586, 'Total loss': 0.22347748115738586}
2023-01-04 00:28:19,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:19,259 INFO:     Epoch: 57
2023-01-04 00:28:20,855 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.37025576730569204, 'Total loss': 0.37025576730569204} | train loss {'Reaction outcome loss': 0.21636194832946942, 'Total loss': 0.21636194832946942}
2023-01-04 00:28:20,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:20,856 INFO:     Epoch: 58
2023-01-04 00:28:22,451 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3753737290700277, 'Total loss': 0.3753737290700277} | train loss {'Reaction outcome loss': 0.21765066199747007, 'Total loss': 0.21765066199747007}
2023-01-04 00:28:22,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:22,451 INFO:     Epoch: 59
2023-01-04 00:28:24,036 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3688597212235133, 'Total loss': 0.3688597212235133} | train loss {'Reaction outcome loss': 0.21669887330221094, 'Total loss': 0.21669887330221094}
2023-01-04 00:28:24,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:24,037 INFO:     Epoch: 60
2023-01-04 00:28:25,655 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3498252063989639, 'Total loss': 0.3498252063989639} | train loss {'Reaction outcome loss': 0.21724881425979076, 'Total loss': 0.21724881425979076}
2023-01-04 00:28:25,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:25,655 INFO:     Epoch: 61
2023-01-04 00:28:27,286 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3706689308087031, 'Total loss': 0.3706689308087031} | train loss {'Reaction outcome loss': 0.2118926641760745, 'Total loss': 0.2118926641760745}
2023-01-04 00:28:27,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:27,286 INFO:     Epoch: 62
2023-01-04 00:28:28,910 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3827699229121208, 'Total loss': 0.3827699229121208} | train loss {'Reaction outcome loss': 0.21228797029217947, 'Total loss': 0.21228797029217947}
2023-01-04 00:28:28,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:28,910 INFO:     Epoch: 63
2023-01-04 00:28:30,513 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36633344093958536, 'Total loss': 0.36633344093958536} | train loss {'Reaction outcome loss': 0.21142297573100802, 'Total loss': 0.21142297573100802}
2023-01-04 00:28:30,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:30,513 INFO:     Epoch: 64
2023-01-04 00:28:32,150 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3741720408201218, 'Total loss': 0.3741720408201218} | train loss {'Reaction outcome loss': 0.2087979813245972, 'Total loss': 0.2087979813245972}
2023-01-04 00:28:32,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:32,151 INFO:     Epoch: 65
2023-01-04 00:28:33,758 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.35548024872938794, 'Total loss': 0.35548024872938794} | train loss {'Reaction outcome loss': 0.20619402514041765, 'Total loss': 0.20619402514041765}
2023-01-04 00:28:33,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:33,759 INFO:     Epoch: 66
2023-01-04 00:28:35,358 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.35661327143510185, 'Total loss': 0.35661327143510185} | train loss {'Reaction outcome loss': 0.20662187378711414, 'Total loss': 0.20662187378711414}
2023-01-04 00:28:35,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:35,358 INFO:     Epoch: 67
2023-01-04 00:28:36,978 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.37692929009596504, 'Total loss': 0.37692929009596504} | train loss {'Reaction outcome loss': 0.20492191508877283, 'Total loss': 0.20492191508877283}
2023-01-04 00:28:36,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:36,978 INFO:     Epoch: 68
2023-01-04 00:28:38,603 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3795993834733963, 'Total loss': 0.3795993834733963} | train loss {'Reaction outcome loss': 0.2018037985293684, 'Total loss': 0.2018037985293684}
2023-01-04 00:28:38,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:38,603 INFO:     Epoch: 69
2023-01-04 00:28:40,187 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.34425358672936757, 'Total loss': 0.34425358672936757} | train loss {'Reaction outcome loss': 0.20260487139065567, 'Total loss': 0.20260487139065567}
2023-01-04 00:28:40,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:40,187 INFO:     Epoch: 70
2023-01-04 00:28:41,763 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37310782770315803, 'Total loss': 0.37310782770315803} | train loss {'Reaction outcome loss': 0.20033429933718636, 'Total loss': 0.20033429933718636}
2023-01-04 00:28:41,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:41,763 INFO:     Epoch: 71
2023-01-04 00:28:43,391 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3855225746830305, 'Total loss': 0.3855225746830305} | train loss {'Reaction outcome loss': 0.20203199626985882, 'Total loss': 0.20203199626985882}
2023-01-04 00:28:43,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:43,391 INFO:     Epoch: 72
2023-01-04 00:28:45,012 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.36900450388590494, 'Total loss': 0.36900450388590494} | train loss {'Reaction outcome loss': 0.1991407412941149, 'Total loss': 0.1991407412941149}
2023-01-04 00:28:45,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:45,013 INFO:     Epoch: 73
2023-01-04 00:28:46,616 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.35909821341435116, 'Total loss': 0.35909821341435116} | train loss {'Reaction outcome loss': 0.1984509406881272, 'Total loss': 0.1984509406881272}
2023-01-04 00:28:46,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:46,616 INFO:     Epoch: 74
2023-01-04 00:28:48,202 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.36537726124127706, 'Total loss': 0.36537726124127706} | train loss {'Reaction outcome loss': 0.19842866861728142, 'Total loss': 0.19842866861728142}
2023-01-04 00:28:48,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:48,202 INFO:     Epoch: 75
2023-01-04 00:28:49,800 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3800150493780772, 'Total loss': 0.3800150493780772} | train loss {'Reaction outcome loss': 0.19863702012630907, 'Total loss': 0.19863702012630907}
2023-01-04 00:28:49,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:49,800 INFO:     Epoch: 76
2023-01-04 00:28:51,394 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38299189507961273, 'Total loss': 0.38299189507961273} | train loss {'Reaction outcome loss': 0.2038092488782359, 'Total loss': 0.2038092488782359}
2023-01-04 00:28:51,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:51,395 INFO:     Epoch: 77
2023-01-04 00:28:53,026 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3683591663837433, 'Total loss': 0.3683591663837433} | train loss {'Reaction outcome loss': 0.1931315493243544, 'Total loss': 0.1931315493243544}
2023-01-04 00:28:53,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:53,027 INFO:     Epoch: 78
2023-01-04 00:28:54,653 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3631377118329207, 'Total loss': 0.3631377118329207} | train loss {'Reaction outcome loss': 0.20387606616988205, 'Total loss': 0.20387606616988205}
2023-01-04 00:28:54,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:54,653 INFO:     Epoch: 79
2023-01-04 00:28:56,295 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3662694940964381, 'Total loss': 0.3662694940964381} | train loss {'Reaction outcome loss': 0.19326503621546115, 'Total loss': 0.19326503621546115}
2023-01-04 00:28:56,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:56,295 INFO:     Epoch: 80
2023-01-04 00:28:57,885 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37017519970734913, 'Total loss': 0.37017519970734913} | train loss {'Reaction outcome loss': 0.19061664767323763, 'Total loss': 0.19061664767323763}
2023-01-04 00:28:57,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:57,886 INFO:     Epoch: 81
2023-01-04 00:28:59,473 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39144618312517804, 'Total loss': 0.39144618312517804} | train loss {'Reaction outcome loss': 0.19260823307527258, 'Total loss': 0.19260823307527258}
2023-01-04 00:28:59,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:28:59,473 INFO:     Epoch: 82
2023-01-04 00:29:01,056 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37747509181499483, 'Total loss': 0.37747509181499483} | train loss {'Reaction outcome loss': 0.1911009272614889, 'Total loss': 0.1911009272614889}
2023-01-04 00:29:01,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:01,056 INFO:     Epoch: 83
2023-01-04 00:29:02,689 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.37511905978123344, 'Total loss': 0.37511905978123344} | train loss {'Reaction outcome loss': 0.19056503015085385, 'Total loss': 0.19056503015085385}
2023-01-04 00:29:02,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:02,689 INFO:     Epoch: 84
2023-01-04 00:29:04,268 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3595132514834404, 'Total loss': 0.3595132514834404} | train loss {'Reaction outcome loss': 0.18796970083138254, 'Total loss': 0.18796970083138254}
2023-01-04 00:29:04,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:04,269 INFO:     Epoch: 85
2023-01-04 00:29:05,872 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39436856508255, 'Total loss': 0.39436856508255} | train loss {'Reaction outcome loss': 0.18803785362895037, 'Total loss': 0.18803785362895037}
2023-01-04 00:29:05,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:05,872 INFO:     Epoch: 86
2023-01-04 00:29:07,472 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.37753613690535226, 'Total loss': 0.37753613690535226} | train loss {'Reaction outcome loss': 0.18768821626088247, 'Total loss': 0.18768821626088247}
2023-01-04 00:29:07,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:07,472 INFO:     Epoch: 87
2023-01-04 00:29:09,064 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3817475338776906, 'Total loss': 0.3817475338776906} | train loss {'Reaction outcome loss': 0.18826714980626263, 'Total loss': 0.18826714980626263}
2023-01-04 00:29:09,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:09,065 INFO:     Epoch: 88
2023-01-04 00:29:10,695 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3582995766152938, 'Total loss': 0.3582995766152938} | train loss {'Reaction outcome loss': 0.18511916609376372, 'Total loss': 0.18511916609376372}
2023-01-04 00:29:10,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:10,695 INFO:     Epoch: 89
2023-01-04 00:29:12,280 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37768430473903813, 'Total loss': 0.37768430473903813} | train loss {'Reaction outcome loss': 0.18527630444726167, 'Total loss': 0.18527630444726167}
2023-01-04 00:29:12,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:12,280 INFO:     Epoch: 90
2023-01-04 00:29:13,872 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3709042064845562, 'Total loss': 0.3709042064845562} | train loss {'Reaction outcome loss': 0.1859497825402998, 'Total loss': 0.1859497825402998}
2023-01-04 00:29:13,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:13,872 INFO:     Epoch: 91
2023-01-04 00:29:15,452 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3726533552010854, 'Total loss': 0.3726533552010854} | train loss {'Reaction outcome loss': 0.1853075321891004, 'Total loss': 0.1853075321891004}
2023-01-04 00:29:15,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:15,453 INFO:     Epoch: 92
2023-01-04 00:29:17,046 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.36283592879772186, 'Total loss': 0.36283592879772186} | train loss {'Reaction outcome loss': 0.1825960358286403, 'Total loss': 0.1825960358286403}
2023-01-04 00:29:17,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:17,046 INFO:     Epoch: 93
2023-01-04 00:29:18,617 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38098148281375566, 'Total loss': 0.38098148281375566} | train loss {'Reaction outcome loss': 0.18209234785087797, 'Total loss': 0.18209234785087797}
2023-01-04 00:29:18,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:18,617 INFO:     Epoch: 94
2023-01-04 00:29:20,209 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3973064323266347, 'Total loss': 0.3973064323266347} | train loss {'Reaction outcome loss': 0.18156228337328936, 'Total loss': 0.18156228337328936}
2023-01-04 00:29:20,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:20,210 INFO:     Epoch: 95
2023-01-04 00:29:21,802 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38083315789699557, 'Total loss': 0.38083315789699557} | train loss {'Reaction outcome loss': 0.18747488239339716, 'Total loss': 0.18747488239339716}
2023-01-04 00:29:21,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:21,803 INFO:     Epoch: 96
2023-01-04 00:29:23,396 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.36983633438746133, 'Total loss': 0.36983633438746133} | train loss {'Reaction outcome loss': 0.18128128562244147, 'Total loss': 0.18128128562244147}
2023-01-04 00:29:23,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:23,396 INFO:     Epoch: 97
2023-01-04 00:29:24,983 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3800085167090098, 'Total loss': 0.3800085167090098} | train loss {'Reaction outcome loss': 0.17943081201087477, 'Total loss': 0.17943081201087477}
2023-01-04 00:29:24,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:24,983 INFO:     Epoch: 98
2023-01-04 00:29:26,590 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37734972933928174, 'Total loss': 0.37734972933928174} | train loss {'Reaction outcome loss': 0.17835428131756076, 'Total loss': 0.17835428131756076}
2023-01-04 00:29:26,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:26,590 INFO:     Epoch: 99
2023-01-04 00:29:28,184 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.35778308982650436, 'Total loss': 0.35778308982650436} | train loss {'Reaction outcome loss': 0.17940808326660562, 'Total loss': 0.17940808326660562}
2023-01-04 00:29:28,185 INFO:     Best model found after epoch 36 of 100.
2023-01-04 00:29:28,185 INFO:   Done with stage: TRAINING
2023-01-04 00:29:28,185 INFO:   Starting stage: EVALUATION
2023-01-04 00:29:28,314 INFO:   Done with stage: EVALUATION
2023-01-04 00:29:28,314 INFO:   Leaving out SEQ value Fold_5
2023-01-04 00:29:28,327 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 00:29:28,327 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:29:28,976 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:29:28,976 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:29:29,046 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:29:29,046 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:29:29,046 INFO:     No hyperparam tuning for this model
2023-01-04 00:29:29,046 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:29:29,046 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:29:29,047 INFO:     None feature selector for col prot
2023-01-04 00:29:29,047 INFO:     None feature selector for col prot
2023-01-04 00:29:29,047 INFO:     None feature selector for col prot
2023-01-04 00:29:29,047 INFO:     None feature selector for col chem
2023-01-04 00:29:29,047 INFO:     None feature selector for col chem
2023-01-04 00:29:29,048 INFO:     None feature selector for col chem
2023-01-04 00:29:29,048 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:29:29,048 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:29:29,049 INFO:     Number of params in model 70141
2023-01-04 00:29:29,052 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:29:29,052 INFO:   Starting stage: TRAINING
2023-01-04 00:29:29,097 INFO:     Val loss before train {'Reaction outcome loss': 0.9964188456535339, 'Total loss': 0.9964188456535339}
2023-01-04 00:29:29,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:29,097 INFO:     Epoch: 0
2023-01-04 00:29:30,691 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6520684281984965, 'Total loss': 0.6520684281984965} | train loss {'Reaction outcome loss': 0.8336679646039268, 'Total loss': 0.8336679646039268}
2023-01-04 00:29:30,691 INFO:     Found new best model at epoch 0
2023-01-04 00:29:30,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:30,692 INFO:     Epoch: 1
2023-01-04 00:29:32,281 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5427760561307271, 'Total loss': 0.5427760561307271} | train loss {'Reaction outcome loss': 0.5937682431097066, 'Total loss': 0.5937682431097066}
2023-01-04 00:29:32,281 INFO:     Found new best model at epoch 1
2023-01-04 00:29:32,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:32,282 INFO:     Epoch: 2
2023-01-04 00:29:33,866 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5129133482774099, 'Total loss': 0.5129133482774099} | train loss {'Reaction outcome loss': 0.5249899693021706, 'Total loss': 0.5249899693021706}
2023-01-04 00:29:33,867 INFO:     Found new best model at epoch 2
2023-01-04 00:29:33,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:33,868 INFO:     Epoch: 3
2023-01-04 00:29:35,448 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.498273766040802, 'Total loss': 0.498273766040802} | train loss {'Reaction outcome loss': 0.4872303640584223, 'Total loss': 0.4872303640584223}
2023-01-04 00:29:35,449 INFO:     Found new best model at epoch 3
2023-01-04 00:29:35,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:35,449 INFO:     Epoch: 4
2023-01-04 00:29:37,084 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47916502157847085, 'Total loss': 0.47916502157847085} | train loss {'Reaction outcome loss': 0.4578241572483352, 'Total loss': 0.4578241572483352}
2023-01-04 00:29:37,084 INFO:     Found new best model at epoch 4
2023-01-04 00:29:37,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:37,085 INFO:     Epoch: 5
2023-01-04 00:29:38,715 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45177834630012514, 'Total loss': 0.45177834630012514} | train loss {'Reaction outcome loss': 0.43547719786959005, 'Total loss': 0.43547719786959005}
2023-01-04 00:29:38,715 INFO:     Found new best model at epoch 5
2023-01-04 00:29:38,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:38,716 INFO:     Epoch: 6
2023-01-04 00:29:40,355 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4576119929552078, 'Total loss': 0.4576119929552078} | train loss {'Reaction outcome loss': 0.41581468327165944, 'Total loss': 0.41581468327165944}
2023-01-04 00:29:40,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:40,355 INFO:     Epoch: 7
2023-01-04 00:29:41,968 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4428203582763672, 'Total loss': 0.4428203582763672} | train loss {'Reaction outcome loss': 0.4012517148783491, 'Total loss': 0.4012517148783491}
2023-01-04 00:29:41,968 INFO:     Found new best model at epoch 7
2023-01-04 00:29:41,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:41,969 INFO:     Epoch: 8
2023-01-04 00:29:43,581 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43484311501185097, 'Total loss': 0.43484311501185097} | train loss {'Reaction outcome loss': 0.38927177285997444, 'Total loss': 0.38927177285997444}
2023-01-04 00:29:43,581 INFO:     Found new best model at epoch 8
2023-01-04 00:29:43,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:43,582 INFO:     Epoch: 9
2023-01-04 00:29:45,170 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43312457104523977, 'Total loss': 0.43312457104523977} | train loss {'Reaction outcome loss': 0.37717132689935634, 'Total loss': 0.37717132689935634}
2023-01-04 00:29:45,170 INFO:     Found new best model at epoch 9
2023-01-04 00:29:45,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:45,171 INFO:     Epoch: 10
2023-01-04 00:29:46,777 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4190615956981977, 'Total loss': 0.4190615956981977} | train loss {'Reaction outcome loss': 0.3684247518059149, 'Total loss': 0.3684247518059149}
2023-01-04 00:29:46,777 INFO:     Found new best model at epoch 10
2023-01-04 00:29:46,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:46,778 INFO:     Epoch: 11
2023-01-04 00:29:48,392 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4148632208506266, 'Total loss': 0.4148632208506266} | train loss {'Reaction outcome loss': 0.3593262817293728, 'Total loss': 0.3593262817293728}
2023-01-04 00:29:48,392 INFO:     Found new best model at epoch 11
2023-01-04 00:29:48,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:48,393 INFO:     Epoch: 12
2023-01-04 00:29:50,013 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4150310079256693, 'Total loss': 0.4150310079256693} | train loss {'Reaction outcome loss': 0.35122524581123343, 'Total loss': 0.35122524581123343}
2023-01-04 00:29:50,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:50,013 INFO:     Epoch: 13
2023-01-04 00:29:51,618 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43237953384717304, 'Total loss': 0.43237953384717304} | train loss {'Reaction outcome loss': 0.3427303804871408, 'Total loss': 0.3427303804871408}
2023-01-04 00:29:51,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:51,620 INFO:     Epoch: 14
2023-01-04 00:29:53,204 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40797961354255674, 'Total loss': 0.40797961354255674} | train loss {'Reaction outcome loss': 0.33898252496220144, 'Total loss': 0.33898252496220144}
2023-01-04 00:29:53,204 INFO:     Found new best model at epoch 14
2023-01-04 00:29:53,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:53,205 INFO:     Epoch: 15
2023-01-04 00:29:54,798 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40965519547462464, 'Total loss': 0.40965519547462464} | train loss {'Reaction outcome loss': 0.33195754223997415, 'Total loss': 0.33195754223997415}
2023-01-04 00:29:54,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:54,798 INFO:     Epoch: 16
2023-01-04 00:29:56,414 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41778683563073477, 'Total loss': 0.41778683563073477} | train loss {'Reaction outcome loss': 0.3248150598271229, 'Total loss': 0.3248150598271229}
2023-01-04 00:29:56,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:56,414 INFO:     Epoch: 17
2023-01-04 00:29:58,035 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4055478195349375, 'Total loss': 0.4055478195349375} | train loss {'Reaction outcome loss': 0.3198046817676255, 'Total loss': 0.3198046817676255}
2023-01-04 00:29:58,035 INFO:     Found new best model at epoch 17
2023-01-04 00:29:58,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:58,036 INFO:     Epoch: 18
2023-01-04 00:29:59,645 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4249806940555573, 'Total loss': 0.4249806940555573} | train loss {'Reaction outcome loss': 0.3119169666771424, 'Total loss': 0.3119169666771424}
2023-01-04 00:29:59,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:29:59,645 INFO:     Epoch: 19
2023-01-04 00:30:01,239 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4203091263771057, 'Total loss': 0.4203091263771057} | train loss {'Reaction outcome loss': 0.3063781597527141, 'Total loss': 0.3063781597527141}
2023-01-04 00:30:01,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:01,240 INFO:     Epoch: 20
2023-01-04 00:30:02,836 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.404659433166186, 'Total loss': 0.404659433166186} | train loss {'Reaction outcome loss': 0.3037932921160645, 'Total loss': 0.3037932921160645}
2023-01-04 00:30:02,837 INFO:     Found new best model at epoch 20
2023-01-04 00:30:02,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:02,837 INFO:     Epoch: 21
2023-01-04 00:30:04,451 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3888117184241613, 'Total loss': 0.3888117184241613} | train loss {'Reaction outcome loss': 0.30059407250653103, 'Total loss': 0.30059407250653103}
2023-01-04 00:30:04,452 INFO:     Found new best model at epoch 21
2023-01-04 00:30:04,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:04,452 INFO:     Epoch: 22
2023-01-04 00:30:06,054 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39330981771151224, 'Total loss': 0.39330981771151224} | train loss {'Reaction outcome loss': 0.29389204213980735, 'Total loss': 0.29389204213980735}
2023-01-04 00:30:06,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:06,054 INFO:     Epoch: 23
2023-01-04 00:30:07,656 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3973853588104248, 'Total loss': 0.3973853588104248} | train loss {'Reaction outcome loss': 0.29068586219519055, 'Total loss': 0.29068586219519055}
2023-01-04 00:30:07,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:07,656 INFO:     Epoch: 24
2023-01-04 00:30:09,248 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3909153550863266, 'Total loss': 0.3909153550863266} | train loss {'Reaction outcome loss': 0.28847372878867367, 'Total loss': 0.28847372878867367}
2023-01-04 00:30:09,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:09,248 INFO:     Epoch: 25
2023-01-04 00:30:10,877 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3932555596033732, 'Total loss': 0.3932555596033732} | train loss {'Reaction outcome loss': 0.284393591221274, 'Total loss': 0.284393591221274}
2023-01-04 00:30:10,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:10,878 INFO:     Epoch: 26
2023-01-04 00:30:12,482 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41433067123095196, 'Total loss': 0.41433067123095196} | train loss {'Reaction outcome loss': 0.28087577845107775, 'Total loss': 0.28087577845107775}
2023-01-04 00:30:12,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:12,482 INFO:     Epoch: 27
2023-01-04 00:30:14,107 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39605168998241425, 'Total loss': 0.39605168998241425} | train loss {'Reaction outcome loss': 0.2776058848261403, 'Total loss': 0.2776058848261403}
2023-01-04 00:30:14,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:14,107 INFO:     Epoch: 28
2023-01-04 00:30:15,734 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39770403305689495, 'Total loss': 0.39770403305689495} | train loss {'Reaction outcome loss': 0.27419486224974104, 'Total loss': 0.27419486224974104}
2023-01-04 00:30:15,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:15,734 INFO:     Epoch: 29
2023-01-04 00:30:17,361 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3868079642454783, 'Total loss': 0.3868079642454783} | train loss {'Reaction outcome loss': 0.2696238632048295, 'Total loss': 0.2696238632048295}
2023-01-04 00:30:17,362 INFO:     Found new best model at epoch 29
2023-01-04 00:30:17,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:17,362 INFO:     Epoch: 30
2023-01-04 00:30:18,962 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40205040176709494, 'Total loss': 0.40205040176709494} | train loss {'Reaction outcome loss': 0.26766179867815026, 'Total loss': 0.26766179867815026}
2023-01-04 00:30:18,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:18,962 INFO:     Epoch: 31
2023-01-04 00:30:20,549 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40468134184678395, 'Total loss': 0.40468134184678395} | train loss {'Reaction outcome loss': 0.2642944412917867, 'Total loss': 0.2642944412917867}
2023-01-04 00:30:20,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:20,549 INFO:     Epoch: 32
2023-01-04 00:30:22,182 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.392224316795667, 'Total loss': 0.392224316795667} | train loss {'Reaction outcome loss': 0.2647720572911875, 'Total loss': 0.2647720572911875}
2023-01-04 00:30:22,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:22,183 INFO:     Epoch: 33
2023-01-04 00:30:23,813 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3978720009326935, 'Total loss': 0.3978720009326935} | train loss {'Reaction outcome loss': 0.25792681376049664, 'Total loss': 0.25792681376049664}
2023-01-04 00:30:23,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:23,814 INFO:     Epoch: 34
2023-01-04 00:30:25,451 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39390962521235146, 'Total loss': 0.39390962521235146} | train loss {'Reaction outcome loss': 0.25729283500825884, 'Total loss': 0.25729283500825884}
2023-01-04 00:30:25,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:25,451 INFO:     Epoch: 35
2023-01-04 00:30:27,041 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3922797828912735, 'Total loss': 0.3922797828912735} | train loss {'Reaction outcome loss': 0.25695207709655005, 'Total loss': 0.25695207709655005}
2023-01-04 00:30:27,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:27,041 INFO:     Epoch: 36
2023-01-04 00:30:28,645 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3916664818922679, 'Total loss': 0.3916664818922679} | train loss {'Reaction outcome loss': 0.2526688555571577, 'Total loss': 0.2526688555571577}
2023-01-04 00:30:28,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:28,646 INFO:     Epoch: 37
2023-01-04 00:30:30,237 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39762698610623676, 'Total loss': 0.39762698610623676} | train loss {'Reaction outcome loss': 0.2509950308754556, 'Total loss': 0.2509950308754556}
2023-01-04 00:30:30,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:30,237 INFO:     Epoch: 38
2023-01-04 00:30:31,879 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39166009227434795, 'Total loss': 0.39166009227434795} | train loss {'Reaction outcome loss': 0.24445747262680573, 'Total loss': 0.24445747262680573}
2023-01-04 00:30:31,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:31,880 INFO:     Epoch: 39
2023-01-04 00:30:33,522 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4104799568653107, 'Total loss': 0.4104799568653107} | train loss {'Reaction outcome loss': 0.2451608013025475, 'Total loss': 0.2451608013025475}
2023-01-04 00:30:33,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:33,522 INFO:     Epoch: 40
2023-01-04 00:30:35,163 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37738414605458576, 'Total loss': 0.37738414605458576} | train loss {'Reaction outcome loss': 0.24291309464171476, 'Total loss': 0.24291309464171476}
2023-01-04 00:30:35,164 INFO:     Found new best model at epoch 40
2023-01-04 00:30:35,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:35,164 INFO:     Epoch: 41
2023-01-04 00:30:36,765 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3966098705927531, 'Total loss': 0.3966098705927531} | train loss {'Reaction outcome loss': 0.24222090251286538, 'Total loss': 0.24222090251286538}
2023-01-04 00:30:36,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:36,765 INFO:     Epoch: 42
2023-01-04 00:30:38,384 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.37273249924182894, 'Total loss': 0.37273249924182894} | train loss {'Reaction outcome loss': 0.23843844238978001, 'Total loss': 0.23843844238978001}
2023-01-04 00:30:38,384 INFO:     Found new best model at epoch 42
2023-01-04 00:30:38,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:38,385 INFO:     Epoch: 43
2023-01-04 00:30:39,984 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39320124934117, 'Total loss': 0.39320124934117} | train loss {'Reaction outcome loss': 0.23527067946774435, 'Total loss': 0.23527067946774435}
2023-01-04 00:30:39,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:39,984 INFO:     Epoch: 44
2023-01-04 00:30:41,588 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3726355200012525, 'Total loss': 0.3726355200012525} | train loss {'Reaction outcome loss': 0.2351053866157678, 'Total loss': 0.2351053866157678}
2023-01-04 00:30:41,589 INFO:     Found new best model at epoch 44
2023-01-04 00:30:41,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:41,590 INFO:     Epoch: 45
2023-01-04 00:30:43,191 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4217310388882955, 'Total loss': 0.4217310388882955} | train loss {'Reaction outcome loss': 0.23233116549920518, 'Total loss': 0.23233116549920518}
2023-01-04 00:30:43,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:43,191 INFO:     Epoch: 46
2023-01-04 00:30:44,774 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4019142339626948, 'Total loss': 0.4019142339626948} | train loss {'Reaction outcome loss': 0.22981291693309153, 'Total loss': 0.22981291693309153}
2023-01-04 00:30:44,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:44,775 INFO:     Epoch: 47
2023-01-04 00:30:46,393 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39222373912731806, 'Total loss': 0.39222373912731806} | train loss {'Reaction outcome loss': 0.22992211447134345, 'Total loss': 0.22992211447134345}
2023-01-04 00:30:46,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:46,393 INFO:     Epoch: 48
2023-01-04 00:30:47,988 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3881056358416875, 'Total loss': 0.3881056358416875} | train loss {'Reaction outcome loss': 0.22998603107912016, 'Total loss': 0.22998603107912016}
2023-01-04 00:30:47,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:47,988 INFO:     Epoch: 49
2023-01-04 00:30:49,610 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3912302697698275, 'Total loss': 0.3912302697698275} | train loss {'Reaction outcome loss': 0.22492097714909148, 'Total loss': 0.22492097714909148}
2023-01-04 00:30:49,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:49,610 INFO:     Epoch: 50
2023-01-04 00:30:51,236 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40270155370235444, 'Total loss': 0.40270155370235444} | train loss {'Reaction outcome loss': 0.22300209890418965, 'Total loss': 0.22300209890418965}
2023-01-04 00:30:51,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:51,237 INFO:     Epoch: 51
2023-01-04 00:30:52,866 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4045896515250206, 'Total loss': 0.4045896515250206} | train loss {'Reaction outcome loss': 0.22290551265708375, 'Total loss': 0.22290551265708375}
2023-01-04 00:30:52,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:52,868 INFO:     Epoch: 52
2023-01-04 00:30:54,463 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39269906282424927, 'Total loss': 0.39269906282424927} | train loss {'Reaction outcome loss': 0.22382046400639985, 'Total loss': 0.22382046400639985}
2023-01-04 00:30:54,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:54,463 INFO:     Epoch: 53
2023-01-04 00:30:56,071 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39791930640737216, 'Total loss': 0.39791930640737216} | train loss {'Reaction outcome loss': 0.22048735337513448, 'Total loss': 0.22048735337513448}
2023-01-04 00:30:56,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:56,072 INFO:     Epoch: 54
2023-01-04 00:30:57,710 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3936524907747904, 'Total loss': 0.3936524907747904} | train loss {'Reaction outcome loss': 0.2205006509535149, 'Total loss': 0.2205006509535149}
2023-01-04 00:30:57,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:57,711 INFO:     Epoch: 55
2023-01-04 00:30:59,367 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4124629577000936, 'Total loss': 0.4124629577000936} | train loss {'Reaction outcome loss': 0.21824123474369195, 'Total loss': 0.21824123474369195}
2023-01-04 00:30:59,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:30:59,368 INFO:     Epoch: 56
2023-01-04 00:31:01,028 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4199059814214706, 'Total loss': 0.4199059814214706} | train loss {'Reaction outcome loss': 0.21405917138452996, 'Total loss': 0.21405917138452996}
2023-01-04 00:31:01,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:01,029 INFO:     Epoch: 57
2023-01-04 00:31:02,613 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42419211367766063, 'Total loss': 0.42419211367766063} | train loss {'Reaction outcome loss': 0.2146024562230179, 'Total loss': 0.2146024562230179}
2023-01-04 00:31:02,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:02,613 INFO:     Epoch: 58
2023-01-04 00:31:04,256 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40974513987700145, 'Total loss': 0.40974513987700145} | train loss {'Reaction outcome loss': 0.21280384430870253, 'Total loss': 0.21280384430870253}
2023-01-04 00:31:04,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:04,256 INFO:     Epoch: 59
2023-01-04 00:31:05,895 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39765170713265735, 'Total loss': 0.39765170713265735} | train loss {'Reaction outcome loss': 0.21240494961073683, 'Total loss': 0.21240494961073683}
2023-01-04 00:31:05,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:05,895 INFO:     Epoch: 60
2023-01-04 00:31:07,561 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4129317283630371, 'Total loss': 0.4129317283630371} | train loss {'Reaction outcome loss': 0.21082537424908648, 'Total loss': 0.21082537424908648}
2023-01-04 00:31:07,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:07,561 INFO:     Epoch: 61
2023-01-04 00:31:09,203 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4087954352299372, 'Total loss': 0.4087954352299372} | train loss {'Reaction outcome loss': 0.2095089814212133, 'Total loss': 0.2095089814212133}
2023-01-04 00:31:09,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:09,203 INFO:     Epoch: 62
2023-01-04 00:31:10,858 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39404784242312113, 'Total loss': 0.39404784242312113} | train loss {'Reaction outcome loss': 0.21001298261624812, 'Total loss': 0.21001298261624812}
2023-01-04 00:31:10,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:10,858 INFO:     Epoch: 63
2023-01-04 00:31:12,502 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4046374440193176, 'Total loss': 0.4046374440193176} | train loss {'Reaction outcome loss': 0.20874882631326624, 'Total loss': 0.20874882631326624}
2023-01-04 00:31:12,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:12,503 INFO:     Epoch: 64
2023-01-04 00:31:14,147 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3970818415284157, 'Total loss': 0.3970818415284157} | train loss {'Reaction outcome loss': 0.20471132344932763, 'Total loss': 0.20471132344932763}
2023-01-04 00:31:14,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:14,147 INFO:     Epoch: 65
2023-01-04 00:31:15,791 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.395629745721817, 'Total loss': 0.395629745721817} | train loss {'Reaction outcome loss': 0.20302673056049253, 'Total loss': 0.20302673056049253}
2023-01-04 00:31:15,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:15,791 INFO:     Epoch: 66
2023-01-04 00:31:17,457 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41605776151021323, 'Total loss': 0.41605776151021323} | train loss {'Reaction outcome loss': 0.20271841817222777, 'Total loss': 0.20271841817222777}
2023-01-04 00:31:17,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:17,458 INFO:     Epoch: 67
2023-01-04 00:31:19,121 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4148726592461268, 'Total loss': 0.4148726592461268} | train loss {'Reaction outcome loss': 0.2030931203104959, 'Total loss': 0.2030931203104959}
2023-01-04 00:31:19,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:19,121 INFO:     Epoch: 68
2023-01-04 00:31:20,785 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40300337548057236, 'Total loss': 0.40300337548057236} | train loss {'Reaction outcome loss': 0.20327378683034264, 'Total loss': 0.20327378683034264}
2023-01-04 00:31:20,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:20,786 INFO:     Epoch: 69
2023-01-04 00:31:22,395 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40157631834348045, 'Total loss': 0.40157631834348045} | train loss {'Reaction outcome loss': 0.20086564879447544, 'Total loss': 0.20086564879447544}
2023-01-04 00:31:22,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:22,395 INFO:     Epoch: 70
2023-01-04 00:31:24,004 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40080010692278545, 'Total loss': 0.40080010692278545} | train loss {'Reaction outcome loss': 0.1992595355204619, 'Total loss': 0.1992595355204619}
2023-01-04 00:31:24,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:24,004 INFO:     Epoch: 71
2023-01-04 00:31:25,631 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39030038118362426, 'Total loss': 0.39030038118362426} | train loss {'Reaction outcome loss': 0.19849489663562836, 'Total loss': 0.19849489663562836}
2023-01-04 00:31:25,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:25,632 INFO:     Epoch: 72
2023-01-04 00:31:27,238 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40435474961996076, 'Total loss': 0.40435474961996076} | train loss {'Reaction outcome loss': 0.19893535029560006, 'Total loss': 0.19893535029560006}
2023-01-04 00:31:27,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:27,239 INFO:     Epoch: 73
2023-01-04 00:31:28,862 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4199075013399124, 'Total loss': 0.4199075013399124} | train loss {'Reaction outcome loss': 0.19567821395418705, 'Total loss': 0.19567821395418705}
2023-01-04 00:31:28,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:28,863 INFO:     Epoch: 74
2023-01-04 00:31:30,438 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40219242572784425, 'Total loss': 0.40219242572784425} | train loss {'Reaction outcome loss': 0.19573015727721396, 'Total loss': 0.19573015727721396}
2023-01-04 00:31:30,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:30,438 INFO:     Epoch: 75
2023-01-04 00:31:32,056 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40237724483013154, 'Total loss': 0.40237724483013154} | train loss {'Reaction outcome loss': 0.19417289505958127, 'Total loss': 0.19417289505958127}
2023-01-04 00:31:32,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:32,056 INFO:     Epoch: 76
2023-01-04 00:31:33,651 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43958727419376376, 'Total loss': 0.43958727419376376} | train loss {'Reaction outcome loss': 0.19407035066117448, 'Total loss': 0.19407035066117448}
2023-01-04 00:31:33,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:33,651 INFO:     Epoch: 77
2023-01-04 00:31:35,282 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43359212776025136, 'Total loss': 0.43359212776025136} | train loss {'Reaction outcome loss': 0.19329541235731829, 'Total loss': 0.19329541235731829}
2023-01-04 00:31:35,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:35,283 INFO:     Epoch: 78
2023-01-04 00:31:36,910 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3918893992900848, 'Total loss': 0.3918893992900848} | train loss {'Reaction outcome loss': 0.19212943223382375, 'Total loss': 0.19212943223382375}
2023-01-04 00:31:36,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:36,910 INFO:     Epoch: 79
2023-01-04 00:31:38,526 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4306051444262266, 'Total loss': 0.4306051444262266} | train loss {'Reaction outcome loss': 0.18945803649938708, 'Total loss': 0.18945803649938708}
2023-01-04 00:31:38,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:38,526 INFO:     Epoch: 80
2023-01-04 00:31:40,127 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41147127449512483, 'Total loss': 0.41147127449512483} | train loss {'Reaction outcome loss': 0.1911924194531105, 'Total loss': 0.1911924194531105}
2023-01-04 00:31:40,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:40,128 INFO:     Epoch: 81
2023-01-04 00:31:41,751 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4252676904201508, 'Total loss': 0.4252676904201508} | train loss {'Reaction outcome loss': 0.19277270649314357, 'Total loss': 0.19277270649314357}
2023-01-04 00:31:41,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:41,751 INFO:     Epoch: 82
2023-01-04 00:31:43,367 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4103446448842684, 'Total loss': 0.4103446448842684} | train loss {'Reaction outcome loss': 0.1880958294260588, 'Total loss': 0.1880958294260588}
2023-01-04 00:31:43,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:43,368 INFO:     Epoch: 83
2023-01-04 00:31:44,998 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42136482894420624, 'Total loss': 0.42136482894420624} | train loss {'Reaction outcome loss': 0.19039458664477088, 'Total loss': 0.19039458664477088}
2023-01-04 00:31:44,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:44,998 INFO:     Epoch: 84
2023-01-04 00:31:46,627 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42976006468137107, 'Total loss': 0.42976006468137107} | train loss {'Reaction outcome loss': 0.18863254765364668, 'Total loss': 0.18863254765364668}
2023-01-04 00:31:46,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:46,627 INFO:     Epoch: 85
2023-01-04 00:31:48,249 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41873784859975177, 'Total loss': 0.41873784859975177} | train loss {'Reaction outcome loss': 0.18866046136144266, 'Total loss': 0.18866046136144266}
2023-01-04 00:31:48,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:48,250 INFO:     Epoch: 86
2023-01-04 00:31:49,863 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.414896551767985, 'Total loss': 0.414896551767985} | train loss {'Reaction outcome loss': 0.18670359238417356, 'Total loss': 0.18670359238417356}
2023-01-04 00:31:49,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:49,863 INFO:     Epoch: 87
2023-01-04 00:31:51,442 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41117186347643536, 'Total loss': 0.41117186347643536} | train loss {'Reaction outcome loss': 0.18600212976282685, 'Total loss': 0.18600212976282685}
2023-01-04 00:31:51,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:51,442 INFO:     Epoch: 88
2023-01-04 00:31:53,040 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.410156969477733, 'Total loss': 0.410156969477733} | train loss {'Reaction outcome loss': 0.1849452031756136, 'Total loss': 0.1849452031756136}
2023-01-04 00:31:53,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:53,040 INFO:     Epoch: 89
2023-01-04 00:31:54,647 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.415971831480662, 'Total loss': 0.415971831480662} | train loss {'Reaction outcome loss': 0.18548417905688502, 'Total loss': 0.18548417905688502}
2023-01-04 00:31:54,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:54,647 INFO:     Epoch: 90
2023-01-04 00:31:56,246 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3971499532461166, 'Total loss': 0.3971499532461166} | train loss {'Reaction outcome loss': 0.18495043844576348, 'Total loss': 0.18495043844576348}
2023-01-04 00:31:56,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:56,246 INFO:     Epoch: 91
2023-01-04 00:31:57,835 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3955293377240499, 'Total loss': 0.3955293377240499} | train loss {'Reaction outcome loss': 0.18241145042870666, 'Total loss': 0.18241145042870666}
2023-01-04 00:31:57,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:57,835 INFO:     Epoch: 92
2023-01-04 00:31:59,434 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4035316169261932, 'Total loss': 0.4035316169261932} | train loss {'Reaction outcome loss': 0.18333997992993692, 'Total loss': 0.18333997992993692}
2023-01-04 00:31:59,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:31:59,435 INFO:     Epoch: 93
2023-01-04 00:32:01,016 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39206870396931964, 'Total loss': 0.39206870396931964} | train loss {'Reaction outcome loss': 0.18186230701310324, 'Total loss': 0.18186230701310324}
2023-01-04 00:32:01,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:01,016 INFO:     Epoch: 94
2023-01-04 00:32:02,615 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4037464494506518, 'Total loss': 0.4037464494506518} | train loss {'Reaction outcome loss': 0.1802050021312297, 'Total loss': 0.1802050021312297}
2023-01-04 00:32:02,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:02,615 INFO:     Epoch: 95
2023-01-04 00:32:04,215 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3998369723558426, 'Total loss': 0.3998369723558426} | train loss {'Reaction outcome loss': 0.1794491763149358, 'Total loss': 0.1794491763149358}
2023-01-04 00:32:04,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:04,215 INFO:     Epoch: 96
2023-01-04 00:32:05,821 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40870359738667805, 'Total loss': 0.40870359738667805} | train loss {'Reaction outcome loss': 0.1777726073988078, 'Total loss': 0.1777726073988078}
2023-01-04 00:32:05,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:05,822 INFO:     Epoch: 97
2023-01-04 00:32:07,415 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40671269297599794, 'Total loss': 0.40671269297599794} | train loss {'Reaction outcome loss': 0.18014450609643645, 'Total loss': 0.18014450609643645}
2023-01-04 00:32:07,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:07,415 INFO:     Epoch: 98
2023-01-04 00:32:09,014 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41747807065645853, 'Total loss': 0.41747807065645853} | train loss {'Reaction outcome loss': 0.17629542511077564, 'Total loss': 0.17629542511077564}
2023-01-04 00:32:09,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:09,014 INFO:     Epoch: 99
2023-01-04 00:32:10,615 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3936347852150599, 'Total loss': 0.3936347852150599} | train loss {'Reaction outcome loss': 0.18044473655817742, 'Total loss': 0.18044473655817742}
2023-01-04 00:32:10,615 INFO:     Best model found after epoch 45 of 100.
2023-01-04 00:32:10,615 INFO:   Done with stage: TRAINING
2023-01-04 00:32:10,615 INFO:   Starting stage: EVALUATION
2023-01-04 00:32:10,737 INFO:   Done with stage: EVALUATION
2023-01-04 00:32:10,737 INFO:   Leaving out SEQ value Fold_6
2023-01-04 00:32:10,750 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 00:32:10,750 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:32:11,402 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:32:11,402 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:32:11,471 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:32:11,471 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:32:11,471 INFO:     No hyperparam tuning for this model
2023-01-04 00:32:11,472 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:32:11,472 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:32:11,472 INFO:     None feature selector for col prot
2023-01-04 00:32:11,472 INFO:     None feature selector for col prot
2023-01-04 00:32:11,473 INFO:     None feature selector for col prot
2023-01-04 00:32:11,473 INFO:     None feature selector for col chem
2023-01-04 00:32:11,473 INFO:     None feature selector for col chem
2023-01-04 00:32:11,473 INFO:     None feature selector for col chem
2023-01-04 00:32:11,473 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:32:11,473 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:32:11,474 INFO:     Number of params in model 70141
2023-01-04 00:32:11,478 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:32:11,478 INFO:   Starting stage: TRAINING
2023-01-04 00:32:11,521 INFO:     Val loss before train {'Reaction outcome loss': 0.9819859663645426, 'Total loss': 0.9819859663645426}
2023-01-04 00:32:11,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:11,522 INFO:     Epoch: 0
2023-01-04 00:32:13,119 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6657172719637553, 'Total loss': 0.6657172719637553} | train loss {'Reaction outcome loss': 0.8505678789123244, 'Total loss': 0.8505678789123244}
2023-01-04 00:32:13,119 INFO:     Found new best model at epoch 0
2023-01-04 00:32:13,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:13,120 INFO:     Epoch: 1
2023-01-04 00:32:14,718 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5525719145933787, 'Total loss': 0.5525719145933787} | train loss {'Reaction outcome loss': 0.6004681000081094, 'Total loss': 0.6004681000081094}
2023-01-04 00:32:14,719 INFO:     Found new best model at epoch 1
2023-01-04 00:32:14,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:14,719 INFO:     Epoch: 2
2023-01-04 00:32:16,300 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5239947736263275, 'Total loss': 0.5239947736263275} | train loss {'Reaction outcome loss': 0.5270206602356705, 'Total loss': 0.5270206602356705}
2023-01-04 00:32:16,300 INFO:     Found new best model at epoch 2
2023-01-04 00:32:16,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:16,301 INFO:     Epoch: 3
2023-01-04 00:32:17,886 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5050634801387787, 'Total loss': 0.5050634801387787} | train loss {'Reaction outcome loss': 0.48903412685014197, 'Total loss': 0.48903412685014197}
2023-01-04 00:32:17,886 INFO:     Found new best model at epoch 3
2023-01-04 00:32:17,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:17,887 INFO:     Epoch: 4
2023-01-04 00:32:19,491 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5058412353197733, 'Total loss': 0.5058412353197733} | train loss {'Reaction outcome loss': 0.4602860347279246, 'Total loss': 0.4602860347279246}
2023-01-04 00:32:19,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:19,492 INFO:     Epoch: 5
2023-01-04 00:32:21,085 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4797000745932261, 'Total loss': 0.4797000745932261} | train loss {'Reaction outcome loss': 0.4429582390732611, 'Total loss': 0.4429582390732611}
2023-01-04 00:32:21,085 INFO:     Found new best model at epoch 5
2023-01-04 00:32:21,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:21,086 INFO:     Epoch: 6
2023-01-04 00:32:22,682 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4715709716081619, 'Total loss': 0.4715709716081619} | train loss {'Reaction outcome loss': 0.4272186882604939, 'Total loss': 0.4272186882604939}
2023-01-04 00:32:22,682 INFO:     Found new best model at epoch 6
2023-01-04 00:32:22,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:22,683 INFO:     Epoch: 7
2023-01-04 00:32:24,263 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45372499426205953, 'Total loss': 0.45372499426205953} | train loss {'Reaction outcome loss': 0.41238788510267826, 'Total loss': 0.41238788510267826}
2023-01-04 00:32:24,264 INFO:     Found new best model at epoch 7
2023-01-04 00:32:24,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:24,264 INFO:     Epoch: 8
2023-01-04 00:32:25,881 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4452312350273132, 'Total loss': 0.4452312350273132} | train loss {'Reaction outcome loss': 0.39902034194033215, 'Total loss': 0.39902034194033215}
2023-01-04 00:32:25,881 INFO:     Found new best model at epoch 8
2023-01-04 00:32:25,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:25,882 INFO:     Epoch: 9
2023-01-04 00:32:27,485 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4458089788754781, 'Total loss': 0.4458089788754781} | train loss {'Reaction outcome loss': 0.3901157895157087, 'Total loss': 0.3901157895157087}
2023-01-04 00:32:27,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:27,485 INFO:     Epoch: 10
2023-01-04 00:32:29,106 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46403748194376626, 'Total loss': 0.46403748194376626} | train loss {'Reaction outcome loss': 0.3822131029235712, 'Total loss': 0.3822131029235712}
2023-01-04 00:32:29,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:29,106 INFO:     Epoch: 11
2023-01-04 00:32:30,724 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4421661376953125, 'Total loss': 0.4421661376953125} | train loss {'Reaction outcome loss': 0.37502087965760333, 'Total loss': 0.37502087965760333}
2023-01-04 00:32:30,725 INFO:     Found new best model at epoch 11
2023-01-04 00:32:30,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:30,726 INFO:     Epoch: 12
2023-01-04 00:32:32,332 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4450908288359642, 'Total loss': 0.4450908288359642} | train loss {'Reaction outcome loss': 0.36863989401878655, 'Total loss': 0.36863989401878655}
2023-01-04 00:32:32,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:32,332 INFO:     Epoch: 13
2023-01-04 00:32:33,926 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42923369308312737, 'Total loss': 0.42923369308312737} | train loss {'Reaction outcome loss': 0.3617220055725277, 'Total loss': 0.3617220055725277}
2023-01-04 00:32:33,926 INFO:     Found new best model at epoch 13
2023-01-04 00:32:33,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:33,927 INFO:     Epoch: 14
2023-01-04 00:32:35,499 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4352318286895752, 'Total loss': 0.4352318286895752} | train loss {'Reaction outcome loss': 0.35395079192476, 'Total loss': 0.35395079192476}
2023-01-04 00:32:35,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:35,499 INFO:     Epoch: 15
2023-01-04 00:32:37,129 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44484615127245586, 'Total loss': 0.44484615127245586} | train loss {'Reaction outcome loss': 0.3446598940299473, 'Total loss': 0.3446598940299473}
2023-01-04 00:32:37,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:37,130 INFO:     Epoch: 16
2023-01-04 00:32:38,743 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42092888553937274, 'Total loss': 0.42092888553937274} | train loss {'Reaction outcome loss': 0.3422261638021893, 'Total loss': 0.3422261638021893}
2023-01-04 00:32:38,743 INFO:     Found new best model at epoch 16
2023-01-04 00:32:38,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:38,744 INFO:     Epoch: 17
2023-01-04 00:32:40,337 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4289356966813405, 'Total loss': 0.4289356966813405} | train loss {'Reaction outcome loss': 0.33591362622067117, 'Total loss': 0.33591362622067117}
2023-01-04 00:32:40,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:40,337 INFO:     Epoch: 18
2023-01-04 00:32:41,956 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4359833478927612, 'Total loss': 0.4359833478927612} | train loss {'Reaction outcome loss': 0.3365901610341625, 'Total loss': 0.3365901610341625}
2023-01-04 00:32:41,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:41,956 INFO:     Epoch: 19
2023-01-04 00:32:43,538 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4280903309583664, 'Total loss': 0.4280903309583664} | train loss {'Reaction outcome loss': 0.3323191547955292, 'Total loss': 0.3323191547955292}
2023-01-04 00:32:43,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:43,538 INFO:     Epoch: 20
2023-01-04 00:32:45,119 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4335548142592112, 'Total loss': 0.4335548142592112} | train loss {'Reaction outcome loss': 0.3290631783235332, 'Total loss': 0.3290631783235332}
2023-01-04 00:32:45,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:45,119 INFO:     Epoch: 21
2023-01-04 00:32:46,715 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42899198134740196, 'Total loss': 0.42899198134740196} | train loss {'Reaction outcome loss': 0.3199351208311492, 'Total loss': 0.3199351208311492}
2023-01-04 00:32:46,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:46,715 INFO:     Epoch: 22
2023-01-04 00:32:48,311 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44321275055408477, 'Total loss': 0.44321275055408477} | train loss {'Reaction outcome loss': 0.3153909490075961, 'Total loss': 0.3153909490075961}
2023-01-04 00:32:48,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:48,312 INFO:     Epoch: 23
2023-01-04 00:32:49,907 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4139904916286469, 'Total loss': 0.4139904916286469} | train loss {'Reaction outcome loss': 0.3113790301579064, 'Total loss': 0.3113790301579064}
2023-01-04 00:32:49,908 INFO:     Found new best model at epoch 23
2023-01-04 00:32:49,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:49,909 INFO:     Epoch: 24
2023-01-04 00:32:51,483 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41339011391003927, 'Total loss': 0.41339011391003927} | train loss {'Reaction outcome loss': 0.30923677411308326, 'Total loss': 0.30923677411308326}
2023-01-04 00:32:51,483 INFO:     Found new best model at epoch 24
2023-01-04 00:32:51,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:51,484 INFO:     Epoch: 25
2023-01-04 00:32:53,096 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43082936604817706, 'Total loss': 0.43082936604817706} | train loss {'Reaction outcome loss': 0.2981894533512905, 'Total loss': 0.2981894533512905}
2023-01-04 00:32:53,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:53,097 INFO:     Epoch: 26
2023-01-04 00:32:54,679 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4298238933086395, 'Total loss': 0.4298238933086395} | train loss {'Reaction outcome loss': 0.2939495723694563, 'Total loss': 0.2939495723694563}
2023-01-04 00:32:54,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:54,679 INFO:     Epoch: 27
2023-01-04 00:32:56,305 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4338059981664022, 'Total loss': 0.4338059981664022} | train loss {'Reaction outcome loss': 0.2912342058928292, 'Total loss': 0.2912342058928292}
2023-01-04 00:32:56,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:56,305 INFO:     Epoch: 28
2023-01-04 00:32:57,925 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4357561270395915, 'Total loss': 0.4357561270395915} | train loss {'Reaction outcome loss': 0.28889392359733523, 'Total loss': 0.28889392359733523}
2023-01-04 00:32:57,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:57,925 INFO:     Epoch: 29
2023-01-04 00:32:59,529 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44494513273239134, 'Total loss': 0.44494513273239134} | train loss {'Reaction outcome loss': 0.2802583864903536, 'Total loss': 0.2802583864903536}
2023-01-04 00:32:59,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:32:59,530 INFO:     Epoch: 30
2023-01-04 00:33:01,122 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4150093247493108, 'Total loss': 0.4150093247493108} | train loss {'Reaction outcome loss': 0.27663207776419335, 'Total loss': 0.27663207776419335}
2023-01-04 00:33:01,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:01,124 INFO:     Epoch: 31
2023-01-04 00:33:02,701 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42282619774341584, 'Total loss': 0.42282619774341584} | train loss {'Reaction outcome loss': 0.27622186626051215, 'Total loss': 0.27622186626051215}
2023-01-04 00:33:02,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:02,701 INFO:     Epoch: 32
2023-01-04 00:33:04,304 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.396025487780571, 'Total loss': 0.396025487780571} | train loss {'Reaction outcome loss': 0.2729841602377364, 'Total loss': 0.2729841602377364}
2023-01-04 00:33:04,304 INFO:     Found new best model at epoch 32
2023-01-04 00:33:04,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:04,305 INFO:     Epoch: 33
2023-01-04 00:33:05,928 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.419637131690979, 'Total loss': 0.419637131690979} | train loss {'Reaction outcome loss': 0.2682934358405043, 'Total loss': 0.2682934358405043}
2023-01-04 00:33:05,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:05,928 INFO:     Epoch: 34
2023-01-04 00:33:07,552 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4188506861527761, 'Total loss': 0.4188506861527761} | train loss {'Reaction outcome loss': 0.28946267467909964, 'Total loss': 0.28946267467909964}
2023-01-04 00:33:07,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:07,553 INFO:     Epoch: 35
2023-01-04 00:33:09,128 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43236574828624724, 'Total loss': 0.43236574828624724} | train loss {'Reaction outcome loss': 0.2619452525227182, 'Total loss': 0.2619452525227182}
2023-01-04 00:33:09,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:09,128 INFO:     Epoch: 36
2023-01-04 00:33:10,752 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39892827769120537, 'Total loss': 0.39892827769120537} | train loss {'Reaction outcome loss': 0.2608417758002769, 'Total loss': 0.2608417758002769}
2023-01-04 00:33:10,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:10,752 INFO:     Epoch: 37
2023-01-04 00:33:12,355 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40339357952276866, 'Total loss': 0.40339357952276866} | train loss {'Reaction outcome loss': 0.2566207581591131, 'Total loss': 0.2566207581591131}
2023-01-04 00:33:12,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:12,356 INFO:     Epoch: 38
2023-01-04 00:33:13,939 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3899295141299566, 'Total loss': 0.3899295141299566} | train loss {'Reaction outcome loss': 0.2550667417640595, 'Total loss': 0.2550667417640595}
2023-01-04 00:33:13,939 INFO:     Found new best model at epoch 38
2023-01-04 00:33:13,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:13,940 INFO:     Epoch: 39
2023-01-04 00:33:15,528 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40090073545773824, 'Total loss': 0.40090073545773824} | train loss {'Reaction outcome loss': 0.25378588528584933, 'Total loss': 0.25378588528584933}
2023-01-04 00:33:15,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:15,528 INFO:     Epoch: 40
2023-01-04 00:33:17,152 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39776264627774555, 'Total loss': 0.39776264627774555} | train loss {'Reaction outcome loss': 0.24869802299940932, 'Total loss': 0.24869802299940932}
2023-01-04 00:33:17,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:17,152 INFO:     Epoch: 41
2023-01-04 00:33:18,750 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4015611837307612, 'Total loss': 0.4015611837307612} | train loss {'Reaction outcome loss': 0.24809584544931093, 'Total loss': 0.24809584544931093}
2023-01-04 00:33:18,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:18,750 INFO:     Epoch: 42
2023-01-04 00:33:20,340 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4244975646336873, 'Total loss': 0.4244975646336873} | train loss {'Reaction outcome loss': 0.2428888674239979, 'Total loss': 0.2428888674239979}
2023-01-04 00:33:20,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:20,341 INFO:     Epoch: 43
2023-01-04 00:33:21,949 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39968596523006755, 'Total loss': 0.39968596523006755} | train loss {'Reaction outcome loss': 0.25345557195174956, 'Total loss': 0.25345557195174956}
2023-01-04 00:33:21,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:21,950 INFO:     Epoch: 44
2023-01-04 00:33:23,575 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3947314957777659, 'Total loss': 0.3947314957777659} | train loss {'Reaction outcome loss': 0.2510602208549508, 'Total loss': 0.2510602208549508}
2023-01-04 00:33:23,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:23,575 INFO:     Epoch: 45
2023-01-04 00:33:25,203 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3912090599536896, 'Total loss': 0.3912090599536896} | train loss {'Reaction outcome loss': 0.23787669323264973, 'Total loss': 0.23787669323264973}
2023-01-04 00:33:25,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:25,203 INFO:     Epoch: 46
2023-01-04 00:33:26,822 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4014822800954183, 'Total loss': 0.4014822800954183} | train loss {'Reaction outcome loss': 0.23768254332674627, 'Total loss': 0.23768254332674627}
2023-01-04 00:33:26,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:26,822 INFO:     Epoch: 47
2023-01-04 00:33:28,400 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3984613686800003, 'Total loss': 0.3984613686800003} | train loss {'Reaction outcome loss': 0.23513975558233907, 'Total loss': 0.23513975558233907}
2023-01-04 00:33:28,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:28,401 INFO:     Epoch: 48
2023-01-04 00:33:30,046 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3978673110405604, 'Total loss': 0.3978673110405604} | train loss {'Reaction outcome loss': 0.23360098071018423, 'Total loss': 0.23360098071018423}
2023-01-04 00:33:30,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:30,046 INFO:     Epoch: 49
2023-01-04 00:33:31,705 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4038607656955719, 'Total loss': 0.4038607656955719} | train loss {'Reaction outcome loss': 0.23026446093791636, 'Total loss': 0.23026446093791636}
2023-01-04 00:33:31,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:31,707 INFO:     Epoch: 50
2023-01-04 00:33:33,285 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39681396782398226, 'Total loss': 0.39681396782398226} | train loss {'Reaction outcome loss': 0.22812753313843606, 'Total loss': 0.22812753313843606}
2023-01-04 00:33:33,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:33,285 INFO:     Epoch: 51
2023-01-04 00:33:34,944 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40392396996418634, 'Total loss': 0.40392396996418634} | train loss {'Reaction outcome loss': 0.22718547601328717, 'Total loss': 0.22718547601328717}
2023-01-04 00:33:34,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:34,944 INFO:     Epoch: 52
2023-01-04 00:33:36,573 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3937893862525622, 'Total loss': 0.3937893862525622} | train loss {'Reaction outcome loss': 0.22500934271627795, 'Total loss': 0.22500934271627795}
2023-01-04 00:33:36,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:36,573 INFO:     Epoch: 53
2023-01-04 00:33:38,196 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40070404261350634, 'Total loss': 0.40070404261350634} | train loss {'Reaction outcome loss': 0.22324026556537097, 'Total loss': 0.22324026556537097}
2023-01-04 00:33:38,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:38,197 INFO:     Epoch: 54
2023-01-04 00:33:39,778 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.416837266087532, 'Total loss': 0.416837266087532} | train loss {'Reaction outcome loss': 0.22072893928152157, 'Total loss': 0.22072893928152157}
2023-01-04 00:33:39,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:39,778 INFO:     Epoch: 55
2023-01-04 00:33:41,372 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4110395093758901, 'Total loss': 0.4110395093758901} | train loss {'Reaction outcome loss': 0.22988891218235527, 'Total loss': 0.22988891218235527}
2023-01-04 00:33:41,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:41,372 INFO:     Epoch: 56
2023-01-04 00:33:42,968 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.401191383600235, 'Total loss': 0.401191383600235} | train loss {'Reaction outcome loss': 0.23256534992707084, 'Total loss': 0.23256534992707084}
2023-01-04 00:33:42,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:42,968 INFO:     Epoch: 57
2023-01-04 00:33:44,563 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4009411563475927, 'Total loss': 0.4009411563475927} | train loss {'Reaction outcome loss': 0.21660841408901024, 'Total loss': 0.21660841408901024}
2023-01-04 00:33:44,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:44,564 INFO:     Epoch: 58
2023-01-04 00:33:46,141 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4207198997338613, 'Total loss': 0.4207198997338613} | train loss {'Reaction outcome loss': 0.23530311894643566, 'Total loss': 0.23530311894643566}
2023-01-04 00:33:46,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:46,141 INFO:     Epoch: 59
2023-01-04 00:33:47,742 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4256547510623932, 'Total loss': 0.4256547510623932} | train loss {'Reaction outcome loss': 0.23881161350594915, 'Total loss': 0.23881161350594915}
2023-01-04 00:33:47,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:47,742 INFO:     Epoch: 60
2023-01-04 00:33:49,361 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39144518971443176, 'Total loss': 0.39144518971443176} | train loss {'Reaction outcome loss': 0.23965204982896862, 'Total loss': 0.23965204982896862}
2023-01-04 00:33:49,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:49,361 INFO:     Epoch: 61
2023-01-04 00:33:50,977 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3985483209292094, 'Total loss': 0.3985483209292094} | train loss {'Reaction outcome loss': 0.2137667958694679, 'Total loss': 0.2137667958694679}
2023-01-04 00:33:50,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:50,978 INFO:     Epoch: 62
2023-01-04 00:33:52,581 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42544947465260824, 'Total loss': 0.42544947465260824} | train loss {'Reaction outcome loss': 0.2087825067979081, 'Total loss': 0.2087825067979081}
2023-01-04 00:33:52,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:52,581 INFO:     Epoch: 63
2023-01-04 00:33:54,159 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4031510651111603, 'Total loss': 0.4031510651111603} | train loss {'Reaction outcome loss': 0.20866767154939883, 'Total loss': 0.20866767154939883}
2023-01-04 00:33:54,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:54,159 INFO:     Epoch: 64
2023-01-04 00:33:55,780 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4004400899012884, 'Total loss': 0.4004400899012884} | train loss {'Reaction outcome loss': 0.20696647976106708, 'Total loss': 0.20696647976106708}
2023-01-04 00:33:55,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:55,780 INFO:     Epoch: 65
2023-01-04 00:33:57,360 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3951656276981036, 'Total loss': 0.3951656276981036} | train loss {'Reaction outcome loss': 0.20323575407678288, 'Total loss': 0.20323575407678288}
2023-01-04 00:33:57,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:57,361 INFO:     Epoch: 66
2023-01-04 00:33:58,958 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3959984451532364, 'Total loss': 0.3959984451532364} | train loss {'Reaction outcome loss': 0.20422124852255866, 'Total loss': 0.20422124852255866}
2023-01-04 00:33:58,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:33:58,958 INFO:     Epoch: 67
2023-01-04 00:34:00,555 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4169268141190211, 'Total loss': 0.4169268141190211} | train loss {'Reaction outcome loss': 0.20303867590627162, 'Total loss': 0.20303867590627162}
2023-01-04 00:34:00,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:00,555 INFO:     Epoch: 68
2023-01-04 00:34:02,151 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.422599995136261, 'Total loss': 0.422599995136261} | train loss {'Reaction outcome loss': 0.20424287021160126, 'Total loss': 0.20424287021160126}
2023-01-04 00:34:02,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:02,152 INFO:     Epoch: 69
2023-01-04 00:34:03,732 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42158147096633913, 'Total loss': 0.42158147096633913} | train loss {'Reaction outcome loss': 0.20302077315821973, 'Total loss': 0.20302077315821973}
2023-01-04 00:34:03,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:03,732 INFO:     Epoch: 70
2023-01-04 00:34:05,334 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42114413728316624, 'Total loss': 0.42114413728316624} | train loss {'Reaction outcome loss': 0.19889653060565013, 'Total loss': 0.19889653060565013}
2023-01-04 00:34:05,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:05,334 INFO:     Epoch: 71
2023-01-04 00:34:06,924 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41692645152409874, 'Total loss': 0.41692645152409874} | train loss {'Reaction outcome loss': 0.1979869342783628, 'Total loss': 0.1979869342783628}
2023-01-04 00:34:06,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:06,924 INFO:     Epoch: 72
2023-01-04 00:34:08,550 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41508789857228595, 'Total loss': 0.41508789857228595} | train loss {'Reaction outcome loss': 0.19819418159802782, 'Total loss': 0.19819418159802782}
2023-01-04 00:34:08,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:08,551 INFO:     Epoch: 73
2023-01-04 00:34:10,171 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4000148137410482, 'Total loss': 0.4000148137410482} | train loss {'Reaction outcome loss': 0.19779752599804298, 'Total loss': 0.19779752599804298}
2023-01-04 00:34:10,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:10,171 INFO:     Epoch: 74
2023-01-04 00:34:11,770 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4146195868651072, 'Total loss': 0.4146195868651072} | train loss {'Reaction outcome loss': 0.20208248790299546, 'Total loss': 0.20208248790299546}
2023-01-04 00:34:11,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:11,771 INFO:     Epoch: 75
2023-01-04 00:34:13,363 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40860664546489717, 'Total loss': 0.40860664546489717} | train loss {'Reaction outcome loss': 0.21253439754861797, 'Total loss': 0.21253439754861797}
2023-01-04 00:34:13,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:13,363 INFO:     Epoch: 76
2023-01-04 00:34:14,964 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4048174053430557, 'Total loss': 0.4048174053430557} | train loss {'Reaction outcome loss': 0.19847929003931905, 'Total loss': 0.19847929003931905}
2023-01-04 00:34:14,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:14,964 INFO:     Epoch: 77
2023-01-04 00:34:16,579 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40965462625026705, 'Total loss': 0.40965462625026705} | train loss {'Reaction outcome loss': 0.19679780218048373, 'Total loss': 0.19679780218048373}
2023-01-04 00:34:16,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:16,580 INFO:     Epoch: 78
2023-01-04 00:34:18,175 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40144568582375845, 'Total loss': 0.40144568582375845} | train loss {'Reaction outcome loss': 0.19718881088747497, 'Total loss': 0.19718881088747497}
2023-01-04 00:34:18,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:18,175 INFO:     Epoch: 79
2023-01-04 00:34:19,770 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4310381124416987, 'Total loss': 0.4310381124416987} | train loss {'Reaction outcome loss': 0.1910493386824163, 'Total loss': 0.1910493386824163}
2023-01-04 00:34:19,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:19,770 INFO:     Epoch: 80
2023-01-04 00:34:21,348 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3969026709596316, 'Total loss': 0.3969026709596316} | train loss {'Reaction outcome loss': 0.1902425200610921, 'Total loss': 0.1902425200610921}
2023-01-04 00:34:21,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:21,349 INFO:     Epoch: 81
2023-01-04 00:34:22,942 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40934829612572987, 'Total loss': 0.40934829612572987} | train loss {'Reaction outcome loss': 0.18983113414405112, 'Total loss': 0.18983113414405112}
2023-01-04 00:34:22,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:22,943 INFO:     Epoch: 82
2023-01-04 00:34:24,520 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40415624976158143, 'Total loss': 0.40415624976158143} | train loss {'Reaction outcome loss': 0.18997876376058717, 'Total loss': 0.18997876376058717}
2023-01-04 00:34:24,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:24,520 INFO:     Epoch: 83
2023-01-04 00:34:26,115 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3910360107819239, 'Total loss': 0.3910360107819239} | train loss {'Reaction outcome loss': 0.18959458431471948, 'Total loss': 0.18959458431471948}
2023-01-04 00:34:26,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:26,116 INFO:     Epoch: 84
2023-01-04 00:34:27,731 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4371180276075999, 'Total loss': 0.4371180276075999} | train loss {'Reaction outcome loss': 0.18783758073073611, 'Total loss': 0.18783758073073611}
2023-01-04 00:34:27,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:27,731 INFO:     Epoch: 85
2023-01-04 00:34:29,351 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41260802348454795, 'Total loss': 0.41260802348454795} | train loss {'Reaction outcome loss': 0.18834248723251748, 'Total loss': 0.18834248723251748}
2023-01-04 00:34:29,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:29,352 INFO:     Epoch: 86
2023-01-04 00:34:30,947 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4233013649781545, 'Total loss': 0.4233013649781545} | train loss {'Reaction outcome loss': 0.18704098022008903, 'Total loss': 0.18704098022008903}
2023-01-04 00:34:30,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:30,947 INFO:     Epoch: 87
2023-01-04 00:34:32,551 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4085841079552968, 'Total loss': 0.4085841079552968} | train loss {'Reaction outcome loss': 0.18524276519410482, 'Total loss': 0.18524276519410482}
2023-01-04 00:34:32,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:32,551 INFO:     Epoch: 88
2023-01-04 00:34:34,166 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4120234251022339, 'Total loss': 0.4120234251022339} | train loss {'Reaction outcome loss': 0.18663223947130947, 'Total loss': 0.18663223947130947}
2023-01-04 00:34:34,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:34,167 INFO:     Epoch: 89
2023-01-04 00:34:35,788 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41941402554512025, 'Total loss': 0.41941402554512025} | train loss {'Reaction outcome loss': 0.1852884017195944, 'Total loss': 0.1852884017195944}
2023-01-04 00:34:35,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:35,788 INFO:     Epoch: 90
2023-01-04 00:34:37,377 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3935892581939697, 'Total loss': 0.3935892581939697} | train loss {'Reaction outcome loss': 0.1824129517384184, 'Total loss': 0.1824129517384184}
2023-01-04 00:34:37,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:37,377 INFO:     Epoch: 91
2023-01-04 00:34:38,974 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43161752820014954, 'Total loss': 0.43161752820014954} | train loss {'Reaction outcome loss': 0.18223004108807325, 'Total loss': 0.18223004108807325}
2023-01-04 00:34:38,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:38,976 INFO:     Epoch: 92
2023-01-04 00:34:40,054 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4118740916252136, 'Total loss': 0.4118740916252136} | train loss {'Reaction outcome loss': 0.1836726041055163, 'Total loss': 0.1836726041055163}
2023-01-04 00:34:40,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:40,055 INFO:     Epoch: 93
2023-01-04 00:34:41,141 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4342529892921448, 'Total loss': 0.4342529892921448} | train loss {'Reaction outcome loss': 0.18301774873955012, 'Total loss': 0.18301774873955012}
2023-01-04 00:34:41,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:41,141 INFO:     Epoch: 94
2023-01-04 00:34:42,212 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41146399974823, 'Total loss': 0.41146399974823} | train loss {'Reaction outcome loss': 0.18100346238972395, 'Total loss': 0.18100346238972395}
2023-01-04 00:34:42,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:42,212 INFO:     Epoch: 95
2023-01-04 00:34:43,279 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42761566241582233, 'Total loss': 0.42761566241582233} | train loss {'Reaction outcome loss': 0.18927504806576864, 'Total loss': 0.18927504806576864}
2023-01-04 00:34:43,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:43,279 INFO:     Epoch: 96
2023-01-04 00:34:44,780 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40005278488000234, 'Total loss': 0.40005278488000234} | train loss {'Reaction outcome loss': 0.20954096655401847, 'Total loss': 0.20954096655401847}
2023-01-04 00:34:44,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:44,780 INFO:     Epoch: 97
2023-01-04 00:34:46,371 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4067561899622281, 'Total loss': 0.4067561899622281} | train loss {'Reaction outcome loss': 0.18695039779835287, 'Total loss': 0.18695039779835287}
2023-01-04 00:34:46,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:46,372 INFO:     Epoch: 98
2023-01-04 00:34:47,963 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41434625486532844, 'Total loss': 0.41434625486532844} | train loss {'Reaction outcome loss': 0.1787510339362189, 'Total loss': 0.1787510339362189}
2023-01-04 00:34:47,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:47,963 INFO:     Epoch: 99
2023-01-04 00:34:49,534 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4068434943755468, 'Total loss': 0.4068434943755468} | train loss {'Reaction outcome loss': 0.1737036447064357, 'Total loss': 0.1737036447064357}
2023-01-04 00:34:49,534 INFO:     Best model found after epoch 39 of 100.
2023-01-04 00:34:49,534 INFO:   Done with stage: TRAINING
2023-01-04 00:34:49,534 INFO:   Starting stage: EVALUATION
2023-01-04 00:34:49,664 INFO:   Done with stage: EVALUATION
2023-01-04 00:34:49,664 INFO:   Leaving out SEQ value Fold_7
2023-01-04 00:34:49,677 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 00:34:49,677 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:34:50,331 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:34:50,331 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:34:50,401 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:34:50,402 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:34:50,402 INFO:     No hyperparam tuning for this model
2023-01-04 00:34:50,402 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:34:50,402 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:34:50,402 INFO:     None feature selector for col prot
2023-01-04 00:34:50,403 INFO:     None feature selector for col prot
2023-01-04 00:34:50,403 INFO:     None feature selector for col prot
2023-01-04 00:34:50,403 INFO:     None feature selector for col chem
2023-01-04 00:34:50,403 INFO:     None feature selector for col chem
2023-01-04 00:34:50,403 INFO:     None feature selector for col chem
2023-01-04 00:34:50,403 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:34:50,403 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:34:50,404 INFO:     Number of params in model 70141
2023-01-04 00:34:50,408 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:34:50,408 INFO:   Starting stage: TRAINING
2023-01-04 00:34:50,451 INFO:     Val loss before train {'Reaction outcome loss': 1.02250421444575, 'Total loss': 1.02250421444575}
2023-01-04 00:34:50,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:50,451 INFO:     Epoch: 0
2023-01-04 00:34:52,037 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6845471858978271, 'Total loss': 0.6845471858978271} | train loss {'Reaction outcome loss': 0.8224311399853964, 'Total loss': 0.8224311399853964}
2023-01-04 00:34:52,037 INFO:     Found new best model at epoch 0
2023-01-04 00:34:52,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:52,038 INFO:     Epoch: 1
2023-01-04 00:34:53,647 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5860020260016123, 'Total loss': 0.5860020260016123} | train loss {'Reaction outcome loss': 0.5845803009427112, 'Total loss': 0.5845803009427112}
2023-01-04 00:34:53,647 INFO:     Found new best model at epoch 1
2023-01-04 00:34:53,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:53,648 INFO:     Epoch: 2
2023-01-04 00:34:55,248 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5368019898732503, 'Total loss': 0.5368019898732503} | train loss {'Reaction outcome loss': 0.5275365479722403, 'Total loss': 0.5275365479722403}
2023-01-04 00:34:55,248 INFO:     Found new best model at epoch 2
2023-01-04 00:34:55,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:55,249 INFO:     Epoch: 3
2023-01-04 00:34:56,830 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5001404196023941, 'Total loss': 0.5001404196023941} | train loss {'Reaction outcome loss': 0.4884892163285311, 'Total loss': 0.4884892163285311}
2023-01-04 00:34:56,831 INFO:     Found new best model at epoch 3
2023-01-04 00:34:56,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:56,831 INFO:     Epoch: 4
2023-01-04 00:34:58,442 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48866678873697916, 'Total loss': 0.48866678873697916} | train loss {'Reaction outcome loss': 0.4600701427384131, 'Total loss': 0.4600701427384131}
2023-01-04 00:34:58,442 INFO:     Found new best model at epoch 4
2023-01-04 00:34:58,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:34:58,443 INFO:     Epoch: 5
2023-01-04 00:35:00,047 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5059183458487193, 'Total loss': 0.5059183458487193} | train loss {'Reaction outcome loss': 0.44284219282638765, 'Total loss': 0.44284219282638765}
2023-01-04 00:35:00,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:00,047 INFO:     Epoch: 6
2023-01-04 00:35:01,646 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5017151415348053, 'Total loss': 0.5017151415348053} | train loss {'Reaction outcome loss': 0.4281412436934775, 'Total loss': 0.4281412436934775}
2023-01-04 00:35:01,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:01,647 INFO:     Epoch: 7
2023-01-04 00:35:03,236 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47591010530789696, 'Total loss': 0.47591010530789696} | train loss {'Reaction outcome loss': 0.41535686359123286, 'Total loss': 0.41535686359123286}
2023-01-04 00:35:03,236 INFO:     Found new best model at epoch 7
2023-01-04 00:35:03,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:03,237 INFO:     Epoch: 8
2023-01-04 00:35:04,825 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46198460360368093, 'Total loss': 0.46198460360368093} | train loss {'Reaction outcome loss': 0.4040284480248321, 'Total loss': 0.4040284480248321}
2023-01-04 00:35:04,826 INFO:     Found new best model at epoch 8
2023-01-04 00:35:04,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:04,827 INFO:     Epoch: 9
2023-01-04 00:35:06,419 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46617458363374076, 'Total loss': 0.46617458363374076} | train loss {'Reaction outcome loss': 0.39571201037683024, 'Total loss': 0.39571201037683024}
2023-01-04 00:35:06,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:06,419 INFO:     Epoch: 10
2023-01-04 00:35:08,031 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4574461082617442, 'Total loss': 0.4574461082617442} | train loss {'Reaction outcome loss': 0.3849286833319111, 'Total loss': 0.3849286833319111}
2023-01-04 00:35:08,031 INFO:     Found new best model at epoch 10
2023-01-04 00:35:08,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:08,032 INFO:     Epoch: 11
2023-01-04 00:35:09,614 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.448491045832634, 'Total loss': 0.448491045832634} | train loss {'Reaction outcome loss': 0.37542554413548845, 'Total loss': 0.37542554413548845}
2023-01-04 00:35:09,614 INFO:     Found new best model at epoch 11
2023-01-04 00:35:09,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:09,615 INFO:     Epoch: 12
2023-01-04 00:35:11,182 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4972676436106364, 'Total loss': 0.4972676436106364} | train loss {'Reaction outcome loss': 0.37510013277979865, 'Total loss': 0.37510013277979865}
2023-01-04 00:35:11,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:11,182 INFO:     Epoch: 13
2023-01-04 00:35:12,799 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47383956909179686, 'Total loss': 0.47383956909179686} | train loss {'Reaction outcome loss': 0.3757019990488239, 'Total loss': 0.3757019990488239}
2023-01-04 00:35:12,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:12,800 INFO:     Epoch: 14
2023-01-04 00:35:14,418 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4672122170527776, 'Total loss': 0.4672122170527776} | train loss {'Reaction outcome loss': 0.35715329478008917, 'Total loss': 0.35715329478008917}
2023-01-04 00:35:14,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:14,419 INFO:     Epoch: 15
2023-01-04 00:35:16,021 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45883530179659526, 'Total loss': 0.45883530179659526} | train loss {'Reaction outcome loss': 0.35074495820310037, 'Total loss': 0.35074495820310037}
2023-01-04 00:35:16,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:16,021 INFO:     Epoch: 16
2023-01-04 00:35:17,626 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4497357904911041, 'Total loss': 0.4497357904911041} | train loss {'Reaction outcome loss': 0.3437752378429624, 'Total loss': 0.3437752378429624}
2023-01-04 00:35:17,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:17,626 INFO:     Epoch: 17
2023-01-04 00:35:19,219 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44872448543707527, 'Total loss': 0.44872448543707527} | train loss {'Reaction outcome loss': 0.33888474649385264, 'Total loss': 0.33888474649385264}
2023-01-04 00:35:19,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:19,219 INFO:     Epoch: 18
2023-01-04 00:35:20,857 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42594924370447795, 'Total loss': 0.42594924370447795} | train loss {'Reaction outcome loss': 0.3346987167049361, 'Total loss': 0.3346987167049361}
2023-01-04 00:35:20,858 INFO:     Found new best model at epoch 18
2023-01-04 00:35:20,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:20,859 INFO:     Epoch: 19
2023-01-04 00:35:22,486 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4467733561992645, 'Total loss': 0.4467733561992645} | train loss {'Reaction outcome loss': 0.3267109468511805, 'Total loss': 0.3267109468511805}
2023-01-04 00:35:22,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:22,486 INFO:     Epoch: 20
2023-01-04 00:35:24,100 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44867975314458214, 'Total loss': 0.44867975314458214} | train loss {'Reaction outcome loss': 0.32167092603007064, 'Total loss': 0.32167092603007064}
2023-01-04 00:35:24,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:24,101 INFO:     Epoch: 21
2023-01-04 00:35:25,721 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43604707618554434, 'Total loss': 0.43604707618554434} | train loss {'Reaction outcome loss': 0.319528357355275, 'Total loss': 0.319528357355275}
2023-01-04 00:35:25,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:25,721 INFO:     Epoch: 22
2023-01-04 00:35:27,315 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.425640136996905, 'Total loss': 0.425640136996905} | train loss {'Reaction outcome loss': 0.3211715958364632, 'Total loss': 0.3211715958364632}
2023-01-04 00:35:27,315 INFO:     Found new best model at epoch 22
2023-01-04 00:35:27,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:27,316 INFO:     Epoch: 23
2023-01-04 00:35:28,891 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4592002511024475, 'Total loss': 0.4592002511024475} | train loss {'Reaction outcome loss': 0.33933332783804426, 'Total loss': 0.33933332783804426}
2023-01-04 00:35:28,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:28,892 INFO:     Epoch: 24
2023-01-04 00:35:30,477 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4306359817584356, 'Total loss': 0.4306359817584356} | train loss {'Reaction outcome loss': 0.3096193029558745, 'Total loss': 0.3096193029558745}
2023-01-04 00:35:30,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:30,477 INFO:     Epoch: 25
2023-01-04 00:35:32,068 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4455342928568522, 'Total loss': 0.4455342928568522} | train loss {'Reaction outcome loss': 0.30196213430684543, 'Total loss': 0.30196213430684543}
2023-01-04 00:35:32,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:32,068 INFO:     Epoch: 26
2023-01-04 00:35:33,673 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4366773625214895, 'Total loss': 0.4366773625214895} | train loss {'Reaction outcome loss': 0.29729819843824784, 'Total loss': 0.29729819843824784}
2023-01-04 00:35:33,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:33,674 INFO:     Epoch: 27
2023-01-04 00:35:35,291 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4348978102207184, 'Total loss': 0.4348978102207184} | train loss {'Reaction outcome loss': 0.2937030718945291, 'Total loss': 0.2937030718945291}
2023-01-04 00:35:35,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:35,291 INFO:     Epoch: 28
2023-01-04 00:35:36,899 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42144322792689004, 'Total loss': 0.42144322792689004} | train loss {'Reaction outcome loss': 0.28909406338588917, 'Total loss': 0.28909406338588917}
2023-01-04 00:35:36,899 INFO:     Found new best model at epoch 28
2023-01-04 00:35:36,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:36,900 INFO:     Epoch: 29
2023-01-04 00:35:38,506 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.435974183678627, 'Total loss': 0.435974183678627} | train loss {'Reaction outcome loss': 0.28732706739337766, 'Total loss': 0.28732706739337766}
2023-01-04 00:35:38,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:38,506 INFO:     Epoch: 30
2023-01-04 00:35:40,116 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42404446204503377, 'Total loss': 0.42404446204503377} | train loss {'Reaction outcome loss': 0.28357258199025637, 'Total loss': 0.28357258199025637}
2023-01-04 00:35:40,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:40,117 INFO:     Epoch: 31
2023-01-04 00:35:41,716 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43032878935337066, 'Total loss': 0.43032878935337066} | train loss {'Reaction outcome loss': 0.28053965553155413, 'Total loss': 0.28053965553155413}
2023-01-04 00:35:41,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:41,716 INFO:     Epoch: 32
2023-01-04 00:35:43,321 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41557726860046384, 'Total loss': 0.41557726860046384} | train loss {'Reaction outcome loss': 0.279285813641289, 'Total loss': 0.279285813641289}
2023-01-04 00:35:43,321 INFO:     Found new best model at epoch 32
2023-01-04 00:35:43,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:43,322 INFO:     Epoch: 33
2023-01-04 00:35:44,916 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44641690850257876, 'Total loss': 0.44641690850257876} | train loss {'Reaction outcome loss': 0.27610072334402136, 'Total loss': 0.27610072334402136}
2023-01-04 00:35:44,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:44,917 INFO:     Epoch: 34
2023-01-04 00:35:46,498 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4294428646564484, 'Total loss': 0.4294428646564484} | train loss {'Reaction outcome loss': 0.270926413051764, 'Total loss': 0.270926413051764}
2023-01-04 00:35:46,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:46,498 INFO:     Epoch: 35
2023-01-04 00:35:48,091 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4247444103161494, 'Total loss': 0.4247444103161494} | train loss {'Reaction outcome loss': 0.2662787251714347, 'Total loss': 0.2662787251714347}
2023-01-04 00:35:48,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:48,091 INFO:     Epoch: 36
2023-01-04 00:35:49,684 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4319772134224574, 'Total loss': 0.4319772134224574} | train loss {'Reaction outcome loss': 0.2648625716742506, 'Total loss': 0.2648625716742506}
2023-01-04 00:35:49,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:49,684 INFO:     Epoch: 37
2023-01-04 00:35:51,273 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.404208176334699, 'Total loss': 0.404208176334699} | train loss {'Reaction outcome loss': 0.2609601985108148, 'Total loss': 0.2609601985108148}
2023-01-04 00:35:51,274 INFO:     Found new best model at epoch 37
2023-01-04 00:35:51,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:51,275 INFO:     Epoch: 38
2023-01-04 00:35:52,889 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42982240319252013, 'Total loss': 0.42982240319252013} | train loss {'Reaction outcome loss': 0.2569852543157944, 'Total loss': 0.2569852543157944}
2023-01-04 00:35:52,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:52,889 INFO:     Epoch: 39
2023-01-04 00:35:54,509 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42600420912106834, 'Total loss': 0.42600420912106834} | train loss {'Reaction outcome loss': 0.27349873409485037, 'Total loss': 0.27349873409485037}
2023-01-04 00:35:54,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:54,509 INFO:     Epoch: 40
2023-01-04 00:35:56,104 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4569737454255422, 'Total loss': 0.4569737454255422} | train loss {'Reaction outcome loss': 0.2681751036071691, 'Total loss': 0.2681751036071691}
2023-01-04 00:35:56,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:56,105 INFO:     Epoch: 41
2023-01-04 00:35:57,695 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4274381031592687, 'Total loss': 0.4274381031592687} | train loss {'Reaction outcome loss': 0.251513487699887, 'Total loss': 0.251513487699887}
2023-01-04 00:35:57,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:57,696 INFO:     Epoch: 42
2023-01-04 00:35:59,293 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44044417639573413, 'Total loss': 0.44044417639573413} | train loss {'Reaction outcome loss': 0.24951146034763425, 'Total loss': 0.24951146034763425}
2023-01-04 00:35:59,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:35:59,293 INFO:     Epoch: 43
2023-01-04 00:36:00,883 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42981492082277933, 'Total loss': 0.42981492082277933} | train loss {'Reaction outcome loss': 0.2457374567295899, 'Total loss': 0.2457374567295899}
2023-01-04 00:36:00,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:00,884 INFO:     Epoch: 44
2023-01-04 00:36:02,484 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43761400183041893, 'Total loss': 0.43761400183041893} | train loss {'Reaction outcome loss': 0.24201200679754434, 'Total loss': 0.24201200679754434}
2023-01-04 00:36:02,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:02,484 INFO:     Epoch: 45
2023-01-04 00:36:04,095 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4359926442305247, 'Total loss': 0.4359926442305247} | train loss {'Reaction outcome loss': 0.24458891156709928, 'Total loss': 0.24458891156709928}
2023-01-04 00:36:04,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:04,096 INFO:     Epoch: 46
2023-01-04 00:36:05,706 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4326408803462982, 'Total loss': 0.4326408803462982} | train loss {'Reaction outcome loss': 0.24265528021488283, 'Total loss': 0.24265528021488283}
2023-01-04 00:36:05,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:05,706 INFO:     Epoch: 47
2023-01-04 00:36:07,294 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44318618178367614, 'Total loss': 0.44318618178367614} | train loss {'Reaction outcome loss': 0.2350190269728731, 'Total loss': 0.2350190269728731}
2023-01-04 00:36:07,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:07,295 INFO:     Epoch: 48
2023-01-04 00:36:08,881 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4312689850727717, 'Total loss': 0.4312689850727717} | train loss {'Reaction outcome loss': 0.23638490458572473, 'Total loss': 0.23638490458572473}
2023-01-04 00:36:08,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:08,881 INFO:     Epoch: 49
2023-01-04 00:36:10,485 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4239738752444585, 'Total loss': 0.4239738752444585} | train loss {'Reaction outcome loss': 0.2339339553668717, 'Total loss': 0.2339339553668717}
2023-01-04 00:36:10,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:10,485 INFO:     Epoch: 50
2023-01-04 00:36:12,071 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4261802216370901, 'Total loss': 0.4261802216370901} | train loss {'Reaction outcome loss': 0.23182530706390683, 'Total loss': 0.23182530706390683}
2023-01-04 00:36:12,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:12,071 INFO:     Epoch: 51
2023-01-04 00:36:13,667 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.443793644507726, 'Total loss': 0.443793644507726} | train loss {'Reaction outcome loss': 0.2399837486580878, 'Total loss': 0.2399837486580878}
2023-01-04 00:36:13,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:13,667 INFO:     Epoch: 52
2023-01-04 00:36:15,280 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43014762699604037, 'Total loss': 0.43014762699604037} | train loss {'Reaction outcome loss': 0.24771067799883895, 'Total loss': 0.24771067799883895}
2023-01-04 00:36:15,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:15,282 INFO:     Epoch: 53
2023-01-04 00:36:16,895 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4321207682291667, 'Total loss': 0.4321207682291667} | train loss {'Reaction outcome loss': 0.22793655582042277, 'Total loss': 0.22793655582042277}
2023-01-04 00:36:16,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:16,895 INFO:     Epoch: 54
2023-01-04 00:36:18,481 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4395559191703796, 'Total loss': 0.4395559191703796} | train loss {'Reaction outcome loss': 0.2264517950885499, 'Total loss': 0.2264517950885499}
2023-01-04 00:36:18,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:18,481 INFO:     Epoch: 55
2023-01-04 00:36:20,106 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41935271124045054, 'Total loss': 0.41935271124045054} | train loss {'Reaction outcome loss': 0.22273479578375438, 'Total loss': 0.22273479578375438}
2023-01-04 00:36:20,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:20,106 INFO:     Epoch: 56
2023-01-04 00:36:21,715 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4273461252450943, 'Total loss': 0.4273461252450943} | train loss {'Reaction outcome loss': 0.22207015440284705, 'Total loss': 0.22207015440284705}
2023-01-04 00:36:21,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:21,715 INFO:     Epoch: 57
2023-01-04 00:36:23,311 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4479374607404073, 'Total loss': 0.4479374607404073} | train loss {'Reaction outcome loss': 0.2184435697576112, 'Total loss': 0.2184435697576112}
2023-01-04 00:36:23,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:23,311 INFO:     Epoch: 58
2023-01-04 00:36:24,927 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43336844742298125, 'Total loss': 0.43336844742298125} | train loss {'Reaction outcome loss': 0.21736013354645853, 'Total loss': 0.21736013354645853}
2023-01-04 00:36:24,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:24,927 INFO:     Epoch: 59
2023-01-04 00:36:26,522 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46620832085609437, 'Total loss': 0.46620832085609437} | train loss {'Reaction outcome loss': 0.21725753126067002, 'Total loss': 0.21725753126067002}
2023-01-04 00:36:26,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:26,522 INFO:     Epoch: 60
2023-01-04 00:36:28,107 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43675475716590884, 'Total loss': 0.43675475716590884} | train loss {'Reaction outcome loss': 0.2141836058418857, 'Total loss': 0.2141836058418857}
2023-01-04 00:36:28,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:28,107 INFO:     Epoch: 61
2023-01-04 00:36:29,699 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45529395739237466, 'Total loss': 0.45529395739237466} | train loss {'Reaction outcome loss': 0.22481178746059322, 'Total loss': 0.22481178746059322}
2023-01-04 00:36:29,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:29,700 INFO:     Epoch: 62
2023-01-04 00:36:31,272 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42232879300912224, 'Total loss': 0.42232879300912224} | train loss {'Reaction outcome loss': 0.2283137683932538, 'Total loss': 0.2283137683932538}
2023-01-04 00:36:31,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:31,273 INFO:     Epoch: 63
2023-01-04 00:36:32,891 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41876757740974424, 'Total loss': 0.41876757740974424} | train loss {'Reaction outcome loss': 0.21076827275944685, 'Total loss': 0.21076827275944685}
2023-01-04 00:36:32,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:32,891 INFO:     Epoch: 64
2023-01-04 00:36:34,506 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4398106257120768, 'Total loss': 0.4398106257120768} | train loss {'Reaction outcome loss': 0.20887924455430196, 'Total loss': 0.20887924455430196}
2023-01-04 00:36:34,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:34,507 INFO:     Epoch: 65
2023-01-04 00:36:36,095 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43821313480536145, 'Total loss': 0.43821313480536145} | train loss {'Reaction outcome loss': 0.20952738758406023, 'Total loss': 0.20952738758406023}
2023-01-04 00:36:36,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:36,096 INFO:     Epoch: 66
2023-01-04 00:36:37,693 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.436337822675705, 'Total loss': 0.436337822675705} | train loss {'Reaction outcome loss': 0.20608162384588216, 'Total loss': 0.20608162384588216}
2023-01-04 00:36:37,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:37,694 INFO:     Epoch: 67
2023-01-04 00:36:39,312 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.443414568901062, 'Total loss': 0.443414568901062} | train loss {'Reaction outcome loss': 0.20730151464733249, 'Total loss': 0.20730151464733249}
2023-01-04 00:36:39,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:39,313 INFO:     Epoch: 68
2023-01-04 00:36:40,894 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41995001832644147, 'Total loss': 0.41995001832644147} | train loss {'Reaction outcome loss': 0.20168753375933654, 'Total loss': 0.20168753375933654}
2023-01-04 00:36:40,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:40,894 INFO:     Epoch: 69
2023-01-04 00:36:42,484 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42657694121201833, 'Total loss': 0.42657694121201833} | train loss {'Reaction outcome loss': 0.20253097549510235, 'Total loss': 0.20253097549510235}
2023-01-04 00:36:42,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:42,484 INFO:     Epoch: 70
2023-01-04 00:36:44,077 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45506591101487476, 'Total loss': 0.45506591101487476} | train loss {'Reaction outcome loss': 0.20114909667197778, 'Total loss': 0.20114909667197778}
2023-01-04 00:36:44,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:44,077 INFO:     Epoch: 71
2023-01-04 00:36:45,675 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4187299201885859, 'Total loss': 0.4187299201885859} | train loss {'Reaction outcome loss': 0.1991929141804576, 'Total loss': 0.1991929141804576}
2023-01-04 00:36:45,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:45,675 INFO:     Epoch: 72
2023-01-04 00:36:47,268 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4483201617995898, 'Total loss': 0.4483201617995898} | train loss {'Reaction outcome loss': 0.20018219986282612, 'Total loss': 0.20018219986282612}
2023-01-04 00:36:47,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:47,269 INFO:     Epoch: 73
2023-01-04 00:36:48,846 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42850058476130165, 'Total loss': 0.42850058476130165} | train loss {'Reaction outcome loss': 0.1999403760362285, 'Total loss': 0.1999403760362285}
2023-01-04 00:36:48,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:48,846 INFO:     Epoch: 74
2023-01-04 00:36:50,426 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4415700105329355, 'Total loss': 0.4415700105329355} | train loss {'Reaction outcome loss': 0.199226893376613, 'Total loss': 0.199226893376613}
2023-01-04 00:36:50,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:50,426 INFO:     Epoch: 75
2023-01-04 00:36:52,020 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4499854862689972, 'Total loss': 0.4499854862689972} | train loss {'Reaction outcome loss': 0.19786199013712272, 'Total loss': 0.19786199013712272}
2023-01-04 00:36:52,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:52,021 INFO:     Epoch: 76
2023-01-04 00:36:53,616 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4353565932561954, 'Total loss': 0.4353565932561954} | train loss {'Reaction outcome loss': 0.19765345381808624, 'Total loss': 0.19765345381808624}
2023-01-04 00:36:53,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:53,616 INFO:     Epoch: 77
2023-01-04 00:36:55,205 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4269092967112859, 'Total loss': 0.4269092967112859} | train loss {'Reaction outcome loss': 0.1950753817686548, 'Total loss': 0.1950753817686548}
2023-01-04 00:36:55,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:55,205 INFO:     Epoch: 78
2023-01-04 00:36:56,796 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4539343327283859, 'Total loss': 0.4539343327283859} | train loss {'Reaction outcome loss': 0.19332687412953828, 'Total loss': 0.19332687412953828}
2023-01-04 00:36:56,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:56,796 INFO:     Epoch: 79
2023-01-04 00:36:58,370 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4477761427561442, 'Total loss': 0.4477761427561442} | train loss {'Reaction outcome loss': 0.1930831917861065, 'Total loss': 0.1930831917861065}
2023-01-04 00:36:58,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:58,371 INFO:     Epoch: 80
2023-01-04 00:36:59,960 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4590777814388275, 'Total loss': 0.4590777814388275} | train loss {'Reaction outcome loss': 0.19374200381861412, 'Total loss': 0.19374200381861412}
2023-01-04 00:36:59,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:36:59,961 INFO:     Epoch: 81
2023-01-04 00:37:01,551 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44719640413920086, 'Total loss': 0.44719640413920086} | train loss {'Reaction outcome loss': 0.1899241218183095, 'Total loss': 0.1899241218183095}
2023-01-04 00:37:01,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:01,552 INFO:     Epoch: 82
2023-01-04 00:37:03,145 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46965934534867604, 'Total loss': 0.46965934534867604} | train loss {'Reaction outcome loss': 0.19235596125540527, 'Total loss': 0.19235596125540527}
2023-01-04 00:37:03,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:03,145 INFO:     Epoch: 83
2023-01-04 00:37:04,751 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4444394369920095, 'Total loss': 0.4444394369920095} | train loss {'Reaction outcome loss': 0.19955581511654283, 'Total loss': 0.19955581511654283}
2023-01-04 00:37:04,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:04,751 INFO:     Epoch: 84
2023-01-04 00:37:06,360 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4479305426279704, 'Total loss': 0.4479305426279704} | train loss {'Reaction outcome loss': 0.19937269744949174, 'Total loss': 0.19937269744949174}
2023-01-04 00:37:06,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:06,360 INFO:     Epoch: 85
2023-01-04 00:37:07,946 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4480363816022873, 'Total loss': 0.4480363816022873} | train loss {'Reaction outcome loss': 0.18795823692124797, 'Total loss': 0.18795823692124797}
2023-01-04 00:37:07,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:07,946 INFO:     Epoch: 86
2023-01-04 00:37:09,558 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45114943782488504, 'Total loss': 0.45114943782488504} | train loss {'Reaction outcome loss': 0.1860771601881477, 'Total loss': 0.1860771601881477}
2023-01-04 00:37:09,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:09,558 INFO:     Epoch: 87
2023-01-04 00:37:11,165 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46295345822970074, 'Total loss': 0.46295345822970074} | train loss {'Reaction outcome loss': 0.18345786135709521, 'Total loss': 0.18345786135709521}
2023-01-04 00:37:11,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:11,166 INFO:     Epoch: 88
2023-01-04 00:37:12,767 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4361414909362793, 'Total loss': 0.4361414909362793} | train loss {'Reaction outcome loss': 0.1863313363460095, 'Total loss': 0.1863313363460095}
2023-01-04 00:37:12,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:12,768 INFO:     Epoch: 89
2023-01-04 00:37:14,376 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47265194555123646, 'Total loss': 0.47265194555123646} | train loss {'Reaction outcome loss': 0.18760303511331533, 'Total loss': 0.18760303511331533}
2023-01-04 00:37:14,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:14,376 INFO:     Epoch: 90
2023-01-04 00:37:15,970 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4476387361685435, 'Total loss': 0.4476387361685435} | train loss {'Reaction outcome loss': 0.18118432251166255, 'Total loss': 0.18118432251166255}
2023-01-04 00:37:15,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:15,970 INFO:     Epoch: 91
2023-01-04 00:37:17,572 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4451259394486745, 'Total loss': 0.4451259394486745} | train loss {'Reaction outcome loss': 0.18338459333049748, 'Total loss': 0.18338459333049748}
2023-01-04 00:37:17,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:17,572 INFO:     Epoch: 92
2023-01-04 00:37:19,199 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4293872520327568, 'Total loss': 0.4293872520327568} | train loss {'Reaction outcome loss': 0.179133012222693, 'Total loss': 0.179133012222693}
2023-01-04 00:37:19,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:19,199 INFO:     Epoch: 93
2023-01-04 00:37:20,792 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4508692592382431, 'Total loss': 0.4508692592382431} | train loss {'Reaction outcome loss': 0.17944197082871813, 'Total loss': 0.17944197082871813}
2023-01-04 00:37:20,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:20,792 INFO:     Epoch: 94
2023-01-04 00:37:22,409 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4631867676973343, 'Total loss': 0.4631867676973343} | train loss {'Reaction outcome loss': 0.17894147633384253, 'Total loss': 0.17894147633384253}
2023-01-04 00:37:22,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:22,409 INFO:     Epoch: 95
2023-01-04 00:37:24,028 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42251571317513786, 'Total loss': 0.42251571317513786} | train loss {'Reaction outcome loss': 0.20468081312551015, 'Total loss': 0.20468081312551015}
2023-01-04 00:37:24,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:24,028 INFO:     Epoch: 96
2023-01-04 00:37:25,607 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44534674485524495, 'Total loss': 0.44534674485524495} | train loss {'Reaction outcome loss': 0.17921261717497872, 'Total loss': 0.17921261717497872}
2023-01-04 00:37:25,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:25,608 INFO:     Epoch: 97
2023-01-04 00:37:27,217 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44482251852750776, 'Total loss': 0.44482251852750776} | train loss {'Reaction outcome loss': 0.17674725860917428, 'Total loss': 0.17674725860917428}
2023-01-04 00:37:27,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:27,219 INFO:     Epoch: 98
2023-01-04 00:37:28,824 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47567530870437624, 'Total loss': 0.47567530870437624} | train loss {'Reaction outcome loss': 0.17727398922400334, 'Total loss': 0.17727398922400334}
2023-01-04 00:37:28,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:28,824 INFO:     Epoch: 99
2023-01-04 00:37:30,407 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4324548770984014, 'Total loss': 0.4324548770984014} | train loss {'Reaction outcome loss': 0.17650917933012047, 'Total loss': 0.17650917933012047}
2023-01-04 00:37:30,407 INFO:     Best model found after epoch 38 of 100.
2023-01-04 00:37:30,407 INFO:   Done with stage: TRAINING
2023-01-04 00:37:30,407 INFO:   Starting stage: EVALUATION
2023-01-04 00:37:30,535 INFO:   Done with stage: EVALUATION
2023-01-04 00:37:30,536 INFO:   Leaving out SEQ value Fold_8
2023-01-04 00:37:30,549 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 00:37:30,549 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:37:31,193 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:37:31,193 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:37:31,262 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:37:31,262 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:37:31,262 INFO:     No hyperparam tuning for this model
2023-01-04 00:37:31,262 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:37:31,262 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:37:31,263 INFO:     None feature selector for col prot
2023-01-04 00:37:31,263 INFO:     None feature selector for col prot
2023-01-04 00:37:31,263 INFO:     None feature selector for col prot
2023-01-04 00:37:31,264 INFO:     None feature selector for col chem
2023-01-04 00:37:31,264 INFO:     None feature selector for col chem
2023-01-04 00:37:31,264 INFO:     None feature selector for col chem
2023-01-04 00:37:31,264 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:37:31,264 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:37:31,265 INFO:     Number of params in model 70141
2023-01-04 00:37:31,269 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:37:31,269 INFO:   Starting stage: TRAINING
2023-01-04 00:37:31,312 INFO:     Val loss before train {'Reaction outcome loss': 0.9846698443094889, 'Total loss': 0.9846698443094889}
2023-01-04 00:37:31,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:31,312 INFO:     Epoch: 0
2023-01-04 00:37:32,902 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7202507098515828, 'Total loss': 0.7202507098515828} | train loss {'Reaction outcome loss': 0.8416181601884164, 'Total loss': 0.8416181601884164}
2023-01-04 00:37:32,902 INFO:     Found new best model at epoch 0
2023-01-04 00:37:32,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:32,903 INFO:     Epoch: 1
2023-01-04 00:37:34,486 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.578585704167684, 'Total loss': 0.578585704167684} | train loss {'Reaction outcome loss': 0.609111426514147, 'Total loss': 0.609111426514147}
2023-01-04 00:37:34,487 INFO:     Found new best model at epoch 1
2023-01-04 00:37:34,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:34,488 INFO:     Epoch: 2
2023-01-04 00:37:36,077 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.573691592613856, 'Total loss': 0.573691592613856} | train loss {'Reaction outcome loss': 0.5348712478256051, 'Total loss': 0.5348712478256051}
2023-01-04 00:37:36,077 INFO:     Found new best model at epoch 2
2023-01-04 00:37:36,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:36,078 INFO:     Epoch: 3
2023-01-04 00:37:37,667 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5116723597049713, 'Total loss': 0.5116723597049713} | train loss {'Reaction outcome loss': 0.49212686586511006, 'Total loss': 0.49212686586511006}
2023-01-04 00:37:37,667 INFO:     Found new best model at epoch 3
2023-01-04 00:37:37,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:37,668 INFO:     Epoch: 4
2023-01-04 00:37:39,251 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5195840239524842, 'Total loss': 0.5195840239524842} | train loss {'Reaction outcome loss': 0.463163877144838, 'Total loss': 0.463163877144838}
2023-01-04 00:37:39,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:39,251 INFO:     Epoch: 5
2023-01-04 00:37:40,847 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5036203344662984, 'Total loss': 0.5036203344662984} | train loss {'Reaction outcome loss': 0.43904058973649485, 'Total loss': 0.43904058973649485}
2023-01-04 00:37:40,847 INFO:     Found new best model at epoch 5
2023-01-04 00:37:40,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:40,848 INFO:     Epoch: 6
2023-01-04 00:37:42,431 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48875121275583905, 'Total loss': 0.48875121275583905} | train loss {'Reaction outcome loss': 0.42170677265841444, 'Total loss': 0.42170677265841444}
2023-01-04 00:37:42,431 INFO:     Found new best model at epoch 6
2023-01-04 00:37:42,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:42,432 INFO:     Epoch: 7
2023-01-04 00:37:44,007 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46172409057617186, 'Total loss': 0.46172409057617186} | train loss {'Reaction outcome loss': 0.4072846035599272, 'Total loss': 0.4072846035599272}
2023-01-04 00:37:44,007 INFO:     Found new best model at epoch 7
2023-01-04 00:37:44,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:44,008 INFO:     Epoch: 8
2023-01-04 00:37:45,586 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46415473421414694, 'Total loss': 0.46415473421414694} | train loss {'Reaction outcome loss': 0.3940379677729292, 'Total loss': 0.3940379677729292}
2023-01-04 00:37:45,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:45,586 INFO:     Epoch: 9
2023-01-04 00:37:47,160 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4709626545508703, 'Total loss': 0.4709626545508703} | train loss {'Reaction outcome loss': 0.38527854395545885, 'Total loss': 0.38527854395545885}
2023-01-04 00:37:47,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:47,161 INFO:     Epoch: 10
2023-01-04 00:37:48,733 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5026094396909078, 'Total loss': 0.5026094396909078} | train loss {'Reaction outcome loss': 0.3740349396954089, 'Total loss': 0.3740349396954089}
2023-01-04 00:37:48,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:48,733 INFO:     Epoch: 11
2023-01-04 00:37:50,333 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.463895853360494, 'Total loss': 0.463895853360494} | train loss {'Reaction outcome loss': 0.36972053288976786, 'Total loss': 0.36972053288976786}
2023-01-04 00:37:50,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:50,334 INFO:     Epoch: 12
2023-01-04 00:37:51,903 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4596251388390859, 'Total loss': 0.4596251388390859} | train loss {'Reaction outcome loss': 0.3569686887137619, 'Total loss': 0.3569686887137619}
2023-01-04 00:37:51,903 INFO:     Found new best model at epoch 12
2023-01-04 00:37:51,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:51,904 INFO:     Epoch: 13
2023-01-04 00:37:53,501 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4700018137693405, 'Total loss': 0.4700018137693405} | train loss {'Reaction outcome loss': 0.3517636465447726, 'Total loss': 0.3517636465447726}
2023-01-04 00:37:53,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:53,501 INFO:     Epoch: 14
2023-01-04 00:37:55,097 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47899614572525023, 'Total loss': 0.47899614572525023} | train loss {'Reaction outcome loss': 0.3419073750520801, 'Total loss': 0.3419073750520801}
2023-01-04 00:37:55,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:55,097 INFO:     Epoch: 15
2023-01-04 00:37:56,681 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4720016300678253, 'Total loss': 0.4720016300678253} | train loss {'Reaction outcome loss': 0.3354416262535822, 'Total loss': 0.3354416262535822}
2023-01-04 00:37:56,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:56,681 INFO:     Epoch: 16
2023-01-04 00:37:58,282 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49552554488182066, 'Total loss': 0.49552554488182066} | train loss {'Reaction outcome loss': 0.33024401062137476, 'Total loss': 0.33024401062137476}
2023-01-04 00:37:58,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:58,284 INFO:     Epoch: 17
2023-01-04 00:37:59,876 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45762274861335756, 'Total loss': 0.45762274861335756} | train loss {'Reaction outcome loss': 0.32453469882954605, 'Total loss': 0.32453469882954605}
2023-01-04 00:37:59,876 INFO:     Found new best model at epoch 17
2023-01-04 00:37:59,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:37:59,877 INFO:     Epoch: 18
2023-01-04 00:38:01,460 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43099744742115337, 'Total loss': 0.43099744742115337} | train loss {'Reaction outcome loss': 0.32132100202006736, 'Total loss': 0.32132100202006736}
2023-01-04 00:38:01,460 INFO:     Found new best model at epoch 18
2023-01-04 00:38:01,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:01,461 INFO:     Epoch: 19
2023-01-04 00:38:03,060 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45349257389704384, 'Total loss': 0.45349257389704384} | train loss {'Reaction outcome loss': 0.31554711907556204, 'Total loss': 0.31554711907556204}
2023-01-04 00:38:03,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:03,062 INFO:     Epoch: 20
2023-01-04 00:38:04,654 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44155237277348836, 'Total loss': 0.44155237277348836} | train loss {'Reaction outcome loss': 0.30905033620722566, 'Total loss': 0.30905033620722566}
2023-01-04 00:38:04,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:04,655 INFO:     Epoch: 21
2023-01-04 00:38:06,214 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4313036600748698, 'Total loss': 0.4313036600748698} | train loss {'Reaction outcome loss': 0.3026770862849641, 'Total loss': 0.3026770862849641}
2023-01-04 00:38:06,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:06,214 INFO:     Epoch: 22
2023-01-04 00:38:07,788 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46713828245798744, 'Total loss': 0.46713828245798744} | train loss {'Reaction outcome loss': 0.3006663461635401, 'Total loss': 0.3006663461635401}
2023-01-04 00:38:07,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:07,788 INFO:     Epoch: 23
2023-01-04 00:38:09,345 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4645573258399963, 'Total loss': 0.4645573258399963} | train loss {'Reaction outcome loss': 0.2951259253335086, 'Total loss': 0.2951259253335086}
2023-01-04 00:38:09,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:09,346 INFO:     Epoch: 24
2023-01-04 00:38:10,941 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47718991041183473, 'Total loss': 0.47718991041183473} | train loss {'Reaction outcome loss': 0.2890302379762297, 'Total loss': 0.2890302379762297}
2023-01-04 00:38:10,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:10,942 INFO:     Epoch: 25
2023-01-04 00:38:12,545 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4524006317059199, 'Total loss': 0.4524006317059199} | train loss {'Reaction outcome loss': 0.288491331382003, 'Total loss': 0.288491331382003}
2023-01-04 00:38:12,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:12,545 INFO:     Epoch: 26
2023-01-04 00:38:14,127 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46797150174776714, 'Total loss': 0.46797150174776714} | train loss {'Reaction outcome loss': 0.28094809000199533, 'Total loss': 0.28094809000199533}
2023-01-04 00:38:14,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:14,127 INFO:     Epoch: 27
2023-01-04 00:38:15,729 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4456535756587982, 'Total loss': 0.4456535756587982} | train loss {'Reaction outcome loss': 0.2786349058151245, 'Total loss': 0.2786349058151245}
2023-01-04 00:38:15,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:15,731 INFO:     Epoch: 28
2023-01-04 00:38:17,296 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43453540205955504, 'Total loss': 0.43453540205955504} | train loss {'Reaction outcome loss': 0.2741093953505104, 'Total loss': 0.2741093953505104}
2023-01-04 00:38:17,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:17,297 INFO:     Epoch: 29
2023-01-04 00:38:18,862 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4766255954901377, 'Total loss': 0.4766255954901377} | train loss {'Reaction outcome loss': 0.27085638684885843, 'Total loss': 0.27085638684885843}
2023-01-04 00:38:18,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:18,862 INFO:     Epoch: 30
2023-01-04 00:38:20,450 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4573476721843084, 'Total loss': 0.4573476721843084} | train loss {'Reaction outcome loss': 0.2686642514807837, 'Total loss': 0.2686642514807837}
2023-01-04 00:38:20,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:20,451 INFO:     Epoch: 31
2023-01-04 00:38:22,027 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4700042486190796, 'Total loss': 0.4700042486190796} | train loss {'Reaction outcome loss': 0.2673190481032862, 'Total loss': 0.2673190481032862}
2023-01-04 00:38:22,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:22,029 INFO:     Epoch: 32
2023-01-04 00:38:23,588 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4332726448774338, 'Total loss': 0.4332726448774338} | train loss {'Reaction outcome loss': 0.2627716881970128, 'Total loss': 0.2627716881970128}
2023-01-04 00:38:23,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:23,588 INFO:     Epoch: 33
2023-01-04 00:38:25,158 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4320812463760376, 'Total loss': 0.4320812463760376} | train loss {'Reaction outcome loss': 0.2573622351839811, 'Total loss': 0.2573622351839811}
2023-01-04 00:38:25,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:25,158 INFO:     Epoch: 34
2023-01-04 00:38:26,761 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.432099786400795, 'Total loss': 0.432099786400795} | train loss {'Reaction outcome loss': 0.2551690633152867, 'Total loss': 0.2551690633152867}
2023-01-04 00:38:26,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:26,762 INFO:     Epoch: 35
2023-01-04 00:38:28,318 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43057408009966214, 'Total loss': 0.43057408009966214} | train loss {'Reaction outcome loss': 0.2541847581064308, 'Total loss': 0.2541847581064308}
2023-01-04 00:38:28,319 INFO:     Found new best model at epoch 35
2023-01-04 00:38:28,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:28,319 INFO:     Epoch: 36
2023-01-04 00:38:29,894 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4172385404507319, 'Total loss': 0.4172385404507319} | train loss {'Reaction outcome loss': 0.24899698456838018, 'Total loss': 0.24899698456838018}
2023-01-04 00:38:29,894 INFO:     Found new best model at epoch 36
2023-01-04 00:38:29,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:29,895 INFO:     Epoch: 37
2023-01-04 00:38:31,467 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4255745406883458, 'Total loss': 0.4255745406883458} | train loss {'Reaction outcome loss': 0.2486551388579629, 'Total loss': 0.2486551388579629}
2023-01-04 00:38:31,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:31,468 INFO:     Epoch: 38
2023-01-04 00:38:33,034 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4480425367752711, 'Total loss': 0.4480425367752711} | train loss {'Reaction outcome loss': 0.24692536205489993, 'Total loss': 0.24692536205489993}
2023-01-04 00:38:33,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:33,035 INFO:     Epoch: 39
2023-01-04 00:38:34,603 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41986863017082215, 'Total loss': 0.41986863017082215} | train loss {'Reaction outcome loss': 0.24586152550065038, 'Total loss': 0.24586152550065038}
2023-01-04 00:38:34,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:34,603 INFO:     Epoch: 40
2023-01-04 00:38:36,181 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43025858799616495, 'Total loss': 0.43025858799616495} | train loss {'Reaction outcome loss': 0.2413964895702107, 'Total loss': 0.2413964895702107}
2023-01-04 00:38:36,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:36,181 INFO:     Epoch: 41
2023-01-04 00:38:37,783 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46364519794782005, 'Total loss': 0.46364519794782005} | train loss {'Reaction outcome loss': 0.24123615083786157, 'Total loss': 0.24123615083786157}
2023-01-04 00:38:37,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:37,783 INFO:     Epoch: 42
2023-01-04 00:38:39,397 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4287486642599106, 'Total loss': 0.4287486642599106} | train loss {'Reaction outcome loss': 0.23582187705697158, 'Total loss': 0.23582187705697158}
2023-01-04 00:38:39,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:39,399 INFO:     Epoch: 43
2023-01-04 00:38:40,987 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45588859617710115, 'Total loss': 0.45588859617710115} | train loss {'Reaction outcome loss': 0.23465035550105265, 'Total loss': 0.23465035550105265}
2023-01-04 00:38:40,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:40,987 INFO:     Epoch: 44
2023-01-04 00:38:42,574 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43650317589441934, 'Total loss': 0.43650317589441934} | train loss {'Reaction outcome loss': 0.23316467687105522, 'Total loss': 0.23316467687105522}
2023-01-04 00:38:42,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:42,574 INFO:     Epoch: 45
2023-01-04 00:38:44,177 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43489182790120445, 'Total loss': 0.43489182790120445} | train loss {'Reaction outcome loss': 0.23111741152001825, 'Total loss': 0.23111741152001825}
2023-01-04 00:38:44,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:44,177 INFO:     Epoch: 46
2023-01-04 00:38:45,737 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44437821904818214, 'Total loss': 0.44437821904818214} | train loss {'Reaction outcome loss': 0.2264985955924123, 'Total loss': 0.2264985955924123}
2023-01-04 00:38:45,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:45,738 INFO:     Epoch: 47
2023-01-04 00:38:47,322 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4601228227217992, 'Total loss': 0.4601228227217992} | train loss {'Reaction outcome loss': 0.2295304411960827, 'Total loss': 0.2295304411960827}
2023-01-04 00:38:47,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:47,322 INFO:     Epoch: 48
2023-01-04 00:38:48,927 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42547744512557983, 'Total loss': 0.42547744512557983} | train loss {'Reaction outcome loss': 0.22616840533284477, 'Total loss': 0.22616840533284477}
2023-01-04 00:38:48,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:48,927 INFO:     Epoch: 49
2023-01-04 00:38:50,493 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4461684266726176, 'Total loss': 0.4461684266726176} | train loss {'Reaction outcome loss': 0.22377157287719923, 'Total loss': 0.22377157287719923}
2023-01-04 00:38:50,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:50,493 INFO:     Epoch: 50
2023-01-04 00:38:52,068 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43038979917764664, 'Total loss': 0.43038979917764664} | train loss {'Reaction outcome loss': 0.22411530116920944, 'Total loss': 0.22411530116920944}
2023-01-04 00:38:52,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:52,069 INFO:     Epoch: 51
2023-01-04 00:38:53,642 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44679461121559144, 'Total loss': 0.44679461121559144} | train loss {'Reaction outcome loss': 0.22024627789964168, 'Total loss': 0.22024627789964168}
2023-01-04 00:38:53,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:53,643 INFO:     Epoch: 52
2023-01-04 00:38:55,199 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4238873432079951, 'Total loss': 0.4238873432079951} | train loss {'Reaction outcome loss': 0.2178992192830631, 'Total loss': 0.2178992192830631}
2023-01-04 00:38:55,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:55,199 INFO:     Epoch: 53
2023-01-04 00:38:56,800 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47512166798114774, 'Total loss': 0.47512166798114774} | train loss {'Reaction outcome loss': 0.21690026078468713, 'Total loss': 0.21690026078468713}
2023-01-04 00:38:56,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:56,801 INFO:     Epoch: 54
2023-01-04 00:38:58,408 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43393341501553856, 'Total loss': 0.43393341501553856} | train loss {'Reaction outcome loss': 0.21826942499740656, 'Total loss': 0.21826942499740656}
2023-01-04 00:38:58,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:58,409 INFO:     Epoch: 55
2023-01-04 00:38:59,973 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4637296269337336, 'Total loss': 0.4637296269337336} | train loss {'Reaction outcome loss': 0.21816153378113284, 'Total loss': 0.21816153378113284}
2023-01-04 00:38:59,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:38:59,973 INFO:     Epoch: 56
2023-01-04 00:39:01,560 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44394554297129313, 'Total loss': 0.44394554297129313} | train loss {'Reaction outcome loss': 0.21254399589402773, 'Total loss': 0.21254399589402773}
2023-01-04 00:39:01,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:01,561 INFO:     Epoch: 57
2023-01-04 00:39:03,141 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4468582312266032, 'Total loss': 0.4468582312266032} | train loss {'Reaction outcome loss': 0.20891046590912035, 'Total loss': 0.20891046590912035}
2023-01-04 00:39:03,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:03,143 INFO:     Epoch: 58
2023-01-04 00:39:04,739 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4455967888236046, 'Total loss': 0.4455967888236046} | train loss {'Reaction outcome loss': 0.2088579043827869, 'Total loss': 0.2088579043827869}
2023-01-04 00:39:04,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:04,740 INFO:     Epoch: 59
2023-01-04 00:39:06,342 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4546616494655609, 'Total loss': 0.4546616494655609} | train loss {'Reaction outcome loss': 0.20863408802056704, 'Total loss': 0.20863408802056704}
2023-01-04 00:39:06,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:06,342 INFO:     Epoch: 60
2023-01-04 00:39:07,923 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4618823637564977, 'Total loss': 0.4618823637564977} | train loss {'Reaction outcome loss': 0.20573525731673553, 'Total loss': 0.20573525731673553}
2023-01-04 00:39:07,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:07,923 INFO:     Epoch: 61
2023-01-04 00:39:09,529 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4325019121170044, 'Total loss': 0.4325019121170044} | train loss {'Reaction outcome loss': 0.20692721893499186, 'Total loss': 0.20692721893499186}
2023-01-04 00:39:09,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:09,530 INFO:     Epoch: 62
2023-01-04 00:39:11,109 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4637294371922811, 'Total loss': 0.4637294371922811} | train loss {'Reaction outcome loss': 0.20891213554875318, 'Total loss': 0.20891213554875318}
2023-01-04 00:39:11,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:11,110 INFO:     Epoch: 63
2023-01-04 00:39:12,669 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.443082003792127, 'Total loss': 0.443082003792127} | train loss {'Reaction outcome loss': 0.20456071068351958, 'Total loss': 0.20456071068351958}
2023-01-04 00:39:12,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:12,670 INFO:     Epoch: 64
2023-01-04 00:39:14,266 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45639288127422334, 'Total loss': 0.45639288127422334} | train loss {'Reaction outcome loss': 0.20310139257610935, 'Total loss': 0.20310139257610935}
2023-01-04 00:39:14,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:14,266 INFO:     Epoch: 65
2023-01-04 00:39:15,864 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43978345195452373, 'Total loss': 0.43978345195452373} | train loss {'Reaction outcome loss': 0.20269815329694268, 'Total loss': 0.20269815329694268}
2023-01-04 00:39:15,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:15,866 INFO:     Epoch: 66
2023-01-04 00:39:17,435 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.443556751559178, 'Total loss': 0.443556751559178} | train loss {'Reaction outcome loss': 0.19887440246376362, 'Total loss': 0.19887440246376362}
2023-01-04 00:39:17,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:17,436 INFO:     Epoch: 67
2023-01-04 00:39:19,039 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49055757323900856, 'Total loss': 0.49055757323900856} | train loss {'Reaction outcome loss': 0.1983872348179993, 'Total loss': 0.1983872348179993}
2023-01-04 00:39:19,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:19,039 INFO:     Epoch: 68
2023-01-04 00:39:20,630 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4409613698720932, 'Total loss': 0.4409613698720932} | train loss {'Reaction outcome loss': 0.20106172988075258, 'Total loss': 0.20106172988075258}
2023-01-04 00:39:20,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:20,631 INFO:     Epoch: 69
2023-01-04 00:39:22,191 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46586799472570417, 'Total loss': 0.46586799472570417} | train loss {'Reaction outcome loss': 0.19982637325813482, 'Total loss': 0.19982637325813482}
2023-01-04 00:39:22,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:22,191 INFO:     Epoch: 70
2023-01-04 00:39:23,761 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4869521717230479, 'Total loss': 0.4869521717230479} | train loss {'Reaction outcome loss': 0.19413155390311293, 'Total loss': 0.19413155390311293}
2023-01-04 00:39:23,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:23,761 INFO:     Epoch: 71
2023-01-04 00:39:25,363 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4869200964768728, 'Total loss': 0.4869200964768728} | train loss {'Reaction outcome loss': 0.19453348702454304, 'Total loss': 0.19453348702454304}
2023-01-04 00:39:25,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:25,364 INFO:     Epoch: 72
2023-01-04 00:39:26,955 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47219007114569345, 'Total loss': 0.47219007114569345} | train loss {'Reaction outcome loss': 0.19615223325597933, 'Total loss': 0.19615223325597933}
2023-01-04 00:39:26,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:26,956 INFO:     Epoch: 73
2023-01-04 00:39:28,554 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4394252995649974, 'Total loss': 0.4394252995649974} | train loss {'Reaction outcome loss': 0.19125997850964793, 'Total loss': 0.19125997850964793}
2023-01-04 00:39:28,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:28,555 INFO:     Epoch: 74
2023-01-04 00:39:30,138 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48975573082764945, 'Total loss': 0.48975573082764945} | train loss {'Reaction outcome loss': 0.19293125860747837, 'Total loss': 0.19293125860747837}
2023-01-04 00:39:30,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:30,139 INFO:     Epoch: 75
2023-01-04 00:39:31,708 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47455008228619894, 'Total loss': 0.47455008228619894} | train loss {'Reaction outcome loss': 0.19090618397835846, 'Total loss': 0.19090618397835846}
2023-01-04 00:39:31,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:31,708 INFO:     Epoch: 76
2023-01-04 00:39:33,277 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.453511169552803, 'Total loss': 0.453511169552803} | train loss {'Reaction outcome loss': 0.19017204932268067, 'Total loss': 0.19017204932268067}
2023-01-04 00:39:33,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:33,279 INFO:     Epoch: 77
2023-01-04 00:39:34,832 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4426980969806512, 'Total loss': 0.4426980969806512} | train loss {'Reaction outcome loss': 0.19065830009160462, 'Total loss': 0.19065830009160462}
2023-01-04 00:39:34,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:34,832 INFO:     Epoch: 78
2023-01-04 00:39:36,400 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4692011843125025, 'Total loss': 0.4692011843125025} | train loss {'Reaction outcome loss': 0.18845789790180795, 'Total loss': 0.18845789790180795}
2023-01-04 00:39:36,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:36,400 INFO:     Epoch: 79
2023-01-04 00:39:37,969 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4712673932313919, 'Total loss': 0.4712673932313919} | train loss {'Reaction outcome loss': 0.18807849979144095, 'Total loss': 0.18807849979144095}
2023-01-04 00:39:37,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:37,970 INFO:     Epoch: 80
2023-01-04 00:39:39,530 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4807066301504771, 'Total loss': 0.4807066301504771} | train loss {'Reaction outcome loss': 0.18565709637853253, 'Total loss': 0.18565709637853253}
2023-01-04 00:39:39,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:39,531 INFO:     Epoch: 81
2023-01-04 00:39:41,117 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45257890125115713, 'Total loss': 0.45257890125115713} | train loss {'Reaction outcome loss': 0.1862046253413726, 'Total loss': 0.1862046253413726}
2023-01-04 00:39:41,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:41,117 INFO:     Epoch: 82
2023-01-04 00:39:42,692 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4586145202318827, 'Total loss': 0.4586145202318827} | train loss {'Reaction outcome loss': 0.1837353991897224, 'Total loss': 0.1837353991897224}
2023-01-04 00:39:42,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:42,692 INFO:     Epoch: 83
2023-01-04 00:39:44,257 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4673928956190745, 'Total loss': 0.4673928956190745} | train loss {'Reaction outcome loss': 0.18184302949377304, 'Total loss': 0.18184302949377304}
2023-01-04 00:39:44,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:44,257 INFO:     Epoch: 84
2023-01-04 00:39:45,844 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4715882033109665, 'Total loss': 0.4715882033109665} | train loss {'Reaction outcome loss': 0.1813168104587894, 'Total loss': 0.1813168104587894}
2023-01-04 00:39:45,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:45,846 INFO:     Epoch: 85
2023-01-04 00:39:47,450 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4644624203443527, 'Total loss': 0.4644624203443527} | train loss {'Reaction outcome loss': 0.1829612691402299, 'Total loss': 0.1829612691402299}
2023-01-04 00:39:47,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:47,451 INFO:     Epoch: 86
2023-01-04 00:39:49,010 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4501746823390325, 'Total loss': 0.4501746823390325} | train loss {'Reaction outcome loss': 0.17947801260530075, 'Total loss': 0.17947801260530075}
2023-01-04 00:39:49,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:49,010 INFO:     Epoch: 87
2023-01-04 00:39:50,590 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4525568922360738, 'Total loss': 0.4525568922360738} | train loss {'Reaction outcome loss': 0.18328001508455136, 'Total loss': 0.18328001508455136}
2023-01-04 00:39:50,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:50,590 INFO:     Epoch: 88
2023-01-04 00:39:52,195 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.486308957139651, 'Total loss': 0.486308957139651} | train loss {'Reaction outcome loss': 0.17956367476191712, 'Total loss': 0.17956367476191712}
2023-01-04 00:39:52,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:52,196 INFO:     Epoch: 89
2023-01-04 00:39:53,757 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4461186716953913, 'Total loss': 0.4461186716953913} | train loss {'Reaction outcome loss': 0.17761935479256696, 'Total loss': 0.17761935479256696}
2023-01-04 00:39:53,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:53,758 INFO:     Epoch: 90
2023-01-04 00:39:55,362 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45598067740599313, 'Total loss': 0.45598067740599313} | train loss {'Reaction outcome loss': 0.17808416272230418, 'Total loss': 0.17808416272230418}
2023-01-04 00:39:55,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:55,362 INFO:     Epoch: 91
2023-01-04 00:39:56,916 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5069383690754573, 'Total loss': 0.5069383690754573} | train loss {'Reaction outcome loss': 0.17994818365672133, 'Total loss': 0.17994818365672133}
2023-01-04 00:39:56,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:56,917 INFO:     Epoch: 92
2023-01-04 00:39:58,508 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4347318599621455, 'Total loss': 0.4347318599621455} | train loss {'Reaction outcome loss': 0.17758304538416775, 'Total loss': 0.17758304538416775}
2023-01-04 00:39:58,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:39:58,508 INFO:     Epoch: 93
2023-01-04 00:40:00,085 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46136128107706703, 'Total loss': 0.46136128107706703} | train loss {'Reaction outcome loss': 0.17225452137073918, 'Total loss': 0.17225452137073918}
2023-01-04 00:40:00,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:00,085 INFO:     Epoch: 94
2023-01-04 00:40:01,662 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47613371222590406, 'Total loss': 0.47613371222590406} | train loss {'Reaction outcome loss': 0.17503607203508473, 'Total loss': 0.17503607203508473}
2023-01-04 00:40:01,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:01,662 INFO:     Epoch: 95
2023-01-04 00:40:03,253 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4732751170794169, 'Total loss': 0.4732751170794169} | train loss {'Reaction outcome loss': 0.1714051668822165, 'Total loss': 0.1714051668822165}
2023-01-04 00:40:03,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:03,254 INFO:     Epoch: 96
2023-01-04 00:40:04,838 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4647020955880483, 'Total loss': 0.4647020955880483} | train loss {'Reaction outcome loss': 0.17239624948919693, 'Total loss': 0.17239624948919693}
2023-01-04 00:40:04,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:04,839 INFO:     Epoch: 97
2023-01-04 00:40:06,425 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47233217855294546, 'Total loss': 0.47233217855294546} | train loss {'Reaction outcome loss': 0.1734770213564237, 'Total loss': 0.1734770213564237}
2023-01-04 00:40:06,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:06,425 INFO:     Epoch: 98
2023-01-04 00:40:08,030 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4550536354382833, 'Total loss': 0.4550536354382833} | train loss {'Reaction outcome loss': 0.1723906218719024, 'Total loss': 0.1723906218719024}
2023-01-04 00:40:08,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:08,030 INFO:     Epoch: 99
2023-01-04 00:40:09,636 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46149371067682904, 'Total loss': 0.46149371067682904} | train loss {'Reaction outcome loss': 0.17322557758635435, 'Total loss': 0.17322557758635435}
2023-01-04 00:40:09,637 INFO:     Best model found after epoch 37 of 100.
2023-01-04 00:40:09,637 INFO:   Done with stage: TRAINING
2023-01-04 00:40:09,637 INFO:   Starting stage: EVALUATION
2023-01-04 00:40:09,779 INFO:   Done with stage: EVALUATION
2023-01-04 00:40:09,779 INFO:   Leaving out SEQ value Fold_9
2023-01-04 00:40:09,792 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 00:40:09,792 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:40:10,451 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:40:10,451 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:40:10,523 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:40:10,523 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:40:10,523 INFO:     No hyperparam tuning for this model
2023-01-04 00:40:10,523 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:40:10,523 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:40:10,524 INFO:     None feature selector for col prot
2023-01-04 00:40:10,524 INFO:     None feature selector for col prot
2023-01-04 00:40:10,524 INFO:     None feature selector for col prot
2023-01-04 00:40:10,525 INFO:     None feature selector for col chem
2023-01-04 00:40:10,525 INFO:     None feature selector for col chem
2023-01-04 00:40:10,525 INFO:     None feature selector for col chem
2023-01-04 00:40:10,525 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:40:10,525 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:40:10,526 INFO:     Number of params in model 70141
2023-01-04 00:40:10,529 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:40:10,530 INFO:   Starting stage: TRAINING
2023-01-04 00:40:10,565 INFO:     Val loss before train {'Reaction outcome loss': 0.9901848316192627, 'Total loss': 0.9901848316192627}
2023-01-04 00:40:10,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:10,565 INFO:     Epoch: 0
2023-01-04 00:40:11,632 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6307078023751577, 'Total loss': 0.6307078023751577} | train loss {'Reaction outcome loss': 0.8494526221268419, 'Total loss': 0.8494526221268419}
2023-01-04 00:40:11,632 INFO:     Found new best model at epoch 0
2023-01-04 00:40:11,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:11,633 INFO:     Epoch: 1
2023-01-04 00:40:12,696 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5003447274367014, 'Total loss': 0.5003447274367014} | train loss {'Reaction outcome loss': 0.6033738584298155, 'Total loss': 0.6033738584298155}
2023-01-04 00:40:12,696 INFO:     Found new best model at epoch 1
2023-01-04 00:40:12,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:12,697 INFO:     Epoch: 2
2023-01-04 00:40:13,768 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46111851235230766, 'Total loss': 0.46111851235230766} | train loss {'Reaction outcome loss': 0.5271914428019006, 'Total loss': 0.5271914428019006}
2023-01-04 00:40:13,769 INFO:     Found new best model at epoch 2
2023-01-04 00:40:13,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:13,769 INFO:     Epoch: 3
2023-01-04 00:40:15,059 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4279598226149877, 'Total loss': 0.4279598226149877} | train loss {'Reaction outcome loss': 0.48842130104700726, 'Total loss': 0.48842130104700726}
2023-01-04 00:40:15,061 INFO:     Found new best model at epoch 3
2023-01-04 00:40:15,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:15,062 INFO:     Epoch: 4
2023-01-04 00:40:16,681 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4025651882092158, 'Total loss': 0.4025651882092158} | train loss {'Reaction outcome loss': 0.4619028928919115, 'Total loss': 0.4619028928919115}
2023-01-04 00:40:16,681 INFO:     Found new best model at epoch 4
2023-01-04 00:40:16,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:16,682 INFO:     Epoch: 5
2023-01-04 00:40:18,303 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3942060103019079, 'Total loss': 0.3942060103019079} | train loss {'Reaction outcome loss': 0.44073490160044987, 'Total loss': 0.44073490160044987}
2023-01-04 00:40:18,303 INFO:     Found new best model at epoch 5
2023-01-04 00:40:18,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:18,304 INFO:     Epoch: 6
2023-01-04 00:40:19,916 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4036330739657084, 'Total loss': 0.4036330739657084} | train loss {'Reaction outcome loss': 0.422755296173357, 'Total loss': 0.422755296173357}
2023-01-04 00:40:19,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:19,917 INFO:     Epoch: 7
2023-01-04 00:40:21,516 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.39081334869066875, 'Total loss': 0.39081334869066875} | train loss {'Reaction outcome loss': 0.40892972488064266, 'Total loss': 0.40892972488064266}
2023-01-04 00:40:21,516 INFO:     Found new best model at epoch 7
2023-01-04 00:40:21,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:21,517 INFO:     Epoch: 8
2023-01-04 00:40:23,106 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.39205580155054726, 'Total loss': 0.39205580155054726} | train loss {'Reaction outcome loss': 0.39739706772851985, 'Total loss': 0.39739706772851985}
2023-01-04 00:40:23,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:23,106 INFO:     Epoch: 9
2023-01-04 00:40:24,701 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3760827855517467, 'Total loss': 0.3760827855517467} | train loss {'Reaction outcome loss': 0.3886250978351766, 'Total loss': 0.3886250978351766}
2023-01-04 00:40:24,701 INFO:     Found new best model at epoch 9
2023-01-04 00:40:24,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:24,702 INFO:     Epoch: 10
2023-01-04 00:40:26,302 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.38460907638072966, 'Total loss': 0.38460907638072966} | train loss {'Reaction outcome loss': 0.37921924944279506, 'Total loss': 0.37921924944279506}
2023-01-04 00:40:26,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:26,304 INFO:     Epoch: 11
2023-01-04 00:40:27,909 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3997935871283213, 'Total loss': 0.3997935871283213} | train loss {'Reaction outcome loss': 0.3770659088656522, 'Total loss': 0.3770659088656522}
2023-01-04 00:40:27,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:27,909 INFO:     Epoch: 12
2023-01-04 00:40:29,524 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.38208400110403695, 'Total loss': 0.38208400110403695} | train loss {'Reaction outcome loss': 0.367573969070361, 'Total loss': 0.367573969070361}
2023-01-04 00:40:29,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:29,524 INFO:     Epoch: 13
2023-01-04 00:40:31,108 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3931951920191447, 'Total loss': 0.3931951920191447} | train loss {'Reaction outcome loss': 0.36968286443447723, 'Total loss': 0.36968286443447723}
2023-01-04 00:40:31,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:31,109 INFO:     Epoch: 14
2023-01-04 00:40:32,701 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39970464011033374, 'Total loss': 0.39970464011033374} | train loss {'Reaction outcome loss': 0.36014966072811594, 'Total loss': 0.36014966072811594}
2023-01-04 00:40:32,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:32,702 INFO:     Epoch: 15
2023-01-04 00:40:34,317 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3857670803864797, 'Total loss': 0.3857670803864797} | train loss {'Reaction outcome loss': 0.34453572556916356, 'Total loss': 0.34453572556916356}
2023-01-04 00:40:34,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:34,317 INFO:     Epoch: 16
2023-01-04 00:40:35,940 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.38545798063278197, 'Total loss': 0.38545798063278197} | train loss {'Reaction outcome loss': 0.33608792425838, 'Total loss': 0.33608792425838}
2023-01-04 00:40:35,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:35,940 INFO:     Epoch: 17
2023-01-04 00:40:37,561 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.36494398017724355, 'Total loss': 0.36494398017724355} | train loss {'Reaction outcome loss': 0.3395550422424424, 'Total loss': 0.3395550422424424}
2023-01-04 00:40:37,561 INFO:     Found new best model at epoch 17
2023-01-04 00:40:37,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:37,562 INFO:     Epoch: 18
2023-01-04 00:40:39,147 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3796903053919474, 'Total loss': 0.3796903053919474} | train loss {'Reaction outcome loss': 0.3323560082682651, 'Total loss': 0.3323560082682651}
2023-01-04 00:40:39,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:39,149 INFO:     Epoch: 19
2023-01-04 00:40:40,722 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3792797307173411, 'Total loss': 0.3792797307173411} | train loss {'Reaction outcome loss': 0.32316439938933955, 'Total loss': 0.32316439938933955}
2023-01-04 00:40:40,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:40,722 INFO:     Epoch: 20
2023-01-04 00:40:42,307 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.36994134485721586, 'Total loss': 0.36994134485721586} | train loss {'Reaction outcome loss': 0.31637114521277987, 'Total loss': 0.31637114521277987}
2023-01-04 00:40:42,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:42,308 INFO:     Epoch: 21
2023-01-04 00:40:43,926 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.38414112528165184, 'Total loss': 0.38414112528165184} | train loss {'Reaction outcome loss': 0.31168372395610355, 'Total loss': 0.31168372395610355}
2023-01-04 00:40:43,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:43,926 INFO:     Epoch: 22
2023-01-04 00:40:45,545 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3899619996547699, 'Total loss': 0.3899619996547699} | train loss {'Reaction outcome loss': 0.30494402284713706, 'Total loss': 0.30494402284713706}
2023-01-04 00:40:45,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:45,547 INFO:     Epoch: 23
2023-01-04 00:40:47,157 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.37852858503659564, 'Total loss': 0.37852858503659564} | train loss {'Reaction outcome loss': 0.29969229851849377, 'Total loss': 0.29969229851849377}
2023-01-04 00:40:47,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:47,158 INFO:     Epoch: 24
2023-01-04 00:40:48,753 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38086988230546315, 'Total loss': 0.38086988230546315} | train loss {'Reaction outcome loss': 0.29691708587326, 'Total loss': 0.29691708587326}
2023-01-04 00:40:48,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:48,753 INFO:     Epoch: 25
2023-01-04 00:40:50,373 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.380165296792984, 'Total loss': 0.380165296792984} | train loss {'Reaction outcome loss': 0.2942894919998134, 'Total loss': 0.2942894919998134}
2023-01-04 00:40:50,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:50,374 INFO:     Epoch: 26
2023-01-04 00:40:51,976 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4003287514050802, 'Total loss': 0.4003287514050802} | train loss {'Reaction outcome loss': 0.2891095091071675, 'Total loss': 0.2891095091071675}
2023-01-04 00:40:51,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:51,977 INFO:     Epoch: 27
2023-01-04 00:40:53,592 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3835134128729502, 'Total loss': 0.3835134128729502} | train loss {'Reaction outcome loss': 0.283019427001726, 'Total loss': 0.283019427001726}
2023-01-04 00:40:53,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:53,593 INFO:     Epoch: 28
2023-01-04 00:40:55,180 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3900475800037384, 'Total loss': 0.3900475800037384} | train loss {'Reaction outcome loss': 0.28172215399588796, 'Total loss': 0.28172215399588796}
2023-01-04 00:40:55,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:55,180 INFO:     Epoch: 29
2023-01-04 00:40:56,801 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3946165199081103, 'Total loss': 0.3946165199081103} | train loss {'Reaction outcome loss': 0.2776874998935323, 'Total loss': 0.2776874998935323}
2023-01-04 00:40:56,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:56,803 INFO:     Epoch: 30
2023-01-04 00:40:58,373 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41565258502960206, 'Total loss': 0.41565258502960206} | train loss {'Reaction outcome loss': 0.2737749098273723, 'Total loss': 0.2737749098273723}
2023-01-04 00:40:58,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:58,373 INFO:     Epoch: 31
2023-01-04 00:40:59,967 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3895831942558289, 'Total loss': 0.3895831942558289} | train loss {'Reaction outcome loss': 0.27134313040237495, 'Total loss': 0.27134313040237495}
2023-01-04 00:40:59,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:40:59,968 INFO:     Epoch: 32
2023-01-04 00:41:01,591 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3783588856458664, 'Total loss': 0.3783588856458664} | train loss {'Reaction outcome loss': 0.2657189295640674, 'Total loss': 0.2657189295640674}
2023-01-04 00:41:01,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:01,592 INFO:     Epoch: 33
2023-01-04 00:41:03,213 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3706355551878611, 'Total loss': 0.3706355551878611} | train loss {'Reaction outcome loss': 0.2638993514026853, 'Total loss': 0.2638993514026853}
2023-01-04 00:41:03,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:03,214 INFO:     Epoch: 34
2023-01-04 00:41:04,802 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3840666969617208, 'Total loss': 0.3840666969617208} | train loss {'Reaction outcome loss': 0.26211254715082655, 'Total loss': 0.26211254715082655}
2023-01-04 00:41:04,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:04,807 INFO:     Epoch: 35
2023-01-04 00:41:06,410 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4028828670581182, 'Total loss': 0.4028828670581182} | train loss {'Reaction outcome loss': 0.25880859477868967, 'Total loss': 0.25880859477868967}
2023-01-04 00:41:06,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:06,410 INFO:     Epoch: 36
2023-01-04 00:41:07,984 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3845462381839752, 'Total loss': 0.3845462381839752} | train loss {'Reaction outcome loss': 0.2534869656488097, 'Total loss': 0.2534869656488097}
2023-01-04 00:41:07,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:07,985 INFO:     Epoch: 37
2023-01-04 00:41:09,558 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41328966021537783, 'Total loss': 0.41328966021537783} | train loss {'Reaction outcome loss': 0.2511108586753624, 'Total loss': 0.2511108586753624}
2023-01-04 00:41:09,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:09,558 INFO:     Epoch: 38
2023-01-04 00:41:11,145 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3827413747708003, 'Total loss': 0.3827413747708003} | train loss {'Reaction outcome loss': 0.24992997150073518, 'Total loss': 0.24992997150073518}
2023-01-04 00:41:11,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:11,146 INFO:     Epoch: 39
2023-01-04 00:41:12,734 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39205445249875387, 'Total loss': 0.39205445249875387} | train loss {'Reaction outcome loss': 0.24290464020863958, 'Total loss': 0.24290464020863958}
2023-01-04 00:41:12,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:12,734 INFO:     Epoch: 40
2023-01-04 00:41:14,324 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3878260801235835, 'Total loss': 0.3878260801235835} | train loss {'Reaction outcome loss': 0.2426256855057242, 'Total loss': 0.2426256855057242}
2023-01-04 00:41:14,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:14,326 INFO:     Epoch: 41
2023-01-04 00:41:15,901 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3997251371542613, 'Total loss': 0.3997251371542613} | train loss {'Reaction outcome loss': 0.23836362348689968, 'Total loss': 0.23836362348689968}
2023-01-04 00:41:15,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:15,901 INFO:     Epoch: 42
2023-01-04 00:41:17,476 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.398924732208252, 'Total loss': 0.398924732208252} | train loss {'Reaction outcome loss': 0.23761815561643426, 'Total loss': 0.23761815561643426}
2023-01-04 00:41:17,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:17,477 INFO:     Epoch: 43
2023-01-04 00:41:19,070 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3975164473056793, 'Total loss': 0.3975164473056793} | train loss {'Reaction outcome loss': 0.23612404514805993, 'Total loss': 0.23612404514805993}
2023-01-04 00:41:19,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:19,070 INFO:     Epoch: 44
2023-01-04 00:41:20,662 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3791971027851105, 'Total loss': 0.3791971027851105} | train loss {'Reaction outcome loss': 0.2328944179293551, 'Total loss': 0.2328944179293551}
2023-01-04 00:41:20,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:20,663 INFO:     Epoch: 45
2023-01-04 00:41:22,254 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42149817645549775, 'Total loss': 0.42149817645549775} | train loss {'Reaction outcome loss': 0.22855418025300014, 'Total loss': 0.22855418025300014}
2023-01-04 00:41:22,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:22,254 INFO:     Epoch: 46
2023-01-04 00:41:23,845 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4154358367125193, 'Total loss': 0.4154358367125193} | train loss {'Reaction outcome loss': 0.22847088110511718, 'Total loss': 0.22847088110511718}
2023-01-04 00:41:23,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:23,846 INFO:     Epoch: 47
2023-01-04 00:41:25,427 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.391208553314209, 'Total loss': 0.391208553314209} | train loss {'Reaction outcome loss': 0.2256530020655929, 'Total loss': 0.2256530020655929}
2023-01-04 00:41:25,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:25,427 INFO:     Epoch: 48
2023-01-04 00:41:27,020 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38708082139492034, 'Total loss': 0.38708082139492034} | train loss {'Reaction outcome loss': 0.22265927777904004, 'Total loss': 0.22265927777904004}
2023-01-04 00:41:27,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:27,021 INFO:     Epoch: 49
2023-01-04 00:41:28,604 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3974018047253291, 'Total loss': 0.3974018047253291} | train loss {'Reaction outcome loss': 0.2259460547399046, 'Total loss': 0.2259460547399046}
2023-01-04 00:41:28,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:28,604 INFO:     Epoch: 50
2023-01-04 00:41:30,226 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4161919022599856, 'Total loss': 0.4161919022599856} | train loss {'Reaction outcome loss': 0.22821893123372042, 'Total loss': 0.22821893123372042}
2023-01-04 00:41:30,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:30,226 INFO:     Epoch: 51
2023-01-04 00:41:31,848 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40295590112606683, 'Total loss': 0.40295590112606683} | train loss {'Reaction outcome loss': 0.21762139014975654, 'Total loss': 0.21762139014975654}
2023-01-04 00:41:31,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:31,848 INFO:     Epoch: 52
2023-01-04 00:41:33,445 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4223101456960042, 'Total loss': 0.4223101456960042} | train loss {'Reaction outcome loss': 0.2198104269100704, 'Total loss': 0.2198104269100704}
2023-01-04 00:41:33,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:33,446 INFO:     Epoch: 53
2023-01-04 00:41:35,035 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41570392648379006, 'Total loss': 0.41570392648379006} | train loss {'Reaction outcome loss': 0.2175967978529524, 'Total loss': 0.2175967978529524}
2023-01-04 00:41:35,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:35,035 INFO:     Epoch: 54
2023-01-04 00:41:36,623 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4225048174460729, 'Total loss': 0.4225048174460729} | train loss {'Reaction outcome loss': 0.21110059302030265, 'Total loss': 0.21110059302030265}
2023-01-04 00:41:36,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:36,623 INFO:     Epoch: 55
2023-01-04 00:41:38,246 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43389503061771395, 'Total loss': 0.43389503061771395} | train loss {'Reaction outcome loss': 0.21049068437206397, 'Total loss': 0.21049068437206397}
2023-01-04 00:41:38,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:38,246 INFO:     Epoch: 56
2023-01-04 00:41:39,857 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42656864126523336, 'Total loss': 0.42656864126523336} | train loss {'Reaction outcome loss': 0.2078218964966979, 'Total loss': 0.2078218964966979}
2023-01-04 00:41:39,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:39,859 INFO:     Epoch: 57
2023-01-04 00:41:41,481 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43331331610679624, 'Total loss': 0.43331331610679624} | train loss {'Reaction outcome loss': 0.20571450248657577, 'Total loss': 0.20571450248657577}
2023-01-04 00:41:41,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:41,481 INFO:     Epoch: 58
2023-01-04 00:41:43,068 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43600314954916636, 'Total loss': 0.43600314954916636} | train loss {'Reaction outcome loss': 0.2058509270242159, 'Total loss': 0.2058509270242159}
2023-01-04 00:41:43,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:43,069 INFO:     Epoch: 59
2023-01-04 00:41:44,642 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41168709099292755, 'Total loss': 0.41168709099292755} | train loss {'Reaction outcome loss': 0.20818645380221415, 'Total loss': 0.20818645380221415}
2023-01-04 00:41:44,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:44,642 INFO:     Epoch: 60
2023-01-04 00:41:46,265 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43360506693522133, 'Total loss': 0.43360506693522133} | train loss {'Reaction outcome loss': 0.20399380163808414, 'Total loss': 0.20399380163808414}
2023-01-04 00:41:46,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:46,267 INFO:     Epoch: 61
2023-01-04 00:41:47,890 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4198077748219172, 'Total loss': 0.4198077748219172} | train loss {'Reaction outcome loss': 0.2019845288925116, 'Total loss': 0.2019845288925116}
2023-01-04 00:41:47,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:47,890 INFO:     Epoch: 62
2023-01-04 00:41:49,513 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4405249610543251, 'Total loss': 0.4405249610543251} | train loss {'Reaction outcome loss': 0.20133630431635116, 'Total loss': 0.20133630431635116}
2023-01-04 00:41:49,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:49,514 INFO:     Epoch: 63
2023-01-04 00:41:51,100 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41333143015702567, 'Total loss': 0.41333143015702567} | train loss {'Reaction outcome loss': 0.1995183367564781, 'Total loss': 0.1995183367564781}
2023-01-04 00:41:51,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:51,102 INFO:     Epoch: 64
2023-01-04 00:41:52,694 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42882379045089086, 'Total loss': 0.42882379045089086} | train loss {'Reaction outcome loss': 0.1973506893580476, 'Total loss': 0.1973506893580476}
2023-01-04 00:41:52,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:52,695 INFO:     Epoch: 65
2023-01-04 00:41:54,296 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42322280009587604, 'Total loss': 0.42322280009587604} | train loss {'Reaction outcome loss': 0.1949591860073902, 'Total loss': 0.1949591860073902}
2023-01-04 00:41:54,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:54,296 INFO:     Epoch: 66
2023-01-04 00:41:55,915 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4406193971633911, 'Total loss': 0.4406193971633911} | train loss {'Reaction outcome loss': 0.1971945832213522, 'Total loss': 0.1971945832213522}
2023-01-04 00:41:55,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:55,915 INFO:     Epoch: 67
2023-01-04 00:41:57,546 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43408432404200237, 'Total loss': 0.43408432404200237} | train loss {'Reaction outcome loss': 0.1982599929029095, 'Total loss': 0.1982599929029095}
2023-01-04 00:41:57,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:57,547 INFO:     Epoch: 68
2023-01-04 00:41:59,166 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42339639862378436, 'Total loss': 0.42339639862378436} | train loss {'Reaction outcome loss': 0.20107375842496328, 'Total loss': 0.20107375842496328}
2023-01-04 00:41:59,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:41:59,167 INFO:     Epoch: 69
2023-01-04 00:42:00,771 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4374764412641525, 'Total loss': 0.4374764412641525} | train loss {'Reaction outcome loss': 0.19275331419919603, 'Total loss': 0.19275331419919603}
2023-01-04 00:42:00,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:00,771 INFO:     Epoch: 70
2023-01-04 00:42:02,375 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4322633405526479, 'Total loss': 0.4322633405526479} | train loss {'Reaction outcome loss': 0.19413070624991172, 'Total loss': 0.19413070624991172}
2023-01-04 00:42:02,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:02,377 INFO:     Epoch: 71
2023-01-04 00:42:03,993 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42937587598959603, 'Total loss': 0.42937587598959603} | train loss {'Reaction outcome loss': 0.19871015700957048, 'Total loss': 0.19871015700957048}
2023-01-04 00:42:03,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:03,993 INFO:     Epoch: 72
2023-01-04 00:42:05,587 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43573635121186577, 'Total loss': 0.43573635121186577} | train loss {'Reaction outcome loss': 0.1919778862806118, 'Total loss': 0.1919778862806118}
2023-01-04 00:42:05,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:05,587 INFO:     Epoch: 73
2023-01-04 00:42:07,218 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4236105024814606, 'Total loss': 0.4236105024814606} | train loss {'Reaction outcome loss': 0.19299624178893282, 'Total loss': 0.19299624178893282}
2023-01-04 00:42:07,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:07,219 INFO:     Epoch: 74
2023-01-04 00:42:08,843 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41129768391450244, 'Total loss': 0.41129768391450244} | train loss {'Reaction outcome loss': 0.1853993280276262, 'Total loss': 0.1853993280276262}
2023-01-04 00:42:08,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:08,844 INFO:     Epoch: 75
2023-01-04 00:42:10,446 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43805236319700874, 'Total loss': 0.43805236319700874} | train loss {'Reaction outcome loss': 0.18587091298431388, 'Total loss': 0.18587091298431388}
2023-01-04 00:42:10,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:10,446 INFO:     Epoch: 76
2023-01-04 00:42:12,046 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4419334848721822, 'Total loss': 0.4419334848721822} | train loss {'Reaction outcome loss': 0.18414590018463955, 'Total loss': 0.18414590018463955}
2023-01-04 00:42:12,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:12,046 INFO:     Epoch: 77
2023-01-04 00:42:13,676 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44062629640102385, 'Total loss': 0.44062629640102385} | train loss {'Reaction outcome loss': 0.1846568372540945, 'Total loss': 0.1846568372540945}
2023-01-04 00:42:13,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:13,678 INFO:     Epoch: 78
2023-01-04 00:42:15,298 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4432209367553393, 'Total loss': 0.4432209367553393} | train loss {'Reaction outcome loss': 0.18386705318951738, 'Total loss': 0.18386705318951738}
2023-01-04 00:42:15,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:15,298 INFO:     Epoch: 79
2023-01-04 00:42:16,929 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4291343669096629, 'Total loss': 0.4291343669096629} | train loss {'Reaction outcome loss': 0.18121795230621027, 'Total loss': 0.18121795230621027}
2023-01-04 00:42:16,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:16,930 INFO:     Epoch: 80
2023-01-04 00:42:18,540 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4401714503765106, 'Total loss': 0.4401714503765106} | train loss {'Reaction outcome loss': 0.18251979000447993, 'Total loss': 0.18251979000447993}
2023-01-04 00:42:18,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:18,541 INFO:     Epoch: 81
2023-01-04 00:42:20,136 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40908823907375336, 'Total loss': 0.40908823907375336} | train loss {'Reaction outcome loss': 0.1777926022777388, 'Total loss': 0.1777926022777388}
2023-01-04 00:42:20,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:20,137 INFO:     Epoch: 82
2023-01-04 00:42:21,742 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4129471302032471, 'Total loss': 0.4129471302032471} | train loss {'Reaction outcome loss': 0.17832017221456004, 'Total loss': 0.17832017221456004}
2023-01-04 00:42:21,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:21,742 INFO:     Epoch: 83
2023-01-04 00:42:23,351 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4184809610247612, 'Total loss': 0.4184809610247612} | train loss {'Reaction outcome loss': 0.1763510698894435, 'Total loss': 0.1763510698894435}
2023-01-04 00:42:23,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:23,352 INFO:     Epoch: 84
2023-01-04 00:42:24,964 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4337831219037374, 'Total loss': 0.4337831219037374} | train loss {'Reaction outcome loss': 0.17567873475698012, 'Total loss': 0.17567873475698012}
2023-01-04 00:42:24,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:24,964 INFO:     Epoch: 85
2023-01-04 00:42:26,596 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43364163637161257, 'Total loss': 0.43364163637161257} | train loss {'Reaction outcome loss': 0.17502236985129074, 'Total loss': 0.17502236985129074}
2023-01-04 00:42:26,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:26,598 INFO:     Epoch: 86
2023-01-04 00:42:28,185 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4124627704421679, 'Total loss': 0.4124627704421679} | train loss {'Reaction outcome loss': 0.177049172502281, 'Total loss': 0.177049172502281}
2023-01-04 00:42:28,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:28,185 INFO:     Epoch: 87
2023-01-04 00:42:29,771 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43181902468204497, 'Total loss': 0.43181902468204497} | train loss {'Reaction outcome loss': 0.17503249753404038, 'Total loss': 0.17503249753404038}
2023-01-04 00:42:29,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:29,771 INFO:     Epoch: 88
2023-01-04 00:42:31,400 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42518364191055297, 'Total loss': 0.42518364191055297} | train loss {'Reaction outcome loss': 0.18324642984763437, 'Total loss': 0.18324642984763437}
2023-01-04 00:42:31,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:31,400 INFO:     Epoch: 89
2023-01-04 00:42:33,021 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43729268113772074, 'Total loss': 0.43729268113772074} | train loss {'Reaction outcome loss': 0.18956850338575193, 'Total loss': 0.18956850338575193}
2023-01-04 00:42:33,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:33,022 INFO:     Epoch: 90
2023-01-04 00:42:34,616 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4464260101318359, 'Total loss': 0.4464260101318359} | train loss {'Reaction outcome loss': 0.1723440133062178, 'Total loss': 0.1723440133062178}
2023-01-04 00:42:34,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:34,616 INFO:     Epoch: 91
2023-01-04 00:42:36,207 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44654379884401957, 'Total loss': 0.44654379884401957} | train loss {'Reaction outcome loss': 0.17755053350782068, 'Total loss': 0.17755053350782068}
2023-01-04 00:42:36,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:36,207 INFO:     Epoch: 92
2023-01-04 00:42:37,786 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43721249798933665, 'Total loss': 0.43721249798933665} | train loss {'Reaction outcome loss': 0.17213727484119337, 'Total loss': 0.17213727484119337}
2023-01-04 00:42:37,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:37,787 INFO:     Epoch: 93
2023-01-04 00:42:39,360 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43795964221159617, 'Total loss': 0.43795964221159617} | train loss {'Reaction outcome loss': 0.17204334288523399, 'Total loss': 0.17204334288523399}
2023-01-04 00:42:39,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:39,360 INFO:     Epoch: 94
2023-01-04 00:42:40,971 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41955493787924447, 'Total loss': 0.41955493787924447} | train loss {'Reaction outcome loss': 0.16986198396304078, 'Total loss': 0.16986198396304078}
2023-01-04 00:42:40,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:40,971 INFO:     Epoch: 95
2023-01-04 00:42:42,584 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42335627774397533, 'Total loss': 0.42335627774397533} | train loss {'Reaction outcome loss': 0.17115373129322045, 'Total loss': 0.17115373129322045}
2023-01-04 00:42:42,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:42,584 INFO:     Epoch: 96
2023-01-04 00:42:44,203 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41513803973793983, 'Total loss': 0.41513803973793983} | train loss {'Reaction outcome loss': 0.1763522951069994, 'Total loss': 0.1763522951069994}
2023-01-04 00:42:44,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:44,203 INFO:     Epoch: 97
2023-01-04 00:42:45,788 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43654643297195433, 'Total loss': 0.43654643297195433} | train loss {'Reaction outcome loss': 0.1681739938819943, 'Total loss': 0.1681739938819943}
2023-01-04 00:42:45,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:45,789 INFO:     Epoch: 98
2023-01-04 00:42:47,360 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43907628655433656, 'Total loss': 0.43907628655433656} | train loss {'Reaction outcome loss': 0.16518249316794792, 'Total loss': 0.16518249316794792}
2023-01-04 00:42:47,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:47,360 INFO:     Epoch: 99
2023-01-04 00:42:48,944 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44212327649195987, 'Total loss': 0.44212327649195987} | train loss {'Reaction outcome loss': 0.16592012202380685, 'Total loss': 0.16592012202380685}
2023-01-04 00:42:48,944 INFO:     Best model found after epoch 18 of 100.
2023-01-04 00:42:48,944 INFO:   Done with stage: TRAINING
2023-01-04 00:42:48,944 INFO:   Starting stage: EVALUATION
2023-01-04 00:42:49,074 INFO:   Done with stage: EVALUATION
2023-01-04 00:42:49,082 INFO:   Leaving out SEQ value Fold_0
2023-01-04 00:42:49,095 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 00:42:49,095 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:42:49,747 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:42:49,747 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:42:49,817 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:42:49,817 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:42:49,817 INFO:     No hyperparam tuning for this model
2023-01-04 00:42:49,817 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:42:49,817 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:42:49,818 INFO:     None feature selector for col prot
2023-01-04 00:42:49,818 INFO:     None feature selector for col prot
2023-01-04 00:42:49,818 INFO:     None feature selector for col prot
2023-01-04 00:42:49,819 INFO:     None feature selector for col chem
2023-01-04 00:42:49,819 INFO:     None feature selector for col chem
2023-01-04 00:42:49,819 INFO:     None feature selector for col chem
2023-01-04 00:42:49,819 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:42:49,819 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:42:49,820 INFO:     Number of params in model 70141
2023-01-04 00:42:49,823 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:42:49,823 INFO:   Starting stage: TRAINING
2023-01-04 00:42:49,868 INFO:     Val loss before train {'Reaction outcome loss': 1.0357859055201213, 'Total loss': 1.0357859055201213}
2023-01-04 00:42:49,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:49,868 INFO:     Epoch: 0
2023-01-04 00:42:51,467 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7010371267795563, 'Total loss': 0.7010371267795563} | train loss {'Reaction outcome loss': 0.8475031745822533, 'Total loss': 0.8475031745822533}
2023-01-04 00:42:51,468 INFO:     Found new best model at epoch 0
2023-01-04 00:42:51,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:51,469 INFO:     Epoch: 1
2023-01-04 00:42:53,081 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5815989236036937, 'Total loss': 0.5815989236036937} | train loss {'Reaction outcome loss': 0.605876742389755, 'Total loss': 0.605876742389755}
2023-01-04 00:42:53,081 INFO:     Found new best model at epoch 1
2023-01-04 00:42:53,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:53,082 INFO:     Epoch: 2
2023-01-04 00:42:54,664 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5617352545261383, 'Total loss': 0.5617352545261383} | train loss {'Reaction outcome loss': 0.5354718586528654, 'Total loss': 0.5354718586528654}
2023-01-04 00:42:54,664 INFO:     Found new best model at epoch 2
2023-01-04 00:42:54,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:54,665 INFO:     Epoch: 3
2023-01-04 00:42:56,253 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5407239516576131, 'Total loss': 0.5407239516576131} | train loss {'Reaction outcome loss': 0.5080461076636246, 'Total loss': 0.5080461076636246}
2023-01-04 00:42:56,253 INFO:     Found new best model at epoch 3
2023-01-04 00:42:56,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:56,254 INFO:     Epoch: 4
2023-01-04 00:42:57,838 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5334637115399042, 'Total loss': 0.5334637115399042} | train loss {'Reaction outcome loss': 0.4764880233687227, 'Total loss': 0.4764880233687227}
2023-01-04 00:42:57,839 INFO:     Found new best model at epoch 4
2023-01-04 00:42:57,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:57,840 INFO:     Epoch: 5
2023-01-04 00:42:59,424 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4956274966398875, 'Total loss': 0.4956274966398875} | train loss {'Reaction outcome loss': 0.4509125978321485, 'Total loss': 0.4509125978321485}
2023-01-04 00:42:59,424 INFO:     Found new best model at epoch 5
2023-01-04 00:42:59,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:42:59,425 INFO:     Epoch: 6
2023-01-04 00:43:01,006 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49435845017433167, 'Total loss': 0.49435845017433167} | train loss {'Reaction outcome loss': 0.4341545580326161, 'Total loss': 0.4341545580326161}
2023-01-04 00:43:01,006 INFO:     Found new best model at epoch 6
2023-01-04 00:43:01,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:01,007 INFO:     Epoch: 7
2023-01-04 00:43:02,588 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47568382918834684, 'Total loss': 0.47568382918834684} | train loss {'Reaction outcome loss': 0.41863343995604396, 'Total loss': 0.41863343995604396}
2023-01-04 00:43:02,588 INFO:     Found new best model at epoch 7
2023-01-04 00:43:02,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:02,589 INFO:     Epoch: 8
2023-01-04 00:43:04,161 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4686466693878174, 'Total loss': 0.4686466693878174} | train loss {'Reaction outcome loss': 0.40844476711092703, 'Total loss': 0.40844476711092703}
2023-01-04 00:43:04,162 INFO:     Found new best model at epoch 8
2023-01-04 00:43:04,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:04,163 INFO:     Epoch: 9
2023-01-04 00:43:05,735 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45306881666183474, 'Total loss': 0.45306881666183474} | train loss {'Reaction outcome loss': 0.39644732399619237, 'Total loss': 0.39644732399619237}
2023-01-04 00:43:05,735 INFO:     Found new best model at epoch 9
2023-01-04 00:43:05,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:05,736 INFO:     Epoch: 10
2023-01-04 00:43:07,322 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46740923523902894, 'Total loss': 0.46740923523902894} | train loss {'Reaction outcome loss': 0.3886716646020827, 'Total loss': 0.3886716646020827}
2023-01-04 00:43:07,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:07,322 INFO:     Epoch: 11
2023-01-04 00:43:08,909 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44922546048959094, 'Total loss': 0.44922546048959094} | train loss {'Reaction outcome loss': 0.37966594463585457, 'Total loss': 0.37966594463585457}
2023-01-04 00:43:08,910 INFO:     Found new best model at epoch 11
2023-01-04 00:43:08,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:08,911 INFO:     Epoch: 12
2023-01-04 00:43:10,500 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4319729392727216, 'Total loss': 0.4319729392727216} | train loss {'Reaction outcome loss': 0.3687535603933519, 'Total loss': 0.3687535603933519}
2023-01-04 00:43:10,501 INFO:     Found new best model at epoch 12
2023-01-04 00:43:10,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:10,502 INFO:     Epoch: 13
2023-01-04 00:43:12,069 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4445548981428146, 'Total loss': 0.4445548981428146} | train loss {'Reaction outcome loss': 0.3631214415418335, 'Total loss': 0.3631214415418335}
2023-01-04 00:43:12,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:12,069 INFO:     Epoch: 14
2023-01-04 00:43:13,678 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45528170267740886, 'Total loss': 0.45528170267740886} | train loss {'Reaction outcome loss': 0.354717658773618, 'Total loss': 0.354717658773618}
2023-01-04 00:43:13,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:13,679 INFO:     Epoch: 15
2023-01-04 00:43:15,288 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4423921495676041, 'Total loss': 0.4423921495676041} | train loss {'Reaction outcome loss': 0.3472552648224841, 'Total loss': 0.3472552648224841}
2023-01-04 00:43:15,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:15,289 INFO:     Epoch: 16
2023-01-04 00:43:16,898 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45803768634796144, 'Total loss': 0.45803768634796144} | train loss {'Reaction outcome loss': 0.34006683260161913, 'Total loss': 0.34006683260161913}
2023-01-04 00:43:16,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:16,899 INFO:     Epoch: 17
2023-01-04 00:43:18,487 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4466000219186147, 'Total loss': 0.4466000219186147} | train loss {'Reaction outcome loss': 0.3336437177317946, 'Total loss': 0.3336437177317946}
2023-01-04 00:43:18,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:18,487 INFO:     Epoch: 18
2023-01-04 00:43:20,075 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4403170843919118, 'Total loss': 0.4403170843919118} | train loss {'Reaction outcome loss': 0.32795729826919845, 'Total loss': 0.32795729826919845}
2023-01-04 00:43:20,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:20,076 INFO:     Epoch: 19
2023-01-04 00:43:21,670 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4518851468960444, 'Total loss': 0.4518851468960444} | train loss {'Reaction outcome loss': 0.32313206464565103, 'Total loss': 0.32313206464565103}
2023-01-04 00:43:21,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:21,670 INFO:     Epoch: 20
2023-01-04 00:43:23,271 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4478332569201787, 'Total loss': 0.4478332569201787} | train loss {'Reaction outcome loss': 0.31507697542184504, 'Total loss': 0.31507697542184504}
2023-01-04 00:43:23,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:23,273 INFO:     Epoch: 21
2023-01-04 00:43:24,869 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.429219056169192, 'Total loss': 0.429219056169192} | train loss {'Reaction outcome loss': 0.31357016654658143, 'Total loss': 0.31357016654658143}
2023-01-04 00:43:24,869 INFO:     Found new best model at epoch 21
2023-01-04 00:43:24,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:24,870 INFO:     Epoch: 22
2023-01-04 00:43:26,477 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43159855107466377, 'Total loss': 0.43159855107466377} | train loss {'Reaction outcome loss': 0.31105444410923816, 'Total loss': 0.31105444410923816}
2023-01-04 00:43:26,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:26,477 INFO:     Epoch: 23
2023-01-04 00:43:28,090 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4290164848168691, 'Total loss': 0.4290164848168691} | train loss {'Reaction outcome loss': 0.30512276326940546, 'Total loss': 0.30512276326940546}
2023-01-04 00:43:28,091 INFO:     Found new best model at epoch 23
2023-01-04 00:43:28,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:28,092 INFO:     Epoch: 24
2023-01-04 00:43:29,680 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4339700977007548, 'Total loss': 0.4339700977007548} | train loss {'Reaction outcome loss': 0.30335557493516174, 'Total loss': 0.30335557493516174}
2023-01-04 00:43:29,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:29,680 INFO:     Epoch: 25
2023-01-04 00:43:31,285 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4326536476612091, 'Total loss': 0.4326536476612091} | train loss {'Reaction outcome loss': 0.2956250455467523, 'Total loss': 0.2956250455467523}
2023-01-04 00:43:31,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:31,285 INFO:     Epoch: 26
2023-01-04 00:43:32,873 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44066341618696847, 'Total loss': 0.44066341618696847} | train loss {'Reaction outcome loss': 0.290773840695666, 'Total loss': 0.290773840695666}
2023-01-04 00:43:32,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:32,874 INFO:     Epoch: 27
2023-01-04 00:43:34,489 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42910140156745913, 'Total loss': 0.42910140156745913} | train loss {'Reaction outcome loss': 0.2863502767463417, 'Total loss': 0.2863502767463417}
2023-01-04 00:43:34,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:34,490 INFO:     Epoch: 28
2023-01-04 00:43:36,075 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45333495537439983, 'Total loss': 0.45333495537439983} | train loss {'Reaction outcome loss': 0.28084052050489583, 'Total loss': 0.28084052050489583}
2023-01-04 00:43:36,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:36,076 INFO:     Epoch: 29
2023-01-04 00:43:37,695 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4286797046661377, 'Total loss': 0.4286797046661377} | train loss {'Reaction outcome loss': 0.27891443564516044, 'Total loss': 0.27891443564516044}
2023-01-04 00:43:37,695 INFO:     Found new best model at epoch 29
2023-01-04 00:43:37,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:37,696 INFO:     Epoch: 30
2023-01-04 00:43:39,278 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4233885357777278, 'Total loss': 0.4233885357777278} | train loss {'Reaction outcome loss': 0.27468882429588964, 'Total loss': 0.27468882429588964}
2023-01-04 00:43:39,278 INFO:     Found new best model at epoch 30
2023-01-04 00:43:39,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:39,279 INFO:     Epoch: 31
2023-01-04 00:43:40,875 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4342746943235397, 'Total loss': 0.4342746943235397} | train loss {'Reaction outcome loss': 0.27159711380026885, 'Total loss': 0.27159711380026885}
2023-01-04 00:43:40,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:40,876 INFO:     Epoch: 32
2023-01-04 00:43:42,463 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4248151570558548, 'Total loss': 0.4248151570558548} | train loss {'Reaction outcome loss': 0.27061071894738986, 'Total loss': 0.27061071894738986}
2023-01-04 00:43:42,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:42,463 INFO:     Epoch: 33
2023-01-04 00:43:44,047 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4242071330547333, 'Total loss': 0.4242071330547333} | train loss {'Reaction outcome loss': 0.26959105819949636, 'Total loss': 0.26959105819949636}
2023-01-04 00:43:44,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:44,047 INFO:     Epoch: 34
2023-01-04 00:43:45,661 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42379621664683026, 'Total loss': 0.42379621664683026} | train loss {'Reaction outcome loss': 0.2635094691725934, 'Total loss': 0.2635094691725934}
2023-01-04 00:43:45,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:45,661 INFO:     Epoch: 35
2023-01-04 00:43:47,281 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42323170055945714, 'Total loss': 0.42323170055945714} | train loss {'Reaction outcome loss': 0.26246441557895445, 'Total loss': 0.26246441557895445}
2023-01-04 00:43:47,282 INFO:     Found new best model at epoch 35
2023-01-04 00:43:47,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:47,283 INFO:     Epoch: 36
2023-01-04 00:43:48,858 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4294106860955556, 'Total loss': 0.4294106860955556} | train loss {'Reaction outcome loss': 0.2598405277720936, 'Total loss': 0.2598405277720936}
2023-01-04 00:43:48,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:48,858 INFO:     Epoch: 37
2023-01-04 00:43:50,452 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4229544977347056, 'Total loss': 0.4229544977347056} | train loss {'Reaction outcome loss': 0.2545019372456422, 'Total loss': 0.2545019372456422}
2023-01-04 00:43:50,452 INFO:     Found new best model at epoch 37
2023-01-04 00:43:50,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:50,453 INFO:     Epoch: 38
2023-01-04 00:43:52,063 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4218911871314049, 'Total loss': 0.4218911871314049} | train loss {'Reaction outcome loss': 0.2781098504429278, 'Total loss': 0.2781098504429278}
2023-01-04 00:43:52,063 INFO:     Found new best model at epoch 38
2023-01-04 00:43:52,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:52,064 INFO:     Epoch: 39
2023-01-04 00:43:53,649 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.411362353960673, 'Total loss': 0.411362353960673} | train loss {'Reaction outcome loss': 0.2653213571757078, 'Total loss': 0.2653213571757078}
2023-01-04 00:43:53,650 INFO:     Found new best model at epoch 39
2023-01-04 00:43:53,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:53,651 INFO:     Epoch: 40
2023-01-04 00:43:55,232 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4264817476272583, 'Total loss': 0.4264817476272583} | train loss {'Reaction outcome loss': 0.2528536254928137, 'Total loss': 0.2528536254928137}
2023-01-04 00:43:55,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:55,232 INFO:     Epoch: 41
2023-01-04 00:43:56,826 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4059847116470337, 'Total loss': 0.4059847116470337} | train loss {'Reaction outcome loss': 0.2473995047149019, 'Total loss': 0.2473995047149019}
2023-01-04 00:43:56,827 INFO:     Found new best model at epoch 41
2023-01-04 00:43:56,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:56,827 INFO:     Epoch: 42
2023-01-04 00:43:58,423 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4036964972813924, 'Total loss': 0.4036964972813924} | train loss {'Reaction outcome loss': 0.2578569050149425, 'Total loss': 0.2578569050149425}
2023-01-04 00:43:58,424 INFO:     Found new best model at epoch 42
2023-01-04 00:43:58,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:43:58,425 INFO:     Epoch: 43
2023-01-04 00:44:00,036 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41239731311798095, 'Total loss': 0.41239731311798095} | train loss {'Reaction outcome loss': 0.2522902014341367, 'Total loss': 0.2522902014341367}
2023-01-04 00:44:00,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:00,036 INFO:     Epoch: 44
2023-01-04 00:44:01,651 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42170769572257993, 'Total loss': 0.42170769572257993} | train loss {'Reaction outcome loss': 0.24119286182816513, 'Total loss': 0.24119286182816513}
2023-01-04 00:44:01,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:01,651 INFO:     Epoch: 45
2023-01-04 00:44:03,271 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42793102165063224, 'Total loss': 0.42793102165063224} | train loss {'Reaction outcome loss': 0.24033499838433403, 'Total loss': 0.24033499838433403}
2023-01-04 00:44:03,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:03,272 INFO:     Epoch: 46
2023-01-04 00:44:04,890 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4038117607434591, 'Total loss': 0.4038117607434591} | train loss {'Reaction outcome loss': 0.2389277543335624, 'Total loss': 0.2389277543335624}
2023-01-04 00:44:04,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:04,891 INFO:     Epoch: 47
2023-01-04 00:44:06,477 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.417187870045503, 'Total loss': 0.417187870045503} | train loss {'Reaction outcome loss': 0.2350774200808635, 'Total loss': 0.2350774200808635}
2023-01-04 00:44:06,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:06,477 INFO:     Epoch: 48
2023-01-04 00:44:08,074 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42171014050642647, 'Total loss': 0.42171014050642647} | train loss {'Reaction outcome loss': 0.2567833297062611, 'Total loss': 0.2567833297062611}
2023-01-04 00:44:08,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:08,074 INFO:     Epoch: 49
2023-01-04 00:44:09,694 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42847462793191277, 'Total loss': 0.42847462793191277} | train loss {'Reaction outcome loss': 0.2628602200985778, 'Total loss': 0.2628602200985778}
2023-01-04 00:44:09,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:09,694 INFO:     Epoch: 50
2023-01-04 00:44:11,280 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41076871554056804, 'Total loss': 0.41076871554056804} | train loss {'Reaction outcome loss': 0.23170364748659558, 'Total loss': 0.23170364748659558}
2023-01-04 00:44:11,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:11,281 INFO:     Epoch: 51
2023-01-04 00:44:12,872 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4052215089400609, 'Total loss': 0.4052215089400609} | train loss {'Reaction outcome loss': 0.22904012050434097, 'Total loss': 0.22904012050434097}
2023-01-04 00:44:12,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:12,872 INFO:     Epoch: 52
2023-01-04 00:44:14,484 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42923651039600375, 'Total loss': 0.42923651039600375} | train loss {'Reaction outcome loss': 0.22796126683850004, 'Total loss': 0.22796126683850004}
2023-01-04 00:44:14,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:14,484 INFO:     Epoch: 53
2023-01-04 00:44:16,070 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4217908968528112, 'Total loss': 0.4217908968528112} | train loss {'Reaction outcome loss': 0.22456604697690372, 'Total loss': 0.22456604697690372}
2023-01-04 00:44:16,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:16,071 INFO:     Epoch: 54
2023-01-04 00:44:17,669 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4246808151404063, 'Total loss': 0.4246808151404063} | train loss {'Reaction outcome loss': 0.22123192772615122, 'Total loss': 0.22123192772615122}
2023-01-04 00:44:17,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:17,670 INFO:     Epoch: 55
2023-01-04 00:44:19,263 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41676703095436096, 'Total loss': 0.41676703095436096} | train loss {'Reaction outcome loss': 0.22610730679192836, 'Total loss': 0.22610730679192836}
2023-01-04 00:44:19,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:19,264 INFO:     Epoch: 56
2023-01-04 00:44:20,887 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42127752900123594, 'Total loss': 0.42127752900123594} | train loss {'Reaction outcome loss': 0.220843431567672, 'Total loss': 0.220843431567672}
2023-01-04 00:44:20,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:20,887 INFO:     Epoch: 57
2023-01-04 00:44:22,497 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43842240373293556, 'Total loss': 0.43842240373293556} | train loss {'Reaction outcome loss': 0.2224246391189703, 'Total loss': 0.2224246391189703}
2023-01-04 00:44:22,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:22,498 INFO:     Epoch: 58
2023-01-04 00:44:24,080 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4204830219348272, 'Total loss': 0.4204830219348272} | train loss {'Reaction outcome loss': 0.2228039467978912, 'Total loss': 0.2228039467978912}
2023-01-04 00:44:24,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:24,080 INFO:     Epoch: 59
2023-01-04 00:44:25,684 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4104726274808248, 'Total loss': 0.4104726274808248} | train loss {'Reaction outcome loss': 0.21810601142478053, 'Total loss': 0.21810601142478053}
2023-01-04 00:44:25,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:25,684 INFO:     Epoch: 60
2023-01-04 00:44:27,279 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4293575326601664, 'Total loss': 0.4293575326601664} | train loss {'Reaction outcome loss': 0.21606933572194606, 'Total loss': 0.21606933572194606}
2023-01-04 00:44:27,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:27,280 INFO:     Epoch: 61
2023-01-04 00:44:28,876 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41066824619968734, 'Total loss': 0.41066824619968734} | train loss {'Reaction outcome loss': 0.2157000955261722, 'Total loss': 0.2157000955261722}
2023-01-04 00:44:28,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:28,877 INFO:     Epoch: 62
2023-01-04 00:44:30,471 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4259353240331014, 'Total loss': 0.4259353240331014} | train loss {'Reaction outcome loss': 0.21239973344357999, 'Total loss': 0.21239973344357999}
2023-01-04 00:44:30,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:30,471 INFO:     Epoch: 63
2023-01-04 00:44:32,074 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4189448028802872, 'Total loss': 0.4189448028802872} | train loss {'Reaction outcome loss': 0.20988068041185834, 'Total loss': 0.20988068041185834}
2023-01-04 00:44:32,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:32,074 INFO:     Epoch: 64
2023-01-04 00:44:33,651 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4239014228185018, 'Total loss': 0.4239014228185018} | train loss {'Reaction outcome loss': 0.2110082052507926, 'Total loss': 0.2110082052507926}
2023-01-04 00:44:33,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:33,653 INFO:     Epoch: 65
2023-01-04 00:44:35,242 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40698027710119883, 'Total loss': 0.40698027710119883} | train loss {'Reaction outcome loss': 0.215999531870087, 'Total loss': 0.215999531870087}
2023-01-04 00:44:35,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:35,242 INFO:     Epoch: 66
2023-01-04 00:44:36,828 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41975475003321966, 'Total loss': 0.41975475003321966} | train loss {'Reaction outcome loss': 0.22231969396597234, 'Total loss': 0.22231969396597234}
2023-01-04 00:44:36,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:36,828 INFO:     Epoch: 67
2023-01-04 00:44:38,452 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44818633993466694, 'Total loss': 0.44818633993466694} | train loss {'Reaction outcome loss': 0.21907261489094168, 'Total loss': 0.21907261489094168}
2023-01-04 00:44:38,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:38,452 INFO:     Epoch: 68
2023-01-04 00:44:40,078 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4218602985143661, 'Total loss': 0.4218602985143661} | train loss {'Reaction outcome loss': 0.2186793037158761, 'Total loss': 0.2186793037158761}
2023-01-04 00:44:40,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:40,079 INFO:     Epoch: 69
2023-01-04 00:44:41,678 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4233107308546702, 'Total loss': 0.4233107308546702} | train loss {'Reaction outcome loss': 0.20289158376281324, 'Total loss': 0.20289158376281324}
2023-01-04 00:44:41,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:41,679 INFO:     Epoch: 70
2023-01-04 00:44:43,261 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4325895647207896, 'Total loss': 0.4325895647207896} | train loss {'Reaction outcome loss': 0.1982259251262408, 'Total loss': 0.1982259251262408}
2023-01-04 00:44:43,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:43,261 INFO:     Epoch: 71
2023-01-04 00:44:44,876 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4231496642033259, 'Total loss': 0.4231496642033259} | train loss {'Reaction outcome loss': 0.19779156877294832, 'Total loss': 0.19779156877294832}
2023-01-04 00:44:44,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:44,876 INFO:     Epoch: 72
2023-01-04 00:44:46,495 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4377366304397583, 'Total loss': 0.4377366304397583} | train loss {'Reaction outcome loss': 0.19990025118560248, 'Total loss': 0.19990025118560248}
2023-01-04 00:44:46,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:46,495 INFO:     Epoch: 73
2023-01-04 00:44:48,085 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4330435961484909, 'Total loss': 0.4330435961484909} | train loss {'Reaction outcome loss': 0.19892140358485672, 'Total loss': 0.19892140358485672}
2023-01-04 00:44:48,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:48,086 INFO:     Epoch: 74
2023-01-04 00:44:49,673 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4372331152359645, 'Total loss': 0.4372331152359645} | train loss {'Reaction outcome loss': 0.19424501435334104, 'Total loss': 0.19424501435334104}
2023-01-04 00:44:49,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:49,673 INFO:     Epoch: 75
2023-01-04 00:44:51,272 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4205593923727671, 'Total loss': 0.4205593923727671} | train loss {'Reaction outcome loss': 0.19503570093825873, 'Total loss': 0.19503570093825873}
2023-01-04 00:44:51,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:51,272 INFO:     Epoch: 76
2023-01-04 00:44:52,875 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4198925564686457, 'Total loss': 0.4198925564686457} | train loss {'Reaction outcome loss': 0.19515838666373622, 'Total loss': 0.19515838666373622}
2023-01-04 00:44:52,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:52,875 INFO:     Epoch: 77
2023-01-04 00:44:54,501 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4540213793516159, 'Total loss': 0.4540213793516159} | train loss {'Reaction outcome loss': 0.19353466507374728, 'Total loss': 0.19353466507374728}
2023-01-04 00:44:54,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:54,502 INFO:     Epoch: 78
2023-01-04 00:44:56,098 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44813751578330996, 'Total loss': 0.44813751578330996} | train loss {'Reaction outcome loss': 0.19280189322138988, 'Total loss': 0.19280189322138988}
2023-01-04 00:44:56,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:56,098 INFO:     Epoch: 79
2023-01-04 00:44:57,721 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44805794954299927, 'Total loss': 0.44805794954299927} | train loss {'Reaction outcome loss': 0.19312644698420892, 'Total loss': 0.19312644698420892}
2023-01-04 00:44:57,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:57,721 INFO:     Epoch: 80
2023-01-04 00:44:59,339 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4445406377315521, 'Total loss': 0.4445406377315521} | train loss {'Reaction outcome loss': 0.19409725858249527, 'Total loss': 0.19409725858249527}
2023-01-04 00:44:59,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:44:59,340 INFO:     Epoch: 81
2023-01-04 00:45:00,937 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43684266408284506, 'Total loss': 0.43684266408284506} | train loss {'Reaction outcome loss': 0.195486907822867, 'Total loss': 0.195486907822867}
2023-01-04 00:45:00,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:00,937 INFO:     Epoch: 82
2023-01-04 00:45:02,527 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45496303737163546, 'Total loss': 0.45496303737163546} | train loss {'Reaction outcome loss': 0.18918058646370206, 'Total loss': 0.18918058646370206}
2023-01-04 00:45:02,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:02,527 INFO:     Epoch: 83
2023-01-04 00:45:04,119 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4153955072164536, 'Total loss': 0.4153955072164536} | train loss {'Reaction outcome loss': 0.1873704291659954, 'Total loss': 0.1873704291659954}
2023-01-04 00:45:04,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:04,119 INFO:     Epoch: 84
2023-01-04 00:45:05,713 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4377930839856466, 'Total loss': 0.4377930839856466} | train loss {'Reaction outcome loss': 0.18751088180579245, 'Total loss': 0.18751088180579245}
2023-01-04 00:45:05,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:05,714 INFO:     Epoch: 85
2023-01-04 00:45:07,305 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44827820956707, 'Total loss': 0.44827820956707} | train loss {'Reaction outcome loss': 0.18872086761331192, 'Total loss': 0.18872086761331192}
2023-01-04 00:45:07,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:07,305 INFO:     Epoch: 86
2023-01-04 00:45:08,890 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44059580465157827, 'Total loss': 0.44059580465157827} | train loss {'Reaction outcome loss': 0.18370045353725983, 'Total loss': 0.18370045353725983}
2023-01-04 00:45:08,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:08,890 INFO:     Epoch: 87
2023-01-04 00:45:10,471 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41435687529544035, 'Total loss': 0.41435687529544035} | train loss {'Reaction outcome loss': 0.19346066917954147, 'Total loss': 0.19346066917954147}
2023-01-04 00:45:10,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:10,473 INFO:     Epoch: 88
2023-01-04 00:45:12,063 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4369465659062068, 'Total loss': 0.4369465659062068} | train loss {'Reaction outcome loss': 0.18868265817771948, 'Total loss': 0.18868265817771948}
2023-01-04 00:45:12,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:12,063 INFO:     Epoch: 89
2023-01-04 00:45:13,664 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43149683078130086, 'Total loss': 0.43149683078130086} | train loss {'Reaction outcome loss': 0.18397262537948098, 'Total loss': 0.18397262537948098}
2023-01-04 00:45:13,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:13,665 INFO:     Epoch: 90
2023-01-04 00:45:15,289 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4483438233534495, 'Total loss': 0.4483438233534495} | train loss {'Reaction outcome loss': 0.18013341384737389, 'Total loss': 0.18013341384737389}
2023-01-04 00:45:15,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:15,289 INFO:     Epoch: 91
2023-01-04 00:45:16,915 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42101100236177447, 'Total loss': 0.42101100236177447} | train loss {'Reaction outcome loss': 0.18156397175651207, 'Total loss': 0.18156397175651207}
2023-01-04 00:45:16,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:16,916 INFO:     Epoch: 92
2023-01-04 00:45:18,498 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43937544425328573, 'Total loss': 0.43937544425328573} | train loss {'Reaction outcome loss': 0.17985728089157763, 'Total loss': 0.17985728089157763}
2023-01-04 00:45:18,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:18,498 INFO:     Epoch: 93
2023-01-04 00:45:20,088 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4219882527987162, 'Total loss': 0.4219882527987162} | train loss {'Reaction outcome loss': 0.1815596093270553, 'Total loss': 0.1815596093270553}
2023-01-04 00:45:20,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:20,089 INFO:     Epoch: 94
2023-01-04 00:45:21,695 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4282749543587367, 'Total loss': 0.4282749543587367} | train loss {'Reaction outcome loss': 0.1782134583154666, 'Total loss': 0.1782134583154666}
2023-01-04 00:45:21,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:21,695 INFO:     Epoch: 95
2023-01-04 00:45:23,288 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41955113572378955, 'Total loss': 0.41955113572378955} | train loss {'Reaction outcome loss': 0.18085466821814433, 'Total loss': 0.18085466821814433}
2023-01-04 00:45:23,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:23,289 INFO:     Epoch: 96
2023-01-04 00:45:24,879 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46403952439626056, 'Total loss': 0.46403952439626056} | train loss {'Reaction outcome loss': 0.17749295746772617, 'Total loss': 0.17749295746772617}
2023-01-04 00:45:24,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:24,879 INFO:     Epoch: 97
2023-01-04 00:45:26,490 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4210261185963949, 'Total loss': 0.4210261185963949} | train loss {'Reaction outcome loss': 0.18145488014343372, 'Total loss': 0.18145488014343372}
2023-01-04 00:45:26,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:26,490 INFO:     Epoch: 98
2023-01-04 00:45:28,113 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44308823148409526, 'Total loss': 0.44308823148409526} | train loss {'Reaction outcome loss': 0.17576123822979844, 'Total loss': 0.17576123822979844}
2023-01-04 00:45:28,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:28,115 INFO:     Epoch: 99
2023-01-04 00:45:29,716 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4284148126840591, 'Total loss': 0.4284148126840591} | train loss {'Reaction outcome loss': 0.17489033575006085, 'Total loss': 0.17489033575006085}
2023-01-04 00:45:29,717 INFO:     Best model found after epoch 43 of 100.
2023-01-04 00:45:29,717 INFO:   Done with stage: TRAINING
2023-01-04 00:45:29,717 INFO:   Starting stage: EVALUATION
2023-01-04 00:45:29,847 INFO:   Done with stage: EVALUATION
2023-01-04 00:45:29,848 INFO:   Leaving out SEQ value Fold_1
2023-01-04 00:45:29,861 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 00:45:29,861 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:45:30,519 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:45:30,519 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:45:30,589 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:45:30,589 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:45:30,589 INFO:     No hyperparam tuning for this model
2023-01-04 00:45:30,589 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:45:30,589 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:45:30,590 INFO:     None feature selector for col prot
2023-01-04 00:45:30,590 INFO:     None feature selector for col prot
2023-01-04 00:45:30,590 INFO:     None feature selector for col prot
2023-01-04 00:45:30,591 INFO:     None feature selector for col chem
2023-01-04 00:45:30,591 INFO:     None feature selector for col chem
2023-01-04 00:45:30,591 INFO:     None feature selector for col chem
2023-01-04 00:45:30,591 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:45:30,591 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:45:30,592 INFO:     Number of params in model 70141
2023-01-04 00:45:30,595 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:45:30,596 INFO:   Starting stage: TRAINING
2023-01-04 00:45:30,640 INFO:     Val loss before train {'Reaction outcome loss': 0.9801231066385905, 'Total loss': 0.9801231066385905}
2023-01-04 00:45:30,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:30,640 INFO:     Epoch: 0
2023-01-04 00:45:32,236 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7063030620416005, 'Total loss': 0.7063030620416005} | train loss {'Reaction outcome loss': 0.8310690621935688, 'Total loss': 0.8310690621935688}
2023-01-04 00:45:32,236 INFO:     Found new best model at epoch 0
2023-01-04 00:45:32,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:32,237 INFO:     Epoch: 1
2023-01-04 00:45:33,832 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6302111387252808, 'Total loss': 0.6302111387252808} | train loss {'Reaction outcome loss': 0.6159442864574384, 'Total loss': 0.6159442864574384}
2023-01-04 00:45:33,833 INFO:     Found new best model at epoch 1
2023-01-04 00:45:33,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:33,834 INFO:     Epoch: 2
2023-01-04 00:45:35,415 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.55653801659743, 'Total loss': 0.55653801659743} | train loss {'Reaction outcome loss': 0.5445767853247083, 'Total loss': 0.5445767853247083}
2023-01-04 00:45:35,415 INFO:     Found new best model at epoch 2
2023-01-04 00:45:35,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:35,416 INFO:     Epoch: 3
2023-01-04 00:45:36,992 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5440622409184773, 'Total loss': 0.5440622409184773} | train loss {'Reaction outcome loss': 0.5015446959903626, 'Total loss': 0.5015446959903626}
2023-01-04 00:45:36,992 INFO:     Found new best model at epoch 3
2023-01-04 00:45:36,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:36,993 INFO:     Epoch: 4
2023-01-04 00:45:38,616 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.510897292693456, 'Total loss': 0.510897292693456} | train loss {'Reaction outcome loss': 0.46650322750244505, 'Total loss': 0.46650322750244505}
2023-01-04 00:45:38,616 INFO:     Found new best model at epoch 4
2023-01-04 00:45:38,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:38,617 INFO:     Epoch: 5
2023-01-04 00:45:40,208 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.506237119436264, 'Total loss': 0.506237119436264} | train loss {'Reaction outcome loss': 0.4454884433638443, 'Total loss': 0.4454884433638443}
2023-01-04 00:45:40,210 INFO:     Found new best model at epoch 5
2023-01-04 00:45:40,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:40,210 INFO:     Epoch: 6
2023-01-04 00:45:41,803 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5065483530362447, 'Total loss': 0.5065483530362447} | train loss {'Reaction outcome loss': 0.4267983502856847, 'Total loss': 0.4267983502856847}
2023-01-04 00:45:41,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:41,803 INFO:     Epoch: 7
2023-01-04 00:45:43,405 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4653876781463623, 'Total loss': 0.4653876781463623} | train loss {'Reaction outcome loss': 0.4149629215615383, 'Total loss': 0.4149629215615383}
2023-01-04 00:45:43,405 INFO:     Found new best model at epoch 7
2023-01-04 00:45:43,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:43,406 INFO:     Epoch: 8
2023-01-04 00:45:44,990 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5017447829246521, 'Total loss': 0.5017447829246521} | train loss {'Reaction outcome loss': 0.40442164560806926, 'Total loss': 0.40442164560806926}
2023-01-04 00:45:44,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:44,990 INFO:     Epoch: 9
2023-01-04 00:45:46,590 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47924033204714456, 'Total loss': 0.47924033204714456} | train loss {'Reaction outcome loss': 0.3908771957824196, 'Total loss': 0.3908771957824196}
2023-01-04 00:45:46,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:46,592 INFO:     Epoch: 10
2023-01-04 00:45:48,213 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4624577909708023, 'Total loss': 0.4624577909708023} | train loss {'Reaction outcome loss': 0.4063660528888737, 'Total loss': 0.4063660528888737}
2023-01-04 00:45:48,213 INFO:     Found new best model at epoch 10
2023-01-04 00:45:48,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:48,214 INFO:     Epoch: 11
2023-01-04 00:45:49,807 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4645836551984151, 'Total loss': 0.4645836551984151} | train loss {'Reaction outcome loss': 0.3786495176100684, 'Total loss': 0.3786495176100684}
2023-01-04 00:45:49,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:49,807 INFO:     Epoch: 12
2023-01-04 00:45:51,433 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45698536435763043, 'Total loss': 0.45698536435763043} | train loss {'Reaction outcome loss': 0.3803225833436717, 'Total loss': 0.3803225833436717}
2023-01-04 00:45:51,433 INFO:     Found new best model at epoch 12
2023-01-04 00:45:51,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:51,434 INFO:     Epoch: 13
2023-01-04 00:45:53,034 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46594051917394, 'Total loss': 0.46594051917394} | train loss {'Reaction outcome loss': 0.3651909467264794, 'Total loss': 0.3651909467264794}
2023-01-04 00:45:53,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:53,036 INFO:     Epoch: 14
2023-01-04 00:45:54,628 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4475851356983185, 'Total loss': 0.4475851356983185} | train loss {'Reaction outcome loss': 0.35285377472747065, 'Total loss': 0.35285377472747065}
2023-01-04 00:45:54,628 INFO:     Found new best model at epoch 14
2023-01-04 00:45:54,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:54,629 INFO:     Epoch: 15
2023-01-04 00:45:56,234 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4487448255221049, 'Total loss': 0.4487448255221049} | train loss {'Reaction outcome loss': 0.34761049270446825, 'Total loss': 0.34761049270446825}
2023-01-04 00:45:56,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:56,234 INFO:     Epoch: 16
2023-01-04 00:45:57,818 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46674447854359946, 'Total loss': 0.46674447854359946} | train loss {'Reaction outcome loss': 0.3396047132656626, 'Total loss': 0.3396047132656626}
2023-01-04 00:45:57,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:57,818 INFO:     Epoch: 17
2023-01-04 00:45:59,442 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47013849914073946, 'Total loss': 0.47013849914073946} | train loss {'Reaction outcome loss': 0.3432316239923239, 'Total loss': 0.3432316239923239}
2023-01-04 00:45:59,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:45:59,443 INFO:     Epoch: 18
2023-01-04 00:46:01,024 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4443252811829249, 'Total loss': 0.4443252811829249} | train loss {'Reaction outcome loss': 0.34037296721657767, 'Total loss': 0.34037296721657767}
2023-01-04 00:46:01,024 INFO:     Found new best model at epoch 18
2023-01-04 00:46:01,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:01,025 INFO:     Epoch: 19
2023-01-04 00:46:02,625 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45098448991775514, 'Total loss': 0.45098448991775514} | train loss {'Reaction outcome loss': 0.32478342696023005, 'Total loss': 0.32478342696023005}
2023-01-04 00:46:02,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:02,625 INFO:     Epoch: 20
2023-01-04 00:46:04,208 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4482964684565862, 'Total loss': 0.4482964684565862} | train loss {'Reaction outcome loss': 0.3170225712819956, 'Total loss': 0.3170225712819956}
2023-01-04 00:46:04,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:04,208 INFO:     Epoch: 21
2023-01-04 00:46:05,801 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4620744367440542, 'Total loss': 0.4620744367440542} | train loss {'Reaction outcome loss': 0.3128346586990106, 'Total loss': 0.3128346586990106}
2023-01-04 00:46:05,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:05,802 INFO:     Epoch: 22
2023-01-04 00:46:07,395 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47488183081150054, 'Total loss': 0.47488183081150054} | train loss {'Reaction outcome loss': 0.3103575935971964, 'Total loss': 0.3103575935971964}
2023-01-04 00:46:07,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:07,395 INFO:     Epoch: 23
2023-01-04 00:46:08,987 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44596967299779255, 'Total loss': 0.44596967299779255} | train loss {'Reaction outcome loss': 0.30492484134257486, 'Total loss': 0.30492484134257486}
2023-01-04 00:46:08,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:08,987 INFO:     Epoch: 24
2023-01-04 00:46:10,575 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4709165632724762, 'Total loss': 0.4709165632724762} | train loss {'Reaction outcome loss': 0.3087516996631588, 'Total loss': 0.3087516996631588}
2023-01-04 00:46:10,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:10,576 INFO:     Epoch: 25
2023-01-04 00:46:12,148 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44551794131596884, 'Total loss': 0.44551794131596884} | train loss {'Reaction outcome loss': 0.307838362591439, 'Total loss': 0.307838362591439}
2023-01-04 00:46:12,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:12,148 INFO:     Epoch: 26
2023-01-04 00:46:13,733 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4466086566448212, 'Total loss': 0.4466086566448212} | train loss {'Reaction outcome loss': 0.29788693480625533, 'Total loss': 0.29788693480625533}
2023-01-04 00:46:13,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:13,733 INFO:     Epoch: 27
2023-01-04 00:46:15,357 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44248962004979453, 'Total loss': 0.44248962004979453} | train loss {'Reaction outcome loss': 0.2993884831936895, 'Total loss': 0.2993884831936895}
2023-01-04 00:46:15,358 INFO:     Found new best model at epoch 27
2023-01-04 00:46:15,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:15,359 INFO:     Epoch: 28
2023-01-04 00:46:16,991 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45009321769078575, 'Total loss': 0.45009321769078575} | train loss {'Reaction outcome loss': 0.29127112346822803, 'Total loss': 0.29127112346822803}
2023-01-04 00:46:16,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:16,993 INFO:     Epoch: 29
2023-01-04 00:46:18,649 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46600937147935234, 'Total loss': 0.46600937147935234} | train loss {'Reaction outcome loss': 0.2902387175709009, 'Total loss': 0.2902387175709009}
2023-01-04 00:46:18,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:18,650 INFO:     Epoch: 30
2023-01-04 00:46:20,290 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4657326658566793, 'Total loss': 0.4657326658566793} | train loss {'Reaction outcome loss': 0.28128139078077197, 'Total loss': 0.28128139078077197}
2023-01-04 00:46:20,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:20,290 INFO:     Epoch: 31
2023-01-04 00:46:21,943 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4638414045174917, 'Total loss': 0.4638414045174917} | train loss {'Reaction outcome loss': 0.2779332824267339, 'Total loss': 0.2779332824267339}
2023-01-04 00:46:21,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:21,944 INFO:     Epoch: 32
2023-01-04 00:46:23,581 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4547318547964096, 'Total loss': 0.4547318547964096} | train loss {'Reaction outcome loss': 0.2790298655968844, 'Total loss': 0.2790298655968844}
2023-01-04 00:46:23,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:23,581 INFO:     Epoch: 33
2023-01-04 00:46:25,192 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4712327162424723, 'Total loss': 0.4712327162424723} | train loss {'Reaction outcome loss': 0.2718021665578303, 'Total loss': 0.2718021665578303}
2023-01-04 00:46:25,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:25,193 INFO:     Epoch: 34
2023-01-04 00:46:26,821 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4681689510742823, 'Total loss': 0.4681689510742823} | train loss {'Reaction outcome loss': 0.2712590295848423, 'Total loss': 0.2712590295848423}
2023-01-04 00:46:26,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:26,823 INFO:     Epoch: 35
2023-01-04 00:46:28,424 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4649007240931193, 'Total loss': 0.4649007240931193} | train loss {'Reaction outcome loss': 0.26498125712522236, 'Total loss': 0.26498125712522236}
2023-01-04 00:46:28,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:28,424 INFO:     Epoch: 36
2023-01-04 00:46:30,002 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4782049258550008, 'Total loss': 0.4782049258550008} | train loss {'Reaction outcome loss': 0.26768624840601196, 'Total loss': 0.26768624840601196}
2023-01-04 00:46:30,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:30,003 INFO:     Epoch: 37
2023-01-04 00:46:31,599 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4683722347021103, 'Total loss': 0.4683722347021103} | train loss {'Reaction outcome loss': 0.2720303037216502, 'Total loss': 0.2720303037216502}
2023-01-04 00:46:31,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:31,600 INFO:     Epoch: 38
2023-01-04 00:46:33,197 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45930675864219667, 'Total loss': 0.45930675864219667} | train loss {'Reaction outcome loss': 0.25695223734710715, 'Total loss': 0.25695223734710715}
2023-01-04 00:46:33,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:33,198 INFO:     Epoch: 39
2023-01-04 00:46:34,798 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44658101300398506, 'Total loss': 0.44658101300398506} | train loss {'Reaction outcome loss': 0.25306334847877937, 'Total loss': 0.25306334847877937}
2023-01-04 00:46:34,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:34,799 INFO:     Epoch: 40
2023-01-04 00:46:36,396 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4677359044551849, 'Total loss': 0.4677359044551849} | train loss {'Reaction outcome loss': 0.2490091170753737, 'Total loss': 0.2490091170753737}
2023-01-04 00:46:36,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:36,396 INFO:     Epoch: 41
2023-01-04 00:46:37,974 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44747404257456463, 'Total loss': 0.44747404257456463} | train loss {'Reaction outcome loss': 0.25977645674045535, 'Total loss': 0.25977645674045535}
2023-01-04 00:46:37,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:37,974 INFO:     Epoch: 42
2023-01-04 00:46:39,574 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45660132467746734, 'Total loss': 0.45660132467746734} | train loss {'Reaction outcome loss': 0.25394365894675686, 'Total loss': 0.25394365894675686}
2023-01-04 00:46:39,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:39,575 INFO:     Epoch: 43
2023-01-04 00:46:41,157 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44400986631711326, 'Total loss': 0.44400986631711326} | train loss {'Reaction outcome loss': 0.24595409369710292, 'Total loss': 0.24595409369710292}
2023-01-04 00:46:41,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:41,158 INFO:     Epoch: 44
2023-01-04 00:46:42,784 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45982766449451445, 'Total loss': 0.45982766449451445} | train loss {'Reaction outcome loss': 0.24282442794545836, 'Total loss': 0.24282442794545836}
2023-01-04 00:46:42,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:42,784 INFO:     Epoch: 45
2023-01-04 00:46:44,362 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4559661209583282, 'Total loss': 0.4559661209583282} | train loss {'Reaction outcome loss': 0.24031062867805408, 'Total loss': 0.24031062867805408}
2023-01-04 00:46:44,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:44,362 INFO:     Epoch: 46
2023-01-04 00:46:45,956 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4616551617781321, 'Total loss': 0.4616551617781321} | train loss {'Reaction outcome loss': 0.24013282763569252, 'Total loss': 0.24013282763569252}
2023-01-04 00:46:45,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:45,958 INFO:     Epoch: 47
2023-01-04 00:46:47,544 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4657276471455892, 'Total loss': 0.4657276471455892} | train loss {'Reaction outcome loss': 0.24089636077975307, 'Total loss': 0.24089636077975307}
2023-01-04 00:46:47,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:47,544 INFO:     Epoch: 48
2023-01-04 00:46:49,147 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4457802787423134, 'Total loss': 0.4457802787423134} | train loss {'Reaction outcome loss': 0.2346417275864793, 'Total loss': 0.2346417275864793}
2023-01-04 00:46:49,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:49,147 INFO:     Epoch: 49
2023-01-04 00:46:50,772 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4662031273047129, 'Total loss': 0.4662031273047129} | train loss {'Reaction outcome loss': 0.23604418873530475, 'Total loss': 0.23604418873530475}
2023-01-04 00:46:50,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:50,772 INFO:     Epoch: 50
2023-01-04 00:46:52,381 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4620121339956919, 'Total loss': 0.4620121339956919} | train loss {'Reaction outcome loss': 0.23044481505707337, 'Total loss': 0.23044481505707337}
2023-01-04 00:46:52,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:52,382 INFO:     Epoch: 51
2023-01-04 00:46:53,960 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48844785392284396, 'Total loss': 0.48844785392284396} | train loss {'Reaction outcome loss': 0.22901767419070762, 'Total loss': 0.22901767419070762}
2023-01-04 00:46:53,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:53,960 INFO:     Epoch: 52
2023-01-04 00:46:55,561 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45966442028681437, 'Total loss': 0.45966442028681437} | train loss {'Reaction outcome loss': 0.22374963367432085, 'Total loss': 0.22374963367432085}
2023-01-04 00:46:55,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:55,561 INFO:     Epoch: 53
2023-01-04 00:46:57,133 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4453202853600184, 'Total loss': 0.4453202853600184} | train loss {'Reaction outcome loss': 0.22471962599303114, 'Total loss': 0.22471962599303114}
2023-01-04 00:46:57,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:57,134 INFO:     Epoch: 54
2023-01-04 00:46:58,724 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4573819736639659, 'Total loss': 0.4573819736639659} | train loss {'Reaction outcome loss': 0.2199489997456903, 'Total loss': 0.2199489997456903}
2023-01-04 00:46:58,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:46:58,724 INFO:     Epoch: 55
2023-01-04 00:47:00,322 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47913179695606234, 'Total loss': 0.47913179695606234} | train loss {'Reaction outcome loss': 0.2192952181685014, 'Total loss': 0.2192952181685014}
2023-01-04 00:47:00,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:00,322 INFO:     Epoch: 56
2023-01-04 00:47:01,907 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45524097482363385, 'Total loss': 0.45524097482363385} | train loss {'Reaction outcome loss': 0.2236161953702137, 'Total loss': 0.2236161953702137}
2023-01-04 00:47:01,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:01,907 INFO:     Epoch: 57
2023-01-04 00:47:03,530 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4517936776081721, 'Total loss': 0.4517936776081721} | train loss {'Reaction outcome loss': 0.2181734334917037, 'Total loss': 0.2181734334917037}
2023-01-04 00:47:03,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:03,531 INFO:     Epoch: 58
2023-01-04 00:47:05,124 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.482133807738622, 'Total loss': 0.482133807738622} | train loss {'Reaction outcome loss': 0.21404848278473146, 'Total loss': 0.21404848278473146}
2023-01-04 00:47:05,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:05,126 INFO:     Epoch: 59
2023-01-04 00:47:06,707 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45732246041297914, 'Total loss': 0.45732246041297914} | train loss {'Reaction outcome loss': 0.21283078753554763, 'Total loss': 0.21283078753554763}
2023-01-04 00:47:06,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:06,708 INFO:     Epoch: 60
2023-01-04 00:47:08,305 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4672567387421926, 'Total loss': 0.4672567387421926} | train loss {'Reaction outcome loss': 0.20731393343036567, 'Total loss': 0.20731393343036567}
2023-01-04 00:47:08,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:08,305 INFO:     Epoch: 61
2023-01-04 00:47:09,928 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4586911638577779, 'Total loss': 0.4586911638577779} | train loss {'Reaction outcome loss': 0.20932491308591072, 'Total loss': 0.20932491308591072}
2023-01-04 00:47:09,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:09,928 INFO:     Epoch: 62
2023-01-04 00:47:11,522 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4684857805569967, 'Total loss': 0.4684857805569967} | train loss {'Reaction outcome loss': 0.2086367269727381, 'Total loss': 0.2086367269727381}
2023-01-04 00:47:11,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:11,523 INFO:     Epoch: 63
2023-01-04 00:47:13,108 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4763554443915685, 'Total loss': 0.4763554443915685} | train loss {'Reaction outcome loss': 0.20968703050976215, 'Total loss': 0.20968703050976215}
2023-01-04 00:47:13,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:13,108 INFO:     Epoch: 64
2023-01-04 00:47:14,691 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.465550156434377, 'Total loss': 0.465550156434377} | train loss {'Reaction outcome loss': 0.20964915637412798, 'Total loss': 0.20964915637412798}
2023-01-04 00:47:14,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:14,691 INFO:     Epoch: 65
2023-01-04 00:47:16,278 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4790425141652425, 'Total loss': 0.4790425141652425} | train loss {'Reaction outcome loss': 0.20515156306488358, 'Total loss': 0.20515156306488358}
2023-01-04 00:47:16,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:16,278 INFO:     Epoch: 66
2023-01-04 00:47:17,865 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47314366896947224, 'Total loss': 0.47314366896947224} | train loss {'Reaction outcome loss': 0.20168514815104308, 'Total loss': 0.20168514815104308}
2023-01-04 00:47:17,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:17,866 INFO:     Epoch: 67
2023-01-04 00:47:19,478 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48339298566182454, 'Total loss': 0.48339298566182454} | train loss {'Reaction outcome loss': 0.20234390984346712, 'Total loss': 0.20234390984346712}
2023-01-04 00:47:19,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:19,478 INFO:     Epoch: 68
2023-01-04 00:47:21,103 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4803729025026163, 'Total loss': 0.4803729025026163} | train loss {'Reaction outcome loss': 0.20019915170311267, 'Total loss': 0.20019915170311267}
2023-01-04 00:47:21,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:21,103 INFO:     Epoch: 69
2023-01-04 00:47:22,686 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.483964204788208, 'Total loss': 0.483964204788208} | train loss {'Reaction outcome loss': 0.19587088270834985, 'Total loss': 0.19587088270834985}
2023-01-04 00:47:22,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:22,687 INFO:     Epoch: 70
2023-01-04 00:47:24,271 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45672522683938344, 'Total loss': 0.45672522683938344} | train loss {'Reaction outcome loss': 0.1956686858607429, 'Total loss': 0.1956686858607429}
2023-01-04 00:47:24,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:24,271 INFO:     Epoch: 71
2023-01-04 00:47:25,852 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4939425398906072, 'Total loss': 0.4939425398906072} | train loss {'Reaction outcome loss': 0.19553275688351435, 'Total loss': 0.19553275688351435}
2023-01-04 00:47:25,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:25,853 INFO:     Epoch: 72
2023-01-04 00:47:27,442 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5001898556947708, 'Total loss': 0.5001898556947708} | train loss {'Reaction outcome loss': 0.19539971975778378, 'Total loss': 0.19539971975778378}
2023-01-04 00:47:27,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:27,442 INFO:     Epoch: 73
2023-01-04 00:47:29,033 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49783944090207416, 'Total loss': 0.49783944090207416} | train loss {'Reaction outcome loss': 0.19246586265617752, 'Total loss': 0.19246586265617752}
2023-01-04 00:47:29,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:29,035 INFO:     Epoch: 74
2023-01-04 00:47:30,625 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4948072870572408, 'Total loss': 0.4948072870572408} | train loss {'Reaction outcome loss': 0.19018868759714835, 'Total loss': 0.19018868759714835}
2023-01-04 00:47:30,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:30,625 INFO:     Epoch: 75
2023-01-04 00:47:32,202 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5148174325625102, 'Total loss': 0.5148174325625102} | train loss {'Reaction outcome loss': 0.19172393644491778, 'Total loss': 0.19172393644491778}
2023-01-04 00:47:32,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:32,202 INFO:     Epoch: 76
2023-01-04 00:47:33,805 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5180170863866806, 'Total loss': 0.5180170863866806} | train loss {'Reaction outcome loss': 0.19053491269764694, 'Total loss': 0.19053491269764694}
2023-01-04 00:47:33,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:33,805 INFO:     Epoch: 77
2023-01-04 00:47:35,396 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4968399782975515, 'Total loss': 0.4968399782975515} | train loss {'Reaction outcome loss': 0.18841208772063628, 'Total loss': 0.18841208772063628}
2023-01-04 00:47:35,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:35,397 INFO:     Epoch: 78
2023-01-04 00:47:36,986 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5130827893813451, 'Total loss': 0.5130827893813451} | train loss {'Reaction outcome loss': 0.19237571643611442, 'Total loss': 0.19237571643611442}
2023-01-04 00:47:36,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:36,986 INFO:     Epoch: 79
2023-01-04 00:47:38,576 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5082588573296865, 'Total loss': 0.5082588573296865} | train loss {'Reaction outcome loss': 0.18833858844816964, 'Total loss': 0.18833858844816964}
2023-01-04 00:47:38,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:38,577 INFO:     Epoch: 80
2023-01-04 00:47:40,167 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48450263738632204, 'Total loss': 0.48450263738632204} | train loss {'Reaction outcome loss': 0.1875262155292043, 'Total loss': 0.1875262155292043}
2023-01-04 00:47:40,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:40,168 INFO:     Epoch: 81
2023-01-04 00:47:41,743 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4640759120384852, 'Total loss': 0.4640759120384852} | train loss {'Reaction outcome loss': 0.18454640572789408, 'Total loss': 0.18454640572789408}
2023-01-04 00:47:41,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:41,744 INFO:     Epoch: 82
2023-01-04 00:47:43,336 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5117816726366679, 'Total loss': 0.5117816726366679} | train loss {'Reaction outcome loss': 0.1960365585307928, 'Total loss': 0.1960365585307928}
2023-01-04 00:47:43,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:43,336 INFO:     Epoch: 83
2023-01-04 00:47:44,961 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5122069001197815, 'Total loss': 0.5122069001197815} | train loss {'Reaction outcome loss': 0.20531146128432473, 'Total loss': 0.20531146128432473}
2023-01-04 00:47:44,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:44,962 INFO:     Epoch: 84
2023-01-04 00:47:46,561 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5198119188348452, 'Total loss': 0.5198119188348452} | train loss {'Reaction outcome loss': 0.20075025336004532, 'Total loss': 0.20075025336004532}
2023-01-04 00:47:46,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:46,562 INFO:     Epoch: 85
2023-01-04 00:47:48,154 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4756255586942037, 'Total loss': 0.4756255586942037} | train loss {'Reaction outcome loss': 0.18212700951372043, 'Total loss': 0.18212700951372043}
2023-01-04 00:47:48,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:48,154 INFO:     Epoch: 86
2023-01-04 00:47:49,755 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4822715202967326, 'Total loss': 0.4822715202967326} | train loss {'Reaction outcome loss': 0.179427198236437, 'Total loss': 0.179427198236437}
2023-01-04 00:47:49,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:49,755 INFO:     Epoch: 87
2023-01-04 00:47:51,340 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4833146890004476, 'Total loss': 0.4833146890004476} | train loss {'Reaction outcome loss': 0.17811741962677974, 'Total loss': 0.17811741962677974}
2023-01-04 00:47:51,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:51,341 INFO:     Epoch: 88
2023-01-04 00:47:52,958 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4885293781757355, 'Total loss': 0.4885293781757355} | train loss {'Reaction outcome loss': 0.17935764050433636, 'Total loss': 0.17935764050433636}
2023-01-04 00:47:52,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:52,959 INFO:     Epoch: 89
2023-01-04 00:47:54,573 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5057088047266006, 'Total loss': 0.5057088047266006} | train loss {'Reaction outcome loss': 0.18007677618711107, 'Total loss': 0.18007677618711107}
2023-01-04 00:47:54,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:54,573 INFO:     Epoch: 90
2023-01-04 00:47:56,188 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49574583768844604, 'Total loss': 0.49574583768844604} | train loss {'Reaction outcome loss': 0.1835567359763623, 'Total loss': 0.1835567359763623}
2023-01-04 00:47:56,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:56,188 INFO:     Epoch: 91
2023-01-04 00:47:57,791 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5020997862021128, 'Total loss': 0.5020997862021128} | train loss {'Reaction outcome loss': 0.17614411575756833, 'Total loss': 0.17614411575756833}
2023-01-04 00:47:57,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:57,793 INFO:     Epoch: 92
2023-01-04 00:47:59,371 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49721979796886445, 'Total loss': 0.49721979796886445} | train loss {'Reaction outcome loss': 0.1764111377440555, 'Total loss': 0.1764111377440555}
2023-01-04 00:47:59,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:47:59,371 INFO:     Epoch: 93
2023-01-04 00:48:00,982 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5167087684075038, 'Total loss': 0.5167087684075038} | train loss {'Reaction outcome loss': 0.1755669915337553, 'Total loss': 0.1755669915337553}
2023-01-04 00:48:00,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:00,982 INFO:     Epoch: 94
2023-01-04 00:48:02,587 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4919113079706828, 'Total loss': 0.4919113079706828} | train loss {'Reaction outcome loss': 0.17512575403869024, 'Total loss': 0.17512575403869024}
2023-01-04 00:48:02,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:02,587 INFO:     Epoch: 95
2023-01-04 00:48:04,212 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5091977079709371, 'Total loss': 0.5091977079709371} | train loss {'Reaction outcome loss': 0.17231247466870758, 'Total loss': 0.17231247466870758}
2023-01-04 00:48:04,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:04,214 INFO:     Epoch: 96
2023-01-04 00:48:05,813 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5075989941755931, 'Total loss': 0.5075989941755931} | train loss {'Reaction outcome loss': 0.17351945509384994, 'Total loss': 0.17351945509384994}
2023-01-04 00:48:05,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:05,813 INFO:     Epoch: 97
2023-01-04 00:48:07,421 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5110123157501221, 'Total loss': 0.5110123157501221} | train loss {'Reaction outcome loss': 0.19194992405591885, 'Total loss': 0.19194992405591885}
2023-01-04 00:48:07,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:07,422 INFO:     Epoch: 98
2023-01-04 00:48:09,045 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5009192635615667, 'Total loss': 0.5009192635615667} | train loss {'Reaction outcome loss': 0.1996102328479722, 'Total loss': 0.1996102328479722}
2023-01-04 00:48:09,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:09,046 INFO:     Epoch: 99
2023-01-04 00:48:10,628 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5076119581858317, 'Total loss': 0.5076119581858317} | train loss {'Reaction outcome loss': 0.1861125562075134, 'Total loss': 0.1861125562075134}
2023-01-04 00:48:10,628 INFO:     Best model found after epoch 28 of 100.
2023-01-04 00:48:10,628 INFO:   Done with stage: TRAINING
2023-01-04 00:48:10,628 INFO:   Starting stage: EVALUATION
2023-01-04 00:48:10,758 INFO:   Done with stage: EVALUATION
2023-01-04 00:48:10,758 INFO:   Leaving out SEQ value Fold_2
2023-01-04 00:48:10,771 INFO:   examples: 20,544| examples in train: 17,236 | examples in val: 908| examples in test: 2,400
2023-01-04 00:48:10,771 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:48:11,415 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:48:11,415 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:48:11,484 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:48:11,484 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:48:11,484 INFO:     No hyperparam tuning for this model
2023-01-04 00:48:11,484 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:48:11,484 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:48:11,485 INFO:     None feature selector for col prot
2023-01-04 00:48:11,485 INFO:     None feature selector for col prot
2023-01-04 00:48:11,485 INFO:     None feature selector for col prot
2023-01-04 00:48:11,485 INFO:     None feature selector for col chem
2023-01-04 00:48:11,486 INFO:     None feature selector for col chem
2023-01-04 00:48:11,486 INFO:     None feature selector for col chem
2023-01-04 00:48:11,486 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:48:11,486 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:48:11,487 INFO:     Number of params in model 70141
2023-01-04 00:48:11,490 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:48:11,490 INFO:   Starting stage: TRAINING
2023-01-04 00:48:11,536 INFO:     Val loss before train {'Reaction outcome loss': 1.0840086778004965, 'Total loss': 1.0840086778004965}
2023-01-04 00:48:11,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:11,536 INFO:     Epoch: 0
2023-01-04 00:48:13,100 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7063101212183635, 'Total loss': 0.7063101212183635} | train loss {'Reaction outcome loss': 0.8597222409866474, 'Total loss': 0.8597222409866474}
2023-01-04 00:48:13,100 INFO:     Found new best model at epoch 0
2023-01-04 00:48:13,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:13,101 INFO:     Epoch: 1
2023-01-04 00:48:14,663 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5607565224170685, 'Total loss': 0.5607565224170685} | train loss {'Reaction outcome loss': 0.6178606921324024, 'Total loss': 0.6178606921324024}
2023-01-04 00:48:14,665 INFO:     Found new best model at epoch 1
2023-01-04 00:48:14,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:14,666 INFO:     Epoch: 2
2023-01-04 00:48:16,219 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47863841652870176, 'Total loss': 0.47863841652870176} | train loss {'Reaction outcome loss': 0.5186934704581897, 'Total loss': 0.5186934704581897}
2023-01-04 00:48:16,219 INFO:     Found new best model at epoch 2
2023-01-04 00:48:16,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:16,220 INFO:     Epoch: 3
2023-01-04 00:48:17,802 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4439913536111514, 'Total loss': 0.4439913536111514} | train loss {'Reaction outcome loss': 0.4766428279655951, 'Total loss': 0.4766428279655951}
2023-01-04 00:48:17,803 INFO:     Found new best model at epoch 3
2023-01-04 00:48:17,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:17,803 INFO:     Epoch: 4
2023-01-04 00:48:19,350 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.461787215868632, 'Total loss': 0.461787215868632} | train loss {'Reaction outcome loss': 0.44946847022683534, 'Total loss': 0.44946847022683534}
2023-01-04 00:48:19,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:19,350 INFO:     Epoch: 5
2023-01-04 00:48:20,921 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4377009133497874, 'Total loss': 0.4377009133497874} | train loss {'Reaction outcome loss': 0.4277287870645523, 'Total loss': 0.4277287870645523}
2023-01-04 00:48:20,922 INFO:     Found new best model at epoch 5
2023-01-04 00:48:20,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:20,923 INFO:     Epoch: 6
2023-01-04 00:48:22,521 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4046892325083415, 'Total loss': 0.4046892325083415} | train loss {'Reaction outcome loss': 0.4138220241224324, 'Total loss': 0.4138220241224324}
2023-01-04 00:48:22,521 INFO:     Found new best model at epoch 6
2023-01-04 00:48:22,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:22,522 INFO:     Epoch: 7
2023-01-04 00:48:24,112 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.41574190656344095, 'Total loss': 0.41574190656344095} | train loss {'Reaction outcome loss': 0.4008501888425262, 'Total loss': 0.4008501888425262}
2023-01-04 00:48:24,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:24,113 INFO:     Epoch: 8
2023-01-04 00:48:25,672 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.40678863525390624, 'Total loss': 0.40678863525390624} | train loss {'Reaction outcome loss': 0.39148266837000845, 'Total loss': 0.39148266837000845}
2023-01-04 00:48:25,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:25,672 INFO:     Epoch: 9
2023-01-04 00:48:27,241 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4180423984924952, 'Total loss': 0.4180423984924952} | train loss {'Reaction outcome loss': 0.3790894954016915, 'Total loss': 0.3790894954016915}
2023-01-04 00:48:27,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:27,242 INFO:     Epoch: 10
2023-01-04 00:48:28,797 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42609650592009224, 'Total loss': 0.42609650592009224} | train loss {'Reaction outcome loss': 0.3710172404845556, 'Total loss': 0.3710172404845556}
2023-01-04 00:48:28,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:28,797 INFO:     Epoch: 11
2023-01-04 00:48:30,387 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4103761613368988, 'Total loss': 0.4103761613368988} | train loss {'Reaction outcome loss': 0.36448298345009483, 'Total loss': 0.36448298345009483}
2023-01-04 00:48:30,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:30,387 INFO:     Epoch: 12
2023-01-04 00:48:31,959 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.372188974916935, 'Total loss': 0.372188974916935} | train loss {'Reaction outcome loss': 0.3533908022498643, 'Total loss': 0.3533908022498643}
2023-01-04 00:48:31,959 INFO:     Found new best model at epoch 12
2023-01-04 00:48:31,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:31,960 INFO:     Epoch: 13
2023-01-04 00:48:33,549 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.36942580540974934, 'Total loss': 0.36942580540974934} | train loss {'Reaction outcome loss': 0.3480268145600955, 'Total loss': 0.3480268145600955}
2023-01-04 00:48:33,551 INFO:     Found new best model at epoch 13
2023-01-04 00:48:33,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:33,552 INFO:     Epoch: 14
2023-01-04 00:48:35,117 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.37201874057451884, 'Total loss': 0.37201874057451884} | train loss {'Reaction outcome loss': 0.3391360224948989, 'Total loss': 0.3391360224948989}
2023-01-04 00:48:35,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:35,118 INFO:     Epoch: 15
2023-01-04 00:48:36,667 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.35699364443620046, 'Total loss': 0.35699364443620046} | train loss {'Reaction outcome loss': 0.3339259942924535, 'Total loss': 0.3339259942924535}
2023-01-04 00:48:36,667 INFO:     Found new best model at epoch 15
2023-01-04 00:48:36,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:36,668 INFO:     Epoch: 16
2023-01-04 00:48:38,229 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3411687905589739, 'Total loss': 0.3411687905589739} | train loss {'Reaction outcome loss': 0.32897973982272327, 'Total loss': 0.32897973982272327}
2023-01-04 00:48:38,229 INFO:     Found new best model at epoch 16
2023-01-04 00:48:38,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:38,230 INFO:     Epoch: 17
2023-01-04 00:48:39,791 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38080944418907164, 'Total loss': 0.38080944418907164} | train loss {'Reaction outcome loss': 0.32171711844426615, 'Total loss': 0.32171711844426615}
2023-01-04 00:48:39,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:39,792 INFO:     Epoch: 18
2023-01-04 00:48:41,354 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3670816044012705, 'Total loss': 0.3670816044012705} | train loss {'Reaction outcome loss': 0.3161285196189527, 'Total loss': 0.3161285196189527}
2023-01-04 00:48:41,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:41,354 INFO:     Epoch: 19
2023-01-04 00:48:42,920 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.37865152458349866, 'Total loss': 0.37865152458349866} | train loss {'Reaction outcome loss': 0.31026921606174224, 'Total loss': 0.31026921606174224}
2023-01-04 00:48:42,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:42,920 INFO:     Epoch: 20
2023-01-04 00:48:44,473 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.35137076874574025, 'Total loss': 0.35137076874574025} | train loss {'Reaction outcome loss': 0.3042114043677295, 'Total loss': 0.3042114043677295}
2023-01-04 00:48:44,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:44,474 INFO:     Epoch: 21
2023-01-04 00:48:46,044 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.33520559246341386, 'Total loss': 0.33520559246341386} | train loss {'Reaction outcome loss': 0.3011500444677141, 'Total loss': 0.3011500444677141}
2023-01-04 00:48:46,045 INFO:     Found new best model at epoch 21
2023-01-04 00:48:46,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:46,046 INFO:     Epoch: 22
2023-01-04 00:48:47,636 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.34472584426403047, 'Total loss': 0.34472584426403047} | train loss {'Reaction outcome loss': 0.29334763734153024, 'Total loss': 0.29334763734153024}
2023-01-04 00:48:47,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:47,636 INFO:     Epoch: 23
2023-01-04 00:48:49,228 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3294453797241052, 'Total loss': 0.3294453797241052} | train loss {'Reaction outcome loss': 0.2885545060866409, 'Total loss': 0.2885545060866409}
2023-01-04 00:48:49,228 INFO:     Found new best model at epoch 23
2023-01-04 00:48:49,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:49,229 INFO:     Epoch: 24
2023-01-04 00:48:50,807 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3703586161136627, 'Total loss': 0.3703586161136627} | train loss {'Reaction outcome loss': 0.28510366083571204, 'Total loss': 0.28510366083571204}
2023-01-04 00:48:50,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:50,807 INFO:     Epoch: 25
2023-01-04 00:48:52,347 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3361118560036023, 'Total loss': 0.3361118560036023} | train loss {'Reaction outcome loss': 0.28321932660484755, 'Total loss': 0.28321932660484755}
2023-01-04 00:48:52,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:52,348 INFO:     Epoch: 26
2023-01-04 00:48:53,918 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.34306924839814507, 'Total loss': 0.34306924839814507} | train loss {'Reaction outcome loss': 0.27728912824833835, 'Total loss': 0.27728912824833835}
2023-01-04 00:48:53,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:53,918 INFO:     Epoch: 27
2023-01-04 00:48:55,492 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.34234409034252167, 'Total loss': 0.34234409034252167} | train loss {'Reaction outcome loss': 0.271574101348718, 'Total loss': 0.271574101348718}
2023-01-04 00:48:55,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:55,492 INFO:     Epoch: 28
2023-01-04 00:48:57,079 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3246970037619273, 'Total loss': 0.3246970037619273} | train loss {'Reaction outcome loss': 0.26931952674079823, 'Total loss': 0.26931952674079823}
2023-01-04 00:48:57,079 INFO:     Found new best model at epoch 28
2023-01-04 00:48:57,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:57,080 INFO:     Epoch: 29
2023-01-04 00:48:58,670 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.33355438597500325, 'Total loss': 0.33355438597500325} | train loss {'Reaction outcome loss': 0.26484625310533577, 'Total loss': 0.26484625310533577}
2023-01-04 00:48:58,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:48:58,671 INFO:     Epoch: 30
2023-01-04 00:49:00,238 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.34789943397045137, 'Total loss': 0.34789943397045137} | train loss {'Reaction outcome loss': 0.26260567692418896, 'Total loss': 0.26260567692418896}
2023-01-04 00:49:00,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:00,238 INFO:     Epoch: 31
2023-01-04 00:49:01,806 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.34815569619337716, 'Total loss': 0.34815569619337716} | train loss {'Reaction outcome loss': 0.2592821968650376, 'Total loss': 0.2592821968650376}
2023-01-04 00:49:01,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:01,806 INFO:     Epoch: 32
2023-01-04 00:49:03,353 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.34087232251962024, 'Total loss': 0.34087232251962024} | train loss {'Reaction outcome loss': 0.2552705065795669, 'Total loss': 0.2552705065795669}
2023-01-04 00:49:03,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:03,353 INFO:     Epoch: 33
2023-01-04 00:49:04,910 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3298357605934143, 'Total loss': 0.3298357605934143} | train loss {'Reaction outcome loss': 0.25361670749606907, 'Total loss': 0.25361670749606907}
2023-01-04 00:49:04,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:04,912 INFO:     Epoch: 34
2023-01-04 00:49:06,494 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.33857819040616355, 'Total loss': 0.33857819040616355} | train loss {'Reaction outcome loss': 0.2480413417297381, 'Total loss': 0.2480413417297381}
2023-01-04 00:49:06,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:06,494 INFO:     Epoch: 35
2023-01-04 00:49:08,107 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3746823608875275, 'Total loss': 0.3746823608875275} | train loss {'Reaction outcome loss': 0.24420860616697204, 'Total loss': 0.24420860616697204}
2023-01-04 00:49:08,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:08,107 INFO:     Epoch: 36
2023-01-04 00:49:09,702 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3314498613278071, 'Total loss': 0.3314498613278071} | train loss {'Reaction outcome loss': 0.24551444217838622, 'Total loss': 0.24551444217838622}
2023-01-04 00:49:09,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:09,703 INFO:     Epoch: 37
2023-01-04 00:49:11,255 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3474448243776957, 'Total loss': 0.3474448243776957} | train loss {'Reaction outcome loss': 0.2393586971555595, 'Total loss': 0.2393586971555595}
2023-01-04 00:49:11,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:11,255 INFO:     Epoch: 38
2023-01-04 00:49:12,821 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.37591437697410585, 'Total loss': 0.37591437697410585} | train loss {'Reaction outcome loss': 0.23818126955518015, 'Total loss': 0.23818126955518015}
2023-01-04 00:49:12,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:12,821 INFO:     Epoch: 39
2023-01-04 00:49:14,375 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3364354143540064, 'Total loss': 0.3364354143540064} | train loss {'Reaction outcome loss': 0.23453184440732003, 'Total loss': 0.23453184440732003}
2023-01-04 00:49:14,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:14,375 INFO:     Epoch: 40
2023-01-04 00:49:15,965 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.33243486707409226, 'Total loss': 0.33243486707409226} | train loss {'Reaction outcome loss': 0.23252185519646715, 'Total loss': 0.23252185519646715}
2023-01-04 00:49:15,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:15,966 INFO:     Epoch: 41
2023-01-04 00:49:17,532 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.35125601092974346, 'Total loss': 0.35125601092974346} | train loss {'Reaction outcome loss': 0.23416848253044817, 'Total loss': 0.23416848253044817}
2023-01-04 00:49:17,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:17,534 INFO:     Epoch: 42
2023-01-04 00:49:19,112 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.35074129899342854, 'Total loss': 0.35074129899342854} | train loss {'Reaction outcome loss': 0.22654667521516483, 'Total loss': 0.22654667521516483}
2023-01-04 00:49:19,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:19,112 INFO:     Epoch: 43
2023-01-04 00:49:20,660 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3715290705362956, 'Total loss': 0.3715290705362956} | train loss {'Reaction outcome loss': 0.2258854534201048, 'Total loss': 0.2258854534201048}
2023-01-04 00:49:20,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:20,660 INFO:     Epoch: 44
2023-01-04 00:49:22,215 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3273095437015096, 'Total loss': 0.3273095437015096} | train loss {'Reaction outcome loss': 0.22322797485523754, 'Total loss': 0.22322797485523754}
2023-01-04 00:49:22,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:22,215 INFO:     Epoch: 45
2023-01-04 00:49:23,801 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.35906122426191966, 'Total loss': 0.35906122426191966} | train loss {'Reaction outcome loss': 0.2226011564610181, 'Total loss': 0.2226011564610181}
2023-01-04 00:49:23,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:23,803 INFO:     Epoch: 46
2023-01-04 00:49:25,376 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3550969282786051, 'Total loss': 0.3550969282786051} | train loss {'Reaction outcome loss': 0.2195164424246522, 'Total loss': 0.2195164424246522}
2023-01-04 00:49:25,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:25,376 INFO:     Epoch: 47
2023-01-04 00:49:26,932 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.36858786046504977, 'Total loss': 0.36858786046504977} | train loss {'Reaction outcome loss': 0.21699987545057578, 'Total loss': 0.21699987545057578}
2023-01-04 00:49:26,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:26,933 INFO:     Epoch: 48
2023-01-04 00:49:28,482 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.34358328878879546, 'Total loss': 0.34358328878879546} | train loss {'Reaction outcome loss': 0.21691629480984476, 'Total loss': 0.21691629480984476}
2023-01-04 00:49:28,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:28,482 INFO:     Epoch: 49
2023-01-04 00:49:30,068 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.37777861654758454, 'Total loss': 0.37777861654758454} | train loss {'Reaction outcome loss': 0.21683229114170427, 'Total loss': 0.21683229114170427}
2023-01-04 00:49:30,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:30,069 INFO:     Epoch: 50
2023-01-04 00:49:31,623 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3752772221962611, 'Total loss': 0.3752772221962611} | train loss {'Reaction outcome loss': 0.21502284636652028, 'Total loss': 0.21502284636652028}
2023-01-04 00:49:31,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:31,623 INFO:     Epoch: 51
2023-01-04 00:49:33,190 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.38425781528155006, 'Total loss': 0.38425781528155006} | train loss {'Reaction outcome loss': 0.20926566405428781, 'Total loss': 0.20926566405428781}
2023-01-04 00:49:33,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:33,190 INFO:     Epoch: 52
2023-01-04 00:49:34,756 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38387428025404613, 'Total loss': 0.38387428025404613} | train loss {'Reaction outcome loss': 0.20958086101821174, 'Total loss': 0.20958086101821174}
2023-01-04 00:49:34,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:34,757 INFO:     Epoch: 53
2023-01-04 00:49:36,323 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.36751632193724315, 'Total loss': 0.36751632193724315} | train loss {'Reaction outcome loss': 0.20802925934118252, 'Total loss': 0.20802925934118252}
2023-01-04 00:49:36,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:36,325 INFO:     Epoch: 54
2023-01-04 00:49:37,694 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3915246367454529, 'Total loss': 0.3915246367454529} | train loss {'Reaction outcome loss': 0.2054731094174915, 'Total loss': 0.2054731094174915}
2023-01-04 00:49:37,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:37,694 INFO:     Epoch: 55
2023-01-04 00:49:38,762 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3682972639799118, 'Total loss': 0.3682972639799118} | train loss {'Reaction outcome loss': 0.20354966771685415, 'Total loss': 0.20354966771685415}
2023-01-04 00:49:38,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:38,762 INFO:     Epoch: 56
2023-01-04 00:49:39,815 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3997826824585597, 'Total loss': 0.3997826824585597} | train loss {'Reaction outcome loss': 0.2027895276883134, 'Total loss': 0.2027895276883134}
2023-01-04 00:49:39,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:39,816 INFO:     Epoch: 57
2023-01-04 00:49:40,861 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40829517046610514, 'Total loss': 0.40829517046610514} | train loss {'Reaction outcome loss': 0.19960819942255814, 'Total loss': 0.19960819942255814}
2023-01-04 00:49:40,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:40,861 INFO:     Epoch: 58
2023-01-04 00:49:41,940 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3521970866868893, 'Total loss': 0.3521970866868893} | train loss {'Reaction outcome loss': 0.1999136331456679, 'Total loss': 0.1999136331456679}
2023-01-04 00:49:41,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:41,942 INFO:     Epoch: 59
2023-01-04 00:49:43,531 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39121075173219044, 'Total loss': 0.39121075173219044} | train loss {'Reaction outcome loss': 0.19651388131358005, 'Total loss': 0.19651388131358005}
2023-01-04 00:49:43,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:43,531 INFO:     Epoch: 60
2023-01-04 00:49:45,149 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3628713379303614, 'Total loss': 0.3628713379303614} | train loss {'Reaction outcome loss': 0.19575920121537316, 'Total loss': 0.19575920121537316}
2023-01-04 00:49:45,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:45,149 INFO:     Epoch: 61
2023-01-04 00:49:46,707 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3628863086303075, 'Total loss': 0.3628863086303075} | train loss {'Reaction outcome loss': 0.1972298694015653, 'Total loss': 0.1972298694015653}
2023-01-04 00:49:46,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:46,708 INFO:     Epoch: 62
2023-01-04 00:49:48,294 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3910858675837517, 'Total loss': 0.3910858675837517} | train loss {'Reaction outcome loss': 0.1966051405157756, 'Total loss': 0.1966051405157756}
2023-01-04 00:49:48,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:48,295 INFO:     Epoch: 63
2023-01-04 00:49:49,872 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.35460844735304514, 'Total loss': 0.35460844735304514} | train loss {'Reaction outcome loss': 0.1936800555912433, 'Total loss': 0.1936800555912433}
2023-01-04 00:49:49,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:49,872 INFO:     Epoch: 64
2023-01-04 00:49:51,432 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3569299810876449, 'Total loss': 0.3569299810876449} | train loss {'Reaction outcome loss': 0.19247591660047572, 'Total loss': 0.19247591660047572}
2023-01-04 00:49:51,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:51,432 INFO:     Epoch: 65
2023-01-04 00:49:52,987 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39165444374084474, 'Total loss': 0.39165444374084474} | train loss {'Reaction outcome loss': 0.1908665937199085, 'Total loss': 0.1908665937199085}
2023-01-04 00:49:52,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:52,988 INFO:     Epoch: 66
2023-01-04 00:49:54,546 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40380188524723054, 'Total loss': 0.40380188524723054} | train loss {'Reaction outcome loss': 0.1888591418939608, 'Total loss': 0.1888591418939608}
2023-01-04 00:49:54,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:54,547 INFO:     Epoch: 67
2023-01-04 00:49:56,111 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4165119131406148, 'Total loss': 0.4165119131406148} | train loss {'Reaction outcome loss': 0.18844185687463594, 'Total loss': 0.18844185687463594}
2023-01-04 00:49:56,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:56,111 INFO:     Epoch: 68
2023-01-04 00:49:57,723 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.37072930534680687, 'Total loss': 0.37072930534680687} | train loss {'Reaction outcome loss': 0.18656599569237894, 'Total loss': 0.18656599569237894}
2023-01-04 00:49:57,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:57,723 INFO:     Epoch: 69
2023-01-04 00:49:59,308 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4516045351823171, 'Total loss': 0.4516045351823171} | train loss {'Reaction outcome loss': 0.1871386298564849, 'Total loss': 0.1871386298564849}
2023-01-04 00:49:59,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:49:59,310 INFO:     Epoch: 70
2023-01-04 00:50:00,859 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3732899859547615, 'Total loss': 0.3732899859547615} | train loss {'Reaction outcome loss': 0.1863598132988921, 'Total loss': 0.1863598132988921}
2023-01-04 00:50:00,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:00,860 INFO:     Epoch: 71
2023-01-04 00:50:02,421 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3912012984355291, 'Total loss': 0.3912012984355291} | train loss {'Reaction outcome loss': 0.18500310276393536, 'Total loss': 0.18500310276393536}
2023-01-04 00:50:02,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:02,422 INFO:     Epoch: 72
2023-01-04 00:50:03,959 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4484495957692464, 'Total loss': 0.4484495957692464} | train loss {'Reaction outcome loss': 0.18454282915012704, 'Total loss': 0.18454282915012704}
2023-01-04 00:50:03,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:03,960 INFO:     Epoch: 73
2023-01-04 00:50:05,512 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.36780949781338373, 'Total loss': 0.36780949781338373} | train loss {'Reaction outcome loss': 0.18138684445509204, 'Total loss': 0.18138684445509204}
2023-01-04 00:50:05,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:05,512 INFO:     Epoch: 74
2023-01-04 00:50:07,101 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3927100509405136, 'Total loss': 0.3927100509405136} | train loss {'Reaction outcome loss': 0.18326471178206027, 'Total loss': 0.18326471178206027}
2023-01-04 00:50:07,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:07,102 INFO:     Epoch: 75
2023-01-04 00:50:08,657 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3899074306090673, 'Total loss': 0.3899074306090673} | train loss {'Reaction outcome loss': 0.17870977740320895, 'Total loss': 0.17870977740320895}
2023-01-04 00:50:08,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:08,657 INFO:     Epoch: 76
2023-01-04 00:50:10,207 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3946064236263434, 'Total loss': 0.3946064236263434} | train loss {'Reaction outcome loss': 0.17910916367890659, 'Total loss': 0.17910916367890659}
2023-01-04 00:50:10,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:10,207 INFO:     Epoch: 77
2023-01-04 00:50:11,765 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43384834229946134, 'Total loss': 0.43384834229946134} | train loss {'Reaction outcome loss': 0.17742568516620882, 'Total loss': 0.17742568516620882}
2023-01-04 00:50:11,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:11,765 INFO:     Epoch: 78
2023-01-04 00:50:13,311 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4040794720252355, 'Total loss': 0.4040794720252355} | train loss {'Reaction outcome loss': 0.17518308135094465, 'Total loss': 0.17518308135094465}
2023-01-04 00:50:13,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:13,312 INFO:     Epoch: 79
2023-01-04 00:50:14,867 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4237920920054118, 'Total loss': 0.4237920920054118} | train loss {'Reaction outcome loss': 0.1788967766488592, 'Total loss': 0.1788967766488592}
2023-01-04 00:50:14,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:14,867 INFO:     Epoch: 80
2023-01-04 00:50:16,464 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4541458562016487, 'Total loss': 0.4541458562016487} | train loss {'Reaction outcome loss': 0.1757961820466099, 'Total loss': 0.1757961820466099}
2023-01-04 00:50:16,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:16,464 INFO:     Epoch: 81
2023-01-04 00:50:18,047 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3932340040802956, 'Total loss': 0.3932340040802956} | train loss {'Reaction outcome loss': 0.1733799850637162, 'Total loss': 0.1733799850637162}
2023-01-04 00:50:18,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:18,047 INFO:     Epoch: 82
2023-01-04 00:50:19,647 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41089819570382435, 'Total loss': 0.41089819570382435} | train loss {'Reaction outcome loss': 0.17352896884980576, 'Total loss': 0.17352896884980576}
2023-01-04 00:50:19,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:19,648 INFO:     Epoch: 83
2023-01-04 00:50:21,246 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39617589314778645, 'Total loss': 0.39617589314778645} | train loss {'Reaction outcome loss': 0.1742012527667814, 'Total loss': 0.1742012527667814}
2023-01-04 00:50:21,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:21,246 INFO:     Epoch: 84
2023-01-04 00:50:22,819 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40304712057113645, 'Total loss': 0.40304712057113645} | train loss {'Reaction outcome loss': 0.17362500760290359, 'Total loss': 0.17362500760290359}
2023-01-04 00:50:22,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:22,819 INFO:     Epoch: 85
2023-01-04 00:50:24,441 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39596568743387855, 'Total loss': 0.39596568743387855} | train loss {'Reaction outcome loss': 0.17395483734155143, 'Total loss': 0.17395483734155143}
2023-01-04 00:50:24,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:24,442 INFO:     Epoch: 86
2023-01-04 00:50:26,004 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4017705380916595, 'Total loss': 0.4017705380916595} | train loss {'Reaction outcome loss': 0.17072390571788507, 'Total loss': 0.17072390571788507}
2023-01-04 00:50:26,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:26,005 INFO:     Epoch: 87
2023-01-04 00:50:27,544 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44787504971027375, 'Total loss': 0.44787504971027375} | train loss {'Reaction outcome loss': 0.17014918031377924, 'Total loss': 0.17014918031377924}
2023-01-04 00:50:27,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:27,545 INFO:     Epoch: 88
2023-01-04 00:50:29,123 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.389036696155866, 'Total loss': 0.389036696155866} | train loss {'Reaction outcome loss': 0.17154568276471563, 'Total loss': 0.17154568276471563}
2023-01-04 00:50:29,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:29,123 INFO:     Epoch: 89
2023-01-04 00:50:30,712 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3871767039100329, 'Total loss': 0.3871767039100329} | train loss {'Reaction outcome loss': 0.16835275733912433, 'Total loss': 0.16835275733912433}
2023-01-04 00:50:30,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:30,714 INFO:     Epoch: 90
2023-01-04 00:50:32,256 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40589717229207356, 'Total loss': 0.40589717229207356} | train loss {'Reaction outcome loss': 0.16923864212714965, 'Total loss': 0.16923864212714965}
2023-01-04 00:50:32,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:32,256 INFO:     Epoch: 91
2023-01-04 00:50:33,816 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41346808622280756, 'Total loss': 0.41346808622280756} | train loss {'Reaction outcome loss': 0.16844419087110846, 'Total loss': 0.16844419087110846}
2023-01-04 00:50:33,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:33,817 INFO:     Epoch: 92
2023-01-04 00:50:35,376 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40962217350800834, 'Total loss': 0.40962217350800834} | train loss {'Reaction outcome loss': 0.16576563251480736, 'Total loss': 0.16576563251480736}
2023-01-04 00:50:35,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:35,376 INFO:     Epoch: 93
2023-01-04 00:50:36,923 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41693886717160544, 'Total loss': 0.41693886717160544} | train loss {'Reaction outcome loss': 0.17031414650932505, 'Total loss': 0.17031414650932505}
2023-01-04 00:50:36,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:36,925 INFO:     Epoch: 94
2023-01-04 00:50:38,486 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41673104961713153, 'Total loss': 0.41673104961713153} | train loss {'Reaction outcome loss': 0.1666610756268104, 'Total loss': 0.1666610756268104}
2023-01-04 00:50:38,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:38,486 INFO:     Epoch: 95
2023-01-04 00:50:40,068 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41439300750692687, 'Total loss': 0.41439300750692687} | train loss {'Reaction outcome loss': 0.16417333487145327, 'Total loss': 0.16417333487145327}
2023-01-04 00:50:40,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:40,068 INFO:     Epoch: 96
2023-01-04 00:50:41,621 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4343740234772364, 'Total loss': 0.4343740234772364} | train loss {'Reaction outcome loss': 0.16497340187154436, 'Total loss': 0.16497340187154436}
2023-01-04 00:50:41,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:41,621 INFO:     Epoch: 97
2023-01-04 00:50:43,196 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3957028736670812, 'Total loss': 0.3957028736670812} | train loss {'Reaction outcome loss': 0.1669109317715521, 'Total loss': 0.1669109317715521}
2023-01-04 00:50:43,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:43,197 INFO:     Epoch: 98
2023-01-04 00:50:44,771 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39529768327871956, 'Total loss': 0.39529768327871956} | train loss {'Reaction outcome loss': 0.16678137381181674, 'Total loss': 0.16678137381181674}
2023-01-04 00:50:44,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:44,771 INFO:     Epoch: 99
2023-01-04 00:50:46,329 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4221996545791626, 'Total loss': 0.4221996545791626} | train loss {'Reaction outcome loss': 0.16386952225325835, 'Total loss': 0.16386952225325835}
2023-01-04 00:50:46,329 INFO:     Best model found after epoch 29 of 100.
2023-01-04 00:50:46,329 INFO:   Done with stage: TRAINING
2023-01-04 00:50:46,329 INFO:   Starting stage: EVALUATION
2023-01-04 00:50:46,483 INFO:   Done with stage: EVALUATION
2023-01-04 00:50:46,483 INFO:   Leaving out SEQ value Fold_3
2023-01-04 00:50:46,496 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 00:50:46,496 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:50:47,139 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:50:47,139 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:50:47,208 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:50:47,208 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:50:47,209 INFO:     No hyperparam tuning for this model
2023-01-04 00:50:47,209 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:50:47,209 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:50:47,209 INFO:     None feature selector for col prot
2023-01-04 00:50:47,210 INFO:     None feature selector for col prot
2023-01-04 00:50:47,210 INFO:     None feature selector for col prot
2023-01-04 00:50:47,210 INFO:     None feature selector for col chem
2023-01-04 00:50:47,210 INFO:     None feature selector for col chem
2023-01-04 00:50:47,210 INFO:     None feature selector for col chem
2023-01-04 00:50:47,210 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:50:47,210 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:50:47,212 INFO:     Number of params in model 70141
2023-01-04 00:50:47,215 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:50:47,215 INFO:   Starting stage: TRAINING
2023-01-04 00:50:47,259 INFO:     Val loss before train {'Reaction outcome loss': 0.998025377591451, 'Total loss': 0.998025377591451}
2023-01-04 00:50:47,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:47,260 INFO:     Epoch: 0
2023-01-04 00:50:48,850 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7240496297677358, 'Total loss': 0.7240496297677358} | train loss {'Reaction outcome loss': 0.8381742532654997, 'Total loss': 0.8381742532654997}
2023-01-04 00:50:48,851 INFO:     Found new best model at epoch 0
2023-01-04 00:50:48,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:48,852 INFO:     Epoch: 1
2023-01-04 00:50:50,429 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5576058169205983, 'Total loss': 0.5576058169205983} | train loss {'Reaction outcome loss': 0.6063455253730327, 'Total loss': 0.6063455253730327}
2023-01-04 00:50:50,430 INFO:     Found new best model at epoch 1
2023-01-04 00:50:50,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:50,430 INFO:     Epoch: 2
2023-01-04 00:50:52,007 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5230642855167389, 'Total loss': 0.5230642855167389} | train loss {'Reaction outcome loss': 0.526279513543342, 'Total loss': 0.526279513543342}
2023-01-04 00:50:52,007 INFO:     Found new best model at epoch 2
2023-01-04 00:50:52,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:52,008 INFO:     Epoch: 3
2023-01-04 00:50:53,585 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5027184655268987, 'Total loss': 0.5027184655268987} | train loss {'Reaction outcome loss': 0.48716286075857534, 'Total loss': 0.48716286075857534}
2023-01-04 00:50:53,586 INFO:     Found new best model at epoch 3
2023-01-04 00:50:53,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:53,587 INFO:     Epoch: 4
2023-01-04 00:50:55,161 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49984715779622396, 'Total loss': 0.49984715779622396} | train loss {'Reaction outcome loss': 0.4638315786918004, 'Total loss': 0.4638315786918004}
2023-01-04 00:50:55,161 INFO:     Found new best model at epoch 4
2023-01-04 00:50:55,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:55,162 INFO:     Epoch: 5
2023-01-04 00:50:56,758 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4851314425468445, 'Total loss': 0.4851314425468445} | train loss {'Reaction outcome loss': 0.44297632609149473, 'Total loss': 0.44297632609149473}
2023-01-04 00:50:56,758 INFO:     Found new best model at epoch 5
2023-01-04 00:50:56,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:56,759 INFO:     Epoch: 6
2023-01-04 00:50:58,337 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4688404033581416, 'Total loss': 0.4688404033581416} | train loss {'Reaction outcome loss': 0.42578437564137217, 'Total loss': 0.42578437564137217}
2023-01-04 00:50:58,337 INFO:     Found new best model at epoch 6
2023-01-04 00:50:58,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:58,338 INFO:     Epoch: 7
2023-01-04 00:50:59,907 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4905472695827484, 'Total loss': 0.4905472695827484} | train loss {'Reaction outcome loss': 0.4156164678134324, 'Total loss': 0.4156164678134324}
2023-01-04 00:50:59,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:50:59,908 INFO:     Epoch: 8
2023-01-04 00:51:01,498 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4821338574091593, 'Total loss': 0.4821338574091593} | train loss {'Reaction outcome loss': 0.4006731154417599, 'Total loss': 0.4006731154417599}
2023-01-04 00:51:01,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:01,499 INFO:     Epoch: 9
2023-01-04 00:51:03,076 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4674481352170308, 'Total loss': 0.4674481352170308} | train loss {'Reaction outcome loss': 0.3908156741669763, 'Total loss': 0.3908156741669763}
2023-01-04 00:51:03,076 INFO:     Found new best model at epoch 9
2023-01-04 00:51:03,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:03,077 INFO:     Epoch: 10
2023-01-04 00:51:04,654 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46018200516700747, 'Total loss': 0.46018200516700747} | train loss {'Reaction outcome loss': 0.3786078535102226, 'Total loss': 0.3786078535102226}
2023-01-04 00:51:04,654 INFO:     Found new best model at epoch 10
2023-01-04 00:51:04,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:04,655 INFO:     Epoch: 11
2023-01-04 00:51:06,232 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4981903890768687, 'Total loss': 0.4981903890768687} | train loss {'Reaction outcome loss': 0.37145883778294364, 'Total loss': 0.37145883778294364}
2023-01-04 00:51:06,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:06,233 INFO:     Epoch: 12
2023-01-04 00:51:07,797 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4509264747301737, 'Total loss': 0.4509264747301737} | train loss {'Reaction outcome loss': 0.36171329616408643, 'Total loss': 0.36171329616408643}
2023-01-04 00:51:07,797 INFO:     Found new best model at epoch 12
2023-01-04 00:51:07,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:07,798 INFO:     Epoch: 13
2023-01-04 00:51:09,408 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45790144403775535, 'Total loss': 0.45790144403775535} | train loss {'Reaction outcome loss': 0.35570345196750136, 'Total loss': 0.35570345196750136}
2023-01-04 00:51:09,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:09,408 INFO:     Epoch: 14
2023-01-04 00:51:11,015 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4813088417053223, 'Total loss': 0.4813088417053223} | train loss {'Reaction outcome loss': 0.3473215104241074, 'Total loss': 0.3473215104241074}
2023-01-04 00:51:11,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:11,016 INFO:     Epoch: 15
2023-01-04 00:51:12,580 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45686832467714944, 'Total loss': 0.45686832467714944} | train loss {'Reaction outcome loss': 0.34152154318797284, 'Total loss': 0.34152154318797284}
2023-01-04 00:51:12,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:12,580 INFO:     Epoch: 16
2023-01-04 00:51:14,160 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46686240633328757, 'Total loss': 0.46686240633328757} | train loss {'Reaction outcome loss': 0.3317152282748467, 'Total loss': 0.3317152282748467}
2023-01-04 00:51:14,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:14,160 INFO:     Epoch: 17
2023-01-04 00:51:15,719 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45561801791191103, 'Total loss': 0.45561801791191103} | train loss {'Reaction outcome loss': 0.3253775900536841, 'Total loss': 0.3253775900536841}
2023-01-04 00:51:15,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:15,719 INFO:     Epoch: 18
2023-01-04 00:51:17,315 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46682116289933523, 'Total loss': 0.46682116289933523} | train loss {'Reaction outcome loss': 0.3197474131435702, 'Total loss': 0.3197474131435702}
2023-01-04 00:51:17,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:17,315 INFO:     Epoch: 19
2023-01-04 00:51:18,920 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4743664522965749, 'Total loss': 0.4743664522965749} | train loss {'Reaction outcome loss': 0.31201482389545265, 'Total loss': 0.31201482389545265}
2023-01-04 00:51:18,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:18,921 INFO:     Epoch: 20
2023-01-04 00:51:20,521 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4835508366425832, 'Total loss': 0.4835508366425832} | train loss {'Reaction outcome loss': 0.30726806336379314, 'Total loss': 0.30726806336379314}
2023-01-04 00:51:20,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:20,521 INFO:     Epoch: 21
2023-01-04 00:51:22,085 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4873935987552007, 'Total loss': 0.4873935987552007} | train loss {'Reaction outcome loss': 0.30568161110083264, 'Total loss': 0.30568161110083264}
2023-01-04 00:51:22,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:22,085 INFO:     Epoch: 22
2023-01-04 00:51:23,664 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45822485685348513, 'Total loss': 0.45822485685348513} | train loss {'Reaction outcome loss': 0.29933482097400416, 'Total loss': 0.29933482097400416}
2023-01-04 00:51:23,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:23,664 INFO:     Epoch: 23
2023-01-04 00:51:25,235 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4562051067749659, 'Total loss': 0.4562051067749659} | train loss {'Reaction outcome loss': 0.29433298329293944, 'Total loss': 0.29433298329293944}
2023-01-04 00:51:25,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:25,236 INFO:     Epoch: 24
2023-01-04 00:51:26,828 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45924975275993346, 'Total loss': 0.45924975275993346} | train loss {'Reaction outcome loss': 0.2872345480358317, 'Total loss': 0.2872345480358317}
2023-01-04 00:51:26,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:26,829 INFO:     Epoch: 25
2023-01-04 00:51:28,436 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45193909605344135, 'Total loss': 0.45193909605344135} | train loss {'Reaction outcome loss': 0.28463214054539965, 'Total loss': 0.28463214054539965}
2023-01-04 00:51:28,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:28,436 INFO:     Epoch: 26
2023-01-04 00:51:30,018 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4507964571317037, 'Total loss': 0.4507964571317037} | train loss {'Reaction outcome loss': 0.28347635400164256, 'Total loss': 0.28347635400164256}
2023-01-04 00:51:30,020 INFO:     Found new best model at epoch 26
2023-01-04 00:51:30,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:30,020 INFO:     Epoch: 27
2023-01-04 00:51:31,599 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44818729360898335, 'Total loss': 0.44818729360898335} | train loss {'Reaction outcome loss': 0.27972218427029283, 'Total loss': 0.27972218427029283}
2023-01-04 00:51:31,599 INFO:     Found new best model at epoch 27
2023-01-04 00:51:31,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:31,600 INFO:     Epoch: 28
2023-01-04 00:51:33,199 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43707431182265283, 'Total loss': 0.43707431182265283} | train loss {'Reaction outcome loss': 0.2767217482948478, 'Total loss': 0.2767217482948478}
2023-01-04 00:51:33,199 INFO:     Found new best model at epoch 28
2023-01-04 00:51:33,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:33,200 INFO:     Epoch: 29
2023-01-04 00:51:34,771 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4523163437843323, 'Total loss': 0.4523163437843323} | train loss {'Reaction outcome loss': 0.27202154791507965, 'Total loss': 0.27202154791507965}
2023-01-04 00:51:34,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:34,771 INFO:     Epoch: 30
2023-01-04 00:51:36,382 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42956696152687074, 'Total loss': 0.42956696152687074} | train loss {'Reaction outcome loss': 0.26645230722951363, 'Total loss': 0.26645230722951363}
2023-01-04 00:51:36,383 INFO:     Found new best model at epoch 30
2023-01-04 00:51:36,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:36,384 INFO:     Epoch: 31
2023-01-04 00:51:37,972 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44463796516259513, 'Total loss': 0.44463796516259513} | train loss {'Reaction outcome loss': 0.26336017341076673, 'Total loss': 0.26336017341076673}
2023-01-04 00:51:37,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:37,972 INFO:     Epoch: 32
2023-01-04 00:51:39,532 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4868006477753321, 'Total loss': 0.4868006477753321} | train loss {'Reaction outcome loss': 0.2602108222442669, 'Total loss': 0.2602108222442669}
2023-01-04 00:51:39,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:39,532 INFO:     Epoch: 33
2023-01-04 00:51:41,134 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4603023290634155, 'Total loss': 0.4603023290634155} | train loss {'Reaction outcome loss': 0.25746926049882674, 'Total loss': 0.25746926049882674}
2023-01-04 00:51:41,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:41,134 INFO:     Epoch: 34
2023-01-04 00:51:42,693 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4772246450185776, 'Total loss': 0.4772246450185776} | train loss {'Reaction outcome loss': 0.25375232848273965, 'Total loss': 0.25375232848273965}
2023-01-04 00:51:42,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:42,694 INFO:     Epoch: 35
2023-01-04 00:51:44,272 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.430404860774676, 'Total loss': 0.430404860774676} | train loss {'Reaction outcome loss': 0.25296742059699784, 'Total loss': 0.25296742059699784}
2023-01-04 00:51:44,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:44,272 INFO:     Epoch: 36
2023-01-04 00:51:45,860 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4551271140575409, 'Total loss': 0.4551271140575409} | train loss {'Reaction outcome loss': 0.24899064829989231, 'Total loss': 0.24899064829989231}
2023-01-04 00:51:45,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:45,860 INFO:     Epoch: 37
2023-01-04 00:51:47,451 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45989830096562706, 'Total loss': 0.45989830096562706} | train loss {'Reaction outcome loss': 0.24488022456784825, 'Total loss': 0.24488022456784825}
2023-01-04 00:51:47,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:47,452 INFO:     Epoch: 38
2023-01-04 00:51:49,026 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4561284899711609, 'Total loss': 0.4561284899711609} | train loss {'Reaction outcome loss': 0.24283737536424246, 'Total loss': 0.24283737536424246}
2023-01-04 00:51:49,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:49,026 INFO:     Epoch: 39
2023-01-04 00:51:50,627 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4437061965465546, 'Total loss': 0.4437061965465546} | train loss {'Reaction outcome loss': 0.24014990430857455, 'Total loss': 0.24014990430857455}
2023-01-04 00:51:50,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:50,627 INFO:     Epoch: 40
2023-01-04 00:51:52,205 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44096050461133324, 'Total loss': 0.44096050461133324} | train loss {'Reaction outcome loss': 0.24039334981214433, 'Total loss': 0.24039334981214433}
2023-01-04 00:51:52,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:52,205 INFO:     Epoch: 41
2023-01-04 00:51:53,783 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45587146778901416, 'Total loss': 0.45587146778901416} | train loss {'Reaction outcome loss': 0.23435934795401034, 'Total loss': 0.23435934795401034}
2023-01-04 00:51:53,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:53,784 INFO:     Epoch: 42
2023-01-04 00:51:55,360 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4262491300702095, 'Total loss': 0.4262491300702095} | train loss {'Reaction outcome loss': 0.23376601782965137, 'Total loss': 0.23376601782965137}
2023-01-04 00:51:55,361 INFO:     Found new best model at epoch 42
2023-01-04 00:51:55,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:55,362 INFO:     Epoch: 43
2023-01-04 00:51:56,918 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4406042456626892, 'Total loss': 0.4406042456626892} | train loss {'Reaction outcome loss': 0.23373917644440909, 'Total loss': 0.23373917644440909}
2023-01-04 00:51:56,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:56,919 INFO:     Epoch: 44
2023-01-04 00:51:58,519 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4324371010065079, 'Total loss': 0.4324371010065079} | train loss {'Reaction outcome loss': 0.22943558687200913, 'Total loss': 0.22943558687200913}
2023-01-04 00:51:58,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:51:58,519 INFO:     Epoch: 45
2023-01-04 00:52:00,123 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4395921876033147, 'Total loss': 0.4395921876033147} | train loss {'Reaction outcome loss': 0.22973220799486715, 'Total loss': 0.22973220799486715}
2023-01-04 00:52:00,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:00,124 INFO:     Epoch: 46
2023-01-04 00:52:01,696 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4475717971722285, 'Total loss': 0.4475717971722285} | train loss {'Reaction outcome loss': 0.2238962138310457, 'Total loss': 0.2238962138310457}
2023-01-04 00:52:01,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:01,696 INFO:     Epoch: 47
2023-01-04 00:52:03,302 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4356200550993284, 'Total loss': 0.4356200550993284} | train loss {'Reaction outcome loss': 0.2259053875975338, 'Total loss': 0.2259053875975338}
2023-01-04 00:52:03,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:03,302 INFO:     Epoch: 48
2023-01-04 00:52:04,904 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4586631049712499, 'Total loss': 0.4586631049712499} | train loss {'Reaction outcome loss': 0.22620947991972004, 'Total loss': 0.22620947991972004}
2023-01-04 00:52:04,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:04,904 INFO:     Epoch: 49
2023-01-04 00:52:06,476 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43730853299299877, 'Total loss': 0.43730853299299877} | train loss {'Reaction outcome loss': 0.22173266273824285, 'Total loss': 0.22173266273824285}
2023-01-04 00:52:06,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:06,477 INFO:     Epoch: 50
2023-01-04 00:52:08,057 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45106620490550997, 'Total loss': 0.45106620490550997} | train loss {'Reaction outcome loss': 0.2221392273575395, 'Total loss': 0.2221392273575395}
2023-01-04 00:52:08,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:08,057 INFO:     Epoch: 51
2023-01-04 00:52:09,620 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43123877545197803, 'Total loss': 0.43123877545197803} | train loss {'Reaction outcome loss': 0.22184957905020905, 'Total loss': 0.22184957905020905}
2023-01-04 00:52:09,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:09,620 INFO:     Epoch: 52
2023-01-04 00:52:11,201 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4527164181073507, 'Total loss': 0.4527164181073507} | train loss {'Reaction outcome loss': 0.21826966342963142, 'Total loss': 0.21826966342963142}
2023-01-04 00:52:11,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:11,202 INFO:     Epoch: 53
2023-01-04 00:52:12,781 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4325256293018659, 'Total loss': 0.4325256293018659} | train loss {'Reaction outcome loss': 0.21342920859927658, 'Total loss': 0.21342920859927658}
2023-01-04 00:52:12,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:12,782 INFO:     Epoch: 54
2023-01-04 00:52:14,359 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4511702169974645, 'Total loss': 0.4511702169974645} | train loss {'Reaction outcome loss': 0.21397704818036967, 'Total loss': 0.21397704818036967}
2023-01-04 00:52:14,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:14,360 INFO:     Epoch: 55
2023-01-04 00:52:15,917 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43263000845909116, 'Total loss': 0.43263000845909116} | train loss {'Reaction outcome loss': 0.21401003922844108, 'Total loss': 0.21401003922844108}
2023-01-04 00:52:15,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:15,918 INFO:     Epoch: 56
2023-01-04 00:52:17,501 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4392204314470291, 'Total loss': 0.4392204314470291} | train loss {'Reaction outcome loss': 0.21105105384174502, 'Total loss': 0.21105105384174502}
2023-01-04 00:52:17,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:17,501 INFO:     Epoch: 57
2023-01-04 00:52:19,070 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4577386677265167, 'Total loss': 0.4577386677265167} | train loss {'Reaction outcome loss': 0.20876818651763293, 'Total loss': 0.20876818651763293}
2023-01-04 00:52:19,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:19,072 INFO:     Epoch: 58
2023-01-04 00:52:20,658 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.455439892411232, 'Total loss': 0.455439892411232} | train loss {'Reaction outcome loss': 0.2090321309700772, 'Total loss': 0.2090321309700772}
2023-01-04 00:52:20,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:20,658 INFO:     Epoch: 59
2023-01-04 00:52:22,251 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43741193413734436, 'Total loss': 0.43741193413734436} | train loss {'Reaction outcome loss': 0.20438507836544034, 'Total loss': 0.20438507836544034}
2023-01-04 00:52:22,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:22,251 INFO:     Epoch: 60
2023-01-04 00:52:23,831 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47564650177955625, 'Total loss': 0.47564650177955625} | train loss {'Reaction outcome loss': 0.20709046877020007, 'Total loss': 0.20709046877020007}
2023-01-04 00:52:23,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:23,831 INFO:     Epoch: 61
2023-01-04 00:52:25,410 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4651880979537964, 'Total loss': 0.4651880979537964} | train loss {'Reaction outcome loss': 0.20548664274942743, 'Total loss': 0.20548664274942743}
2023-01-04 00:52:25,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:25,411 INFO:     Epoch: 62
2023-01-04 00:52:26,986 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48539926409721373, 'Total loss': 0.48539926409721373} | train loss {'Reaction outcome loss': 0.2033179730531715, 'Total loss': 0.2033179730531715}
2023-01-04 00:52:26,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:26,987 INFO:     Epoch: 63
2023-01-04 00:52:28,564 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4380106608072917, 'Total loss': 0.4380106608072917} | train loss {'Reaction outcome loss': 0.20455453297867007, 'Total loss': 0.20455453297867007}
2023-01-04 00:52:28,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:28,564 INFO:     Epoch: 64
2023-01-04 00:52:30,154 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45144599278767905, 'Total loss': 0.45144599278767905} | train loss {'Reaction outcome loss': 0.20158028384268065, 'Total loss': 0.20158028384268065}
2023-01-04 00:52:30,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:30,154 INFO:     Epoch: 65
2023-01-04 00:52:31,760 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48223028679688773, 'Total loss': 0.48223028679688773} | train loss {'Reaction outcome loss': 0.2009325032924121, 'Total loss': 0.2009325032924121}
2023-01-04 00:52:31,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:31,761 INFO:     Epoch: 66
2023-01-04 00:52:33,331 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43991433680057523, 'Total loss': 0.43991433680057523} | train loss {'Reaction outcome loss': 0.202189510231053, 'Total loss': 0.202189510231053}
2023-01-04 00:52:33,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:33,331 INFO:     Epoch: 67
2023-01-04 00:52:34,910 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46623852054278053, 'Total loss': 0.46623852054278053} | train loss {'Reaction outcome loss': 0.1987554241831486, 'Total loss': 0.1987554241831486}
2023-01-04 00:52:34,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:34,910 INFO:     Epoch: 68
2023-01-04 00:52:36,467 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4501582463582357, 'Total loss': 0.4501582463582357} | train loss {'Reaction outcome loss': 0.19951314393144387, 'Total loss': 0.19951314393144387}
2023-01-04 00:52:36,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:36,468 INFO:     Epoch: 69
2023-01-04 00:52:38,049 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4740848441918691, 'Total loss': 0.4740848441918691} | train loss {'Reaction outcome loss': 0.19608793573474492, 'Total loss': 0.19608793573474492}
2023-01-04 00:52:38,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:38,049 INFO:     Epoch: 70
2023-01-04 00:52:39,628 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4266938890020053, 'Total loss': 0.4266938890020053} | train loss {'Reaction outcome loss': 0.19477466980998331, 'Total loss': 0.19477466980998331}
2023-01-04 00:52:39,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:39,628 INFO:     Epoch: 71
2023-01-04 00:52:41,208 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4516075800793866, 'Total loss': 0.4516075800793866} | train loss {'Reaction outcome loss': 0.19467666036289036, 'Total loss': 0.19467666036289036}
2023-01-04 00:52:41,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:41,209 INFO:     Epoch: 72
2023-01-04 00:52:42,777 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4334361304839452, 'Total loss': 0.4334361304839452} | train loss {'Reaction outcome loss': 0.19155900836956344, 'Total loss': 0.19155900836956344}
2023-01-04 00:52:42,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:42,778 INFO:     Epoch: 73
2023-01-04 00:52:44,361 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4551468352476756, 'Total loss': 0.4551468352476756} | train loss {'Reaction outcome loss': 0.1908008369102037, 'Total loss': 0.1908008369102037}
2023-01-04 00:52:44,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:44,362 INFO:     Epoch: 74
2023-01-04 00:52:45,934 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4858602543671926, 'Total loss': 0.4858602543671926} | train loss {'Reaction outcome loss': 0.19352500974763553, 'Total loss': 0.19352500974763553}
2023-01-04 00:52:45,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:45,934 INFO:     Epoch: 75
2023-01-04 00:52:47,516 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45318583995103834, 'Total loss': 0.45318583995103834} | train loss {'Reaction outcome loss': 0.1898657557701235, 'Total loss': 0.1898657557701235}
2023-01-04 00:52:47,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:47,516 INFO:     Epoch: 76
2023-01-04 00:52:49,100 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.470325767993927, 'Total loss': 0.470325767993927} | train loss {'Reaction outcome loss': 0.19059069219963018, 'Total loss': 0.19059069219963018}
2023-01-04 00:52:49,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:49,102 INFO:     Epoch: 77
2023-01-04 00:52:50,670 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4438329646984736, 'Total loss': 0.4438329646984736} | train loss {'Reaction outcome loss': 0.18933274043594306, 'Total loss': 0.18933274043594306}
2023-01-04 00:52:50,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:50,670 INFO:     Epoch: 78
2023-01-04 00:52:52,265 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45617970724900564, 'Total loss': 0.45617970724900564} | train loss {'Reaction outcome loss': 0.18820809001178096, 'Total loss': 0.18820809001178096}
2023-01-04 00:52:52,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:52,265 INFO:     Epoch: 79
2023-01-04 00:52:53,851 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44573852891723315, 'Total loss': 0.44573852891723315} | train loss {'Reaction outcome loss': 0.18887952182974135, 'Total loss': 0.18887952182974135}
2023-01-04 00:52:53,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:53,852 INFO:     Epoch: 80
2023-01-04 00:52:55,424 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4397614618142446, 'Total loss': 0.4397614618142446} | train loss {'Reaction outcome loss': 0.1873007480041448, 'Total loss': 0.1873007480041448}
2023-01-04 00:52:55,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:55,425 INFO:     Epoch: 81
2023-01-04 00:52:57,009 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49018203616142275, 'Total loss': 0.49018203616142275} | train loss {'Reaction outcome loss': 0.1877333334623239, 'Total loss': 0.1877333334623239}
2023-01-04 00:52:57,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:57,009 INFO:     Epoch: 82
2023-01-04 00:52:58,605 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48458430767059324, 'Total loss': 0.48458430767059324} | train loss {'Reaction outcome loss': 0.18478455836628818, 'Total loss': 0.18478455836628818}
2023-01-04 00:52:58,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:52:58,605 INFO:     Epoch: 83
2023-01-04 00:53:00,181 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47005239824453987, 'Total loss': 0.47005239824453987} | train loss {'Reaction outcome loss': 0.1853575743871294, 'Total loss': 0.1853575743871294}
2023-01-04 00:53:00,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:00,182 INFO:     Epoch: 84
2023-01-04 00:53:01,762 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4884859393040339, 'Total loss': 0.4884859393040339} | train loss {'Reaction outcome loss': 0.18353473384192576, 'Total loss': 0.18353473384192576}
2023-01-04 00:53:01,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:01,762 INFO:     Epoch: 85
2023-01-04 00:53:03,326 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46826284726460776, 'Total loss': 0.46826284726460776} | train loss {'Reaction outcome loss': 0.18355891387568507, 'Total loss': 0.18355891387568507}
2023-01-04 00:53:03,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:03,326 INFO:     Epoch: 86
2023-01-04 00:53:04,936 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4566181858380636, 'Total loss': 0.4566181858380636} | train loss {'Reaction outcome loss': 0.18465059441633713, 'Total loss': 0.18465059441633713}
2023-01-04 00:53:04,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:04,936 INFO:     Epoch: 87
2023-01-04 00:53:06,544 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4664830466111501, 'Total loss': 0.4664830466111501} | train loss {'Reaction outcome loss': 0.18513861861277794, 'Total loss': 0.18513861861277794}
2023-01-04 00:53:06,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:06,546 INFO:     Epoch: 88
2023-01-04 00:53:08,142 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4733326176802317, 'Total loss': 0.4733326176802317} | train loss {'Reaction outcome loss': 0.17957056252347245, 'Total loss': 0.17957056252347245}
2023-01-04 00:53:08,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:08,142 INFO:     Epoch: 89
2023-01-04 00:53:09,703 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46395988166332247, 'Total loss': 0.46395988166332247} | train loss {'Reaction outcome loss': 0.17771039108981143, 'Total loss': 0.17771039108981143}
2023-01-04 00:53:09,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:09,703 INFO:     Epoch: 90
2023-01-04 00:53:11,283 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4921591281890869, 'Total loss': 0.4921591281890869} | train loss {'Reaction outcome loss': 0.17837759877654005, 'Total loss': 0.17837759877654005}
2023-01-04 00:53:11,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:11,283 INFO:     Epoch: 91
2023-01-04 00:53:12,846 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44261220991611483, 'Total loss': 0.44261220991611483} | train loss {'Reaction outcome loss': 0.1788265469787649, 'Total loss': 0.1788265469787649}
2023-01-04 00:53:12,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:12,847 INFO:     Epoch: 92
2023-01-04 00:53:14,424 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46054914593696594, 'Total loss': 0.46054914593696594} | train loss {'Reaction outcome loss': 0.17756888341336025, 'Total loss': 0.17756888341336025}
2023-01-04 00:53:14,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:14,425 INFO:     Epoch: 93
2023-01-04 00:53:15,997 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4407980054616928, 'Total loss': 0.4407980054616928} | train loss {'Reaction outcome loss': 0.17743197750750478, 'Total loss': 0.17743197750750478}
2023-01-04 00:53:15,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:15,997 INFO:     Epoch: 94
2023-01-04 00:53:17,555 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4714151998360952, 'Total loss': 0.4714151998360952} | train loss {'Reaction outcome loss': 0.1764425633563882, 'Total loss': 0.1764425633563882}
2023-01-04 00:53:17,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:17,555 INFO:     Epoch: 95
2023-01-04 00:53:19,133 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46767390966415406, 'Total loss': 0.46767390966415406} | train loss {'Reaction outcome loss': 0.17786609519259397, 'Total loss': 0.17786609519259397}
2023-01-04 00:53:19,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:19,134 INFO:     Epoch: 96
2023-01-04 00:53:20,715 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46967195967833203, 'Total loss': 0.46967195967833203} | train loss {'Reaction outcome loss': 0.17741542274043673, 'Total loss': 0.17741542274043673}
2023-01-04 00:53:20,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:20,715 INFO:     Epoch: 97
2023-01-04 00:53:22,282 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44119299749533336, 'Total loss': 0.44119299749533336} | train loss {'Reaction outcome loss': 0.17503351371585232, 'Total loss': 0.17503351371585232}
2023-01-04 00:53:22,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:22,283 INFO:     Epoch: 98
2023-01-04 00:53:23,861 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.49320788780848185, 'Total loss': 0.49320788780848185} | train loss {'Reaction outcome loss': 0.17639293064851136, 'Total loss': 0.17639293064851136}
2023-01-04 00:53:23,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:23,862 INFO:     Epoch: 99
2023-01-04 00:53:25,441 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4698604663213094, 'Total loss': 0.4698604663213094} | train loss {'Reaction outcome loss': 0.17060930874785443, 'Total loss': 0.17060930874785443}
2023-01-04 00:53:25,442 INFO:     Best model found after epoch 43 of 100.
2023-01-04 00:53:25,442 INFO:   Done with stage: TRAINING
2023-01-04 00:53:25,443 INFO:   Starting stage: EVALUATION
2023-01-04 00:53:25,583 INFO:   Done with stage: EVALUATION
2023-01-04 00:53:25,583 INFO:   Leaving out SEQ value Fold_4
2023-01-04 00:53:25,596 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 00:53:25,596 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:53:26,237 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:53:26,237 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:53:26,307 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:53:26,307 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:53:26,308 INFO:     No hyperparam tuning for this model
2023-01-04 00:53:26,308 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:53:26,308 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:53:26,308 INFO:     None feature selector for col prot
2023-01-04 00:53:26,309 INFO:     None feature selector for col prot
2023-01-04 00:53:26,309 INFO:     None feature selector for col prot
2023-01-04 00:53:26,309 INFO:     None feature selector for col chem
2023-01-04 00:53:26,309 INFO:     None feature selector for col chem
2023-01-04 00:53:26,309 INFO:     None feature selector for col chem
2023-01-04 00:53:26,309 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:53:26,309 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:53:26,310 INFO:     Number of params in model 70141
2023-01-04 00:53:26,314 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:53:26,314 INFO:   Starting stage: TRAINING
2023-01-04 00:53:26,358 INFO:     Val loss before train {'Reaction outcome loss': 0.9536542256673177, 'Total loss': 0.9536542256673177}
2023-01-04 00:53:26,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:26,358 INFO:     Epoch: 0
2023-01-04 00:53:27,975 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6376615266005198, 'Total loss': 0.6376615266005198} | train loss {'Reaction outcome loss': 0.8360836709338322, 'Total loss': 0.8360836709338322}
2023-01-04 00:53:27,975 INFO:     Found new best model at epoch 0
2023-01-04 00:53:27,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:27,976 INFO:     Epoch: 1
2023-01-04 00:53:29,591 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5395724594593048, 'Total loss': 0.5395724594593048} | train loss {'Reaction outcome loss': 0.5704393465192866, 'Total loss': 0.5704393465192866}
2023-01-04 00:53:29,592 INFO:     Found new best model at epoch 1
2023-01-04 00:53:29,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:29,593 INFO:     Epoch: 2
2023-01-04 00:53:31,199 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5162343382835388, 'Total loss': 0.5162343382835388} | train loss {'Reaction outcome loss': 0.5132362658994786, 'Total loss': 0.5132362658994786}
2023-01-04 00:53:31,199 INFO:     Found new best model at epoch 2
2023-01-04 00:53:31,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:31,200 INFO:     Epoch: 3
2023-01-04 00:53:32,786 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5124619781970978, 'Total loss': 0.5124619781970978} | train loss {'Reaction outcome loss': 0.47651006097810855, 'Total loss': 0.47651006097810855}
2023-01-04 00:53:32,786 INFO:     Found new best model at epoch 3
2023-01-04 00:53:32,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:32,787 INFO:     Epoch: 4
2023-01-04 00:53:34,391 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4624892771244049, 'Total loss': 0.4624892771244049} | train loss {'Reaction outcome loss': 0.448288022581002, 'Total loss': 0.448288022581002}
2023-01-04 00:53:34,391 INFO:     Found new best model at epoch 4
2023-01-04 00:53:34,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:34,392 INFO:     Epoch: 5
2023-01-04 00:53:35,974 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4649973789850871, 'Total loss': 0.4649973789850871} | train loss {'Reaction outcome loss': 0.4254768852083741, 'Total loss': 0.4254768852083741}
2023-01-04 00:53:35,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:35,974 INFO:     Epoch: 6
2023-01-04 00:53:37,568 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4513275841871897, 'Total loss': 0.4513275841871897} | train loss {'Reaction outcome loss': 0.4067759923989375, 'Total loss': 0.4067759923989375}
2023-01-04 00:53:37,569 INFO:     Found new best model at epoch 6
2023-01-04 00:53:37,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:37,570 INFO:     Epoch: 7
2023-01-04 00:53:39,168 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4378756711880366, 'Total loss': 0.4378756711880366} | train loss {'Reaction outcome loss': 0.39362764018385304, 'Total loss': 0.39362764018385304}
2023-01-04 00:53:39,168 INFO:     Found new best model at epoch 7
2023-01-04 00:53:39,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:39,169 INFO:     Epoch: 8
2023-01-04 00:53:40,763 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42925177812576293, 'Total loss': 0.42925177812576293} | train loss {'Reaction outcome loss': 0.3831617320914423, 'Total loss': 0.3831617320914423}
2023-01-04 00:53:40,763 INFO:     Found new best model at epoch 8
2023-01-04 00:53:40,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:40,764 INFO:     Epoch: 9
2023-01-04 00:53:42,357 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4264698525269826, 'Total loss': 0.4264698525269826} | train loss {'Reaction outcome loss': 0.3727766271896552, 'Total loss': 0.3727766271896552}
2023-01-04 00:53:42,357 INFO:     Found new best model at epoch 9
2023-01-04 00:53:42,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:42,358 INFO:     Epoch: 10
2023-01-04 00:53:43,965 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43331448634465536, 'Total loss': 0.43331448634465536} | train loss {'Reaction outcome loss': 0.3783878860860199, 'Total loss': 0.3783878860860199}
2023-01-04 00:53:43,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:43,966 INFO:     Epoch: 11
2023-01-04 00:53:45,571 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42923983534177146, 'Total loss': 0.42923983534177146} | train loss {'Reaction outcome loss': 0.357956062870748, 'Total loss': 0.357956062870748}
2023-01-04 00:53:45,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:45,571 INFO:     Epoch: 12
2023-01-04 00:53:47,163 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4074529200792313, 'Total loss': 0.4074529200792313} | train loss {'Reaction outcome loss': 0.3496425134548243, 'Total loss': 0.3496425134548243}
2023-01-04 00:53:47,163 INFO:     Found new best model at epoch 12
2023-01-04 00:53:47,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:47,164 INFO:     Epoch: 13
2023-01-04 00:53:48,763 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40325287779172264, 'Total loss': 0.40325287779172264} | train loss {'Reaction outcome loss': 0.3416467047147993, 'Total loss': 0.3416467047147993}
2023-01-04 00:53:48,763 INFO:     Found new best model at epoch 13
2023-01-04 00:53:48,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:48,764 INFO:     Epoch: 14
2023-01-04 00:53:50,381 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4027980089187622, 'Total loss': 0.4027980089187622} | train loss {'Reaction outcome loss': 0.328545140993336, 'Total loss': 0.328545140993336}
2023-01-04 00:53:50,383 INFO:     Found new best model at epoch 14
2023-01-04 00:53:50,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:50,384 INFO:     Epoch: 15
2023-01-04 00:53:52,002 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3954145719607671, 'Total loss': 0.3954145719607671} | train loss {'Reaction outcome loss': 0.3234028554406773, 'Total loss': 0.3234028554406773}
2023-01-04 00:53:52,002 INFO:     Found new best model at epoch 15
2023-01-04 00:53:52,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:52,003 INFO:     Epoch: 16
2023-01-04 00:53:53,578 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3877308915058772, 'Total loss': 0.3877308915058772} | train loss {'Reaction outcome loss': 0.3177841122302672, 'Total loss': 0.3177841122302672}
2023-01-04 00:53:53,578 INFO:     Found new best model at epoch 16
2023-01-04 00:53:53,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:53,579 INFO:     Epoch: 17
2023-01-04 00:53:55,168 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3756815234820048, 'Total loss': 0.3756815234820048} | train loss {'Reaction outcome loss': 0.31289521887990396, 'Total loss': 0.31289521887990396}
2023-01-04 00:53:55,168 INFO:     Found new best model at epoch 17
2023-01-04 00:53:55,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:55,169 INFO:     Epoch: 18
2023-01-04 00:53:56,758 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.38640392025311787, 'Total loss': 0.38640392025311787} | train loss {'Reaction outcome loss': 0.3077060284782235, 'Total loss': 0.3077060284782235}
2023-01-04 00:53:56,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:56,759 INFO:     Epoch: 19
2023-01-04 00:53:58,365 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39425390362739565, 'Total loss': 0.39425390362739565} | train loss {'Reaction outcome loss': 0.300241575292919, 'Total loss': 0.300241575292919}
2023-01-04 00:53:58,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:58,365 INFO:     Epoch: 20
2023-01-04 00:53:59,957 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3821612407763799, 'Total loss': 0.3821612407763799} | train loss {'Reaction outcome loss': 0.3024840810592624, 'Total loss': 0.3024840810592624}
2023-01-04 00:53:59,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:53:59,957 INFO:     Epoch: 21
2023-01-04 00:54:01,584 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.38347530364990234, 'Total loss': 0.38347530364990234} | train loss {'Reaction outcome loss': 0.2917512533081142, 'Total loss': 0.2917512533081142}
2023-01-04 00:54:01,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:01,585 INFO:     Epoch: 22
2023-01-04 00:54:03,167 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.37007875442504884, 'Total loss': 0.37007875442504884} | train loss {'Reaction outcome loss': 0.28666355394154275, 'Total loss': 0.28666355394154275}
2023-01-04 00:54:03,167 INFO:     Found new best model at epoch 22
2023-01-04 00:54:03,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:03,168 INFO:     Epoch: 23
2023-01-04 00:54:04,781 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.38150017460187274, 'Total loss': 0.38150017460187274} | train loss {'Reaction outcome loss': 0.29284341255391855, 'Total loss': 0.29284341255391855}
2023-01-04 00:54:04,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:04,781 INFO:     Epoch: 24
2023-01-04 00:54:06,370 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.37902111411094663, 'Total loss': 0.37902111411094663} | train loss {'Reaction outcome loss': 0.29167142215495306, 'Total loss': 0.29167142215495306}
2023-01-04 00:54:06,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:06,371 INFO:     Epoch: 25
2023-01-04 00:54:07,957 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3806448062260946, 'Total loss': 0.3806448062260946} | train loss {'Reaction outcome loss': 0.274302877890675, 'Total loss': 0.274302877890675}
2023-01-04 00:54:07,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:07,959 INFO:     Epoch: 26
2023-01-04 00:54:09,546 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3986711412668228, 'Total loss': 0.3986711412668228} | train loss {'Reaction outcome loss': 0.2743648278299298, 'Total loss': 0.2743648278299298}
2023-01-04 00:54:09,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:09,547 INFO:     Epoch: 27
2023-01-04 00:54:11,146 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3781558165947596, 'Total loss': 0.3781558165947596} | train loss {'Reaction outcome loss': 0.26705590014698566, 'Total loss': 0.26705590014698566}
2023-01-04 00:54:11,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:11,146 INFO:     Epoch: 28
2023-01-04 00:54:12,742 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.395969831943512, 'Total loss': 0.395969831943512} | train loss {'Reaction outcome loss': 0.2636690415522974, 'Total loss': 0.2636690415522974}
2023-01-04 00:54:12,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:12,742 INFO:     Epoch: 29
2023-01-04 00:54:14,336 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38447280327479044, 'Total loss': 0.38447280327479044} | train loss {'Reaction outcome loss': 0.26194990451982003, 'Total loss': 0.26194990451982003}
2023-01-04 00:54:14,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:14,337 INFO:     Epoch: 30
2023-01-04 00:54:15,957 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.36430288751920065, 'Total loss': 0.36430288751920065} | train loss {'Reaction outcome loss': 0.2580488036476089, 'Total loss': 0.2580488036476089}
2023-01-04 00:54:15,957 INFO:     Found new best model at epoch 30
2023-01-04 00:54:15,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:15,958 INFO:     Epoch: 31
2023-01-04 00:54:17,548 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3745962580045064, 'Total loss': 0.3745962580045064} | train loss {'Reaction outcome loss': 0.25442811439785623, 'Total loss': 0.25442811439785623}
2023-01-04 00:54:17,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:17,549 INFO:     Epoch: 32
2023-01-04 00:54:19,211 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3847998509804408, 'Total loss': 0.3847998509804408} | train loss {'Reaction outcome loss': 0.25288314142844814, 'Total loss': 0.25288314142844814}
2023-01-04 00:54:19,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:19,212 INFO:     Epoch: 33
2023-01-04 00:54:20,801 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3760429248213768, 'Total loss': 0.3760429248213768} | train loss {'Reaction outcome loss': 0.253496096196139, 'Total loss': 0.253496096196139}
2023-01-04 00:54:20,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:20,801 INFO:     Epoch: 34
2023-01-04 00:54:22,461 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3862565368413925, 'Total loss': 0.3862565368413925} | train loss {'Reaction outcome loss': 0.24665743422498793, 'Total loss': 0.24665743422498793}
2023-01-04 00:54:22,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:22,461 INFO:     Epoch: 35
2023-01-04 00:54:24,043 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3674649010101954, 'Total loss': 0.3674649010101954} | train loss {'Reaction outcome loss': 0.24125792804187624, 'Total loss': 0.24125792804187624}
2023-01-04 00:54:24,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:24,043 INFO:     Epoch: 36
2023-01-04 00:54:25,703 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37118975818157196, 'Total loss': 0.37118975818157196} | train loss {'Reaction outcome loss': 0.24143042583402374, 'Total loss': 0.24143042583402374}
2023-01-04 00:54:25,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:25,703 INFO:     Epoch: 37
2023-01-04 00:54:27,369 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37909911970297494, 'Total loss': 0.37909911970297494} | train loss {'Reaction outcome loss': 0.24889630879666927, 'Total loss': 0.24889630879666927}
2023-01-04 00:54:27,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:27,371 INFO:     Epoch: 38
2023-01-04 00:54:28,964 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3651772518952688, 'Total loss': 0.3651772518952688} | train loss {'Reaction outcome loss': 0.255612372944238, 'Total loss': 0.255612372944238}
2023-01-04 00:54:28,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:28,964 INFO:     Epoch: 39
2023-01-04 00:54:30,618 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.38478605846563974, 'Total loss': 0.38478605846563974} | train loss {'Reaction outcome loss': 0.23333972039381604, 'Total loss': 0.23333972039381604}
2023-01-04 00:54:30,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:30,618 INFO:     Epoch: 40
2023-01-04 00:54:32,280 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3805961807568868, 'Total loss': 0.3805961807568868} | train loss {'Reaction outcome loss': 0.2298770985748295, 'Total loss': 0.2298770985748295}
2023-01-04 00:54:32,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:32,281 INFO:     Epoch: 41
2023-01-04 00:54:33,858 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.35175154109795886, 'Total loss': 0.35175154109795886} | train loss {'Reaction outcome loss': 0.22863592886141557, 'Total loss': 0.22863592886141557}
2023-01-04 00:54:33,858 INFO:     Found new best model at epoch 41
2023-01-04 00:54:33,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:33,859 INFO:     Epoch: 42
2023-01-04 00:54:35,494 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38161224623521167, 'Total loss': 0.38161224623521167} | train loss {'Reaction outcome loss': 0.2254450315123667, 'Total loss': 0.2254450315123667}
2023-01-04 00:54:35,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:35,494 INFO:     Epoch: 43
2023-01-04 00:54:37,155 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3724662313858668, 'Total loss': 0.3724662313858668} | train loss {'Reaction outcome loss': 0.22356683878309053, 'Total loss': 0.22356683878309053}
2023-01-04 00:54:37,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:37,155 INFO:     Epoch: 44
2023-01-04 00:54:38,795 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3805684506893158, 'Total loss': 0.3805684506893158} | train loss {'Reaction outcome loss': 0.23094084956075833, 'Total loss': 0.23094084956075833}
2023-01-04 00:54:38,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:38,796 INFO:     Epoch: 45
2023-01-04 00:54:40,458 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.35877564499775566, 'Total loss': 0.35877564499775566} | train loss {'Reaction outcome loss': 0.22477006972295002, 'Total loss': 0.22477006972295002}
2023-01-04 00:54:40,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:40,459 INFO:     Epoch: 46
2023-01-04 00:54:42,120 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.36961454500754676, 'Total loss': 0.36961454500754676} | train loss {'Reaction outcome loss': 0.21915457966953408, 'Total loss': 0.21915457966953408}
2023-01-04 00:54:42,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:42,121 INFO:     Epoch: 47
2023-01-04 00:54:43,758 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.34817441999912263, 'Total loss': 0.34817441999912263} | train loss {'Reaction outcome loss': 0.21729673483038653, 'Total loss': 0.21729673483038653}
2023-01-04 00:54:43,758 INFO:     Found new best model at epoch 47
2023-01-04 00:54:43,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:43,759 INFO:     Epoch: 48
2023-01-04 00:54:45,419 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3903698831796646, 'Total loss': 0.3903698831796646} | train loss {'Reaction outcome loss': 0.2143542737596043, 'Total loss': 0.2143542737596043}
2023-01-04 00:54:45,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:45,420 INFO:     Epoch: 49
2023-01-04 00:54:47,040 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3681112358967463, 'Total loss': 0.3681112358967463} | train loss {'Reaction outcome loss': 0.2127927657847054, 'Total loss': 0.2127927657847054}
2023-01-04 00:54:47,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:47,040 INFO:     Epoch: 50
2023-01-04 00:54:48,678 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3731490562359492, 'Total loss': 0.3731490562359492} | train loss {'Reaction outcome loss': 0.21405905186860025, 'Total loss': 0.21405905186860025}
2023-01-04 00:54:48,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:48,678 INFO:     Epoch: 51
2023-01-04 00:54:50,263 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3927242249250412, 'Total loss': 0.3927242249250412} | train loss {'Reaction outcome loss': 0.21009121282701887, 'Total loss': 0.21009121282701887}
2023-01-04 00:54:50,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:50,263 INFO:     Epoch: 52
2023-01-04 00:54:51,840 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3694092830022176, 'Total loss': 0.3694092830022176} | train loss {'Reaction outcome loss': 0.21078698575349888, 'Total loss': 0.21078698575349888}
2023-01-04 00:54:51,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:51,841 INFO:     Epoch: 53
2023-01-04 00:54:53,434 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3591142982244492, 'Total loss': 0.3591142982244492} | train loss {'Reaction outcome loss': 0.20688240919970785, 'Total loss': 0.20688240919970785}
2023-01-04 00:54:53,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:53,435 INFO:     Epoch: 54
2023-01-04 00:54:55,045 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3784016768137614, 'Total loss': 0.3784016768137614} | train loss {'Reaction outcome loss': 0.20479307569811403, 'Total loss': 0.20479307569811403}
2023-01-04 00:54:55,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:55,045 INFO:     Epoch: 55
2023-01-04 00:54:56,628 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37263704240322115, 'Total loss': 0.37263704240322115} | train loss {'Reaction outcome loss': 0.20509987626493523, 'Total loss': 0.20509987626493523}
2023-01-04 00:54:56,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:56,629 INFO:     Epoch: 56
2023-01-04 00:54:58,230 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3849050263563792, 'Total loss': 0.3849050263563792} | train loss {'Reaction outcome loss': 0.2064866819014044, 'Total loss': 0.2064866819014044}
2023-01-04 00:54:58,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:58,230 INFO:     Epoch: 57
2023-01-04 00:54:59,841 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3709618866443634, 'Total loss': 0.3709618866443634} | train loss {'Reaction outcome loss': 0.20523341243044368, 'Total loss': 0.20523341243044368}
2023-01-04 00:54:59,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:54:59,841 INFO:     Epoch: 58
2023-01-04 00:55:01,430 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3786875605583191, 'Total loss': 0.3786875605583191} | train loss {'Reaction outcome loss': 0.19970013741365858, 'Total loss': 0.19970013741365858}
2023-01-04 00:55:01,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:01,430 INFO:     Epoch: 59
2023-01-04 00:55:03,026 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.35030904014905295, 'Total loss': 0.35030904014905295} | train loss {'Reaction outcome loss': 0.19651135669994182, 'Total loss': 0.19651135669994182}
2023-01-04 00:55:03,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:03,027 INFO:     Epoch: 60
2023-01-04 00:55:04,623 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.38488171199957527, 'Total loss': 0.38488171199957527} | train loss {'Reaction outcome loss': 0.1979432266470858, 'Total loss': 0.1979432266470858}
2023-01-04 00:55:04,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:04,623 INFO:     Epoch: 61
2023-01-04 00:55:06,223 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41662405133247377, 'Total loss': 0.41662405133247377} | train loss {'Reaction outcome loss': 0.19538457527675707, 'Total loss': 0.19538457527675707}
2023-01-04 00:55:06,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:06,223 INFO:     Epoch: 62
2023-01-04 00:55:07,843 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.36332560181617735, 'Total loss': 0.36332560181617735} | train loss {'Reaction outcome loss': 0.19610309598805464, 'Total loss': 0.19610309598805464}
2023-01-04 00:55:07,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:07,843 INFO:     Epoch: 63
2023-01-04 00:55:09,449 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37224456667900085, 'Total loss': 0.37224456667900085} | train loss {'Reaction outcome loss': 0.19555041144696483, 'Total loss': 0.19555041144696483}
2023-01-04 00:55:09,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:09,450 INFO:     Epoch: 64
2023-01-04 00:55:10,532 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38212184657653175, 'Total loss': 0.38212184657653175} | train loss {'Reaction outcome loss': 0.19236300471559356, 'Total loss': 0.19236300471559356}
2023-01-04 00:55:10,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:10,533 INFO:     Epoch: 65
2023-01-04 00:55:11,609 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3824702521165212, 'Total loss': 0.3824702521165212} | train loss {'Reaction outcome loss': 0.1906983870068106, 'Total loss': 0.1906983870068106}
2023-01-04 00:55:11,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:11,609 INFO:     Epoch: 66
2023-01-04 00:55:12,682 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37771768172581993, 'Total loss': 0.37771768172581993} | train loss {'Reaction outcome loss': 0.19238808374528005, 'Total loss': 0.19238808374528005}
2023-01-04 00:55:12,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:12,682 INFO:     Epoch: 67
2023-01-04 00:55:13,843 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.373222620288531, 'Total loss': 0.373222620288531} | train loss {'Reaction outcome loss': 0.1934968467356394, 'Total loss': 0.1934968467356394}
2023-01-04 00:55:13,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:13,845 INFO:     Epoch: 68
2023-01-04 00:55:15,441 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3626203527053197, 'Total loss': 0.3626203527053197} | train loss {'Reaction outcome loss': 0.1903874934935669, 'Total loss': 0.1903874934935669}
2023-01-04 00:55:15,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:15,442 INFO:     Epoch: 69
2023-01-04 00:55:17,056 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3773677269617716, 'Total loss': 0.3773677269617716} | train loss {'Reaction outcome loss': 0.19054216938768176, 'Total loss': 0.19054216938768176}
2023-01-04 00:55:17,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:17,056 INFO:     Epoch: 70
2023-01-04 00:55:18,689 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.36941279222567874, 'Total loss': 0.36941279222567874} | train loss {'Reaction outcome loss': 0.19651884796326488, 'Total loss': 0.19651884796326488}
2023-01-04 00:55:18,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:18,689 INFO:     Epoch: 71
2023-01-04 00:55:20,296 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.36409431298573813, 'Total loss': 0.36409431298573813} | train loss {'Reaction outcome loss': 0.18511582362344084, 'Total loss': 0.18511582362344084}
2023-01-04 00:55:20,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:20,298 INFO:     Epoch: 72
2023-01-04 00:55:21,868 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3880547821521759, 'Total loss': 0.3880547821521759} | train loss {'Reaction outcome loss': 0.1820159546207675, 'Total loss': 0.1820159546207675}
2023-01-04 00:55:21,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:21,869 INFO:     Epoch: 73
2023-01-04 00:55:23,459 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3733442395925522, 'Total loss': 0.3733442395925522} | train loss {'Reaction outcome loss': 0.18178401403871458, 'Total loss': 0.18178401403871458}
2023-01-04 00:55:23,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:23,459 INFO:     Epoch: 74
2023-01-04 00:55:25,056 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3682460164030393, 'Total loss': 0.3682460164030393} | train loss {'Reaction outcome loss': 0.18057449906537196, 'Total loss': 0.18057449906537196}
2023-01-04 00:55:25,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:25,056 INFO:     Epoch: 75
2023-01-04 00:55:26,675 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.38422703444957734, 'Total loss': 0.38422703444957734} | train loss {'Reaction outcome loss': 0.18145594781144345, 'Total loss': 0.18145594781144345}
2023-01-04 00:55:26,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:26,676 INFO:     Epoch: 76
2023-01-04 00:55:28,270 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4017684578895569, 'Total loss': 0.4017684578895569} | train loss {'Reaction outcome loss': 0.2045215741744724, 'Total loss': 0.2045215741744724}
2023-01-04 00:55:28,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:28,270 INFO:     Epoch: 77
2023-01-04 00:55:29,888 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.37192320575316745, 'Total loss': 0.37192320575316745} | train loss {'Reaction outcome loss': 0.18510242312660682, 'Total loss': 0.18510242312660682}
2023-01-04 00:55:29,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:29,888 INFO:     Epoch: 78
2023-01-04 00:55:31,479 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4018821765979131, 'Total loss': 0.4018821765979131} | train loss {'Reaction outcome loss': 0.18022648096362187, 'Total loss': 0.18022648096362187}
2023-01-04 00:55:31,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:31,481 INFO:     Epoch: 79
2023-01-04 00:55:33,079 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.38381496667861936, 'Total loss': 0.38381496667861936} | train loss {'Reaction outcome loss': 0.17792130562040678, 'Total loss': 0.17792130562040678}
2023-01-04 00:55:33,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:33,079 INFO:     Epoch: 80
2023-01-04 00:55:34,693 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3712860892216365, 'Total loss': 0.3712860892216365} | train loss {'Reaction outcome loss': 0.17623760607186367, 'Total loss': 0.17623760607186367}
2023-01-04 00:55:34,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:34,693 INFO:     Epoch: 81
2023-01-04 00:55:36,313 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3801175793011983, 'Total loss': 0.3801175793011983} | train loss {'Reaction outcome loss': 0.1777416262923337, 'Total loss': 0.1777416262923337}
2023-01-04 00:55:36,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:36,313 INFO:     Epoch: 82
2023-01-04 00:55:37,934 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4126467650135358, 'Total loss': 0.4126467650135358} | train loss {'Reaction outcome loss': 0.175649076935282, 'Total loss': 0.175649076935282}
2023-01-04 00:55:37,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:37,936 INFO:     Epoch: 83
2023-01-04 00:55:39,535 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.36991785367329916, 'Total loss': 0.36991785367329916} | train loss {'Reaction outcome loss': 0.17597476903608986, 'Total loss': 0.17597476903608986}
2023-01-04 00:55:39,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:39,535 INFO:     Epoch: 84
2023-01-04 00:55:41,116 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4026280721028646, 'Total loss': 0.4026280721028646} | train loss {'Reaction outcome loss': 0.17544938704214882, 'Total loss': 0.17544938704214882}
2023-01-04 00:55:41,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:41,117 INFO:     Epoch: 85
2023-01-04 00:55:42,711 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39314545343319574, 'Total loss': 0.39314545343319574} | train loss {'Reaction outcome loss': 0.18538090654065076, 'Total loss': 0.18538090654065076}
2023-01-04 00:55:42,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:42,712 INFO:     Epoch: 86
2023-01-04 00:55:44,305 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4097603271404902, 'Total loss': 0.4097603271404902} | train loss {'Reaction outcome loss': 0.1754372968718658, 'Total loss': 0.1754372968718658}
2023-01-04 00:55:44,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:44,306 INFO:     Epoch: 87
2023-01-04 00:55:45,902 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39596044818560283, 'Total loss': 0.39596044818560283} | train loss {'Reaction outcome loss': 0.17196957847235075, 'Total loss': 0.17196957847235075}
2023-01-04 00:55:45,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:45,902 INFO:     Epoch: 88
2023-01-04 00:55:47,520 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38499847849210106, 'Total loss': 0.38499847849210106} | train loss {'Reaction outcome loss': 0.16919018398702051, 'Total loss': 0.16919018398702051}
2023-01-04 00:55:47,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:47,521 INFO:     Epoch: 89
2023-01-04 00:55:49,107 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37976154883702595, 'Total loss': 0.37976154883702595} | train loss {'Reaction outcome loss': 0.17082802832265914, 'Total loss': 0.17082802832265914}
2023-01-04 00:55:49,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:49,109 INFO:     Epoch: 90
2023-01-04 00:55:50,696 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.386786550283432, 'Total loss': 0.386786550283432} | train loss {'Reaction outcome loss': 0.16814288105376982, 'Total loss': 0.16814288105376982}
2023-01-04 00:55:50,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:50,696 INFO:     Epoch: 91
2023-01-04 00:55:52,305 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4143206844727198, 'Total loss': 0.4143206844727198} | train loss {'Reaction outcome loss': 0.16878840501822592, 'Total loss': 0.16878840501822592}
2023-01-04 00:55:52,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:52,306 INFO:     Epoch: 92
2023-01-04 00:55:53,925 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43225645323594414, 'Total loss': 0.43225645323594414} | train loss {'Reaction outcome loss': 0.16952739695620223, 'Total loss': 0.16952739695620223}
2023-01-04 00:55:53,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:53,926 INFO:     Epoch: 93
2023-01-04 00:55:55,543 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.385272283355395, 'Total loss': 0.385272283355395} | train loss {'Reaction outcome loss': 0.16940757593325972, 'Total loss': 0.16940757593325972}
2023-01-04 00:55:55,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:55,543 INFO:     Epoch: 94
2023-01-04 00:55:57,168 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38009614249070484, 'Total loss': 0.38009614249070484} | train loss {'Reaction outcome loss': 0.1683422456511492, 'Total loss': 0.1683422456511492}
2023-01-04 00:55:57,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:57,170 INFO:     Epoch: 95
2023-01-04 00:55:58,745 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3682209094365438, 'Total loss': 0.3682209094365438} | train loss {'Reaction outcome loss': 0.16550541451118514, 'Total loss': 0.16550541451118514}
2023-01-04 00:55:58,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:55:58,745 INFO:     Epoch: 96
2023-01-04 00:56:00,335 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3885204792022705, 'Total loss': 0.3885204792022705} | train loss {'Reaction outcome loss': 0.16618231870149652, 'Total loss': 0.16618231870149652}
2023-01-04 00:56:00,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:00,336 INFO:     Epoch: 97
2023-01-04 00:56:01,926 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4000082532564799, 'Total loss': 0.4000082532564799} | train loss {'Reaction outcome loss': 0.1657094203915419, 'Total loss': 0.1657094203915419}
2023-01-04 00:56:01,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:01,926 INFO:     Epoch: 98
2023-01-04 00:56:03,516 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3983774721622467, 'Total loss': 0.3983774721622467} | train loss {'Reaction outcome loss': 0.1632591541080425, 'Total loss': 0.1632591541080425}
2023-01-04 00:56:03,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:03,518 INFO:     Epoch: 99
2023-01-04 00:56:05,108 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4037496089935303, 'Total loss': 0.4037496089935303} | train loss {'Reaction outcome loss': 0.16576789272896375, 'Total loss': 0.16576789272896375}
2023-01-04 00:56:05,108 INFO:     Best model found after epoch 48 of 100.
2023-01-04 00:56:05,108 INFO:   Done with stage: TRAINING
2023-01-04 00:56:05,108 INFO:   Starting stage: EVALUATION
2023-01-04 00:56:05,239 INFO:   Done with stage: EVALUATION
2023-01-04 00:56:05,239 INFO:   Leaving out SEQ value Fold_5
2023-01-04 00:56:05,251 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 00:56:05,252 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:56:05,906 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:56:05,906 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:56:05,976 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:56:05,976 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:56:05,976 INFO:     No hyperparam tuning for this model
2023-01-04 00:56:05,976 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:56:05,976 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:56:05,977 INFO:     None feature selector for col prot
2023-01-04 00:56:05,977 INFO:     None feature selector for col prot
2023-01-04 00:56:05,977 INFO:     None feature selector for col prot
2023-01-04 00:56:05,978 INFO:     None feature selector for col chem
2023-01-04 00:56:05,978 INFO:     None feature selector for col chem
2023-01-04 00:56:05,978 INFO:     None feature selector for col chem
2023-01-04 00:56:05,978 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:56:05,978 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:56:05,979 INFO:     Number of params in model 70141
2023-01-04 00:56:05,983 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:56:05,983 INFO:   Starting stage: TRAINING
2023-01-04 00:56:06,027 INFO:     Val loss before train {'Reaction outcome loss': 0.9816461165746053, 'Total loss': 0.9816461165746053}
2023-01-04 00:56:06,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:06,027 INFO:     Epoch: 0
2023-01-04 00:56:07,589 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7082323849201202, 'Total loss': 0.7082323849201202} | train loss {'Reaction outcome loss': 0.8680081980815832, 'Total loss': 0.8680081980815832}
2023-01-04 00:56:07,590 INFO:     Found new best model at epoch 0
2023-01-04 00:56:07,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:07,590 INFO:     Epoch: 1
2023-01-04 00:56:09,191 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.601877111196518, 'Total loss': 0.601877111196518} | train loss {'Reaction outcome loss': 0.6042117970945833, 'Total loss': 0.6042117970945833}
2023-01-04 00:56:09,191 INFO:     Found new best model at epoch 1
2023-01-04 00:56:09,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:09,192 INFO:     Epoch: 2
2023-01-04 00:56:10,805 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.559734445810318, 'Total loss': 0.559734445810318} | train loss {'Reaction outcome loss': 0.5308839065981084, 'Total loss': 0.5308839065981084}
2023-01-04 00:56:10,806 INFO:     Found new best model at epoch 2
2023-01-04 00:56:10,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:10,807 INFO:     Epoch: 3
2023-01-04 00:56:12,403 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5235678195953369, 'Total loss': 0.5235678195953369} | train loss {'Reaction outcome loss': 0.4949531878034274, 'Total loss': 0.4949531878034274}
2023-01-04 00:56:12,403 INFO:     Found new best model at epoch 3
2023-01-04 00:56:12,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:12,404 INFO:     Epoch: 4
2023-01-04 00:56:13,993 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5067099312941233, 'Total loss': 0.5067099312941233} | train loss {'Reaction outcome loss': 0.4748609690670518, 'Total loss': 0.4748609690670518}
2023-01-04 00:56:13,994 INFO:     Found new best model at epoch 4
2023-01-04 00:56:13,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:13,995 INFO:     Epoch: 5
2023-01-04 00:56:15,581 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5025484343369802, 'Total loss': 0.5025484343369802} | train loss {'Reaction outcome loss': 0.44741097078835795, 'Total loss': 0.44741097078835795}
2023-01-04 00:56:15,581 INFO:     Found new best model at epoch 5
2023-01-04 00:56:15,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:15,582 INFO:     Epoch: 6
2023-01-04 00:56:17,166 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.485600072145462, 'Total loss': 0.485600072145462} | train loss {'Reaction outcome loss': 0.4303892081606782, 'Total loss': 0.4303892081606782}
2023-01-04 00:56:17,166 INFO:     Found new best model at epoch 6
2023-01-04 00:56:17,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:17,167 INFO:     Epoch: 7
2023-01-04 00:56:18,758 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4864509085814158, 'Total loss': 0.4864509085814158} | train loss {'Reaction outcome loss': 0.417198001238369, 'Total loss': 0.417198001238369}
2023-01-04 00:56:18,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:18,759 INFO:     Epoch: 8
2023-01-04 00:56:20,382 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4789978742599487, 'Total loss': 0.4789978742599487} | train loss {'Reaction outcome loss': 0.4057718741343073, 'Total loss': 0.4057718741343073}
2023-01-04 00:56:20,382 INFO:     Found new best model at epoch 8
2023-01-04 00:56:20,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:20,383 INFO:     Epoch: 9
2023-01-04 00:56:22,000 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44888426661491393, 'Total loss': 0.44888426661491393} | train loss {'Reaction outcome loss': 0.4009651683702849, 'Total loss': 0.4009651683702849}
2023-01-04 00:56:22,001 INFO:     Found new best model at epoch 9
2023-01-04 00:56:22,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:22,001 INFO:     Epoch: 10
2023-01-04 00:56:23,586 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44332332412401837, 'Total loss': 0.44332332412401837} | train loss {'Reaction outcome loss': 0.39306556943642057, 'Total loss': 0.39306556943642057}
2023-01-04 00:56:23,587 INFO:     Found new best model at epoch 10
2023-01-04 00:56:23,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:23,588 INFO:     Epoch: 11
2023-01-04 00:56:25,162 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4443014224370321, 'Total loss': 0.4443014224370321} | train loss {'Reaction outcome loss': 0.3893952125116535, 'Total loss': 0.3893952125116535}
2023-01-04 00:56:25,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:25,163 INFO:     Epoch: 12
2023-01-04 00:56:26,770 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44221898516019187, 'Total loss': 0.44221898516019187} | train loss {'Reaction outcome loss': 0.37735936080739985, 'Total loss': 0.37735936080739985}
2023-01-04 00:56:26,770 INFO:     Found new best model at epoch 12
2023-01-04 00:56:26,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:26,771 INFO:     Epoch: 13
2023-01-04 00:56:28,396 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4514062503973643, 'Total loss': 0.4514062503973643} | train loss {'Reaction outcome loss': 0.36619692832987377, 'Total loss': 0.36619692832987377}
2023-01-04 00:56:28,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:28,397 INFO:     Epoch: 14
2023-01-04 00:56:30,031 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.434564205010732, 'Total loss': 0.434564205010732} | train loss {'Reaction outcome loss': 0.3591022609979373, 'Total loss': 0.3591022609979373}
2023-01-04 00:56:30,032 INFO:     Found new best model at epoch 14
2023-01-04 00:56:30,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:30,032 INFO:     Epoch: 15
2023-01-04 00:56:31,675 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4399484614531199, 'Total loss': 0.4399484614531199} | train loss {'Reaction outcome loss': 0.3519444369598784, 'Total loss': 0.3519444369598784}
2023-01-04 00:56:31,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:31,675 INFO:     Epoch: 16
2023-01-04 00:56:33,275 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4290511429309845, 'Total loss': 0.4290511429309845} | train loss {'Reaction outcome loss': 0.3477001848590115, 'Total loss': 0.3477001848590115}
2023-01-04 00:56:33,275 INFO:     Found new best model at epoch 16
2023-01-04 00:56:33,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:33,276 INFO:     Epoch: 17
2023-01-04 00:56:34,849 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4350011746088664, 'Total loss': 0.4350011746088664} | train loss {'Reaction outcome loss': 0.3415399073906567, 'Total loss': 0.3415399073906567}
2023-01-04 00:56:34,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:34,851 INFO:     Epoch: 18
2023-01-04 00:56:36,450 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4101142555475235, 'Total loss': 0.4101142555475235} | train loss {'Reaction outcome loss': 0.3387114047680212, 'Total loss': 0.3387114047680212}
2023-01-04 00:56:36,451 INFO:     Found new best model at epoch 18
2023-01-04 00:56:36,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:36,451 INFO:     Epoch: 19
2023-01-04 00:56:38,056 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4076388825972875, 'Total loss': 0.4076388825972875} | train loss {'Reaction outcome loss': 0.33401549577820994, 'Total loss': 0.33401549577820994}
2023-01-04 00:56:38,056 INFO:     Found new best model at epoch 19
2023-01-04 00:56:38,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:38,057 INFO:     Epoch: 20
2023-01-04 00:56:39,671 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41411772270997366, 'Total loss': 0.41411772270997366} | train loss {'Reaction outcome loss': 0.32675677386746893, 'Total loss': 0.32675677386746893}
2023-01-04 00:56:39,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:39,671 INFO:     Epoch: 21
2023-01-04 00:56:41,288 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.409661465883255, 'Total loss': 0.409661465883255} | train loss {'Reaction outcome loss': 0.32266457203113, 'Total loss': 0.32266457203113}
2023-01-04 00:56:41,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:41,289 INFO:     Epoch: 22
2023-01-04 00:56:42,887 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3934152533610662, 'Total loss': 0.3934152533610662} | train loss {'Reaction outcome loss': 0.314029212926339, 'Total loss': 0.314029212926339}
2023-01-04 00:56:42,887 INFO:     Found new best model at epoch 22
2023-01-04 00:56:42,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:42,888 INFO:     Epoch: 23
2023-01-04 00:56:44,465 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4066484053929647, 'Total loss': 0.4066484053929647} | train loss {'Reaction outcome loss': 0.3114146679248391, 'Total loss': 0.3114146679248391}
2023-01-04 00:56:44,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:44,465 INFO:     Epoch: 24
2023-01-04 00:56:46,090 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4075334976116816, 'Total loss': 0.4075334976116816} | train loss {'Reaction outcome loss': 0.3073107126452353, 'Total loss': 0.3073107126452353}
2023-01-04 00:56:46,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:46,090 INFO:     Epoch: 25
2023-01-04 00:56:47,709 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3998761256535848, 'Total loss': 0.3998761256535848} | train loss {'Reaction outcome loss': 0.3045291305123997, 'Total loss': 0.3045291305123997}
2023-01-04 00:56:47,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:47,709 INFO:     Epoch: 26
2023-01-04 00:56:49,308 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39583484729131063, 'Total loss': 0.39583484729131063} | train loss {'Reaction outcome loss': 0.2973133887671134, 'Total loss': 0.2973133887671134}
2023-01-04 00:56:49,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:49,308 INFO:     Epoch: 27
2023-01-04 00:56:50,931 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40502473910649617, 'Total loss': 0.40502473910649617} | train loss {'Reaction outcome loss': 0.29448280137359584, 'Total loss': 0.29448280137359584}
2023-01-04 00:56:50,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:50,932 INFO:     Epoch: 28
2023-01-04 00:56:52,509 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4079750210046768, 'Total loss': 0.4079750210046768} | train loss {'Reaction outcome loss': 0.29109463910930755, 'Total loss': 0.29109463910930755}
2023-01-04 00:56:52,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:52,509 INFO:     Epoch: 29
2023-01-04 00:56:54,099 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38568282028039297, 'Total loss': 0.38568282028039297} | train loss {'Reaction outcome loss': 0.2879045674116756, 'Total loss': 0.2879045674116756}
2023-01-04 00:56:54,099 INFO:     Found new best model at epoch 29
2023-01-04 00:56:54,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:54,100 INFO:     Epoch: 30
2023-01-04 00:56:55,691 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39837192595005033, 'Total loss': 0.39837192595005033} | train loss {'Reaction outcome loss': 0.2826148095900071, 'Total loss': 0.2826148095900071}
2023-01-04 00:56:55,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:55,692 INFO:     Epoch: 31
2023-01-04 00:56:57,304 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4153871138890584, 'Total loss': 0.4153871138890584} | train loss {'Reaction outcome loss': 0.2785806968079313, 'Total loss': 0.2785806968079313}
2023-01-04 00:56:57,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:57,304 INFO:     Epoch: 32
2023-01-04 00:56:58,925 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40903792579968773, 'Total loss': 0.40903792579968773} | train loss {'Reaction outcome loss': 0.27782066287877766, 'Total loss': 0.27782066287877766}
2023-01-04 00:56:58,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:56:58,925 INFO:     Epoch: 33
2023-01-04 00:57:00,526 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4019309878349304, 'Total loss': 0.4019309878349304} | train loss {'Reaction outcome loss': 0.2743239251194873, 'Total loss': 0.2743239251194873}
2023-01-04 00:57:00,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:00,526 INFO:     Epoch: 34
2023-01-04 00:57:02,118 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.37827734649181366, 'Total loss': 0.37827734649181366} | train loss {'Reaction outcome loss': 0.2774728127903696, 'Total loss': 0.2774728127903696}
2023-01-04 00:57:02,118 INFO:     Found new best model at epoch 34
2023-01-04 00:57:02,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:02,119 INFO:     Epoch: 35
2023-01-04 00:57:03,709 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39934736092885337, 'Total loss': 0.39934736092885337} | train loss {'Reaction outcome loss': 0.28181166605012864, 'Total loss': 0.28181166605012864}
2023-01-04 00:57:03,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:03,709 INFO:     Epoch: 36
2023-01-04 00:57:05,315 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39569175243377686, 'Total loss': 0.39569175243377686} | train loss {'Reaction outcome loss': 0.26574458496854303, 'Total loss': 0.26574458496854303}
2023-01-04 00:57:05,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:05,317 INFO:     Epoch: 37
2023-01-04 00:57:06,935 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3787687828143438, 'Total loss': 0.3787687828143438} | train loss {'Reaction outcome loss': 0.25996716886114934, 'Total loss': 0.25996716886114934}
2023-01-04 00:57:06,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:06,936 INFO:     Epoch: 38
2023-01-04 00:57:08,531 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3943715155124664, 'Total loss': 0.3943715155124664} | train loss {'Reaction outcome loss': 0.25839177165450394, 'Total loss': 0.25839177165450394}
2023-01-04 00:57:08,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:08,531 INFO:     Epoch: 39
2023-01-04 00:57:10,116 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4346534589926402, 'Total loss': 0.4346534589926402} | train loss {'Reaction outcome loss': 0.2557547573452357, 'Total loss': 0.2557547573452357}
2023-01-04 00:57:10,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:10,116 INFO:     Epoch: 40
2023-01-04 00:57:11,713 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3885030517975489, 'Total loss': 0.3885030517975489} | train loss {'Reaction outcome loss': 0.25213966227618195, 'Total loss': 0.25213966227618195}
2023-01-04 00:57:11,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:11,714 INFO:     Epoch: 41
2023-01-04 00:57:13,332 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3856010337670644, 'Total loss': 0.3856010337670644} | train loss {'Reaction outcome loss': 0.2487597990084264, 'Total loss': 0.2487597990084264}
2023-01-04 00:57:13,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:13,333 INFO:     Epoch: 42
2023-01-04 00:57:14,954 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41555215915044147, 'Total loss': 0.41555215915044147} | train loss {'Reaction outcome loss': 0.252348766743165, 'Total loss': 0.252348766743165}
2023-01-04 00:57:14,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:14,954 INFO:     Epoch: 43
2023-01-04 00:57:16,555 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4097818990548452, 'Total loss': 0.4097818990548452} | train loss {'Reaction outcome loss': 0.24726601402052556, 'Total loss': 0.24726601402052556}
2023-01-04 00:57:16,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:16,555 INFO:     Epoch: 44
2023-01-04 00:57:18,179 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3833766875167688, 'Total loss': 0.3833766875167688} | train loss {'Reaction outcome loss': 0.2436962901147258, 'Total loss': 0.2436962901147258}
2023-01-04 00:57:18,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:18,179 INFO:     Epoch: 45
2023-01-04 00:57:19,774 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.37669430176417035, 'Total loss': 0.37669430176417035} | train loss {'Reaction outcome loss': 0.23972850121646078, 'Total loss': 0.23972850121646078}
2023-01-04 00:57:19,774 INFO:     Found new best model at epoch 45
2023-01-04 00:57:19,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:19,775 INFO:     Epoch: 46
2023-01-04 00:57:21,387 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4012967805067698, 'Total loss': 0.4012967805067698} | train loss {'Reaction outcome loss': 0.24135441372198038, 'Total loss': 0.24135441372198038}
2023-01-04 00:57:21,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:21,387 INFO:     Epoch: 47
2023-01-04 00:57:22,977 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41169050633907317, 'Total loss': 0.41169050633907317} | train loss {'Reaction outcome loss': 0.2383579787582267, 'Total loss': 0.2383579787582267}
2023-01-04 00:57:22,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:22,977 INFO:     Epoch: 48
2023-01-04 00:57:24,569 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3976344088713328, 'Total loss': 0.3976344088713328} | train loss {'Reaction outcome loss': 0.23394136028229326, 'Total loss': 0.23394136028229326}
2023-01-04 00:57:24,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:24,570 INFO:     Epoch: 49
2023-01-04 00:57:26,162 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3840424050887426, 'Total loss': 0.3840424050887426} | train loss {'Reaction outcome loss': 0.23235390628468705, 'Total loss': 0.23235390628468705}
2023-01-04 00:57:26,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:26,164 INFO:     Epoch: 50
2023-01-04 00:57:27,764 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3905619223912557, 'Total loss': 0.3905619223912557} | train loss {'Reaction outcome loss': 0.23160601231822933, 'Total loss': 0.23160601231822933}
2023-01-04 00:57:27,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:27,764 INFO:     Epoch: 51
2023-01-04 00:57:29,358 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4072049597899119, 'Total loss': 0.4072049597899119} | train loss {'Reaction outcome loss': 0.22758660209871343, 'Total loss': 0.22758660209871343}
2023-01-04 00:57:29,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:29,358 INFO:     Epoch: 52
2023-01-04 00:57:30,980 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3875804086526235, 'Total loss': 0.3875804086526235} | train loss {'Reaction outcome loss': 0.22655888696950252, 'Total loss': 0.22655888696950252}
2023-01-04 00:57:30,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:30,980 INFO:     Epoch: 53
2023-01-04 00:57:32,577 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4092782696088155, 'Total loss': 0.4092782696088155} | train loss {'Reaction outcome loss': 0.22510912801215824, 'Total loss': 0.22510912801215824}
2023-01-04 00:57:32,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:32,578 INFO:     Epoch: 54
2023-01-04 00:57:34,182 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4025281846523285, 'Total loss': 0.4025281846523285} | train loss {'Reaction outcome loss': 0.22266860415808312, 'Total loss': 0.22266860415808312}
2023-01-04 00:57:34,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:34,182 INFO:     Epoch: 55
2023-01-04 00:57:35,808 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38891169627507527, 'Total loss': 0.38891169627507527} | train loss {'Reaction outcome loss': 0.2225419552321883, 'Total loss': 0.2225419552321883}
2023-01-04 00:57:35,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:35,808 INFO:     Epoch: 56
2023-01-04 00:57:37,397 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4059350381294886, 'Total loss': 0.4059350381294886} | train loss {'Reaction outcome loss': 0.22189854123238203, 'Total loss': 0.22189854123238203}
2023-01-04 00:57:37,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:37,397 INFO:     Epoch: 57
2023-01-04 00:57:39,010 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40029941499233246, 'Total loss': 0.40029941499233246} | train loss {'Reaction outcome loss': 0.21790614915147855, 'Total loss': 0.21790614915147855}
2023-01-04 00:57:39,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:39,010 INFO:     Epoch: 58
2023-01-04 00:57:40,617 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39935624599456787, 'Total loss': 0.39935624599456787} | train loss {'Reaction outcome loss': 0.2176232282197732, 'Total loss': 0.2176232282197732}
2023-01-04 00:57:40,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:40,617 INFO:     Epoch: 59
2023-01-04 00:57:42,236 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3882120579481125, 'Total loss': 0.3882120579481125} | train loss {'Reaction outcome loss': 0.21563542463674978, 'Total loss': 0.21563542463674978}
2023-01-04 00:57:42,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:42,236 INFO:     Epoch: 60
2023-01-04 00:57:43,841 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39142209887504575, 'Total loss': 0.39142209887504575} | train loss {'Reaction outcome loss': 0.21538499988399554, 'Total loss': 0.21538499988399554}
2023-01-04 00:57:43,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:43,841 INFO:     Epoch: 61
2023-01-04 00:57:45,445 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41708386143048604, 'Total loss': 0.41708386143048604} | train loss {'Reaction outcome loss': 0.2160994845604443, 'Total loss': 0.2160994845604443}
2023-01-04 00:57:45,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:45,446 INFO:     Epoch: 62
2023-01-04 00:57:47,041 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4260700225830078, 'Total loss': 0.4260700225830078} | train loss {'Reaction outcome loss': 0.2118326879740841, 'Total loss': 0.2118326879740841}
2023-01-04 00:57:47,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:47,042 INFO:     Epoch: 63
2023-01-04 00:57:48,661 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39149107138315836, 'Total loss': 0.39149107138315836} | train loss {'Reaction outcome loss': 0.20913202797933278, 'Total loss': 0.20913202797933278}
2023-01-04 00:57:48,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:48,661 INFO:     Epoch: 64
2023-01-04 00:57:50,265 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3979884659250577, 'Total loss': 0.3979884659250577} | train loss {'Reaction outcome loss': 0.2077033485731353, 'Total loss': 0.2077033485731353}
2023-01-04 00:57:50,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:50,265 INFO:     Epoch: 65
2023-01-04 00:57:51,880 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40992850561936695, 'Total loss': 0.40992850561936695} | train loss {'Reaction outcome loss': 0.20576476391769297, 'Total loss': 0.20576476391769297}
2023-01-04 00:57:51,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:51,880 INFO:     Epoch: 66
2023-01-04 00:57:53,489 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3856783628463745, 'Total loss': 0.3856783628463745} | train loss {'Reaction outcome loss': 0.20711664553137793, 'Total loss': 0.20711664553137793}
2023-01-04 00:57:53,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:53,490 INFO:     Epoch: 67
2023-01-04 00:57:55,085 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3912873854239782, 'Total loss': 0.3912873854239782} | train loss {'Reaction outcome loss': 0.20336346000355357, 'Total loss': 0.20336346000355357}
2023-01-04 00:57:55,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:55,085 INFO:     Epoch: 68
2023-01-04 00:57:56,669 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3796037048101425, 'Total loss': 0.3796037048101425} | train loss {'Reaction outcome loss': 0.20047658246450895, 'Total loss': 0.20047658246450895}
2023-01-04 00:57:56,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:56,670 INFO:     Epoch: 69
2023-01-04 00:57:58,268 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.38663441240787505, 'Total loss': 0.38663441240787505} | train loss {'Reaction outcome loss': 0.2025739201951934, 'Total loss': 0.2025739201951934}
2023-01-04 00:57:58,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:58,269 INFO:     Epoch: 70
2023-01-04 00:57:59,850 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40056159496307375, 'Total loss': 0.40056159496307375} | train loss {'Reaction outcome loss': 0.2001711345552737, 'Total loss': 0.2001711345552737}
2023-01-04 00:57:59,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:57:59,850 INFO:     Epoch: 71
2023-01-04 00:58:01,469 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3946935882170995, 'Total loss': 0.3946935882170995} | train loss {'Reaction outcome loss': 0.2009431541255385, 'Total loss': 0.2009431541255385}
2023-01-04 00:58:01,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:01,470 INFO:     Epoch: 72
2023-01-04 00:58:03,046 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38973622520764667, 'Total loss': 0.38973622520764667} | train loss {'Reaction outcome loss': 0.19803462167813754, 'Total loss': 0.19803462167813754}
2023-01-04 00:58:03,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:03,047 INFO:     Epoch: 73
2023-01-04 00:58:04,607 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38794705594579376, 'Total loss': 0.38794705594579376} | train loss {'Reaction outcome loss': 0.2003252608836561, 'Total loss': 0.2003252608836561}
2023-01-04 00:58:04,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:04,608 INFO:     Epoch: 74
2023-01-04 00:58:06,202 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40711522897084557, 'Total loss': 0.40711522897084557} | train loss {'Reaction outcome loss': 0.21028231283022594, 'Total loss': 0.21028231283022594}
2023-01-04 00:58:06,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:06,202 INFO:     Epoch: 75
2023-01-04 00:58:07,797 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.402083154519399, 'Total loss': 0.402083154519399} | train loss {'Reaction outcome loss': 0.19499976355185988, 'Total loss': 0.19499976355185988}
2023-01-04 00:58:07,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:07,797 INFO:     Epoch: 76
2023-01-04 00:58:09,393 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37867184579372404, 'Total loss': 0.37867184579372404} | train loss {'Reaction outcome loss': 0.19246801785640485, 'Total loss': 0.19246801785640485}
2023-01-04 00:58:09,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:09,394 INFO:     Epoch: 77
2023-01-04 00:58:10,989 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3919439931710561, 'Total loss': 0.3919439931710561} | train loss {'Reaction outcome loss': 0.19061980243988227, 'Total loss': 0.19061980243988227}
2023-01-04 00:58:10,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:10,989 INFO:     Epoch: 78
2023-01-04 00:58:12,560 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39992546538511914, 'Total loss': 0.39992546538511914} | train loss {'Reaction outcome loss': 0.1916136971659675, 'Total loss': 0.1916136971659675}
2023-01-04 00:58:12,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:12,560 INFO:     Epoch: 79
2023-01-04 00:58:14,145 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39851030309995017, 'Total loss': 0.39851030309995017} | train loss {'Reaction outcome loss': 0.19376656222226776, 'Total loss': 0.19376656222226776}
2023-01-04 00:58:14,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:14,145 INFO:     Epoch: 80
2023-01-04 00:58:15,762 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4016150544087092, 'Total loss': 0.4016150544087092} | train loss {'Reaction outcome loss': 0.18920700127626702, 'Total loss': 0.18920700127626702}
2023-01-04 00:58:15,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:15,763 INFO:     Epoch: 81
2023-01-04 00:58:17,388 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.390082478026549, 'Total loss': 0.390082478026549} | train loss {'Reaction outcome loss': 0.19839852166942495, 'Total loss': 0.19839852166942495}
2023-01-04 00:58:17,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:17,389 INFO:     Epoch: 82
2023-01-04 00:58:19,008 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40441969434420266, 'Total loss': 0.40441969434420266} | train loss {'Reaction outcome loss': 0.22577324477290106, 'Total loss': 0.22577324477290106}
2023-01-04 00:58:19,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:19,009 INFO:     Epoch: 83
2023-01-04 00:58:20,628 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41409669319788617, 'Total loss': 0.41409669319788617} | train loss {'Reaction outcome loss': 0.1919635389998987, 'Total loss': 0.1919635389998987}
2023-01-04 00:58:20,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:20,628 INFO:     Epoch: 84
2023-01-04 00:58:22,218 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40677191217740377, 'Total loss': 0.40677191217740377} | train loss {'Reaction outcome loss': 0.19224184391213636, 'Total loss': 0.19224184391213636}
2023-01-04 00:58:22,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:22,218 INFO:     Epoch: 85
2023-01-04 00:58:23,823 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41016738216082255, 'Total loss': 0.41016738216082255} | train loss {'Reaction outcome loss': 0.18436767224238135, 'Total loss': 0.18436767224238135}
2023-01-04 00:58:23,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:23,823 INFO:     Epoch: 86
2023-01-04 00:58:25,441 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41250691066185635, 'Total loss': 0.41250691066185635} | train loss {'Reaction outcome loss': 0.18291726724761986, 'Total loss': 0.18291726724761986}
2023-01-04 00:58:25,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:25,441 INFO:     Epoch: 87
2023-01-04 00:58:27,064 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3884386320908864, 'Total loss': 0.3884386320908864} | train loss {'Reaction outcome loss': 0.1828709442462254, 'Total loss': 0.1828709442462254}
2023-01-04 00:58:27,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:27,065 INFO:     Epoch: 88
2023-01-04 00:58:28,686 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3850139558315277, 'Total loss': 0.3850139558315277} | train loss {'Reaction outcome loss': 0.18134062846935273, 'Total loss': 0.18134062846935273}
2023-01-04 00:58:28,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:28,686 INFO:     Epoch: 89
2023-01-04 00:58:30,286 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4000300019979477, 'Total loss': 0.4000300019979477} | train loss {'Reaction outcome loss': 0.18092480801894545, 'Total loss': 0.18092480801894545}
2023-01-04 00:58:30,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:30,286 INFO:     Epoch: 90
2023-01-04 00:58:31,874 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3845639616250992, 'Total loss': 0.3845639616250992} | train loss {'Reaction outcome loss': 0.17886985583396198, 'Total loss': 0.17886985583396198}
2023-01-04 00:58:31,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:31,874 INFO:     Epoch: 91
2023-01-04 00:58:33,461 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39219994644323986, 'Total loss': 0.39219994644323986} | train loss {'Reaction outcome loss': 0.18041291478785107, 'Total loss': 0.18041291478785107}
2023-01-04 00:58:33,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:33,463 INFO:     Epoch: 92
2023-01-04 00:58:35,051 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4074381818373998, 'Total loss': 0.4074381818373998} | train loss {'Reaction outcome loss': 0.18050855807571983, 'Total loss': 0.18050855807571983}
2023-01-04 00:58:35,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:35,051 INFO:     Epoch: 93
2023-01-04 00:58:36,639 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38746904929478965, 'Total loss': 0.38746904929478965} | train loss {'Reaction outcome loss': 0.17625780448239917, 'Total loss': 0.17625780448239917}
2023-01-04 00:58:36,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:36,640 INFO:     Epoch: 94
2023-01-04 00:58:38,231 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3831158459186554, 'Total loss': 0.3831158459186554} | train loss {'Reaction outcome loss': 0.17952638728699336, 'Total loss': 0.17952638728699336}
2023-01-04 00:58:38,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:38,231 INFO:     Epoch: 95
2023-01-04 00:58:39,809 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38842257062594093, 'Total loss': 0.38842257062594093} | train loss {'Reaction outcome loss': 0.17748932695637146, 'Total loss': 0.17748932695637146}
2023-01-04 00:58:39,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:39,810 INFO:     Epoch: 96
2023-01-04 00:58:41,393 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3961685429016749, 'Total loss': 0.3961685429016749} | train loss {'Reaction outcome loss': 0.18306198955511005, 'Total loss': 0.18306198955511005}
2023-01-04 00:58:41,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:41,393 INFO:     Epoch: 97
2023-01-04 00:58:42,988 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3886425794102252, 'Total loss': 0.3886425794102252} | train loss {'Reaction outcome loss': 0.1769047926173316, 'Total loss': 0.1769047926173316}
2023-01-04 00:58:42,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:42,988 INFO:     Epoch: 98
2023-01-04 00:58:44,577 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4049743493398031, 'Total loss': 0.4049743493398031} | train loss {'Reaction outcome loss': 0.1755309583428586, 'Total loss': 0.1755309583428586}
2023-01-04 00:58:44,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:44,578 INFO:     Epoch: 99
2023-01-04 00:58:46,206 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3968464136123657, 'Total loss': 0.3968464136123657} | train loss {'Reaction outcome loss': 0.17305644036378656, 'Total loss': 0.17305644036378656}
2023-01-04 00:58:46,206 INFO:     Best model found after epoch 46 of 100.
2023-01-04 00:58:46,207 INFO:   Done with stage: TRAINING
2023-01-04 00:58:46,207 INFO:   Starting stage: EVALUATION
2023-01-04 00:58:46,339 INFO:   Done with stage: EVALUATION
2023-01-04 00:58:46,339 INFO:   Leaving out SEQ value Fold_6
2023-01-04 00:58:46,352 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 00:58:46,352 INFO:   Starting stage: FEATURE SCALING
2023-01-04 00:58:47,008 INFO:   Done with stage: FEATURE SCALING
2023-01-04 00:58:47,008 INFO:   Starting stage: SCALING TARGETS
2023-01-04 00:58:47,079 INFO:   Done with stage: SCALING TARGETS
2023-01-04 00:58:47,079 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:58:47,079 INFO:     No hyperparam tuning for this model
2023-01-04 00:58:47,079 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 00:58:47,079 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 00:58:47,080 INFO:     None feature selector for col prot
2023-01-04 00:58:47,080 INFO:     None feature selector for col prot
2023-01-04 00:58:47,080 INFO:     None feature selector for col prot
2023-01-04 00:58:47,081 INFO:     None feature selector for col chem
2023-01-04 00:58:47,081 INFO:     None feature selector for col chem
2023-01-04 00:58:47,081 INFO:     None feature selector for col chem
2023-01-04 00:58:47,081 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 00:58:47,081 INFO:   Starting stage: BUILD MODEL
2023-01-04 00:58:47,082 INFO:     Number of params in model 70141
2023-01-04 00:58:47,086 INFO:   Done with stage: BUILD MODEL
2023-01-04 00:58:47,086 INFO:   Starting stage: TRAINING
2023-01-04 00:58:47,131 INFO:     Val loss before train {'Reaction outcome loss': 1.0090131680170695, 'Total loss': 1.0090131680170695}
2023-01-04 00:58:47,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:47,131 INFO:     Epoch: 0
2023-01-04 00:58:48,715 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7163322329521179, 'Total loss': 0.7163322329521179} | train loss {'Reaction outcome loss': 0.8646791469359744, 'Total loss': 0.8646791469359744}
2023-01-04 00:58:48,715 INFO:     Found new best model at epoch 0
2023-01-04 00:58:48,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:48,716 INFO:     Epoch: 1
2023-01-04 00:58:50,298 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5856437007586162, 'Total loss': 0.5856437007586162} | train loss {'Reaction outcome loss': 0.6466396063890146, 'Total loss': 0.6466396063890146}
2023-01-04 00:58:50,298 INFO:     Found new best model at epoch 1
2023-01-04 00:58:50,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:50,299 INFO:     Epoch: 2
2023-01-04 00:58:51,958 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.53577188650767, 'Total loss': 0.53577188650767} | train loss {'Reaction outcome loss': 0.5561314411326379, 'Total loss': 0.5561314411326379}
2023-01-04 00:58:51,959 INFO:     Found new best model at epoch 2
2023-01-04 00:58:51,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:51,960 INFO:     Epoch: 3
2023-01-04 00:58:53,631 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48259958227475486, 'Total loss': 0.48259958227475486} | train loss {'Reaction outcome loss': 0.5124464589778496, 'Total loss': 0.5124464589778496}
2023-01-04 00:58:53,631 INFO:     Found new best model at epoch 3
2023-01-04 00:58:53,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:53,632 INFO:     Epoch: 4
2023-01-04 00:58:55,301 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4773055930932363, 'Total loss': 0.4773055930932363} | train loss {'Reaction outcome loss': 0.4811145865722843, 'Total loss': 0.4811145865722843}
2023-01-04 00:58:55,301 INFO:     Found new best model at epoch 4
2023-01-04 00:58:55,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:55,302 INFO:     Epoch: 5
2023-01-04 00:58:56,940 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4524005005757014, 'Total loss': 0.4524005005757014} | train loss {'Reaction outcome loss': 0.460281032673252, 'Total loss': 0.460281032673252}
2023-01-04 00:58:56,940 INFO:     Found new best model at epoch 5
2023-01-04 00:58:56,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:56,941 INFO:     Epoch: 6
2023-01-04 00:58:58,524 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.445572163661321, 'Total loss': 0.445572163661321} | train loss {'Reaction outcome loss': 0.4399454556810467, 'Total loss': 0.4399454556810467}
2023-01-04 00:58:58,524 INFO:     Found new best model at epoch 6
2023-01-04 00:58:58,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:58:58,525 INFO:     Epoch: 7
2023-01-04 00:59:00,117 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4317103346188863, 'Total loss': 0.4317103346188863} | train loss {'Reaction outcome loss': 0.42636255677050783, 'Total loss': 0.42636255677050783}
2023-01-04 00:59:00,117 INFO:     Found new best model at epoch 7
2023-01-04 00:59:00,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:00,118 INFO:     Epoch: 8
2023-01-04 00:59:01,708 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.455035874247551, 'Total loss': 0.455035874247551} | train loss {'Reaction outcome loss': 0.4202283022628314, 'Total loss': 0.4202283022628314}
2023-01-04 00:59:01,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:01,708 INFO:     Epoch: 9
2023-01-04 00:59:03,334 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.416056760152181, 'Total loss': 0.416056760152181} | train loss {'Reaction outcome loss': 0.40667593702707655, 'Total loss': 0.40667593702707655}
2023-01-04 00:59:03,334 INFO:     Found new best model at epoch 9
2023-01-04 00:59:03,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:03,335 INFO:     Epoch: 10
2023-01-04 00:59:04,963 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.406191814939181, 'Total loss': 0.406191814939181} | train loss {'Reaction outcome loss': 0.39391955077999097, 'Total loss': 0.39391955077999097}
2023-01-04 00:59:04,963 INFO:     Found new best model at epoch 10
2023-01-04 00:59:04,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:04,964 INFO:     Epoch: 11
2023-01-04 00:59:06,577 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41770944992701214, 'Total loss': 0.41770944992701214} | train loss {'Reaction outcome loss': 0.3874933111693953, 'Total loss': 0.3874933111693953}
2023-01-04 00:59:06,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:06,577 INFO:     Epoch: 12
2023-01-04 00:59:08,189 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40927677353223163, 'Total loss': 0.40927677353223163} | train loss {'Reaction outcome loss': 0.3806237537899743, 'Total loss': 0.3806237537899743}
2023-01-04 00:59:08,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:08,189 INFO:     Epoch: 13
2023-01-04 00:59:09,789 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4133875648180644, 'Total loss': 0.4133875648180644} | train loss {'Reaction outcome loss': 0.37745056954630907, 'Total loss': 0.37745056954630907}
2023-01-04 00:59:09,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:09,790 INFO:     Epoch: 14
2023-01-04 00:59:11,376 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4031109889348348, 'Total loss': 0.4031109889348348} | train loss {'Reaction outcome loss': 0.3707274401229739, 'Total loss': 0.3707274401229739}
2023-01-04 00:59:11,377 INFO:     Found new best model at epoch 14
2023-01-04 00:59:11,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:11,377 INFO:     Epoch: 15
2023-01-04 00:59:12,965 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3954910357793172, 'Total loss': 0.3954910357793172} | train loss {'Reaction outcome loss': 0.3595908935978145, 'Total loss': 0.3595908935978145}
2023-01-04 00:59:12,965 INFO:     Found new best model at epoch 15
2023-01-04 00:59:12,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:12,966 INFO:     Epoch: 16
2023-01-04 00:59:14,543 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40146342317263284, 'Total loss': 0.40146342317263284} | train loss {'Reaction outcome loss': 0.35571494095864287, 'Total loss': 0.35571494095864287}
2023-01-04 00:59:14,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:14,544 INFO:     Epoch: 17
2023-01-04 00:59:16,112 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4087344547112783, 'Total loss': 0.4087344547112783} | train loss {'Reaction outcome loss': 0.3496947622911978, 'Total loss': 0.3496947622911978}
2023-01-04 00:59:16,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:16,113 INFO:     Epoch: 18
2023-01-04 00:59:17,725 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3909080609679222, 'Total loss': 0.3909080609679222} | train loss {'Reaction outcome loss': 0.36282205479084584, 'Total loss': 0.36282205479084584}
2023-01-04 00:59:17,725 INFO:     Found new best model at epoch 18
2023-01-04 00:59:17,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:17,726 INFO:     Epoch: 19
2023-01-04 00:59:19,317 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4157585660616557, 'Total loss': 0.4157585660616557} | train loss {'Reaction outcome loss': 0.3466245842004276, 'Total loss': 0.3466245842004276}
2023-01-04 00:59:19,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:19,317 INFO:     Epoch: 20
2023-01-04 00:59:20,951 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38668892284234363, 'Total loss': 0.38668892284234363} | train loss {'Reaction outcome loss': 0.3331160091620404, 'Total loss': 0.3331160091620404}
2023-01-04 00:59:20,951 INFO:     Found new best model at epoch 20
2023-01-04 00:59:20,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:20,952 INFO:     Epoch: 21
2023-01-04 00:59:22,585 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3808720593651136, 'Total loss': 0.3808720593651136} | train loss {'Reaction outcome loss': 0.3286326990582629, 'Total loss': 0.3286326990582629}
2023-01-04 00:59:22,586 INFO:     Found new best model at epoch 21
2023-01-04 00:59:22,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:22,586 INFO:     Epoch: 22
2023-01-04 00:59:24,186 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4038723945617676, 'Total loss': 0.4038723945617676} | train loss {'Reaction outcome loss': 0.32302522327265015, 'Total loss': 0.32302522327265015}
2023-01-04 00:59:24,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:24,186 INFO:     Epoch: 23
2023-01-04 00:59:25,780 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.38909633954366046, 'Total loss': 0.38909633954366046} | train loss {'Reaction outcome loss': 0.3251872698142045, 'Total loss': 0.3251872698142045}
2023-01-04 00:59:25,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:25,780 INFO:     Epoch: 24
2023-01-04 00:59:27,401 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3959639807542165, 'Total loss': 0.3959639807542165} | train loss {'Reaction outcome loss': 0.31698015346394287, 'Total loss': 0.31698015346394287}
2023-01-04 00:59:27,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:27,401 INFO:     Epoch: 25
2023-01-04 00:59:29,023 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39303834935029347, 'Total loss': 0.39303834935029347} | train loss {'Reaction outcome loss': 0.3138162933671307, 'Total loss': 0.3138162933671307}
2023-01-04 00:59:29,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:29,024 INFO:     Epoch: 26
2023-01-04 00:59:30,610 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3858934650818507, 'Total loss': 0.3858934650818507} | train loss {'Reaction outcome loss': 0.30833922829175286, 'Total loss': 0.30833922829175286}
2023-01-04 00:59:30,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:30,610 INFO:     Epoch: 27
2023-01-04 00:59:32,219 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39101594885190327, 'Total loss': 0.39101594885190327} | train loss {'Reaction outcome loss': 0.3059906638564839, 'Total loss': 0.3059906638564839}
2023-01-04 00:59:32,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:32,219 INFO:     Epoch: 28
2023-01-04 00:59:33,810 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38415219585100807, 'Total loss': 0.38415219585100807} | train loss {'Reaction outcome loss': 0.2998879663646221, 'Total loss': 0.2998879663646221}
2023-01-04 00:59:33,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:33,810 INFO:     Epoch: 29
2023-01-04 00:59:35,408 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38105447590351105, 'Total loss': 0.38105447590351105} | train loss {'Reaction outcome loss': 0.29620756933708553, 'Total loss': 0.29620756933708553}
2023-01-04 00:59:35,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:35,408 INFO:     Epoch: 30
2023-01-04 00:59:37,016 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39937341411908467, 'Total loss': 0.39937341411908467} | train loss {'Reaction outcome loss': 0.2937376527385651, 'Total loss': 0.2937376527385651}
2023-01-04 00:59:37,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:37,016 INFO:     Epoch: 31
2023-01-04 00:59:38,633 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3909960091114044, 'Total loss': 0.3909960091114044} | train loss {'Reaction outcome loss': 0.2913558533941598, 'Total loss': 0.2913558533941598}
2023-01-04 00:59:38,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:38,633 INFO:     Epoch: 32
2023-01-04 00:59:40,222 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3797080417474111, 'Total loss': 0.3797080417474111} | train loss {'Reaction outcome loss': 0.29083598020783474, 'Total loss': 0.29083598020783474}
2023-01-04 00:59:40,222 INFO:     Found new best model at epoch 32
2023-01-04 00:59:40,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:40,223 INFO:     Epoch: 33
2023-01-04 00:59:41,793 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4009378393491109, 'Total loss': 0.4009378393491109} | train loss {'Reaction outcome loss': 0.28466819785555436, 'Total loss': 0.28466819785555436}
2023-01-04 00:59:41,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:41,793 INFO:     Epoch: 34
2023-01-04 00:59:43,383 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39378799696763356, 'Total loss': 0.39378799696763356} | train loss {'Reaction outcome loss': 0.28344666689931264, 'Total loss': 0.28344666689931264}
2023-01-04 00:59:43,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:43,383 INFO:     Epoch: 35
2023-01-04 00:59:44,985 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3965533991654714, 'Total loss': 0.3965533991654714} | train loss {'Reaction outcome loss': 0.27842239513520856, 'Total loss': 0.27842239513520856}
2023-01-04 00:59:44,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:44,986 INFO:     Epoch: 36
2023-01-04 00:59:46,599 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3987342894077301, 'Total loss': 0.3987342894077301} | train loss {'Reaction outcome loss': 0.2773719433727978, 'Total loss': 0.2773719433727978}
2023-01-04 00:59:46,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:46,599 INFO:     Epoch: 37
2023-01-04 00:59:48,225 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3986964305241903, 'Total loss': 0.3986964305241903} | train loss {'Reaction outcome loss': 0.27441192510119383, 'Total loss': 0.27441192510119383}
2023-01-04 00:59:48,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:48,225 INFO:     Epoch: 38
2023-01-04 00:59:49,856 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4045862932999929, 'Total loss': 0.4045862932999929} | train loss {'Reaction outcome loss': 0.28935942196867603, 'Total loss': 0.28935942196867603}
2023-01-04 00:59:49,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:49,856 INFO:     Epoch: 39
2023-01-04 00:59:51,457 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39710098803043364, 'Total loss': 0.39710098803043364} | train loss {'Reaction outcome loss': 0.2768540729606605, 'Total loss': 0.2768540729606605}
2023-01-04 00:59:51,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:51,458 INFO:     Epoch: 40
2023-01-04 00:59:53,064 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40339631736278536, 'Total loss': 0.40339631736278536} | train loss {'Reaction outcome loss': 0.26663550894801924, 'Total loss': 0.26663550894801924}
2023-01-04 00:59:53,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:53,064 INFO:     Epoch: 41
2023-01-04 00:59:54,679 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3939566731452942, 'Total loss': 0.3939566731452942} | train loss {'Reaction outcome loss': 0.263303362503749, 'Total loss': 0.263303362503749}
2023-01-04 00:59:54,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:54,679 INFO:     Epoch: 42
2023-01-04 00:59:56,306 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3949456294377645, 'Total loss': 0.3949456294377645} | train loss {'Reaction outcome loss': 0.2624139919121196, 'Total loss': 0.2624139919121196}
2023-01-04 00:59:56,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:56,306 INFO:     Epoch: 43
2023-01-04 00:59:57,908 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3881964907050133, 'Total loss': 0.3881964907050133} | train loss {'Reaction outcome loss': 0.2621707170661809, 'Total loss': 0.2621707170661809}
2023-01-04 00:59:57,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:57,908 INFO:     Epoch: 44
2023-01-04 00:59:59,521 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4173866957426071, 'Total loss': 0.4173866957426071} | train loss {'Reaction outcome loss': 0.256262446274522, 'Total loss': 0.256262446274522}
2023-01-04 00:59:59,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 00:59:59,521 INFO:     Epoch: 45
2023-01-04 01:00:01,083 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3910628487666448, 'Total loss': 0.3910628487666448} | train loss {'Reaction outcome loss': 0.2624552374354739, 'Total loss': 0.2624552374354739}
2023-01-04 01:00:01,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:01,083 INFO:     Epoch: 46
2023-01-04 01:00:02,673 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3977692981561025, 'Total loss': 0.3977692981561025} | train loss {'Reaction outcome loss': 0.2576555591346561, 'Total loss': 0.2576555591346561}
2023-01-04 01:00:02,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:02,673 INFO:     Epoch: 47
2023-01-04 01:00:04,282 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3991241196791331, 'Total loss': 0.3991241196791331} | train loss {'Reaction outcome loss': 0.2607063243732504, 'Total loss': 0.2607063243732504}
2023-01-04 01:00:04,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:04,283 INFO:     Epoch: 48
2023-01-04 01:00:05,886 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3835509826739629, 'Total loss': 0.3835509826739629} | train loss {'Reaction outcome loss': 0.25529470875103405, 'Total loss': 0.25529470875103405}
2023-01-04 01:00:05,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:05,887 INFO:     Epoch: 49
2023-01-04 01:00:07,497 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3757039546966553, 'Total loss': 0.3757039546966553} | train loss {'Reaction outcome loss': 0.2519157303503944, 'Total loss': 0.2519157303503944}
2023-01-04 01:00:07,497 INFO:     Found new best model at epoch 49
2023-01-04 01:00:07,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:07,498 INFO:     Epoch: 50
2023-01-04 01:00:09,077 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4174001902341843, 'Total loss': 0.4174001902341843} | train loss {'Reaction outcome loss': 0.25872856659301813, 'Total loss': 0.25872856659301813}
2023-01-04 01:00:09,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:09,077 INFO:     Epoch: 51
2023-01-04 01:00:10,679 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3986421803633372, 'Total loss': 0.3986421803633372} | train loss {'Reaction outcome loss': 0.2661874857202602, 'Total loss': 0.2661874857202602}
2023-01-04 01:00:10,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:10,679 INFO:     Epoch: 52
2023-01-04 01:00:12,295 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38766116301218667, 'Total loss': 0.38766116301218667} | train loss {'Reaction outcome loss': 0.24180362912390949, 'Total loss': 0.24180362912390949}
2023-01-04 01:00:12,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:12,296 INFO:     Epoch: 53
2023-01-04 01:00:13,899 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.394965531428655, 'Total loss': 0.394965531428655} | train loss {'Reaction outcome loss': 0.24151921715668362, 'Total loss': 0.24151921715668362}
2023-01-04 01:00:13,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:13,899 INFO:     Epoch: 54
2023-01-04 01:00:15,516 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39397240032752356, 'Total loss': 0.39397240032752356} | train loss {'Reaction outcome loss': 0.23877879512999073, 'Total loss': 0.23877879512999073}
2023-01-04 01:00:15,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:15,517 INFO:     Epoch: 55
2023-01-04 01:00:17,127 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3894727905591329, 'Total loss': 0.3894727905591329} | train loss {'Reaction outcome loss': 0.23540029380529776, 'Total loss': 0.23540029380529776}
2023-01-04 01:00:17,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:17,127 INFO:     Epoch: 56
2023-01-04 01:00:18,701 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.416413152217865, 'Total loss': 0.416413152217865} | train loss {'Reaction outcome loss': 0.24143781897652408, 'Total loss': 0.24143781897652408}
2023-01-04 01:00:18,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:18,701 INFO:     Epoch: 57
2023-01-04 01:00:20,295 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3961699972550074, 'Total loss': 0.3961699972550074} | train loss {'Reaction outcome loss': 0.24634428009217052, 'Total loss': 0.24634428009217052}
2023-01-04 01:00:20,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:20,296 INFO:     Epoch: 58
2023-01-04 01:00:21,913 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42751487096150714, 'Total loss': 0.42751487096150714} | train loss {'Reaction outcome loss': 0.23168734424119897, 'Total loss': 0.23168734424119897}
2023-01-04 01:00:21,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:21,914 INFO:     Epoch: 59
2023-01-04 01:00:23,508 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40425527493158975, 'Total loss': 0.40425527493158975} | train loss {'Reaction outcome loss': 0.22887947194386218, 'Total loss': 0.22887947194386218}
2023-01-04 01:00:23,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:23,509 INFO:     Epoch: 60
2023-01-04 01:00:25,124 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39862771729628244, 'Total loss': 0.39862771729628244} | train loss {'Reaction outcome loss': 0.22878970470349264, 'Total loss': 0.22878970470349264}
2023-01-04 01:00:25,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:25,124 INFO:     Epoch: 61
2023-01-04 01:00:26,726 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40074704090754193, 'Total loss': 0.40074704090754193} | train loss {'Reaction outcome loss': 0.226751554430044, 'Total loss': 0.226751554430044}
2023-01-04 01:00:26,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:26,726 INFO:     Epoch: 62
2023-01-04 01:00:28,292 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4023822585741679, 'Total loss': 0.4023822585741679} | train loss {'Reaction outcome loss': 0.22759501787874362, 'Total loss': 0.22759501787874362}
2023-01-04 01:00:28,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:28,292 INFO:     Epoch: 63
2023-01-04 01:00:29,885 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3821054309606552, 'Total loss': 0.3821054309606552} | train loss {'Reaction outcome loss': 0.2282993163191376, 'Total loss': 0.2282993163191376}
2023-01-04 01:00:29,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:29,885 INFO:     Epoch: 64
2023-01-04 01:00:31,497 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39963750541210175, 'Total loss': 0.39963750541210175} | train loss {'Reaction outcome loss': 0.2229856873282056, 'Total loss': 0.2229856873282056}
2023-01-04 01:00:31,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:31,497 INFO:     Epoch: 65
2023-01-04 01:00:33,103 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3914762198925018, 'Total loss': 0.3914762198925018} | train loss {'Reaction outcome loss': 0.2242741039213349, 'Total loss': 0.2242741039213349}
2023-01-04 01:00:33,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:33,103 INFO:     Epoch: 66
2023-01-04 01:00:34,719 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4047266532977422, 'Total loss': 0.4047266532977422} | train loss {'Reaction outcome loss': 0.21768191527318803, 'Total loss': 0.21768191527318803}
2023-01-04 01:00:34,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:34,719 INFO:     Epoch: 67
2023-01-04 01:00:36,307 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4133316894372304, 'Total loss': 0.4133316894372304} | train loss {'Reaction outcome loss': 0.21805493131387924, 'Total loss': 0.21805493131387924}
2023-01-04 01:00:36,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:36,307 INFO:     Epoch: 68
2023-01-04 01:00:37,900 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39991981387138364, 'Total loss': 0.39991981387138364} | train loss {'Reaction outcome loss': 0.2166970031119991, 'Total loss': 0.2166970031119991}
2023-01-04 01:00:37,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:37,900 INFO:     Epoch: 69
2023-01-04 01:00:39,518 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4029873897631963, 'Total loss': 0.4029873897631963} | train loss {'Reaction outcome loss': 0.21634725398262558, 'Total loss': 0.21634725398262558}
2023-01-04 01:00:39,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:39,518 INFO:     Epoch: 70
2023-01-04 01:00:41,131 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40091480215390524, 'Total loss': 0.40091480215390524} | train loss {'Reaction outcome loss': 0.21624429027914352, 'Total loss': 0.21624429027914352}
2023-01-04 01:00:41,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:41,131 INFO:     Epoch: 71
2023-01-04 01:00:42,746 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4470913747946421, 'Total loss': 0.4470913747946421} | train loss {'Reaction outcome loss': 0.2651926504475051, 'Total loss': 0.2651926504475051}
2023-01-04 01:00:42,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:42,747 INFO:     Epoch: 72
2023-01-04 01:00:44,363 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39297891954580944, 'Total loss': 0.39297891954580944} | train loss {'Reaction outcome loss': 0.2228167502047575, 'Total loss': 0.2228167502047575}
2023-01-04 01:00:44,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:44,364 INFO:     Epoch: 73
2023-01-04 01:00:45,945 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39738007287184396, 'Total loss': 0.39738007287184396} | train loss {'Reaction outcome loss': 0.22418145169892037, 'Total loss': 0.22418145169892037}
2023-01-04 01:00:45,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:45,946 INFO:     Epoch: 74
2023-01-04 01:00:47,533 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38376973023017247, 'Total loss': 0.38376973023017247} | train loss {'Reaction outcome loss': 0.21370730117938574, 'Total loss': 0.21370730117938574}
2023-01-04 01:00:47,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:47,533 INFO:     Epoch: 75
2023-01-04 01:00:49,127 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4003230929374695, 'Total loss': 0.4003230929374695} | train loss {'Reaction outcome loss': 0.2098687479434454, 'Total loss': 0.2098687479434454}
2023-01-04 01:00:49,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:49,127 INFO:     Epoch: 76
2023-01-04 01:00:50,721 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39530917604764304, 'Total loss': 0.39530917604764304} | train loss {'Reaction outcome loss': 0.20940232209091925, 'Total loss': 0.20940232209091925}
2023-01-04 01:00:50,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:50,721 INFO:     Epoch: 77
2023-01-04 01:00:52,327 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4020063410202662, 'Total loss': 0.4020063410202662} | train loss {'Reaction outcome loss': 0.20880757342177053, 'Total loss': 0.20880757342177053}
2023-01-04 01:00:52,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:52,327 INFO:     Epoch: 78
2023-01-04 01:00:53,916 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41551651805639267, 'Total loss': 0.41551651805639267} | train loss {'Reaction outcome loss': 0.2094887503274325, 'Total loss': 0.2094887503274325}
2023-01-04 01:00:53,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:53,916 INFO:     Epoch: 79
2023-01-04 01:00:55,494 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40991199811299645, 'Total loss': 0.40991199811299645} | train loss {'Reaction outcome loss': 0.2097299105425427, 'Total loss': 0.2097299105425427}
2023-01-04 01:00:55,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:55,495 INFO:     Epoch: 80
2023-01-04 01:00:57,087 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4147408882776896, 'Total loss': 0.4147408882776896} | train loss {'Reaction outcome loss': 0.20455194810199537, 'Total loss': 0.20455194810199537}
2023-01-04 01:00:57,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:57,088 INFO:     Epoch: 81
2023-01-04 01:00:58,682 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4169721593459447, 'Total loss': 0.4169721593459447} | train loss {'Reaction outcome loss': 0.20427423497607958, 'Total loss': 0.20427423497607958}
2023-01-04 01:00:58,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:00:58,682 INFO:     Epoch: 82
2023-01-04 01:01:00,275 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42337791124979657, 'Total loss': 0.42337791124979657} | train loss {'Reaction outcome loss': 0.2066362135220265, 'Total loss': 0.2066362135220265}
2023-01-04 01:01:00,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:00,275 INFO:     Epoch: 83
2023-01-04 01:01:01,869 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4155901004870733, 'Total loss': 0.4155901004870733} | train loss {'Reaction outcome loss': 0.2072107784751545, 'Total loss': 0.2072107784751545}
2023-01-04 01:01:01,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:01,869 INFO:     Epoch: 84
2023-01-04 01:01:03,448 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3959913303454717, 'Total loss': 0.3959913303454717} | train loss {'Reaction outcome loss': 0.20424174614680046, 'Total loss': 0.20424174614680046}
2023-01-04 01:01:03,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:03,449 INFO:     Epoch: 85
2023-01-04 01:01:05,031 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42158411542574564, 'Total loss': 0.42158411542574564} | train loss {'Reaction outcome loss': 0.19949346294447753, 'Total loss': 0.19949346294447753}
2023-01-04 01:01:05,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:05,032 INFO:     Epoch: 86
2023-01-04 01:01:06,642 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4177326718966166, 'Total loss': 0.4177326718966166} | train loss {'Reaction outcome loss': 0.2027931944334262, 'Total loss': 0.2027931944334262}
2023-01-04 01:01:06,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:06,642 INFO:     Epoch: 87
2023-01-04 01:01:08,244 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4055229723453522, 'Total loss': 0.4055229723453522} | train loss {'Reaction outcome loss': 0.19818636497560269, 'Total loss': 0.19818636497560269}
2023-01-04 01:01:08,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:08,244 INFO:     Epoch: 88
2023-01-04 01:01:09,852 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38644673228263854, 'Total loss': 0.38644673228263854} | train loss {'Reaction outcome loss': 0.19864417024707992, 'Total loss': 0.19864417024707992}
2023-01-04 01:01:09,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:09,852 INFO:     Epoch: 89
2023-01-04 01:01:11,467 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4120253105958303, 'Total loss': 0.4120253105958303} | train loss {'Reaction outcome loss': 0.2036335998336258, 'Total loss': 0.2036335998336258}
2023-01-04 01:01:11,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:11,468 INFO:     Epoch: 90
2023-01-04 01:01:13,029 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4010491242011388, 'Total loss': 0.4010491242011388} | train loss {'Reaction outcome loss': 0.20949829976124407, 'Total loss': 0.20949829976124407}
2023-01-04 01:01:13,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:13,029 INFO:     Epoch: 91
2023-01-04 01:01:14,651 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4072124163309733, 'Total loss': 0.4072124163309733} | train loss {'Reaction outcome loss': 0.19791105278916116, 'Total loss': 0.19791105278916116}
2023-01-04 01:01:14,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:14,651 INFO:     Epoch: 92
2023-01-04 01:01:16,271 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4088700105746587, 'Total loss': 0.4088700105746587} | train loss {'Reaction outcome loss': 0.2022971797707504, 'Total loss': 0.2022971797707504}
2023-01-04 01:01:16,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:16,271 INFO:     Epoch: 93
2023-01-04 01:01:17,873 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4147186656792959, 'Total loss': 0.4147186656792959} | train loss {'Reaction outcome loss': 0.2149963237858121, 'Total loss': 0.2149963237858121}
2023-01-04 01:01:17,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:17,875 INFO:     Epoch: 94
2023-01-04 01:01:19,480 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40705420076847076, 'Total loss': 0.40705420076847076} | train loss {'Reaction outcome loss': 0.21040666786459464, 'Total loss': 0.21040666786459464}
2023-01-04 01:01:19,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:19,480 INFO:     Epoch: 95
2023-01-04 01:01:21,076 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40538977781931557, 'Total loss': 0.40538977781931557} | train loss {'Reaction outcome loss': 0.19477505075179657, 'Total loss': 0.19477505075179657}
2023-01-04 01:01:21,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:21,077 INFO:     Epoch: 96
2023-01-04 01:01:22,681 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40160752832889557, 'Total loss': 0.40160752832889557} | train loss {'Reaction outcome loss': 0.1917542531623242, 'Total loss': 0.1917542531623242}
2023-01-04 01:01:22,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:22,682 INFO:     Epoch: 97
2023-01-04 01:01:24,297 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3923917651176453, 'Total loss': 0.3923917651176453} | train loss {'Reaction outcome loss': 0.19429393227060707, 'Total loss': 0.19429393227060707}
2023-01-04 01:01:24,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:24,298 INFO:     Epoch: 98
2023-01-04 01:01:25,885 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4084156493345896, 'Total loss': 0.4084156493345896} | train loss {'Reaction outcome loss': 0.18939799966798435, 'Total loss': 0.18939799966798435}
2023-01-04 01:01:25,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:25,885 INFO:     Epoch: 99
2023-01-04 01:01:27,507 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40283383429050446, 'Total loss': 0.40283383429050446} | train loss {'Reaction outcome loss': 0.19137912003935753, 'Total loss': 0.19137912003935753}
2023-01-04 01:01:27,507 INFO:     Best model found after epoch 50 of 100.
2023-01-04 01:01:27,508 INFO:   Done with stage: TRAINING
2023-01-04 01:01:27,508 INFO:   Starting stage: EVALUATION
2023-01-04 01:01:27,638 INFO:   Done with stage: EVALUATION
2023-01-04 01:01:27,638 INFO:   Leaving out SEQ value Fold_7
2023-01-04 01:01:27,650 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 01:01:27,651 INFO:   Starting stage: FEATURE SCALING
2023-01-04 01:01:28,294 INFO:   Done with stage: FEATURE SCALING
2023-01-04 01:01:28,294 INFO:   Starting stage: SCALING TARGETS
2023-01-04 01:01:28,364 INFO:   Done with stage: SCALING TARGETS
2023-01-04 01:01:28,364 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:01:28,364 INFO:     No hyperparam tuning for this model
2023-01-04 01:01:28,364 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:01:28,364 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 01:01:28,365 INFO:     None feature selector for col prot
2023-01-04 01:01:28,365 INFO:     None feature selector for col prot
2023-01-04 01:01:28,365 INFO:     None feature selector for col prot
2023-01-04 01:01:28,366 INFO:     None feature selector for col chem
2023-01-04 01:01:28,366 INFO:     None feature selector for col chem
2023-01-04 01:01:28,366 INFO:     None feature selector for col chem
2023-01-04 01:01:28,366 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 01:01:28,366 INFO:   Starting stage: BUILD MODEL
2023-01-04 01:01:28,367 INFO:     Number of params in model 70141
2023-01-04 01:01:28,370 INFO:   Done with stage: BUILD MODEL
2023-01-04 01:01:28,371 INFO:   Starting stage: TRAINING
2023-01-04 01:01:28,414 INFO:     Val loss before train {'Reaction outcome loss': 0.9665772517522176, 'Total loss': 0.9665772517522176}
2023-01-04 01:01:28,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:28,415 INFO:     Epoch: 0
2023-01-04 01:01:29,999 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6976655463377635, 'Total loss': 0.6976655463377635} | train loss {'Reaction outcome loss': 0.8439766998110265, 'Total loss': 0.8439766998110265}
2023-01-04 01:01:29,999 INFO:     Found new best model at epoch 0
2023-01-04 01:01:29,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:30,000 INFO:     Epoch: 1
2023-01-04 01:01:31,580 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5523776988188426, 'Total loss': 0.5523776988188426} | train loss {'Reaction outcome loss': 0.5929351028337375, 'Total loss': 0.5929351028337375}
2023-01-04 01:01:31,580 INFO:     Found new best model at epoch 1
2023-01-04 01:01:31,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:31,581 INFO:     Epoch: 2
2023-01-04 01:01:33,180 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.527321336666743, 'Total loss': 0.527321336666743} | train loss {'Reaction outcome loss': 0.5228621070996088, 'Total loss': 0.5228621070996088}
2023-01-04 01:01:33,181 INFO:     Found new best model at epoch 2
2023-01-04 01:01:33,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:33,182 INFO:     Epoch: 3
2023-01-04 01:01:34,781 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5129094918568929, 'Total loss': 0.5129094918568929} | train loss {'Reaction outcome loss': 0.49007485535278217, 'Total loss': 0.49007485535278217}
2023-01-04 01:01:34,781 INFO:     Found new best model at epoch 3
2023-01-04 01:01:34,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:34,782 INFO:     Epoch: 4
2023-01-04 01:01:36,381 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49905285437901814, 'Total loss': 0.49905285437901814} | train loss {'Reaction outcome loss': 0.46668278536211283, 'Total loss': 0.46668278536211283}
2023-01-04 01:01:36,381 INFO:     Found new best model at epoch 4
2023-01-04 01:01:36,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:36,382 INFO:     Epoch: 5
2023-01-04 01:01:37,976 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4772059341271718, 'Total loss': 0.4772059341271718} | train loss {'Reaction outcome loss': 0.44610594562675115, 'Total loss': 0.44610594562675115}
2023-01-04 01:01:37,976 INFO:     Found new best model at epoch 5
2023-01-04 01:01:37,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:37,977 INFO:     Epoch: 6
2023-01-04 01:01:39,544 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4703778366247813, 'Total loss': 0.4703778366247813} | train loss {'Reaction outcome loss': 0.4291951992559089, 'Total loss': 0.4291951992559089}
2023-01-04 01:01:39,544 INFO:     Found new best model at epoch 6
2023-01-04 01:01:39,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:39,545 INFO:     Epoch: 7
2023-01-04 01:01:41,144 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4770074109236399, 'Total loss': 0.4770074109236399} | train loss {'Reaction outcome loss': 0.4141111931215555, 'Total loss': 0.4141111931215555}
2023-01-04 01:01:41,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:41,144 INFO:     Epoch: 8
2023-01-04 01:01:42,768 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46814998785654705, 'Total loss': 0.46814998785654705} | train loss {'Reaction outcome loss': 0.40334993111312606, 'Total loss': 0.40334993111312606}
2023-01-04 01:01:42,768 INFO:     Found new best model at epoch 8
2023-01-04 01:01:42,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:42,769 INFO:     Epoch: 9
2023-01-04 01:01:44,378 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.456022235751152, 'Total loss': 0.456022235751152} | train loss {'Reaction outcome loss': 0.39302917470355325, 'Total loss': 0.39302917470355325}
2023-01-04 01:01:44,379 INFO:     Found new best model at epoch 9
2023-01-04 01:01:44,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:44,379 INFO:     Epoch: 10
2023-01-04 01:01:45,974 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4630555252234141, 'Total loss': 0.4630555252234141} | train loss {'Reaction outcome loss': 0.38443150061992964, 'Total loss': 0.38443150061992964}
2023-01-04 01:01:45,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:45,974 INFO:     Epoch: 11
2023-01-04 01:01:47,554 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4833827495574951, 'Total loss': 0.4833827495574951} | train loss {'Reaction outcome loss': 0.3746102816468972, 'Total loss': 0.3746102816468972}
2023-01-04 01:01:47,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:47,555 INFO:     Epoch: 12
2023-01-04 01:01:49,172 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46057408253351845, 'Total loss': 0.46057408253351845} | train loss {'Reaction outcome loss': 0.3682805060909974, 'Total loss': 0.3682805060909974}
2023-01-04 01:01:49,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:49,172 INFO:     Epoch: 13
2023-01-04 01:01:50,801 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4539889494578044, 'Total loss': 0.4539889494578044} | train loss {'Reaction outcome loss': 0.36107163591182617, 'Total loss': 0.36107163591182617}
2023-01-04 01:01:50,801 INFO:     Found new best model at epoch 13
2023-01-04 01:01:50,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:50,802 INFO:     Epoch: 14
2023-01-04 01:01:52,432 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46845109860102335, 'Total loss': 0.46845109860102335} | train loss {'Reaction outcome loss': 0.35451644379309366, 'Total loss': 0.35451644379309366}
2023-01-04 01:01:52,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:52,433 INFO:     Epoch: 15
2023-01-04 01:01:54,036 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4964947243531545, 'Total loss': 0.4964947243531545} | train loss {'Reaction outcome loss': 0.34604399916228407, 'Total loss': 0.34604399916228407}
2023-01-04 01:01:54,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:54,036 INFO:     Epoch: 16
2023-01-04 01:01:55,642 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4814973463614782, 'Total loss': 0.4814973463614782} | train loss {'Reaction outcome loss': 0.34053702749285025, 'Total loss': 0.34053702749285025}
2023-01-04 01:01:55,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:55,643 INFO:     Epoch: 17
2023-01-04 01:01:57,223 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47290469308694205, 'Total loss': 0.47290469308694205} | train loss {'Reaction outcome loss': 0.3358000487304336, 'Total loss': 0.3358000487304336}
2023-01-04 01:01:57,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:57,223 INFO:     Epoch: 18
2023-01-04 01:01:58,806 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45299655993779503, 'Total loss': 0.45299655993779503} | train loss {'Reaction outcome loss': 0.32875208212365314, 'Total loss': 0.32875208212365314}
2023-01-04 01:01:58,807 INFO:     Found new best model at epoch 18
2023-01-04 01:01:58,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:01:58,808 INFO:     Epoch: 19
2023-01-04 01:02:00,393 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4699894924958547, 'Total loss': 0.4699894924958547} | train loss {'Reaction outcome loss': 0.3252774477542953, 'Total loss': 0.3252774477542953}
2023-01-04 01:02:00,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:00,393 INFO:     Epoch: 20
2023-01-04 01:02:02,012 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48236016035079954, 'Total loss': 0.48236016035079954} | train loss {'Reaction outcome loss': 0.3184728468852353, 'Total loss': 0.3184728468852353}
2023-01-04 01:02:02,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:02,012 INFO:     Epoch: 21
2023-01-04 01:02:03,644 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48307370642820996, 'Total loss': 0.48307370642820996} | train loss {'Reaction outcome loss': 0.3150103057495954, 'Total loss': 0.3150103057495954}
2023-01-04 01:02:03,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:03,644 INFO:     Epoch: 22
2023-01-04 01:02:05,249 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4611091256141663, 'Total loss': 0.4611091256141663} | train loss {'Reaction outcome loss': 0.30952667184039573, 'Total loss': 0.30952667184039573}
2023-01-04 01:02:05,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:05,250 INFO:     Epoch: 23
2023-01-04 01:02:06,842 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45483139902353287, 'Total loss': 0.45483139902353287} | train loss {'Reaction outcome loss': 0.3035117281795839, 'Total loss': 0.3035117281795839}
2023-01-04 01:02:06,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:06,842 INFO:     Epoch: 24
2023-01-04 01:02:08,477 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4722611447175344, 'Total loss': 0.4722611447175344} | train loss {'Reaction outcome loss': 0.30072977751601043, 'Total loss': 0.30072977751601043}
2023-01-04 01:02:08,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:08,477 INFO:     Epoch: 25
2023-01-04 01:02:10,093 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4660355677207311, 'Total loss': 0.4660355677207311} | train loss {'Reaction outcome loss': 0.2947616470903696, 'Total loss': 0.2947616470903696}
2023-01-04 01:02:10,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:10,094 INFO:     Epoch: 26
2023-01-04 01:02:11,725 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4642580568790436, 'Total loss': 0.4642580568790436} | train loss {'Reaction outcome loss': 0.29165905751691396, 'Total loss': 0.29165905751691396}
2023-01-04 01:02:11,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:11,726 INFO:     Epoch: 27
2023-01-04 01:02:13,324 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43954263627529144, 'Total loss': 0.43954263627529144} | train loss {'Reaction outcome loss': 0.2859419020773702, 'Total loss': 0.2859419020773702}
2023-01-04 01:02:13,324 INFO:     Found new best model at epoch 27
2023-01-04 01:02:13,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:13,325 INFO:     Epoch: 28
2023-01-04 01:02:14,910 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45492923458417256, 'Total loss': 0.45492923458417256} | train loss {'Reaction outcome loss': 0.28512600857751036, 'Total loss': 0.28512600857751036}
2023-01-04 01:02:14,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:14,910 INFO:     Epoch: 29
2023-01-04 01:02:16,512 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46055042545000713, 'Total loss': 0.46055042545000713} | train loss {'Reaction outcome loss': 0.28191795773024164, 'Total loss': 0.28191795773024164}
2023-01-04 01:02:16,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:16,512 INFO:     Epoch: 30
2023-01-04 01:02:18,130 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4606127868096034, 'Total loss': 0.4606127868096034} | train loss {'Reaction outcome loss': 0.27563624304554524, 'Total loss': 0.27563624304554524}
2023-01-04 01:02:18,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:18,130 INFO:     Epoch: 31
2023-01-04 01:02:19,731 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4747506737709045, 'Total loss': 0.4747506737709045} | train loss {'Reaction outcome loss': 0.2710799738657173, 'Total loss': 0.2710799738657173}
2023-01-04 01:02:19,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:19,731 INFO:     Epoch: 32
2023-01-04 01:02:21,331 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46609109044075014, 'Total loss': 0.46609109044075014} | train loss {'Reaction outcome loss': 0.27159943754384663, 'Total loss': 0.27159943754384663}
2023-01-04 01:02:21,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:21,331 INFO:     Epoch: 33
2023-01-04 01:02:22,920 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46364740530649823, 'Total loss': 0.46364740530649823} | train loss {'Reaction outcome loss': 0.26694506683827307, 'Total loss': 0.26694506683827307}
2023-01-04 01:02:22,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:22,921 INFO:     Epoch: 34
2023-01-04 01:02:24,493 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4634565571943919, 'Total loss': 0.4634565571943919} | train loss {'Reaction outcome loss': 0.26555061221983456, 'Total loss': 0.26555061221983456}
2023-01-04 01:02:24,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:24,493 INFO:     Epoch: 35
2023-01-04 01:02:26,124 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4596473475297292, 'Total loss': 0.4596473475297292} | train loss {'Reaction outcome loss': 0.26075297529516667, 'Total loss': 0.26075297529516667}
2023-01-04 01:02:26,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:26,124 INFO:     Epoch: 36
2023-01-04 01:02:27,723 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4646764318148295, 'Total loss': 0.4646764318148295} | train loss {'Reaction outcome loss': 0.2577763177212395, 'Total loss': 0.2577763177212395}
2023-01-04 01:02:27,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:27,723 INFO:     Epoch: 37
2023-01-04 01:02:29,348 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47315404017766316, 'Total loss': 0.47315404017766316} | train loss {'Reaction outcome loss': 0.2542226841195826, 'Total loss': 0.2542226841195826}
2023-01-04 01:02:29,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:29,349 INFO:     Epoch: 38
2023-01-04 01:02:30,972 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45578036109606423, 'Total loss': 0.45578036109606423} | train loss {'Reaction outcome loss': 0.2539187386120915, 'Total loss': 0.2539187386120915}
2023-01-04 01:02:30,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:30,972 INFO:     Epoch: 39
2023-01-04 01:02:32,584 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45626158515612286, 'Total loss': 0.45626158515612286} | train loss {'Reaction outcome loss': 0.2498187829172138, 'Total loss': 0.2498187829172138}
2023-01-04 01:02:32,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:32,584 INFO:     Epoch: 40
2023-01-04 01:02:34,190 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46509437362353007, 'Total loss': 0.46509437362353007} | train loss {'Reaction outcome loss': 0.24611870446898015, 'Total loss': 0.24611870446898015}
2023-01-04 01:02:34,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:34,190 INFO:     Epoch: 41
2023-01-04 01:02:35,817 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4744250555833181, 'Total loss': 0.4744250555833181} | train loss {'Reaction outcome loss': 0.2422185018389664, 'Total loss': 0.2422185018389664}
2023-01-04 01:02:35,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:35,817 INFO:     Epoch: 42
2023-01-04 01:02:37,422 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46088228821754457, 'Total loss': 0.46088228821754457} | train loss {'Reaction outcome loss': 0.24245024421369987, 'Total loss': 0.24245024421369987}
2023-01-04 01:02:37,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:37,422 INFO:     Epoch: 43
2023-01-04 01:02:39,043 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47064754168192546, 'Total loss': 0.47064754168192546} | train loss {'Reaction outcome loss': 0.23867927649014695, 'Total loss': 0.23867927649014695}
2023-01-04 01:02:39,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:39,043 INFO:     Epoch: 44
2023-01-04 01:02:40,672 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4515206585327784, 'Total loss': 0.4515206585327784} | train loss {'Reaction outcome loss': 0.23790367308076107, 'Total loss': 0.23790367308076107}
2023-01-04 01:02:40,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:40,672 INFO:     Epoch: 45
2023-01-04 01:02:42,247 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4641576290130615, 'Total loss': 0.4641576290130615} | train loss {'Reaction outcome loss': 0.23731320862412883, 'Total loss': 0.23731320862412883}
2023-01-04 01:02:42,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:42,247 INFO:     Epoch: 46
2023-01-04 01:02:43,837 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4620588759581248, 'Total loss': 0.4620588759581248} | train loss {'Reaction outcome loss': 0.23208482482803428, 'Total loss': 0.23208482482803428}
2023-01-04 01:02:43,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:43,838 INFO:     Epoch: 47
2023-01-04 01:02:45,464 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46267464955647786, 'Total loss': 0.46267464955647786} | train loss {'Reaction outcome loss': 0.2307121766670624, 'Total loss': 0.2307121766670624}
2023-01-04 01:02:45,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:45,464 INFO:     Epoch: 48
2023-01-04 01:02:47,094 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5169469058513642, 'Total loss': 0.5169469058513642} | train loss {'Reaction outcome loss': 0.2283911698830687, 'Total loss': 0.2283911698830687}
2023-01-04 01:02:47,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:47,094 INFO:     Epoch: 49
2023-01-04 01:02:48,718 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5163865586121877, 'Total loss': 0.5163865586121877} | train loss {'Reaction outcome loss': 0.2272652527014809, 'Total loss': 0.2272652527014809}
2023-01-04 01:02:48,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:48,719 INFO:     Epoch: 50
2023-01-04 01:02:50,315 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4711693326632182, 'Total loss': 0.4711693326632182} | train loss {'Reaction outcome loss': 0.22256181432129243, 'Total loss': 0.22256181432129243}
2023-01-04 01:02:50,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:50,315 INFO:     Epoch: 51
2023-01-04 01:02:51,895 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49242108265558876, 'Total loss': 0.49242108265558876} | train loss {'Reaction outcome loss': 0.22280022890612966, 'Total loss': 0.22280022890612966}
2023-01-04 01:02:51,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:51,895 INFO:     Epoch: 52
2023-01-04 01:02:53,495 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4848770340283712, 'Total loss': 0.4848770340283712} | train loss {'Reaction outcome loss': 0.22120341322374687, 'Total loss': 0.22120341322374687}
2023-01-04 01:02:53,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:53,495 INFO:     Epoch: 53
2023-01-04 01:02:55,095 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45836927443742753, 'Total loss': 0.45836927443742753} | train loss {'Reaction outcome loss': 0.21963412543281322, 'Total loss': 0.21963412543281322}
2023-01-04 01:02:55,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:55,095 INFO:     Epoch: 54
2023-01-04 01:02:56,695 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47514028946558634, 'Total loss': 0.47514028946558634} | train loss {'Reaction outcome loss': 0.21775681329117785, 'Total loss': 0.21775681329117785}
2023-01-04 01:02:56,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:56,695 INFO:     Epoch: 55
2023-01-04 01:02:58,294 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4848860601584117, 'Total loss': 0.4848860601584117} | train loss {'Reaction outcome loss': 0.2148975404214773, 'Total loss': 0.2148975404214773}
2023-01-04 01:02:58,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:58,294 INFO:     Epoch: 56
2023-01-04 01:02:59,875 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46089238425095874, 'Total loss': 0.46089238425095874} | train loss {'Reaction outcome loss': 0.21379899322341064, 'Total loss': 0.21379899322341064}
2023-01-04 01:02:59,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:02:59,875 INFO:     Epoch: 57
2023-01-04 01:03:01,489 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46200196047623954, 'Total loss': 0.46200196047623954} | train loss {'Reaction outcome loss': 0.21198978872182997, 'Total loss': 0.21198978872182997}
2023-01-04 01:03:01,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:01,489 INFO:     Epoch: 58
2023-01-04 01:03:03,123 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.48078030049800874, 'Total loss': 0.48078030049800874} | train loss {'Reaction outcome loss': 0.2102100221500715, 'Total loss': 0.2102100221500715}
2023-01-04 01:03:03,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:03,123 INFO:     Epoch: 59
2023-01-04 01:03:04,712 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4926252802213033, 'Total loss': 0.4926252802213033} | train loss {'Reaction outcome loss': 0.20987233177284687, 'Total loss': 0.20987233177284687}
2023-01-04 01:03:04,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:04,713 INFO:     Epoch: 60
2023-01-04 01:03:06,329 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4640582412481308, 'Total loss': 0.4640582412481308} | train loss {'Reaction outcome loss': 0.20740082966237722, 'Total loss': 0.20740082966237722}
2023-01-04 01:03:06,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:06,330 INFO:     Epoch: 61
2023-01-04 01:03:07,938 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4786439299583435, 'Total loss': 0.4786439299583435} | train loss {'Reaction outcome loss': 0.20801296224985744, 'Total loss': 0.20801296224985744}
2023-01-04 01:03:07,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:07,939 INFO:     Epoch: 62
2023-01-04 01:03:09,517 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4893404175837835, 'Total loss': 0.4893404175837835} | train loss {'Reaction outcome loss': 0.20644910357865615, 'Total loss': 0.20644910357865615}
2023-01-04 01:03:09,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:09,517 INFO:     Epoch: 63
2023-01-04 01:03:11,143 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47779427965482074, 'Total loss': 0.47779427965482074} | train loss {'Reaction outcome loss': 0.20527150034097558, 'Total loss': 0.20527150034097558}
2023-01-04 01:03:11,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:11,144 INFO:     Epoch: 64
2023-01-04 01:03:12,770 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4635090837876002, 'Total loss': 0.4635090837876002} | train loss {'Reaction outcome loss': 0.2029956966329245, 'Total loss': 0.2029956966329245}
2023-01-04 01:03:12,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:12,770 INFO:     Epoch: 65
2023-01-04 01:03:14,398 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47952879865964254, 'Total loss': 0.47952879865964254} | train loss {'Reaction outcome loss': 0.1971786086202098, 'Total loss': 0.1971786086202098}
2023-01-04 01:03:14,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:14,398 INFO:     Epoch: 66
2023-01-04 01:03:16,025 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47606632361809414, 'Total loss': 0.47606632361809414} | train loss {'Reaction outcome loss': 0.19912474940023267, 'Total loss': 0.19912474940023267}
2023-01-04 01:03:16,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:16,026 INFO:     Epoch: 67
2023-01-04 01:03:17,633 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4603038022915522, 'Total loss': 0.4603038022915522} | train loss {'Reaction outcome loss': 0.19858306394183894, 'Total loss': 0.19858306394183894}
2023-01-04 01:03:17,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:17,634 INFO:     Epoch: 68
2023-01-04 01:03:19,225 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4631425658861796, 'Total loss': 0.4631425658861796} | train loss {'Reaction outcome loss': 0.19726852669854672, 'Total loss': 0.19726852669854672}
2023-01-04 01:03:19,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:19,225 INFO:     Epoch: 69
2023-01-04 01:03:20,828 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4745164155960083, 'Total loss': 0.4745164155960083} | train loss {'Reaction outcome loss': 0.19671537775532863, 'Total loss': 0.19671537775532863}
2023-01-04 01:03:20,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:20,828 INFO:     Epoch: 70
2023-01-04 01:03:22,433 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5054178357124328, 'Total loss': 0.5054178357124328} | train loss {'Reaction outcome loss': 0.19303910054992682, 'Total loss': 0.19303910054992682}
2023-01-04 01:03:22,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:22,433 INFO:     Epoch: 71
2023-01-04 01:03:24,035 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5000657091538111, 'Total loss': 0.5000657091538111} | train loss {'Reaction outcome loss': 0.1940889778187236, 'Total loss': 0.1940889778187236}
2023-01-04 01:03:24,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:24,036 INFO:     Epoch: 72
2023-01-04 01:03:25,638 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5050453265508016, 'Total loss': 0.5050453265508016} | train loss {'Reaction outcome loss': 0.19057779138511052, 'Total loss': 0.19057779138511052}
2023-01-04 01:03:25,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:25,638 INFO:     Epoch: 73
2023-01-04 01:03:27,207 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4763660271962484, 'Total loss': 0.4763660271962484} | train loss {'Reaction outcome loss': 0.19013050770124804, 'Total loss': 0.19013050770124804}
2023-01-04 01:03:27,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:27,207 INFO:     Epoch: 74
2023-01-04 01:03:28,831 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48358989258607227, 'Total loss': 0.48358989258607227} | train loss {'Reaction outcome loss': 0.19170552201649774, 'Total loss': 0.19170552201649774}
2023-01-04 01:03:28,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:28,832 INFO:     Epoch: 75
2023-01-04 01:03:30,436 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4727818767229716, 'Total loss': 0.4727818767229716} | train loss {'Reaction outcome loss': 0.18806186224256613, 'Total loss': 0.18806186224256613}
2023-01-04 01:03:30,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:30,436 INFO:     Epoch: 76
2023-01-04 01:03:32,061 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4712784707546234, 'Total loss': 0.4712784707546234} | train loss {'Reaction outcome loss': 0.18973859881020624, 'Total loss': 0.18973859881020624}
2023-01-04 01:03:32,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:32,062 INFO:     Epoch: 77
2023-01-04 01:03:33,664 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5074989999334018, 'Total loss': 0.5074989999334018} | train loss {'Reaction outcome loss': 0.18850633499989225, 'Total loss': 0.18850633499989225}
2023-01-04 01:03:33,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:33,664 INFO:     Epoch: 78
2023-01-04 01:03:35,266 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49896305104096733, 'Total loss': 0.49896305104096733} | train loss {'Reaction outcome loss': 0.18728857858624268, 'Total loss': 0.18728857858624268}
2023-01-04 01:03:35,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:35,268 INFO:     Epoch: 79
2023-01-04 01:03:36,852 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5002292931079865, 'Total loss': 0.5002292931079865} | train loss {'Reaction outcome loss': 0.1840659338268132, 'Total loss': 0.1840659338268132}
2023-01-04 01:03:36,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:36,853 INFO:     Epoch: 80
2023-01-04 01:03:38,454 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.500804873307546, 'Total loss': 0.500804873307546} | train loss {'Reaction outcome loss': 0.18328997673002823, 'Total loss': 0.18328997673002823}
2023-01-04 01:03:38,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:38,454 INFO:     Epoch: 81
2023-01-04 01:03:40,056 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.495380229751269, 'Total loss': 0.495380229751269} | train loss {'Reaction outcome loss': 0.18346050232379876, 'Total loss': 0.18346050232379876}
2023-01-04 01:03:40,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:40,057 INFO:     Epoch: 82
2023-01-04 01:03:41,676 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4744631628195445, 'Total loss': 0.4744631628195445} | train loss {'Reaction outcome loss': 0.1813349621874761, 'Total loss': 0.1813349621874761}
2023-01-04 01:03:41,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:41,677 INFO:     Epoch: 83
2023-01-04 01:03:43,293 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5227567176024119, 'Total loss': 0.5227567176024119} | train loss {'Reaction outcome loss': 0.18352665257260256, 'Total loss': 0.18352665257260256}
2023-01-04 01:03:43,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:43,293 INFO:     Epoch: 84
2023-01-04 01:03:44,871 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47132387161254885, 'Total loss': 0.47132387161254885} | train loss {'Reaction outcome loss': 0.18164262351737986, 'Total loss': 0.18164262351737986}
2023-01-04 01:03:44,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:44,871 INFO:     Epoch: 85
2023-01-04 01:03:46,458 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4860532035430272, 'Total loss': 0.4860532035430272} | train loss {'Reaction outcome loss': 0.17996506938300624, 'Total loss': 0.17996506938300624}
2023-01-04 01:03:46,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:46,458 INFO:     Epoch: 86
2023-01-04 01:03:48,089 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47876230428616207, 'Total loss': 0.47876230428616207} | train loss {'Reaction outcome loss': 0.17926616360860395, 'Total loss': 0.17926616360860395}
2023-01-04 01:03:48,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:48,090 INFO:     Epoch: 87
2023-01-04 01:03:49,703 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5083766996860504, 'Total loss': 0.5083766996860504} | train loss {'Reaction outcome loss': 0.17894525741250505, 'Total loss': 0.17894525741250505}
2023-01-04 01:03:49,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:49,703 INFO:     Epoch: 88
2023-01-04 01:03:51,329 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49197751681009927, 'Total loss': 0.49197751681009927} | train loss {'Reaction outcome loss': 0.17616622084718103, 'Total loss': 0.17616622084718103}
2023-01-04 01:03:51,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:51,329 INFO:     Epoch: 89
2023-01-04 01:03:52,935 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47479315996170046, 'Total loss': 0.47479315996170046} | train loss {'Reaction outcome loss': 0.17771019586210646, 'Total loss': 0.17771019586210646}
2023-01-04 01:03:52,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:52,936 INFO:     Epoch: 90
2023-01-04 01:03:54,525 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47988149176041284, 'Total loss': 0.47988149176041284} | train loss {'Reaction outcome loss': 0.1782786793173005, 'Total loss': 0.1782786793173005}
2023-01-04 01:03:54,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:54,526 INFO:     Epoch: 91
2023-01-04 01:03:56,148 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4984276274840037, 'Total loss': 0.4984276274840037} | train loss {'Reaction outcome loss': 0.17607206927229135, 'Total loss': 0.17607206927229135}
2023-01-04 01:03:56,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:56,149 INFO:     Epoch: 92
2023-01-04 01:03:57,776 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4660729671518008, 'Total loss': 0.4660729671518008} | train loss {'Reaction outcome loss': 0.17473222074579675, 'Total loss': 0.17473222074579675}
2023-01-04 01:03:57,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:57,776 INFO:     Epoch: 93
2023-01-04 01:03:59,400 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47898825506369275, 'Total loss': 0.47898825506369275} | train loss {'Reaction outcome loss': 0.17529787439920197, 'Total loss': 0.17529787439920197}
2023-01-04 01:03:59,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:03:59,400 INFO:     Epoch: 94
2023-01-04 01:04:01,015 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5019807120164236, 'Total loss': 0.5019807120164236} | train loss {'Reaction outcome loss': 0.1733978617976719, 'Total loss': 0.1733978617976719}
2023-01-04 01:04:01,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:01,015 INFO:     Epoch: 95
2023-01-04 01:04:02,611 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48457817832628886, 'Total loss': 0.48457817832628886} | train loss {'Reaction outcome loss': 0.17128545152769836, 'Total loss': 0.17128545152769836}
2023-01-04 01:04:02,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:02,611 INFO:     Epoch: 96
2023-01-04 01:04:04,198 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.486103256046772, 'Total loss': 0.486103256046772} | train loss {'Reaction outcome loss': 0.17463047836070025, 'Total loss': 0.17463047836070025}
2023-01-04 01:04:04,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:04,198 INFO:     Epoch: 97
2023-01-04 01:04:05,798 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4817119538784027, 'Total loss': 0.4817119538784027} | train loss {'Reaction outcome loss': 0.17532276241142397, 'Total loss': 0.17532276241142397}
2023-01-04 01:04:05,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:05,799 INFO:     Epoch: 98
2023-01-04 01:04:07,400 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4981803397337596, 'Total loss': 0.4981803397337596} | train loss {'Reaction outcome loss': 0.17437919000641103, 'Total loss': 0.17437919000641103}
2023-01-04 01:04:07,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:07,400 INFO:     Epoch: 99
2023-01-04 01:04:08,999 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4913505256175995, 'Total loss': 0.4913505256175995} | train loss {'Reaction outcome loss': 0.17044425872742913, 'Total loss': 0.17044425872742913}
2023-01-04 01:04:08,999 INFO:     Best model found after epoch 28 of 100.
2023-01-04 01:04:09,000 INFO:   Done with stage: TRAINING
2023-01-04 01:04:09,000 INFO:   Starting stage: EVALUATION
2023-01-04 01:04:09,123 INFO:   Done with stage: EVALUATION
2023-01-04 01:04:09,123 INFO:   Leaving out SEQ value Fold_8
2023-01-04 01:04:09,135 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 01:04:09,135 INFO:   Starting stage: FEATURE SCALING
2023-01-04 01:04:09,786 INFO:   Done with stage: FEATURE SCALING
2023-01-04 01:04:09,786 INFO:   Starting stage: SCALING TARGETS
2023-01-04 01:04:09,856 INFO:   Done with stage: SCALING TARGETS
2023-01-04 01:04:09,856 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:04:09,856 INFO:     No hyperparam tuning for this model
2023-01-04 01:04:09,856 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:04:09,856 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 01:04:09,857 INFO:     None feature selector for col prot
2023-01-04 01:04:09,857 INFO:     None feature selector for col prot
2023-01-04 01:04:09,857 INFO:     None feature selector for col prot
2023-01-04 01:04:09,857 INFO:     None feature selector for col chem
2023-01-04 01:04:09,858 INFO:     None feature selector for col chem
2023-01-04 01:04:09,858 INFO:     None feature selector for col chem
2023-01-04 01:04:09,858 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 01:04:09,858 INFO:   Starting stage: BUILD MODEL
2023-01-04 01:04:09,859 INFO:     Number of params in model 70141
2023-01-04 01:04:09,862 INFO:   Done with stage: BUILD MODEL
2023-01-04 01:04:09,862 INFO:   Starting stage: TRAINING
2023-01-04 01:04:09,909 INFO:     Val loss before train {'Reaction outcome loss': 0.9562252978483836, 'Total loss': 0.9562252978483836}
2023-01-04 01:04:09,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:09,909 INFO:     Epoch: 0
2023-01-04 01:04:11,493 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5935120046138763, 'Total loss': 0.5935120046138763} | train loss {'Reaction outcome loss': 0.8535037284938868, 'Total loss': 0.8535037284938868}
2023-01-04 01:04:11,494 INFO:     Found new best model at epoch 0
2023-01-04 01:04:11,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:11,494 INFO:     Epoch: 1
2023-01-04 01:04:13,082 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.531273094813029, 'Total loss': 0.531273094813029} | train loss {'Reaction outcome loss': 0.5938880698560377, 'Total loss': 0.5938880698560377}
2023-01-04 01:04:13,083 INFO:     Found new best model at epoch 1
2023-01-04 01:04:13,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:13,084 INFO:     Epoch: 2
2023-01-04 01:04:14,682 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4954620579878489, 'Total loss': 0.4954620579878489} | train loss {'Reaction outcome loss': 0.5197807404646374, 'Total loss': 0.5197807404646374}
2023-01-04 01:04:14,682 INFO:     Found new best model at epoch 2
2023-01-04 01:04:14,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:14,683 INFO:     Epoch: 3
2023-01-04 01:04:16,315 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47193957964579264, 'Total loss': 0.47193957964579264} | train loss {'Reaction outcome loss': 0.4787191743239599, 'Total loss': 0.4787191743239599}
2023-01-04 01:04:16,315 INFO:     Found new best model at epoch 3
2023-01-04 01:04:16,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:16,316 INFO:     Epoch: 4
2023-01-04 01:04:17,924 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4633670628070831, 'Total loss': 0.4633670628070831} | train loss {'Reaction outcome loss': 0.4491702502169764, 'Total loss': 0.4491702502169764}
2023-01-04 01:04:17,924 INFO:     Found new best model at epoch 4
2023-01-04 01:04:17,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:17,925 INFO:     Epoch: 5
2023-01-04 01:04:19,530 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4442087928454081, 'Total loss': 0.4442087928454081} | train loss {'Reaction outcome loss': 0.4277355341704744, 'Total loss': 0.4277355341704744}
2023-01-04 01:04:19,530 INFO:     Found new best model at epoch 5
2023-01-04 01:04:19,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:19,531 INFO:     Epoch: 6
2023-01-04 01:04:21,106 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4398479541142782, 'Total loss': 0.4398479541142782} | train loss {'Reaction outcome loss': 0.412595919269517, 'Total loss': 0.412595919269517}
2023-01-04 01:04:21,106 INFO:     Found new best model at epoch 6
2023-01-04 01:04:21,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:21,107 INFO:     Epoch: 7
2023-01-04 01:04:22,708 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4209449390570323, 'Total loss': 0.4209449390570323} | train loss {'Reaction outcome loss': 0.3952782161614525, 'Total loss': 0.3952782161614525}
2023-01-04 01:04:22,708 INFO:     Found new best model at epoch 7
2023-01-04 01:04:22,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:22,709 INFO:     Epoch: 8
2023-01-04 01:04:24,308 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4141846110423406, 'Total loss': 0.4141846110423406} | train loss {'Reaction outcome loss': 0.38598760957106787, 'Total loss': 0.38598760957106787}
2023-01-04 01:04:24,308 INFO:     Found new best model at epoch 8
2023-01-04 01:04:24,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:24,309 INFO:     Epoch: 9
2023-01-04 01:04:25,910 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43357914686203003, 'Total loss': 0.43357914686203003} | train loss {'Reaction outcome loss': 0.3715865083227089, 'Total loss': 0.3715865083227089}
2023-01-04 01:04:25,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:25,911 INFO:     Epoch: 10
2023-01-04 01:04:27,511 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4234332005182902, 'Total loss': 0.4234332005182902} | train loss {'Reaction outcome loss': 0.3632736735126602, 'Total loss': 0.3632736735126602}
2023-01-04 01:04:27,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:27,511 INFO:     Epoch: 11
2023-01-04 01:04:29,096 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4171572784582774, 'Total loss': 0.4171572784582774} | train loss {'Reaction outcome loss': 0.3507985985881585, 'Total loss': 0.3507985985881585}
2023-01-04 01:04:29,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:29,096 INFO:     Epoch: 12
2023-01-04 01:04:30,679 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4089292764663696, 'Total loss': 0.4089292764663696} | train loss {'Reaction outcome loss': 0.34548278961209616, 'Total loss': 0.34548278961209616}
2023-01-04 01:04:30,679 INFO:     Found new best model at epoch 12
2023-01-04 01:04:30,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:30,680 INFO:     Epoch: 13
2023-01-04 01:04:32,280 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40559140195449195, 'Total loss': 0.40559140195449195} | train loss {'Reaction outcome loss': 0.3360322344550587, 'Total loss': 0.3360322344550587}
2023-01-04 01:04:32,280 INFO:     Found new best model at epoch 13
2023-01-04 01:04:32,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:32,281 INFO:     Epoch: 14
2023-01-04 01:04:33,880 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40993630488713584, 'Total loss': 0.40993630488713584} | train loss {'Reaction outcome loss': 0.327667215832304, 'Total loss': 0.327667215832304}
2023-01-04 01:04:33,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:33,880 INFO:     Epoch: 15
2023-01-04 01:04:35,480 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40675703982512157, 'Total loss': 0.40675703982512157} | train loss {'Reaction outcome loss': 0.3199030573779065, 'Total loss': 0.3199030573779065}
2023-01-04 01:04:35,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:35,481 INFO:     Epoch: 16
2023-01-04 01:04:37,082 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3906509886185328, 'Total loss': 0.3906509886185328} | train loss {'Reaction outcome loss': 0.31493485202535393, 'Total loss': 0.31493485202535393}
2023-01-04 01:04:37,083 INFO:     Found new best model at epoch 16
2023-01-04 01:04:37,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:37,084 INFO:     Epoch: 17
2023-01-04 01:04:38,262 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4121817300717036, 'Total loss': 0.4121817300717036} | train loss {'Reaction outcome loss': 0.30875634843154076, 'Total loss': 0.30875634843154076}
2023-01-04 01:04:38,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:38,262 INFO:     Epoch: 18
2023-01-04 01:04:39,317 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3823164771000544, 'Total loss': 0.3823164771000544} | train loss {'Reaction outcome loss': 0.30284067267545295, 'Total loss': 0.30284067267545295}
2023-01-04 01:04:39,317 INFO:     Found new best model at epoch 18
2023-01-04 01:04:39,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:39,318 INFO:     Epoch: 19
2023-01-04 01:04:40,372 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4032743195692698, 'Total loss': 0.4032743195692698} | train loss {'Reaction outcome loss': 0.2964894792824876, 'Total loss': 0.2964894792824876}
2023-01-04 01:04:40,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:40,373 INFO:     Epoch: 20
2023-01-04 01:04:41,425 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.37852547615766524, 'Total loss': 0.37852547615766524} | train loss {'Reaction outcome loss': 0.2922672906937582, 'Total loss': 0.2922672906937582}
2023-01-04 01:04:41,425 INFO:     Found new best model at epoch 20
2023-01-04 01:04:41,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:41,426 INFO:     Epoch: 21
2023-01-04 01:04:42,779 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40059723854064944, 'Total loss': 0.40059723854064944} | train loss {'Reaction outcome loss': 0.28698401607653723, 'Total loss': 0.28698401607653723}
2023-01-04 01:04:42,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:42,779 INFO:     Epoch: 22
2023-01-04 01:04:44,376 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38421036998430885, 'Total loss': 0.38421036998430885} | train loss {'Reaction outcome loss': 0.2824225243086849, 'Total loss': 0.2824225243086849}
2023-01-04 01:04:44,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:44,377 INFO:     Epoch: 23
2023-01-04 01:04:45,968 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3805335104465485, 'Total loss': 0.3805335104465485} | train loss {'Reaction outcome loss': 0.2792483207631843, 'Total loss': 0.2792483207631843}
2023-01-04 01:04:45,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:45,968 INFO:     Epoch: 24
2023-01-04 01:04:47,581 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39087850948174796, 'Total loss': 0.39087850948174796} | train loss {'Reaction outcome loss': 0.27208065345130245, 'Total loss': 0.27208065345130245}
2023-01-04 01:04:47,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:47,581 INFO:     Epoch: 25
2023-01-04 01:04:49,211 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3908772031466166, 'Total loss': 0.3908772031466166} | train loss {'Reaction outcome loss': 0.270938261563382, 'Total loss': 0.270938261563382}
2023-01-04 01:04:49,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:49,211 INFO:     Epoch: 26
2023-01-04 01:04:50,869 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.36874340772628783, 'Total loss': 0.36874340772628783} | train loss {'Reaction outcome loss': 0.2674969829592033, 'Total loss': 0.2674969829592033}
2023-01-04 01:04:50,869 INFO:     Found new best model at epoch 26
2023-01-04 01:04:50,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:50,871 INFO:     Epoch: 27
2023-01-04 01:04:52,466 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3659990280866623, 'Total loss': 0.3659990280866623} | train loss {'Reaction outcome loss': 0.26243030379395194, 'Total loss': 0.26243030379395194}
2023-01-04 01:04:52,466 INFO:     Found new best model at epoch 27
2023-01-04 01:04:52,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:52,467 INFO:     Epoch: 28
2023-01-04 01:04:54,088 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3774955083926519, 'Total loss': 0.3774955083926519} | train loss {'Reaction outcome loss': 0.2597485344574555, 'Total loss': 0.2597485344574555}
2023-01-04 01:04:54,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:54,088 INFO:     Epoch: 29
2023-01-04 01:04:55,708 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.389381010333697, 'Total loss': 0.389381010333697} | train loss {'Reaction outcome loss': 0.2574092417363656, 'Total loss': 0.2574092417363656}
2023-01-04 01:04:55,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:55,708 INFO:     Epoch: 30
2023-01-04 01:04:57,348 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40568327009677885, 'Total loss': 0.40568327009677885} | train loss {'Reaction outcome loss': 0.25297117383901824, 'Total loss': 0.25297117383901824}
2023-01-04 01:04:57,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:57,349 INFO:     Epoch: 31
2023-01-04 01:04:58,973 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38207051157951355, 'Total loss': 0.38207051157951355} | train loss {'Reaction outcome loss': 0.251680956702908, 'Total loss': 0.251680956702908}
2023-01-04 01:04:58,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:04:58,974 INFO:     Epoch: 32
2023-01-04 01:05:00,580 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3776739736398061, 'Total loss': 0.3776739736398061} | train loss {'Reaction outcome loss': 0.24808226180151913, 'Total loss': 0.24808226180151913}
2023-01-04 01:05:00,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:00,580 INFO:     Epoch: 33
2023-01-04 01:05:02,214 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3693616578976313, 'Total loss': 0.3693616578976313} | train loss {'Reaction outcome loss': 0.2458791378280316, 'Total loss': 0.2458791378280316}
2023-01-04 01:05:02,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:02,214 INFO:     Epoch: 34
2023-01-04 01:05:03,790 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.37558132807413735, 'Total loss': 0.37558132807413735} | train loss {'Reaction outcome loss': 0.23851283680015523, 'Total loss': 0.23851283680015523}
2023-01-04 01:05:03,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:03,790 INFO:     Epoch: 35
2023-01-04 01:05:05,427 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.37938026090463, 'Total loss': 0.37938026090463} | train loss {'Reaction outcome loss': 0.24070144510602692, 'Total loss': 0.24070144510602692}
2023-01-04 01:05:05,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:05,427 INFO:     Epoch: 36
2023-01-04 01:05:07,019 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37803540577491124, 'Total loss': 0.37803540577491124} | train loss {'Reaction outcome loss': 0.23733693061376307, 'Total loss': 0.23733693061376307}
2023-01-04 01:05:07,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:07,019 INFO:     Epoch: 37
2023-01-04 01:05:08,654 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37033484081427254, 'Total loss': 0.37033484081427254} | train loss {'Reaction outcome loss': 0.23558300669012516, 'Total loss': 0.23558300669012516}
2023-01-04 01:05:08,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:08,655 INFO:     Epoch: 38
2023-01-04 01:05:10,238 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3651786635319392, 'Total loss': 0.3651786635319392} | train loss {'Reaction outcome loss': 0.23332588180953415, 'Total loss': 0.23332588180953415}
2023-01-04 01:05:10,239 INFO:     Found new best model at epoch 38
2023-01-04 01:05:10,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:10,239 INFO:     Epoch: 39
2023-01-04 01:05:11,860 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4032425622145335, 'Total loss': 0.4032425622145335} | train loss {'Reaction outcome loss': 0.23023161321663255, 'Total loss': 0.23023161321663255}
2023-01-04 01:05:11,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:11,860 INFO:     Epoch: 40
2023-01-04 01:05:13,448 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39103566805521645, 'Total loss': 0.39103566805521645} | train loss {'Reaction outcome loss': 0.22660154994536824, 'Total loss': 0.22660154994536824}
2023-01-04 01:05:13,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:13,448 INFO:     Epoch: 41
2023-01-04 01:05:15,070 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39804331759611766, 'Total loss': 0.39804331759611766} | train loss {'Reaction outcome loss': 0.22493432544252503, 'Total loss': 0.22493432544252503}
2023-01-04 01:05:15,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:15,071 INFO:     Epoch: 42
2023-01-04 01:05:16,692 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3882571225365003, 'Total loss': 0.3882571225365003} | train loss {'Reaction outcome loss': 0.22188250693603542, 'Total loss': 0.22188250693603542}
2023-01-04 01:05:16,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:16,692 INFO:     Epoch: 43
2023-01-04 01:05:18,265 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3813515325387319, 'Total loss': 0.3813515325387319} | train loss {'Reaction outcome loss': 0.22052783896938127, 'Total loss': 0.22052783896938127}
2023-01-04 01:05:18,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:18,265 INFO:     Epoch: 44
2023-01-04 01:05:19,885 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.37816962202390036, 'Total loss': 0.37816962202390036} | train loss {'Reaction outcome loss': 0.21878990666799597, 'Total loss': 0.21878990666799597}
2023-01-04 01:05:19,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:19,886 INFO:     Epoch: 45
2023-01-04 01:05:21,496 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.36860238363345466, 'Total loss': 0.36860238363345466} | train loss {'Reaction outcome loss': 0.2168183668721669, 'Total loss': 0.2168183668721669}
2023-01-04 01:05:21,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:21,496 INFO:     Epoch: 46
2023-01-04 01:05:23,123 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.388846762975057, 'Total loss': 0.388846762975057} | train loss {'Reaction outcome loss': 0.21762673997922063, 'Total loss': 0.21762673997922063}
2023-01-04 01:05:23,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:23,123 INFO:     Epoch: 47
2023-01-04 01:05:24,760 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3964895913998286, 'Total loss': 0.3964895913998286} | train loss {'Reaction outcome loss': 0.21343467028186208, 'Total loss': 0.21343467028186208}
2023-01-04 01:05:24,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:24,760 INFO:     Epoch: 48
2023-01-04 01:05:26,379 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.37681108713150024, 'Total loss': 0.37681108713150024} | train loss {'Reaction outcome loss': 0.21118532730407663, 'Total loss': 0.21118532730407663}
2023-01-04 01:05:26,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:26,379 INFO:     Epoch: 49
2023-01-04 01:05:27,977 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.37810302476088203, 'Total loss': 0.37810302476088203} | train loss {'Reaction outcome loss': 0.21005006273031665, 'Total loss': 0.21005006273031665}
2023-01-04 01:05:27,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:27,978 INFO:     Epoch: 50
2023-01-04 01:05:29,579 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3774984141190847, 'Total loss': 0.3774984141190847} | train loss {'Reaction outcome loss': 0.20898689714929472, 'Total loss': 0.20898689714929472}
2023-01-04 01:05:29,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:29,580 INFO:     Epoch: 51
2023-01-04 01:05:31,171 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3825969099998474, 'Total loss': 0.3825969099998474} | train loss {'Reaction outcome loss': 0.20871527701454903, 'Total loss': 0.20871527701454903}
2023-01-04 01:05:31,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:31,171 INFO:     Epoch: 52
2023-01-04 01:05:32,804 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3714260364572207, 'Total loss': 0.3714260364572207} | train loss {'Reaction outcome loss': 0.2077484305894224, 'Total loss': 0.2077484305894224}
2023-01-04 01:05:32,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:32,804 INFO:     Epoch: 53
2023-01-04 01:05:34,403 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3806629627943039, 'Total loss': 0.3806629627943039} | train loss {'Reaction outcome loss': 0.2022826103123732, 'Total loss': 0.2022826103123732}
2023-01-04 01:05:34,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:34,403 INFO:     Epoch: 54
2023-01-04 01:05:36,027 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3828539123137792, 'Total loss': 0.3828539123137792} | train loss {'Reaction outcome loss': 0.20360360629453125, 'Total loss': 0.20360360629453125}
2023-01-04 01:05:36,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:36,027 INFO:     Epoch: 55
2023-01-04 01:05:37,606 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38804593483606975, 'Total loss': 0.38804593483606975} | train loss {'Reaction outcome loss': 0.20228824847199642, 'Total loss': 0.20228824847199642}
2023-01-04 01:05:37,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:37,606 INFO:     Epoch: 56
2023-01-04 01:05:39,222 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3771885931491852, 'Total loss': 0.3771885931491852} | train loss {'Reaction outcome loss': 0.19922921176502206, 'Total loss': 0.19922921176502206}
2023-01-04 01:05:39,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:39,222 INFO:     Epoch: 57
2023-01-04 01:05:40,849 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.37612757583459216, 'Total loss': 0.37612757583459216} | train loss {'Reaction outcome loss': 0.19966622474956383, 'Total loss': 0.19966622474956383}
2023-01-04 01:05:40,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:40,849 INFO:     Epoch: 58
2023-01-04 01:05:42,478 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38080866436163585, 'Total loss': 0.38080866436163585} | train loss {'Reaction outcome loss': 0.19747980042538918, 'Total loss': 0.19747980042538918}
2023-01-04 01:05:42,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:42,479 INFO:     Epoch: 59
2023-01-04 01:05:44,107 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38931049903233844, 'Total loss': 0.38931049903233844} | train loss {'Reaction outcome loss': 0.19816914646607228, 'Total loss': 0.19816914646607228}
2023-01-04 01:05:44,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:44,108 INFO:     Epoch: 60
2023-01-04 01:05:45,706 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.38389679888884226, 'Total loss': 0.38389679888884226} | train loss {'Reaction outcome loss': 0.19546485528188492, 'Total loss': 0.19546485528188492}
2023-01-04 01:05:45,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:45,706 INFO:     Epoch: 61
2023-01-04 01:05:47,339 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37996562918027244, 'Total loss': 0.37996562918027244} | train loss {'Reaction outcome loss': 0.19514233308982118, 'Total loss': 0.19514233308982118}
2023-01-04 01:05:47,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:47,339 INFO:     Epoch: 62
2023-01-04 01:05:48,948 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3687136540810267, 'Total loss': 0.3687136540810267} | train loss {'Reaction outcome loss': 0.1926531719736459, 'Total loss': 0.1926531719736459}
2023-01-04 01:05:48,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:48,948 INFO:     Epoch: 63
2023-01-04 01:05:50,586 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3855668726066748, 'Total loss': 0.3855668726066748} | train loss {'Reaction outcome loss': 0.19383304443089325, 'Total loss': 0.19383304443089325}
2023-01-04 01:05:50,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:50,587 INFO:     Epoch: 64
2023-01-04 01:05:52,221 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3850570827722549, 'Total loss': 0.3850570827722549} | train loss {'Reaction outcome loss': 0.19292319311158537, 'Total loss': 0.19292319311158537}
2023-01-04 01:05:52,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:52,222 INFO:     Epoch: 65
2023-01-04 01:05:53,852 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38329539994398754, 'Total loss': 0.38329539994398754} | train loss {'Reaction outcome loss': 0.18979534437536977, 'Total loss': 0.18979534437536977}
2023-01-04 01:05:53,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:53,852 INFO:     Epoch: 66
2023-01-04 01:05:55,436 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3820041378339132, 'Total loss': 0.3820041378339132} | train loss {'Reaction outcome loss': 0.19334261924942908, 'Total loss': 0.19334261924942908}
2023-01-04 01:05:55,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:55,437 INFO:     Epoch: 67
2023-01-04 01:05:57,066 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.37003989120324454, 'Total loss': 0.37003989120324454} | train loss {'Reaction outcome loss': 0.19070825173724645, 'Total loss': 0.19070825173724645}
2023-01-04 01:05:57,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:57,067 INFO:     Epoch: 68
2023-01-04 01:05:58,661 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3935054302215576, 'Total loss': 0.3935054302215576} | train loss {'Reaction outcome loss': 0.18892468729927223, 'Total loss': 0.18892468729927223}
2023-01-04 01:05:58,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:05:58,662 INFO:     Epoch: 69
2023-01-04 01:06:00,268 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39577126999696094, 'Total loss': 0.39577126999696094} | train loss {'Reaction outcome loss': 0.18477987656739644, 'Total loss': 0.18477987656739644}
2023-01-04 01:06:00,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:00,268 INFO:     Epoch: 70
2023-01-04 01:06:01,872 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3771778404712677, 'Total loss': 0.3771778404712677} | train loss {'Reaction outcome loss': 0.1868840229667266, 'Total loss': 0.1868840229667266}
2023-01-04 01:06:01,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:01,872 INFO:     Epoch: 71
2023-01-04 01:06:03,460 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.428575344880422, 'Total loss': 0.428575344880422} | train loss {'Reaction outcome loss': 0.18563109546200462, 'Total loss': 0.18563109546200462}
2023-01-04 01:06:03,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:03,461 INFO:     Epoch: 72
2023-01-04 01:06:05,049 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.376927109559377, 'Total loss': 0.376927109559377} | train loss {'Reaction outcome loss': 0.18531415377498103, 'Total loss': 0.18531415377498103}
2023-01-04 01:06:05,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:05,049 INFO:     Epoch: 73
2023-01-04 01:06:06,659 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3982096423705419, 'Total loss': 0.3982096423705419} | train loss {'Reaction outcome loss': 0.18321745285918997, 'Total loss': 0.18321745285918997}
2023-01-04 01:06:06,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:06,659 INFO:     Epoch: 74
2023-01-04 01:06:08,265 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3831960678100586, 'Total loss': 0.3831960678100586} | train loss {'Reaction outcome loss': 0.1837395318659419, 'Total loss': 0.1837395318659419}
2023-01-04 01:06:08,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:08,266 INFO:     Epoch: 75
2023-01-04 01:06:09,871 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4049850185712179, 'Total loss': 0.4049850185712179} | train loss {'Reaction outcome loss': 0.18472721817691404, 'Total loss': 0.18472721817691404}
2023-01-04 01:06:09,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:09,871 INFO:     Epoch: 76
2023-01-04 01:06:11,476 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40171218613783516, 'Total loss': 0.40171218613783516} | train loss {'Reaction outcome loss': 0.17871010615507188, 'Total loss': 0.17871010615507188}
2023-01-04 01:06:11,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:11,476 INFO:     Epoch: 77
2023-01-04 01:06:13,082 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3728967939813932, 'Total loss': 0.3728967939813932} | train loss {'Reaction outcome loss': 0.18065178068186616, 'Total loss': 0.18065178068186616}
2023-01-04 01:06:13,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:13,082 INFO:     Epoch: 78
2023-01-04 01:06:14,681 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3734024792909622, 'Total loss': 0.3734024792909622} | train loss {'Reaction outcome loss': 0.1815205239203325, 'Total loss': 0.1815205239203325}
2023-01-04 01:06:14,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:14,682 INFO:     Epoch: 79
2023-01-04 01:06:16,289 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.38970695734024047, 'Total loss': 0.38970695734024047} | train loss {'Reaction outcome loss': 0.18013215962030826, 'Total loss': 0.18013215962030826}
2023-01-04 01:06:16,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:16,289 INFO:     Epoch: 80
2023-01-04 01:06:17,909 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.380627778172493, 'Total loss': 0.380627778172493} | train loss {'Reaction outcome loss': 0.18020968448491734, 'Total loss': 0.18020968448491734}
2023-01-04 01:06:17,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:17,909 INFO:     Epoch: 81
2023-01-04 01:06:19,513 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.37901244262854256, 'Total loss': 0.37901244262854256} | train loss {'Reaction outcome loss': 0.17658290755850958, 'Total loss': 0.17658290755850958}
2023-01-04 01:06:19,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:19,513 INFO:     Epoch: 82
2023-01-04 01:06:21,095 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3901310662428538, 'Total loss': 0.3901310662428538} | train loss {'Reaction outcome loss': 0.17696716675252422, 'Total loss': 0.17696716675252422}
2023-01-04 01:06:21,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:21,096 INFO:     Epoch: 83
2023-01-04 01:06:22,686 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3896808971961339, 'Total loss': 0.3896808971961339} | train loss {'Reaction outcome loss': 0.17549605584209146, 'Total loss': 0.17549605584209146}
2023-01-04 01:06:22,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:22,687 INFO:     Epoch: 84
2023-01-04 01:06:24,271 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40102489590644835, 'Total loss': 0.40102489590644835} | train loss {'Reaction outcome loss': 0.17661966384802055, 'Total loss': 0.17661966384802055}
2023-01-04 01:06:24,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:24,271 INFO:     Epoch: 85
2023-01-04 01:06:25,865 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3750100865960121, 'Total loss': 0.3750100865960121} | train loss {'Reaction outcome loss': 0.17649927335229806, 'Total loss': 0.17649927335229806}
2023-01-04 01:06:25,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:25,865 INFO:     Epoch: 86
2023-01-04 01:06:27,467 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4086320439974467, 'Total loss': 0.4086320439974467} | train loss {'Reaction outcome loss': 0.17490047085290567, 'Total loss': 0.17490047085290567}
2023-01-04 01:06:27,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:27,467 INFO:     Epoch: 87
2023-01-04 01:06:29,068 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.384466952085495, 'Total loss': 0.384466952085495} | train loss {'Reaction outcome loss': 0.17628427091246263, 'Total loss': 0.17628427091246263}
2023-01-04 01:06:29,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:29,068 INFO:     Epoch: 88
2023-01-04 01:06:30,659 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3934165934721629, 'Total loss': 0.3934165934721629} | train loss {'Reaction outcome loss': 0.17309765718097292, 'Total loss': 0.17309765718097292}
2023-01-04 01:06:30,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:30,659 INFO:     Epoch: 89
2023-01-04 01:06:32,285 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3758035063743591, 'Total loss': 0.3758035063743591} | train loss {'Reaction outcome loss': 0.17331559409384048, 'Total loss': 0.17331559409384048}
2023-01-04 01:06:32,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:32,286 INFO:     Epoch: 90
2023-01-04 01:06:33,883 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3931945870320002, 'Total loss': 0.3931945870320002} | train loss {'Reaction outcome loss': 0.17345288331327885, 'Total loss': 0.17345288331327885}
2023-01-04 01:06:33,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:33,884 INFO:     Epoch: 91
2023-01-04 01:06:35,484 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3941991200049718, 'Total loss': 0.3941991200049718} | train loss {'Reaction outcome loss': 0.17343969833415124, 'Total loss': 0.17343969833415124}
2023-01-04 01:06:35,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:35,485 INFO:     Epoch: 92
2023-01-04 01:06:37,086 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37707761526107786, 'Total loss': 0.37707761526107786} | train loss {'Reaction outcome loss': 0.17139150394590752, 'Total loss': 0.17139150394590752}
2023-01-04 01:06:37,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:37,086 INFO:     Epoch: 93
2023-01-04 01:06:38,687 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3802108446756999, 'Total loss': 0.3802108446756999} | train loss {'Reaction outcome loss': 0.1717791755411384, 'Total loss': 0.1717791755411384}
2023-01-04 01:06:38,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:38,687 INFO:     Epoch: 94
2023-01-04 01:06:40,260 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3952658424774806, 'Total loss': 0.3952658424774806} | train loss {'Reaction outcome loss': 0.17082840061682655, 'Total loss': 0.17082840061682655}
2023-01-04 01:06:40,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:40,260 INFO:     Epoch: 95
2023-01-04 01:06:41,887 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3841908444960912, 'Total loss': 0.3841908444960912} | train loss {'Reaction outcome loss': 0.1696499271943681, 'Total loss': 0.1696499271943681}
2023-01-04 01:06:41,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:41,887 INFO:     Epoch: 96
2023-01-04 01:06:43,495 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40732048948605853, 'Total loss': 0.40732048948605853} | train loss {'Reaction outcome loss': 0.170770018134562, 'Total loss': 0.170770018134562}
2023-01-04 01:06:43,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:43,496 INFO:     Epoch: 97
2023-01-04 01:06:45,128 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40203914244969685, 'Total loss': 0.40203914244969685} | train loss {'Reaction outcome loss': 0.16979112197722337, 'Total loss': 0.16979112197722337}
2023-01-04 01:06:45,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:45,130 INFO:     Epoch: 98
2023-01-04 01:06:46,728 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4049370398124059, 'Total loss': 0.4049370398124059} | train loss {'Reaction outcome loss': 0.17243516597130237, 'Total loss': 0.17243516597130237}
2023-01-04 01:06:46,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:46,729 INFO:     Epoch: 99
2023-01-04 01:06:48,317 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4119943459828695, 'Total loss': 0.4119943459828695} | train loss {'Reaction outcome loss': 0.16905170212422468, 'Total loss': 0.16905170212422468}
2023-01-04 01:06:48,317 INFO:     Best model found after epoch 39 of 100.
2023-01-04 01:06:48,317 INFO:   Done with stage: TRAINING
2023-01-04 01:06:48,317 INFO:   Starting stage: EVALUATION
2023-01-04 01:06:48,442 INFO:   Done with stage: EVALUATION
2023-01-04 01:06:48,442 INFO:   Leaving out SEQ value Fold_9
2023-01-04 01:06:48,455 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 01:06:48,455 INFO:   Starting stage: FEATURE SCALING
2023-01-04 01:06:49,109 INFO:   Done with stage: FEATURE SCALING
2023-01-04 01:06:49,109 INFO:   Starting stage: SCALING TARGETS
2023-01-04 01:06:49,180 INFO:   Done with stage: SCALING TARGETS
2023-01-04 01:06:49,180 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:06:49,180 INFO:     No hyperparam tuning for this model
2023-01-04 01:06:49,180 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 01:06:49,180 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 01:06:49,181 INFO:     None feature selector for col prot
2023-01-04 01:06:49,181 INFO:     None feature selector for col prot
2023-01-04 01:06:49,181 INFO:     None feature selector for col prot
2023-01-04 01:06:49,182 INFO:     None feature selector for col chem
2023-01-04 01:06:49,182 INFO:     None feature selector for col chem
2023-01-04 01:06:49,182 INFO:     None feature selector for col chem
2023-01-04 01:06:49,182 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 01:06:49,182 INFO:   Starting stage: BUILD MODEL
2023-01-04 01:06:49,183 INFO:     Number of params in model 70141
2023-01-04 01:06:49,186 INFO:   Done with stage: BUILD MODEL
2023-01-04 01:06:49,187 INFO:   Starting stage: TRAINING
2023-01-04 01:06:49,232 INFO:     Val loss before train {'Reaction outcome loss': 0.9823169668515523, 'Total loss': 0.9823169668515523}
2023-01-04 01:06:49,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:49,232 INFO:     Epoch: 0
2023-01-04 01:06:50,838 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6084118068218232, 'Total loss': 0.6084118068218232} | train loss {'Reaction outcome loss': 0.8713784729656966, 'Total loss': 0.8713784729656966}
2023-01-04 01:06:50,839 INFO:     Found new best model at epoch 0
2023-01-04 01:06:50,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:50,839 INFO:     Epoch: 1
2023-01-04 01:06:52,468 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4908242960770925, 'Total loss': 0.4908242960770925} | train loss {'Reaction outcome loss': 0.6202276128865576, 'Total loss': 0.6202276128865576}
2023-01-04 01:06:52,469 INFO:     Found new best model at epoch 1
2023-01-04 01:06:52,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:52,470 INFO:     Epoch: 2
2023-01-04 01:06:54,094 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45114288131395974, 'Total loss': 0.45114288131395974} | train loss {'Reaction outcome loss': 0.5469905127272637, 'Total loss': 0.5469905127272637}
2023-01-04 01:06:54,094 INFO:     Found new best model at epoch 2
2023-01-04 01:06:54,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:54,095 INFO:     Epoch: 3
2023-01-04 01:06:55,726 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4398952126502991, 'Total loss': 0.4398952126502991} | train loss {'Reaction outcome loss': 0.5114334511800088, 'Total loss': 0.5114334511800088}
2023-01-04 01:06:55,726 INFO:     Found new best model at epoch 3
2023-01-04 01:06:55,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:55,727 INFO:     Epoch: 4
2023-01-04 01:06:57,324 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4234196732441584, 'Total loss': 0.4234196732441584} | train loss {'Reaction outcome loss': 0.49063528723258903, 'Total loss': 0.49063528723258903}
2023-01-04 01:06:57,324 INFO:     Found new best model at epoch 4
2023-01-04 01:06:57,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:57,325 INFO:     Epoch: 5
2023-01-04 01:06:58,950 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4118646631638209, 'Total loss': 0.4118646631638209} | train loss {'Reaction outcome loss': 0.4628288410604, 'Total loss': 0.4628288410604}
2023-01-04 01:06:58,950 INFO:     Found new best model at epoch 5
2023-01-04 01:06:58,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:06:58,951 INFO:     Epoch: 6
2023-01-04 01:07:00,552 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3871360242366791, 'Total loss': 0.3871360242366791} | train loss {'Reaction outcome loss': 0.44483030641761917, 'Total loss': 0.44483030641761917}
2023-01-04 01:07:00,552 INFO:     Found new best model at epoch 6
2023-01-04 01:07:00,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:00,553 INFO:     Epoch: 7
2023-01-04 01:07:02,171 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.39347080190976463, 'Total loss': 0.39347080190976463} | train loss {'Reaction outcome loss': 0.4367003756156866, 'Total loss': 0.4367003756156866}
2023-01-04 01:07:02,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:02,172 INFO:     Epoch: 8
2023-01-04 01:07:03,792 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.36936679581801096, 'Total loss': 0.36936679581801096} | train loss {'Reaction outcome loss': 0.423132787094168, 'Total loss': 0.423132787094168}
2023-01-04 01:07:03,792 INFO:     Found new best model at epoch 8
2023-01-04 01:07:03,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:03,793 INFO:     Epoch: 9
2023-01-04 01:07:05,403 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.36686555047829944, 'Total loss': 0.36686555047829944} | train loss {'Reaction outcome loss': 0.40679427890943876, 'Total loss': 0.40679427890943876}
2023-01-04 01:07:05,404 INFO:     Found new best model at epoch 9
2023-01-04 01:07:05,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:05,405 INFO:     Epoch: 10
2023-01-04 01:07:06,976 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3604161103566488, 'Total loss': 0.3604161103566488} | train loss {'Reaction outcome loss': 0.39432349988677795, 'Total loss': 0.39432349988677795}
2023-01-04 01:07:06,976 INFO:     Found new best model at epoch 10
2023-01-04 01:07:06,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:06,977 INFO:     Epoch: 11
2023-01-04 01:07:08,564 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3586930592854818, 'Total loss': 0.3586930592854818} | train loss {'Reaction outcome loss': 0.3868989814359668, 'Total loss': 0.3868989814359668}
2023-01-04 01:07:08,564 INFO:     Found new best model at epoch 11
2023-01-04 01:07:08,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:08,565 INFO:     Epoch: 12
2023-01-04 01:07:10,171 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.35274312893549603, 'Total loss': 0.35274312893549603} | train loss {'Reaction outcome loss': 0.3803254330355296, 'Total loss': 0.3803254330355296}
2023-01-04 01:07:10,171 INFO:     Found new best model at epoch 12
2023-01-04 01:07:10,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:10,172 INFO:     Epoch: 13
2023-01-04 01:07:11,798 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.35512568056583405, 'Total loss': 0.35512568056583405} | train loss {'Reaction outcome loss': 0.36933160886384436, 'Total loss': 0.36933160886384436}
2023-01-04 01:07:11,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:11,799 INFO:     Epoch: 14
2023-01-04 01:07:13,402 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3531635642051697, 'Total loss': 0.3531635642051697} | train loss {'Reaction outcome loss': 0.3643036471220894, 'Total loss': 0.3643036471220894}
2023-01-04 01:07:13,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:13,402 INFO:     Epoch: 15
2023-01-04 01:07:14,981 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.34690744082132974, 'Total loss': 0.34690744082132974} | train loss {'Reaction outcome loss': 0.3584241343770122, 'Total loss': 0.3584241343770122}
2023-01-04 01:07:14,981 INFO:     Found new best model at epoch 15
2023-01-04 01:07:14,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:14,982 INFO:     Epoch: 16
2023-01-04 01:07:16,598 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.33943511148293815, 'Total loss': 0.33943511148293815} | train loss {'Reaction outcome loss': 0.35156386660115013, 'Total loss': 0.35156386660115013}
2023-01-04 01:07:16,600 INFO:     Found new best model at epoch 16
2023-01-04 01:07:16,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:16,600 INFO:     Epoch: 17
2023-01-04 01:07:18,205 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3415348211924235, 'Total loss': 0.3415348211924235} | train loss {'Reaction outcome loss': 0.3467700404530067, 'Total loss': 0.3467700404530067}
2023-01-04 01:07:18,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:18,206 INFO:     Epoch: 18
2023-01-04 01:07:19,839 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3420901546875636, 'Total loss': 0.3420901546875636} | train loss {'Reaction outcome loss': 0.3400982713083858, 'Total loss': 0.3400982713083858}
2023-01-04 01:07:19,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:19,839 INFO:     Epoch: 19
2023-01-04 01:07:21,426 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.35150764683882396, 'Total loss': 0.35150764683882396} | train loss {'Reaction outcome loss': 0.33428487891628256, 'Total loss': 0.33428487891628256}
2023-01-04 01:07:21,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:21,427 INFO:     Epoch: 20
2023-01-04 01:07:23,047 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.34839729567368827, 'Total loss': 0.34839729567368827} | train loss {'Reaction outcome loss': 0.3314519978486477, 'Total loss': 0.3314519978486477}
2023-01-04 01:07:23,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:23,048 INFO:     Epoch: 21
2023-01-04 01:07:24,629 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3316555420557658, 'Total loss': 0.3316555420557658} | train loss {'Reaction outcome loss': 0.32370022979212343, 'Total loss': 0.32370022979212343}
2023-01-04 01:07:24,629 INFO:     Found new best model at epoch 21
2023-01-04 01:07:24,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:24,630 INFO:     Epoch: 22
2023-01-04 01:07:26,241 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.351262961824735, 'Total loss': 0.351262961824735} | train loss {'Reaction outcome loss': 0.32075645406460523, 'Total loss': 0.32075645406460523}
2023-01-04 01:07:26,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:26,241 INFO:     Epoch: 23
2023-01-04 01:07:27,851 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3395956347386042, 'Total loss': 0.3395956347386042} | train loss {'Reaction outcome loss': 0.314148990329409, 'Total loss': 0.314148990329409}
2023-01-04 01:07:27,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:27,851 INFO:     Epoch: 24
2023-01-04 01:07:29,440 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.33000800510247547, 'Total loss': 0.33000800510247547} | train loss {'Reaction outcome loss': 0.3086073835231904, 'Total loss': 0.3086073835231904}
2023-01-04 01:07:29,441 INFO:     Found new best model at epoch 24
2023-01-04 01:07:29,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:29,441 INFO:     Epoch: 25
2023-01-04 01:07:31,028 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.32827693919340767, 'Total loss': 0.32827693919340767} | train loss {'Reaction outcome loss': 0.30619320420690044, 'Total loss': 0.30619320420690044}
2023-01-04 01:07:31,029 INFO:     Found new best model at epoch 25
2023-01-04 01:07:31,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:31,029 INFO:     Epoch: 26
2023-01-04 01:07:32,661 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.33493265211582185, 'Total loss': 0.33493265211582185} | train loss {'Reaction outcome loss': 0.2997827135782311, 'Total loss': 0.2997827135782311}
2023-01-04 01:07:32,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:32,661 INFO:     Epoch: 27
2023-01-04 01:07:34,243 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3573045919338862, 'Total loss': 0.3573045919338862} | train loss {'Reaction outcome loss': 0.3095281047719544, 'Total loss': 0.3095281047719544}
2023-01-04 01:07:34,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:34,244 INFO:     Epoch: 28
2023-01-04 01:07:35,831 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3281171133120855, 'Total loss': 0.3281171133120855} | train loss {'Reaction outcome loss': 0.3144162420075441, 'Total loss': 0.3144162420075441}
2023-01-04 01:07:35,831 INFO:     Found new best model at epoch 28
2023-01-04 01:07:35,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:35,832 INFO:     Epoch: 29
2023-01-04 01:07:37,456 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.33465517063935596, 'Total loss': 0.33465517063935596} | train loss {'Reaction outcome loss': 0.2989617814782305, 'Total loss': 0.2989617814782305}
2023-01-04 01:07:37,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:37,456 INFO:     Epoch: 30
2023-01-04 01:07:39,090 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.36010348002115883, 'Total loss': 0.36010348002115883} | train loss {'Reaction outcome loss': 0.28916956304127106, 'Total loss': 0.28916956304127106}
2023-01-04 01:07:39,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:39,090 INFO:     Epoch: 31
2023-01-04 01:07:40,723 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3358431994915009, 'Total loss': 0.3358431994915009} | train loss {'Reaction outcome loss': 0.2796104681488098, 'Total loss': 0.2796104681488098}
2023-01-04 01:07:40,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:40,724 INFO:     Epoch: 32
2023-01-04 01:07:42,307 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.32614775200684865, 'Total loss': 0.32614775200684865} | train loss {'Reaction outcome loss': 0.27738040993732493, 'Total loss': 0.27738040993732493}
2023-01-04 01:07:42,307 INFO:     Found new best model at epoch 32
2023-01-04 01:07:42,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:42,308 INFO:     Epoch: 33
2023-01-04 01:07:43,929 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3279674639304479, 'Total loss': 0.3279674639304479} | train loss {'Reaction outcome loss': 0.27648657946817856, 'Total loss': 0.27648657946817856}
2023-01-04 01:07:43,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:43,929 INFO:     Epoch: 34
2023-01-04 01:07:45,509 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.33543799618879955, 'Total loss': 0.33543799618879955} | train loss {'Reaction outcome loss': 0.2743425223136159, 'Total loss': 0.2743425223136159}
2023-01-04 01:07:45,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:45,510 INFO:     Epoch: 35
2023-01-04 01:07:47,127 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.32692367484172186, 'Total loss': 0.32692367484172186} | train loss {'Reaction outcome loss': 0.26939405339425837, 'Total loss': 0.26939405339425837}
2023-01-04 01:07:47,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:47,128 INFO:     Epoch: 36
2023-01-04 01:07:48,763 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.33227288027604424, 'Total loss': 0.33227288027604424} | train loss {'Reaction outcome loss': 0.2667933338936722, 'Total loss': 0.2667933338936722}
2023-01-04 01:07:48,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:48,763 INFO:     Epoch: 37
2023-01-04 01:07:50,368 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.35461020668347676, 'Total loss': 0.35461020668347676} | train loss {'Reaction outcome loss': 0.26354969782540505, 'Total loss': 0.26354969782540505}
2023-01-04 01:07:50,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:50,369 INFO:     Epoch: 38
2023-01-04 01:07:51,954 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3286183799306552, 'Total loss': 0.3286183799306552} | train loss {'Reaction outcome loss': 0.2594346183152242, 'Total loss': 0.2594346183152242}
2023-01-04 01:07:51,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:51,955 INFO:     Epoch: 39
2023-01-04 01:07:53,550 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3454825838406881, 'Total loss': 0.3454825838406881} | train loss {'Reaction outcome loss': 0.2564431148466479, 'Total loss': 0.2564431148466479}
2023-01-04 01:07:53,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:53,551 INFO:     Epoch: 40
2023-01-04 01:07:55,126 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.34397589464982353, 'Total loss': 0.34397589464982353} | train loss {'Reaction outcome loss': 0.2533756977190142, 'Total loss': 0.2533756977190142}
2023-01-04 01:07:55,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:55,127 INFO:     Epoch: 41
2023-01-04 01:07:56,727 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3383604814608892, 'Total loss': 0.3383604814608892} | train loss {'Reaction outcome loss': 0.25831038037827914, 'Total loss': 0.25831038037827914}
2023-01-04 01:07:56,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:56,727 INFO:     Epoch: 42
2023-01-04 01:07:58,342 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.33434049089749657, 'Total loss': 0.33434049089749657} | train loss {'Reaction outcome loss': 0.2607325645858773, 'Total loss': 0.2607325645858773}
2023-01-04 01:07:58,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:58,343 INFO:     Epoch: 43
2023-01-04 01:07:59,920 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.33249311049779257, 'Total loss': 0.33249311049779257} | train loss {'Reaction outcome loss': 0.24997154453961665, 'Total loss': 0.24997154453961665}
2023-01-04 01:07:59,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:07:59,920 INFO:     Epoch: 44
2023-01-04 01:08:01,530 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3727040022611618, 'Total loss': 0.3727040022611618} | train loss {'Reaction outcome loss': 0.24794892103249289, 'Total loss': 0.24794892103249289}
2023-01-04 01:08:01,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:01,530 INFO:     Epoch: 45
2023-01-04 01:08:03,109 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.36582684020201367, 'Total loss': 0.36582684020201367} | train loss {'Reaction outcome loss': 0.24489122646480319, 'Total loss': 0.24489122646480319}
2023-01-04 01:08:03,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:03,109 INFO:     Epoch: 46
2023-01-04 01:08:04,714 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.33790811002254484, 'Total loss': 0.33790811002254484} | train loss {'Reaction outcome loss': 0.24088982289549019, 'Total loss': 0.24088982289549019}
2023-01-04 01:08:04,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:04,714 INFO:     Epoch: 47
2023-01-04 01:08:06,329 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.34917491575082144, 'Total loss': 0.34917491575082144} | train loss {'Reaction outcome loss': 0.24147005422391754, 'Total loss': 0.24147005422391754}
2023-01-04 01:08:06,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:06,330 INFO:     Epoch: 48
2023-01-04 01:08:07,946 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3264231562614441, 'Total loss': 0.3264231562614441} | train loss {'Reaction outcome loss': 0.2434924056443919, 'Total loss': 0.2434924056443919}
2023-01-04 01:08:07,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:07,947 INFO:     Epoch: 49
2023-01-04 01:08:09,527 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3469141900539398, 'Total loss': 0.3469141900539398} | train loss {'Reaction outcome loss': 0.2352133982581174, 'Total loss': 0.2352133982581174}
2023-01-04 01:08:09,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:09,527 INFO:     Epoch: 50
2023-01-04 01:08:11,156 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.34199319084485374, 'Total loss': 0.34199319084485374} | train loss {'Reaction outcome loss': 0.23155129531158414, 'Total loss': 0.23155129531158414}
2023-01-04 01:08:11,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:11,157 INFO:     Epoch: 51
2023-01-04 01:08:12,747 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.34009419977664945, 'Total loss': 0.34009419977664945} | train loss {'Reaction outcome loss': 0.23138905890439088, 'Total loss': 0.23138905890439088}
2023-01-04 01:08:12,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:12,747 INFO:     Epoch: 52
2023-01-04 01:08:14,356 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3490360299746195, 'Total loss': 0.3490360299746195} | train loss {'Reaction outcome loss': 0.2383173357533372, 'Total loss': 0.2383173357533372}
2023-01-04 01:08:14,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:14,357 INFO:     Epoch: 53
2023-01-04 01:08:15,959 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3432360053062439, 'Total loss': 0.3432360053062439} | train loss {'Reaction outcome loss': 0.23628743614012754, 'Total loss': 0.23628743614012754}
2023-01-04 01:08:15,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:15,959 INFO:     Epoch: 54
2023-01-04 01:08:17,562 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.36168912748495735, 'Total loss': 0.36168912748495735} | train loss {'Reaction outcome loss': 0.22855680811124435, 'Total loss': 0.22855680811124435}
2023-01-04 01:08:17,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:17,562 INFO:     Epoch: 55
2023-01-04 01:08:19,135 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.35826965868473054, 'Total loss': 0.35826965868473054} | train loss {'Reaction outcome loss': 0.22566663575918833, 'Total loss': 0.22566663575918833}
2023-01-04 01:08:19,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:19,135 INFO:     Epoch: 56
2023-01-04 01:08:20,756 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.34676701327164966, 'Total loss': 0.34676701327164966} | train loss {'Reaction outcome loss': 0.22436362030102697, 'Total loss': 0.22436362030102697}
2023-01-04 01:08:20,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:20,756 INFO:     Epoch: 57
2023-01-04 01:08:22,333 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3485232909520467, 'Total loss': 0.3485232909520467} | train loss {'Reaction outcome loss': 0.22268710511464937, 'Total loss': 0.22268710511464937}
2023-01-04 01:08:22,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:22,334 INFO:     Epoch: 58
2023-01-04 01:08:23,935 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.35688582559426624, 'Total loss': 0.35688582559426624} | train loss {'Reaction outcome loss': 0.22114379707480183, 'Total loss': 0.22114379707480183}
2023-01-04 01:08:23,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:23,935 INFO:     Epoch: 59
2023-01-04 01:08:25,538 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.34832890977462133, 'Total loss': 0.34832890977462133} | train loss {'Reaction outcome loss': 0.21784743587773267, 'Total loss': 0.21784743587773267}
2023-01-04 01:08:25,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:25,538 INFO:     Epoch: 60
2023-01-04 01:08:27,120 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3542791118224462, 'Total loss': 0.3542791118224462} | train loss {'Reaction outcome loss': 0.22934921650027018, 'Total loss': 0.22934921650027018}
2023-01-04 01:08:27,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:27,120 INFO:     Epoch: 61
2023-01-04 01:08:28,741 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3589733829100927, 'Total loss': 0.3589733829100927} | train loss {'Reaction outcome loss': 0.23558959103040938, 'Total loss': 0.23558959103040938}
2023-01-04 01:08:28,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:28,742 INFO:     Epoch: 62
2023-01-04 01:08:30,339 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3434571365515391, 'Total loss': 0.3434571365515391} | train loss {'Reaction outcome loss': 0.2224656874988822, 'Total loss': 0.2224656874988822}
2023-01-04 01:08:30,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:30,339 INFO:     Epoch: 63
2023-01-04 01:08:31,964 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3570362548033396, 'Total loss': 0.3570362548033396} | train loss {'Reaction outcome loss': 0.21183395251442771, 'Total loss': 0.21183395251442771}
2023-01-04 01:08:31,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:31,965 INFO:     Epoch: 64
2023-01-04 01:08:33,579 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3446706891059875, 'Total loss': 0.3446706891059875} | train loss {'Reaction outcome loss': 0.21124654155278552, 'Total loss': 0.21124654155278552}
2023-01-04 01:08:33,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:33,579 INFO:     Epoch: 65
2023-01-04 01:08:35,204 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3709096312522888, 'Total loss': 0.3709096312522888} | train loss {'Reaction outcome loss': 0.20992035353422997, 'Total loss': 0.20992035353422997}
2023-01-04 01:08:35,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:35,204 INFO:     Epoch: 66
2023-01-04 01:08:36,803 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3694745272397995, 'Total loss': 0.3694745272397995} | train loss {'Reaction outcome loss': 0.20680456067456185, 'Total loss': 0.20680456067456185}
2023-01-04 01:08:36,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:36,803 INFO:     Epoch: 67
2023-01-04 01:08:38,438 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3535371740659078, 'Total loss': 0.3535371740659078} | train loss {'Reaction outcome loss': 0.20691506629404816, 'Total loss': 0.20691506629404816}
2023-01-04 01:08:38,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:38,438 INFO:     Epoch: 68
2023-01-04 01:08:40,031 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.375056728720665, 'Total loss': 0.375056728720665} | train loss {'Reaction outcome loss': 0.2109765083718019, 'Total loss': 0.2109765083718019}
2023-01-04 01:08:40,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:40,031 INFO:     Epoch: 69
2023-01-04 01:08:41,634 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3641152292490005, 'Total loss': 0.3641152292490005} | train loss {'Reaction outcome loss': 0.20872967789435518, 'Total loss': 0.20872967789435518}
2023-01-04 01:08:41,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:41,635 INFO:     Epoch: 70
2023-01-04 01:08:43,237 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3704593062400818, 'Total loss': 0.3704593062400818} | train loss {'Reaction outcome loss': 0.20514453000108968, 'Total loss': 0.20514453000108968}
2023-01-04 01:08:43,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:43,238 INFO:     Epoch: 71
2023-01-04 01:08:44,841 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.36824750403563183, 'Total loss': 0.36824750403563183} | train loss {'Reaction outcome loss': 0.2059678807611725, 'Total loss': 0.2059678807611725}
2023-01-04 01:08:44,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:44,841 INFO:     Epoch: 72
2023-01-04 01:08:46,446 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3460763990879059, 'Total loss': 0.3460763990879059} | train loss {'Reaction outcome loss': 0.20367153389784304, 'Total loss': 0.20367153389784304}
2023-01-04 01:08:46,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:46,446 INFO:     Epoch: 73
2023-01-04 01:08:48,031 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37223399579524996, 'Total loss': 0.37223399579524996} | train loss {'Reaction outcome loss': 0.2041006127311461, 'Total loss': 0.2041006127311461}
2023-01-04 01:08:48,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:48,032 INFO:     Epoch: 74
2023-01-04 01:08:49,608 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39196835160255433, 'Total loss': 0.39196835160255433} | train loss {'Reaction outcome loss': 0.20155605197330748, 'Total loss': 0.20155605197330748}
2023-01-04 01:08:49,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:49,608 INFO:     Epoch: 75
2023-01-04 01:08:51,220 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.37553079475959145, 'Total loss': 0.37553079475959145} | train loss {'Reaction outcome loss': 0.2046549447813827, 'Total loss': 0.2046549447813827}
2023-01-04 01:08:51,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:51,220 INFO:     Epoch: 76
2023-01-04 01:08:52,819 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3619360774755478, 'Total loss': 0.3619360774755478} | train loss {'Reaction outcome loss': 0.19738363465496703, 'Total loss': 0.19738363465496703}
2023-01-04 01:08:52,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:52,820 INFO:     Epoch: 77
2023-01-04 01:08:54,404 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3785819043715795, 'Total loss': 0.3785819043715795} | train loss {'Reaction outcome loss': 0.19678083926025203, 'Total loss': 0.19678083926025203}
2023-01-04 01:08:54,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:54,405 INFO:     Epoch: 78
2023-01-04 01:08:56,024 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.36226642529169717, 'Total loss': 0.36226642529169717} | train loss {'Reaction outcome loss': 0.19734120353695556, 'Total loss': 0.19734120353695556}
2023-01-04 01:08:56,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:56,024 INFO:     Epoch: 79
2023-01-04 01:08:57,600 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3998294403155645, 'Total loss': 0.3998294403155645} | train loss {'Reaction outcome loss': 0.19974592927357424, 'Total loss': 0.19974592927357424}
2023-01-04 01:08:57,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:57,600 INFO:     Epoch: 80
2023-01-04 01:08:59,200 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3771335557103157, 'Total loss': 0.3771335557103157} | train loss {'Reaction outcome loss': 0.20437993076241887, 'Total loss': 0.20437993076241887}
2023-01-04 01:08:59,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:08:59,200 INFO:     Epoch: 81
2023-01-04 01:09:00,810 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3756420334180196, 'Total loss': 0.3756420334180196} | train loss {'Reaction outcome loss': 0.19280495917748497, 'Total loss': 0.19280495917748497}
2023-01-04 01:09:00,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:00,811 INFO:     Epoch: 82
2023-01-04 01:09:02,409 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3712326298157374, 'Total loss': 0.3712326298157374} | train loss {'Reaction outcome loss': 0.19397534987439752, 'Total loss': 0.19397534987439752}
2023-01-04 01:09:02,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:02,409 INFO:     Epoch: 83
2023-01-04 01:09:03,987 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3934621125459671, 'Total loss': 0.3934621125459671} | train loss {'Reaction outcome loss': 0.19091039841631477, 'Total loss': 0.19091039841631477}
2023-01-04 01:09:03,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:03,988 INFO:     Epoch: 84
2023-01-04 01:09:05,589 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37717292209466297, 'Total loss': 0.37717292209466297} | train loss {'Reaction outcome loss': 0.19028685811402588, 'Total loss': 0.19028685811402588}
2023-01-04 01:09:05,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:05,589 INFO:     Epoch: 85
2023-01-04 01:09:07,186 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3823960661888123, 'Total loss': 0.3823960661888123} | train loss {'Reaction outcome loss': 0.19000555466914523, 'Total loss': 0.19000555466914523}
2023-01-04 01:09:07,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:07,187 INFO:     Epoch: 86
2023-01-04 01:09:08,808 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40519137183825177, 'Total loss': 0.40519137183825177} | train loss {'Reaction outcome loss': 0.19585746499892, 'Total loss': 0.19585746499892}
2023-01-04 01:09:08,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:08,809 INFO:     Epoch: 87
2023-01-04 01:09:10,425 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3694341724117597, 'Total loss': 0.3694341724117597} | train loss {'Reaction outcome loss': 0.18813556914592747, 'Total loss': 0.18813556914592747}
2023-01-04 01:09:10,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:10,425 INFO:     Epoch: 88
2023-01-04 01:09:12,045 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.36536048352718353, 'Total loss': 0.36536048352718353} | train loss {'Reaction outcome loss': 0.1865939945265131, 'Total loss': 0.1865939945265131}
2023-01-04 01:09:12,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:12,045 INFO:     Epoch: 89
2023-01-04 01:09:13,633 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.34857610960801444, 'Total loss': 0.34857610960801444} | train loss {'Reaction outcome loss': 0.18400108655560965, 'Total loss': 0.18400108655560965}
2023-01-04 01:09:13,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:13,635 INFO:     Epoch: 90
2023-01-04 01:09:15,238 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3813710530598958, 'Total loss': 0.3813710530598958} | train loss {'Reaction outcome loss': 0.19064321123279523, 'Total loss': 0.19064321123279523}
2023-01-04 01:09:15,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:15,238 INFO:     Epoch: 91
2023-01-04 01:09:16,863 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3783557613690694, 'Total loss': 0.3783557613690694} | train loss {'Reaction outcome loss': 0.20095517688795275, 'Total loss': 0.20095517688795275}
2023-01-04 01:09:16,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:16,863 INFO:     Epoch: 92
2023-01-04 01:09:18,492 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3536063919464747, 'Total loss': 0.3536063919464747} | train loss {'Reaction outcome loss': 0.2036406619987194, 'Total loss': 0.2036406619987194}
2023-01-04 01:09:18,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:18,492 INFO:     Epoch: 93
2023-01-04 01:09:20,117 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39005349973837533, 'Total loss': 0.39005349973837533} | train loss {'Reaction outcome loss': 0.1846427806177298, 'Total loss': 0.1846427806177298}
2023-01-04 01:09:20,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:20,117 INFO:     Epoch: 94
2023-01-04 01:09:21,711 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.35951893428961434, 'Total loss': 0.35951893428961434} | train loss {'Reaction outcome loss': 0.1807097955134468, 'Total loss': 0.1807097955134468}
2023-01-04 01:09:21,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:21,711 INFO:     Epoch: 95
2023-01-04 01:09:23,344 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3720910757780075, 'Total loss': 0.3720910757780075} | train loss {'Reaction outcome loss': 0.1797810277661009, 'Total loss': 0.1797810277661009}
2023-01-04 01:09:23,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:23,344 INFO:     Epoch: 96
2023-01-04 01:09:24,935 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4088653326034546, 'Total loss': 0.4088653326034546} | train loss {'Reaction outcome loss': 0.18335514506865022, 'Total loss': 0.18335514506865022}
2023-01-04 01:09:24,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:24,936 INFO:     Epoch: 97
2023-01-04 01:09:26,531 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.36836821436882017, 'Total loss': 0.36836821436882017} | train loss {'Reaction outcome loss': 0.18473935652287185, 'Total loss': 0.18473935652287185}
2023-01-04 01:09:26,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:26,531 INFO:     Epoch: 98
2023-01-04 01:09:28,130 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3977135012547175, 'Total loss': 0.3977135012547175} | train loss {'Reaction outcome loss': 0.17962504876871116, 'Total loss': 0.17962504876871116}
2023-01-04 01:09:28,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 01:09:28,130 INFO:     Epoch: 99
2023-01-04 01:09:29,727 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39577689170837405, 'Total loss': 0.39577689170837405} | train loss {'Reaction outcome loss': 0.17753635283087785, 'Total loss': 0.17753635283087785}
2023-01-04 01:09:29,728 INFO:     Best model found after epoch 33 of 100.
2023-01-04 01:09:29,728 INFO:   Done with stage: TRAINING
2023-01-04 01:09:29,728 INFO:   Starting stage: EVALUATION
2023-01-04 01:09:29,857 INFO:   Done with stage: EVALUATION
2023-01-04 01:09:29,857 INFO: Done with stage: RUNNING SPLITS
2023-01-04 01:09:29,857 INFO: Starting stage: COMPUTE METRICS
2023-01-04 01:09:31,031 INFO: Done with stage: COMPUTE METRICS
2023-01-04 01:09:31,032 INFO: Starting stage: EXPORT RESULTS
2023-01-04 01:09:31,049 INFO:   Final results averaged over 50 folds: 
2023-01-04 01:09:31,053 INFO:   
                    mae  neg-spearman     rmse  spearman
dataset_split                                          
test           0.18546           NaN  0.32057       NaN
2023-01-04 01:09:32,726 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2023-01-04 01:09:32,732 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2023-01-04 01:09:32,734 DEBUG:   interactive is False
2023-01-04 01:09:32,734 DEBUG:   platform is linux
2023-01-04 01:09:32,734 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.sql.naming', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2023-01-04 01:09:32,908 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2023-01-04 01:09:32,910 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2023-01-04 01:09:33,342 DEBUG:   Loaded backend agg version unknown.
2023-01-04 01:09:33,344 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-04 01:09:33,344 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,344 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,344 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,344 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 01:09:33,344 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 01:09:33,345 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 01:09:33,345 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,345 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,345 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,345 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,345 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 01:09:33,345 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 01:09:33,345 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,345 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,345 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,345 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 01:09:33,345 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,345 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 01:09:33,345 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,345 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,345 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-04 01:09:33,346 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 01:09:33,346 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 01:09:33,346 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,346 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,346 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,346 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,346 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,346 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,346 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,346 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,346 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,346 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-04 01:09:33,346 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,346 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,346 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,346 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,346 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 01:09:33,347 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 01:09:33,347 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,347 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,347 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,347 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 01:09:33,347 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,347 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-04 01:09:33,384 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2023-01-04 01:09:33,384 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,384 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,384 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,384 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 01:09:33,384 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 01:09:33,384 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 01:09:33,384 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,384 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,385 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,385 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,385 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 01:09:33,385 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 01:09:33,385 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,385 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,385 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,385 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 01:09:33,385 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,385 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 01:09:33,385 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,385 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,385 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-04 01:09:33,385 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 01:09:33,385 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 01:09:33,385 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,385 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,386 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,386 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,386 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,386 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,386 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,386 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,386 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,386 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-04 01:09:33,386 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,386 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,386 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,386 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,386 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 01:09:33,386 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 01:09:33,386 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,386 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,386 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,387 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 01:09:33,387 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,387 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-04 01:09:33,395 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-04 01:09:33,395 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,395 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,395 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,395 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 01:09:33,396 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 01:09:33,396 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 01:09:33,396 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,396 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,396 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,396 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,396 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 01:09:33,396 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 01:09:33,396 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,396 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,396 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,396 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 01:09:33,396 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,396 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 01:09:33,396 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,396 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,397 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-04 01:09:33,397 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 01:09:33,397 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 01:09:33,397 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,397 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,397 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,397 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,397 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,397 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,397 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,397 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,397 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,397 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-04 01:09:33,397 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,397 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,397 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,397 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,397 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 01:09:33,398 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 01:09:33,398 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,398 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,398 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 01:09:33,398 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 01:09:33,398 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 01:09:33,398 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-04 01:09:33,675 INFO: Done with stage: EXPORT RESULTS
2023-01-04 01:09:33,675 INFO: Starting stage: SAVE MODEL
2023-01-04 01:09:33,721 INFO: Done with stage: SAVE MODEL
2023-01-04 01:09:33,721 INFO: Wall time for program:  8010.79 seconds
