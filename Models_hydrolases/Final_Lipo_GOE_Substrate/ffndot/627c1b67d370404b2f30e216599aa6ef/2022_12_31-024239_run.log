2022-12-31 02:42:56,033 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffndot/627c1b67d370404b2f30e216599aa6ef/2022_12_31-024239",
  "seed": 1,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "morgan1024",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffndot",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.95,
  "val_size": 0.05,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.00015553873022161447,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 3,
  "hidden_size": 90,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-12-31 02:42:56,040 INFO: Starting stage: BUILD FEATURIZERS
2022-12-31 02:42:56,044 INFO:   Creating esm representation model
2022-12-31 02:42:56,044 INFO:   Done esm representation model
2022-12-31 02:42:56,044 INFO: Done with stage: BUILD FEATURIZERS
2022-12-31 02:42:56,044 INFO: Starting stage: BUILDING DATASET
2022-12-31 02:42:56,099 INFO: Done with stage: BUILDING DATASET
2022-12-31 02:42:56,099 INFO: Starting stage: FEATURIZING DATA
2022-12-31 02:42:56,100 INFO:   Featurizing proteins
2022-12-31 02:42:56,104 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-12-31 02:42:56,138 INFO:   Loaded feature cache of size 489
2022-12-31 02:42:56,139 INFO:   Starting to pool ESM Embeddings
2022-12-31 02:42:56,272 INFO:   Featurizing molecules
2022-12-31 02:42:56,274 INFO:   Loading cache file data/program_cache/739a0d20a6c75d701bd3663cec254635
2022-12-31 02:42:56,276 INFO:   Loaded feature cache of size 498
2022-12-31 02:42:57,629 INFO: Done with stage: FEATURIZING DATA
2022-12-31 02:42:57,629 INFO: Starting stage: RUNNING SPLITS
2022-12-31 02:42:57,638 INFO:   Leaving out SEQ value Fold_0
2022-12-31 02:42:57,652 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 02:42:57,652 INFO:   Starting stage: FEATURE SCALING
2022-12-31 02:42:58,307 INFO:   Done with stage: FEATURE SCALING
2022-12-31 02:42:58,307 INFO:   Starting stage: SCALING TARGETS
2022-12-31 02:42:58,414 INFO:   Done with stage: SCALING TARGETS
2022-12-31 02:42:58,414 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 02:42:58,414 INFO:     No hyperparam tuning for this model
2022-12-31 02:42:58,414 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 02:42:58,414 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 02:42:58,415 INFO:     None feature selector for col prot
2022-12-31 02:42:58,416 INFO:     None feature selector for col prot
2022-12-31 02:42:58,416 INFO:     None feature selector for col prot
2022-12-31 02:42:58,416 INFO:     None feature selector for col chem
2022-12-31 02:42:58,416 INFO:     None feature selector for col chem
2022-12-31 02:42:58,417 INFO:     None feature selector for col chem
2022-12-31 02:42:58,417 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 02:42:58,417 INFO:   Starting stage: BUILD MODEL
2022-12-31 02:42:58,420 INFO:     Number of params in model 224011
2022-12-31 02:42:58,420 INFO:   Done with stage: BUILD MODEL
2022-12-31 02:42:58,420 INFO:   Starting stage: TRAINING
2022-12-31 02:43:00,030 INFO:     Val loss before train {'Reaction outcome loss': 0.921192882458369, 'Total loss': 0.921192882458369}
2022-12-31 02:43:00,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:00,031 INFO:     Epoch: 0
2022-12-31 02:43:01,677 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5330557107925415, 'Total loss': 0.5330557107925415} | train loss {'Reaction outcome loss': 0.7823661265574096, 'Total loss': 0.7823661265574096}
2022-12-31 02:43:01,677 INFO:     Found new best model at epoch 0
2022-12-31 02:43:01,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:01,678 INFO:     Epoch: 1
2022-12-31 02:43:03,272 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.46813017427921294, 'Total loss': 0.46813017427921294} | train loss {'Reaction outcome loss': 0.5035154841321728, 'Total loss': 0.5035154841321728}
2022-12-31 02:43:03,272 INFO:     Found new best model at epoch 1
2022-12-31 02:43:03,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:03,273 INFO:     Epoch: 2
2022-12-31 02:43:04,861 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4289481431245804, 'Total loss': 0.4289481431245804} | train loss {'Reaction outcome loss': 0.44127573012869, 'Total loss': 0.44127573012869}
2022-12-31 02:43:04,862 INFO:     Found new best model at epoch 2
2022-12-31 02:43:04,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:04,863 INFO:     Epoch: 3
2022-12-31 02:43:06,478 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.453277176618576, 'Total loss': 0.453277176618576} | train loss {'Reaction outcome loss': 0.3999078466724127, 'Total loss': 0.3999078466724127}
2022-12-31 02:43:06,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:06,479 INFO:     Epoch: 4
2022-12-31 02:43:08,110 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4482043445110321, 'Total loss': 0.4482043445110321} | train loss {'Reaction outcome loss': 0.3768655302159952, 'Total loss': 0.3768655302159952}
2022-12-31 02:43:08,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:08,110 INFO:     Epoch: 5
2022-12-31 02:43:09,746 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4326726794242859, 'Total loss': 0.4326726794242859} | train loss {'Reaction outcome loss': 0.3569902130590254, 'Total loss': 0.3569902130590254}
2022-12-31 02:43:09,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:09,746 INFO:     Epoch: 6
2022-12-31 02:43:11,391 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.39387963314851127, 'Total loss': 0.39387963314851127} | train loss {'Reaction outcome loss': 0.33469985145734343, 'Total loss': 0.33469985145734343}
2022-12-31 02:43:11,391 INFO:     Found new best model at epoch 6
2022-12-31 02:43:11,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:11,392 INFO:     Epoch: 7
2022-12-31 02:43:12,988 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4059065063794454, 'Total loss': 0.4059065063794454} | train loss {'Reaction outcome loss': 0.31726077914019646, 'Total loss': 0.31726077914019646}
2022-12-31 02:43:12,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:12,988 INFO:     Epoch: 8
2022-12-31 02:43:14,597 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4248848656813304, 'Total loss': 0.4248848656813304} | train loss {'Reaction outcome loss': 0.30304579571871965, 'Total loss': 0.30304579571871965}
2022-12-31 02:43:14,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:14,597 INFO:     Epoch: 9
2022-12-31 02:43:16,203 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4042883448302746, 'Total loss': 0.4042883448302746} | train loss {'Reaction outcome loss': 0.2909301296695248, 'Total loss': 0.2909301296695248}
2022-12-31 02:43:16,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:16,203 INFO:     Epoch: 10
2022-12-31 02:43:17,816 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4494563857714335, 'Total loss': 0.4494563857714335} | train loss {'Reaction outcome loss': 0.2749488965041881, 'Total loss': 0.2749488965041881}
2022-12-31 02:43:17,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:17,816 INFO:     Epoch: 11
2022-12-31 02:43:19,426 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.426064758002758, 'Total loss': 0.426064758002758} | train loss {'Reaction outcome loss': 0.2658653820527124, 'Total loss': 0.2658653820527124}
2022-12-31 02:43:19,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:19,427 INFO:     Epoch: 12
2022-12-31 02:43:21,039 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.489949432015419, 'Total loss': 0.489949432015419} | train loss {'Reaction outcome loss': 0.2542805282668562, 'Total loss': 0.2542805282668562}
2022-12-31 02:43:21,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:21,039 INFO:     Epoch: 13
2022-12-31 02:43:22,641 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4333190272251765, 'Total loss': 0.4333190272251765} | train loss {'Reaction outcome loss': 0.24488868092224275, 'Total loss': 0.24488868092224275}
2022-12-31 02:43:22,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:22,641 INFO:     Epoch: 14
2022-12-31 02:43:24,253 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44087985455989837, 'Total loss': 0.44087985455989837} | train loss {'Reaction outcome loss': 0.23712090693496085, 'Total loss': 0.23712090693496085}
2022-12-31 02:43:24,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:24,254 INFO:     Epoch: 15
2022-12-31 02:43:25,859 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44569356441497804, 'Total loss': 0.44569356441497804} | train loss {'Reaction outcome loss': 0.22900547598225948, 'Total loss': 0.22900547598225948}
2022-12-31 02:43:25,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:25,859 INFO:     Epoch: 16
2022-12-31 02:43:27,475 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4289703567822774, 'Total loss': 0.4289703567822774} | train loss {'Reaction outcome loss': 0.2250957044844444, 'Total loss': 0.2250957044844444}
2022-12-31 02:43:27,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:27,476 INFO:     Epoch: 17
2022-12-31 02:43:29,092 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44945289691289264, 'Total loss': 0.44945289691289264} | train loss {'Reaction outcome loss': 0.22214366055874926, 'Total loss': 0.22214366055874926}
2022-12-31 02:43:29,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:29,093 INFO:     Epoch: 18
2022-12-31 02:43:30,720 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4499711513519287, 'Total loss': 0.4499711513519287} | train loss {'Reaction outcome loss': 0.21050301444590527, 'Total loss': 0.21050301444590527}
2022-12-31 02:43:30,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:30,722 INFO:     Epoch: 19
2022-12-31 02:43:32,327 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.422722386320432, 'Total loss': 0.422722386320432} | train loss {'Reaction outcome loss': 0.20331998394150627, 'Total loss': 0.20331998394150627}
2022-12-31 02:43:32,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:32,327 INFO:     Epoch: 20
2022-12-31 02:43:33,941 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4206182546913624, 'Total loss': 0.4206182546913624} | train loss {'Reaction outcome loss': 0.1948666874755979, 'Total loss': 0.1948666874755979}
2022-12-31 02:43:33,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:33,941 INFO:     Epoch: 21
2022-12-31 02:43:35,142 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42869335810343423, 'Total loss': 0.42869335810343423} | train loss {'Reaction outcome loss': 0.19256825733506855, 'Total loss': 0.19256825733506855}
2022-12-31 02:43:35,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:35,142 INFO:     Epoch: 22
2022-12-31 02:43:36,247 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43646797637144724, 'Total loss': 0.43646797637144724} | train loss {'Reaction outcome loss': 0.18803901773887677, 'Total loss': 0.18803901773887677}
2022-12-31 02:43:36,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:36,247 INFO:     Epoch: 23
2022-12-31 02:43:37,358 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4626603424549103, 'Total loss': 0.4626603424549103} | train loss {'Reaction outcome loss': 0.18440160050906323, 'Total loss': 0.18440160050906323}
2022-12-31 02:43:37,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:37,359 INFO:     Epoch: 24
2022-12-31 02:43:38,478 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4310543219248454, 'Total loss': 0.4310543219248454} | train loss {'Reaction outcome loss': 0.17861463146236461, 'Total loss': 0.17861463146236461}
2022-12-31 02:43:38,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:38,478 INFO:     Epoch: 25
2022-12-31 02:43:40,044 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4405686378479004, 'Total loss': 0.4405686378479004} | train loss {'Reaction outcome loss': 0.17643040000041435, 'Total loss': 0.17643040000041435}
2022-12-31 02:43:40,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:40,044 INFO:     Epoch: 26
2022-12-31 02:43:41,687 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4504040757815043, 'Total loss': 0.4504040757815043} | train loss {'Reaction outcome loss': 0.17507342600874304, 'Total loss': 0.17507342600874304}
2022-12-31 02:43:41,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:41,687 INFO:     Epoch: 27
2022-12-31 02:43:43,317 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4345629811286926, 'Total loss': 0.4345629811286926} | train loss {'Reaction outcome loss': 0.16972941266297747, 'Total loss': 0.16972941266297747}
2022-12-31 02:43:43,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:43,318 INFO:     Epoch: 28
2022-12-31 02:43:44,929 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44653604527314505, 'Total loss': 0.44653604527314505} | train loss {'Reaction outcome loss': 0.16453381088108587, 'Total loss': 0.16453381088108587}
2022-12-31 02:43:44,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:44,929 INFO:     Epoch: 29
2022-12-31 02:43:46,540 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46187884906927745, 'Total loss': 0.46187884906927745} | train loss {'Reaction outcome loss': 0.16780715224916462, 'Total loss': 0.16780715224916462}
2022-12-31 02:43:46,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:46,540 INFO:     Epoch: 30
2022-12-31 02:43:48,138 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4552462843557199, 'Total loss': 0.4552462843557199} | train loss {'Reaction outcome loss': 0.164677511344599, 'Total loss': 0.164677511344599}
2022-12-31 02:43:48,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:48,138 INFO:     Epoch: 31
2022-12-31 02:43:49,760 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4601053655147552, 'Total loss': 0.4601053655147552} | train loss {'Reaction outcome loss': 0.1611057402968625, 'Total loss': 0.1611057402968625}
2022-12-31 02:43:49,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:49,761 INFO:     Epoch: 32
2022-12-31 02:43:51,357 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4911425272623698, 'Total loss': 0.4911425272623698} | train loss {'Reaction outcome loss': 0.1560993842616841, 'Total loss': 0.1560993842616841}
2022-12-31 02:43:51,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:51,357 INFO:     Epoch: 33
2022-12-31 02:43:53,004 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4727112054824829, 'Total loss': 0.4727112054824829} | train loss {'Reaction outcome loss': 0.15847960330423091, 'Total loss': 0.15847960330423091}
2022-12-31 02:43:53,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:53,004 INFO:     Epoch: 34
2022-12-31 02:43:54,650 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4752882947524389, 'Total loss': 0.4752882947524389} | train loss {'Reaction outcome loss': 0.1533803678673757, 'Total loss': 0.1533803678673757}
2022-12-31 02:43:54,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:54,650 INFO:     Epoch: 35
2022-12-31 02:43:56,295 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45561932946244876, 'Total loss': 0.45561932946244876} | train loss {'Reaction outcome loss': 0.15641808553151923, 'Total loss': 0.15641808553151923}
2022-12-31 02:43:56,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:56,295 INFO:     Epoch: 36
2022-12-31 02:43:57,895 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46265455782413484, 'Total loss': 0.46265455782413484} | train loss {'Reaction outcome loss': 0.15074613565005934, 'Total loss': 0.15074613565005934}
2022-12-31 02:43:57,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:57,895 INFO:     Epoch: 37
2022-12-31 02:43:59,536 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45650327801704405, 'Total loss': 0.45650327801704405} | train loss {'Reaction outcome loss': 0.1467824959513414, 'Total loss': 0.1467824959513414}
2022-12-31 02:43:59,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:43:59,536 INFO:     Epoch: 38
2022-12-31 02:44:01,180 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4592482129732768, 'Total loss': 0.4592482129732768} | train loss {'Reaction outcome loss': 0.14543808259295074, 'Total loss': 0.14543808259295074}
2022-12-31 02:44:01,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:01,181 INFO:     Epoch: 39
2022-12-31 02:44:02,772 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4548434602717559, 'Total loss': 0.4548434602717559} | train loss {'Reaction outcome loss': 0.14441931173000688, 'Total loss': 0.14441931173000688}
2022-12-31 02:44:02,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:02,773 INFO:     Epoch: 40
2022-12-31 02:44:04,420 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4397917033483585, 'Total loss': 0.4397917033483585} | train loss {'Reaction outcome loss': 0.14603131700429942, 'Total loss': 0.14603131700429942}
2022-12-31 02:44:04,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:04,421 INFO:     Epoch: 41
2022-12-31 02:44:06,013 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49187638560930885, 'Total loss': 0.49187638560930885} | train loss {'Reaction outcome loss': 0.14795402128201646, 'Total loss': 0.14795402128201646}
2022-12-31 02:44:06,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:06,013 INFO:     Epoch: 42
2022-12-31 02:44:07,643 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43820792337258657, 'Total loss': 0.43820792337258657} | train loss {'Reaction outcome loss': 0.14271232814633802, 'Total loss': 0.14271232814633802}
2022-12-31 02:44:07,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:07,644 INFO:     Epoch: 43
2022-12-31 02:44:09,295 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44607646663983663, 'Total loss': 0.44607646663983663} | train loss {'Reaction outcome loss': 0.13944844270445705, 'Total loss': 0.13944844270445705}
2022-12-31 02:44:09,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:09,295 INFO:     Epoch: 44
2022-12-31 02:44:10,942 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4957935601472855, 'Total loss': 0.4957935601472855} | train loss {'Reaction outcome loss': 0.14092352387969528, 'Total loss': 0.14092352387969528}
2022-12-31 02:44:10,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:10,942 INFO:     Epoch: 45
2022-12-31 02:44:12,591 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48840278188387554, 'Total loss': 0.48840278188387554} | train loss {'Reaction outcome loss': 0.14024055112262457, 'Total loss': 0.14024055112262457}
2022-12-31 02:44:12,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:12,591 INFO:     Epoch: 46
2022-12-31 02:44:14,207 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46282851894696553, 'Total loss': 0.46282851894696553} | train loss {'Reaction outcome loss': 0.13980007857159327, 'Total loss': 0.13980007857159327}
2022-12-31 02:44:14,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:14,207 INFO:     Epoch: 47
2022-12-31 02:44:15,823 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4755178034305573, 'Total loss': 0.4755178034305573} | train loss {'Reaction outcome loss': 0.13637898917797775, 'Total loss': 0.13637898917797775}
2022-12-31 02:44:15,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:15,823 INFO:     Epoch: 48
2022-12-31 02:44:17,435 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45732010900974274, 'Total loss': 0.45732010900974274} | train loss {'Reaction outcome loss': 0.1362290845760878, 'Total loss': 0.1362290845760878}
2022-12-31 02:44:17,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:17,436 INFO:     Epoch: 49
2022-12-31 02:44:19,078 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4617523729801178, 'Total loss': 0.4617523729801178} | train loss {'Reaction outcome loss': 0.13177670509087078, 'Total loss': 0.13177670509087078}
2022-12-31 02:44:19,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:19,078 INFO:     Epoch: 50
2022-12-31 02:44:20,720 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48946438332398734, 'Total loss': 0.48946438332398734} | train loss {'Reaction outcome loss': 0.12881613388527935, 'Total loss': 0.12881613388527935}
2022-12-31 02:44:20,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:20,721 INFO:     Epoch: 51
2022-12-31 02:44:22,355 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4768184542655945, 'Total loss': 0.4768184542655945} | train loss {'Reaction outcome loss': 0.13512904426013034, 'Total loss': 0.13512904426013034}
2022-12-31 02:44:22,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:22,355 INFO:     Epoch: 52
2022-12-31 02:44:24,008 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4474749773740768, 'Total loss': 0.4474749773740768} | train loss {'Reaction outcome loss': 0.1318450659042695, 'Total loss': 0.1318450659042695}
2022-12-31 02:44:24,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:24,008 INFO:     Epoch: 53
2022-12-31 02:44:25,615 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4526426980892817, 'Total loss': 0.4526426980892817} | train loss {'Reaction outcome loss': 0.12955654793821494, 'Total loss': 0.12955654793821494}
2022-12-31 02:44:25,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:25,615 INFO:     Epoch: 54
2022-12-31 02:44:27,247 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5119943648576737, 'Total loss': 0.5119943648576737} | train loss {'Reaction outcome loss': 0.12615018957993868, 'Total loss': 0.12615018957993868}
2022-12-31 02:44:27,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:27,247 INFO:     Epoch: 55
2022-12-31 02:44:28,891 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4957479417324066, 'Total loss': 0.4957479417324066} | train loss {'Reaction outcome loss': 0.13314122014385632, 'Total loss': 0.13314122014385632}
2022-12-31 02:44:28,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:28,892 INFO:     Epoch: 56
2022-12-31 02:44:30,536 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.495608976483345, 'Total loss': 0.495608976483345} | train loss {'Reaction outcome loss': 0.12794716414678228, 'Total loss': 0.12794716414678228}
2022-12-31 02:44:30,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:30,536 INFO:     Epoch: 57
2022-12-31 02:44:32,182 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4798274616400401, 'Total loss': 0.4798274616400401} | train loss {'Reaction outcome loss': 0.12880906849291907, 'Total loss': 0.12880906849291907}
2022-12-31 02:44:32,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:32,183 INFO:     Epoch: 58
2022-12-31 02:44:33,785 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4607787569363912, 'Total loss': 0.4607787569363912} | train loss {'Reaction outcome loss': 0.12582590968105875, 'Total loss': 0.12582590968105875}
2022-12-31 02:44:33,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:33,785 INFO:     Epoch: 59
2022-12-31 02:44:35,386 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.452085014184316, 'Total loss': 0.452085014184316} | train loss {'Reaction outcome loss': 0.12909450538323394, 'Total loss': 0.12909450538323394}
2022-12-31 02:44:35,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:35,386 INFO:     Epoch: 60
2022-12-31 02:44:37,004 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5016986131668091, 'Total loss': 0.5016986131668091} | train loss {'Reaction outcome loss': 0.12350755665901599, 'Total loss': 0.12350755665901599}
2022-12-31 02:44:37,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:37,004 INFO:     Epoch: 61
2022-12-31 02:44:38,624 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4873384217421214, 'Total loss': 0.4873384217421214} | train loss {'Reaction outcome loss': 0.12080937272770119, 'Total loss': 0.12080937272770119}
2022-12-31 02:44:38,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:38,624 INFO:     Epoch: 62
2022-12-31 02:44:40,240 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4565479422609011, 'Total loss': 0.4565479422609011} | train loss {'Reaction outcome loss': 0.12022614473606641, 'Total loss': 0.12022614473606641}
2022-12-31 02:44:40,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:40,240 INFO:     Epoch: 63
2022-12-31 02:44:41,859 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4952288468678792, 'Total loss': 0.4952288468678792} | train loss {'Reaction outcome loss': 0.12247934359408942, 'Total loss': 0.12247934359408942}
2022-12-31 02:44:41,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:41,859 INFO:     Epoch: 64
2022-12-31 02:44:43,458 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45651324596256015, 'Total loss': 0.45651324596256015} | train loss {'Reaction outcome loss': 0.12181462392538459, 'Total loss': 0.12181462392538459}
2022-12-31 02:44:43,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:43,458 INFO:     Epoch: 65
2022-12-31 02:44:45,107 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45740288197994233, 'Total loss': 0.45740288197994233} | train loss {'Reaction outcome loss': 0.11986017074169857, 'Total loss': 0.11986017074169857}
2022-12-31 02:44:45,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:45,107 INFO:     Epoch: 66
2022-12-31 02:44:46,746 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4706265350182851, 'Total loss': 0.4706265350182851} | train loss {'Reaction outcome loss': 0.12726259626611902, 'Total loss': 0.12726259626611902}
2022-12-31 02:44:46,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:46,747 INFO:     Epoch: 67
2022-12-31 02:44:48,397 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48169377048810325, 'Total loss': 0.48169377048810325} | train loss {'Reaction outcome loss': 0.12165963857847474, 'Total loss': 0.12165963857847474}
2022-12-31 02:44:48,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:48,398 INFO:     Epoch: 68
2022-12-31 02:44:50,013 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4532659356792768, 'Total loss': 0.4532659356792768} | train loss {'Reaction outcome loss': 0.12076639543686594, 'Total loss': 0.12076639543686594}
2022-12-31 02:44:50,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:50,013 INFO:     Epoch: 69
2022-12-31 02:44:51,643 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4654827865151068, 'Total loss': 0.4654827865151068} | train loss {'Reaction outcome loss': 0.11878338752693118, 'Total loss': 0.11878338752693118}
2022-12-31 02:44:51,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:51,644 INFO:     Epoch: 70
2022-12-31 02:44:53,251 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45666028509537376, 'Total loss': 0.45666028509537376} | train loss {'Reaction outcome loss': 0.120214132838132, 'Total loss': 0.120214132838132}
2022-12-31 02:44:53,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:53,252 INFO:     Epoch: 71
2022-12-31 02:44:54,900 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45179334928592046, 'Total loss': 0.45179334928592046} | train loss {'Reaction outcome loss': 0.11762274857252263, 'Total loss': 0.11762274857252263}
2022-12-31 02:44:54,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:54,900 INFO:     Epoch: 72
2022-12-31 02:44:56,531 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46312768949816624, 'Total loss': 0.46312768949816624} | train loss {'Reaction outcome loss': 0.1145178089975874, 'Total loss': 0.1145178089975874}
2022-12-31 02:44:56,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:56,532 INFO:     Epoch: 73
2022-12-31 02:44:58,181 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48967969218889873, 'Total loss': 0.48967969218889873} | train loss {'Reaction outcome loss': 0.12206621345596545, 'Total loss': 0.12206621345596545}
2022-12-31 02:44:58,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:58,182 INFO:     Epoch: 74
2022-12-31 02:44:59,794 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44291583200295764, 'Total loss': 0.44291583200295764} | train loss {'Reaction outcome loss': 0.12100916809740138, 'Total loss': 0.12100916809740138}
2022-12-31 02:44:59,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:44:59,794 INFO:     Epoch: 75
2022-12-31 02:45:01,429 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4755395591259003, 'Total loss': 0.4755395591259003} | train loss {'Reaction outcome loss': 0.11836446824418756, 'Total loss': 0.11836446824418756}
2022-12-31 02:45:01,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:01,429 INFO:     Epoch: 76
2022-12-31 02:45:03,037 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47725434402624767, 'Total loss': 0.47725434402624767} | train loss {'Reaction outcome loss': 0.11288043511468548, 'Total loss': 0.11288043511468548}
2022-12-31 02:45:03,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:03,038 INFO:     Epoch: 77
2022-12-31 02:45:04,655 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43185499906539915, 'Total loss': 0.43185499906539915} | train loss {'Reaction outcome loss': 0.11698455403170006, 'Total loss': 0.11698455403170006}
2022-12-31 02:45:04,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:04,655 INFO:     Epoch: 78
2022-12-31 02:45:06,272 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4253633429606756, 'Total loss': 0.4253633429606756} | train loss {'Reaction outcome loss': 0.1126425073777612, 'Total loss': 0.1126425073777612}
2022-12-31 02:45:06,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:06,272 INFO:     Epoch: 79
2022-12-31 02:45:07,917 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46620136859516303, 'Total loss': 0.46620136859516303} | train loss {'Reaction outcome loss': 0.1102192467215024, 'Total loss': 0.1102192467215024}
2022-12-31 02:45:07,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:07,917 INFO:     Epoch: 80
2022-12-31 02:45:09,525 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48048484325408936, 'Total loss': 0.48048484325408936} | train loss {'Reaction outcome loss': 0.12181758492649447, 'Total loss': 0.12181758492649447}
2022-12-31 02:45:09,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:09,526 INFO:     Epoch: 81
2022-12-31 02:45:11,139 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4907148758570353, 'Total loss': 0.4907148758570353} | train loss {'Reaction outcome loss': 0.11909939777515419, 'Total loss': 0.11909939777515419}
2022-12-31 02:45:11,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:11,139 INFO:     Epoch: 82
2022-12-31 02:45:12,762 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46908617615699766, 'Total loss': 0.46908617615699766} | train loss {'Reaction outcome loss': 0.11502443910610517, 'Total loss': 0.11502443910610517}
2022-12-31 02:45:12,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:12,762 INFO:     Epoch: 83
2022-12-31 02:45:14,393 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4603805383046468, 'Total loss': 0.4603805383046468} | train loss {'Reaction outcome loss': 0.11535150989644476, 'Total loss': 0.11535150989644476}
2022-12-31 02:45:14,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:14,393 INFO:     Epoch: 84
2022-12-31 02:45:16,039 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47261887366573013, 'Total loss': 0.47261887366573013} | train loss {'Reaction outcome loss': 0.11372510036334205, 'Total loss': 0.11372510036334205}
2022-12-31 02:45:16,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:16,039 INFO:     Epoch: 85
2022-12-31 02:45:17,683 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4384903356432915, 'Total loss': 0.4384903356432915} | train loss {'Reaction outcome loss': 0.11168565357363214, 'Total loss': 0.11168565357363214}
2022-12-31 02:45:17,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:17,683 INFO:     Epoch: 86
2022-12-31 02:45:19,291 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4856689214706421, 'Total loss': 0.4856689214706421} | train loss {'Reaction outcome loss': 0.10851738884731199, 'Total loss': 0.10851738884731199}
2022-12-31 02:45:19,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:19,291 INFO:     Epoch: 87
2022-12-31 02:45:20,895 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4677895426750183, 'Total loss': 0.4677895426750183} | train loss {'Reaction outcome loss': 0.1111623243336658, 'Total loss': 0.1111623243336658}
2022-12-31 02:45:20,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:20,895 INFO:     Epoch: 88
2022-12-31 02:45:22,542 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47430960486332574, 'Total loss': 0.47430960486332574} | train loss {'Reaction outcome loss': 0.11322492712787983, 'Total loss': 0.11322492712787983}
2022-12-31 02:45:22,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:22,543 INFO:     Epoch: 89
2022-12-31 02:45:24,180 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4512850095828374, 'Total loss': 0.4512850095828374} | train loss {'Reaction outcome loss': 0.11202340062550736, 'Total loss': 0.11202340062550736}
2022-12-31 02:45:24,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:24,181 INFO:     Epoch: 90
2022-12-31 02:45:25,829 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.534977529446284, 'Total loss': 0.534977529446284} | train loss {'Reaction outcome loss': 0.1078176730203241, 'Total loss': 0.1078176730203241}
2022-12-31 02:45:25,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:25,830 INFO:     Epoch: 91
2022-12-31 02:45:27,480 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4403331220149994, 'Total loss': 0.4403331220149994} | train loss {'Reaction outcome loss': 0.11147091634087128, 'Total loss': 0.11147091634087128}
2022-12-31 02:45:27,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:27,481 INFO:     Epoch: 92
2022-12-31 02:45:29,108 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44643300722042717, 'Total loss': 0.44643300722042717} | train loss {'Reaction outcome loss': 0.10685338356767546, 'Total loss': 0.10685338356767546}
2022-12-31 02:45:29,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:29,109 INFO:     Epoch: 93
2022-12-31 02:45:30,744 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4795439640680949, 'Total loss': 0.4795439640680949} | train loss {'Reaction outcome loss': 0.10852888444841126, 'Total loss': 0.10852888444841126}
2022-12-31 02:45:30,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:30,744 INFO:     Epoch: 94
2022-12-31 02:45:32,382 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46500848432381947, 'Total loss': 0.46500848432381947} | train loss {'Reaction outcome loss': 0.11433935711405925, 'Total loss': 0.11433935711405925}
2022-12-31 02:45:32,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:32,382 INFO:     Epoch: 95
2022-12-31 02:45:34,031 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4571212271849314, 'Total loss': 0.4571212271849314} | train loss {'Reaction outcome loss': 0.11141776626813651, 'Total loss': 0.11141776626813651}
2022-12-31 02:45:34,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:34,032 INFO:     Epoch: 96
2022-12-31 02:45:35,633 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4694955935080846, 'Total loss': 0.4694955935080846} | train loss {'Reaction outcome loss': 0.10923053863912056, 'Total loss': 0.10923053863912056}
2022-12-31 02:45:35,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:35,633 INFO:     Epoch: 97
2022-12-31 02:45:37,276 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48400166978438697, 'Total loss': 0.48400166978438697} | train loss {'Reaction outcome loss': 0.10763431077604711, 'Total loss': 0.10763431077604711}
2022-12-31 02:45:37,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:37,276 INFO:     Epoch: 98
2022-12-31 02:45:38,891 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4642882138490677, 'Total loss': 0.4642882138490677} | train loss {'Reaction outcome loss': 0.10805516595689532, 'Total loss': 0.10805516595689532}
2022-12-31 02:45:38,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:38,892 INFO:     Epoch: 99
2022-12-31 02:45:40,532 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45938287178675336, 'Total loss': 0.45938287178675336} | train loss {'Reaction outcome loss': 0.11532088781744515, 'Total loss': 0.11532088781744515}
2022-12-31 02:45:40,532 INFO:     Best model found after epoch 7 of 100.
2022-12-31 02:45:40,533 INFO:   Done with stage: TRAINING
2022-12-31 02:45:40,533 INFO:   Starting stage: EVALUATION
2022-12-31 02:45:40,676 INFO:   Done with stage: EVALUATION
2022-12-31 02:45:40,676 INFO:   Leaving out SEQ value Fold_1
2022-12-31 02:45:40,689 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 02:45:40,689 INFO:   Starting stage: FEATURE SCALING
2022-12-31 02:45:41,363 INFO:   Done with stage: FEATURE SCALING
2022-12-31 02:45:41,363 INFO:   Starting stage: SCALING TARGETS
2022-12-31 02:45:41,435 INFO:   Done with stage: SCALING TARGETS
2022-12-31 02:45:41,435 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 02:45:41,435 INFO:     No hyperparam tuning for this model
2022-12-31 02:45:41,435 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 02:45:41,435 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 02:45:41,436 INFO:     None feature selector for col prot
2022-12-31 02:45:41,436 INFO:     None feature selector for col prot
2022-12-31 02:45:41,436 INFO:     None feature selector for col prot
2022-12-31 02:45:41,437 INFO:     None feature selector for col chem
2022-12-31 02:45:41,437 INFO:     None feature selector for col chem
2022-12-31 02:45:41,437 INFO:     None feature selector for col chem
2022-12-31 02:45:41,437 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 02:45:41,437 INFO:   Starting stage: BUILD MODEL
2022-12-31 02:45:41,439 INFO:     Number of params in model 224011
2022-12-31 02:45:41,442 INFO:   Done with stage: BUILD MODEL
2022-12-31 02:45:41,442 INFO:   Starting stage: TRAINING
2022-12-31 02:45:41,488 INFO:     Val loss before train {'Reaction outcome loss': 1.007165801525116, 'Total loss': 1.007165801525116}
2022-12-31 02:45:41,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:41,488 INFO:     Epoch: 0
2022-12-31 02:45:43,117 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6605217933654786, 'Total loss': 0.6605217933654786} | train loss {'Reaction outcome loss': 0.7720195345472598, 'Total loss': 0.7720195345472598}
2022-12-31 02:45:43,117 INFO:     Found new best model at epoch 0
2022-12-31 02:45:43,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:43,118 INFO:     Epoch: 1
2022-12-31 02:45:44,731 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5860185186068217, 'Total loss': 0.5860185186068217} | train loss {'Reaction outcome loss': 0.517738383260855, 'Total loss': 0.517738383260855}
2022-12-31 02:45:44,731 INFO:     Found new best model at epoch 1
2022-12-31 02:45:44,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:44,732 INFO:     Epoch: 2
2022-12-31 02:45:46,339 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5760193566481272, 'Total loss': 0.5760193566481272} | train loss {'Reaction outcome loss': 0.4445158313247848, 'Total loss': 0.4445158313247848}
2022-12-31 02:45:46,339 INFO:     Found new best model at epoch 2
2022-12-31 02:45:46,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:46,340 INFO:     Epoch: 3
2022-12-31 02:45:47,948 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5530890603860219, 'Total loss': 0.5530890603860219} | train loss {'Reaction outcome loss': 0.40247206995938567, 'Total loss': 0.40247206995938567}
2022-12-31 02:45:47,948 INFO:     Found new best model at epoch 3
2022-12-31 02:45:47,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:47,949 INFO:     Epoch: 4
2022-12-31 02:45:49,565 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5552615900834401, 'Total loss': 0.5552615900834401} | train loss {'Reaction outcome loss': 0.37312109471362864, 'Total loss': 0.37312109471362864}
2022-12-31 02:45:49,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:49,565 INFO:     Epoch: 5
2022-12-31 02:45:51,217 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5096433023611705, 'Total loss': 0.5096433023611705} | train loss {'Reaction outcome loss': 0.34936892934222485, 'Total loss': 0.34936892934222485}
2022-12-31 02:45:51,217 INFO:     Found new best model at epoch 5
2022-12-31 02:45:51,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:51,219 INFO:     Epoch: 6
2022-12-31 02:45:52,870 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5154635975758235, 'Total loss': 0.5154635975758235} | train loss {'Reaction outcome loss': 0.32449624150741735, 'Total loss': 0.32449624150741735}
2022-12-31 02:45:52,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:52,871 INFO:     Epoch: 7
2022-12-31 02:45:54,519 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5063072005907695, 'Total loss': 0.5063072005907695} | train loss {'Reaction outcome loss': 0.30968497566009057, 'Total loss': 0.30968497566009057}
2022-12-31 02:45:54,519 INFO:     Found new best model at epoch 7
2022-12-31 02:45:54,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:54,520 INFO:     Epoch: 8
2022-12-31 02:45:56,136 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5126584261655808, 'Total loss': 0.5126584261655808} | train loss {'Reaction outcome loss': 0.2933779316608443, 'Total loss': 0.2933779316608443}
2022-12-31 02:45:56,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:56,136 INFO:     Epoch: 9
2022-12-31 02:45:57,758 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5392097304264705, 'Total loss': 0.5392097304264705} | train loss {'Reaction outcome loss': 0.2818346371928203, 'Total loss': 0.2818346371928203}
2022-12-31 02:45:57,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:57,759 INFO:     Epoch: 10
2022-12-31 02:45:59,422 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5527323881785074, 'Total loss': 0.5527323881785074} | train loss {'Reaction outcome loss': 0.26827182837397506, 'Total loss': 0.26827182837397506}
2022-12-31 02:45:59,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:45:59,423 INFO:     Epoch: 11
2022-12-31 02:46:01,075 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5079152544339498, 'Total loss': 0.5079152544339498} | train loss {'Reaction outcome loss': 0.2605809503052708, 'Total loss': 0.2605809503052708}
2022-12-31 02:46:01,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:01,075 INFO:     Epoch: 12
2022-12-31 02:46:02,702 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5244927207628886, 'Total loss': 0.5244927207628886} | train loss {'Reaction outcome loss': 0.24740113089185045, 'Total loss': 0.24740113089185045}
2022-12-31 02:46:02,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:02,702 INFO:     Epoch: 13
2022-12-31 02:46:04,361 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5052438318729401, 'Total loss': 0.5052438318729401} | train loss {'Reaction outcome loss': 0.24132284291176737, 'Total loss': 0.24132284291176737}
2022-12-31 02:46:04,361 INFO:     Found new best model at epoch 13
2022-12-31 02:46:04,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:04,362 INFO:     Epoch: 14
2022-12-31 02:46:05,978 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5204002221425374, 'Total loss': 0.5204002221425374} | train loss {'Reaction outcome loss': 0.23339352598143875, 'Total loss': 0.23339352598143875}
2022-12-31 02:46:05,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:05,978 INFO:     Epoch: 15
2022-12-31 02:46:07,605 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.543085586031278, 'Total loss': 0.543085586031278} | train loss {'Reaction outcome loss': 0.22841815904636556, 'Total loss': 0.22841815904636556}
2022-12-31 02:46:07,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:07,606 INFO:     Epoch: 16
2022-12-31 02:46:09,234 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5207893927892049, 'Total loss': 0.5207893927892049} | train loss {'Reaction outcome loss': 0.21958734668399868, 'Total loss': 0.21958734668399868}
2022-12-31 02:46:09,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:09,235 INFO:     Epoch: 17
2022-12-31 02:46:10,861 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.55218981107076, 'Total loss': 0.55218981107076} | train loss {'Reaction outcome loss': 0.21566177042373252, 'Total loss': 0.21566177042373252}
2022-12-31 02:46:10,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:10,861 INFO:     Epoch: 18
2022-12-31 02:46:12,489 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5391136184334755, 'Total loss': 0.5391136184334755} | train loss {'Reaction outcome loss': 0.20846554568202735, 'Total loss': 0.20846554568202735}
2022-12-31 02:46:12,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:12,489 INFO:     Epoch: 19
2022-12-31 02:46:14,119 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5264208674430847, 'Total loss': 0.5264208674430847} | train loss {'Reaction outcome loss': 0.20509973841177745, 'Total loss': 0.20509973841177745}
2022-12-31 02:46:14,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:14,119 INFO:     Epoch: 20
2022-12-31 02:46:15,761 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5419000804424285, 'Total loss': 0.5419000804424285} | train loss {'Reaction outcome loss': 0.205178297445367, 'Total loss': 0.205178297445367}
2022-12-31 02:46:15,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:15,762 INFO:     Epoch: 21
2022-12-31 02:46:17,373 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5460505326588948, 'Total loss': 0.5460505326588948} | train loss {'Reaction outcome loss': 0.22203397378325462, 'Total loss': 0.22203397378325462}
2022-12-31 02:46:17,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:17,373 INFO:     Epoch: 22
2022-12-31 02:46:19,029 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5088304718335469, 'Total loss': 0.5088304718335469} | train loss {'Reaction outcome loss': 0.19488350703128768, 'Total loss': 0.19488350703128768}
2022-12-31 02:46:19,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:19,029 INFO:     Epoch: 23
2022-12-31 02:46:20,688 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5237734337647756, 'Total loss': 0.5237734337647756} | train loss {'Reaction outcome loss': 0.18750489192029487, 'Total loss': 0.18750489192029487}
2022-12-31 02:46:20,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:20,689 INFO:     Epoch: 24
2022-12-31 02:46:22,342 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5061013390620549, 'Total loss': 0.5061013390620549} | train loss {'Reaction outcome loss': 0.17962809920182748, 'Total loss': 0.17962809920182748}
2022-12-31 02:46:22,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:22,343 INFO:     Epoch: 25
2022-12-31 02:46:23,966 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.543642571568489, 'Total loss': 0.543642571568489} | train loss {'Reaction outcome loss': 0.17981436699662573, 'Total loss': 0.17981436699662573}
2022-12-31 02:46:23,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:23,966 INFO:     Epoch: 26
2022-12-31 02:46:25,626 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5246839384237926, 'Total loss': 0.5246839384237926} | train loss {'Reaction outcome loss': 0.17628272052557356, 'Total loss': 0.17628272052557356}
2022-12-31 02:46:25,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:25,626 INFO:     Epoch: 27
2022-12-31 02:46:27,252 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5192403435707093, 'Total loss': 0.5192403435707093} | train loss {'Reaction outcome loss': 0.17278795691031584, 'Total loss': 0.17278795691031584}
2022-12-31 02:46:27,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:27,252 INFO:     Epoch: 28
2022-12-31 02:46:28,916 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4920250803232193, 'Total loss': 0.4920250803232193} | train loss {'Reaction outcome loss': 0.1766754214987631, 'Total loss': 0.1766754214987631}
2022-12-31 02:46:28,916 INFO:     Found new best model at epoch 28
2022-12-31 02:46:28,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:28,917 INFO:     Epoch: 29
2022-12-31 02:46:30,554 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5455695867538453, 'Total loss': 0.5455695867538453} | train loss {'Reaction outcome loss': 0.17505504436129463, 'Total loss': 0.17505504436129463}
2022-12-31 02:46:30,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:30,554 INFO:     Epoch: 30
2022-12-31 02:46:32,213 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5046431163946787, 'Total loss': 0.5046431163946787} | train loss {'Reaction outcome loss': 0.16598592585026947, 'Total loss': 0.16598592585026947}
2022-12-31 02:46:32,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:32,213 INFO:     Epoch: 31
2022-12-31 02:46:33,832 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5156210054953893, 'Total loss': 0.5156210054953893} | train loss {'Reaction outcome loss': 0.16133440457675877, 'Total loss': 0.16133440457675877}
2022-12-31 02:46:33,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:33,832 INFO:     Epoch: 32
2022-12-31 02:46:35,451 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5117327938477199, 'Total loss': 0.5117327938477199} | train loss {'Reaction outcome loss': 0.16784390119373446, 'Total loss': 0.16784390119373446}
2022-12-31 02:46:35,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:35,452 INFO:     Epoch: 33
2022-12-31 02:46:37,110 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5115457455317179, 'Total loss': 0.5115457455317179} | train loss {'Reaction outcome loss': 0.16189121528852568, 'Total loss': 0.16189121528852568}
2022-12-31 02:46:37,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:37,110 INFO:     Epoch: 34
2022-12-31 02:46:38,750 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5415533463160197, 'Total loss': 0.5415533463160197} | train loss {'Reaction outcome loss': 0.16741330054608863, 'Total loss': 0.16741330054608863}
2022-12-31 02:46:38,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:38,750 INFO:     Epoch: 35
2022-12-31 02:46:40,407 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5030976501603921, 'Total loss': 0.5030976501603921} | train loss {'Reaction outcome loss': 0.17807626277731353, 'Total loss': 0.17807626277731353}
2022-12-31 02:46:40,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:40,409 INFO:     Epoch: 36
2022-12-31 02:46:42,029 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.542025625705719, 'Total loss': 0.542025625705719} | train loss {'Reaction outcome loss': 0.15541547127205654, 'Total loss': 0.15541547127205654}
2022-12-31 02:46:42,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:42,029 INFO:     Epoch: 37
2022-12-31 02:46:43,681 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5052339315414429, 'Total loss': 0.5052339315414429} | train loss {'Reaction outcome loss': 0.15370841141776653, 'Total loss': 0.15370841141776653}
2022-12-31 02:46:43,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:43,681 INFO:     Epoch: 38
2022-12-31 02:46:45,303 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49881514807542165, 'Total loss': 0.49881514807542165} | train loss {'Reaction outcome loss': 0.15174597120536762, 'Total loss': 0.15174597120536762}
2022-12-31 02:46:45,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:45,303 INFO:     Epoch: 39
2022-12-31 02:46:46,925 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5177536984284719, 'Total loss': 0.5177536984284719} | train loss {'Reaction outcome loss': 0.15150526037799916, 'Total loss': 0.15150526037799916}
2022-12-31 02:46:46,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:46,926 INFO:     Epoch: 40
2022-12-31 02:46:48,545 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4972118020057678, 'Total loss': 0.4972118020057678} | train loss {'Reaction outcome loss': 0.1490750212051089, 'Total loss': 0.1490750212051089}
2022-12-31 02:46:48,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:48,546 INFO:     Epoch: 41
2022-12-31 02:46:50,203 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5143723616997401, 'Total loss': 0.5143723616997401} | train loss {'Reaction outcome loss': 0.147636092055346, 'Total loss': 0.147636092055346}
2022-12-31 02:46:50,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:50,203 INFO:     Epoch: 42
2022-12-31 02:46:51,820 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5108309755722682, 'Total loss': 0.5108309755722682} | train loss {'Reaction outcome loss': 0.14723281785594788, 'Total loss': 0.14723281785594788}
2022-12-31 02:46:51,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:51,820 INFO:     Epoch: 43
2022-12-31 02:46:53,435 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5252954343954722, 'Total loss': 0.5252954343954722} | train loss {'Reaction outcome loss': 0.1478609702637608, 'Total loss': 0.1478609702637608}
2022-12-31 02:46:53,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:53,435 INFO:     Epoch: 44
2022-12-31 02:46:55,049 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5295491566260656, 'Total loss': 0.5295491566260656} | train loss {'Reaction outcome loss': 0.14763692053763763, 'Total loss': 0.14763692053763763}
2022-12-31 02:46:55,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:55,049 INFO:     Epoch: 45
2022-12-31 02:46:56,684 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5250636478265126, 'Total loss': 0.5250636478265126} | train loss {'Reaction outcome loss': 0.1415415309197472, 'Total loss': 0.1415415309197472}
2022-12-31 02:46:56,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:56,684 INFO:     Epoch: 46
2022-12-31 02:46:58,339 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5560107007622719, 'Total loss': 0.5560107007622719} | train loss {'Reaction outcome loss': 0.1452122947970486, 'Total loss': 0.1452122947970486}
2022-12-31 02:46:58,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:58,340 INFO:     Epoch: 47
2022-12-31 02:46:59,959 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5378740151723226, 'Total loss': 0.5378740151723226} | train loss {'Reaction outcome loss': 0.1523574478958018, 'Total loss': 0.1523574478958018}
2022-12-31 02:46:59,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:46:59,960 INFO:     Epoch: 48
2022-12-31 02:47:01,606 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4909115880727768, 'Total loss': 0.4909115880727768} | train loss {'Reaction outcome loss': 0.1534692664351061, 'Total loss': 0.1534692664351061}
2022-12-31 02:47:01,606 INFO:     Found new best model at epoch 48
2022-12-31 02:47:01,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:01,607 INFO:     Epoch: 49
2022-12-31 02:47:03,222 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49149196594953537, 'Total loss': 0.49149196594953537} | train loss {'Reaction outcome loss': 0.14904699431470994, 'Total loss': 0.14904699431470994}
2022-12-31 02:47:03,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:03,223 INFO:     Epoch: 50
2022-12-31 02:47:04,888 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.514571925997734, 'Total loss': 0.514571925997734} | train loss {'Reaction outcome loss': 0.14638027620495067, 'Total loss': 0.14638027620495067}
2022-12-31 02:47:04,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:04,888 INFO:     Epoch: 51
2022-12-31 02:47:06,554 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5070799708366394, 'Total loss': 0.5070799708366394} | train loss {'Reaction outcome loss': 0.16220510465849447, 'Total loss': 0.16220510465849447}
2022-12-31 02:47:06,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:06,554 INFO:     Epoch: 52
2022-12-31 02:47:08,172 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5105900804201762, 'Total loss': 0.5105900804201762} | train loss {'Reaction outcome loss': 0.14131687439141283, 'Total loss': 0.14131687439141283}
2022-12-31 02:47:08,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:08,172 INFO:     Epoch: 53
2022-12-31 02:47:09,795 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5191655069589615, 'Total loss': 0.5191655069589615} | train loss {'Reaction outcome loss': 0.14229641890531217, 'Total loss': 0.14229641890531217}
2022-12-31 02:47:09,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:09,795 INFO:     Epoch: 54
2022-12-31 02:47:11,421 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5180556664864222, 'Total loss': 0.5180556664864222} | train loss {'Reaction outcome loss': 0.14873285203719971, 'Total loss': 0.14873285203719971}
2022-12-31 02:47:11,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:11,422 INFO:     Epoch: 55
2022-12-31 02:47:13,048 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5111349493265152, 'Total loss': 0.5111349493265152} | train loss {'Reaction outcome loss': 0.13228227743240786, 'Total loss': 0.13228227743240786}
2022-12-31 02:47:13,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:13,048 INFO:     Epoch: 56
2022-12-31 02:47:14,676 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5031895935535431, 'Total loss': 0.5031895935535431} | train loss {'Reaction outcome loss': 0.133564684031349, 'Total loss': 0.133564684031349}
2022-12-31 02:47:14,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:14,677 INFO:     Epoch: 57
2022-12-31 02:47:16,308 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5418655057748158, 'Total loss': 0.5418655057748158} | train loss {'Reaction outcome loss': 0.13016247669525066, 'Total loss': 0.13016247669525066}
2022-12-31 02:47:16,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:16,308 INFO:     Epoch: 58
2022-12-31 02:47:17,934 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.520724109808604, 'Total loss': 0.520724109808604} | train loss {'Reaction outcome loss': 0.13415473179412546, 'Total loss': 0.13415473179412546}
2022-12-31 02:47:17,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:17,935 INFO:     Epoch: 59
2022-12-31 02:47:19,574 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5399370928605397, 'Total loss': 0.5399370928605397} | train loss {'Reaction outcome loss': 0.1332381852578534, 'Total loss': 0.1332381852578534}
2022-12-31 02:47:19,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:19,574 INFO:     Epoch: 60
2022-12-31 02:47:21,237 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5232893745104472, 'Total loss': 0.5232893745104472} | train loss {'Reaction outcome loss': 0.12723087579963802, 'Total loss': 0.12723087579963802}
2022-12-31 02:47:21,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:21,238 INFO:     Epoch: 61
2022-12-31 02:47:22,898 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5369362264871598, 'Total loss': 0.5369362264871598} | train loss {'Reaction outcome loss': 0.12729364094186324, 'Total loss': 0.12729364094186324}
2022-12-31 02:47:22,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:22,898 INFO:     Epoch: 62
2022-12-31 02:47:24,557 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4995853861172994, 'Total loss': 0.4995853861172994} | train loss {'Reaction outcome loss': 0.12992149638572248, 'Total loss': 0.12992149638572248}
2022-12-31 02:47:24,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:24,557 INFO:     Epoch: 63
2022-12-31 02:47:26,217 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5566058993339539, 'Total loss': 0.5566058993339539} | train loss {'Reaction outcome loss': 0.1272084075810752, 'Total loss': 0.1272084075810752}
2022-12-31 02:47:26,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:26,217 INFO:     Epoch: 64
2022-12-31 02:47:27,841 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5541183114051819, 'Total loss': 0.5541183114051819} | train loss {'Reaction outcome loss': 0.12927650495734816, 'Total loss': 0.12927650495734816}
2022-12-31 02:47:27,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:27,841 INFO:     Epoch: 65
2022-12-31 02:47:29,453 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.526076290011406, 'Total loss': 0.526076290011406} | train loss {'Reaction outcome loss': 0.12390772543638351, 'Total loss': 0.12390772543638351}
2022-12-31 02:47:29,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:29,453 INFO:     Epoch: 66
2022-12-31 02:47:31,076 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5314312954743703, 'Total loss': 0.5314312954743703} | train loss {'Reaction outcome loss': 0.12737518831736583, 'Total loss': 0.12737518831736583}
2022-12-31 02:47:31,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:31,076 INFO:     Epoch: 67
2022-12-31 02:47:32,706 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5199171473582586, 'Total loss': 0.5199171473582586} | train loss {'Reaction outcome loss': 0.12434003706658732, 'Total loss': 0.12434003706658732}
2022-12-31 02:47:32,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:32,707 INFO:     Epoch: 68
2022-12-31 02:47:34,367 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5416061917940775, 'Total loss': 0.5416061917940775} | train loss {'Reaction outcome loss': 0.12434196680778373, 'Total loss': 0.12434196680778373}
2022-12-31 02:47:34,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:34,367 INFO:     Epoch: 69
2022-12-31 02:47:35,984 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5096897562344869, 'Total loss': 0.5096897562344869} | train loss {'Reaction outcome loss': 0.1245422938326128, 'Total loss': 0.1245422938326128}
2022-12-31 02:47:35,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:35,985 INFO:     Epoch: 70
2022-12-31 02:47:37,594 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5206435551246007, 'Total loss': 0.5206435551246007} | train loss {'Reaction outcome loss': 0.12289660784122332, 'Total loss': 0.12289660784122332}
2022-12-31 02:47:37,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:37,594 INFO:     Epoch: 71
2022-12-31 02:47:39,254 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5226112276315689, 'Total loss': 0.5226112276315689} | train loss {'Reaction outcome loss': 0.1233450774376726, 'Total loss': 0.1233450774376726}
2022-12-31 02:47:39,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:39,255 INFO:     Epoch: 72
2022-12-31 02:47:40,916 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48868012527624766, 'Total loss': 0.48868012527624766} | train loss {'Reaction outcome loss': 0.12492035403662105, 'Total loss': 0.12492035403662105}
2022-12-31 02:47:40,916 INFO:     Found new best model at epoch 72
2022-12-31 02:47:40,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:40,917 INFO:     Epoch: 73
2022-12-31 02:47:42,529 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5324127207199733, 'Total loss': 0.5324127207199733} | train loss {'Reaction outcome loss': 0.1187387296193502, 'Total loss': 0.1187387296193502}
2022-12-31 02:47:42,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:42,530 INFO:     Epoch: 74
2022-12-31 02:47:44,191 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4858536740144094, 'Total loss': 0.4858536740144094} | train loss {'Reaction outcome loss': 0.11942223663672981, 'Total loss': 0.11942223663672981}
2022-12-31 02:47:44,191 INFO:     Found new best model at epoch 74
2022-12-31 02:47:44,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:44,192 INFO:     Epoch: 75
2022-12-31 02:47:45,816 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5147819101810456, 'Total loss': 0.5147819101810456} | train loss {'Reaction outcome loss': 0.11823760480151775, 'Total loss': 0.11823760480151775}
2022-12-31 02:47:45,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:45,816 INFO:     Epoch: 76
2022-12-31 02:47:47,430 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5002992292245229, 'Total loss': 0.5002992292245229} | train loss {'Reaction outcome loss': 0.12066315683583473, 'Total loss': 0.12066315683583473}
2022-12-31 02:47:47,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:47,431 INFO:     Epoch: 77
2022-12-31 02:47:49,044 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4930456876754761, 'Total loss': 0.4930456876754761} | train loss {'Reaction outcome loss': 0.11918238017664329, 'Total loss': 0.11918238017664329}
2022-12-31 02:47:49,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:49,044 INFO:     Epoch: 78
2022-12-31 02:47:50,704 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5047867129246394, 'Total loss': 0.5047867129246394} | train loss {'Reaction outcome loss': 0.1152493455649718, 'Total loss': 0.1152493455649718}
2022-12-31 02:47:50,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:50,704 INFO:     Epoch: 79
2022-12-31 02:47:52,324 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5035498400529226, 'Total loss': 0.5035498400529226} | train loss {'Reaction outcome loss': 0.11749550964315489, 'Total loss': 0.11749550964315489}
2022-12-31 02:47:52,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:52,324 INFO:     Epoch: 80
2022-12-31 02:47:53,984 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5617031365633011, 'Total loss': 0.5617031365633011} | train loss {'Reaction outcome loss': 0.12338065317379769, 'Total loss': 0.12338065317379769}
2022-12-31 02:47:53,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:53,985 INFO:     Epoch: 81
2022-12-31 02:47:55,619 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.517608509461085, 'Total loss': 0.517608509461085} | train loss {'Reaction outcome loss': 0.12300178736778974, 'Total loss': 0.12300178736778974}
2022-12-31 02:47:55,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:55,619 INFO:     Epoch: 82
2022-12-31 02:47:57,246 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5181920150915782, 'Total loss': 0.5181920150915782} | train loss {'Reaction outcome loss': 0.11709602289930984, 'Total loss': 0.11709602289930984}
2022-12-31 02:47:57,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:57,246 INFO:     Epoch: 83
2022-12-31 02:47:58,960 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5089973688125611, 'Total loss': 0.5089973688125611} | train loss {'Reaction outcome loss': 0.11393965358650388, 'Total loss': 0.11393965358650388}
2022-12-31 02:47:58,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:47:58,960 INFO:     Epoch: 84
2022-12-31 02:48:00,588 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5629310141007106, 'Total loss': 0.5629310141007106} | train loss {'Reaction outcome loss': 0.11115516452085011, 'Total loss': 0.11115516452085011}
2022-12-31 02:48:00,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:00,588 INFO:     Epoch: 85
2022-12-31 02:48:02,255 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.500174367427826, 'Total loss': 0.500174367427826} | train loss {'Reaction outcome loss': 0.11682453859880891, 'Total loss': 0.11682453859880891}
2022-12-31 02:48:02,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:02,256 INFO:     Epoch: 86
2022-12-31 02:48:03,905 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49434527854124705, 'Total loss': 0.49434527854124705} | train loss {'Reaction outcome loss': 0.11835686306996808, 'Total loss': 0.11835686306996808}
2022-12-31 02:48:03,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:03,905 INFO:     Epoch: 87
2022-12-31 02:48:05,558 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.55373009343942, 'Total loss': 0.55373009343942} | train loss {'Reaction outcome loss': 0.11328628326929532, 'Total loss': 0.11328628326929532}
2022-12-31 02:48:05,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:05,559 INFO:     Epoch: 88
2022-12-31 02:48:07,219 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.517937982082367, 'Total loss': 0.517937982082367} | train loss {'Reaction outcome loss': 0.11004055503450429, 'Total loss': 0.11004055503450429}
2022-12-31 02:48:07,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:07,220 INFO:     Epoch: 89
2022-12-31 02:48:08,836 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5181290417909622, 'Total loss': 0.5181290417909622} | train loss {'Reaction outcome loss': 0.11025289496077069, 'Total loss': 0.11025289496077069}
2022-12-31 02:48:08,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:08,837 INFO:     Epoch: 90
2022-12-31 02:48:10,497 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5279507358868917, 'Total loss': 0.5279507358868917} | train loss {'Reaction outcome loss': 0.11211345906462777, 'Total loss': 0.11211345906462777}
2022-12-31 02:48:10,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:10,497 INFO:     Epoch: 91
2022-12-31 02:48:12,143 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5256601889928182, 'Total loss': 0.5256601889928182} | train loss {'Reaction outcome loss': 0.11438923750635392, 'Total loss': 0.11438923750635392}
2022-12-31 02:48:12,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:12,143 INFO:     Epoch: 92
2022-12-31 02:48:13,755 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5450649281342824, 'Total loss': 0.5450649281342824} | train loss {'Reaction outcome loss': 0.11350661901525345, 'Total loss': 0.11350661901525345}
2022-12-31 02:48:13,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:13,755 INFO:     Epoch: 93
2022-12-31 02:48:15,371 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5097493469715119, 'Total loss': 0.5097493469715119} | train loss {'Reaction outcome loss': 0.11287419012312414, 'Total loss': 0.11287419012312414}
2022-12-31 02:48:15,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:15,372 INFO:     Epoch: 94
2022-12-31 02:48:17,002 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.529697526494662, 'Total loss': 0.529697526494662} | train loss {'Reaction outcome loss': 0.11030655097557178, 'Total loss': 0.11030655097557178}
2022-12-31 02:48:17,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:17,002 INFO:     Epoch: 95
2022-12-31 02:48:18,626 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5335030009349188, 'Total loss': 0.5335030009349188} | train loss {'Reaction outcome loss': 0.10945162390145555, 'Total loss': 0.10945162390145555}
2022-12-31 02:48:18,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:18,626 INFO:     Epoch: 96
2022-12-31 02:48:20,243 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5162384808063507, 'Total loss': 0.5162384808063507} | train loss {'Reaction outcome loss': 0.11093666809028946, 'Total loss': 0.11093666809028946}
2022-12-31 02:48:20,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:20,243 INFO:     Epoch: 97
2022-12-31 02:48:21,905 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5606315781672796, 'Total loss': 0.5606315781672796} | train loss {'Reaction outcome loss': 0.11503295248468826, 'Total loss': 0.11503295248468826}
2022-12-31 02:48:21,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:21,905 INFO:     Epoch: 98
2022-12-31 02:48:23,530 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5330383002758026, 'Total loss': 0.5330383002758026} | train loss {'Reaction outcome loss': 0.1084483125707571, 'Total loss': 0.1084483125707571}
2022-12-31 02:48:23,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:23,532 INFO:     Epoch: 99
2022-12-31 02:48:25,160 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5545652468999227, 'Total loss': 0.5545652468999227} | train loss {'Reaction outcome loss': 0.1087179223338709, 'Total loss': 0.1087179223338709}
2022-12-31 02:48:25,160 INFO:     Best model found after epoch 75 of 100.
2022-12-31 02:48:25,160 INFO:   Done with stage: TRAINING
2022-12-31 02:48:25,160 INFO:   Starting stage: EVALUATION
2022-12-31 02:48:25,290 INFO:   Done with stage: EVALUATION
2022-12-31 02:48:25,290 INFO:   Leaving out SEQ value Fold_2
2022-12-31 02:48:25,302 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 02:48:25,303 INFO:   Starting stage: FEATURE SCALING
2022-12-31 02:48:25,947 INFO:   Done with stage: FEATURE SCALING
2022-12-31 02:48:25,947 INFO:   Starting stage: SCALING TARGETS
2022-12-31 02:48:26,019 INFO:   Done with stage: SCALING TARGETS
2022-12-31 02:48:26,019 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 02:48:26,020 INFO:     No hyperparam tuning for this model
2022-12-31 02:48:26,020 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 02:48:26,020 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 02:48:26,020 INFO:     None feature selector for col prot
2022-12-31 02:48:26,021 INFO:     None feature selector for col prot
2022-12-31 02:48:26,021 INFO:     None feature selector for col prot
2022-12-31 02:48:26,021 INFO:     None feature selector for col chem
2022-12-31 02:48:26,021 INFO:     None feature selector for col chem
2022-12-31 02:48:26,021 INFO:     None feature selector for col chem
2022-12-31 02:48:26,021 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 02:48:26,021 INFO:   Starting stage: BUILD MODEL
2022-12-31 02:48:26,023 INFO:     Number of params in model 224011
2022-12-31 02:48:26,026 INFO:   Done with stage: BUILD MODEL
2022-12-31 02:48:26,027 INFO:   Starting stage: TRAINING
2022-12-31 02:48:26,071 INFO:     Val loss before train {'Reaction outcome loss': 0.9445464332898458, 'Total loss': 0.9445464332898458}
2022-12-31 02:48:26,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:26,071 INFO:     Epoch: 0
2022-12-31 02:48:27,687 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5208388328552246, 'Total loss': 0.5208388328552246} | train loss {'Reaction outcome loss': 0.7732992122208115, 'Total loss': 0.7732992122208115}
2022-12-31 02:48:27,688 INFO:     Found new best model at epoch 0
2022-12-31 02:48:27,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:27,689 INFO:     Epoch: 1
2022-12-31 02:48:29,297 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.44777926802635193, 'Total loss': 0.44777926802635193} | train loss {'Reaction outcome loss': 0.5174302378275099, 'Total loss': 0.5174302378275099}
2022-12-31 02:48:29,297 INFO:     Found new best model at epoch 1
2022-12-31 02:48:29,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:29,298 INFO:     Epoch: 2
2022-12-31 02:48:30,901 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4185020824273427, 'Total loss': 0.4185020824273427} | train loss {'Reaction outcome loss': 0.44964737956323764, 'Total loss': 0.44964737956323764}
2022-12-31 02:48:30,902 INFO:     Found new best model at epoch 2
2022-12-31 02:48:30,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:30,903 INFO:     Epoch: 3
2022-12-31 02:48:32,509 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.38883264660835265, 'Total loss': 0.38883264660835265} | train loss {'Reaction outcome loss': 0.4081672948044147, 'Total loss': 0.4081672948044147}
2022-12-31 02:48:32,509 INFO:     Found new best model at epoch 3
2022-12-31 02:48:32,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:32,510 INFO:     Epoch: 4
2022-12-31 02:48:34,114 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.3737305819988251, 'Total loss': 0.3737305819988251} | train loss {'Reaction outcome loss': 0.38314761553150023, 'Total loss': 0.38314761553150023}
2022-12-31 02:48:34,114 INFO:     Found new best model at epoch 4
2022-12-31 02:48:34,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:34,115 INFO:     Epoch: 5
2022-12-31 02:48:35,721 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3699384500583013, 'Total loss': 0.3699384500583013} | train loss {'Reaction outcome loss': 0.3573048274393064, 'Total loss': 0.3573048274393064}
2022-12-31 02:48:35,721 INFO:     Found new best model at epoch 5
2022-12-31 02:48:35,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:35,723 INFO:     Epoch: 6
2022-12-31 02:48:37,358 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3668490042289098, 'Total loss': 0.3668490042289098} | train loss {'Reaction outcome loss': 0.33657426117871797, 'Total loss': 0.33657426117871797}
2022-12-31 02:48:37,358 INFO:     Found new best model at epoch 6
2022-12-31 02:48:37,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:37,359 INFO:     Epoch: 7
2022-12-31 02:48:38,962 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.37718872328599296, 'Total loss': 0.37718872328599296} | train loss {'Reaction outcome loss': 0.3176836399157552, 'Total loss': 0.3176836399157552}
2022-12-31 02:48:38,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:38,963 INFO:     Epoch: 8
2022-12-31 02:48:40,594 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3726715604464213, 'Total loss': 0.3726715604464213} | train loss {'Reaction outcome loss': 0.3053582318834145, 'Total loss': 0.3053582318834145}
2022-12-31 02:48:40,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:40,594 INFO:     Epoch: 9
2022-12-31 02:48:42,196 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3612872858842214, 'Total loss': 0.3612872858842214} | train loss {'Reaction outcome loss': 0.28927320511127913, 'Total loss': 0.28927320511127913}
2022-12-31 02:48:42,197 INFO:     Found new best model at epoch 9
2022-12-31 02:48:42,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:42,198 INFO:     Epoch: 10
2022-12-31 02:48:43,818 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.38434454103310906, 'Total loss': 0.38434454103310906} | train loss {'Reaction outcome loss': 0.28004850933912895, 'Total loss': 0.28004850933912895}
2022-12-31 02:48:43,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:43,819 INFO:     Epoch: 11
2022-12-31 02:48:45,440 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.35553312798341113, 'Total loss': 0.35553312798341113} | train loss {'Reaction outcome loss': 0.2662528572182586, 'Total loss': 0.2662528572182586}
2022-12-31 02:48:45,440 INFO:     Found new best model at epoch 11
2022-12-31 02:48:45,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:45,441 INFO:     Epoch: 12
2022-12-31 02:48:47,060 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39879648288091024, 'Total loss': 0.39879648288091024} | train loss {'Reaction outcome loss': 0.25536307992998264, 'Total loss': 0.25536307992998264}
2022-12-31 02:48:47,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:47,060 INFO:     Epoch: 13
2022-12-31 02:48:48,677 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3831305056810379, 'Total loss': 0.3831305056810379} | train loss {'Reaction outcome loss': 0.2467408772816297, 'Total loss': 0.2467408772816297}
2022-12-31 02:48:48,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:48,677 INFO:     Epoch: 14
2022-12-31 02:48:50,291 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3573100099960963, 'Total loss': 0.3573100099960963} | train loss {'Reaction outcome loss': 0.24201534620492998, 'Total loss': 0.24201534620492998}
2022-12-31 02:48:50,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:50,291 INFO:     Epoch: 15
2022-12-31 02:48:51,944 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.378225721915563, 'Total loss': 0.378225721915563} | train loss {'Reaction outcome loss': 0.23016569847037105, 'Total loss': 0.23016569847037105}
2022-12-31 02:48:51,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:51,944 INFO:     Epoch: 16
2022-12-31 02:48:53,554 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.36382612387339275, 'Total loss': 0.36382612387339275} | train loss {'Reaction outcome loss': 0.22554722754624637, 'Total loss': 0.22554722754624637}
2022-12-31 02:48:53,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:53,554 INFO:     Epoch: 17
2022-12-31 02:48:55,206 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3885196417570114, 'Total loss': 0.3885196417570114} | train loss {'Reaction outcome loss': 0.21728966858265172, 'Total loss': 0.21728966858265172}
2022-12-31 02:48:55,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:55,207 INFO:     Epoch: 18
2022-12-31 02:48:56,859 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.37642635802427926, 'Total loss': 0.37642635802427926} | train loss {'Reaction outcome loss': 0.2128337520806894, 'Total loss': 0.2128337520806894}
2022-12-31 02:48:56,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:56,859 INFO:     Epoch: 19
2022-12-31 02:48:58,385 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3902468899885813, 'Total loss': 0.3902468899885813} | train loss {'Reaction outcome loss': 0.20642367994453567, 'Total loss': 0.20642367994453567}
2022-12-31 02:48:58,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:58,386 INFO:     Epoch: 20
2022-12-31 02:48:59,523 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3872188409169515, 'Total loss': 0.3872188409169515} | train loss {'Reaction outcome loss': 0.20001590581624396, 'Total loss': 0.20001590581624396}
2022-12-31 02:48:59,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:48:59,523 INFO:     Epoch: 21
2022-12-31 02:49:00,645 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3702183206876119, 'Total loss': 0.3702183206876119} | train loss {'Reaction outcome loss': 0.1948988624392961, 'Total loss': 0.1948988624392961}
2022-12-31 02:49:00,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:00,645 INFO:     Epoch: 22
2022-12-31 02:49:01,770 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.395356755455335, 'Total loss': 0.395356755455335} | train loss {'Reaction outcome loss': 0.1941561593273043, 'Total loss': 0.1941561593273043}
2022-12-31 02:49:01,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:01,770 INFO:     Epoch: 23
2022-12-31 02:49:02,967 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39908980031808217, 'Total loss': 0.39908980031808217} | train loss {'Reaction outcome loss': 0.18847475733852734, 'Total loss': 0.18847475733852734}
2022-12-31 02:49:02,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:02,967 INFO:     Epoch: 24
2022-12-31 02:49:04,586 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.37275853951772053, 'Total loss': 0.37275853951772053} | train loss {'Reaction outcome loss': 0.1823886398695083, 'Total loss': 0.1823886398695083}
2022-12-31 02:49:04,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:04,587 INFO:     Epoch: 25
2022-12-31 02:49:06,200 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40180395990610124, 'Total loss': 0.40180395990610124} | train loss {'Reaction outcome loss': 0.18115995532024082, 'Total loss': 0.18115995532024082}
2022-12-31 02:49:06,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:06,200 INFO:     Epoch: 26
2022-12-31 02:49:07,850 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4064062833786011, 'Total loss': 0.4064062833786011} | train loss {'Reaction outcome loss': 0.1768456711399838, 'Total loss': 0.1768456711399838}
2022-12-31 02:49:07,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:07,850 INFO:     Epoch: 27
2022-12-31 02:49:09,501 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41703887581825255, 'Total loss': 0.41703887581825255} | train loss {'Reaction outcome loss': 0.17270096689190742, 'Total loss': 0.17270096689190742}
2022-12-31 02:49:09,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:09,501 INFO:     Epoch: 28
2022-12-31 02:49:11,130 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43144001960754397, 'Total loss': 0.43144001960754397} | train loss {'Reaction outcome loss': 0.1725727785038796, 'Total loss': 0.1725727785038796}
2022-12-31 02:49:11,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:11,130 INFO:     Epoch: 29
2022-12-31 02:49:12,754 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4024083028237025, 'Total loss': 0.4024083028237025} | train loss {'Reaction outcome loss': 0.17018960920386833, 'Total loss': 0.17018960920386833}
2022-12-31 02:49:12,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:12,754 INFO:     Epoch: 30
2022-12-31 02:49:14,408 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4042089809974035, 'Total loss': 0.4042089809974035} | train loss {'Reaction outcome loss': 0.1641726548287229, 'Total loss': 0.1641726548287229}
2022-12-31 02:49:14,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:14,408 INFO:     Epoch: 31
2022-12-31 02:49:16,030 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39739684959252675, 'Total loss': 0.39739684959252675} | train loss {'Reaction outcome loss': 0.16667567845773848, 'Total loss': 0.16667567845773848}
2022-12-31 02:49:16,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:16,030 INFO:     Epoch: 32
2022-12-31 02:49:17,683 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.410534613331159, 'Total loss': 0.410534613331159} | train loss {'Reaction outcome loss': 0.16039830389820095, 'Total loss': 0.16039830389820095}
2022-12-31 02:49:17,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:17,684 INFO:     Epoch: 33
2022-12-31 02:49:19,333 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.37895786042014756, 'Total loss': 0.37895786042014756} | train loss {'Reaction outcome loss': 0.16260584747677084, 'Total loss': 0.16260584747677084}
2022-12-31 02:49:19,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:19,334 INFO:     Epoch: 34
2022-12-31 02:49:20,985 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38240511566400526, 'Total loss': 0.38240511566400526} | train loss {'Reaction outcome loss': 0.1592084878858478, 'Total loss': 0.1592084878858478}
2022-12-31 02:49:20,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:20,985 INFO:     Epoch: 35
2022-12-31 02:49:22,616 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3974005381266276, 'Total loss': 0.3974005381266276} | train loss {'Reaction outcome loss': 0.15585523341394905, 'Total loss': 0.15585523341394905}
2022-12-31 02:49:22,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:22,616 INFO:     Epoch: 36
2022-12-31 02:49:24,236 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40962548355261486, 'Total loss': 0.40962548355261486} | train loss {'Reaction outcome loss': 0.1539907020917774, 'Total loss': 0.1539907020917774}
2022-12-31 02:49:24,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:24,236 INFO:     Epoch: 37
2022-12-31 02:49:25,853 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4171762044231097, 'Total loss': 0.4171762044231097} | train loss {'Reaction outcome loss': 0.15408323980174468, 'Total loss': 0.15408323980174468}
2022-12-31 02:49:25,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:25,853 INFO:     Epoch: 38
2022-12-31 02:49:27,457 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3827814678351084, 'Total loss': 0.3827814678351084} | train loss {'Reaction outcome loss': 0.14812301096581196, 'Total loss': 0.14812301096581196}
2022-12-31 02:49:27,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:27,457 INFO:     Epoch: 39
2022-12-31 02:49:29,110 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43045859734217323, 'Total loss': 0.43045859734217323} | train loss {'Reaction outcome loss': 0.14828030176351975, 'Total loss': 0.14828030176351975}
2022-12-31 02:49:29,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:29,111 INFO:     Epoch: 40
2022-12-31 02:49:30,721 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.397287259499232, 'Total loss': 0.397287259499232} | train loss {'Reaction outcome loss': 0.1463368685718925, 'Total loss': 0.1463368685718925}
2022-12-31 02:49:30,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:30,721 INFO:     Epoch: 41
2022-12-31 02:49:32,364 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41153573493162793, 'Total loss': 0.41153573493162793} | train loss {'Reaction outcome loss': 0.14634177555078573, 'Total loss': 0.14634177555078573}
2022-12-31 02:49:32,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:32,364 INFO:     Epoch: 42
2022-12-31 02:49:34,003 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4130271504322688, 'Total loss': 0.4130271504322688} | train loss {'Reaction outcome loss': 0.1445350232092242, 'Total loss': 0.1445350232092242}
2022-12-31 02:49:34,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:34,003 INFO:     Epoch: 43
2022-12-31 02:49:35,625 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3758454142759244, 'Total loss': 0.3758454142759244} | train loss {'Reaction outcome loss': 0.1438701312010088, 'Total loss': 0.1438701312010088}
2022-12-31 02:49:35,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:35,626 INFO:     Epoch: 44
2022-12-31 02:49:37,241 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.389641913274924, 'Total loss': 0.389641913274924} | train loss {'Reaction outcome loss': 0.14378793683433294, 'Total loss': 0.14378793683433294}
2022-12-31 02:49:37,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:37,242 INFO:     Epoch: 45
2022-12-31 02:49:38,892 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39536016086737313, 'Total loss': 0.39536016086737313} | train loss {'Reaction outcome loss': 0.14355239940018658, 'Total loss': 0.14355239940018658}
2022-12-31 02:49:38,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:38,892 INFO:     Epoch: 46
2022-12-31 02:49:40,518 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39403439859549205, 'Total loss': 0.39403439859549205} | train loss {'Reaction outcome loss': 0.1388958245311884, 'Total loss': 0.1388958245311884}
2022-12-31 02:49:40,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:40,518 INFO:     Epoch: 47
2022-12-31 02:49:42,139 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4044521331787109, 'Total loss': 0.4044521331787109} | train loss {'Reaction outcome loss': 0.1348556363479282, 'Total loss': 0.1348556363479282}
2022-12-31 02:49:42,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:42,139 INFO:     Epoch: 48
2022-12-31 02:49:43,764 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3925349056720734, 'Total loss': 0.3925349056720734} | train loss {'Reaction outcome loss': 0.13440715798591502, 'Total loss': 0.13440715798591502}
2022-12-31 02:49:43,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:43,764 INFO:     Epoch: 49
2022-12-31 02:49:45,415 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44261391361554464, 'Total loss': 0.44261391361554464} | train loss {'Reaction outcome loss': 0.13297510433884296, 'Total loss': 0.13297510433884296}
2022-12-31 02:49:45,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:45,416 INFO:     Epoch: 50
2022-12-31 02:49:47,082 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3970651587471366, 'Total loss': 0.3970651587471366} | train loss {'Reaction outcome loss': 0.13545482753211782, 'Total loss': 0.13545482753211782}
2022-12-31 02:49:47,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:47,082 INFO:     Epoch: 51
2022-12-31 02:49:48,722 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.434396959344546, 'Total loss': 0.434396959344546} | train loss {'Reaction outcome loss': 0.13492939477772825, 'Total loss': 0.13492939477772825}
2022-12-31 02:49:48,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:48,722 INFO:     Epoch: 52
2022-12-31 02:49:50,319 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3957854986190796, 'Total loss': 0.3957854986190796} | train loss {'Reaction outcome loss': 0.1333854085813365, 'Total loss': 0.1333854085813365}
2022-12-31 02:49:50,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:50,319 INFO:     Epoch: 53
2022-12-31 02:49:51,969 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42134409546852114, 'Total loss': 0.42134409546852114} | train loss {'Reaction outcome loss': 0.13034953572957295, 'Total loss': 0.13034953572957295}
2022-12-31 02:49:51,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:51,969 INFO:     Epoch: 54
2022-12-31 02:49:53,578 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3964067819217841, 'Total loss': 0.3964067819217841} | train loss {'Reaction outcome loss': 0.13062033308482981, 'Total loss': 0.13062033308482981}
2022-12-31 02:49:53,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:53,578 INFO:     Epoch: 55
2022-12-31 02:49:55,201 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41318678309520085, 'Total loss': 0.41318678309520085} | train loss {'Reaction outcome loss': 0.13300061688493311, 'Total loss': 0.13300061688493311}
2022-12-31 02:49:55,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:55,202 INFO:     Epoch: 56
2022-12-31 02:49:56,815 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4402057508627574, 'Total loss': 0.4402057508627574} | train loss {'Reaction outcome loss': 0.13100682383906231, 'Total loss': 0.13100682383906231}
2022-12-31 02:49:56,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:56,816 INFO:     Epoch: 57
2022-12-31 02:49:58,454 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38225910887122155, 'Total loss': 0.38225910887122155} | train loss {'Reaction outcome loss': 0.13023671897699254, 'Total loss': 0.13023671897699254}
2022-12-31 02:49:58,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:49:58,454 INFO:     Epoch: 58
2022-12-31 02:50:00,101 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42339997589588163, 'Total loss': 0.42339997589588163} | train loss {'Reaction outcome loss': 0.12561838341244652, 'Total loss': 0.12561838341244652}
2022-12-31 02:50:00,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:00,102 INFO:     Epoch: 59
2022-12-31 02:50:01,710 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43316039790709815, 'Total loss': 0.43316039790709815} | train loss {'Reaction outcome loss': 0.12547446992146327, 'Total loss': 0.12547446992146327}
2022-12-31 02:50:01,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:01,710 INFO:     Epoch: 60
2022-12-31 02:50:03,332 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.418829008936882, 'Total loss': 0.418829008936882} | train loss {'Reaction outcome loss': 0.1293115744632363, 'Total loss': 0.1293115744632363}
2022-12-31 02:50:03,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:03,332 INFO:     Epoch: 61
2022-12-31 02:50:04,966 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4172883562743664, 'Total loss': 0.4172883562743664} | train loss {'Reaction outcome loss': 0.12457872970186065, 'Total loss': 0.12457872970186065}
2022-12-31 02:50:04,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:04,966 INFO:     Epoch: 62
2022-12-31 02:50:06,620 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42523845930894216, 'Total loss': 0.42523845930894216} | train loss {'Reaction outcome loss': 0.12397673868499424, 'Total loss': 0.12397673868499424}
2022-12-31 02:50:06,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:06,621 INFO:     Epoch: 63
2022-12-31 02:50:08,231 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41841105024019876, 'Total loss': 0.41841105024019876} | train loss {'Reaction outcome loss': 0.12208014968306805, 'Total loss': 0.12208014968306805}
2022-12-31 02:50:08,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:08,231 INFO:     Epoch: 64
2022-12-31 02:50:09,853 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3898573855559031, 'Total loss': 0.3898573855559031} | train loss {'Reaction outcome loss': 0.12151592830705871, 'Total loss': 0.12151592830705871}
2022-12-31 02:50:09,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:09,853 INFO:     Epoch: 65
2022-12-31 02:50:11,460 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4176921019951502, 'Total loss': 0.4176921019951502} | train loss {'Reaction outcome loss': 0.12003380842048023, 'Total loss': 0.12003380842048023}
2022-12-31 02:50:11,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:11,460 INFO:     Epoch: 66
2022-12-31 02:50:13,080 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37403216237823167, 'Total loss': 0.37403216237823167} | train loss {'Reaction outcome loss': 0.12432634254006573, 'Total loss': 0.12432634254006573}
2022-12-31 02:50:13,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:13,080 INFO:     Epoch: 67
2022-12-31 02:50:14,689 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3977909691631794, 'Total loss': 0.3977909691631794} | train loss {'Reaction outcome loss': 0.12110887305049674, 'Total loss': 0.12110887305049674}
2022-12-31 02:50:14,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:14,689 INFO:     Epoch: 68
2022-12-31 02:50:16,288 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3981960092981656, 'Total loss': 0.3981960092981656} | train loss {'Reaction outcome loss': 0.1248917322704419, 'Total loss': 0.1248917322704419}
2022-12-31 02:50:16,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:16,288 INFO:     Epoch: 69
2022-12-31 02:50:17,908 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40822183961669606, 'Total loss': 0.40822183961669606} | train loss {'Reaction outcome loss': 0.11844505591617122, 'Total loss': 0.11844505591617122}
2022-12-31 02:50:17,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:17,908 INFO:     Epoch: 70
2022-12-31 02:50:19,560 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4067419777313868, 'Total loss': 0.4067419777313868} | train loss {'Reaction outcome loss': 0.11858884373299071, 'Total loss': 0.11858884373299071}
2022-12-31 02:50:19,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:19,561 INFO:     Epoch: 71
2022-12-31 02:50:21,171 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44141837358474734, 'Total loss': 0.44141837358474734} | train loss {'Reaction outcome loss': 0.11581634397339756, 'Total loss': 0.11581634397339756}
2022-12-31 02:50:21,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:21,172 INFO:     Epoch: 72
2022-12-31 02:50:22,791 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40828686704238254, 'Total loss': 0.40828686704238254} | train loss {'Reaction outcome loss': 0.12191384225186423, 'Total loss': 0.12191384225186423}
2022-12-31 02:50:22,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:22,791 INFO:     Epoch: 73
2022-12-31 02:50:24,413 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41702532867590586, 'Total loss': 0.41702532867590586} | train loss {'Reaction outcome loss': 0.11639683768425109, 'Total loss': 0.11639683768425109}
2022-12-31 02:50:24,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:24,414 INFO:     Epoch: 74
2022-12-31 02:50:26,027 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39383323341608045, 'Total loss': 0.39383323341608045} | train loss {'Reaction outcome loss': 0.11683672687113557, 'Total loss': 0.11683672687113557}
2022-12-31 02:50:26,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:26,027 INFO:     Epoch: 75
2022-12-31 02:50:27,669 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4017339626948039, 'Total loss': 0.4017339626948039} | train loss {'Reaction outcome loss': 0.11454952113758636, 'Total loss': 0.11454952113758636}
2022-12-31 02:50:27,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:27,670 INFO:     Epoch: 76
2022-12-31 02:50:29,307 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37812835946679113, 'Total loss': 0.37812835946679113} | train loss {'Reaction outcome loss': 0.1164075756992764, 'Total loss': 0.1164075756992764}
2022-12-31 02:50:29,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:29,307 INFO:     Epoch: 77
2022-12-31 02:50:30,960 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4282335937023163, 'Total loss': 0.4282335937023163} | train loss {'Reaction outcome loss': 0.11769923187510185, 'Total loss': 0.11769923187510185}
2022-12-31 02:50:30,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:30,961 INFO:     Epoch: 78
2022-12-31 02:50:32,566 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4038238068421682, 'Total loss': 0.4038238068421682} | train loss {'Reaction outcome loss': 0.11226784441123859, 'Total loss': 0.11226784441123859}
2022-12-31 02:50:32,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:32,566 INFO:     Epoch: 79
2022-12-31 02:50:34,218 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3656339004635811, 'Total loss': 0.3656339004635811} | train loss {'Reaction outcome loss': 0.11358426007727691, 'Total loss': 0.11358426007727691}
2022-12-31 02:50:34,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:34,218 INFO:     Epoch: 80
2022-12-31 02:50:35,835 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4079142623891433, 'Total loss': 0.4079142623891433} | train loss {'Reaction outcome loss': 0.11541464931695267, 'Total loss': 0.11541464931695267}
2022-12-31 02:50:35,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:35,835 INFO:     Epoch: 81
2022-12-31 02:50:37,490 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4067276338736216, 'Total loss': 0.4067276338736216} | train loss {'Reaction outcome loss': 0.1119475677255949, 'Total loss': 0.1119475677255949}
2022-12-31 02:50:37,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:37,491 INFO:     Epoch: 82
2022-12-31 02:50:39,106 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41169218669335045, 'Total loss': 0.41169218669335045} | train loss {'Reaction outcome loss': 0.11373844080822149, 'Total loss': 0.11373844080822149}
2022-12-31 02:50:39,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:39,107 INFO:     Epoch: 83
2022-12-31 02:50:40,726 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39928365101416907, 'Total loss': 0.39928365101416907} | train loss {'Reaction outcome loss': 0.10825026718505325, 'Total loss': 0.10825026718505325}
2022-12-31 02:50:40,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:40,726 INFO:     Epoch: 84
2022-12-31 02:50:42,341 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4245515312999487, 'Total loss': 0.4245515312999487} | train loss {'Reaction outcome loss': 0.11265931755345124, 'Total loss': 0.11265931755345124}
2022-12-31 02:50:42,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:42,341 INFO:     Epoch: 85
2022-12-31 02:50:43,946 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4464478631814321, 'Total loss': 0.4464478631814321} | train loss {'Reaction outcome loss': 0.11911350292796065, 'Total loss': 0.11911350292796065}
2022-12-31 02:50:43,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:43,946 INFO:     Epoch: 86
2022-12-31 02:50:45,550 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38741521363457043, 'Total loss': 0.38741521363457043} | train loss {'Reaction outcome loss': 0.11858133351036014, 'Total loss': 0.11858133351036014}
2022-12-31 02:50:45,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:45,550 INFO:     Epoch: 87
2022-12-31 02:50:47,150 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4235265875856082, 'Total loss': 0.4235265875856082} | train loss {'Reaction outcome loss': 0.117828096846037, 'Total loss': 0.117828096846037}
2022-12-31 02:50:47,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:47,151 INFO:     Epoch: 88
2022-12-31 02:50:48,756 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43458484709262846, 'Total loss': 0.43458484709262846} | train loss {'Reaction outcome loss': 0.10906199379535188, 'Total loss': 0.10906199379535188}
2022-12-31 02:50:48,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:48,756 INFO:     Epoch: 89
2022-12-31 02:50:50,372 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44585156242052715, 'Total loss': 0.44585156242052715} | train loss {'Reaction outcome loss': 0.10890008011547318, 'Total loss': 0.10890008011547318}
2022-12-31 02:50:50,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:50,373 INFO:     Epoch: 90
2022-12-31 02:50:51,999 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41090453962484996, 'Total loss': 0.41090453962484996} | train loss {'Reaction outcome loss': 0.10789813649038492, 'Total loss': 0.10789813649038492}
2022-12-31 02:50:51,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:51,999 INFO:     Epoch: 91
2022-12-31 02:50:53,617 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4003831376632055, 'Total loss': 0.4003831376632055} | train loss {'Reaction outcome loss': 0.10959295467235637, 'Total loss': 0.10959295467235637}
2022-12-31 02:50:53,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:53,617 INFO:     Epoch: 92
2022-12-31 02:50:55,269 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4040852189064026, 'Total loss': 0.4040852189064026} | train loss {'Reaction outcome loss': 0.11205618294979017, 'Total loss': 0.11205618294979017}
2022-12-31 02:50:55,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:55,269 INFO:     Epoch: 93
2022-12-31 02:50:56,900 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4220329483350118, 'Total loss': 0.4220329483350118} | train loss {'Reaction outcome loss': 0.11561677292376811, 'Total loss': 0.11561677292376811}
2022-12-31 02:50:56,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:56,900 INFO:     Epoch: 94
2022-12-31 02:50:58,518 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4321908781925837, 'Total loss': 0.4321908781925837} | train loss {'Reaction outcome loss': 0.11765662762404412, 'Total loss': 0.11765662762404412}
2022-12-31 02:50:58,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:50:58,518 INFO:     Epoch: 95
2022-12-31 02:51:00,137 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41915926784276963, 'Total loss': 0.41915926784276963} | train loss {'Reaction outcome loss': 0.11134434079778564, 'Total loss': 0.11134434079778564}
2022-12-31 02:51:00,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:00,137 INFO:     Epoch: 96
2022-12-31 02:51:01,747 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41206101576487225, 'Total loss': 0.41206101576487225} | train loss {'Reaction outcome loss': 0.10951657797529424, 'Total loss': 0.10951657797529424}
2022-12-31 02:51:01,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:01,748 INFO:     Epoch: 97
2022-12-31 02:51:03,346 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3954254458347956, 'Total loss': 0.3954254458347956} | train loss {'Reaction outcome loss': 0.10811729389191843, 'Total loss': 0.10811729389191843}
2022-12-31 02:51:03,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:03,347 INFO:     Epoch: 98
2022-12-31 02:51:04,948 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4046017587184906, 'Total loss': 0.4046017587184906} | train loss {'Reaction outcome loss': 0.10842695592453934, 'Total loss': 0.10842695592453934}
2022-12-31 02:51:04,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:04,949 INFO:     Epoch: 99
2022-12-31 02:51:06,565 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3818751076857249, 'Total loss': 0.3818751076857249} | train loss {'Reaction outcome loss': 0.10769884625660514, 'Total loss': 0.10769884625660514}
2022-12-31 02:51:06,565 INFO:     Best model found after epoch 12 of 100.
2022-12-31 02:51:06,565 INFO:   Done with stage: TRAINING
2022-12-31 02:51:06,566 INFO:   Starting stage: EVALUATION
2022-12-31 02:51:06,704 INFO:   Done with stage: EVALUATION
2022-12-31 02:51:06,704 INFO:   Leaving out SEQ value Fold_3
2022-12-31 02:51:06,716 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 02:51:06,717 INFO:   Starting stage: FEATURE SCALING
2022-12-31 02:51:07,368 INFO:   Done with stage: FEATURE SCALING
2022-12-31 02:51:07,368 INFO:   Starting stage: SCALING TARGETS
2022-12-31 02:51:07,440 INFO:   Done with stage: SCALING TARGETS
2022-12-31 02:51:07,440 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 02:51:07,440 INFO:     No hyperparam tuning for this model
2022-12-31 02:51:07,440 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 02:51:07,440 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 02:51:07,441 INFO:     None feature selector for col prot
2022-12-31 02:51:07,441 INFO:     None feature selector for col prot
2022-12-31 02:51:07,441 INFO:     None feature selector for col prot
2022-12-31 02:51:07,442 INFO:     None feature selector for col chem
2022-12-31 02:51:07,442 INFO:     None feature selector for col chem
2022-12-31 02:51:07,442 INFO:     None feature selector for col chem
2022-12-31 02:51:07,442 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 02:51:07,442 INFO:   Starting stage: BUILD MODEL
2022-12-31 02:51:07,444 INFO:     Number of params in model 224011
2022-12-31 02:51:07,447 INFO:   Done with stage: BUILD MODEL
2022-12-31 02:51:07,447 INFO:   Starting stage: TRAINING
2022-12-31 02:51:07,494 INFO:     Val loss before train {'Reaction outcome loss': 0.9997405131657918, 'Total loss': 0.9997405131657918}
2022-12-31 02:51:07,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:07,494 INFO:     Epoch: 0
2022-12-31 02:51:09,125 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5505296230316162, 'Total loss': 0.5505296230316162} | train loss {'Reaction outcome loss': 0.7824304684670302, 'Total loss': 0.7824304684670302}
2022-12-31 02:51:09,125 INFO:     Found new best model at epoch 0
2022-12-31 02:51:09,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:09,127 INFO:     Epoch: 1
2022-12-31 02:51:10,761 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5004780014355977, 'Total loss': 0.5004780014355977} | train loss {'Reaction outcome loss': 0.5141555135049959, 'Total loss': 0.5141555135049959}
2022-12-31 02:51:10,761 INFO:     Found new best model at epoch 1
2022-12-31 02:51:10,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:10,762 INFO:     Epoch: 2
2022-12-31 02:51:12,367 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48318463762601216, 'Total loss': 0.48318463762601216} | train loss {'Reaction outcome loss': 0.4530429258181231, 'Total loss': 0.4530429258181231}
2022-12-31 02:51:12,368 INFO:     Found new best model at epoch 2
2022-12-31 02:51:12,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:12,369 INFO:     Epoch: 3
2022-12-31 02:51:13,982 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4285659154256185, 'Total loss': 0.4285659154256185} | train loss {'Reaction outcome loss': 0.4104580337548778, 'Total loss': 0.4104580337548778}
2022-12-31 02:51:13,983 INFO:     Found new best model at epoch 3
2022-12-31 02:51:13,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:13,984 INFO:     Epoch: 4
2022-12-31 02:51:15,592 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.42961392402648924, 'Total loss': 0.42961392402648924} | train loss {'Reaction outcome loss': 0.380670839091287, 'Total loss': 0.380670839091287}
2022-12-31 02:51:15,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:15,593 INFO:     Epoch: 5
2022-12-31 02:51:17,212 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4315229723850886, 'Total loss': 0.4315229723850886} | train loss {'Reaction outcome loss': 0.3562668825696855, 'Total loss': 0.3562668825696855}
2022-12-31 02:51:17,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:17,213 INFO:     Epoch: 6
2022-12-31 02:51:18,829 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4156812330087026, 'Total loss': 0.4156812330087026} | train loss {'Reaction outcome loss': 0.34043261612745096, 'Total loss': 0.34043261612745096}
2022-12-31 02:51:18,829 INFO:     Found new best model at epoch 6
2022-12-31 02:51:18,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:18,830 INFO:     Epoch: 7
2022-12-31 02:51:20,440 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3753418311476707, 'Total loss': 0.3753418311476707} | train loss {'Reaction outcome loss': 0.32037086266833936, 'Total loss': 0.32037086266833936}
2022-12-31 02:51:20,440 INFO:     Found new best model at epoch 7
2022-12-31 02:51:20,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:20,441 INFO:     Epoch: 8
2022-12-31 02:51:22,049 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.39901156922181447, 'Total loss': 0.39901156922181447} | train loss {'Reaction outcome loss': 0.30560438084776387, 'Total loss': 0.30560438084776387}
2022-12-31 02:51:22,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:22,050 INFO:     Epoch: 9
2022-12-31 02:51:23,657 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3932173838218053, 'Total loss': 0.3932173838218053} | train loss {'Reaction outcome loss': 0.2880232162556074, 'Total loss': 0.2880232162556074}
2022-12-31 02:51:23,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:23,658 INFO:     Epoch: 10
2022-12-31 02:51:25,282 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39707747201124827, 'Total loss': 0.39707747201124827} | train loss {'Reaction outcome loss': 0.2777916625427612, 'Total loss': 0.2777916625427612}
2022-12-31 02:51:25,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:25,282 INFO:     Epoch: 11
2022-12-31 02:51:26,891 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4136313219865163, 'Total loss': 0.4136313219865163} | train loss {'Reaction outcome loss': 0.2630994571304887, 'Total loss': 0.2630994571304887}
2022-12-31 02:51:26,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:26,891 INFO:     Epoch: 12
2022-12-31 02:51:28,544 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39492955803871155, 'Total loss': 0.39492955803871155} | train loss {'Reaction outcome loss': 0.25709515423887835, 'Total loss': 0.25709515423887835}
2022-12-31 02:51:28,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:28,544 INFO:     Epoch: 13
2022-12-31 02:51:30,158 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3848365267117818, 'Total loss': 0.3848365267117818} | train loss {'Reaction outcome loss': 0.24249489605426788, 'Total loss': 0.24249489605426788}
2022-12-31 02:51:30,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:30,158 INFO:     Epoch: 14
2022-12-31 02:51:31,768 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.37787885864575704, 'Total loss': 0.37787885864575704} | train loss {'Reaction outcome loss': 0.23450886246061672, 'Total loss': 0.23450886246061672}
2022-12-31 02:51:31,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:31,768 INFO:     Epoch: 15
2022-12-31 02:51:33,398 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3696532835563024, 'Total loss': 0.3696532835563024} | train loss {'Reaction outcome loss': 0.22857554197093866, 'Total loss': 0.22857554197093866}
2022-12-31 02:51:33,398 INFO:     Found new best model at epoch 15
2022-12-31 02:51:33,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:33,399 INFO:     Epoch: 16
2022-12-31 02:51:35,012 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3686109781265259, 'Total loss': 0.3686109781265259} | train loss {'Reaction outcome loss': 0.21821789569255426, 'Total loss': 0.21821789569255426}
2022-12-31 02:51:35,012 INFO:     Found new best model at epoch 16
2022-12-31 02:51:35,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:35,013 INFO:     Epoch: 17
2022-12-31 02:51:36,618 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3702683220307032, 'Total loss': 0.3702683220307032} | train loss {'Reaction outcome loss': 0.21177762487128268, 'Total loss': 0.21177762487128268}
2022-12-31 02:51:36,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:36,619 INFO:     Epoch: 18
2022-12-31 02:51:38,232 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39509406288464866, 'Total loss': 0.39509406288464866} | train loss {'Reaction outcome loss': 0.20786551250158436, 'Total loss': 0.20786551250158436}
2022-12-31 02:51:38,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:38,233 INFO:     Epoch: 19
2022-12-31 02:51:39,854 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3623473991950353, 'Total loss': 0.3623473991950353} | train loss {'Reaction outcome loss': 0.19946054084376044, 'Total loss': 0.19946054084376044}
2022-12-31 02:51:39,855 INFO:     Found new best model at epoch 19
2022-12-31 02:51:39,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:39,856 INFO:     Epoch: 20
2022-12-31 02:51:41,469 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40121281147003174, 'Total loss': 0.40121281147003174} | train loss {'Reaction outcome loss': 0.19696979230800032, 'Total loss': 0.19696979230800032}
2022-12-31 02:51:41,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:41,470 INFO:     Epoch: 21
2022-12-31 02:51:43,079 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.37819576064745586, 'Total loss': 0.37819576064745586} | train loss {'Reaction outcome loss': 0.19324374459276017, 'Total loss': 0.19324374459276017}
2022-12-31 02:51:43,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:43,080 INFO:     Epoch: 22
2022-12-31 02:51:44,691 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3750791698694229, 'Total loss': 0.3750791698694229} | train loss {'Reaction outcome loss': 0.18540430052824536, 'Total loss': 0.18540430052824536}
2022-12-31 02:51:44,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:44,691 INFO:     Epoch: 23
2022-12-31 02:51:46,331 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3680053095022837, 'Total loss': 0.3680053095022837} | train loss {'Reaction outcome loss': 0.18544170922552147, 'Total loss': 0.18544170922552147}
2022-12-31 02:51:46,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:46,331 INFO:     Epoch: 24
2022-12-31 02:51:47,961 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38582616448402407, 'Total loss': 0.38582616448402407} | train loss {'Reaction outcome loss': 0.17958227984172148, 'Total loss': 0.17958227984172148}
2022-12-31 02:51:47,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:47,961 INFO:     Epoch: 25
2022-12-31 02:51:49,577 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39229560444752376, 'Total loss': 0.39229560444752376} | train loss {'Reaction outcome loss': 0.1777487894125881, 'Total loss': 0.1777487894125881}
2022-12-31 02:51:49,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:49,577 INFO:     Epoch: 26
2022-12-31 02:51:51,190 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38636775414148966, 'Total loss': 0.38636775414148966} | train loss {'Reaction outcome loss': 0.17340262373909354, 'Total loss': 0.17340262373909354}
2022-12-31 02:51:51,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:51,190 INFO:     Epoch: 27
2022-12-31 02:51:52,797 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4351622387766838, 'Total loss': 0.4351622387766838} | train loss {'Reaction outcome loss': 0.1700353844186468, 'Total loss': 0.1700353844186468}
2022-12-31 02:51:52,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:52,797 INFO:     Epoch: 28
2022-12-31 02:51:54,447 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.37810733846078315, 'Total loss': 0.37810733846078315} | train loss {'Reaction outcome loss': 0.16901438669335558, 'Total loss': 0.16901438669335558}
2022-12-31 02:51:54,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:54,448 INFO:     Epoch: 29
2022-12-31 02:51:56,097 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38517028987407687, 'Total loss': 0.38517028987407687} | train loss {'Reaction outcome loss': 0.16854520300811116, 'Total loss': 0.16854520300811116}
2022-12-31 02:51:56,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:56,098 INFO:     Epoch: 30
2022-12-31 02:51:57,707 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.37960589478413265, 'Total loss': 0.37960589478413265} | train loss {'Reaction outcome loss': 0.16412223516929433, 'Total loss': 0.16412223516929433}
2022-12-31 02:51:57,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:57,707 INFO:     Epoch: 31
2022-12-31 02:51:59,358 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3636534909407298, 'Total loss': 0.3636534909407298} | train loss {'Reaction outcome loss': 0.16236548223209832, 'Total loss': 0.16236548223209832}
2022-12-31 02:51:59,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:51:59,358 INFO:     Epoch: 32
2022-12-31 02:52:00,961 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4127445156375567, 'Total loss': 0.4127445156375567} | train loss {'Reaction outcome loss': 0.160721713048236, 'Total loss': 0.160721713048236}
2022-12-31 02:52:00,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:00,961 INFO:     Epoch: 33
2022-12-31 02:52:02,615 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4308991769949595, 'Total loss': 0.4308991769949595} | train loss {'Reaction outcome loss': 0.15930409038296636, 'Total loss': 0.15930409038296636}
2022-12-31 02:52:02,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:02,615 INFO:     Epoch: 34
2022-12-31 02:52:04,271 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4031823664903641, 'Total loss': 0.4031823664903641} | train loss {'Reaction outcome loss': 0.15676502552372915, 'Total loss': 0.15676502552372915}
2022-12-31 02:52:04,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:04,271 INFO:     Epoch: 35
2022-12-31 02:52:05,909 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4172680546840032, 'Total loss': 0.4172680546840032} | train loss {'Reaction outcome loss': 0.14960612082704358, 'Total loss': 0.14960612082704358}
2022-12-31 02:52:05,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:05,909 INFO:     Epoch: 36
2022-12-31 02:52:07,515 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40166378319263457, 'Total loss': 0.40166378319263457} | train loss {'Reaction outcome loss': 0.1498664974024261, 'Total loss': 0.1498664974024261}
2022-12-31 02:52:07,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:07,515 INFO:     Epoch: 37
2022-12-31 02:52:09,115 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37623446037371955, 'Total loss': 0.37623446037371955} | train loss {'Reaction outcome loss': 0.15341405343114786, 'Total loss': 0.15341405343114786}
2022-12-31 02:52:09,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:09,115 INFO:     Epoch: 38
2022-12-31 02:52:10,729 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.387283992767334, 'Total loss': 0.387283992767334} | train loss {'Reaction outcome loss': 0.14795880307219106, 'Total loss': 0.14795880307219106}
2022-12-31 02:52:10,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:10,729 INFO:     Epoch: 39
2022-12-31 02:52:12,351 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3817693789800008, 'Total loss': 0.3817693789800008} | train loss {'Reaction outcome loss': 0.14622882502935283, 'Total loss': 0.14622882502935283}
2022-12-31 02:52:12,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:12,351 INFO:     Epoch: 40
2022-12-31 02:52:13,982 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46500530938307444, 'Total loss': 0.46500530938307444} | train loss {'Reaction outcome loss': 0.14424889660814275, 'Total loss': 0.14424889660814275}
2022-12-31 02:52:13,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:13,983 INFO:     Epoch: 41
2022-12-31 02:52:15,604 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4013693551222483, 'Total loss': 0.4013693551222483} | train loss {'Reaction outcome loss': 0.14212968678002919, 'Total loss': 0.14212968678002919}
2022-12-31 02:52:15,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:15,604 INFO:     Epoch: 42
2022-12-31 02:52:17,211 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.37049748202164967, 'Total loss': 0.37049748202164967} | train loss {'Reaction outcome loss': 0.13924394522446895, 'Total loss': 0.13924394522446895}
2022-12-31 02:52:17,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:17,211 INFO:     Epoch: 43
2022-12-31 02:52:18,842 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3881157120068868, 'Total loss': 0.3881157120068868} | train loss {'Reaction outcome loss': 0.13821826892544645, 'Total loss': 0.13821826892544645}
2022-12-31 02:52:18,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:18,842 INFO:     Epoch: 44
2022-12-31 02:52:20,496 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40893325706322986, 'Total loss': 0.40893325706322986} | train loss {'Reaction outcome loss': 0.14247729947253462, 'Total loss': 0.14247729947253462}
2022-12-31 02:52:20,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:20,497 INFO:     Epoch: 45
2022-12-31 02:52:22,105 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.422367250919342, 'Total loss': 0.422367250919342} | train loss {'Reaction outcome loss': 0.14328644493506393, 'Total loss': 0.14328644493506393}
2022-12-31 02:52:22,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:22,105 INFO:     Epoch: 46
2022-12-31 02:52:23,758 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4224463661511739, 'Total loss': 0.4224463661511739} | train loss {'Reaction outcome loss': 0.136752729401006, 'Total loss': 0.136752729401006}
2022-12-31 02:52:23,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:23,759 INFO:     Epoch: 47
2022-12-31 02:52:25,373 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4190222134192785, 'Total loss': 0.4190222134192785} | train loss {'Reaction outcome loss': 0.1340326200354926, 'Total loss': 0.1340326200354926}
2022-12-31 02:52:25,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:25,374 INFO:     Epoch: 48
2022-12-31 02:52:26,986 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39665947121878464, 'Total loss': 0.39665947121878464} | train loss {'Reaction outcome loss': 0.1363594270885725, 'Total loss': 0.1363594270885725}
2022-12-31 02:52:26,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:26,986 INFO:     Epoch: 49
2022-12-31 02:52:28,617 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39571847673505545, 'Total loss': 0.39571847673505545} | train loss {'Reaction outcome loss': 0.13269608909175834, 'Total loss': 0.13269608909175834}
2022-12-31 02:52:28,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:28,617 INFO:     Epoch: 50
2022-12-31 02:52:30,270 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4025751200815042, 'Total loss': 0.4025751200815042} | train loss {'Reaction outcome loss': 0.12612461285278145, 'Total loss': 0.12612461285278145}
2022-12-31 02:52:30,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:30,271 INFO:     Epoch: 51
2022-12-31 02:52:31,924 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4266679103175799, 'Total loss': 0.4266679103175799} | train loss {'Reaction outcome loss': 0.13156400567573243, 'Total loss': 0.13156400567573243}
2022-12-31 02:52:31,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:31,924 INFO:     Epoch: 52
2022-12-31 02:52:33,561 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41029216224948567, 'Total loss': 0.41029216224948567} | train loss {'Reaction outcome loss': 0.1302852490135081, 'Total loss': 0.1302852490135081}
2022-12-31 02:52:33,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:33,562 INFO:     Epoch: 53
2022-12-31 02:52:35,169 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44291820923487346, 'Total loss': 0.44291820923487346} | train loss {'Reaction outcome loss': 0.13010810553028254, 'Total loss': 0.13010810553028254}
2022-12-31 02:52:35,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:35,169 INFO:     Epoch: 54
2022-12-31 02:52:36,806 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41121452624599136, 'Total loss': 0.41121452624599136} | train loss {'Reaction outcome loss': 0.12577461016731487, 'Total loss': 0.12577461016731487}
2022-12-31 02:52:36,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:36,806 INFO:     Epoch: 55
2022-12-31 02:52:38,457 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44413550198078156, 'Total loss': 0.44413550198078156} | train loss {'Reaction outcome loss': 0.12129199815689702, 'Total loss': 0.12129199815689702}
2022-12-31 02:52:38,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:38,458 INFO:     Epoch: 56
2022-12-31 02:52:40,065 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4258478512366613, 'Total loss': 0.4258478512366613} | train loss {'Reaction outcome loss': 0.12544238715973025, 'Total loss': 0.12544238715973025}
2022-12-31 02:52:40,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:40,065 INFO:     Epoch: 57
2022-12-31 02:52:41,717 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41555030246575675, 'Total loss': 0.41555030246575675} | train loss {'Reaction outcome loss': 0.12685655978215982, 'Total loss': 0.12685655978215982}
2022-12-31 02:52:41,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:41,718 INFO:     Epoch: 58
2022-12-31 02:52:43,338 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40698455373446146, 'Total loss': 0.40698455373446146} | train loss {'Reaction outcome loss': 0.1334246766709308, 'Total loss': 0.1334246766709308}
2022-12-31 02:52:43,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:43,339 INFO:     Epoch: 59
2022-12-31 02:52:44,953 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3820198357105255, 'Total loss': 0.3820198357105255} | train loss {'Reaction outcome loss': 0.12944273458943314, 'Total loss': 0.12944273458943314}
2022-12-31 02:52:44,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:44,953 INFO:     Epoch: 60
2022-12-31 02:52:46,563 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4030688407520453, 'Total loss': 0.4030688407520453} | train loss {'Reaction outcome loss': 0.1220343819238164, 'Total loss': 0.1220343819238164}
2022-12-31 02:52:46,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:46,563 INFO:     Epoch: 61
2022-12-31 02:52:48,181 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40504436443249386, 'Total loss': 0.40504436443249386} | train loss {'Reaction outcome loss': 0.12096164547362412, 'Total loss': 0.12096164547362412}
2022-12-31 02:52:48,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:48,181 INFO:     Epoch: 62
2022-12-31 02:52:49,801 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4033817787965139, 'Total loss': 0.4033817787965139} | train loss {'Reaction outcome loss': 0.11936474462332082, 'Total loss': 0.11936474462332082}
2022-12-31 02:52:49,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:49,802 INFO:     Epoch: 63
2022-12-31 02:52:51,419 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4044849534829458, 'Total loss': 0.4044849534829458} | train loss {'Reaction outcome loss': 0.12186038882444429, 'Total loss': 0.12186038882444429}
2022-12-31 02:52:51,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:51,419 INFO:     Epoch: 64
2022-12-31 02:52:53,064 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3792732502023379, 'Total loss': 0.3792732502023379} | train loss {'Reaction outcome loss': 0.12379670054583818, 'Total loss': 0.12379670054583818}
2022-12-31 02:52:53,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:53,064 INFO:     Epoch: 65
2022-12-31 02:52:54,671 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39066340078910194, 'Total loss': 0.39066340078910194} | train loss {'Reaction outcome loss': 0.11838805808831876, 'Total loss': 0.11838805808831876}
2022-12-31 02:52:54,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:54,671 INFO:     Epoch: 66
2022-12-31 02:52:56,285 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41598610058426855, 'Total loss': 0.41598610058426855} | train loss {'Reaction outcome loss': 0.11990334618374379, 'Total loss': 0.11990334618374379}
2022-12-31 02:52:56,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:56,286 INFO:     Epoch: 67
2022-12-31 02:52:57,894 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4140135546525319, 'Total loss': 0.4140135546525319} | train loss {'Reaction outcome loss': 0.12165450031298083, 'Total loss': 0.12165450031298083}
2022-12-31 02:52:57,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:57,895 INFO:     Epoch: 68
2022-12-31 02:52:59,504 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40235522414247193, 'Total loss': 0.40235522414247193} | train loss {'Reaction outcome loss': 0.12352190159403983, 'Total loss': 0.12352190159403983}
2022-12-31 02:52:59,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:52:59,504 INFO:     Epoch: 69
2022-12-31 02:53:01,116 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39707424541314446, 'Total loss': 0.39707424541314446} | train loss {'Reaction outcome loss': 0.12026480986247261, 'Total loss': 0.12026480986247261}
2022-12-31 02:53:01,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:01,116 INFO:     Epoch: 70
2022-12-31 02:53:02,763 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43165816416343056, 'Total loss': 0.43165816416343056} | train loss {'Reaction outcome loss': 0.11581659119280503, 'Total loss': 0.11581659119280503}
2022-12-31 02:53:02,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:02,763 INFO:     Epoch: 71
2022-12-31 02:53:04,365 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3820541749397914, 'Total loss': 0.3820541749397914} | train loss {'Reaction outcome loss': 0.11322759683787768, 'Total loss': 0.11322759683787768}
2022-12-31 02:53:04,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:04,365 INFO:     Epoch: 72
2022-12-31 02:53:06,017 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3995456874370575, 'Total loss': 0.3995456874370575} | train loss {'Reaction outcome loss': 0.11625990657863228, 'Total loss': 0.11625990657863228}
2022-12-31 02:53:06,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:06,018 INFO:     Epoch: 73
2022-12-31 02:53:07,628 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38398239215215046, 'Total loss': 0.38398239215215046} | train loss {'Reaction outcome loss': 0.11937384705915775, 'Total loss': 0.11937384705915775}
2022-12-31 02:53:07,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:07,628 INFO:     Epoch: 74
2022-12-31 02:53:09,236 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4314293682575226, 'Total loss': 0.4314293682575226} | train loss {'Reaction outcome loss': 0.11652877665699263, 'Total loss': 0.11652877665699263}
2022-12-31 02:53:09,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:09,237 INFO:     Epoch: 75
2022-12-31 02:53:10,848 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4284609625736872, 'Total loss': 0.4284609625736872} | train loss {'Reaction outcome loss': 0.11761488648892864, 'Total loss': 0.11761488648892864}
2022-12-31 02:53:10,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:10,848 INFO:     Epoch: 76
2022-12-31 02:53:12,466 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4237430214881897, 'Total loss': 0.4237430214881897} | train loss {'Reaction outcome loss': 0.11621720973490636, 'Total loss': 0.11621720973490636}
2022-12-31 02:53:12,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:12,466 INFO:     Epoch: 77
2022-12-31 02:53:14,070 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4345568259557088, 'Total loss': 0.4345568259557088} | train loss {'Reaction outcome loss': 0.11587783549980253, 'Total loss': 0.11587783549980253}
2022-12-31 02:53:14,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:14,071 INFO:     Epoch: 78
2022-12-31 02:53:15,691 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43596224387486776, 'Total loss': 0.43596224387486776} | train loss {'Reaction outcome loss': 0.11365318300974059, 'Total loss': 0.11365318300974059}
2022-12-31 02:53:15,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:15,691 INFO:     Epoch: 79
2022-12-31 02:53:17,311 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4340748945871989, 'Total loss': 0.4340748945871989} | train loss {'Reaction outcome loss': 0.11446391255934689, 'Total loss': 0.11446391255934689}
2022-12-31 02:53:17,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:17,311 INFO:     Epoch: 80
2022-12-31 02:53:18,924 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4261244207620621, 'Total loss': 0.4261244207620621} | train loss {'Reaction outcome loss': 0.11543871216428378, 'Total loss': 0.11543871216428378}
2022-12-31 02:53:18,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:18,924 INFO:     Epoch: 81
2022-12-31 02:53:20,524 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4738999788959821, 'Total loss': 0.4738999788959821} | train loss {'Reaction outcome loss': 0.11353114733632219, 'Total loss': 0.11353114733632219}
2022-12-31 02:53:20,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:20,524 INFO:     Epoch: 82
2022-12-31 02:53:22,177 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4039135237534841, 'Total loss': 0.4039135237534841} | train loss {'Reaction outcome loss': 0.11338813829636812, 'Total loss': 0.11338813829636812}
2022-12-31 02:53:22,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:22,177 INFO:     Epoch: 83
2022-12-31 02:53:23,814 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3854956145087878, 'Total loss': 0.3854956145087878} | train loss {'Reaction outcome loss': 0.11089118580116353, 'Total loss': 0.11089118580116353}
2022-12-31 02:53:23,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:23,814 INFO:     Epoch: 84
2022-12-31 02:53:25,468 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.36983016803860663, 'Total loss': 0.36983016803860663} | train loss {'Reaction outcome loss': 0.1164545904399732, 'Total loss': 0.1164545904399732}
2022-12-31 02:53:25,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:25,469 INFO:     Epoch: 85
2022-12-31 02:53:27,072 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4117052714029948, 'Total loss': 0.4117052714029948} | train loss {'Reaction outcome loss': 0.11594061828371355, 'Total loss': 0.11594061828371355}
2022-12-31 02:53:27,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:27,073 INFO:     Epoch: 86
2022-12-31 02:53:28,710 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4282950053612391, 'Total loss': 0.4282950053612391} | train loss {'Reaction outcome loss': 0.11174142007532455, 'Total loss': 0.11174142007532455}
2022-12-31 02:53:28,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:28,710 INFO:     Epoch: 87
2022-12-31 02:53:30,316 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39374279181162514, 'Total loss': 0.39374279181162514} | train loss {'Reaction outcome loss': 0.10987865534291541, 'Total loss': 0.10987865534291541}
2022-12-31 02:53:30,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:30,316 INFO:     Epoch: 88
2022-12-31 02:53:31,943 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43330631057421365, 'Total loss': 0.43330631057421365} | train loss {'Reaction outcome loss': 0.10707232366523359, 'Total loss': 0.10707232366523359}
2022-12-31 02:53:31,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:31,943 INFO:     Epoch: 89
2022-12-31 02:53:33,548 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39137168129285177, 'Total loss': 0.39137168129285177} | train loss {'Reaction outcome loss': 0.1064535780711249, 'Total loss': 0.1064535780711249}
2022-12-31 02:53:33,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:33,549 INFO:     Epoch: 90
2022-12-31 02:53:35,203 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4397503619392713, 'Total loss': 0.4397503619392713} | train loss {'Reaction outcome loss': 0.11283351576982242, 'Total loss': 0.11283351576982242}
2022-12-31 02:53:35,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:35,203 INFO:     Epoch: 91
2022-12-31 02:53:36,810 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41828181942303977, 'Total loss': 0.41828181942303977} | train loss {'Reaction outcome loss': 0.11022632224672223, 'Total loss': 0.11022632224672223}
2022-12-31 02:53:36,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:36,810 INFO:     Epoch: 92
2022-12-31 02:53:38,415 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40435544500748316, 'Total loss': 0.40435544500748316} | train loss {'Reaction outcome loss': 0.10723390310227762, 'Total loss': 0.10723390310227762}
2022-12-31 02:53:38,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:38,416 INFO:     Epoch: 93
2022-12-31 02:53:40,023 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4420251905918121, 'Total loss': 0.4420251905918121} | train loss {'Reaction outcome loss': 0.11011425805631617, 'Total loss': 0.11011425805631617}
2022-12-31 02:53:40,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:40,023 INFO:     Epoch: 94
2022-12-31 02:53:41,638 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4368262472252051, 'Total loss': 0.4368262472252051} | train loss {'Reaction outcome loss': 0.11099588507650433, 'Total loss': 0.11099588507650433}
2022-12-31 02:53:41,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:41,638 INFO:     Epoch: 95
2022-12-31 02:53:43,250 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45601925949255623, 'Total loss': 0.45601925949255623} | train loss {'Reaction outcome loss': 0.11225523556630215, 'Total loss': 0.11225523556630215}
2022-12-31 02:53:43,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:43,250 INFO:     Epoch: 96
2022-12-31 02:53:44,861 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.441583988070488, 'Total loss': 0.441583988070488} | train loss {'Reaction outcome loss': 0.1121700982729748, 'Total loss': 0.1121700982729748}
2022-12-31 02:53:44,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:44,862 INFO:     Epoch: 97
2022-12-31 02:53:46,466 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45061125308275224, 'Total loss': 0.45061125308275224} | train loss {'Reaction outcome loss': 0.10952118099293243, 'Total loss': 0.10952118099293243}
2022-12-31 02:53:46,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:46,466 INFO:     Epoch: 98
2022-12-31 02:53:48,119 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3886312673489253, 'Total loss': 0.3886312673489253} | train loss {'Reaction outcome loss': 0.10540941203043654, 'Total loss': 0.10540941203043654}
2022-12-31 02:53:48,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:48,120 INFO:     Epoch: 99
2022-12-31 02:53:49,734 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4189988782008489, 'Total loss': 0.4189988782008489} | train loss {'Reaction outcome loss': 0.10402085220128515, 'Total loss': 0.10402085220128515}
2022-12-31 02:53:49,734 INFO:     Best model found after epoch 20 of 100.
2022-12-31 02:53:49,734 INFO:   Done with stage: TRAINING
2022-12-31 02:53:49,734 INFO:   Starting stage: EVALUATION
2022-12-31 02:53:49,870 INFO:   Done with stage: EVALUATION
2022-12-31 02:53:49,870 INFO:   Leaving out SEQ value Fold_4
2022-12-31 02:53:49,883 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 02:53:49,883 INFO:   Starting stage: FEATURE SCALING
2022-12-31 02:53:50,527 INFO:   Done with stage: FEATURE SCALING
2022-12-31 02:53:50,528 INFO:   Starting stage: SCALING TARGETS
2022-12-31 02:53:50,600 INFO:   Done with stage: SCALING TARGETS
2022-12-31 02:53:50,600 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 02:53:50,600 INFO:     No hyperparam tuning for this model
2022-12-31 02:53:50,600 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 02:53:50,600 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 02:53:50,601 INFO:     None feature selector for col prot
2022-12-31 02:53:50,601 INFO:     None feature selector for col prot
2022-12-31 02:53:50,601 INFO:     None feature selector for col prot
2022-12-31 02:53:50,602 INFO:     None feature selector for col chem
2022-12-31 02:53:50,602 INFO:     None feature selector for col chem
2022-12-31 02:53:50,602 INFO:     None feature selector for col chem
2022-12-31 02:53:50,602 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 02:53:50,602 INFO:   Starting stage: BUILD MODEL
2022-12-31 02:53:50,604 INFO:     Number of params in model 224011
2022-12-31 02:53:50,607 INFO:   Done with stage: BUILD MODEL
2022-12-31 02:53:50,607 INFO:   Starting stage: TRAINING
2022-12-31 02:53:50,651 INFO:     Val loss before train {'Reaction outcome loss': 0.9713642160097758, 'Total loss': 0.9713642160097758}
2022-12-31 02:53:50,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:50,651 INFO:     Epoch: 0
2022-12-31 02:53:52,257 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5580799654126167, 'Total loss': 0.5580799654126167} | train loss {'Reaction outcome loss': 0.7867230890441115, 'Total loss': 0.7867230890441115}
2022-12-31 02:53:52,257 INFO:     Found new best model at epoch 0
2022-12-31 02:53:52,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:52,258 INFO:     Epoch: 1
2022-12-31 02:53:53,863 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5177748839060465, 'Total loss': 0.5177748839060465} | train loss {'Reaction outcome loss': 0.5056476583228494, 'Total loss': 0.5056476583228494}
2022-12-31 02:53:53,863 INFO:     Found new best model at epoch 1
2022-12-31 02:53:53,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:53,864 INFO:     Epoch: 2
2022-12-31 02:53:55,462 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48531800011793774, 'Total loss': 0.48531800011793774} | train loss {'Reaction outcome loss': 0.43383507074339545, 'Total loss': 0.43383507074339545}
2022-12-31 02:53:55,462 INFO:     Found new best model at epoch 2
2022-12-31 02:53:55,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:55,463 INFO:     Epoch: 3
2022-12-31 02:53:57,067 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4254617710908254, 'Total loss': 0.4254617710908254} | train loss {'Reaction outcome loss': 0.3974413741515936, 'Total loss': 0.3974413741515936}
2022-12-31 02:53:57,067 INFO:     Found new best model at epoch 3
2022-12-31 02:53:57,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:57,068 INFO:     Epoch: 4
2022-12-31 02:53:58,671 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.41217269947131474, 'Total loss': 0.41217269947131474} | train loss {'Reaction outcome loss': 0.36994380476701, 'Total loss': 0.36994380476701}
2022-12-31 02:53:58,671 INFO:     Found new best model at epoch 4
2022-12-31 02:53:58,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:53:58,672 INFO:     Epoch: 5
2022-12-31 02:54:00,279 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.39797364473342894, 'Total loss': 0.39797364473342894} | train loss {'Reaction outcome loss': 0.3449895767508632, 'Total loss': 0.3449895767508632}
2022-12-31 02:54:00,280 INFO:     Found new best model at epoch 5
2022-12-31 02:54:00,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:00,281 INFO:     Epoch: 6
2022-12-31 02:54:01,935 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4325033674637477, 'Total loss': 0.4325033674637477} | train loss {'Reaction outcome loss': 0.3244005907190977, 'Total loss': 0.3244005907190977}
2022-12-31 02:54:01,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:01,935 INFO:     Epoch: 7
2022-12-31 02:54:03,588 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3784597953160604, 'Total loss': 0.3784597953160604} | train loss {'Reaction outcome loss': 0.31032989092551877, 'Total loss': 0.31032989092551877}
2022-12-31 02:54:03,588 INFO:     Found new best model at epoch 7
2022-12-31 02:54:03,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:03,589 INFO:     Epoch: 8
2022-12-31 02:54:05,219 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4036556695898374, 'Total loss': 0.4036556695898374} | train loss {'Reaction outcome loss': 0.29943258445845905, 'Total loss': 0.29943258445845905}
2022-12-31 02:54:05,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:05,219 INFO:     Epoch: 9
2022-12-31 02:54:06,872 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.386841290195783, 'Total loss': 0.386841290195783} | train loss {'Reaction outcome loss': 0.2865640453885507, 'Total loss': 0.2865640453885507}
2022-12-31 02:54:06,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:06,873 INFO:     Epoch: 10
2022-12-31 02:54:08,481 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40598620573679606, 'Total loss': 0.40598620573679606} | train loss {'Reaction outcome loss': 0.274410884936143, 'Total loss': 0.274410884936143}
2022-12-31 02:54:08,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:08,482 INFO:     Epoch: 11
2022-12-31 02:54:10,136 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.37801736369729044, 'Total loss': 0.37801736369729044} | train loss {'Reaction outcome loss': 0.2640223564294568, 'Total loss': 0.2640223564294568}
2022-12-31 02:54:10,136 INFO:     Found new best model at epoch 11
2022-12-31 02:54:10,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:10,137 INFO:     Epoch: 12
2022-12-31 02:54:11,743 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39164721965789795, 'Total loss': 0.39164721965789795} | train loss {'Reaction outcome loss': 0.25432764737438546, 'Total loss': 0.25432764737438546}
2022-12-31 02:54:11,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:11,743 INFO:     Epoch: 13
2022-12-31 02:54:13,382 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3864656368891398, 'Total loss': 0.3864656368891398} | train loss {'Reaction outcome loss': 0.24483140438360018, 'Total loss': 0.24483140438360018}
2022-12-31 02:54:13,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:13,383 INFO:     Epoch: 14
2022-12-31 02:54:15,037 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3856253842512766, 'Total loss': 0.3856253842512766} | train loss {'Reaction outcome loss': 0.2373696299963189, 'Total loss': 0.2373696299963189}
2022-12-31 02:54:15,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:15,037 INFO:     Epoch: 15
2022-12-31 02:54:16,690 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.374387530485789, 'Total loss': 0.374387530485789} | train loss {'Reaction outcome loss': 0.22773616113801942, 'Total loss': 0.22773616113801942}
2022-12-31 02:54:16,690 INFO:     Found new best model at epoch 15
2022-12-31 02:54:16,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:16,691 INFO:     Epoch: 16
2022-12-31 02:54:18,303 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3513389424420893, 'Total loss': 0.3513389424420893} | train loss {'Reaction outcome loss': 0.22191527070491202, 'Total loss': 0.22191527070491202}
2022-12-31 02:54:18,303 INFO:     Found new best model at epoch 16
2022-12-31 02:54:18,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:18,304 INFO:     Epoch: 17
2022-12-31 02:54:19,926 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38647462824980416, 'Total loss': 0.38647462824980416} | train loss {'Reaction outcome loss': 0.21632402985744234, 'Total loss': 0.21632402985744234}
2022-12-31 02:54:19,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:19,926 INFO:     Epoch: 18
2022-12-31 02:54:21,547 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.380928048491478, 'Total loss': 0.380928048491478} | train loss {'Reaction outcome loss': 0.21272817996405338, 'Total loss': 0.21272817996405338}
2022-12-31 02:54:21,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:21,548 INFO:     Epoch: 19
2022-12-31 02:54:23,159 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3853697617848714, 'Total loss': 0.3853697617848714} | train loss {'Reaction outcome loss': 0.20803147393965374, 'Total loss': 0.20803147393965374}
2022-12-31 02:54:23,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:23,159 INFO:     Epoch: 20
2022-12-31 02:54:24,781 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.37254828264315926, 'Total loss': 0.37254828264315926} | train loss {'Reaction outcome loss': 0.2026121440567892, 'Total loss': 0.2026121440567892}
2022-12-31 02:54:24,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:24,781 INFO:     Epoch: 21
2022-12-31 02:54:26,393 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3736153870820999, 'Total loss': 0.3736153870820999} | train loss {'Reaction outcome loss': 0.19436815410281402, 'Total loss': 0.19436815410281402}
2022-12-31 02:54:26,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:26,394 INFO:     Epoch: 22
2022-12-31 02:54:28,048 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38166197141011554, 'Total loss': 0.38166197141011554} | train loss {'Reaction outcome loss': 0.19139347202314513, 'Total loss': 0.19139347202314513}
2022-12-31 02:54:28,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:28,048 INFO:     Epoch: 23
2022-12-31 02:54:29,659 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3939980020125707, 'Total loss': 0.3939980020125707} | train loss {'Reaction outcome loss': 0.19078582484465445, 'Total loss': 0.19078582484465445}
2022-12-31 02:54:29,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:29,660 INFO:     Epoch: 24
2022-12-31 02:54:31,313 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38993441859881084, 'Total loss': 0.38993441859881084} | train loss {'Reaction outcome loss': 0.1843979183761199, 'Total loss': 0.1843979183761199}
2022-12-31 02:54:31,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:31,315 INFO:     Epoch: 25
2022-12-31 02:54:32,928 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.38805102507273354, 'Total loss': 0.38805102507273354} | train loss {'Reaction outcome loss': 0.1816784018908974, 'Total loss': 0.1816784018908974}
2022-12-31 02:54:32,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:32,928 INFO:     Epoch: 26
2022-12-31 02:54:34,582 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38195280904571216, 'Total loss': 0.38195280904571216} | train loss {'Reaction outcome loss': 0.17963866268141862, 'Total loss': 0.17963866268141862}
2022-12-31 02:54:34,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:34,582 INFO:     Epoch: 27
2022-12-31 02:54:36,198 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3794967363278071, 'Total loss': 0.3794967363278071} | train loss {'Reaction outcome loss': 0.17661289703508798, 'Total loss': 0.17661289703508798}
2022-12-31 02:54:36,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:36,198 INFO:     Epoch: 28
2022-12-31 02:54:37,852 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3431817673146725, 'Total loss': 0.3431817673146725} | train loss {'Reaction outcome loss': 0.17148366870943213, 'Total loss': 0.17148366870943213}
2022-12-31 02:54:37,853 INFO:     Found new best model at epoch 28
2022-12-31 02:54:37,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:37,854 INFO:     Epoch: 29
2022-12-31 02:54:39,508 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.35976795529325806, 'Total loss': 0.35976795529325806} | train loss {'Reaction outcome loss': 0.1699379759392001, 'Total loss': 0.1699379759392001}
2022-12-31 02:54:39,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:39,508 INFO:     Epoch: 30
2022-12-31 02:54:41,144 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4199994216362635, 'Total loss': 0.4199994216362635} | train loss {'Reaction outcome loss': 0.16959053607331248, 'Total loss': 0.16959053607331248}
2022-12-31 02:54:41,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:41,144 INFO:     Epoch: 31
2022-12-31 02:54:42,797 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40091807544231417, 'Total loss': 0.40091807544231417} | train loss {'Reaction outcome loss': 0.16321204241066084, 'Total loss': 0.16321204241066084}
2022-12-31 02:54:42,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:42,797 INFO:     Epoch: 32
2022-12-31 02:54:44,402 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40854300757249196, 'Total loss': 0.40854300757249196} | train loss {'Reaction outcome loss': 0.16366476435758118, 'Total loss': 0.16366476435758118}
2022-12-31 02:54:44,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:44,403 INFO:     Epoch: 33
2022-12-31 02:54:46,050 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4073745588461558, 'Total loss': 0.4073745588461558} | train loss {'Reaction outcome loss': 0.1642141724957058, 'Total loss': 0.1642141724957058}
2022-12-31 02:54:46,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:46,050 INFO:     Epoch: 34
2022-12-31 02:54:47,704 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.36003678959483904, 'Total loss': 0.36003678959483904} | train loss {'Reaction outcome loss': 0.16035498916783308, 'Total loss': 0.16035498916783308}
2022-12-31 02:54:47,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:47,705 INFO:     Epoch: 35
2022-12-31 02:54:49,313 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.36776472131411236, 'Total loss': 0.36776472131411236} | train loss {'Reaction outcome loss': 0.15851774687341746, 'Total loss': 0.15851774687341746}
2022-12-31 02:54:49,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:49,313 INFO:     Epoch: 36
2022-12-31 02:54:50,931 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3941333601872126, 'Total loss': 0.3941333601872126} | train loss {'Reaction outcome loss': 0.15574455983685262, 'Total loss': 0.15574455983685262}
2022-12-31 02:54:50,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:50,932 INFO:     Epoch: 37
2022-12-31 02:54:52,546 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42742359787225725, 'Total loss': 0.42742359787225725} | train loss {'Reaction outcome loss': 0.15276104839260343, 'Total loss': 0.15276104839260343}
2022-12-31 02:54:52,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:52,546 INFO:     Epoch: 38
2022-12-31 02:54:54,150 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3952051982283592, 'Total loss': 0.3952051982283592} | train loss {'Reaction outcome loss': 0.15186204672893033, 'Total loss': 0.15186204672893033}
2022-12-31 02:54:54,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:54,150 INFO:     Epoch: 39
2022-12-31 02:54:55,768 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41389980415503186, 'Total loss': 0.41389980415503186} | train loss {'Reaction outcome loss': 0.1507103272924458, 'Total loss': 0.1507103272924458}
2022-12-31 02:54:55,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:55,768 INFO:     Epoch: 40
2022-12-31 02:54:57,389 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37344979209204515, 'Total loss': 0.37344979209204515} | train loss {'Reaction outcome loss': 0.15183846226954548, 'Total loss': 0.15183846226954548}
2022-12-31 02:54:57,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:57,389 INFO:     Epoch: 41
2022-12-31 02:54:59,006 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4258398214975993, 'Total loss': 0.4258398214975993} | train loss {'Reaction outcome loss': 0.1467008900396988, 'Total loss': 0.1467008900396988}
2022-12-31 02:54:59,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:54:59,006 INFO:     Epoch: 42
2022-12-31 02:55:00,618 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.406709216038386, 'Total loss': 0.406709216038386} | train loss {'Reaction outcome loss': 0.14740338690755686, 'Total loss': 0.14740338690755686}
2022-12-31 02:55:00,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:00,618 INFO:     Epoch: 43
2022-12-31 02:55:02,234 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4237169901529948, 'Total loss': 0.4237169901529948} | train loss {'Reaction outcome loss': 0.14523317288933663, 'Total loss': 0.14523317288933663}
2022-12-31 02:55:02,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:02,235 INFO:     Epoch: 44
2022-12-31 02:55:03,840 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3867659668127696, 'Total loss': 0.3867659668127696} | train loss {'Reaction outcome loss': 0.1467255964419757, 'Total loss': 0.1467255964419757}
2022-12-31 02:55:03,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:03,841 INFO:     Epoch: 45
2022-12-31 02:55:05,459 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3893642485141754, 'Total loss': 0.3893642485141754} | train loss {'Reaction outcome loss': 0.13969889894997986, 'Total loss': 0.13969889894997986}
2022-12-31 02:55:05,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:05,459 INFO:     Epoch: 46
2022-12-31 02:55:07,076 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4154277155796687, 'Total loss': 0.4154277155796687} | train loss {'Reaction outcome loss': 0.14257171154905954, 'Total loss': 0.14257171154905954}
2022-12-31 02:55:07,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:07,076 INFO:     Epoch: 47
2022-12-31 02:55:08,693 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4153559774160385, 'Total loss': 0.4153559774160385} | train loss {'Reaction outcome loss': 0.1424005503161219, 'Total loss': 0.1424005503161219}
2022-12-31 02:55:08,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:08,694 INFO:     Epoch: 48
2022-12-31 02:55:10,299 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4255688567956289, 'Total loss': 0.4255688567956289} | train loss {'Reaction outcome loss': 0.13874248048820853, 'Total loss': 0.13874248048820853}
2022-12-31 02:55:10,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:10,299 INFO:     Epoch: 49
2022-12-31 02:55:11,913 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3600185667475065, 'Total loss': 0.3600185667475065} | train loss {'Reaction outcome loss': 0.13618153916930195, 'Total loss': 0.13618153916930195}
2022-12-31 02:55:11,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:11,913 INFO:     Epoch: 50
2022-12-31 02:55:13,530 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4342929035425186, 'Total loss': 0.4342929035425186} | train loss {'Reaction outcome loss': 0.13752689071502672, 'Total loss': 0.13752689071502672}
2022-12-31 02:55:13,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:13,530 INFO:     Epoch: 51
2022-12-31 02:55:15,184 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4023208161195119, 'Total loss': 0.4023208161195119} | train loss {'Reaction outcome loss': 0.13808067483202058, 'Total loss': 0.13808067483202058}
2022-12-31 02:55:15,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:15,184 INFO:     Epoch: 52
2022-12-31 02:55:16,833 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4329130639632543, 'Total loss': 0.4329130639632543} | train loss {'Reaction outcome loss': 0.13374001135791305, 'Total loss': 0.13374001135791305}
2022-12-31 02:55:16,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:16,833 INFO:     Epoch: 53
2022-12-31 02:55:18,475 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3891515831152598, 'Total loss': 0.3891515831152598} | train loss {'Reaction outcome loss': 0.13661885756938072, 'Total loss': 0.13661885756938072}
2022-12-31 02:55:18,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:18,475 INFO:     Epoch: 54
2022-12-31 02:55:20,130 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4358205715815226, 'Total loss': 0.4358205715815226} | train loss {'Reaction outcome loss': 0.1339360590255989, 'Total loss': 0.1339360590255989}
2022-12-31 02:55:20,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:20,130 INFO:     Epoch: 55
2022-12-31 02:55:21,750 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3894008467594782, 'Total loss': 0.3894008467594782} | train loss {'Reaction outcome loss': 0.13028640469305053, 'Total loss': 0.13028640469305053}
2022-12-31 02:55:21,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:21,750 INFO:     Epoch: 56
2022-12-31 02:55:23,357 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4252112219731013, 'Total loss': 0.4252112219731013} | train loss {'Reaction outcome loss': 0.12943465255853467, 'Total loss': 0.12943465255853467}
2022-12-31 02:55:23,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:23,357 INFO:     Epoch: 57
2022-12-31 02:55:25,010 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4163165268798669, 'Total loss': 0.4163165268798669} | train loss {'Reaction outcome loss': 0.13253602842344855, 'Total loss': 0.13253602842344855}
2022-12-31 02:55:25,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:25,011 INFO:     Epoch: 58
2022-12-31 02:55:26,654 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3537056639790535, 'Total loss': 0.3537056639790535} | train loss {'Reaction outcome loss': 0.1298844077553002, 'Total loss': 0.1298844077553002}
2022-12-31 02:55:26,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:26,655 INFO:     Epoch: 59
2022-12-31 02:55:28,305 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3804069206118584, 'Total loss': 0.3804069206118584} | train loss {'Reaction outcome loss': 0.12745792375891096, 'Total loss': 0.12745792375891096}
2022-12-31 02:55:28,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:28,305 INFO:     Epoch: 60
2022-12-31 02:55:29,920 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3581077153173586, 'Total loss': 0.3581077153173586} | train loss {'Reaction outcome loss': 0.12478691122212522, 'Total loss': 0.12478691122212522}
2022-12-31 02:55:29,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:29,921 INFO:     Epoch: 61
2022-12-31 02:55:31,541 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4014898220698039, 'Total loss': 0.4014898220698039} | train loss {'Reaction outcome loss': 0.1266596022785988, 'Total loss': 0.1266596022785988}
2022-12-31 02:55:31,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:31,541 INFO:     Epoch: 62
2022-12-31 02:55:33,194 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3801905905206998, 'Total loss': 0.3801905905206998} | train loss {'Reaction outcome loss': 0.12745274363058437, 'Total loss': 0.12745274363058437}
2022-12-31 02:55:33,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:33,196 INFO:     Epoch: 63
2022-12-31 02:55:34,800 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3853204389413198, 'Total loss': 0.3853204389413198} | train loss {'Reaction outcome loss': 0.12680038973777452, 'Total loss': 0.12680038973777452}
2022-12-31 02:55:34,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:34,801 INFO:     Epoch: 64
2022-12-31 02:55:36,429 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41546397358179094, 'Total loss': 0.41546397358179094} | train loss {'Reaction outcome loss': 0.12919423073346653, 'Total loss': 0.12919423073346653}
2022-12-31 02:55:36,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:36,429 INFO:     Epoch: 65
2022-12-31 02:55:38,082 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39313644369443257, 'Total loss': 0.39313644369443257} | train loss {'Reaction outcome loss': 0.12741848678722378, 'Total loss': 0.12741848678722378}
2022-12-31 02:55:38,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:38,082 INFO:     Epoch: 66
2022-12-31 02:55:39,690 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41496295581261317, 'Total loss': 0.41496295581261317} | train loss {'Reaction outcome loss': 0.12258332992570788, 'Total loss': 0.12258332992570788}
2022-12-31 02:55:39,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:39,690 INFO:     Epoch: 67
2022-12-31 02:55:41,304 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.380887158960104, 'Total loss': 0.380887158960104} | train loss {'Reaction outcome loss': 0.11906446236777153, 'Total loss': 0.11906446236777153}
2022-12-31 02:55:41,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:41,304 INFO:     Epoch: 68
2022-12-31 02:55:42,918 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3911890814701716, 'Total loss': 0.3911890814701716} | train loss {'Reaction outcome loss': 0.12115632842573588, 'Total loss': 0.12115632842573588}
2022-12-31 02:55:42,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:42,918 INFO:     Epoch: 69
2022-12-31 02:55:44,535 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40762634625037514, 'Total loss': 0.40762634625037514} | train loss {'Reaction outcome loss': 0.12689474351146687, 'Total loss': 0.12689474351146687}
2022-12-31 02:55:44,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:44,535 INFO:     Epoch: 70
2022-12-31 02:55:46,179 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3839679275949796, 'Total loss': 0.3839679275949796} | train loss {'Reaction outcome loss': 0.12515133068842446, 'Total loss': 0.12515133068842446}
2022-12-31 02:55:46,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:46,179 INFO:     Epoch: 71
2022-12-31 02:55:47,833 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3669528951247533, 'Total loss': 0.3669528951247533} | train loss {'Reaction outcome loss': 0.12284279602875485, 'Total loss': 0.12284279602875485}
2022-12-31 02:55:47,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:47,833 INFO:     Epoch: 72
2022-12-31 02:55:49,457 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38754895851016047, 'Total loss': 0.38754895851016047} | train loss {'Reaction outcome loss': 0.11774060271007356, 'Total loss': 0.11774060271007356}
2022-12-31 02:55:49,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:49,457 INFO:     Epoch: 73
2022-12-31 02:55:51,110 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40074665447076163, 'Total loss': 0.40074665447076163} | train loss {'Reaction outcome loss': 0.11774590257113378, 'Total loss': 0.11774590257113378}
2022-12-31 02:55:51,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:51,111 INFO:     Epoch: 74
2022-12-31 02:55:52,765 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37770410229762397, 'Total loss': 0.37770410229762397} | train loss {'Reaction outcome loss': 0.11810289568821798, 'Total loss': 0.11810289568821798}
2022-12-31 02:55:52,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:52,766 INFO:     Epoch: 75
2022-12-31 02:55:54,374 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40916624168554944, 'Total loss': 0.40916624168554944} | train loss {'Reaction outcome loss': 0.12132820660370762, 'Total loss': 0.12132820660370762}
2022-12-31 02:55:54,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:54,375 INFO:     Epoch: 76
2022-12-31 02:55:55,996 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39182399262984596, 'Total loss': 0.39182399262984596} | train loss {'Reaction outcome loss': 0.11858854263538264, 'Total loss': 0.11858854263538264}
2022-12-31 02:55:55,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:55,996 INFO:     Epoch: 77
2022-12-31 02:55:57,614 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43967071572939553, 'Total loss': 0.43967071572939553} | train loss {'Reaction outcome loss': 0.11713945783205656, 'Total loss': 0.11713945783205656}
2022-12-31 02:55:57,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:57,614 INFO:     Epoch: 78
2022-12-31 02:55:59,218 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44664331575234734, 'Total loss': 0.44664331575234734} | train loss {'Reaction outcome loss': 0.11600397810013625, 'Total loss': 0.11600397810013625}
2022-12-31 02:55:59,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:55:59,219 INFO:     Epoch: 79
2022-12-31 02:56:00,872 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.38892643886307876, 'Total loss': 0.38892643886307876} | train loss {'Reaction outcome loss': 0.11273538760830695, 'Total loss': 0.11273538760830695}
2022-12-31 02:56:00,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:00,873 INFO:     Epoch: 80
2022-12-31 02:56:02,526 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40128034849961597, 'Total loss': 0.40128034849961597} | train loss {'Reaction outcome loss': 0.112425235779888, 'Total loss': 0.112425235779888}
2022-12-31 02:56:02,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:02,526 INFO:     Epoch: 81
2022-12-31 02:56:04,164 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40252429644266763, 'Total loss': 0.40252429644266763} | train loss {'Reaction outcome loss': 0.11338245875650786, 'Total loss': 0.11338245875650786}
2022-12-31 02:56:04,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:04,164 INFO:     Epoch: 82
2022-12-31 02:56:05,770 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4237409035364787, 'Total loss': 0.4237409035364787} | train loss {'Reaction outcome loss': 0.11402727804150106, 'Total loss': 0.11402727804150106}
2022-12-31 02:56:05,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:05,770 INFO:     Epoch: 83
2022-12-31 02:56:07,397 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3829143919050694, 'Total loss': 0.3829143919050694} | train loss {'Reaction outcome loss': 0.10998583929171364, 'Total loss': 0.10998583929171364}
2022-12-31 02:56:07,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:07,398 INFO:     Epoch: 84
2022-12-31 02:56:09,052 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37025629679361977, 'Total loss': 0.37025629679361977} | train loss {'Reaction outcome loss': 0.11582858119173532, 'Total loss': 0.11582858119173532}
2022-12-31 02:56:09,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:09,053 INFO:     Epoch: 85
2022-12-31 02:56:10,662 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42639289299647015, 'Total loss': 0.42639289299647015} | train loss {'Reaction outcome loss': 0.11679694005016265, 'Total loss': 0.11679694005016265}
2022-12-31 02:56:10,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:10,663 INFO:     Epoch: 86
2022-12-31 02:56:12,317 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3929392576217651, 'Total loss': 0.3929392576217651} | train loss {'Reaction outcome loss': 0.11711001152641745, 'Total loss': 0.11711001152641745}
2022-12-31 02:56:12,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:12,317 INFO:     Epoch: 87
2022-12-31 02:56:13,925 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4532886584599813, 'Total loss': 0.4532886584599813} | train loss {'Reaction outcome loss': 0.11744592882723405, 'Total loss': 0.11744592882723405}
2022-12-31 02:56:13,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:13,925 INFO:     Epoch: 88
2022-12-31 02:56:15,579 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39402285317579905, 'Total loss': 0.39402285317579905} | train loss {'Reaction outcome loss': 0.11004354486609028, 'Total loss': 0.11004354486609028}
2022-12-31 02:56:15,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:15,580 INFO:     Epoch: 89
2022-12-31 02:56:17,180 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.365724541246891, 'Total loss': 0.365724541246891} | train loss {'Reaction outcome loss': 0.11194600857603941, 'Total loss': 0.11194600857603941}
2022-12-31 02:56:17,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:17,180 INFO:     Epoch: 90
2022-12-31 02:56:18,834 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4618809729814529, 'Total loss': 0.4618809729814529} | train loss {'Reaction outcome loss': 0.10972005953794739, 'Total loss': 0.10972005953794739}
2022-12-31 02:56:18,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:18,834 INFO:     Epoch: 91
2022-12-31 02:56:20,445 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4257867902517319, 'Total loss': 0.4257867902517319} | train loss {'Reaction outcome loss': 0.11077915164166177, 'Total loss': 0.11077915164166177}
2022-12-31 02:56:20,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:20,445 INFO:     Epoch: 92
2022-12-31 02:56:22,075 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.35420649871230125, 'Total loss': 0.35420649871230125} | train loss {'Reaction outcome loss': 0.11029508039797147, 'Total loss': 0.11029508039797147}
2022-12-31 02:56:22,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:22,075 INFO:     Epoch: 93
2022-12-31 02:56:23,692 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4122150828440984, 'Total loss': 0.4122150828440984} | train loss {'Reaction outcome loss': 0.11232029608566396, 'Total loss': 0.11232029608566396}
2022-12-31 02:56:23,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:23,693 INFO:     Epoch: 94
2022-12-31 02:56:25,304 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3869471554954847, 'Total loss': 0.3869471554954847} | train loss {'Reaction outcome loss': 0.11281143325503344, 'Total loss': 0.11281143325503344}
2022-12-31 02:56:25,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:25,304 INFO:     Epoch: 95
2022-12-31 02:56:26,957 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42348338961601256, 'Total loss': 0.42348338961601256} | train loss {'Reaction outcome loss': 0.10660491239816548, 'Total loss': 0.10660491239816548}
2022-12-31 02:56:26,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:26,957 INFO:     Epoch: 96
2022-12-31 02:56:28,561 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3983631191154321, 'Total loss': 0.3983631191154321} | train loss {'Reaction outcome loss': 0.1076335152891553, 'Total loss': 0.1076335152891553}
2022-12-31 02:56:28,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:28,562 INFO:     Epoch: 97
2022-12-31 02:56:30,167 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3897225466867288, 'Total loss': 0.3897225466867288} | train loss {'Reaction outcome loss': 0.1069378064975931, 'Total loss': 0.1069378064975931}
2022-12-31 02:56:30,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:30,167 INFO:     Epoch: 98
2022-12-31 02:56:31,786 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3636097269753615, 'Total loss': 0.3636097269753615} | train loss {'Reaction outcome loss': 0.10896315559384542, 'Total loss': 0.10896315559384542}
2022-12-31 02:56:31,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:31,786 INFO:     Epoch: 99
2022-12-31 02:56:33,406 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40683792531490326, 'Total loss': 0.40683792531490326} | train loss {'Reaction outcome loss': 0.11147027302968458, 'Total loss': 0.11147027302968458}
2022-12-31 02:56:33,406 INFO:     Best model found after epoch 29 of 100.
2022-12-31 02:56:33,406 INFO:   Done with stage: TRAINING
2022-12-31 02:56:33,406 INFO:   Starting stage: EVALUATION
2022-12-31 02:56:33,544 INFO:   Done with stage: EVALUATION
2022-12-31 02:56:33,544 INFO:   Leaving out SEQ value Fold_5
2022-12-31 02:56:33,556 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 02:56:33,556 INFO:   Starting stage: FEATURE SCALING
2022-12-31 02:56:34,207 INFO:   Done with stage: FEATURE SCALING
2022-12-31 02:56:34,208 INFO:   Starting stage: SCALING TARGETS
2022-12-31 02:56:34,281 INFO:   Done with stage: SCALING TARGETS
2022-12-31 02:56:34,281 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 02:56:34,281 INFO:     No hyperparam tuning for this model
2022-12-31 02:56:34,281 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 02:56:34,282 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 02:56:34,282 INFO:     None feature selector for col prot
2022-12-31 02:56:34,282 INFO:     None feature selector for col prot
2022-12-31 02:56:34,283 INFO:     None feature selector for col prot
2022-12-31 02:56:34,283 INFO:     None feature selector for col chem
2022-12-31 02:56:34,283 INFO:     None feature selector for col chem
2022-12-31 02:56:34,283 INFO:     None feature selector for col chem
2022-12-31 02:56:34,283 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 02:56:34,283 INFO:   Starting stage: BUILD MODEL
2022-12-31 02:56:34,285 INFO:     Number of params in model 224011
2022-12-31 02:56:34,289 INFO:   Done with stage: BUILD MODEL
2022-12-31 02:56:34,289 INFO:   Starting stage: TRAINING
2022-12-31 02:56:34,333 INFO:     Val loss before train {'Reaction outcome loss': 1.0344028353691102, 'Total loss': 1.0344028353691102}
2022-12-31 02:56:34,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:34,333 INFO:     Epoch: 0
2022-12-31 02:56:35,950 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5539143780867258, 'Total loss': 0.5539143780867258} | train loss {'Reaction outcome loss': 0.7688890243677989, 'Total loss': 0.7688890243677989}
2022-12-31 02:56:35,950 INFO:     Found new best model at epoch 0
2022-12-31 02:56:35,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:35,951 INFO:     Epoch: 1
2022-12-31 02:56:37,565 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4695267175634702, 'Total loss': 0.4695267175634702} | train loss {'Reaction outcome loss': 0.5111567087184032, 'Total loss': 0.5111567087184032}
2022-12-31 02:56:37,565 INFO:     Found new best model at epoch 1
2022-12-31 02:56:37,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:37,566 INFO:     Epoch: 2
2022-12-31 02:56:39,178 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46025703152020775, 'Total loss': 0.46025703152020775} | train loss {'Reaction outcome loss': 0.4411122422138958, 'Total loss': 0.4411122422138958}
2022-12-31 02:56:39,178 INFO:     Found new best model at epoch 2
2022-12-31 02:56:39,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:39,179 INFO:     Epoch: 3
2022-12-31 02:56:40,824 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4433537075916926, 'Total loss': 0.4433537075916926} | train loss {'Reaction outcome loss': 0.40561315239123674, 'Total loss': 0.40561315239123674}
2022-12-31 02:56:40,824 INFO:     Found new best model at epoch 3
2022-12-31 02:56:40,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:40,825 INFO:     Epoch: 4
2022-12-31 02:56:42,441 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4479721873998642, 'Total loss': 0.4479721873998642} | train loss {'Reaction outcome loss': 0.3783138612204272, 'Total loss': 0.3783138612204272}
2022-12-31 02:56:42,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:42,441 INFO:     Epoch: 5
2022-12-31 02:56:44,068 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43763579924901325, 'Total loss': 0.43763579924901325} | train loss {'Reaction outcome loss': 0.3587958436540287, 'Total loss': 0.3587958436540287}
2022-12-31 02:56:44,069 INFO:     Found new best model at epoch 5
2022-12-31 02:56:44,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:44,070 INFO:     Epoch: 6
2022-12-31 02:56:45,736 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4134365230798721, 'Total loss': 0.4134365230798721} | train loss {'Reaction outcome loss': 0.32917305216297804, 'Total loss': 0.32917305216297804}
2022-12-31 02:56:45,736 INFO:     Found new best model at epoch 6
2022-12-31 02:56:45,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:45,737 INFO:     Epoch: 7
2022-12-31 02:56:47,352 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44259453217188516, 'Total loss': 0.44259453217188516} | train loss {'Reaction outcome loss': 0.31072282881106494, 'Total loss': 0.31072282881106494}
2022-12-31 02:56:47,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:47,352 INFO:     Epoch: 8
2022-12-31 02:56:49,000 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41697086493174235, 'Total loss': 0.41697086493174235} | train loss {'Reaction outcome loss': 0.2973353229733049, 'Total loss': 0.2973353229733049}
2022-12-31 02:56:49,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:49,001 INFO:     Epoch: 9
2022-12-31 02:56:50,615 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4204934636751811, 'Total loss': 0.4204934636751811} | train loss {'Reaction outcome loss': 0.28181625084708567, 'Total loss': 0.28181625084708567}
2022-12-31 02:56:50,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:50,616 INFO:     Epoch: 10
2022-12-31 02:56:52,230 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44666278958320615, 'Total loss': 0.44666278958320615} | train loss {'Reaction outcome loss': 0.2811400783450707, 'Total loss': 0.2811400783450707}
2022-12-31 02:56:52,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:52,230 INFO:     Epoch: 11
2022-12-31 02:56:53,844 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4325769742329915, 'Total loss': 0.4325769742329915} | train loss {'Reaction outcome loss': 0.29668316959093016, 'Total loss': 0.29668316959093016}
2022-12-31 02:56:53,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:53,844 INFO:     Epoch: 12
2022-12-31 02:56:55,509 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41887570718924205, 'Total loss': 0.41887570718924205} | train loss {'Reaction outcome loss': 0.2559907717944082, 'Total loss': 0.2559907717944082}
2022-12-31 02:56:55,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:55,510 INFO:     Epoch: 13
2022-12-31 02:56:57,132 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42587400575478873, 'Total loss': 0.42587400575478873} | train loss {'Reaction outcome loss': 0.2413550629634815, 'Total loss': 0.2413550629634815}
2022-12-31 02:56:57,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:57,133 INFO:     Epoch: 14
2022-12-31 02:56:58,765 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44217058618863425, 'Total loss': 0.44217058618863425} | train loss {'Reaction outcome loss': 0.23400015172049188, 'Total loss': 0.23400015172049188}
2022-12-31 02:56:58,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:56:58,765 INFO:     Epoch: 15
2022-12-31 02:57:00,397 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4236573576927185, 'Total loss': 0.4236573576927185} | train loss {'Reaction outcome loss': 0.23378477436621115, 'Total loss': 0.23378477436621115}
2022-12-31 02:57:00,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:00,397 INFO:     Epoch: 16
2022-12-31 02:57:02,014 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44558863441149393, 'Total loss': 0.44558863441149393} | train loss {'Reaction outcome loss': 0.2141715812626701, 'Total loss': 0.2141715812626701}
2022-12-31 02:57:02,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:02,015 INFO:     Epoch: 17
2022-12-31 02:57:03,678 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4333796779314677, 'Total loss': 0.4333796779314677} | train loss {'Reaction outcome loss': 0.21738271911938986, 'Total loss': 0.21738271911938986}
2022-12-31 02:57:03,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:03,679 INFO:     Epoch: 18
2022-12-31 02:57:05,296 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45917442043622336, 'Total loss': 0.45917442043622336} | train loss {'Reaction outcome loss': 0.21588717559622467, 'Total loss': 0.21588717559622467}
2022-12-31 02:57:05,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:05,296 INFO:     Epoch: 19
2022-12-31 02:57:06,952 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44651201367378235, 'Total loss': 0.44651201367378235} | train loss {'Reaction outcome loss': 0.20572457020192075, 'Total loss': 0.20572457020192075}
2022-12-31 02:57:06,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:06,952 INFO:     Epoch: 20
2022-12-31 02:57:08,570 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45870102047920225, 'Total loss': 0.45870102047920225} | train loss {'Reaction outcome loss': 0.19471877426300468, 'Total loss': 0.19471877426300468}
2022-12-31 02:57:08,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:08,571 INFO:     Epoch: 21
2022-12-31 02:57:10,232 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4250070363283157, 'Total loss': 0.4250070363283157} | train loss {'Reaction outcome loss': 0.19199863438447262, 'Total loss': 0.19199863438447262}
2022-12-31 02:57:10,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:10,232 INFO:     Epoch: 22
2022-12-31 02:57:11,858 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4102451244990031, 'Total loss': 0.4102451244990031} | train loss {'Reaction outcome loss': 0.1912395570969871, 'Total loss': 0.1912395570969871}
2022-12-31 02:57:11,858 INFO:     Found new best model at epoch 22
2022-12-31 02:57:11,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:11,860 INFO:     Epoch: 23
2022-12-31 02:57:13,475 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4535329322020213, 'Total loss': 0.4535329322020213} | train loss {'Reaction outcome loss': 0.18405201425783793, 'Total loss': 0.18405201425783793}
2022-12-31 02:57:13,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:13,476 INFO:     Epoch: 24
2022-12-31 02:57:15,141 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43282359341780346, 'Total loss': 0.43282359341780346} | train loss {'Reaction outcome loss': 0.18085229660779156, 'Total loss': 0.18085229660779156}
2022-12-31 02:57:15,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:15,143 INFO:     Epoch: 25
2022-12-31 02:57:16,760 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43432386418183644, 'Total loss': 0.43432386418183644} | train loss {'Reaction outcome loss': 0.17638971918290994, 'Total loss': 0.17638971918290994}
2022-12-31 02:57:16,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:16,760 INFO:     Epoch: 26
2022-12-31 02:57:18,392 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47029543220996856, 'Total loss': 0.47029543220996856} | train loss {'Reaction outcome loss': 0.17434396776514113, 'Total loss': 0.17434396776514113}
2022-12-31 02:57:18,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:18,392 INFO:     Epoch: 27
2022-12-31 02:57:20,026 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4389801075061162, 'Total loss': 0.4389801075061162} | train loss {'Reaction outcome loss': 0.17127577314396278, 'Total loss': 0.17127577314396278}
2022-12-31 02:57:20,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:20,026 INFO:     Epoch: 28
2022-12-31 02:57:21,660 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4554069002469381, 'Total loss': 0.4554069002469381} | train loss {'Reaction outcome loss': 0.16977686182666651, 'Total loss': 0.16977686182666651}
2022-12-31 02:57:21,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:21,661 INFO:     Epoch: 29
2022-12-31 02:57:23,294 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4142629084487756, 'Total loss': 0.4142629084487756} | train loss {'Reaction outcome loss': 0.1671528080208362, 'Total loss': 0.1671528080208362}
2022-12-31 02:57:23,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:23,294 INFO:     Epoch: 30
2022-12-31 02:57:24,927 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4296542982260386, 'Total loss': 0.4296542982260386} | train loss {'Reaction outcome loss': 0.16939378181553405, 'Total loss': 0.16939378181553405}
2022-12-31 02:57:24,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:24,928 INFO:     Epoch: 31
2022-12-31 02:57:26,539 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4354657908280691, 'Total loss': 0.4354657908280691} | train loss {'Reaction outcome loss': 0.16064719150460366, 'Total loss': 0.16064719150460366}
2022-12-31 02:57:26,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:26,539 INFO:     Epoch: 32
2022-12-31 02:57:28,160 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4320567230383555, 'Total loss': 0.4320567230383555} | train loss {'Reaction outcome loss': 0.15572850008333183, 'Total loss': 0.15572850008333183}
2022-12-31 02:57:28,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:28,160 INFO:     Epoch: 33
2022-12-31 02:57:29,796 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4433744033177694, 'Total loss': 0.4433744033177694} | train loss {'Reaction outcome loss': 0.157360173245568, 'Total loss': 0.157360173245568}
2022-12-31 02:57:29,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:29,796 INFO:     Epoch: 34
2022-12-31 02:57:31,421 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4200516939163208, 'Total loss': 0.4200516939163208} | train loss {'Reaction outcome loss': 0.15378199397968853, 'Total loss': 0.15378199397968853}
2022-12-31 02:57:31,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:31,422 INFO:     Epoch: 35
2022-12-31 02:57:33,040 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41595938404401145, 'Total loss': 0.41595938404401145} | train loss {'Reaction outcome loss': 0.1728160135191528, 'Total loss': 0.1728160135191528}
2022-12-31 02:57:33,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:33,040 INFO:     Epoch: 36
2022-12-31 02:57:34,656 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40836271047592165, 'Total loss': 0.40836271047592165} | train loss {'Reaction outcome loss': 0.16491201262418315, 'Total loss': 0.16491201262418315}
2022-12-31 02:57:34,656 INFO:     Found new best model at epoch 36
2022-12-31 02:57:34,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:34,657 INFO:     Epoch: 37
2022-12-31 02:57:36,285 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41619582374890646, 'Total loss': 0.41619582374890646} | train loss {'Reaction outcome loss': 0.15246114409121114, 'Total loss': 0.15246114409121114}
2022-12-31 02:57:36,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:36,286 INFO:     Epoch: 38
2022-12-31 02:57:37,951 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4307878384987513, 'Total loss': 0.4307878384987513} | train loss {'Reaction outcome loss': 0.14599791851124147, 'Total loss': 0.14599791851124147}
2022-12-31 02:57:37,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:37,951 INFO:     Epoch: 39
2022-12-31 02:57:39,571 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.436643319328626, 'Total loss': 0.436643319328626} | train loss {'Reaction outcome loss': 0.14799513000553302, 'Total loss': 0.14799513000553302}
2022-12-31 02:57:39,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:39,571 INFO:     Epoch: 40
2022-12-31 02:57:41,199 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44017423192660016, 'Total loss': 0.44017423192660016} | train loss {'Reaction outcome loss': 0.14313659285538882, 'Total loss': 0.14313659285538882}
2022-12-31 02:57:41,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:41,199 INFO:     Epoch: 41
2022-12-31 02:57:42,828 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4145394690334797, 'Total loss': 0.4145394690334797} | train loss {'Reaction outcome loss': 0.14475853197417682, 'Total loss': 0.14475853197417682}
2022-12-31 02:57:42,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:42,828 INFO:     Epoch: 42
2022-12-31 02:57:44,469 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4327004094918569, 'Total loss': 0.4327004094918569} | train loss {'Reaction outcome loss': 0.14036724309013496, 'Total loss': 0.14036724309013496}
2022-12-31 02:57:44,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:44,469 INFO:     Epoch: 43
2022-12-31 02:57:46,092 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47189374764760333, 'Total loss': 0.47189374764760333} | train loss {'Reaction outcome loss': 0.1425521121148357, 'Total loss': 0.1425521121148357}
2022-12-31 02:57:46,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:46,094 INFO:     Epoch: 44
2022-12-31 02:57:47,708 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40196831127007804, 'Total loss': 0.40196831127007804} | train loss {'Reaction outcome loss': 0.1397406344042173, 'Total loss': 0.1397406344042173}
2022-12-31 02:57:47,708 INFO:     Found new best model at epoch 44
2022-12-31 02:57:47,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:47,709 INFO:     Epoch: 45
2022-12-31 02:57:49,332 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4142573187748591, 'Total loss': 0.4142573187748591} | train loss {'Reaction outcome loss': 0.1397990644702762, 'Total loss': 0.1397990644702762}
2022-12-31 02:57:49,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:49,333 INFO:     Epoch: 46
2022-12-31 02:57:50,959 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4435677282512188, 'Total loss': 0.4435677282512188} | train loss {'Reaction outcome loss': 0.13408014950868105, 'Total loss': 0.13408014950868105}
2022-12-31 02:57:50,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:50,959 INFO:     Epoch: 47
2022-12-31 02:57:52,616 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.441061736146609, 'Total loss': 0.441061736146609} | train loss {'Reaction outcome loss': 0.1359268930590443, 'Total loss': 0.1359268930590443}
2022-12-31 02:57:52,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:52,617 INFO:     Epoch: 48
2022-12-31 02:57:54,238 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4163602332274119, 'Total loss': 0.4163602332274119} | train loss {'Reaction outcome loss': 0.13438411514895657, 'Total loss': 0.13438411514895657}
2022-12-31 02:57:54,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:54,238 INFO:     Epoch: 49
2022-12-31 02:57:55,903 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4001031095782916, 'Total loss': 0.4001031095782916} | train loss {'Reaction outcome loss': 0.13223306743642804, 'Total loss': 0.13223306743642804}
2022-12-31 02:57:55,903 INFO:     Found new best model at epoch 49
2022-12-31 02:57:55,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:55,904 INFO:     Epoch: 50
2022-12-31 02:57:57,520 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4356251577536265, 'Total loss': 0.4356251577536265} | train loss {'Reaction outcome loss': 0.13168833571810112, 'Total loss': 0.13168833571810112}
2022-12-31 02:57:57,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:57,521 INFO:     Epoch: 51
2022-12-31 02:57:59,185 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43597423409422237, 'Total loss': 0.43597423409422237} | train loss {'Reaction outcome loss': 0.12752151170001447, 'Total loss': 0.12752151170001447}
2022-12-31 02:57:59,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:57:59,185 INFO:     Epoch: 52
2022-12-31 02:58:00,805 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46329832474390664, 'Total loss': 0.46329832474390664} | train loss {'Reaction outcome loss': 0.13221347252239365, 'Total loss': 0.13221347252239365}
2022-12-31 02:58:00,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:00,805 INFO:     Epoch: 53
2022-12-31 02:58:02,444 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44436311622460684, 'Total loss': 0.44436311622460684} | train loss {'Reaction outcome loss': 0.12967926889405793, 'Total loss': 0.12967926889405793}
2022-12-31 02:58:02,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:02,444 INFO:     Epoch: 54
2022-12-31 02:58:04,062 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43966692090034487, 'Total loss': 0.43966692090034487} | train loss {'Reaction outcome loss': 0.127726144250626, 'Total loss': 0.127726144250626}
2022-12-31 02:58:04,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:04,062 INFO:     Epoch: 55
2022-12-31 02:58:05,681 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4176087627808253, 'Total loss': 0.4176087627808253} | train loss {'Reaction outcome loss': 0.12815284682321784, 'Total loss': 0.12815284682321784}
2022-12-31 02:58:05,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:05,682 INFO:     Epoch: 56
2022-12-31 02:58:07,305 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43944603353738787, 'Total loss': 0.43944603353738787} | train loss {'Reaction outcome loss': 0.12805861366159396, 'Total loss': 0.12805861366159396}
2022-12-31 02:58:07,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:07,305 INFO:     Epoch: 57
2022-12-31 02:58:08,969 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4198871846000353, 'Total loss': 0.4198871846000353} | train loss {'Reaction outcome loss': 0.12466164273243613, 'Total loss': 0.12466164273243613}
2022-12-31 02:58:08,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:08,969 INFO:     Epoch: 58
2022-12-31 02:58:10,587 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45419150839249295, 'Total loss': 0.45419150839249295} | train loss {'Reaction outcome loss': 0.1315003781751527, 'Total loss': 0.1315003781751527}
2022-12-31 02:58:10,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:10,587 INFO:     Epoch: 59
2022-12-31 02:58:12,238 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4612422063946724, 'Total loss': 0.4612422063946724} | train loss {'Reaction outcome loss': 0.17396482046477604, 'Total loss': 0.17396482046477604}
2022-12-31 02:58:12,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:12,238 INFO:     Epoch: 60
2022-12-31 02:58:13,856 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4113359731932481, 'Total loss': 0.4113359731932481} | train loss {'Reaction outcome loss': 0.1336148777011566, 'Total loss': 0.1336148777011566}
2022-12-31 02:58:13,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:13,857 INFO:     Epoch: 61
2022-12-31 02:58:15,485 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.448141864935557, 'Total loss': 0.448141864935557} | train loss {'Reaction outcome loss': 0.13001368611730868, 'Total loss': 0.13001368611730868}
2022-12-31 02:58:15,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:15,485 INFO:     Epoch: 62
2022-12-31 02:58:17,123 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44420130451520284, 'Total loss': 0.44420130451520284} | train loss {'Reaction outcome loss': 0.12286182122298286, 'Total loss': 0.12286182122298286}
2022-12-31 02:58:17,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:17,125 INFO:     Epoch: 63
2022-12-31 02:58:18,743 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41396116813023887, 'Total loss': 0.41396116813023887} | train loss {'Reaction outcome loss': 0.11804827940943431, 'Total loss': 0.11804827940943431}
2022-12-31 02:58:18,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:18,743 INFO:     Epoch: 64
2022-12-31 02:58:20,357 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42367543776830036, 'Total loss': 0.42367543776830036} | train loss {'Reaction outcome loss': 0.11888636193487111, 'Total loss': 0.11888636193487111}
2022-12-31 02:58:20,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:20,357 INFO:     Epoch: 65
2022-12-31 02:58:22,022 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48100413630406064, 'Total loss': 0.48100413630406064} | train loss {'Reaction outcome loss': 0.13166433804250066, 'Total loss': 0.13166433804250066}
2022-12-31 02:58:22,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:22,022 INFO:     Epoch: 66
2022-12-31 02:58:23,641 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4392994701862335, 'Total loss': 0.4392994701862335} | train loss {'Reaction outcome loss': 0.16061040479689837, 'Total loss': 0.16061040479689837}
2022-12-31 02:58:23,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:23,642 INFO:     Epoch: 67
2022-12-31 02:58:25,266 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4398631195227305, 'Total loss': 0.4398631195227305} | train loss {'Reaction outcome loss': 0.12468512844213325, 'Total loss': 0.12468512844213325}
2022-12-31 02:58:25,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:25,266 INFO:     Epoch: 68
2022-12-31 02:58:26,932 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4303187221288681, 'Total loss': 0.4303187221288681} | train loss {'Reaction outcome loss': 0.12954064595776246, 'Total loss': 0.12954064595776246}
2022-12-31 02:58:26,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:26,932 INFO:     Epoch: 69
2022-12-31 02:58:28,598 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4161346952120463, 'Total loss': 0.4161346952120463} | train loss {'Reaction outcome loss': 0.1243872814409394, 'Total loss': 0.1243872814409394}
2022-12-31 02:58:28,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:28,599 INFO:     Epoch: 70
2022-12-31 02:58:30,225 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4527970810731252, 'Total loss': 0.4527970810731252} | train loss {'Reaction outcome loss': 0.11847589020423281, 'Total loss': 0.11847589020423281}
2022-12-31 02:58:30,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:30,225 INFO:     Epoch: 71
2022-12-31 02:58:31,890 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41165399675567943, 'Total loss': 0.41165399675567943} | train loss {'Reaction outcome loss': 0.11834205027422497, 'Total loss': 0.11834205027422497}
2022-12-31 02:58:31,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:31,891 INFO:     Epoch: 72
2022-12-31 02:58:33,526 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4132413923740387, 'Total loss': 0.4132413923740387} | train loss {'Reaction outcome loss': 0.11513113619952017, 'Total loss': 0.11513113619952017}
2022-12-31 02:58:33,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:33,527 INFO:     Epoch: 73
2022-12-31 02:58:35,147 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4369783302148183, 'Total loss': 0.4369783302148183} | train loss {'Reaction outcome loss': 0.11846067443221345, 'Total loss': 0.11846067443221345}
2022-12-31 02:58:35,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:35,147 INFO:     Epoch: 74
2022-12-31 02:58:36,812 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4241370474298795, 'Total loss': 0.4241370474298795} | train loss {'Reaction outcome loss': 0.11860978425428967, 'Total loss': 0.11860978425428967}
2022-12-31 02:58:36,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:36,813 INFO:     Epoch: 75
2022-12-31 02:58:38,431 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4393640617529551, 'Total loss': 0.4393640617529551} | train loss {'Reaction outcome loss': 0.11367173411755188, 'Total loss': 0.11367173411755188}
2022-12-31 02:58:38,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:38,432 INFO:     Epoch: 76
2022-12-31 02:58:40,054 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4439716766277949, 'Total loss': 0.4439716766277949} | train loss {'Reaction outcome loss': 0.11954172155009987, 'Total loss': 0.11954172155009987}
2022-12-31 02:58:40,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:40,055 INFO:     Epoch: 77
2022-12-31 02:58:41,720 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4553553104400635, 'Total loss': 0.4553553104400635} | train loss {'Reaction outcome loss': 0.11566359751698958, 'Total loss': 0.11566359751698958}
2022-12-31 02:58:41,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:41,721 INFO:     Epoch: 78
2022-12-31 02:58:43,338 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46612906754016875, 'Total loss': 0.46612906754016875} | train loss {'Reaction outcome loss': 0.11191984164609006, 'Total loss': 0.11191984164609006}
2022-12-31 02:58:43,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:43,338 INFO:     Epoch: 79
2022-12-31 02:58:45,004 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45789168278376263, 'Total loss': 0.45789168278376263} | train loss {'Reaction outcome loss': 0.11294197408711044, 'Total loss': 0.11294197408711044}
2022-12-31 02:58:45,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:45,004 INFO:     Epoch: 80
2022-12-31 02:58:46,624 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4374872833490372, 'Total loss': 0.4374872833490372} | train loss {'Reaction outcome loss': 0.11498991804841933, 'Total loss': 0.11498991804841933}
2022-12-31 02:58:46,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:46,624 INFO:     Epoch: 81
2022-12-31 02:58:48,260 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4238922039667765, 'Total loss': 0.4238922039667765} | train loss {'Reaction outcome loss': 0.11311851305130192, 'Total loss': 0.11311851305130192}
2022-12-31 02:58:48,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:48,260 INFO:     Epoch: 82
2022-12-31 02:58:49,894 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4271677047014236, 'Total loss': 0.4271677047014236} | train loss {'Reaction outcome loss': 0.11503224880468316, 'Total loss': 0.11503224880468316}
2022-12-31 02:58:49,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:49,894 INFO:     Epoch: 83
2022-12-31 02:58:51,462 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4551711658636729, 'Total loss': 0.4551711658636729} | train loss {'Reaction outcome loss': 0.11265863213465428, 'Total loss': 0.11265863213465428}
2022-12-31 02:58:51,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:51,462 INFO:     Epoch: 84
2022-12-31 02:58:52,597 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4385877802968025, 'Total loss': 0.4385877802968025} | train loss {'Reaction outcome loss': 0.11626184376388889, 'Total loss': 0.11626184376388889}
2022-12-31 02:58:52,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:52,599 INFO:     Epoch: 85
2022-12-31 02:58:53,733 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4361787845691045, 'Total loss': 0.4361787845691045} | train loss {'Reaction outcome loss': 0.11274121363163905, 'Total loss': 0.11274121363163905}
2022-12-31 02:58:53,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:53,733 INFO:     Epoch: 86
2022-12-31 02:58:54,868 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4521498521169027, 'Total loss': 0.4521498521169027} | train loss {'Reaction outcome loss': 0.10582522477109349, 'Total loss': 0.10582522477109349}
2022-12-31 02:58:54,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:54,869 INFO:     Epoch: 87
2022-12-31 02:58:56,096 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.480978790918986, 'Total loss': 0.480978790918986} | train loss {'Reaction outcome loss': 0.1094353626563595, 'Total loss': 0.1094353626563595}
2022-12-31 02:58:56,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:56,096 INFO:     Epoch: 88
2022-12-31 02:58:57,721 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4321206877628962, 'Total loss': 0.4321206877628962} | train loss {'Reaction outcome loss': 0.11033657045176158, 'Total loss': 0.11033657045176158}
2022-12-31 02:58:57,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:57,721 INFO:     Epoch: 89
2022-12-31 02:58:59,385 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41949110229810077, 'Total loss': 0.41949110229810077} | train loss {'Reaction outcome loss': 0.10953880115519733, 'Total loss': 0.10953880115519733}
2022-12-31 02:58:59,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:58:59,386 INFO:     Epoch: 90
2022-12-31 02:59:01,006 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44680131574471793, 'Total loss': 0.44680131574471793} | train loss {'Reaction outcome loss': 0.10885765370967683, 'Total loss': 0.10885765370967683}
2022-12-31 02:59:01,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:01,006 INFO:     Epoch: 91
2022-12-31 02:59:02,670 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45410170356432594, 'Total loss': 0.45410170356432594} | train loss {'Reaction outcome loss': 0.11016931119935917, 'Total loss': 0.11016931119935917}
2022-12-31 02:59:02,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:02,670 INFO:     Epoch: 92
2022-12-31 02:59:04,310 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4280878742535909, 'Total loss': 0.4280878742535909} | train loss {'Reaction outcome loss': 0.10975327113461074, 'Total loss': 0.10975327113461074}
2022-12-31 02:59:04,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:04,310 INFO:     Epoch: 93
2022-12-31 02:59:05,924 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46160947581132256, 'Total loss': 0.46160947581132256} | train loss {'Reaction outcome loss': 0.10984588216920003, 'Total loss': 0.10984588216920003}
2022-12-31 02:59:05,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:05,924 INFO:     Epoch: 94
2022-12-31 02:59:07,590 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46489113867282866, 'Total loss': 0.46489113867282866} | train loss {'Reaction outcome loss': 0.11244761586873421, 'Total loss': 0.11244761586873421}
2022-12-31 02:59:07,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:07,590 INFO:     Epoch: 95
2022-12-31 02:59:09,210 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43245102564493815, 'Total loss': 0.43245102564493815} | train loss {'Reaction outcome loss': 0.11461909672579022, 'Total loss': 0.11461909672579022}
2022-12-31 02:59:09,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:09,210 INFO:     Epoch: 96
2022-12-31 02:59:10,876 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4595853676398595, 'Total loss': 0.4595853676398595} | train loss {'Reaction outcome loss': 0.1051293882069792, 'Total loss': 0.1051293882069792}
2022-12-31 02:59:10,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:10,876 INFO:     Epoch: 97
2022-12-31 02:59:12,542 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4237995569904645, 'Total loss': 0.4237995569904645} | train loss {'Reaction outcome loss': 0.10729313355303653, 'Total loss': 0.10729313355303653}
2022-12-31 02:59:12,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:12,543 INFO:     Epoch: 98
2022-12-31 02:59:14,211 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43579448635379475, 'Total loss': 0.43579448635379475} | train loss {'Reaction outcome loss': 0.10653924113232305, 'Total loss': 0.10653924113232305}
2022-12-31 02:59:14,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:14,211 INFO:     Epoch: 99
2022-12-31 02:59:15,835 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4668086757262548, 'Total loss': 0.4668086757262548} | train loss {'Reaction outcome loss': 0.10776077781338245, 'Total loss': 0.10776077781338245}
2022-12-31 02:59:15,835 INFO:     Best model found after epoch 50 of 100.
2022-12-31 02:59:15,835 INFO:   Done with stage: TRAINING
2022-12-31 02:59:15,835 INFO:   Starting stage: EVALUATION
2022-12-31 02:59:15,968 INFO:   Done with stage: EVALUATION
2022-12-31 02:59:15,968 INFO:   Leaving out SEQ value Fold_6
2022-12-31 02:59:15,980 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 02:59:15,980 INFO:   Starting stage: FEATURE SCALING
2022-12-31 02:59:16,634 INFO:   Done with stage: FEATURE SCALING
2022-12-31 02:59:16,634 INFO:   Starting stage: SCALING TARGETS
2022-12-31 02:59:16,708 INFO:   Done with stage: SCALING TARGETS
2022-12-31 02:59:16,708 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 02:59:16,708 INFO:     No hyperparam tuning for this model
2022-12-31 02:59:16,709 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 02:59:16,709 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 02:59:16,709 INFO:     None feature selector for col prot
2022-12-31 02:59:16,709 INFO:     None feature selector for col prot
2022-12-31 02:59:16,709 INFO:     None feature selector for col prot
2022-12-31 02:59:16,710 INFO:     None feature selector for col chem
2022-12-31 02:59:16,710 INFO:     None feature selector for col chem
2022-12-31 02:59:16,710 INFO:     None feature selector for col chem
2022-12-31 02:59:16,710 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 02:59:16,710 INFO:   Starting stage: BUILD MODEL
2022-12-31 02:59:16,712 INFO:     Number of params in model 224011
2022-12-31 02:59:16,715 INFO:   Done with stage: BUILD MODEL
2022-12-31 02:59:16,715 INFO:   Starting stage: TRAINING
2022-12-31 02:59:16,762 INFO:     Val loss before train {'Reaction outcome loss': 0.9999483307202657, 'Total loss': 0.9999483307202657}
2022-12-31 02:59:16,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:16,762 INFO:     Epoch: 0
2022-12-31 02:59:18,386 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.537966537475586, 'Total loss': 0.537966537475586} | train loss {'Reaction outcome loss': 0.778755158992881, 'Total loss': 0.778755158992881}
2022-12-31 02:59:18,386 INFO:     Found new best model at epoch 0
2022-12-31 02:59:18,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:18,387 INFO:     Epoch: 1
2022-12-31 02:59:20,011 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.44881820877393086, 'Total loss': 0.44881820877393086} | train loss {'Reaction outcome loss': 0.5080257794056559, 'Total loss': 0.5080257794056559}
2022-12-31 02:59:20,011 INFO:     Found new best model at epoch 1
2022-12-31 02:59:20,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:20,012 INFO:     Epoch: 2
2022-12-31 02:59:21,636 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4162651727596919, 'Total loss': 0.4162651727596919} | train loss {'Reaction outcome loss': 0.44322777751981135, 'Total loss': 0.44322777751981135}
2022-12-31 02:59:21,636 INFO:     Found new best model at epoch 2
2022-12-31 02:59:21,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:21,637 INFO:     Epoch: 3
2022-12-31 02:59:23,287 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4260275741418203, 'Total loss': 0.4260275741418203} | train loss {'Reaction outcome loss': 0.40202310444645933, 'Total loss': 0.40202310444645933}
2022-12-31 02:59:23,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:23,288 INFO:     Epoch: 4
2022-12-31 02:59:24,911 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.433365535736084, 'Total loss': 0.433365535736084} | train loss {'Reaction outcome loss': 0.3754610862542576, 'Total loss': 0.3754610862542576}
2022-12-31 02:59:24,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:24,911 INFO:     Epoch: 5
2022-12-31 02:59:26,583 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3980877925952276, 'Total loss': 0.3980877925952276} | train loss {'Reaction outcome loss': 0.35082022213656117, 'Total loss': 0.35082022213656117}
2022-12-31 02:59:26,583 INFO:     Found new best model at epoch 5
2022-12-31 02:59:26,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:26,584 INFO:     Epoch: 6
2022-12-31 02:59:28,206 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.38010961016019185, 'Total loss': 0.38010961016019185} | train loss {'Reaction outcome loss': 0.3341584115790116, 'Total loss': 0.3341584115790116}
2022-12-31 02:59:28,208 INFO:     Found new best model at epoch 6
2022-12-31 02:59:28,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:28,209 INFO:     Epoch: 7
2022-12-31 02:59:29,875 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3802586714426676, 'Total loss': 0.3802586714426676} | train loss {'Reaction outcome loss': 0.3172510434412784, 'Total loss': 0.3172510434412784}
2022-12-31 02:59:29,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:29,875 INFO:     Epoch: 8
2022-12-31 02:59:31,522 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4052678972482681, 'Total loss': 0.4052678972482681} | train loss {'Reaction outcome loss': 0.3003807695656477, 'Total loss': 0.3003807695656477}
2022-12-31 02:59:31,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:31,523 INFO:     Epoch: 9
2022-12-31 02:59:33,143 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3975468893845876, 'Total loss': 0.3975468893845876} | train loss {'Reaction outcome loss': 0.2882620716057314, 'Total loss': 0.2882620716057314}
2022-12-31 02:59:33,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:33,143 INFO:     Epoch: 10
2022-12-31 02:59:34,773 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3650605817635854, 'Total loss': 0.3650605817635854} | train loss {'Reaction outcome loss': 0.27157849659773414, 'Total loss': 0.27157849659773414}
2022-12-31 02:59:34,774 INFO:     Found new best model at epoch 10
2022-12-31 02:59:34,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:34,775 INFO:     Epoch: 11
2022-12-31 02:59:36,397 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3897116482257843, 'Total loss': 0.3897116482257843} | train loss {'Reaction outcome loss': 0.26299056258819165, 'Total loss': 0.26299056258819165}
2022-12-31 02:59:36,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:36,397 INFO:     Epoch: 12
2022-12-31 02:59:38,020 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.37579464316368105, 'Total loss': 0.37579464316368105} | train loss {'Reaction outcome loss': 0.2539986133010594, 'Total loss': 0.2539986133010594}
2022-12-31 02:59:38,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:38,020 INFO:     Epoch: 13
2022-12-31 02:59:39,642 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3822686791419983, 'Total loss': 0.3822686791419983} | train loss {'Reaction outcome loss': 0.23961926434552197, 'Total loss': 0.23961926434552197}
2022-12-31 02:59:39,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:39,643 INFO:     Epoch: 14
2022-12-31 02:59:41,254 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.38611559830605985, 'Total loss': 0.38611559830605985} | train loss {'Reaction outcome loss': 0.23170263297344804, 'Total loss': 0.23170263297344804}
2022-12-31 02:59:41,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:41,255 INFO:     Epoch: 15
2022-12-31 02:59:42,904 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40293397605419157, 'Total loss': 0.40293397605419157} | train loss {'Reaction outcome loss': 0.22285234133985282, 'Total loss': 0.22285234133985282}
2022-12-31 02:59:42,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:42,904 INFO:     Epoch: 16
2022-12-31 02:59:44,527 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4138465056816737, 'Total loss': 0.4138465056816737} | train loss {'Reaction outcome loss': 0.21574707237822055, 'Total loss': 0.21574707237822055}
2022-12-31 02:59:44,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:44,527 INFO:     Epoch: 17
2022-12-31 02:59:46,147 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3722817634542783, 'Total loss': 0.3722817634542783} | train loss {'Reaction outcome loss': 0.21338506616544423, 'Total loss': 0.21338506616544423}
2022-12-31 02:59:46,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:46,147 INFO:     Epoch: 18
2022-12-31 02:59:47,768 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40265733897686007, 'Total loss': 0.40265733897686007} | train loss {'Reaction outcome loss': 0.2048488364887797, 'Total loss': 0.2048488364887797}
2022-12-31 02:59:47,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:47,769 INFO:     Epoch: 19
2022-12-31 02:59:49,382 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40588622987270356, 'Total loss': 0.40588622987270356} | train loss {'Reaction outcome loss': 0.19962896624519508, 'Total loss': 0.19962896624519508}
2022-12-31 02:59:49,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:49,382 INFO:     Epoch: 20
2022-12-31 02:59:51,002 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4182610755165418, 'Total loss': 0.4182610755165418} | train loss {'Reaction outcome loss': 0.19537110361421905, 'Total loss': 0.19537110361421905}
2022-12-31 02:59:51,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:51,002 INFO:     Epoch: 21
2022-12-31 02:59:52,670 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40544010400772096, 'Total loss': 0.40544010400772096} | train loss {'Reaction outcome loss': 0.1921432693203111, 'Total loss': 0.1921432693203111}
2022-12-31 02:59:52,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:52,670 INFO:     Epoch: 22
2022-12-31 02:59:54,337 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40963828762372334, 'Total loss': 0.40963828762372334} | train loss {'Reaction outcome loss': 0.18848405700405582, 'Total loss': 0.18848405700405582}
2022-12-31 02:59:54,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:54,337 INFO:     Epoch: 23
2022-12-31 02:59:56,006 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4403289337952932, 'Total loss': 0.4403289337952932} | train loss {'Reaction outcome loss': 0.18277441259029756, 'Total loss': 0.18277441259029756}
2022-12-31 02:59:56,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:56,006 INFO:     Epoch: 24
2022-12-31 02:59:57,626 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40325086812178296, 'Total loss': 0.40325086812178296} | train loss {'Reaction outcome loss': 0.181622853038651, 'Total loss': 0.181622853038651}
2022-12-31 02:59:57,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:57,627 INFO:     Epoch: 25
2022-12-31 02:59:59,282 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4088371922572454, 'Total loss': 0.4088371922572454} | train loss {'Reaction outcome loss': 0.17763977183788907, 'Total loss': 0.17763977183788907}
2022-12-31 02:59:59,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 02:59:59,283 INFO:     Epoch: 26
2022-12-31 03:00:00,898 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4158986459175746, 'Total loss': 0.4158986459175746} | train loss {'Reaction outcome loss': 0.1775887549891799, 'Total loss': 0.1775887549891799}
2022-12-31 03:00:00,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:00,899 INFO:     Epoch: 27
2022-12-31 03:00:02,568 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3913358099758625, 'Total loss': 0.3913358099758625} | train loss {'Reaction outcome loss': 0.17482433523411192, 'Total loss': 0.17482433523411192}
2022-12-31 03:00:02,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:02,568 INFO:     Epoch: 28
2022-12-31 03:00:04,234 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40855654838184513, 'Total loss': 0.40855654838184513} | train loss {'Reaction outcome loss': 0.16566653448469695, 'Total loss': 0.16566653448469695}
2022-12-31 03:00:04,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:04,235 INFO:     Epoch: 29
2022-12-31 03:00:05,902 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4347094198067983, 'Total loss': 0.4347094198067983} | train loss {'Reaction outcome loss': 0.16663379195257214, 'Total loss': 0.16663379195257214}
2022-12-31 03:00:05,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:05,903 INFO:     Epoch: 30
2022-12-31 03:00:07,525 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42417358656724297, 'Total loss': 0.42417358656724297} | train loss {'Reaction outcome loss': 0.1673349235408573, 'Total loss': 0.1673349235408573}
2022-12-31 03:00:07,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:07,525 INFO:     Epoch: 31
2022-12-31 03:00:09,144 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4323678652445475, 'Total loss': 0.4323678652445475} | train loss {'Reaction outcome loss': 0.16336007041029552, 'Total loss': 0.16336007041029552}
2022-12-31 03:00:09,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:09,145 INFO:     Epoch: 32
2022-12-31 03:00:10,779 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41301350394884745, 'Total loss': 0.41301350394884745} | train loss {'Reaction outcome loss': 0.15980242376992418, 'Total loss': 0.15980242376992418}
2022-12-31 03:00:10,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:10,779 INFO:     Epoch: 33
2022-12-31 03:00:12,413 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39497947692871094, 'Total loss': 0.39497947692871094} | train loss {'Reaction outcome loss': 0.16174115625542962, 'Total loss': 0.16174115625542962}
2022-12-31 03:00:12,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:12,414 INFO:     Epoch: 34
2022-12-31 03:00:14,049 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3831444298227628, 'Total loss': 0.3831444298227628} | train loss {'Reaction outcome loss': 0.1618523955486365, 'Total loss': 0.1618523955486365}
2022-12-31 03:00:14,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:14,049 INFO:     Epoch: 35
2022-12-31 03:00:15,690 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43337226162354153, 'Total loss': 0.43337226162354153} | train loss {'Reaction outcome loss': 0.15532078429222754, 'Total loss': 0.15532078429222754}
2022-12-31 03:00:15,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:15,690 INFO:     Epoch: 36
2022-12-31 03:00:17,315 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43042439421017964, 'Total loss': 0.43042439421017964} | train loss {'Reaction outcome loss': 0.1523907128149906, 'Total loss': 0.1523907128149906}
2022-12-31 03:00:17,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:17,315 INFO:     Epoch: 37
2022-12-31 03:00:18,953 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3951563222333789, 'Total loss': 0.3951563222333789} | train loss {'Reaction outcome loss': 0.15626464198454407, 'Total loss': 0.15626464198454407}
2022-12-31 03:00:18,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:18,954 INFO:     Epoch: 38
2022-12-31 03:00:20,581 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4222480257352193, 'Total loss': 0.4222480257352193} | train loss {'Reaction outcome loss': 0.15206480752474996, 'Total loss': 0.15206480752474996}
2022-12-31 03:00:20,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:20,582 INFO:     Epoch: 39
2022-12-31 03:00:22,213 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43343210220336914, 'Total loss': 0.43343210220336914} | train loss {'Reaction outcome loss': 0.15198071499687993, 'Total loss': 0.15198071499687993}
2022-12-31 03:00:22,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:22,213 INFO:     Epoch: 40
2022-12-31 03:00:23,843 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4269510179758072, 'Total loss': 0.4269510179758072} | train loss {'Reaction outcome loss': 0.14688312768472178, 'Total loss': 0.14688312768472178}
2022-12-31 03:00:23,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:23,844 INFO:     Epoch: 41
2022-12-31 03:00:25,474 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4199755648771922, 'Total loss': 0.4199755648771922} | train loss {'Reaction outcome loss': 0.14940530162587062, 'Total loss': 0.14940530162587062}
2022-12-31 03:00:25,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:25,474 INFO:     Epoch: 42
2022-12-31 03:00:27,129 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40321010823051134, 'Total loss': 0.40321010823051134} | train loss {'Reaction outcome loss': 0.1479996252966379, 'Total loss': 0.1479996252966379}
2022-12-31 03:00:27,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:27,129 INFO:     Epoch: 43
2022-12-31 03:00:28,754 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4015495806932449, 'Total loss': 0.4015495806932449} | train loss {'Reaction outcome loss': 0.14644201712460939, 'Total loss': 0.14644201712460939}
2022-12-31 03:00:28,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:28,754 INFO:     Epoch: 44
2022-12-31 03:00:30,378 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4358720372120539, 'Total loss': 0.4358720372120539} | train loss {'Reaction outcome loss': 0.14305764318037012, 'Total loss': 0.14305764318037012}
2022-12-31 03:00:30,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:30,379 INFO:     Epoch: 45
2022-12-31 03:00:32,006 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4342911978562673, 'Total loss': 0.4342911978562673} | train loss {'Reaction outcome loss': 0.1453697154977584, 'Total loss': 0.1453697154977584}
2022-12-31 03:00:32,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:32,006 INFO:     Epoch: 46
2022-12-31 03:00:33,629 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4266613920529683, 'Total loss': 0.4266613920529683} | train loss {'Reaction outcome loss': 0.1392497795008607, 'Total loss': 0.1392497795008607}
2022-12-31 03:00:33,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:33,630 INFO:     Epoch: 47
2022-12-31 03:00:35,246 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41733162601788837, 'Total loss': 0.41733162601788837} | train loss {'Reaction outcome loss': 0.1421283097073624, 'Total loss': 0.1421283097073624}
2022-12-31 03:00:35,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:35,247 INFO:     Epoch: 48
2022-12-31 03:00:36,868 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45684954623381296, 'Total loss': 0.45684954623381296} | train loss {'Reaction outcome loss': 0.14193020612783125, 'Total loss': 0.14193020612783125}
2022-12-31 03:00:36,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:36,869 INFO:     Epoch: 49
2022-12-31 03:00:38,492 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42312499781449636, 'Total loss': 0.42312499781449636} | train loss {'Reaction outcome loss': 0.13548406289843337, 'Total loss': 0.13548406289843337}
2022-12-31 03:00:38,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:38,493 INFO:     Epoch: 50
2022-12-31 03:00:40,161 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40234256414696573, 'Total loss': 0.40234256414696573} | train loss {'Reaction outcome loss': 0.13227043471329372, 'Total loss': 0.13227043471329372}
2022-12-31 03:00:40,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:40,162 INFO:     Epoch: 51
2022-12-31 03:00:41,831 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4079873283704122, 'Total loss': 0.4079873283704122} | train loss {'Reaction outcome loss': 0.13753194969133994, 'Total loss': 0.13753194969133994}
2022-12-31 03:00:41,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:41,832 INFO:     Epoch: 52
2022-12-31 03:00:43,500 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4292162815729777, 'Total loss': 0.4292162815729777} | train loss {'Reaction outcome loss': 0.14005196606320083, 'Total loss': 0.14005196606320083}
2022-12-31 03:00:43,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:43,501 INFO:     Epoch: 53
2022-12-31 03:00:45,135 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4162679731845856, 'Total loss': 0.4162679731845856} | train loss {'Reaction outcome loss': 0.13571251480292112, 'Total loss': 0.13571251480292112}
2022-12-31 03:00:45,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:45,135 INFO:     Epoch: 54
2022-12-31 03:00:46,762 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41465292076269783, 'Total loss': 0.41465292076269783} | train loss {'Reaction outcome loss': 0.1356080183187762, 'Total loss': 0.1356080183187762}
2022-12-31 03:00:46,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:46,762 INFO:     Epoch: 55
2022-12-31 03:00:48,396 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40081923206647235, 'Total loss': 0.40081923206647235} | train loss {'Reaction outcome loss': 0.1333269980796596, 'Total loss': 0.1333269980796596}
2022-12-31 03:00:48,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:48,396 INFO:     Epoch: 56
2022-12-31 03:00:50,029 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4130106290181478, 'Total loss': 0.4130106290181478} | train loss {'Reaction outcome loss': 0.1302615999805637, 'Total loss': 0.1302615999805637}
2022-12-31 03:00:50,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:50,030 INFO:     Epoch: 57
2022-12-31 03:00:51,665 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41789301435152687, 'Total loss': 0.41789301435152687} | train loss {'Reaction outcome loss': 0.12842853622853972, 'Total loss': 0.12842853622853972}
2022-12-31 03:00:51,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:51,665 INFO:     Epoch: 58
2022-12-31 03:00:53,290 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4046179602543513, 'Total loss': 0.4046179602543513} | train loss {'Reaction outcome loss': 0.13027459747974998, 'Total loss': 0.13027459747974998}
2022-12-31 03:00:53,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:53,290 INFO:     Epoch: 59
2022-12-31 03:00:54,904 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4110625634590785, 'Total loss': 0.4110625634590785} | train loss {'Reaction outcome loss': 0.1315750020156053, 'Total loss': 0.1315750020156053}
2022-12-31 03:00:54,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:54,904 INFO:     Epoch: 60
2022-12-31 03:00:56,574 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41244120597839357, 'Total loss': 0.41244120597839357} | train loss {'Reaction outcome loss': 0.12915777113954352, 'Total loss': 0.12915777113954352}
2022-12-31 03:00:56,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:56,574 INFO:     Epoch: 61
2022-12-31 03:00:58,196 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40096142888069153, 'Total loss': 0.40096142888069153} | train loss {'Reaction outcome loss': 0.12585744975531468, 'Total loss': 0.12585744975531468}
2022-12-31 03:00:58,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:58,196 INFO:     Epoch: 62
2022-12-31 03:00:59,866 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3952920620640119, 'Total loss': 0.3952920620640119} | train loss {'Reaction outcome loss': 0.12352231030254911, 'Total loss': 0.12352231030254911}
2022-12-31 03:00:59,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:00:59,867 INFO:     Epoch: 63
2022-12-31 03:01:01,488 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4299765785535177, 'Total loss': 0.4299765785535177} | train loss {'Reaction outcome loss': 0.12313765351953058, 'Total loss': 0.12313765351953058}
2022-12-31 03:01:01,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:01,488 INFO:     Epoch: 64
2022-12-31 03:01:03,146 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41452971200148264, 'Total loss': 0.41452971200148264} | train loss {'Reaction outcome loss': 0.1293840126070574, 'Total loss': 0.1293840126070574}
2022-12-31 03:01:03,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:03,146 INFO:     Epoch: 65
2022-12-31 03:01:04,762 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42448183298110964, 'Total loss': 0.42448183298110964} | train loss {'Reaction outcome loss': 0.12870205611844518, 'Total loss': 0.12870205611844518}
2022-12-31 03:01:04,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:04,762 INFO:     Epoch: 66
2022-12-31 03:01:06,385 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44395567377408346, 'Total loss': 0.44395567377408346} | train loss {'Reaction outcome loss': 0.1251544404769861, 'Total loss': 0.1251544404769861}
2022-12-31 03:01:06,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:06,387 INFO:     Epoch: 67
2022-12-31 03:01:08,008 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43721953431765237, 'Total loss': 0.43721953431765237} | train loss {'Reaction outcome loss': 0.1255773070481831, 'Total loss': 0.1255773070481831}
2022-12-31 03:01:08,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:08,008 INFO:     Epoch: 68
2022-12-31 03:01:09,678 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4021904498338699, 'Total loss': 0.4021904498338699} | train loss {'Reaction outcome loss': 0.12309441055315765, 'Total loss': 0.12309441055315765}
2022-12-31 03:01:09,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:09,678 INFO:     Epoch: 69
2022-12-31 03:01:11,302 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42835062444210054, 'Total loss': 0.42835062444210054} | train loss {'Reaction outcome loss': 0.11976724355700107, 'Total loss': 0.11976724355700107}
2022-12-31 03:01:11,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:11,302 INFO:     Epoch: 70
2022-12-31 03:01:12,926 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4213263382514318, 'Total loss': 0.4213263382514318} | train loss {'Reaction outcome loss': 0.12268203745565852, 'Total loss': 0.12268203745565852}
2022-12-31 03:01:12,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:12,927 INFO:     Epoch: 71
2022-12-31 03:01:14,592 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4260405212640762, 'Total loss': 0.4260405212640762} | train loss {'Reaction outcome loss': 0.11787976356835142, 'Total loss': 0.11787976356835142}
2022-12-31 03:01:14,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:14,593 INFO:     Epoch: 72
2022-12-31 03:01:16,262 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41293599208196, 'Total loss': 0.41293599208196} | train loss {'Reaction outcome loss': 0.12005992585184584, 'Total loss': 0.12005992585184584}
2022-12-31 03:01:16,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:16,263 INFO:     Epoch: 73
2022-12-31 03:01:17,879 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4036324014266332, 'Total loss': 0.4036324014266332} | train loss {'Reaction outcome loss': 0.12338252951448199, 'Total loss': 0.12338252951448199}
2022-12-31 03:01:17,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:17,880 INFO:     Epoch: 74
2022-12-31 03:01:19,497 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4190451081842184, 'Total loss': 0.4190451081842184} | train loss {'Reaction outcome loss': 0.12346171582830458, 'Total loss': 0.12346171582830458}
2022-12-31 03:01:19,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:19,497 INFO:     Epoch: 75
2022-12-31 03:01:21,110 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42550721367200217, 'Total loss': 0.42550721367200217} | train loss {'Reaction outcome loss': 0.11882812971928382, 'Total loss': 0.11882812971928382}
2022-12-31 03:01:21,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:21,110 INFO:     Epoch: 76
2022-12-31 03:01:22,762 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42561392337083814, 'Total loss': 0.42561392337083814} | train loss {'Reaction outcome loss': 0.11996679662874755, 'Total loss': 0.11996679662874755}
2022-12-31 03:01:22,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:22,762 INFO:     Epoch: 77
2022-12-31 03:01:24,428 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42181732356548307, 'Total loss': 0.42181732356548307} | train loss {'Reaction outcome loss': 0.11812149195609083, 'Total loss': 0.11812149195609083}
2022-12-31 03:01:24,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:24,428 INFO:     Epoch: 78
2022-12-31 03:01:26,094 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43778683443864186, 'Total loss': 0.43778683443864186} | train loss {'Reaction outcome loss': 0.11398885144334327, 'Total loss': 0.11398885144334327}
2022-12-31 03:01:26,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:26,095 INFO:     Epoch: 79
2022-12-31 03:01:27,712 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4185932159423828, 'Total loss': 0.4185932159423828} | train loss {'Reaction outcome loss': 0.12020871462972856, 'Total loss': 0.12020871462972856}
2022-12-31 03:01:27,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:27,712 INFO:     Epoch: 80
2022-12-31 03:01:29,378 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.39147641708453496, 'Total loss': 0.39147641708453496} | train loss {'Reaction outcome loss': 0.11535897666911195, 'Total loss': 0.11535897666911195}
2022-12-31 03:01:29,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:29,379 INFO:     Epoch: 81
2022-12-31 03:01:31,003 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3994984060525894, 'Total loss': 0.3994984060525894} | train loss {'Reaction outcome loss': 0.11794049285994405, 'Total loss': 0.11794049285994405}
2022-12-31 03:01:31,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:31,003 INFO:     Epoch: 82
2022-12-31 03:01:32,634 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4152084251244863, 'Total loss': 0.4152084251244863} | train loss {'Reaction outcome loss': 0.12038659336657301, 'Total loss': 0.12038659336657301}
2022-12-31 03:01:32,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:32,634 INFO:     Epoch: 83
2022-12-31 03:01:34,269 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4462854966521263, 'Total loss': 0.4462854966521263} | train loss {'Reaction outcome loss': 0.11724720584205099, 'Total loss': 0.11724720584205099}
2022-12-31 03:01:34,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:34,270 INFO:     Epoch: 84
2022-12-31 03:01:35,905 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40345621580878893, 'Total loss': 0.40345621580878893} | train loss {'Reaction outcome loss': 0.11590067578129981, 'Total loss': 0.11590067578129981}
2022-12-31 03:01:35,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:35,906 INFO:     Epoch: 85
2022-12-31 03:01:37,521 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4257729013760885, 'Total loss': 0.4257729013760885} | train loss {'Reaction outcome loss': 0.11862306377853835, 'Total loss': 0.11862306377853835}
2022-12-31 03:01:37,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:37,521 INFO:     Epoch: 86
2022-12-31 03:01:39,136 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40402789115905763, 'Total loss': 0.40402789115905763} | train loss {'Reaction outcome loss': 0.1165800469184449, 'Total loss': 0.1165800469184449}
2022-12-31 03:01:39,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:39,136 INFO:     Epoch: 87
2022-12-31 03:01:40,766 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39670076221227646, 'Total loss': 0.39670076221227646} | train loss {'Reaction outcome loss': 0.11430573913130895, 'Total loss': 0.11430573913130895}
2022-12-31 03:01:40,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:40,768 INFO:     Epoch: 88
2022-12-31 03:01:42,389 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4335260450839996, 'Total loss': 0.4335260450839996} | train loss {'Reaction outcome loss': 0.11302406369584078, 'Total loss': 0.11302406369584078}
2022-12-31 03:01:42,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:42,390 INFO:     Epoch: 89
2022-12-31 03:01:44,054 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4080357680718104, 'Total loss': 0.4080357680718104} | train loss {'Reaction outcome loss': 0.11942122021306723, 'Total loss': 0.11942122021306723}
2022-12-31 03:01:44,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:44,055 INFO:     Epoch: 90
2022-12-31 03:01:45,720 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.390711040298144, 'Total loss': 0.390711040298144} | train loss {'Reaction outcome loss': 0.11267535166061796, 'Total loss': 0.11267535166061796}
2022-12-31 03:01:45,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:45,720 INFO:     Epoch: 91
2022-12-31 03:01:47,386 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39252566993236543, 'Total loss': 0.39252566993236543} | train loss {'Reaction outcome loss': 0.11183110218400989, 'Total loss': 0.11183110218400989}
2022-12-31 03:01:47,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:47,387 INFO:     Epoch: 92
2022-12-31 03:01:49,005 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4271555622418722, 'Total loss': 0.4271555622418722} | train loss {'Reaction outcome loss': 0.11388221489843856, 'Total loss': 0.11388221489843856}
2022-12-31 03:01:49,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:49,006 INFO:     Epoch: 93
2022-12-31 03:01:50,622 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38989714284737903, 'Total loss': 0.38989714284737903} | train loss {'Reaction outcome loss': 0.11216907247073868, 'Total loss': 0.11216907247073868}
2022-12-31 03:01:50,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:50,623 INFO:     Epoch: 94
2022-12-31 03:01:52,287 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40101924079159895, 'Total loss': 0.40101924079159895} | train loss {'Reaction outcome loss': 0.11113186630450646, 'Total loss': 0.11113186630450646}
2022-12-31 03:01:52,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:52,288 INFO:     Epoch: 95
2022-12-31 03:01:53,908 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4441831037402153, 'Total loss': 0.4441831037402153} | train loss {'Reaction outcome loss': 0.11576748225965709, 'Total loss': 0.11576748225965709}
2022-12-31 03:01:53,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:53,909 INFO:     Epoch: 96
2022-12-31 03:01:55,573 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4159619490305583, 'Total loss': 0.4159619490305583} | train loss {'Reaction outcome loss': 0.11652056234619758, 'Total loss': 0.11652056234619758}
2022-12-31 03:01:55,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:55,574 INFO:     Epoch: 97
2022-12-31 03:01:57,193 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42537589023510614, 'Total loss': 0.42537589023510614} | train loss {'Reaction outcome loss': 0.10918291877208795, 'Total loss': 0.10918291877208795}
2022-12-31 03:01:57,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:57,194 INFO:     Epoch: 98
2022-12-31 03:01:58,809 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42436403334140776, 'Total loss': 0.42436403334140776} | train loss {'Reaction outcome loss': 0.10739029622687168, 'Total loss': 0.10739029622687168}
2022-12-31 03:01:58,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:01:58,809 INFO:     Epoch: 99
2022-12-31 03:02:00,444 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4202816625436147, 'Total loss': 0.4202816625436147} | train loss {'Reaction outcome loss': 0.10719211860593503, 'Total loss': 0.10719211860593503}
2022-12-31 03:02:00,445 INFO:     Best model found after epoch 11 of 100.
2022-12-31 03:02:00,445 INFO:   Done with stage: TRAINING
2022-12-31 03:02:00,445 INFO:   Starting stage: EVALUATION
2022-12-31 03:02:00,570 INFO:   Done with stage: EVALUATION
2022-12-31 03:02:00,570 INFO:   Leaving out SEQ value Fold_7
2022-12-31 03:02:00,583 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 03:02:00,583 INFO:   Starting stage: FEATURE SCALING
2022-12-31 03:02:01,238 INFO:   Done with stage: FEATURE SCALING
2022-12-31 03:02:01,239 INFO:   Starting stage: SCALING TARGETS
2022-12-31 03:02:01,310 INFO:   Done with stage: SCALING TARGETS
2022-12-31 03:02:01,311 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:02:01,311 INFO:     No hyperparam tuning for this model
2022-12-31 03:02:01,311 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:02:01,311 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 03:02:01,311 INFO:     None feature selector for col prot
2022-12-31 03:02:01,312 INFO:     None feature selector for col prot
2022-12-31 03:02:01,312 INFO:     None feature selector for col prot
2022-12-31 03:02:01,312 INFO:     None feature selector for col chem
2022-12-31 03:02:01,312 INFO:     None feature selector for col chem
2022-12-31 03:02:01,312 INFO:     None feature selector for col chem
2022-12-31 03:02:01,312 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 03:02:01,313 INFO:   Starting stage: BUILD MODEL
2022-12-31 03:02:01,314 INFO:     Number of params in model 224011
2022-12-31 03:02:01,318 INFO:   Done with stage: BUILD MODEL
2022-12-31 03:02:01,318 INFO:   Starting stage: TRAINING
2022-12-31 03:02:01,363 INFO:     Val loss before train {'Reaction outcome loss': 0.9597089846928915, 'Total loss': 0.9597089846928915}
2022-12-31 03:02:01,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:01,363 INFO:     Epoch: 0
2022-12-31 03:02:02,979 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5558143774668376, 'Total loss': 0.5558143774668376} | train loss {'Reaction outcome loss': 0.7840987696595814, 'Total loss': 0.7840987696595814}
2022-12-31 03:02:02,979 INFO:     Found new best model at epoch 0
2022-12-31 03:02:02,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:02,980 INFO:     Epoch: 1
2022-12-31 03:02:04,593 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5059900283813477, 'Total loss': 0.5059900283813477} | train loss {'Reaction outcome loss': 0.5171765314037169, 'Total loss': 0.5171765314037169}
2022-12-31 03:02:04,593 INFO:     Found new best model at epoch 1
2022-12-31 03:02:04,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:04,594 INFO:     Epoch: 2
2022-12-31 03:02:06,211 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4968424657980601, 'Total loss': 0.4968424657980601} | train loss {'Reaction outcome loss': 0.45102898436396016, 'Total loss': 0.45102898436396016}
2022-12-31 03:02:06,211 INFO:     Found new best model at epoch 2
2022-12-31 03:02:06,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:06,212 INFO:     Epoch: 3
2022-12-31 03:02:07,815 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4675390024979909, 'Total loss': 0.4675390024979909} | train loss {'Reaction outcome loss': 0.41010915776174783, 'Total loss': 0.41010915776174783}
2022-12-31 03:02:07,815 INFO:     Found new best model at epoch 3
2022-12-31 03:02:07,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:07,816 INFO:     Epoch: 4
2022-12-31 03:02:09,442 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4390705684820811, 'Total loss': 0.4390705684820811} | train loss {'Reaction outcome loss': 0.37973201289560826, 'Total loss': 0.37973201289560826}
2022-12-31 03:02:09,442 INFO:     Found new best model at epoch 4
2022-12-31 03:02:09,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:09,443 INFO:     Epoch: 5
2022-12-31 03:02:11,072 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4486333707968394, 'Total loss': 0.4486333707968394} | train loss {'Reaction outcome loss': 0.35488985607103596, 'Total loss': 0.35488985607103596}
2022-12-31 03:02:11,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:11,072 INFO:     Epoch: 6
2022-12-31 03:02:12,700 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42306353723009427, 'Total loss': 0.42306353723009427} | train loss {'Reaction outcome loss': 0.336048719689142, 'Total loss': 0.336048719689142}
2022-12-31 03:02:12,701 INFO:     Found new best model at epoch 6
2022-12-31 03:02:12,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:12,702 INFO:     Epoch: 7
2022-12-31 03:02:14,329 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4571602682272593, 'Total loss': 0.4571602682272593} | train loss {'Reaction outcome loss': 0.32431491307806276, 'Total loss': 0.32431491307806276}
2022-12-31 03:02:14,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:14,329 INFO:     Epoch: 8
2022-12-31 03:02:15,948 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44178157647450766, 'Total loss': 0.44178157647450766} | train loss {'Reaction outcome loss': 0.31949428079257114, 'Total loss': 0.31949428079257114}
2022-12-31 03:02:15,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:15,948 INFO:     Epoch: 9
2022-12-31 03:02:17,572 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45105773011843364, 'Total loss': 0.45105773011843364} | train loss {'Reaction outcome loss': 0.2907201184256785, 'Total loss': 0.2907201184256785}
2022-12-31 03:02:17,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:17,573 INFO:     Epoch: 10
2022-12-31 03:02:19,202 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42849560678005216, 'Total loss': 0.42849560678005216} | train loss {'Reaction outcome loss': 0.2822085863917364, 'Total loss': 0.2822085863917364}
2022-12-31 03:02:19,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:19,202 INFO:     Epoch: 11
2022-12-31 03:02:20,832 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45167453090349835, 'Total loss': 0.45167453090349835} | train loss {'Reaction outcome loss': 0.26473020102180866, 'Total loss': 0.26473020102180866}
2022-12-31 03:02:20,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:20,832 INFO:     Epoch: 12
2022-12-31 03:02:22,462 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.413093567887942, 'Total loss': 0.413093567887942} | train loss {'Reaction outcome loss': 0.26289496078844304, 'Total loss': 0.26289496078844304}
2022-12-31 03:02:22,462 INFO:     Found new best model at epoch 12
2022-12-31 03:02:22,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:22,463 INFO:     Epoch: 13
2022-12-31 03:02:24,082 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45830563406149544, 'Total loss': 0.45830563406149544} | train loss {'Reaction outcome loss': 0.2424074327353847, 'Total loss': 0.2424074327353847}
2022-12-31 03:02:24,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:24,083 INFO:     Epoch: 14
2022-12-31 03:02:25,734 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4034464155634244, 'Total loss': 0.4034464155634244} | train loss {'Reaction outcome loss': 0.23302254089179295, 'Total loss': 0.23302254089179295}
2022-12-31 03:02:25,734 INFO:     Found new best model at epoch 14
2022-12-31 03:02:25,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:25,735 INFO:     Epoch: 15
2022-12-31 03:02:27,351 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.452174840370814, 'Total loss': 0.452174840370814} | train loss {'Reaction outcome loss': 0.22702732694375774, 'Total loss': 0.22702732694375774}
2022-12-31 03:02:27,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:27,352 INFO:     Epoch: 16
2022-12-31 03:02:29,017 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.438519142071406, 'Total loss': 0.438519142071406} | train loss {'Reaction outcome loss': 0.23264215038279476, 'Total loss': 0.23264215038279476}
2022-12-31 03:02:29,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:29,017 INFO:     Epoch: 17
2022-12-31 03:02:30,635 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40629418989022575, 'Total loss': 0.40629418989022575} | train loss {'Reaction outcome loss': 0.21696339595043843, 'Total loss': 0.21696339595043843}
2022-12-31 03:02:30,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:30,636 INFO:     Epoch: 18
2022-12-31 03:02:32,301 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4144351025422414, 'Total loss': 0.4144351025422414} | train loss {'Reaction outcome loss': 0.20843001770486624, 'Total loss': 0.20843001770486624}
2022-12-31 03:02:32,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:32,302 INFO:     Epoch: 19
2022-12-31 03:02:33,928 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4023869037628174, 'Total loss': 0.4023869037628174} | train loss {'Reaction outcome loss': 0.20383179653604663, 'Total loss': 0.20383179653604663}
2022-12-31 03:02:33,928 INFO:     Found new best model at epoch 19
2022-12-31 03:02:33,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:33,929 INFO:     Epoch: 20
2022-12-31 03:02:35,556 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4009975870450338, 'Total loss': 0.4009975870450338} | train loss {'Reaction outcome loss': 0.20267614423283847, 'Total loss': 0.20267614423283847}
2022-12-31 03:02:35,556 INFO:     Found new best model at epoch 20
2022-12-31 03:02:35,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:35,557 INFO:     Epoch: 21
2022-12-31 03:02:37,175 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4318607012430827, 'Total loss': 0.4318607012430827} | train loss {'Reaction outcome loss': 0.19921909077379826, 'Total loss': 0.19921909077379826}
2022-12-31 03:02:37,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:37,176 INFO:     Epoch: 22
2022-12-31 03:02:38,795 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43922516504923503, 'Total loss': 0.43922516504923503} | train loss {'Reaction outcome loss': 0.18882269087117637, 'Total loss': 0.18882269087117637}
2022-12-31 03:02:38,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:38,795 INFO:     Epoch: 23
2022-12-31 03:02:40,452 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41558554967244465, 'Total loss': 0.41558554967244465} | train loss {'Reaction outcome loss': 0.1877669677993728, 'Total loss': 0.1877669677993728}
2022-12-31 03:02:40,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:40,452 INFO:     Epoch: 24
2022-12-31 03:02:42,071 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.398447730143865, 'Total loss': 0.398447730143865} | train loss {'Reaction outcome loss': 0.18238301522628256, 'Total loss': 0.18238301522628256}
2022-12-31 03:02:42,071 INFO:     Found new best model at epoch 24
2022-12-31 03:02:42,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:42,072 INFO:     Epoch: 25
2022-12-31 03:02:43,681 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4400402287642161, 'Total loss': 0.4400402287642161} | train loss {'Reaction outcome loss': 0.17988717693673528, 'Total loss': 0.17988717693673528}
2022-12-31 03:02:43,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:43,681 INFO:     Epoch: 26
2022-12-31 03:02:45,330 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40423333446184795, 'Total loss': 0.40423333446184795} | train loss {'Reaction outcome loss': 0.17480209792679027, 'Total loss': 0.17480209792679027}
2022-12-31 03:02:45,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:45,330 INFO:     Epoch: 27
2022-12-31 03:02:46,949 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40316878706216813, 'Total loss': 0.40316878706216813} | train loss {'Reaction outcome loss': 0.17207217626623722, 'Total loss': 0.17207217626623722}
2022-12-31 03:02:46,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:46,949 INFO:     Epoch: 28
2022-12-31 03:02:48,614 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4407375027736028, 'Total loss': 0.4407375027736028} | train loss {'Reaction outcome loss': 0.16857823385865797, 'Total loss': 0.16857823385865797}
2022-12-31 03:02:48,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:48,615 INFO:     Epoch: 29
2022-12-31 03:02:50,282 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38173140039046605, 'Total loss': 0.38173140039046605} | train loss {'Reaction outcome loss': 0.1674359854453713, 'Total loss': 0.1674359854453713}
2022-12-31 03:02:50,282 INFO:     Found new best model at epoch 29
2022-12-31 03:02:50,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:50,283 INFO:     Epoch: 30
2022-12-31 03:02:51,897 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44420996606349944, 'Total loss': 0.44420996606349944} | train loss {'Reaction outcome loss': 0.16974168548309218, 'Total loss': 0.16974168548309218}
2022-12-31 03:02:51,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:51,897 INFO:     Epoch: 31
2022-12-31 03:02:53,542 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4039111872514089, 'Total loss': 0.4039111872514089} | train loss {'Reaction outcome loss': 0.15939871617729953, 'Total loss': 0.15939871617729953}
2022-12-31 03:02:53,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:53,543 INFO:     Epoch: 32
2022-12-31 03:02:55,169 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39984858632087705, 'Total loss': 0.39984858632087705} | train loss {'Reaction outcome loss': 0.16254007720187696, 'Total loss': 0.16254007720187696}
2022-12-31 03:02:55,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:55,170 INFO:     Epoch: 33
2022-12-31 03:02:56,794 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42387088934580486, 'Total loss': 0.42387088934580486} | train loss {'Reaction outcome loss': 0.15484160341018163, 'Total loss': 0.15484160341018163}
2022-12-31 03:02:56,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:56,795 INFO:     Epoch: 34
2022-12-31 03:02:58,425 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4209019402662913, 'Total loss': 0.4209019402662913} | train loss {'Reaction outcome loss': 0.1586440068743853, 'Total loss': 0.1586440068743853}
2022-12-31 03:02:58,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:02:58,425 INFO:     Epoch: 35
2022-12-31 03:03:00,056 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44289169609546664, 'Total loss': 0.44289169609546664} | train loss {'Reaction outcome loss': 0.16081314636381727, 'Total loss': 0.16081314636381727}
2022-12-31 03:03:00,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:00,057 INFO:     Epoch: 36
2022-12-31 03:03:01,703 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4083561917146047, 'Total loss': 0.4083561917146047} | train loss {'Reaction outcome loss': 0.1518719683517702, 'Total loss': 0.1518719683517702}
2022-12-31 03:03:01,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:01,703 INFO:     Epoch: 37
2022-12-31 03:03:03,354 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42568028966585797, 'Total loss': 0.42568028966585797} | train loss {'Reaction outcome loss': 0.16156730606166672, 'Total loss': 0.16156730606166672}
2022-12-31 03:03:03,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:03,354 INFO:     Epoch: 38
2022-12-31 03:03:04,975 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4406596541404724, 'Total loss': 0.4406596541404724} | train loss {'Reaction outcome loss': 0.1724511892869081, 'Total loss': 0.1724511892869081}
2022-12-31 03:03:04,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:04,975 INFO:     Epoch: 39
2022-12-31 03:03:06,637 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4668993681669235, 'Total loss': 0.4668993681669235} | train loss {'Reaction outcome loss': 0.15221744398392426, 'Total loss': 0.15221744398392426}
2022-12-31 03:03:06,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:06,638 INFO:     Epoch: 40
2022-12-31 03:03:08,255 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4474022368590037, 'Total loss': 0.4474022368590037} | train loss {'Reaction outcome loss': 0.14319608994739372, 'Total loss': 0.14319608994739372}
2022-12-31 03:03:08,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:08,256 INFO:     Epoch: 41
2022-12-31 03:03:09,867 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4363146487623453, 'Total loss': 0.4363146487623453} | train loss {'Reaction outcome loss': 0.14191461852043058, 'Total loss': 0.14191461852043058}
2022-12-31 03:03:09,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:09,867 INFO:     Epoch: 42
2022-12-31 03:03:11,519 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4265766719977061, 'Total loss': 0.4265766719977061} | train loss {'Reaction outcome loss': 0.1463118324094651, 'Total loss': 0.1463118324094651}
2022-12-31 03:03:11,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:11,519 INFO:     Epoch: 43
2022-12-31 03:03:13,147 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4428973853588104, 'Total loss': 0.4428973853588104} | train loss {'Reaction outcome loss': 0.13757548942500591, 'Total loss': 0.13757548942500591}
2022-12-31 03:03:13,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:13,148 INFO:     Epoch: 44
2022-12-31 03:03:14,776 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45005153119564056, 'Total loss': 0.45005153119564056} | train loss {'Reaction outcome loss': 0.1410508855238415, 'Total loss': 0.1410508855238415}
2022-12-31 03:03:14,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:14,776 INFO:     Epoch: 45
2022-12-31 03:03:16,406 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43645978172620137, 'Total loss': 0.43645978172620137} | train loss {'Reaction outcome loss': 0.1389395789204476, 'Total loss': 0.1389395789204476}
2022-12-31 03:03:16,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:16,407 INFO:     Epoch: 46
2022-12-31 03:03:18,036 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41245943382382394, 'Total loss': 0.41245943382382394} | train loss {'Reaction outcome loss': 0.13572385203282256, 'Total loss': 0.13572385203282256}
2022-12-31 03:03:18,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:18,036 INFO:     Epoch: 47
2022-12-31 03:03:19,657 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4224803904692332, 'Total loss': 0.4224803904692332} | train loss {'Reaction outcome loss': 0.13815033176688038, 'Total loss': 0.13815033176688038}
2022-12-31 03:03:19,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:19,657 INFO:     Epoch: 48
2022-12-31 03:03:21,276 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43546753029028573, 'Total loss': 0.43546753029028573} | train loss {'Reaction outcome loss': 0.1392379948477922, 'Total loss': 0.1392379948477922}
2022-12-31 03:03:21,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:21,276 INFO:     Epoch: 49
2022-12-31 03:03:22,901 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4138876276711623, 'Total loss': 0.4138876276711623} | train loss {'Reaction outcome loss': 0.14381161316882557, 'Total loss': 0.14381161316882557}
2022-12-31 03:03:22,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:22,902 INFO:     Epoch: 50
2022-12-31 03:03:24,527 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4207330495119095, 'Total loss': 0.4207330495119095} | train loss {'Reaction outcome loss': 0.13357950528613097, 'Total loss': 0.13357950528613097}
2022-12-31 03:03:24,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:24,527 INFO:     Epoch: 51
2022-12-31 03:03:26,152 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4336132417122523, 'Total loss': 0.4336132417122523} | train loss {'Reaction outcome loss': 0.14821677512921178, 'Total loss': 0.14821677512921178}
2022-12-31 03:03:26,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:26,152 INFO:     Epoch: 52
2022-12-31 03:03:27,773 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3983728965123495, 'Total loss': 0.3983728965123495} | train loss {'Reaction outcome loss': 0.16385133347501032, 'Total loss': 0.16385133347501032}
2022-12-31 03:03:27,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:27,773 INFO:     Epoch: 53
2022-12-31 03:03:29,393 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43905434509118396, 'Total loss': 0.43905434509118396} | train loss {'Reaction outcome loss': 0.1324735556831845, 'Total loss': 0.1324735556831845}
2022-12-31 03:03:29,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:29,394 INFO:     Epoch: 54
2022-12-31 03:03:31,041 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4276902489364147, 'Total loss': 0.4276902489364147} | train loss {'Reaction outcome loss': 0.1277857942037319, 'Total loss': 0.1277857942037319}
2022-12-31 03:03:31,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:31,041 INFO:     Epoch: 55
2022-12-31 03:03:32,661 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4141397297382355, 'Total loss': 0.4141397297382355} | train loss {'Reaction outcome loss': 0.1268427299337286, 'Total loss': 0.1268427299337286}
2022-12-31 03:03:32,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:32,661 INFO:     Epoch: 56
2022-12-31 03:03:34,325 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4428327520688375, 'Total loss': 0.4428327520688375} | train loss {'Reaction outcome loss': 0.1271508781169491, 'Total loss': 0.1271508781169491}
2022-12-31 03:03:34,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:34,325 INFO:     Epoch: 57
2022-12-31 03:03:35,947 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4218412160873413, 'Total loss': 0.4218412160873413} | train loss {'Reaction outcome loss': 0.12828643910483073, 'Total loss': 0.12828643910483073}
2022-12-31 03:03:35,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:35,948 INFO:     Epoch: 58
2022-12-31 03:03:37,570 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3958805983265241, 'Total loss': 0.3958805983265241} | train loss {'Reaction outcome loss': 0.12846430484458563, 'Total loss': 0.12846430484458563}
2022-12-31 03:03:37,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:37,570 INFO:     Epoch: 59
2022-12-31 03:03:39,180 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4280248562494914, 'Total loss': 0.4280248562494914} | train loss {'Reaction outcome loss': 0.1282352092810839, 'Total loss': 0.1282352092810839}
2022-12-31 03:03:39,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:39,181 INFO:     Epoch: 60
2022-12-31 03:03:40,844 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4030170780917009, 'Total loss': 0.4030170780917009} | train loss {'Reaction outcome loss': 0.13033955947785347, 'Total loss': 0.13033955947785347}
2022-12-31 03:03:40,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:40,845 INFO:     Epoch: 61
2022-12-31 03:03:42,466 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41305553168058395, 'Total loss': 0.41305553168058395} | train loss {'Reaction outcome loss': 0.1251882751478964, 'Total loss': 0.1251882751478964}
2022-12-31 03:03:42,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:42,466 INFO:     Epoch: 62
2022-12-31 03:03:44,130 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43544400135676065, 'Total loss': 0.43544400135676065} | train loss {'Reaction outcome loss': 0.1264955925255798, 'Total loss': 0.1264955925255798}
2022-12-31 03:03:44,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:44,131 INFO:     Epoch: 63
2022-12-31 03:03:45,759 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42351277073224386, 'Total loss': 0.42351277073224386} | train loss {'Reaction outcome loss': 0.12620617047819457, 'Total loss': 0.12620617047819457}
2022-12-31 03:03:45,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:45,759 INFO:     Epoch: 64
2022-12-31 03:03:47,378 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43208373586336773, 'Total loss': 0.43208373586336773} | train loss {'Reaction outcome loss': 0.1283802004564822, 'Total loss': 0.1283802004564822}
2022-12-31 03:03:47,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:47,378 INFO:     Epoch: 65
2022-12-31 03:03:49,001 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4403420517841975, 'Total loss': 0.4403420517841975} | train loss {'Reaction outcome loss': 0.1258405871854663, 'Total loss': 0.1258405871854663}
2022-12-31 03:03:49,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:49,002 INFO:     Epoch: 66
2022-12-31 03:03:50,632 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4241868714491526, 'Total loss': 0.4241868714491526} | train loss {'Reaction outcome loss': 0.12201271580599259, 'Total loss': 0.12201271580599259}
2022-12-31 03:03:50,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:50,632 INFO:     Epoch: 67
2022-12-31 03:03:52,262 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40080278515815737, 'Total loss': 0.40080278515815737} | train loss {'Reaction outcome loss': 0.12057974443608976, 'Total loss': 0.12057974443608976}
2022-12-31 03:03:52,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:52,262 INFO:     Epoch: 68
2022-12-31 03:03:53,893 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45152371724446616, 'Total loss': 0.45152371724446616} | train loss {'Reaction outcome loss': 0.1199176489635779, 'Total loss': 0.1199176489635779}
2022-12-31 03:03:53,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:53,894 INFO:     Epoch: 69
2022-12-31 03:03:55,516 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39664738985399406, 'Total loss': 0.39664738985399406} | train loss {'Reaction outcome loss': 0.12066746390832966, 'Total loss': 0.12066746390832966}
2022-12-31 03:03:55,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:55,516 INFO:     Epoch: 70
2022-12-31 03:03:57,140 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45966509679953255, 'Total loss': 0.45966509679953255} | train loss {'Reaction outcome loss': 0.12250689498445802, 'Total loss': 0.12250689498445802}
2022-12-31 03:03:57,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:57,140 INFO:     Epoch: 71
2022-12-31 03:03:58,770 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4596687575181325, 'Total loss': 0.4596687575181325} | train loss {'Reaction outcome loss': 0.12985927471806685, 'Total loss': 0.12985927471806685}
2022-12-31 03:03:58,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:03:58,770 INFO:     Epoch: 72
2022-12-31 03:04:00,400 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47212909360726674, 'Total loss': 0.47212909360726674} | train loss {'Reaction outcome loss': 0.12097339773963277, 'Total loss': 0.12097339773963277}
2022-12-31 03:04:00,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:00,401 INFO:     Epoch: 73
2022-12-31 03:04:02,031 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4460645894209544, 'Total loss': 0.4460645894209544} | train loss {'Reaction outcome loss': 0.11739922247310776, 'Total loss': 0.11739922247310776}
2022-12-31 03:04:02,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:02,031 INFO:     Epoch: 74
2022-12-31 03:04:03,660 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45552358627319334, 'Total loss': 0.45552358627319334} | train loss {'Reaction outcome loss': 0.11405355784729077, 'Total loss': 0.11405355784729077}
2022-12-31 03:04:03,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:03,661 INFO:     Epoch: 75
2022-12-31 03:04:05,281 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4525635689496994, 'Total loss': 0.4525635689496994} | train loss {'Reaction outcome loss': 0.12099721840704462, 'Total loss': 0.12099721840704462}
2022-12-31 03:04:05,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:05,282 INFO:     Epoch: 76
2022-12-31 03:04:06,899 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4279349744319916, 'Total loss': 0.4279349744319916} | train loss {'Reaction outcome loss': 0.12128067228722089, 'Total loss': 0.12128067228722089}
2022-12-31 03:04:06,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:06,900 INFO:     Epoch: 77
2022-12-31 03:04:08,514 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4126323973139127, 'Total loss': 0.4126323973139127} | train loss {'Reaction outcome loss': 0.11512272186624561, 'Total loss': 0.11512272186624561}
2022-12-31 03:04:08,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:08,515 INFO:     Epoch: 78
2022-12-31 03:04:10,179 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42742459774017333, 'Total loss': 0.42742459774017333} | train loss {'Reaction outcome loss': 0.11497607858710544, 'Total loss': 0.11497607858710544}
2022-12-31 03:04:10,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:10,179 INFO:     Epoch: 79
2022-12-31 03:04:11,816 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4493287891149521, 'Total loss': 0.4493287891149521} | train loss {'Reaction outcome loss': 0.11731439356315247, 'Total loss': 0.11731439356315247}
2022-12-31 03:04:11,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:11,817 INFO:     Epoch: 80
2022-12-31 03:04:13,440 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4679252083102862, 'Total loss': 0.4679252083102862} | train loss {'Reaction outcome loss': 0.11276707843712032, 'Total loss': 0.11276707843712032}
2022-12-31 03:04:13,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:13,440 INFO:     Epoch: 81
2022-12-31 03:04:14,569 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4657167355219523, 'Total loss': 0.4657167355219523} | train loss {'Reaction outcome loss': 0.11342462462114096, 'Total loss': 0.11342462462114096}
2022-12-31 03:04:14,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:14,569 INFO:     Epoch: 82
2022-12-31 03:04:15,689 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44706998467445375, 'Total loss': 0.44706998467445375} | train loss {'Reaction outcome loss': 0.11049176278628284, 'Total loss': 0.11049176278628284}
2022-12-31 03:04:15,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:15,689 INFO:     Epoch: 83
2022-12-31 03:04:16,797 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45251850883165995, 'Total loss': 0.45251850883165995} | train loss {'Reaction outcome loss': 0.11403351674115307, 'Total loss': 0.11403351674115307}
2022-12-31 03:04:16,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:16,797 INFO:     Epoch: 84
2022-12-31 03:04:17,903 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46912503242492676, 'Total loss': 0.46912503242492676} | train loss {'Reaction outcome loss': 0.11648281512189777, 'Total loss': 0.11648281512189777}
2022-12-31 03:04:17,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:17,903 INFO:     Epoch: 85
2022-12-31 03:04:19,467 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43914817174275717, 'Total loss': 0.43914817174275717} | train loss {'Reaction outcome loss': 0.11803102580344547, 'Total loss': 0.11803102580344547}
2022-12-31 03:04:19,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:19,467 INFO:     Epoch: 86
2022-12-31 03:04:21,130 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.429929655790329, 'Total loss': 0.429929655790329} | train loss {'Reaction outcome loss': 0.11408960306359892, 'Total loss': 0.11408960306359892}
2022-12-31 03:04:21,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:21,130 INFO:     Epoch: 87
2022-12-31 03:04:22,752 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46296231349309286, 'Total loss': 0.46296231349309286} | train loss {'Reaction outcome loss': 0.11198433436473589, 'Total loss': 0.11198433436473589}
2022-12-31 03:04:22,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:22,752 INFO:     Epoch: 88
2022-12-31 03:04:24,414 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4725793287158012, 'Total loss': 0.4725793287158012} | train loss {'Reaction outcome loss': 0.11512253267278867, 'Total loss': 0.11512253267278867}
2022-12-31 03:04:24,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:24,415 INFO:     Epoch: 89
2022-12-31 03:04:26,040 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4463062802950541, 'Total loss': 0.4463062802950541} | train loss {'Reaction outcome loss': 0.11160286087576515, 'Total loss': 0.11160286087576515}
2022-12-31 03:04:26,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:26,041 INFO:     Epoch: 90
2022-12-31 03:04:27,651 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.458180366953214, 'Total loss': 0.458180366953214} | train loss {'Reaction outcome loss': 0.10688997902115183, 'Total loss': 0.10688997902115183}
2022-12-31 03:04:27,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:27,651 INFO:     Epoch: 91
2022-12-31 03:04:29,278 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45522130727767945, 'Total loss': 0.45522130727767945} | train loss {'Reaction outcome loss': 0.10647283265932303, 'Total loss': 0.10647283265932303}
2022-12-31 03:04:29,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:29,279 INFO:     Epoch: 92
2022-12-31 03:04:30,904 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47871595323085786, 'Total loss': 0.47871595323085786} | train loss {'Reaction outcome loss': 0.11018865372845565, 'Total loss': 0.11018865372845565}
2022-12-31 03:04:30,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:30,904 INFO:     Epoch: 93
2022-12-31 03:04:32,518 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48273206253846485, 'Total loss': 0.48273206253846485} | train loss {'Reaction outcome loss': 0.11189579679795196, 'Total loss': 0.11189579679795196}
2022-12-31 03:04:32,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:32,518 INFO:     Epoch: 94
2022-12-31 03:04:34,181 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.474710276722908, 'Total loss': 0.474710276722908} | train loss {'Reaction outcome loss': 0.10840892421491435, 'Total loss': 0.10840892421491435}
2022-12-31 03:04:34,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:34,182 INFO:     Epoch: 95
2022-12-31 03:04:35,799 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4065244828661283, 'Total loss': 0.4065244828661283} | train loss {'Reaction outcome loss': 0.11093137823869863, 'Total loss': 0.11093137823869863}
2022-12-31 03:04:35,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:35,800 INFO:     Epoch: 96
2022-12-31 03:04:37,428 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48596726059913636, 'Total loss': 0.48596726059913636} | train loss {'Reaction outcome loss': 0.1156364687359082, 'Total loss': 0.1156364687359082}
2022-12-31 03:04:37,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:37,428 INFO:     Epoch: 97
2022-12-31 03:04:39,057 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47717354545990626, 'Total loss': 0.47717354545990626} | train loss {'Reaction outcome loss': 0.10810899679663767, 'Total loss': 0.10810899679663767}
2022-12-31 03:04:39,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:39,057 INFO:     Epoch: 98
2022-12-31 03:04:40,677 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4431921824812889, 'Total loss': 0.4431921824812889} | train loss {'Reaction outcome loss': 0.10802775380927968, 'Total loss': 0.10802775380927968}
2022-12-31 03:04:40,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:40,679 INFO:     Epoch: 99
2022-12-31 03:04:42,306 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46947191605965294, 'Total loss': 0.46947191605965294} | train loss {'Reaction outcome loss': 0.108409184763424, 'Total loss': 0.108409184763424}
2022-12-31 03:04:42,306 INFO:     Best model found after epoch 30 of 100.
2022-12-31 03:04:42,306 INFO:   Done with stage: TRAINING
2022-12-31 03:04:42,307 INFO:   Starting stage: EVALUATION
2022-12-31 03:04:42,437 INFO:   Done with stage: EVALUATION
2022-12-31 03:04:42,437 INFO:   Leaving out SEQ value Fold_8
2022-12-31 03:04:42,450 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 03:04:42,450 INFO:   Starting stage: FEATURE SCALING
2022-12-31 03:04:43,100 INFO:   Done with stage: FEATURE SCALING
2022-12-31 03:04:43,100 INFO:   Starting stage: SCALING TARGETS
2022-12-31 03:04:43,172 INFO:   Done with stage: SCALING TARGETS
2022-12-31 03:04:43,173 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:04:43,173 INFO:     No hyperparam tuning for this model
2022-12-31 03:04:43,173 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:04:43,173 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 03:04:43,173 INFO:     None feature selector for col prot
2022-12-31 03:04:43,174 INFO:     None feature selector for col prot
2022-12-31 03:04:43,174 INFO:     None feature selector for col prot
2022-12-31 03:04:43,174 INFO:     None feature selector for col chem
2022-12-31 03:04:43,174 INFO:     None feature selector for col chem
2022-12-31 03:04:43,174 INFO:     None feature selector for col chem
2022-12-31 03:04:43,174 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 03:04:43,175 INFO:   Starting stage: BUILD MODEL
2022-12-31 03:04:43,176 INFO:     Number of params in model 224011
2022-12-31 03:04:43,180 INFO:   Done with stage: BUILD MODEL
2022-12-31 03:04:43,180 INFO:   Starting stage: TRAINING
2022-12-31 03:04:43,226 INFO:     Val loss before train {'Reaction outcome loss': 0.9141371210416158, 'Total loss': 0.9141371210416158}
2022-12-31 03:04:43,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:43,226 INFO:     Epoch: 0
2022-12-31 03:04:44,855 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5509532392024994, 'Total loss': 0.5509532392024994} | train loss {'Reaction outcome loss': 0.7900300300125441, 'Total loss': 0.7900300300125441}
2022-12-31 03:04:44,855 INFO:     Found new best model at epoch 0
2022-12-31 03:04:44,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:44,856 INFO:     Epoch: 1
2022-12-31 03:04:46,472 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.47407669524351753, 'Total loss': 0.47407669524351753} | train loss {'Reaction outcome loss': 0.5252240529887892, 'Total loss': 0.5252240529887892}
2022-12-31 03:04:46,472 INFO:     Found new best model at epoch 1
2022-12-31 03:04:46,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:46,473 INFO:     Epoch: 2
2022-12-31 03:04:48,085 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4509532888730367, 'Total loss': 0.4509532888730367} | train loss {'Reaction outcome loss': 0.45449564773994294, 'Total loss': 0.45449564773994294}
2022-12-31 03:04:48,086 INFO:     Found new best model at epoch 2
2022-12-31 03:04:48,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:48,087 INFO:     Epoch: 3
2022-12-31 03:04:49,712 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4126623054345449, 'Total loss': 0.4126623054345449} | train loss {'Reaction outcome loss': 0.4138039236996269, 'Total loss': 0.4138039236996269}
2022-12-31 03:04:49,712 INFO:     Found new best model at epoch 3
2022-12-31 03:04:49,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:49,713 INFO:     Epoch: 4
2022-12-31 03:04:51,327 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.39323862294356027, 'Total loss': 0.39323862294356027} | train loss {'Reaction outcome loss': 0.3855213486341476, 'Total loss': 0.3855213486341476}
2022-12-31 03:04:51,327 INFO:     Found new best model at epoch 4
2022-12-31 03:04:51,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:51,328 INFO:     Epoch: 5
2022-12-31 03:04:52,941 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.40705314675966897, 'Total loss': 0.40705314675966897} | train loss {'Reaction outcome loss': 0.36409447838862735, 'Total loss': 0.36409447838862735}
2022-12-31 03:04:52,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:52,942 INFO:     Epoch: 6
2022-12-31 03:04:54,593 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.38706982831160225, 'Total loss': 0.38706982831160225} | train loss {'Reaction outcome loss': 0.3420605431868111, 'Total loss': 0.3420605431868111}
2022-12-31 03:04:54,594 INFO:     Found new best model at epoch 6
2022-12-31 03:04:54,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:54,595 INFO:     Epoch: 7
2022-12-31 03:04:56,208 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.396001298725605, 'Total loss': 0.396001298725605} | train loss {'Reaction outcome loss': 0.33024335987326026, 'Total loss': 0.33024335987326026}
2022-12-31 03:04:56,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:56,208 INFO:     Epoch: 8
2022-12-31 03:04:57,822 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.37551135222117105, 'Total loss': 0.37551135222117105} | train loss {'Reaction outcome loss': 0.32339306612672203, 'Total loss': 0.32339306612672203}
2022-12-31 03:04:57,822 INFO:     Found new best model at epoch 8
2022-12-31 03:04:57,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:57,824 INFO:     Epoch: 9
2022-12-31 03:04:59,438 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3704567700624466, 'Total loss': 0.3704567700624466} | train loss {'Reaction outcome loss': 0.2923057522687789, 'Total loss': 0.2923057522687789}
2022-12-31 03:04:59,438 INFO:     Found new best model at epoch 9
2022-12-31 03:04:59,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:04:59,439 INFO:     Epoch: 10
2022-12-31 03:05:01,053 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.37550104210774105, 'Total loss': 0.37550104210774105} | train loss {'Reaction outcome loss': 0.2822814916808188, 'Total loss': 0.2822814916808188}
2022-12-31 03:05:01,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:01,054 INFO:     Epoch: 11
2022-12-31 03:05:02,667 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3788326402505239, 'Total loss': 0.3788326402505239} | train loss {'Reaction outcome loss': 0.27070788377254823, 'Total loss': 0.27070788377254823}
2022-12-31 03:05:02,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:02,667 INFO:     Epoch: 12
2022-12-31 03:05:04,299 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.35897384683291117, 'Total loss': 0.35897384683291117} | train loss {'Reaction outcome loss': 0.2564465278300686, 'Total loss': 0.2564465278300686}
2022-12-31 03:05:04,299 INFO:     Found new best model at epoch 12
2022-12-31 03:05:04,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:04,300 INFO:     Epoch: 13
2022-12-31 03:05:05,913 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3684587349494298, 'Total loss': 0.3684587349494298} | train loss {'Reaction outcome loss': 0.25053281978536185, 'Total loss': 0.25053281978536185}
2022-12-31 03:05:05,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:05,914 INFO:     Epoch: 14
2022-12-31 03:05:07,529 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3583848605553309, 'Total loss': 0.3583848605553309} | train loss {'Reaction outcome loss': 0.24131128122942333, 'Total loss': 0.24131128122942333}
2022-12-31 03:05:07,529 INFO:     Found new best model at epoch 14
2022-12-31 03:05:07,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:07,530 INFO:     Epoch: 15
2022-12-31 03:05:09,184 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3612759093443553, 'Total loss': 0.3612759093443553} | train loss {'Reaction outcome loss': 0.2329531447199783, 'Total loss': 0.2329531447199783}
2022-12-31 03:05:09,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:09,184 INFO:     Epoch: 16
2022-12-31 03:05:10,801 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.34889808893203733, 'Total loss': 0.34889808893203733} | train loss {'Reaction outcome loss': 0.2292398331615993, 'Total loss': 0.2292398331615993}
2022-12-31 03:05:10,803 INFO:     Found new best model at epoch 16
2022-12-31 03:05:10,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:10,804 INFO:     Epoch: 17
2022-12-31 03:05:12,417 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3575975154836973, 'Total loss': 0.3575975154836973} | train loss {'Reaction outcome loss': 0.21927895973709857, 'Total loss': 0.21927895973709857}
2022-12-31 03:05:12,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:12,418 INFO:     Epoch: 18
2022-12-31 03:05:14,025 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3803793708483378, 'Total loss': 0.3803793708483378} | train loss {'Reaction outcome loss': 0.21432536974063385, 'Total loss': 0.21432536974063385}
2022-12-31 03:05:14,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:14,026 INFO:     Epoch: 19
2022-12-31 03:05:15,639 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.35021889507770537, 'Total loss': 0.35021889507770537} | train loss {'Reaction outcome loss': 0.20856451704816392, 'Total loss': 0.20856451704816392}
2022-12-31 03:05:15,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:15,640 INFO:     Epoch: 20
2022-12-31 03:05:17,258 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.33489766468604404, 'Total loss': 0.33489766468604404} | train loss {'Reaction outcome loss': 0.2036266879685159, 'Total loss': 0.2036266879685159}
2022-12-31 03:05:17,259 INFO:     Found new best model at epoch 20
2022-12-31 03:05:17,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:17,260 INFO:     Epoch: 21
2022-12-31 03:05:18,863 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3531301826238632, 'Total loss': 0.3531301826238632} | train loss {'Reaction outcome loss': 0.20134976697727983, 'Total loss': 0.20134976697727983}
2022-12-31 03:05:18,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:18,864 INFO:     Epoch: 22
2022-12-31 03:05:20,478 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.362716081738472, 'Total loss': 0.362716081738472} | train loss {'Reaction outcome loss': 0.20936104148437362, 'Total loss': 0.20936104148437362}
2022-12-31 03:05:20,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:20,478 INFO:     Epoch: 23
2022-12-31 03:05:22,100 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.353469705581665, 'Total loss': 0.353469705581665} | train loss {'Reaction outcome loss': 0.21616099945748685, 'Total loss': 0.21616099945748685}
2022-12-31 03:05:22,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:22,100 INFO:     Epoch: 24
2022-12-31 03:05:23,725 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3497764140367508, 'Total loss': 0.3497764140367508} | train loss {'Reaction outcome loss': 0.18918894347608212, 'Total loss': 0.18918894347608212}
2022-12-31 03:05:23,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:23,725 INFO:     Epoch: 25
2022-12-31 03:05:25,350 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.35085546771685283, 'Total loss': 0.35085546771685283} | train loss {'Reaction outcome loss': 0.18178728300119765, 'Total loss': 0.18178728300119765}
2022-12-31 03:05:25,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:25,350 INFO:     Epoch: 26
2022-12-31 03:05:26,964 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.375471027692159, 'Total loss': 0.375471027692159} | train loss {'Reaction outcome loss': 0.17914151527709665, 'Total loss': 0.17914151527709665}
2022-12-31 03:05:26,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:26,964 INFO:     Epoch: 27
2022-12-31 03:05:28,584 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.37313325703144073, 'Total loss': 0.37313325703144073} | train loss {'Reaction outcome loss': 0.17584118820567432, 'Total loss': 0.17584118820567432}
2022-12-31 03:05:28,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:28,584 INFO:     Epoch: 28
2022-12-31 03:05:30,209 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.36366730084021887, 'Total loss': 0.36366730084021887} | train loss {'Reaction outcome loss': 0.17546250466335367, 'Total loss': 0.17546250466335367}
2022-12-31 03:05:30,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:30,210 INFO:     Epoch: 29
2022-12-31 03:05:31,856 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.35758206446965535, 'Total loss': 0.35758206446965535} | train loss {'Reaction outcome loss': 0.1699360445356064, 'Total loss': 0.1699360445356064}
2022-12-31 03:05:31,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:31,856 INFO:     Epoch: 30
2022-12-31 03:05:33,474 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3680345485607783, 'Total loss': 0.3680345485607783} | train loss {'Reaction outcome loss': 0.1648520651894311, 'Total loss': 0.1648520651894311}
2022-12-31 03:05:33,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:33,475 INFO:     Epoch: 31
2022-12-31 03:05:35,118 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3570111721754074, 'Total loss': 0.3570111721754074} | train loss {'Reaction outcome loss': 0.16553474869916512, 'Total loss': 0.16553474869916512}
2022-12-31 03:05:35,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:35,118 INFO:     Epoch: 32
2022-12-31 03:05:36,782 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3536580207447211, 'Total loss': 0.3536580207447211} | train loss {'Reaction outcome loss': 0.16122081406090571, 'Total loss': 0.16122081406090571}
2022-12-31 03:05:36,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:36,782 INFO:     Epoch: 33
2022-12-31 03:05:38,393 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40935893257459005, 'Total loss': 0.40935893257459005} | train loss {'Reaction outcome loss': 0.16097172767605525, 'Total loss': 0.16097172767605525}
2022-12-31 03:05:38,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:38,393 INFO:     Epoch: 34
2022-12-31 03:05:40,049 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.35486629471803705, 'Total loss': 0.35486629471803705} | train loss {'Reaction outcome loss': 0.15450139235337332, 'Total loss': 0.15450139235337332}
2022-12-31 03:05:40,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:40,050 INFO:     Epoch: 35
2022-12-31 03:05:41,680 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.343243733048439, 'Total loss': 0.343243733048439} | train loss {'Reaction outcome loss': 0.15606273365947476, 'Total loss': 0.15606273365947476}
2022-12-31 03:05:41,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:41,680 INFO:     Epoch: 36
2022-12-31 03:05:43,310 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3443275431791941, 'Total loss': 0.3443275431791941} | train loss {'Reaction outcome loss': 0.15334189299323622, 'Total loss': 0.15334189299323622}
2022-12-31 03:05:43,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:43,310 INFO:     Epoch: 37
2022-12-31 03:05:44,931 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3779288545250893, 'Total loss': 0.3779288545250893} | train loss {'Reaction outcome loss': 0.15070206925029989, 'Total loss': 0.15070206925029989}
2022-12-31 03:05:44,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:44,931 INFO:     Epoch: 38
2022-12-31 03:05:46,562 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.35214156806468966, 'Total loss': 0.35214156806468966} | train loss {'Reaction outcome loss': 0.15084559998465433, 'Total loss': 0.15084559998465433}
2022-12-31 03:05:46,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:46,564 INFO:     Epoch: 39
2022-12-31 03:05:48,195 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39940529465675356, 'Total loss': 0.39940529465675356} | train loss {'Reaction outcome loss': 0.14956401974178743, 'Total loss': 0.14956401974178743}
2022-12-31 03:05:48,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:48,195 INFO:     Epoch: 40
2022-12-31 03:05:49,826 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.35375533401966097, 'Total loss': 0.35375533401966097} | train loss {'Reaction outcome loss': 0.14508007238559978, 'Total loss': 0.14508007238559978}
2022-12-31 03:05:49,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:49,826 INFO:     Epoch: 41
2022-12-31 03:05:51,465 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3648290395736694, 'Total loss': 0.3648290395736694} | train loss {'Reaction outcome loss': 0.14410292880906575, 'Total loss': 0.14410292880906575}
2022-12-31 03:05:51,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:51,465 INFO:     Epoch: 42
2022-12-31 03:05:53,099 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3725505183140437, 'Total loss': 0.3725505183140437} | train loss {'Reaction outcome loss': 0.14113197236008052, 'Total loss': 0.14113197236008052}
2022-12-31 03:05:53,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:53,100 INFO:     Epoch: 43
2022-12-31 03:05:54,745 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.34968115091323854, 'Total loss': 0.34968115091323854} | train loss {'Reaction outcome loss': 0.1420794480616915, 'Total loss': 0.1420794480616915}
2022-12-31 03:05:54,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:54,745 INFO:     Epoch: 44
2022-12-31 03:05:56,365 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.34308244635661445, 'Total loss': 0.34308244635661445} | train loss {'Reaction outcome loss': 0.13892652566183655, 'Total loss': 0.13892652566183655}
2022-12-31 03:05:56,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:56,365 INFO:     Epoch: 45
2022-12-31 03:05:57,983 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3634780392050743, 'Total loss': 0.3634780392050743} | train loss {'Reaction outcome loss': 0.1384608969261087, 'Total loss': 0.1384608969261087}
2022-12-31 03:05:57,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:57,983 INFO:     Epoch: 46
2022-12-31 03:05:59,606 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.377049058675766, 'Total loss': 0.377049058675766} | train loss {'Reaction outcome loss': 0.14378890786252485, 'Total loss': 0.14378890786252485}
2022-12-31 03:05:59,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:05:59,607 INFO:     Epoch: 47
2022-12-31 03:06:01,236 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3498553196589152, 'Total loss': 0.3498553196589152} | train loss {'Reaction outcome loss': 0.1443723406992712, 'Total loss': 0.1443723406992712}
2022-12-31 03:06:01,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:01,236 INFO:     Epoch: 48
2022-12-31 03:06:02,865 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.36441949630777043, 'Total loss': 0.36441949630777043} | train loss {'Reaction outcome loss': 0.13428812660229109, 'Total loss': 0.13428812660229109}
2022-12-31 03:06:02,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:02,866 INFO:     Epoch: 49
2022-12-31 03:06:04,487 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39078925947348275, 'Total loss': 0.39078925947348275} | train loss {'Reaction outcome loss': 0.13315112507821733, 'Total loss': 0.13315112507821733}
2022-12-31 03:06:04,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:04,488 INFO:     Epoch: 50
2022-12-31 03:06:06,151 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.35317197640736897, 'Total loss': 0.35317197640736897} | train loss {'Reaction outcome loss': 0.13111628811389708, 'Total loss': 0.13111628811389708}
2022-12-31 03:06:06,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:06,152 INFO:     Epoch: 51
2022-12-31 03:06:07,782 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.36257392962773644, 'Total loss': 0.36257392962773644} | train loss {'Reaction outcome loss': 0.1293425062060545, 'Total loss': 0.1293425062060545}
2022-12-31 03:06:07,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:07,782 INFO:     Epoch: 52
2022-12-31 03:06:09,408 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.357689875861009, 'Total loss': 0.357689875861009} | train loss {'Reaction outcome loss': 0.12634886541691495, 'Total loss': 0.12634886541691495}
2022-12-31 03:06:09,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:09,408 INFO:     Epoch: 53
2022-12-31 03:06:11,038 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3651144228875637, 'Total loss': 0.3651144228875637} | train loss {'Reaction outcome loss': 0.12693584969515476, 'Total loss': 0.12693584969515476}
2022-12-31 03:06:11,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:11,039 INFO:     Epoch: 54
2022-12-31 03:06:12,685 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.355925186475118, 'Total loss': 0.355925186475118} | train loss {'Reaction outcome loss': 0.12784125284330608, 'Total loss': 0.12784125284330608}
2022-12-31 03:06:12,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:12,686 INFO:     Epoch: 55
2022-12-31 03:06:14,306 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3425241510073344, 'Total loss': 0.3425241510073344} | train loss {'Reaction outcome loss': 0.12774090377201175, 'Total loss': 0.12774090377201175}
2022-12-31 03:06:14,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:14,306 INFO:     Epoch: 56
2022-12-31 03:06:15,924 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.36555932263533275, 'Total loss': 0.36555932263533275} | train loss {'Reaction outcome loss': 0.13019363519835178, 'Total loss': 0.13019363519835178}
2022-12-31 03:06:15,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:15,925 INFO:     Epoch: 57
2022-12-31 03:06:17,552 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3473991687099139, 'Total loss': 0.3473991687099139} | train loss {'Reaction outcome loss': 0.12586643611522985, 'Total loss': 0.12586643611522985}
2022-12-31 03:06:17,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:17,552 INFO:     Epoch: 58
2022-12-31 03:06:19,181 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.35448466390371325, 'Total loss': 0.35448466390371325} | train loss {'Reaction outcome loss': 0.12601391529882466, 'Total loss': 0.12601391529882466}
2022-12-31 03:06:19,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:19,181 INFO:     Epoch: 59
2022-12-31 03:06:20,796 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3849413603544235, 'Total loss': 0.3849413603544235} | train loss {'Reaction outcome loss': 0.12649271064910336, 'Total loss': 0.12649271064910336}
2022-12-31 03:06:20,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:20,796 INFO:     Epoch: 60
2022-12-31 03:06:22,420 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.38592934409777324, 'Total loss': 0.38592934409777324} | train loss {'Reaction outcome loss': 0.12585746594735267, 'Total loss': 0.12585746594735267}
2022-12-31 03:06:22,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:22,422 INFO:     Epoch: 61
2022-12-31 03:06:24,041 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.36326981633901595, 'Total loss': 0.36326981633901595} | train loss {'Reaction outcome loss': 0.12309944957677794, 'Total loss': 0.12309944957677794}
2022-12-31 03:06:24,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:24,041 INFO:     Epoch: 62
2022-12-31 03:06:25,670 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.34401073257128395, 'Total loss': 0.34401073257128395} | train loss {'Reaction outcome loss': 0.12387661081131386, 'Total loss': 0.12387661081131386}
2022-12-31 03:06:25,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:25,670 INFO:     Epoch: 63
2022-12-31 03:06:27,300 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.35266127983729045, 'Total loss': 0.35266127983729045} | train loss {'Reaction outcome loss': 0.12039656261228397, 'Total loss': 0.12039656261228397}
2022-12-31 03:06:27,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:27,300 INFO:     Epoch: 64
2022-12-31 03:06:28,929 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3473464940985044, 'Total loss': 0.3473464940985044} | train loss {'Reaction outcome loss': 0.11773794553291275, 'Total loss': 0.11773794553291275}
2022-12-31 03:06:28,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:28,930 INFO:     Epoch: 65
2022-12-31 03:06:30,547 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3727175215880076, 'Total loss': 0.3727175215880076} | train loss {'Reaction outcome loss': 0.12305422904614387, 'Total loss': 0.12305422904614387}
2022-12-31 03:06:30,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:30,547 INFO:     Epoch: 66
2022-12-31 03:06:32,176 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.34351038640985887, 'Total loss': 0.34351038640985887} | train loss {'Reaction outcome loss': 0.1224439157792232, 'Total loss': 0.1224439157792232}
2022-12-31 03:06:32,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:32,176 INFO:     Epoch: 67
2022-12-31 03:06:33,805 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.371532009045283, 'Total loss': 0.371532009045283} | train loss {'Reaction outcome loss': 0.11936517037110457, 'Total loss': 0.11936517037110457}
2022-12-31 03:06:33,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:33,805 INFO:     Epoch: 68
2022-12-31 03:06:35,414 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38383620729049045, 'Total loss': 0.38383620729049045} | train loss {'Reaction outcome loss': 0.11435922441465875, 'Total loss': 0.11435922441465875}
2022-12-31 03:06:35,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:35,414 INFO:     Epoch: 69
2022-12-31 03:06:37,078 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41771707038084666, 'Total loss': 0.41771707038084666} | train loss {'Reaction outcome loss': 0.11490031566548471, 'Total loss': 0.11490031566548471}
2022-12-31 03:06:37,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:37,078 INFO:     Epoch: 70
2022-12-31 03:06:38,690 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.35963747203350066, 'Total loss': 0.35963747203350066} | train loss {'Reaction outcome loss': 0.11912158120464048, 'Total loss': 0.11912158120464048}
2022-12-31 03:06:38,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:38,690 INFO:     Epoch: 71
2022-12-31 03:06:40,307 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.34695000598827996, 'Total loss': 0.34695000598827996} | train loss {'Reaction outcome loss': 0.11813643096278267, 'Total loss': 0.11813643096278267}
2022-12-31 03:06:40,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:40,308 INFO:     Epoch: 72
2022-12-31 03:06:41,971 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37509658336639407, 'Total loss': 0.37509658336639407} | train loss {'Reaction outcome loss': 0.1260541872850255, 'Total loss': 0.1260541872850255}
2022-12-31 03:06:41,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:41,972 INFO:     Epoch: 73
2022-12-31 03:06:43,593 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3673159564534823, 'Total loss': 0.3673159564534823} | train loss {'Reaction outcome loss': 0.16111519308828248, 'Total loss': 0.16111519308828248}
2022-12-31 03:06:43,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:43,593 INFO:     Epoch: 74
2022-12-31 03:06:45,203 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.34095317001144093, 'Total loss': 0.34095317001144093} | train loss {'Reaction outcome loss': 0.15098729491718046, 'Total loss': 0.15098729491718046}
2022-12-31 03:06:45,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:45,204 INFO:     Epoch: 75
2022-12-31 03:06:46,869 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3772648175557454, 'Total loss': 0.3772648175557454} | train loss {'Reaction outcome loss': 0.12464601107342826, 'Total loss': 0.12464601107342826}
2022-12-31 03:06:46,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:46,870 INFO:     Epoch: 76
2022-12-31 03:06:48,486 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3924195885658264, 'Total loss': 0.3924195885658264} | train loss {'Reaction outcome loss': 0.11745544319020827, 'Total loss': 0.11745544319020827}
2022-12-31 03:06:48,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:48,487 INFO:     Epoch: 77
2022-12-31 03:06:50,121 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4065656801064809, 'Total loss': 0.4065656801064809} | train loss {'Reaction outcome loss': 0.13853964483470022, 'Total loss': 0.13853964483470022}
2022-12-31 03:06:50,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:50,121 INFO:     Epoch: 78
2022-12-31 03:06:51,756 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38803332249323524, 'Total loss': 0.38803332249323524} | train loss {'Reaction outcome loss': 0.12070429644317947, 'Total loss': 0.12070429644317947}
2022-12-31 03:06:51,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:51,756 INFO:     Epoch: 79
2022-12-31 03:06:53,390 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.38666186382373174, 'Total loss': 0.38666186382373174} | train loss {'Reaction outcome loss': 0.11575958774609836, 'Total loss': 0.11575958774609836}
2022-12-31 03:06:53,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:53,390 INFO:     Epoch: 80
2022-12-31 03:06:55,006 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3945246438185374, 'Total loss': 0.3945246438185374} | train loss {'Reaction outcome loss': 0.11407494224176448, 'Total loss': 0.11407494224176448}
2022-12-31 03:06:55,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:55,007 INFO:     Epoch: 81
2022-12-31 03:06:56,672 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3787455419699351, 'Total loss': 0.3787455419699351} | train loss {'Reaction outcome loss': 0.11034787452503013, 'Total loss': 0.11034787452503013}
2022-12-31 03:06:56,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:56,672 INFO:     Epoch: 82
2022-12-31 03:06:58,323 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4177111973365148, 'Total loss': 0.4177111973365148} | train loss {'Reaction outcome loss': 0.11045981584817437, 'Total loss': 0.11045981584817437}
2022-12-31 03:06:58,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:58,324 INFO:     Epoch: 83
2022-12-31 03:06:59,939 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3698636323213577, 'Total loss': 0.3698636323213577} | train loss {'Reaction outcome loss': 0.11174853598830574, 'Total loss': 0.11174853598830574}
2022-12-31 03:06:59,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:06:59,940 INFO:     Epoch: 84
2022-12-31 03:07:01,557 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38822557826836906, 'Total loss': 0.38822557826836906} | train loss {'Reaction outcome loss': 0.10962369616158801, 'Total loss': 0.10962369616158801}
2022-12-31 03:07:01,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:01,558 INFO:     Epoch: 85
2022-12-31 03:07:03,205 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40059474607308704, 'Total loss': 0.40059474607308704} | train loss {'Reaction outcome loss': 0.10922105222277384, 'Total loss': 0.10922105222277384}
2022-12-31 03:07:03,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:03,206 INFO:     Epoch: 86
2022-12-31 03:07:04,824 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.36842957337697346, 'Total loss': 0.36842957337697346} | train loss {'Reaction outcome loss': 0.11508564095340157, 'Total loss': 0.11508564095340157}
2022-12-31 03:07:04,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:04,825 INFO:     Epoch: 87
2022-12-31 03:07:06,439 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38430351118246714, 'Total loss': 0.38430351118246714} | train loss {'Reaction outcome loss': 0.11654061296539495, 'Total loss': 0.11654061296539495}
2022-12-31 03:07:06,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:06,440 INFO:     Epoch: 88
2022-12-31 03:07:08,073 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.368012905617555, 'Total loss': 0.368012905617555} | train loss {'Reaction outcome loss': 0.11498900763589241, 'Total loss': 0.11498900763589241}
2022-12-31 03:07:08,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:08,073 INFO:     Epoch: 89
2022-12-31 03:07:09,704 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39277730931838356, 'Total loss': 0.39277730931838356} | train loss {'Reaction outcome loss': 0.1159728332925153, 'Total loss': 0.1159728332925153}
2022-12-31 03:07:09,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:09,704 INFO:     Epoch: 90
2022-12-31 03:07:11,327 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3891933267315229, 'Total loss': 0.3891933267315229} | train loss {'Reaction outcome loss': 0.10977495535410961, 'Total loss': 0.10977495535410961}
2022-12-31 03:07:11,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:11,327 INFO:     Epoch: 91
2022-12-31 03:07:12,934 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38514683991670606, 'Total loss': 0.38514683991670606} | train loss {'Reaction outcome loss': 0.1119642674516333, 'Total loss': 0.1119642674516333}
2022-12-31 03:07:12,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:12,935 INFO:     Epoch: 92
2022-12-31 03:07:14,592 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.36169537852207817, 'Total loss': 0.36169537852207817} | train loss {'Reaction outcome loss': 0.11043267487295215, 'Total loss': 0.11043267487295215}
2022-12-31 03:07:14,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:14,593 INFO:     Epoch: 93
2022-12-31 03:07:16,210 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.37731061577796937, 'Total loss': 0.37731061577796937} | train loss {'Reaction outcome loss': 0.10975922513381997, 'Total loss': 0.10975922513381997}
2022-12-31 03:07:16,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:16,210 INFO:     Epoch: 94
2022-12-31 03:07:17,867 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3465225527683894, 'Total loss': 0.3465225527683894} | train loss {'Reaction outcome loss': 0.10841034635550519, 'Total loss': 0.10841034635550519}
2022-12-31 03:07:17,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:17,868 INFO:     Epoch: 95
2022-12-31 03:07:19,478 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.37718109240134556, 'Total loss': 0.37718109240134556} | train loss {'Reaction outcome loss': 0.10903272297287332, 'Total loss': 0.10903272297287332}
2022-12-31 03:07:19,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:19,478 INFO:     Epoch: 96
2022-12-31 03:07:21,093 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3560070786004265, 'Total loss': 0.3560070786004265} | train loss {'Reaction outcome loss': 0.11413603259986131, 'Total loss': 0.11413603259986131}
2022-12-31 03:07:21,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:21,094 INFO:     Epoch: 97
2022-12-31 03:07:22,752 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3775918960571289, 'Total loss': 0.3775918960571289} | train loss {'Reaction outcome loss': 0.11132061918876876, 'Total loss': 0.11132061918876876}
2022-12-31 03:07:22,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:22,752 INFO:     Epoch: 98
2022-12-31 03:07:24,360 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41625320265690485, 'Total loss': 0.41625320265690485} | train loss {'Reaction outcome loss': 0.11327906346211777, 'Total loss': 0.11327906346211777}
2022-12-31 03:07:24,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:24,360 INFO:     Epoch: 99
2022-12-31 03:07:26,017 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3608396664261818, 'Total loss': 0.3608396664261818} | train loss {'Reaction outcome loss': 0.11563633535642757, 'Total loss': 0.11563633535642757}
2022-12-31 03:07:26,017 INFO:     Best model found after epoch 21 of 100.
2022-12-31 03:07:26,017 INFO:   Done with stage: TRAINING
2022-12-31 03:07:26,017 INFO:   Starting stage: EVALUATION
2022-12-31 03:07:26,146 INFO:   Done with stage: EVALUATION
2022-12-31 03:07:26,146 INFO:   Leaving out SEQ value Fold_9
2022-12-31 03:07:26,158 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 03:07:26,158 INFO:   Starting stage: FEATURE SCALING
2022-12-31 03:07:26,796 INFO:   Done with stage: FEATURE SCALING
2022-12-31 03:07:26,796 INFO:   Starting stage: SCALING TARGETS
2022-12-31 03:07:26,868 INFO:   Done with stage: SCALING TARGETS
2022-12-31 03:07:26,868 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:07:26,868 INFO:     No hyperparam tuning for this model
2022-12-31 03:07:26,868 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:07:26,868 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 03:07:26,869 INFO:     None feature selector for col prot
2022-12-31 03:07:26,869 INFO:     None feature selector for col prot
2022-12-31 03:07:26,869 INFO:     None feature selector for col prot
2022-12-31 03:07:26,869 INFO:     None feature selector for col chem
2022-12-31 03:07:26,870 INFO:     None feature selector for col chem
2022-12-31 03:07:26,870 INFO:     None feature selector for col chem
2022-12-31 03:07:26,870 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 03:07:26,870 INFO:   Starting stage: BUILD MODEL
2022-12-31 03:07:26,872 INFO:     Number of params in model 224011
2022-12-31 03:07:26,875 INFO:   Done with stage: BUILD MODEL
2022-12-31 03:07:26,875 INFO:   Starting stage: TRAINING
2022-12-31 03:07:26,920 INFO:     Val loss before train {'Reaction outcome loss': 1.041866664091746, 'Total loss': 1.041866664091746}
2022-12-31 03:07:26,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:26,920 INFO:     Epoch: 0
2022-12-31 03:07:28,530 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5861595352490743, 'Total loss': 0.5861595352490743} | train loss {'Reaction outcome loss': 0.7713668641728767, 'Total loss': 0.7713668641728767}
2022-12-31 03:07:28,530 INFO:     Found new best model at epoch 0
2022-12-31 03:07:28,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:28,531 INFO:     Epoch: 1
2022-12-31 03:07:30,143 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5075227657953898, 'Total loss': 0.5075227657953898} | train loss {'Reaction outcome loss': 0.5180174571839904, 'Total loss': 0.5180174571839904}
2022-12-31 03:07:30,143 INFO:     Found new best model at epoch 1
2022-12-31 03:07:30,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:30,144 INFO:     Epoch: 2
2022-12-31 03:07:31,758 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48201708793640136, 'Total loss': 0.48201708793640136} | train loss {'Reaction outcome loss': 0.4480871296376711, 'Total loss': 0.4480871296376711}
2022-12-31 03:07:31,758 INFO:     Found new best model at epoch 2
2022-12-31 03:07:31,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:31,759 INFO:     Epoch: 3
2022-12-31 03:07:33,367 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4779458105564117, 'Total loss': 0.4779458105564117} | train loss {'Reaction outcome loss': 0.4157235355156919, 'Total loss': 0.4157235355156919}
2022-12-31 03:07:33,368 INFO:     Found new best model at epoch 3
2022-12-31 03:07:33,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:33,369 INFO:     Epoch: 4
2022-12-31 03:07:34,980 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4884133299191793, 'Total loss': 0.4884133299191793} | train loss {'Reaction outcome loss': 0.38664060494983976, 'Total loss': 0.38664060494983976}
2022-12-31 03:07:34,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:34,982 INFO:     Epoch: 5
2022-12-31 03:07:36,591 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4803551733493805, 'Total loss': 0.4803551733493805} | train loss {'Reaction outcome loss': 0.35458804839763086, 'Total loss': 0.35458804839763086}
2022-12-31 03:07:36,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:36,591 INFO:     Epoch: 6
2022-12-31 03:07:38,229 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4555008918046951, 'Total loss': 0.4555008918046951} | train loss {'Reaction outcome loss': 0.337229347112926, 'Total loss': 0.337229347112926}
2022-12-31 03:07:38,229 INFO:     Found new best model at epoch 6
2022-12-31 03:07:38,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:38,230 INFO:     Epoch: 7
2022-12-31 03:07:39,863 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4702739159266154, 'Total loss': 0.4702739159266154} | train loss {'Reaction outcome loss': 0.31527248045861506, 'Total loss': 0.31527248045861506}
2022-12-31 03:07:39,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:39,863 INFO:     Epoch: 8
2022-12-31 03:07:41,496 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.452574767669042, 'Total loss': 0.452574767669042} | train loss {'Reaction outcome loss': 0.301412489633852, 'Total loss': 0.301412489633852}
2022-12-31 03:07:41,497 INFO:     Found new best model at epoch 8
2022-12-31 03:07:41,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:41,498 INFO:     Epoch: 9
2022-12-31 03:07:43,114 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45540004670619966, 'Total loss': 0.45540004670619966} | train loss {'Reaction outcome loss': 0.2878098366967659, 'Total loss': 0.2878098366967659}
2022-12-31 03:07:43,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:43,114 INFO:     Epoch: 10
2022-12-31 03:07:44,743 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4674437592426936, 'Total loss': 0.4674437592426936} | train loss {'Reaction outcome loss': 0.27423463718614716, 'Total loss': 0.27423463718614716}
2022-12-31 03:07:44,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:44,743 INFO:     Epoch: 11
2022-12-31 03:07:46,371 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47887330651283266, 'Total loss': 0.47887330651283266} | train loss {'Reaction outcome loss': 0.25930882438146713, 'Total loss': 0.25930882438146713}
2022-12-31 03:07:46,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:46,372 INFO:     Epoch: 12
2022-12-31 03:07:48,011 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45297497312227886, 'Total loss': 0.45297497312227886} | train loss {'Reaction outcome loss': 0.24866306294595986, 'Total loss': 0.24866306294595986}
2022-12-31 03:07:48,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:48,012 INFO:     Epoch: 13
2022-12-31 03:07:49,629 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43806016246477764, 'Total loss': 0.43806016246477764} | train loss {'Reaction outcome loss': 0.24102653786289063, 'Total loss': 0.24102653786289063}
2022-12-31 03:07:49,629 INFO:     Found new best model at epoch 13
2022-12-31 03:07:49,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:49,630 INFO:     Epoch: 14
2022-12-31 03:07:51,246 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4513194292783737, 'Total loss': 0.4513194292783737} | train loss {'Reaction outcome loss': 0.23195755011065688, 'Total loss': 0.23195755011065688}
2022-12-31 03:07:51,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:51,246 INFO:     Epoch: 15
2022-12-31 03:07:52,872 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46652485728263854, 'Total loss': 0.46652485728263854} | train loss {'Reaction outcome loss': 0.2234062488065135, 'Total loss': 0.2234062488065135}
2022-12-31 03:07:52,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:52,872 INFO:     Epoch: 16
2022-12-31 03:07:54,505 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47374493976434073, 'Total loss': 0.47374493976434073} | train loss {'Reaction outcome loss': 0.2174890113292613, 'Total loss': 0.2174890113292613}
2022-12-31 03:07:54,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:54,506 INFO:     Epoch: 17
2022-12-31 03:07:56,140 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4650859514872233, 'Total loss': 0.4650859514872233} | train loss {'Reaction outcome loss': 0.21230974633489613, 'Total loss': 0.21230974633489613}
2022-12-31 03:07:56,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:56,140 INFO:     Epoch: 18
2022-12-31 03:07:57,772 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4370837420225143, 'Total loss': 0.4370837420225143} | train loss {'Reaction outcome loss': 0.20570624926156175, 'Total loss': 0.20570624926156175}
2022-12-31 03:07:57,772 INFO:     Found new best model at epoch 18
2022-12-31 03:07:57,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:57,773 INFO:     Epoch: 19
2022-12-31 03:07:59,405 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43765986859798434, 'Total loss': 0.43765986859798434} | train loss {'Reaction outcome loss': 0.19949726000988344, 'Total loss': 0.19949726000988344}
2022-12-31 03:07:59,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:07:59,405 INFO:     Epoch: 20
2022-12-31 03:08:01,028 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4571510910987854, 'Total loss': 0.4571510910987854} | train loss {'Reaction outcome loss': 0.21685583757209606, 'Total loss': 0.21685583757209606}
2022-12-31 03:08:01,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:01,028 INFO:     Epoch: 21
2022-12-31 03:08:02,658 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42782148520151775, 'Total loss': 0.42782148520151775} | train loss {'Reaction outcome loss': 0.197474651834995, 'Total loss': 0.197474651834995}
2022-12-31 03:08:02,658 INFO:     Found new best model at epoch 21
2022-12-31 03:08:02,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:02,659 INFO:     Epoch: 22
2022-12-31 03:08:04,291 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49480311473210653, 'Total loss': 0.49480311473210653} | train loss {'Reaction outcome loss': 0.18932672795937464, 'Total loss': 0.18932672795937464}
2022-12-31 03:08:04,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:04,291 INFO:     Epoch: 23
2022-12-31 03:08:05,909 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4629218578338623, 'Total loss': 0.4629218578338623} | train loss {'Reaction outcome loss': 0.18251255826997795, 'Total loss': 0.18251255826997795}
2022-12-31 03:08:05,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:05,910 INFO:     Epoch: 24
2022-12-31 03:08:07,541 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45619533509016036, 'Total loss': 0.45619533509016036} | train loss {'Reaction outcome loss': 0.17544196973946216, 'Total loss': 0.17544196973946216}
2022-12-31 03:08:07,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:07,541 INFO:     Epoch: 25
2022-12-31 03:08:09,172 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46230028569698334, 'Total loss': 0.46230028569698334} | train loss {'Reaction outcome loss': 0.17375055433713252, 'Total loss': 0.17375055433713252}
2022-12-31 03:08:09,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:09,172 INFO:     Epoch: 26
2022-12-31 03:08:10,793 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4456108589967092, 'Total loss': 0.4456108589967092} | train loss {'Reaction outcome loss': 0.1710403297447424, 'Total loss': 0.1710403297447424}
2022-12-31 03:08:10,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:10,794 INFO:     Epoch: 27
2022-12-31 03:08:12,423 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4568030039469401, 'Total loss': 0.4568030039469401} | train loss {'Reaction outcome loss': 0.16321983970904155, 'Total loss': 0.16321983970904155}
2022-12-31 03:08:12,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:12,423 INFO:     Epoch: 28
2022-12-31 03:08:14,050 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47754403154055275, 'Total loss': 0.47754403154055275} | train loss {'Reaction outcome loss': 0.17239173831415205, 'Total loss': 0.17239173831415205}
2022-12-31 03:08:14,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:14,051 INFO:     Epoch: 29
2022-12-31 03:08:15,672 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46267399860856434, 'Total loss': 0.46267399860856434} | train loss {'Reaction outcome loss': 0.1623726229561304, 'Total loss': 0.1623726229561304}
2022-12-31 03:08:15,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:15,672 INFO:     Epoch: 30
2022-12-31 03:08:17,303 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4724539339542389, 'Total loss': 0.4724539339542389} | train loss {'Reaction outcome loss': 0.16050872562007737, 'Total loss': 0.16050872562007737}
2022-12-31 03:08:17,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:17,304 INFO:     Epoch: 31
2022-12-31 03:08:18,926 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4662916511297226, 'Total loss': 0.4662916511297226} | train loss {'Reaction outcome loss': 0.16868483512308044, 'Total loss': 0.16868483512308044}
2022-12-31 03:08:18,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:18,926 INFO:     Epoch: 32
2022-12-31 03:08:20,554 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46586798628171283, 'Total loss': 0.46586798628171283} | train loss {'Reaction outcome loss': 0.1535336115762867, 'Total loss': 0.1535336115762867}
2022-12-31 03:08:20,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:20,554 INFO:     Epoch: 33
2022-12-31 03:08:22,185 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4861367066701253, 'Total loss': 0.4861367066701253} | train loss {'Reaction outcome loss': 0.14844354675311688, 'Total loss': 0.14844354675311688}
2022-12-31 03:08:22,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:22,185 INFO:     Epoch: 34
2022-12-31 03:08:23,809 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48509613871574403, 'Total loss': 0.48509613871574403} | train loss {'Reaction outcome loss': 0.15094336249297857, 'Total loss': 0.15094336249297857}
2022-12-31 03:08:23,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:23,810 INFO:     Epoch: 35
2022-12-31 03:08:25,441 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4718120485544205, 'Total loss': 0.4718120485544205} | train loss {'Reaction outcome loss': 0.14849830230873456, 'Total loss': 0.14849830230873456}
2022-12-31 03:08:25,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:25,441 INFO:     Epoch: 36
2022-12-31 03:08:27,076 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45306747655073804, 'Total loss': 0.45306747655073804} | train loss {'Reaction outcome loss': 0.14704040662458073, 'Total loss': 0.14704040662458073}
2022-12-31 03:08:27,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:27,076 INFO:     Epoch: 37
2022-12-31 03:08:28,699 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4942619423071543, 'Total loss': 0.4942619423071543} | train loss {'Reaction outcome loss': 0.14456845195272236, 'Total loss': 0.14456845195272236}
2022-12-31 03:08:28,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:28,699 INFO:     Epoch: 38
2022-12-31 03:08:30,334 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49076608270406724, 'Total loss': 0.49076608270406724} | train loss {'Reaction outcome loss': 0.1456761370804009, 'Total loss': 0.1456761370804009}
2022-12-31 03:08:30,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:30,335 INFO:     Epoch: 39
2022-12-31 03:08:31,970 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4564983010292053, 'Total loss': 0.4564983010292053} | train loss {'Reaction outcome loss': 0.14264625719701196, 'Total loss': 0.14264625719701196}
2022-12-31 03:08:31,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:31,970 INFO:     Epoch: 40
2022-12-31 03:08:33,594 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4718664973974228, 'Total loss': 0.4718664973974228} | train loss {'Reaction outcome loss': 0.14790021634847939, 'Total loss': 0.14790021634847939}
2022-12-31 03:08:33,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:33,594 INFO:     Epoch: 41
2022-12-31 03:08:35,229 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4857267747322718, 'Total loss': 0.4857267747322718} | train loss {'Reaction outcome loss': 0.1379824866337425, 'Total loss': 0.1379824866337425}
2022-12-31 03:08:35,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:35,229 INFO:     Epoch: 42
2022-12-31 03:08:36,852 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46022459579010805, 'Total loss': 0.46022459579010805} | train loss {'Reaction outcome loss': 0.13899144700617003, 'Total loss': 0.13899144700617003}
2022-12-31 03:08:36,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:36,852 INFO:     Epoch: 43
2022-12-31 03:08:38,485 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4755080049236616, 'Total loss': 0.4755080049236616} | train loss {'Reaction outcome loss': 0.13721394176578885, 'Total loss': 0.13721394176578885}
2022-12-31 03:08:38,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:38,485 INFO:     Epoch: 44
2022-12-31 03:08:40,122 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47356942196687063, 'Total loss': 0.47356942196687063} | train loss {'Reaction outcome loss': 0.13587716465227076, 'Total loss': 0.13587716465227076}
2022-12-31 03:08:40,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:40,122 INFO:     Epoch: 45
2022-12-31 03:08:41,747 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4950514872868856, 'Total loss': 0.4950514872868856} | train loss {'Reaction outcome loss': 0.13443467944613285, 'Total loss': 0.13443467944613285}
2022-12-31 03:08:41,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:41,747 INFO:     Epoch: 46
2022-12-31 03:08:43,383 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4709701299667358, 'Total loss': 0.4709701299667358} | train loss {'Reaction outcome loss': 0.13236600892328104, 'Total loss': 0.13236600892328104}
2022-12-31 03:08:43,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:43,383 INFO:     Epoch: 47
2022-12-31 03:08:45,017 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47501534124215444, 'Total loss': 0.47501534124215444} | train loss {'Reaction outcome loss': 0.13170455223745733, 'Total loss': 0.13170455223745733}
2022-12-31 03:08:45,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:45,018 INFO:     Epoch: 48
2022-12-31 03:08:46,642 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.480947682261467, 'Total loss': 0.480947682261467} | train loss {'Reaction outcome loss': 0.1371438825968864, 'Total loss': 0.1371438825968864}
2022-12-31 03:08:46,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:46,643 INFO:     Epoch: 49
2022-12-31 03:08:48,278 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4550059322267771, 'Total loss': 0.4550059322267771} | train loss {'Reaction outcome loss': 0.13263350776211102, 'Total loss': 0.13263350776211102}
2022-12-31 03:08:48,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:48,278 INFO:     Epoch: 50
2022-12-31 03:08:49,914 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4803728421529134, 'Total loss': 0.4803728421529134} | train loss {'Reaction outcome loss': 0.12949323959047973, 'Total loss': 0.12949323959047973}
2022-12-31 03:08:49,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:49,914 INFO:     Epoch: 51
2022-12-31 03:08:51,537 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46248167008161545, 'Total loss': 0.46248167008161545} | train loss {'Reaction outcome loss': 0.12964972803720098, 'Total loss': 0.12964972803720098}
2022-12-31 03:08:51,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:51,537 INFO:     Epoch: 52
2022-12-31 03:08:53,170 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4944470157225927, 'Total loss': 0.4944470157225927} | train loss {'Reaction outcome loss': 0.15800268839360587, 'Total loss': 0.15800268839360587}
2022-12-31 03:08:53,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:53,171 INFO:     Epoch: 53
2022-12-31 03:08:54,805 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4587188373009364, 'Total loss': 0.4587188373009364} | train loss {'Reaction outcome loss': 0.13336769436432075, 'Total loss': 0.13336769436432075}
2022-12-31 03:08:54,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:54,806 INFO:     Epoch: 54
2022-12-31 03:08:56,427 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4717705974976222, 'Total loss': 0.4717705974976222} | train loss {'Reaction outcome loss': 0.12736726887321667, 'Total loss': 0.12736726887321667}
2022-12-31 03:08:56,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:56,427 INFO:     Epoch: 55
2022-12-31 03:08:58,060 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4864044855038325, 'Total loss': 0.4864044855038325} | train loss {'Reaction outcome loss': 0.1248694248733691, 'Total loss': 0.1248694248733691}
2022-12-31 03:08:58,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:58,061 INFO:     Epoch: 56
2022-12-31 03:08:59,692 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4993195573488871, 'Total loss': 0.4993195573488871} | train loss {'Reaction outcome loss': 0.13769845327213104, 'Total loss': 0.13769845327213104}
2022-12-31 03:08:59,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:08:59,692 INFO:     Epoch: 57
2022-12-31 03:09:01,353 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4681737075249354, 'Total loss': 0.4681737075249354} | train loss {'Reaction outcome loss': 0.12493933846775875, 'Total loss': 0.12493933846775875}
2022-12-31 03:09:01,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:01,354 INFO:     Epoch: 58
2022-12-31 03:09:02,964 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.48721934060255684, 'Total loss': 0.48721934060255684} | train loss {'Reaction outcome loss': 0.12280699098145292, 'Total loss': 0.12280699098145292}
2022-12-31 03:09:02,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:02,964 INFO:     Epoch: 59
2022-12-31 03:09:04,608 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4810755431652069, 'Total loss': 0.4810755431652069} | train loss {'Reaction outcome loss': 0.12170644221402219, 'Total loss': 0.12170644221402219}
2022-12-31 03:09:04,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:04,609 INFO:     Epoch: 60
2022-12-31 03:09:06,245 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48627674182256064, 'Total loss': 0.48627674182256064} | train loss {'Reaction outcome loss': 0.1193993317179063, 'Total loss': 0.1193993317179063}
2022-12-31 03:09:06,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:06,246 INFO:     Epoch: 61
2022-12-31 03:09:07,880 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49733945628007253, 'Total loss': 0.49733945628007253} | train loss {'Reaction outcome loss': 0.1201582035586319, 'Total loss': 0.1201582035586319}
2022-12-31 03:09:07,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:07,880 INFO:     Epoch: 62
2022-12-31 03:09:09,505 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5167508860429127, 'Total loss': 0.5167508860429127} | train loss {'Reaction outcome loss': 0.11976141344411703, 'Total loss': 0.11976141344411703}
2022-12-31 03:09:09,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:09,505 INFO:     Epoch: 63
2022-12-31 03:09:11,135 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5129987811048825, 'Total loss': 0.5129987811048825} | train loss {'Reaction outcome loss': 0.12230109426899867, 'Total loss': 0.12230109426899867}
2022-12-31 03:09:11,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:11,135 INFO:     Epoch: 64
2022-12-31 03:09:12,770 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5111732145150503, 'Total loss': 0.5111732145150503} | train loss {'Reaction outcome loss': 0.12183195925347494, 'Total loss': 0.12183195925347494}
2022-12-31 03:09:12,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:12,770 INFO:     Epoch: 65
2022-12-31 03:09:14,397 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48618203202883403, 'Total loss': 0.48618203202883403} | train loss {'Reaction outcome loss': 0.12170315744394127, 'Total loss': 0.12170315744394127}
2022-12-31 03:09:14,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:14,397 INFO:     Epoch: 66
2022-12-31 03:09:16,031 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4801555206378301, 'Total loss': 0.4801555206378301} | train loss {'Reaction outcome loss': 0.11880729083761411, 'Total loss': 0.11880729083761411}
2022-12-31 03:09:16,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:16,031 INFO:     Epoch: 67
2022-12-31 03:09:17,667 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47248133420944216, 'Total loss': 0.47248133420944216} | train loss {'Reaction outcome loss': 0.12111117943040091, 'Total loss': 0.12111117943040091}
2022-12-31 03:09:17,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:17,667 INFO:     Epoch: 68
2022-12-31 03:09:19,288 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4783257320523262, 'Total loss': 0.4783257320523262} | train loss {'Reaction outcome loss': 0.12181269471445863, 'Total loss': 0.12181269471445863}
2022-12-31 03:09:19,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:19,288 INFO:     Epoch: 69
2022-12-31 03:09:20,922 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4606863776842753, 'Total loss': 0.4606863776842753} | train loss {'Reaction outcome loss': 0.11648662402750114, 'Total loss': 0.11648662402750114}
2022-12-31 03:09:20,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:20,922 INFO:     Epoch: 70
2022-12-31 03:09:22,548 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44891904219985007, 'Total loss': 0.44891904219985007} | train loss {'Reaction outcome loss': 0.11490895012473734, 'Total loss': 0.11490895012473734}
2022-12-31 03:09:22,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:22,549 INFO:     Epoch: 71
2022-12-31 03:09:24,180 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5299061397711436, 'Total loss': 0.5299061397711436} | train loss {'Reaction outcome loss': 0.11557803860946017, 'Total loss': 0.11557803860946017}
2022-12-31 03:09:24,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:24,181 INFO:     Epoch: 72
2022-12-31 03:09:25,814 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4925830046335856, 'Total loss': 0.4925830046335856} | train loss {'Reaction outcome loss': 0.11809778151191362, 'Total loss': 0.11809778151191362}
2022-12-31 03:09:25,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:25,814 INFO:     Epoch: 73
2022-12-31 03:09:27,444 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4658398926258087, 'Total loss': 0.4658398926258087} | train loss {'Reaction outcome loss': 0.11676065809687303, 'Total loss': 0.11676065809687303}
2022-12-31 03:09:27,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:27,445 INFO:     Epoch: 74
2022-12-31 03:09:29,055 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48055125325918197, 'Total loss': 0.48055125325918197} | train loss {'Reaction outcome loss': 0.11655381407615716, 'Total loss': 0.11655381407615716}
2022-12-31 03:09:29,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:29,056 INFO:     Epoch: 75
2022-12-31 03:09:30,669 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46147151788075763, 'Total loss': 0.46147151788075763} | train loss {'Reaction outcome loss': 0.11710893683408832, 'Total loss': 0.11710893683408832}
2022-12-31 03:09:30,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:30,669 INFO:     Epoch: 76
2022-12-31 03:09:32,319 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.462514387567838, 'Total loss': 0.462514387567838} | train loss {'Reaction outcome loss': 0.11175515599197884, 'Total loss': 0.11175515599197884}
2022-12-31 03:09:32,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:32,320 INFO:     Epoch: 77
2022-12-31 03:09:33,984 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4975106313824654, 'Total loss': 0.4975106313824654} | train loss {'Reaction outcome loss': 0.11350432125407783, 'Total loss': 0.11350432125407783}
2022-12-31 03:09:33,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:33,984 INFO:     Epoch: 78
2022-12-31 03:09:35,603 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4834412902593613, 'Total loss': 0.4834412902593613} | train loss {'Reaction outcome loss': 0.11347670219942486, 'Total loss': 0.11347670219942486}
2022-12-31 03:09:35,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:35,603 INFO:     Epoch: 79
2022-12-31 03:09:37,234 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4816328972578049, 'Total loss': 0.4816328972578049} | train loss {'Reaction outcome loss': 0.11483610888113828, 'Total loss': 0.11483610888113828}
2022-12-31 03:09:37,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:37,234 INFO:     Epoch: 80
2022-12-31 03:09:38,868 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4744349797566732, 'Total loss': 0.4744349797566732} | train loss {'Reaction outcome loss': 0.1123600154522506, 'Total loss': 0.1123600154522506}
2022-12-31 03:09:38,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:38,868 INFO:     Epoch: 81
2022-12-31 03:09:40,501 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5098438660303751, 'Total loss': 0.5098438660303751} | train loss {'Reaction outcome loss': 0.12236530485097319, 'Total loss': 0.12236530485097319}
2022-12-31 03:09:40,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:40,501 INFO:     Epoch: 82
2022-12-31 03:09:42,120 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48479757507642113, 'Total loss': 0.48479757507642113} | train loss {'Reaction outcome loss': 0.16225319772290633, 'Total loss': 0.16225319772290633}
2022-12-31 03:09:42,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:42,121 INFO:     Epoch: 83
2022-12-31 03:09:43,748 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49359337488810223, 'Total loss': 0.49359337488810223} | train loss {'Reaction outcome loss': 0.11556520008457154, 'Total loss': 0.11556520008457154}
2022-12-31 03:09:43,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:43,748 INFO:     Epoch: 84
2022-12-31 03:09:45,365 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4558680340647697, 'Total loss': 0.4558680340647697} | train loss {'Reaction outcome loss': 0.13333560326777777, 'Total loss': 0.13333560326777777}
2022-12-31 03:09:45,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:45,366 INFO:     Epoch: 85
2022-12-31 03:09:46,982 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5360283171137173, 'Total loss': 0.5360283171137173} | train loss {'Reaction outcome loss': 0.11456742609405647, 'Total loss': 0.11456742609405647}
2022-12-31 03:09:46,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:46,983 INFO:     Epoch: 86
2022-12-31 03:09:48,604 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5008152703444163, 'Total loss': 0.5008152703444163} | train loss {'Reaction outcome loss': 0.1389751675511513, 'Total loss': 0.1389751675511513}
2022-12-31 03:09:48,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:48,604 INFO:     Epoch: 87
2022-12-31 03:09:50,249 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45931605994701385, 'Total loss': 0.45931605994701385} | train loss {'Reaction outcome loss': 0.11328723571874645, 'Total loss': 0.11328723571874645}
2022-12-31 03:09:50,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:50,250 INFO:     Epoch: 88
2022-12-31 03:09:51,875 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4637650966644287, 'Total loss': 0.4637650966644287} | train loss {'Reaction outcome loss': 0.10847028489829888, 'Total loss': 0.10847028489829888}
2022-12-31 03:09:51,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:51,875 INFO:     Epoch: 89
2022-12-31 03:09:53,498 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47999748488267263, 'Total loss': 0.47999748488267263} | train loss {'Reaction outcome loss': 0.10578123003537969, 'Total loss': 0.10578123003537969}
2022-12-31 03:09:53,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:53,499 INFO:     Epoch: 90
2022-12-31 03:09:55,120 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49313769340515134, 'Total loss': 0.49313769340515134} | train loss {'Reaction outcome loss': 0.10784348996452721, 'Total loss': 0.10784348996452721}
2022-12-31 03:09:55,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:55,120 INFO:     Epoch: 91
2022-12-31 03:09:56,754 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5083395113547643, 'Total loss': 0.5083395113547643} | train loss {'Reaction outcome loss': 0.1089490066177846, 'Total loss': 0.1089490066177846}
2022-12-31 03:09:56,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:56,754 INFO:     Epoch: 92
2022-12-31 03:09:58,387 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47239623765150707, 'Total loss': 0.47239623765150707} | train loss {'Reaction outcome loss': 0.11079069247901224, 'Total loss': 0.11079069247901224}
2022-12-31 03:09:58,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:09:58,388 INFO:     Epoch: 93
2022-12-31 03:10:00,012 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4650282233022153, 'Total loss': 0.4650282233022153} | train loss {'Reaction outcome loss': 0.11767043581104203, 'Total loss': 0.11767043581104203}
2022-12-31 03:10:00,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:00,012 INFO:     Epoch: 94
2022-12-31 03:10:01,647 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48961203669508296, 'Total loss': 0.48961203669508296} | train loss {'Reaction outcome loss': 0.11366955014513012, 'Total loss': 0.11366955014513012}
2022-12-31 03:10:01,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:01,648 INFO:     Epoch: 95
2022-12-31 03:10:03,282 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4789919743935267, 'Total loss': 0.4789919743935267} | train loss {'Reaction outcome loss': 0.11017068399983607, 'Total loss': 0.11017068399983607}
2022-12-31 03:10:03,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:03,282 INFO:     Epoch: 96
2022-12-31 03:10:04,934 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4890811502933502, 'Total loss': 0.4890811502933502} | train loss {'Reaction outcome loss': 0.10526531915926118, 'Total loss': 0.10526531915926118}
2022-12-31 03:10:04,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:04,935 INFO:     Epoch: 97
2022-12-31 03:10:06,550 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46884320775667826, 'Total loss': 0.46884320775667826} | train loss {'Reaction outcome loss': 0.10675045415806328, 'Total loss': 0.10675045415806328}
2022-12-31 03:10:06,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:06,551 INFO:     Epoch: 98
2022-12-31 03:10:08,160 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4926603615283966, 'Total loss': 0.4926603615283966} | train loss {'Reaction outcome loss': 0.10608060285965726, 'Total loss': 0.10608060285965726}
2022-12-31 03:10:08,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:08,160 INFO:     Epoch: 99
2022-12-31 03:10:09,796 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46581240457793077, 'Total loss': 0.46581240457793077} | train loss {'Reaction outcome loss': 0.10678217442165511, 'Total loss': 0.10678217442165511}
2022-12-31 03:10:09,796 INFO:     Best model found after epoch 22 of 100.
2022-12-31 03:10:09,796 INFO:   Done with stage: TRAINING
2022-12-31 03:10:09,796 INFO:   Starting stage: EVALUATION
2022-12-31 03:10:09,925 INFO:   Done with stage: EVALUATION
2022-12-31 03:10:09,933 INFO:   Leaving out SEQ value Fold_0
2022-12-31 03:10:09,946 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2022-12-31 03:10:09,946 INFO:   Starting stage: FEATURE SCALING
2022-12-31 03:10:10,588 INFO:   Done with stage: FEATURE SCALING
2022-12-31 03:10:10,588 INFO:   Starting stage: SCALING TARGETS
2022-12-31 03:10:10,658 INFO:   Done with stage: SCALING TARGETS
2022-12-31 03:10:10,659 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:10:10,659 INFO:     No hyperparam tuning for this model
2022-12-31 03:10:10,659 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:10:10,659 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 03:10:10,659 INFO:     None feature selector for col prot
2022-12-31 03:10:10,660 INFO:     None feature selector for col prot
2022-12-31 03:10:10,660 INFO:     None feature selector for col prot
2022-12-31 03:10:10,660 INFO:     None feature selector for col chem
2022-12-31 03:10:10,660 INFO:     None feature selector for col chem
2022-12-31 03:10:10,660 INFO:     None feature selector for col chem
2022-12-31 03:10:10,660 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 03:10:10,660 INFO:   Starting stage: BUILD MODEL
2022-12-31 03:10:10,662 INFO:     Number of params in model 224011
2022-12-31 03:10:10,665 INFO:   Done with stage: BUILD MODEL
2022-12-31 03:10:10,665 INFO:   Starting stage: TRAINING
2022-12-31 03:10:10,709 INFO:     Val loss before train {'Reaction outcome loss': 0.9384630660216013, 'Total loss': 0.9384630660216013}
2022-12-31 03:10:10,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:10,710 INFO:     Epoch: 0
2022-12-31 03:10:12,324 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5478944222132365, 'Total loss': 0.5478944222132365} | train loss {'Reaction outcome loss': 0.7784778086461704, 'Total loss': 0.7784778086461704}
2022-12-31 03:10:12,324 INFO:     Found new best model at epoch 0
2022-12-31 03:10:12,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:12,325 INFO:     Epoch: 1
2022-12-31 03:10:13,916 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.47712662319342297, 'Total loss': 0.47712662319342297} | train loss {'Reaction outcome loss': 0.5013868410648895, 'Total loss': 0.5013868410648895}
2022-12-31 03:10:13,916 INFO:     Found new best model at epoch 1
2022-12-31 03:10:13,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:13,917 INFO:     Epoch: 2
2022-12-31 03:10:15,518 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5107446521520614, 'Total loss': 0.5107446521520614} | train loss {'Reaction outcome loss': 0.43335582945509593, 'Total loss': 0.43335582945509593}
2022-12-31 03:10:15,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:15,518 INFO:     Epoch: 3
2022-12-31 03:10:17,114 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.41811954577763877, 'Total loss': 0.41811954577763877} | train loss {'Reaction outcome loss': 0.39229438913044457, 'Total loss': 0.39229438913044457}
2022-12-31 03:10:17,114 INFO:     Found new best model at epoch 3
2022-12-31 03:10:17,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:17,116 INFO:     Epoch: 4
2022-12-31 03:10:18,716 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4582715849081675, 'Total loss': 0.4582715849081675} | train loss {'Reaction outcome loss': 0.3648979397167579, 'Total loss': 0.3648979397167579}
2022-12-31 03:10:18,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:18,717 INFO:     Epoch: 5
2022-12-31 03:10:20,318 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46882316370805105, 'Total loss': 0.46882316370805105} | train loss {'Reaction outcome loss': 0.34502143005933267, 'Total loss': 0.34502143005933267}
2022-12-31 03:10:20,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:20,318 INFO:     Epoch: 6
2022-12-31 03:10:21,914 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4055658628543218, 'Total loss': 0.4055658628543218} | train loss {'Reaction outcome loss': 0.3211676761837903, 'Total loss': 0.3211676761837903}
2022-12-31 03:10:21,914 INFO:     Found new best model at epoch 6
2022-12-31 03:10:21,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:21,915 INFO:     Epoch: 7
2022-12-31 03:10:23,494 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4169118324915568, 'Total loss': 0.4169118324915568} | train loss {'Reaction outcome loss': 0.3067471239289674, 'Total loss': 0.3067471239289674}
2022-12-31 03:10:23,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:23,495 INFO:     Epoch: 8
2022-12-31 03:10:25,078 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41945855220158895, 'Total loss': 0.41945855220158895} | train loss {'Reaction outcome loss': 0.29163307576986697, 'Total loss': 0.29163307576986697}
2022-12-31 03:10:25,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:25,078 INFO:     Epoch: 9
2022-12-31 03:10:26,681 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4136136958996455, 'Total loss': 0.4136136958996455} | train loss {'Reaction outcome loss': 0.2789895709370335, 'Total loss': 0.2789895709370335}
2022-12-31 03:10:26,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:26,682 INFO:     Epoch: 10
2022-12-31 03:10:28,317 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4116922102868557, 'Total loss': 0.4116922102868557} | train loss {'Reaction outcome loss': 0.26746091590266385, 'Total loss': 0.26746091590266385}
2022-12-31 03:10:28,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:28,317 INFO:     Epoch: 11
2022-12-31 03:10:29,947 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.439495794971784, 'Total loss': 0.439495794971784} | train loss {'Reaction outcome loss': 0.253981476890205, 'Total loss': 0.253981476890205}
2022-12-31 03:10:29,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:29,947 INFO:     Epoch: 12
2022-12-31 03:10:31,539 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4340016225973765, 'Total loss': 0.4340016225973765} | train loss {'Reaction outcome loss': 0.24939643247980914, 'Total loss': 0.24939643247980914}
2022-12-31 03:10:31,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:31,539 INFO:     Epoch: 13
2022-12-31 03:10:33,173 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41235380955040457, 'Total loss': 0.41235380955040457} | train loss {'Reaction outcome loss': 0.2387979762195661, 'Total loss': 0.2387979762195661}
2022-12-31 03:10:33,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:33,174 INFO:     Epoch: 14
2022-12-31 03:10:34,808 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43799196581045785, 'Total loss': 0.43799196581045785} | train loss {'Reaction outcome loss': 0.2291562042415582, 'Total loss': 0.2291562042415582}
2022-12-31 03:10:34,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:34,810 INFO:     Epoch: 15
2022-12-31 03:10:36,386 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46913234690825145, 'Total loss': 0.46913234690825145} | train loss {'Reaction outcome loss': 0.22095620780633385, 'Total loss': 0.22095620780633385}
2022-12-31 03:10:36,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:36,386 INFO:     Epoch: 16
2022-12-31 03:10:38,020 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39475853318969406, 'Total loss': 0.39475853318969406} | train loss {'Reaction outcome loss': 0.21385990648197073, 'Total loss': 0.21385990648197073}
2022-12-31 03:10:38,020 INFO:     Found new best model at epoch 16
2022-12-31 03:10:38,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:38,021 INFO:     Epoch: 17
2022-12-31 03:10:39,608 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3913339028755824, 'Total loss': 0.3913339028755824} | train loss {'Reaction outcome loss': 0.21303762124363346, 'Total loss': 0.21303762124363346}
2022-12-31 03:10:39,608 INFO:     Found new best model at epoch 17
2022-12-31 03:10:39,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:39,609 INFO:     Epoch: 18
2022-12-31 03:10:41,200 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42397797107696533, 'Total loss': 0.42397797107696533} | train loss {'Reaction outcome loss': 0.20133763603604918, 'Total loss': 0.20133763603604918}
2022-12-31 03:10:41,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:41,201 INFO:     Epoch: 19
2022-12-31 03:10:42,786 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3929553161064784, 'Total loss': 0.3929553161064784} | train loss {'Reaction outcome loss': 0.19927418552256598, 'Total loss': 0.19927418552256598}
2022-12-31 03:10:42,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:42,786 INFO:     Epoch: 20
2022-12-31 03:10:44,413 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43941312829653423, 'Total loss': 0.43941312829653423} | train loss {'Reaction outcome loss': 0.191839252997231, 'Total loss': 0.191839252997231}
2022-12-31 03:10:44,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:44,413 INFO:     Epoch: 21
2022-12-31 03:10:45,996 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4456323117017746, 'Total loss': 0.4456323117017746} | train loss {'Reaction outcome loss': 0.18525874985182636, 'Total loss': 0.18525874985182636}
2022-12-31 03:10:45,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:45,996 INFO:     Epoch: 22
2022-12-31 03:10:47,631 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43047553300857544, 'Total loss': 0.43047553300857544} | train loss {'Reaction outcome loss': 0.18377720121967836, 'Total loss': 0.18377720121967836}
2022-12-31 03:10:47,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:47,631 INFO:     Epoch: 23
2022-12-31 03:10:49,254 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4547572354475657, 'Total loss': 0.4547572354475657} | train loss {'Reaction outcome loss': 0.18082064939697182, 'Total loss': 0.18082064939697182}
2022-12-31 03:10:49,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:49,254 INFO:     Epoch: 24
2022-12-31 03:10:50,857 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4116233829408884, 'Total loss': 0.4116233829408884} | train loss {'Reaction outcome loss': 0.17300448748472103, 'Total loss': 0.17300448748472103}
2022-12-31 03:10:50,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:50,857 INFO:     Epoch: 25
2022-12-31 03:10:52,457 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39987835213541983, 'Total loss': 0.39987835213541983} | train loss {'Reaction outcome loss': 0.1691342188987015, 'Total loss': 0.1691342188987015}
2022-12-31 03:10:52,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:52,457 INFO:     Epoch: 26
2022-12-31 03:10:54,052 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4332933445771535, 'Total loss': 0.4332933445771535} | train loss {'Reaction outcome loss': 0.16849324580391944, 'Total loss': 0.16849324580391944}
2022-12-31 03:10:54,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:54,053 INFO:     Epoch: 27
2022-12-31 03:10:55,656 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4087246616681417, 'Total loss': 0.4087246616681417} | train loss {'Reaction outcome loss': 0.1621137589656119, 'Total loss': 0.1621137589656119}
2022-12-31 03:10:55,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:55,657 INFO:     Epoch: 28
2022-12-31 03:10:57,261 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3996185133854548, 'Total loss': 0.3996185133854548} | train loss {'Reaction outcome loss': 0.1625664362776681, 'Total loss': 0.1625664362776681}
2022-12-31 03:10:57,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:57,261 INFO:     Epoch: 29
2022-12-31 03:10:58,858 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4275494787842035, 'Total loss': 0.4275494787842035} | train loss {'Reaction outcome loss': 0.1621748348010697, 'Total loss': 0.1621748348010697}
2022-12-31 03:10:58,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:10:58,858 INFO:     Epoch: 30
2022-12-31 03:11:00,463 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44560389320055643, 'Total loss': 0.44560389320055643} | train loss {'Reaction outcome loss': 0.15900453043297427, 'Total loss': 0.15900453043297427}
2022-12-31 03:11:00,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:00,464 INFO:     Epoch: 31
2022-12-31 03:11:02,070 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4383827537298203, 'Total loss': 0.4383827537298203} | train loss {'Reaction outcome loss': 0.1551641812960435, 'Total loss': 0.1551641812960435}
2022-12-31 03:11:02,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:02,070 INFO:     Epoch: 32
2022-12-31 03:11:03,666 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4288666894038518, 'Total loss': 0.4288666894038518} | train loss {'Reaction outcome loss': 0.15195771996481722, 'Total loss': 0.15195771996481722}
2022-12-31 03:11:03,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:03,666 INFO:     Epoch: 33
2022-12-31 03:11:05,269 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4112893044948578, 'Total loss': 0.4112893044948578} | train loss {'Reaction outcome loss': 0.1513532561927044, 'Total loss': 0.1513532561927044}
2022-12-31 03:11:05,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:05,269 INFO:     Epoch: 34
2022-12-31 03:11:06,873 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43157928983370464, 'Total loss': 0.43157928983370464} | train loss {'Reaction outcome loss': 0.14784253440192485, 'Total loss': 0.14784253440192485}
2022-12-31 03:11:06,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:06,873 INFO:     Epoch: 35
2022-12-31 03:11:08,468 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4201696931384504, 'Total loss': 0.4201696931384504} | train loss {'Reaction outcome loss': 0.1473573444005638, 'Total loss': 0.1473573444005638}
2022-12-31 03:11:08,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:08,468 INFO:     Epoch: 36
2022-12-31 03:11:10,073 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3952702259023984, 'Total loss': 0.3952702259023984} | train loss {'Reaction outcome loss': 0.14835936513237957, 'Total loss': 0.14835936513237957}
2022-12-31 03:11:10,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:10,074 INFO:     Epoch: 37
2022-12-31 03:11:11,673 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4583058844010035, 'Total loss': 0.4583058844010035} | train loss {'Reaction outcome loss': 0.14288876823929733, 'Total loss': 0.14288876823929733}
2022-12-31 03:11:11,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:11,674 INFO:     Epoch: 38
2022-12-31 03:11:13,270 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43804388443628944, 'Total loss': 0.43804388443628944} | train loss {'Reaction outcome loss': 0.14434221090329638, 'Total loss': 0.14434221090329638}
2022-12-31 03:11:13,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:13,270 INFO:     Epoch: 39
2022-12-31 03:11:14,873 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4208155999581019, 'Total loss': 0.4208155999581019} | train loss {'Reaction outcome loss': 0.1406898541183544, 'Total loss': 0.1406898541183544}
2022-12-31 03:11:14,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:14,873 INFO:     Epoch: 40
2022-12-31 03:11:16,464 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4310304363568624, 'Total loss': 0.4310304363568624} | train loss {'Reaction outcome loss': 0.13411670256186126, 'Total loss': 0.13411670256186126}
2022-12-31 03:11:16,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:16,465 INFO:     Epoch: 41
2022-12-31 03:11:18,054 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42436126867930096, 'Total loss': 0.42436126867930096} | train loss {'Reaction outcome loss': 0.13752876670182274, 'Total loss': 0.13752876670182274}
2022-12-31 03:11:18,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:18,054 INFO:     Epoch: 42
2022-12-31 03:11:19,690 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41816150943438213, 'Total loss': 0.41816150943438213} | train loss {'Reaction outcome loss': 0.13694455542316405, 'Total loss': 0.13694455542316405}
2022-12-31 03:11:19,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:19,690 INFO:     Epoch: 43
2022-12-31 03:11:21,270 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41090959310531616, 'Total loss': 0.41090959310531616} | train loss {'Reaction outcome loss': 0.13387542817659154, 'Total loss': 0.13387542817659154}
2022-12-31 03:11:21,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:21,270 INFO:     Epoch: 44
2022-12-31 03:11:22,905 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40151897867520653, 'Total loss': 0.40151897867520653} | train loss {'Reaction outcome loss': 0.13600077533860763, 'Total loss': 0.13600077533860763}
2022-12-31 03:11:22,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:22,905 INFO:     Epoch: 45
2022-12-31 03:11:24,540 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4251719648639361, 'Total loss': 0.4251719648639361} | train loss {'Reaction outcome loss': 0.13267717179687646, 'Total loss': 0.13267717179687646}
2022-12-31 03:11:24,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:24,541 INFO:     Epoch: 46
2022-12-31 03:11:26,132 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3921067592377464, 'Total loss': 0.3921067592377464} | train loss {'Reaction outcome loss': 0.1310425715252922, 'Total loss': 0.1310425715252922}
2022-12-31 03:11:26,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:26,133 INFO:     Epoch: 47
2022-12-31 03:11:27,767 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44936849574247995, 'Total loss': 0.44936849574247995} | train loss {'Reaction outcome loss': 0.12984614679589868, 'Total loss': 0.12984614679589868}
2022-12-31 03:11:27,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:27,767 INFO:     Epoch: 48
2022-12-31 03:11:29,401 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43014423847198485, 'Total loss': 0.43014423847198485} | train loss {'Reaction outcome loss': 0.12929124033380973, 'Total loss': 0.12929124033380973}
2022-12-31 03:11:29,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:29,402 INFO:     Epoch: 49
2022-12-31 03:11:30,998 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39806718059505025, 'Total loss': 0.39806718059505025} | train loss {'Reaction outcome loss': 0.12774563903105876, 'Total loss': 0.12774563903105876}
2022-12-31 03:11:30,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:30,999 INFO:     Epoch: 50
2022-12-31 03:11:32,633 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.443699382742246, 'Total loss': 0.443699382742246} | train loss {'Reaction outcome loss': 0.13059366221378155, 'Total loss': 0.13059366221378155}
2022-12-31 03:11:32,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:32,633 INFO:     Epoch: 51
2022-12-31 03:11:34,229 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4448955898483594, 'Total loss': 0.4448955898483594} | train loss {'Reaction outcome loss': 0.12429232985585432, 'Total loss': 0.12429232985585432}
2022-12-31 03:11:34,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:34,229 INFO:     Epoch: 52
2022-12-31 03:11:35,830 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43160650233427683, 'Total loss': 0.43160650233427683} | train loss {'Reaction outcome loss': 0.12563662062918018, 'Total loss': 0.12563662062918018}
2022-12-31 03:11:35,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:35,830 INFO:     Epoch: 53
2022-12-31 03:11:37,433 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4342548648516337, 'Total loss': 0.4342548648516337} | train loss {'Reaction outcome loss': 0.1243047599201314, 'Total loss': 0.1243047599201314}
2022-12-31 03:11:37,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:37,433 INFO:     Epoch: 54
2022-12-31 03:11:39,036 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4452878971894582, 'Total loss': 0.4452878971894582} | train loss {'Reaction outcome loss': 0.12283551555326229, 'Total loss': 0.12283551555326229}
2022-12-31 03:11:39,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:39,036 INFO:     Epoch: 55
2022-12-31 03:11:40,629 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41234414676825204, 'Total loss': 0.41234414676825204} | train loss {'Reaction outcome loss': 0.1217510899506523, 'Total loss': 0.1217510899506523}
2022-12-31 03:11:40,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:40,629 INFO:     Epoch: 56
2022-12-31 03:11:42,232 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4135216514269511, 'Total loss': 0.4135216514269511} | train loss {'Reaction outcome loss': 0.11862927250825281, 'Total loss': 0.11862927250825281}
2022-12-31 03:11:42,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:42,232 INFO:     Epoch: 57
2022-12-31 03:11:43,828 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4343521803617477, 'Total loss': 0.4343521803617477} | train loss {'Reaction outcome loss': 0.12036289440251446, 'Total loss': 0.12036289440251446}
2022-12-31 03:11:43,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:43,828 INFO:     Epoch: 58
2022-12-31 03:11:45,414 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45328783194224037, 'Total loss': 0.45328783194224037} | train loss {'Reaction outcome loss': 0.11710939984562432, 'Total loss': 0.11710939984562432}
2022-12-31 03:11:45,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:45,415 INFO:     Epoch: 59
2022-12-31 03:11:47,005 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4051450570424398, 'Total loss': 0.4051450570424398} | train loss {'Reaction outcome loss': 0.12132953965136047, 'Total loss': 0.12132953965136047}
2022-12-31 03:11:47,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:47,006 INFO:     Epoch: 60
2022-12-31 03:11:48,626 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42840123077233633, 'Total loss': 0.42840123077233633} | train loss {'Reaction outcome loss': 0.12180208054463967, 'Total loss': 0.12180208054463967}
2022-12-31 03:11:48,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:48,626 INFO:     Epoch: 61
2022-12-31 03:11:50,227 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4011633505423864, 'Total loss': 0.4011633505423864} | train loss {'Reaction outcome loss': 0.11659225247236746, 'Total loss': 0.11659225247236746}
2022-12-31 03:11:50,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:50,228 INFO:     Epoch: 62
2022-12-31 03:11:51,831 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42838149666786196, 'Total loss': 0.42838149666786196} | train loss {'Reaction outcome loss': 0.11636827740563953, 'Total loss': 0.11636827740563953}
2022-12-31 03:11:51,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:51,832 INFO:     Epoch: 63
2022-12-31 03:11:53,426 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42435579796632134, 'Total loss': 0.42435579796632134} | train loss {'Reaction outcome loss': 0.11849714338786323, 'Total loss': 0.11849714338786323}
2022-12-31 03:11:53,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:53,427 INFO:     Epoch: 64
2022-12-31 03:11:55,029 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4226052139109621, 'Total loss': 0.4226052139109621} | train loss {'Reaction outcome loss': 0.11967148076282381, 'Total loss': 0.11967148076282381}
2022-12-31 03:11:55,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:55,030 INFO:     Epoch: 65
2022-12-31 03:11:56,631 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.416991858308514, 'Total loss': 0.416991858308514} | train loss {'Reaction outcome loss': 0.11632761055589877, 'Total loss': 0.11632761055589877}
2022-12-31 03:11:56,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:56,632 INFO:     Epoch: 66
2022-12-31 03:11:58,222 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4047317753235499, 'Total loss': 0.4047317753235499} | train loss {'Reaction outcome loss': 0.11885587127734924, 'Total loss': 0.11885587127734924}
2022-12-31 03:11:58,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:58,222 INFO:     Epoch: 67
2022-12-31 03:11:59,827 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45042088627815247, 'Total loss': 0.45042088627815247} | train loss {'Reaction outcome loss': 0.11467700804896461, 'Total loss': 0.11467700804896461}
2022-12-31 03:11:59,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:11:59,827 INFO:     Epoch: 68
2022-12-31 03:12:01,423 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.417768569290638, 'Total loss': 0.417768569290638} | train loss {'Reaction outcome loss': 0.11769531155520589, 'Total loss': 0.11769531155520589}
2022-12-31 03:12:01,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:01,424 INFO:     Epoch: 69
2022-12-31 03:12:03,018 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43423270881175996, 'Total loss': 0.43423270881175996} | train loss {'Reaction outcome loss': 0.11412042075754367, 'Total loss': 0.11412042075754367}
2022-12-31 03:12:03,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:03,018 INFO:     Epoch: 70
2022-12-31 03:12:04,622 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3878369462986787, 'Total loss': 0.3878369462986787} | train loss {'Reaction outcome loss': 0.1106165379742882, 'Total loss': 0.1106165379742882}
2022-12-31 03:12:04,622 INFO:     Found new best model at epoch 70
2022-12-31 03:12:04,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:04,623 INFO:     Epoch: 71
2022-12-31 03:12:06,226 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4367245316505432, 'Total loss': 0.4367245316505432} | train loss {'Reaction outcome loss': 0.11139962797712988, 'Total loss': 0.11139962797712988}
2022-12-31 03:12:06,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:06,226 INFO:     Epoch: 72
2022-12-31 03:12:07,820 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4038839029769103, 'Total loss': 0.4038839029769103} | train loss {'Reaction outcome loss': 0.11220570603158751, 'Total loss': 0.11220570603158751}
2022-12-31 03:12:07,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:07,820 INFO:     Epoch: 73
2022-12-31 03:12:09,425 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4674443816145261, 'Total loss': 0.4674443816145261} | train loss {'Reaction outcome loss': 0.1136462149086556, 'Total loss': 0.1136462149086556}
2022-12-31 03:12:09,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:09,425 INFO:     Epoch: 74
2022-12-31 03:12:11,025 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42528238316687444, 'Total loss': 0.42528238316687444} | train loss {'Reaction outcome loss': 0.11660709826110749, 'Total loss': 0.11660709826110749}
2022-12-31 03:12:11,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:11,025 INFO:     Epoch: 75
2022-12-31 03:12:12,605 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4348155280575156, 'Total loss': 0.4348155280575156} | train loss {'Reaction outcome loss': 0.10940489964989251, 'Total loss': 0.10940489964989251}
2022-12-31 03:12:12,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:12,606 INFO:     Epoch: 76
2022-12-31 03:12:14,241 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40983883539835614, 'Total loss': 0.40983883539835614} | train loss {'Reaction outcome loss': 0.11219048424713259, 'Total loss': 0.11219048424713259}
2022-12-31 03:12:14,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:14,242 INFO:     Epoch: 77
2022-12-31 03:12:15,865 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4344094822804133, 'Total loss': 0.4344094822804133} | train loss {'Reaction outcome loss': 0.11140683045562673, 'Total loss': 0.11140683045562673}
2022-12-31 03:12:15,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:15,866 INFO:     Epoch: 78
2022-12-31 03:12:17,451 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42219096918900806, 'Total loss': 0.42219096918900806} | train loss {'Reaction outcome loss': 0.11221605899135455, 'Total loss': 0.11221605899135455}
2022-12-31 03:12:17,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:17,452 INFO:     Epoch: 79
2022-12-31 03:12:19,087 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4343960344791412, 'Total loss': 0.4343960344791412} | train loss {'Reaction outcome loss': 0.11316369894575809, 'Total loss': 0.11316369894575809}
2022-12-31 03:12:19,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:19,088 INFO:     Epoch: 80
2022-12-31 03:12:20,700 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4399974604447683, 'Total loss': 0.4399974604447683} | train loss {'Reaction outcome loss': 0.11466381359738864, 'Total loss': 0.11466381359738864}
2022-12-31 03:12:20,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:20,700 INFO:     Epoch: 81
2022-12-31 03:12:22,336 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4121925501773755, 'Total loss': 0.4121925501773755} | train loss {'Reaction outcome loss': 0.10933672817341461, 'Total loss': 0.10933672817341461}
2022-12-31 03:12:22,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:22,337 INFO:     Epoch: 82
2022-12-31 03:12:23,924 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4750084141890208, 'Total loss': 0.4750084141890208} | train loss {'Reaction outcome loss': 0.1061528582019367, 'Total loss': 0.1061528582019367}
2022-12-31 03:12:23,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:23,924 INFO:     Epoch: 83
2022-12-31 03:12:25,538 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43567560811837514, 'Total loss': 0.43567560811837514} | train loss {'Reaction outcome loss': 0.10987824055184077, 'Total loss': 0.10987824055184077}
2022-12-31 03:12:25,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:25,538 INFO:     Epoch: 84
2022-12-31 03:12:27,145 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44520874208149813, 'Total loss': 0.44520874208149813} | train loss {'Reaction outcome loss': 0.11189995010768328, 'Total loss': 0.11189995010768328}
2022-12-31 03:12:27,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:27,145 INFO:     Epoch: 85
2022-12-31 03:12:28,750 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4585936516523361, 'Total loss': 0.4585936516523361} | train loss {'Reaction outcome loss': 0.11193423003827761, 'Total loss': 0.11193423003827761}
2022-12-31 03:12:28,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:28,751 INFO:     Epoch: 86
2022-12-31 03:12:30,348 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4574261138836543, 'Total loss': 0.4574261138836543} | train loss {'Reaction outcome loss': 0.10867338570529024, 'Total loss': 0.10867338570529024}
2022-12-31 03:12:30,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:30,348 INFO:     Epoch: 87
2022-12-31 03:12:31,955 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4532154401143392, 'Total loss': 0.4532154401143392} | train loss {'Reaction outcome loss': 0.10521567658249742, 'Total loss': 0.10521567658249742}
2022-12-31 03:12:31,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:31,956 INFO:     Epoch: 88
2022-12-31 03:12:33,562 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4376668930053711, 'Total loss': 0.4376668930053711} | train loss {'Reaction outcome loss': 0.1024699259637013, 'Total loss': 0.1024699259637013}
2022-12-31 03:12:33,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:33,562 INFO:     Epoch: 89
2022-12-31 03:12:35,156 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4347057412068049, 'Total loss': 0.4347057412068049} | train loss {'Reaction outcome loss': 0.10317907355832301, 'Total loss': 0.10317907355832301}
2022-12-31 03:12:35,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:35,157 INFO:     Epoch: 90
2022-12-31 03:12:36,762 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45055189430713655, 'Total loss': 0.45055189430713655} | train loss {'Reaction outcome loss': 0.10157846693100744, 'Total loss': 0.10157846693100744}
2022-12-31 03:12:36,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:36,762 INFO:     Epoch: 91
2022-12-31 03:12:38,367 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41793351620435715, 'Total loss': 0.41793351620435715} | train loss {'Reaction outcome loss': 0.10348376156452947, 'Total loss': 0.10348376156452947}
2022-12-31 03:12:38,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:38,368 INFO:     Epoch: 92
2022-12-31 03:12:39,990 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5089744746685028, 'Total loss': 0.5089744746685028} | train loss {'Reaction outcome loss': 0.10836746046883208, 'Total loss': 0.10836746046883208}
2022-12-31 03:12:39,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:39,990 INFO:     Epoch: 93
2022-12-31 03:12:41,581 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44271885553995766, 'Total loss': 0.44271885553995766} | train loss {'Reaction outcome loss': 0.10615068516862404, 'Total loss': 0.10615068516862404}
2022-12-31 03:12:41,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:41,581 INFO:     Epoch: 94
2022-12-31 03:12:43,211 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4227676436305046, 'Total loss': 0.4227676436305046} | train loss {'Reaction outcome loss': 0.10432200177789175, 'Total loss': 0.10432200177789175}
2022-12-31 03:12:43,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:43,211 INFO:     Epoch: 95
2022-12-31 03:12:44,793 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4163076030711333, 'Total loss': 0.4163076030711333} | train loss {'Reaction outcome loss': 0.10208040178492253, 'Total loss': 0.10208040178492253}
2022-12-31 03:12:44,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:44,794 INFO:     Epoch: 96
2022-12-31 03:12:46,429 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4779019355773926, 'Total loss': 0.4779019355773926} | train loss {'Reaction outcome loss': 0.10616343416620692, 'Total loss': 0.10616343416620692}
2022-12-31 03:12:46,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:46,430 INFO:     Epoch: 97
2022-12-31 03:12:48,023 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4606880048910777, 'Total loss': 0.4606880048910777} | train loss {'Reaction outcome loss': 0.10352123903653608, 'Total loss': 0.10352123903653608}
2022-12-31 03:12:48,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:48,024 INFO:     Epoch: 98
2022-12-31 03:12:49,658 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43475018565853435, 'Total loss': 0.43475018565853435} | train loss {'Reaction outcome loss': 0.10507918758115067, 'Total loss': 0.10507918758115067}
2022-12-31 03:12:49,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:49,658 INFO:     Epoch: 99
2022-12-31 03:12:51,293 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42248704632123313, 'Total loss': 0.42248704632123313} | train loss {'Reaction outcome loss': 0.10898549354727968, 'Total loss': 0.10898549354727968}
2022-12-31 03:12:51,293 INFO:     Best model found after epoch 71 of 100.
2022-12-31 03:12:51,293 INFO:   Done with stage: TRAINING
2022-12-31 03:12:51,294 INFO:   Starting stage: EVALUATION
2022-12-31 03:12:51,442 INFO:   Done with stage: EVALUATION
2022-12-31 03:12:51,442 INFO:   Leaving out SEQ value Fold_1
2022-12-31 03:12:51,455 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 03:12:51,455 INFO:   Starting stage: FEATURE SCALING
2022-12-31 03:12:52,103 INFO:   Done with stage: FEATURE SCALING
2022-12-31 03:12:52,103 INFO:   Starting stage: SCALING TARGETS
2022-12-31 03:12:52,175 INFO:   Done with stage: SCALING TARGETS
2022-12-31 03:12:52,176 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:12:52,176 INFO:     No hyperparam tuning for this model
2022-12-31 03:12:52,176 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:12:52,176 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 03:12:52,176 INFO:     None feature selector for col prot
2022-12-31 03:12:52,177 INFO:     None feature selector for col prot
2022-12-31 03:12:52,177 INFO:     None feature selector for col prot
2022-12-31 03:12:52,177 INFO:     None feature selector for col chem
2022-12-31 03:12:52,177 INFO:     None feature selector for col chem
2022-12-31 03:12:52,177 INFO:     None feature selector for col chem
2022-12-31 03:12:52,177 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 03:12:52,178 INFO:   Starting stage: BUILD MODEL
2022-12-31 03:12:52,179 INFO:     Number of params in model 224011
2022-12-31 03:12:52,183 INFO:   Done with stage: BUILD MODEL
2022-12-31 03:12:52,183 INFO:   Starting stage: TRAINING
2022-12-31 03:12:52,229 INFO:     Val loss before train {'Reaction outcome loss': 1.0831209937731425, 'Total loss': 1.0831209937731425}
2022-12-31 03:12:52,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:52,229 INFO:     Epoch: 0
2022-12-31 03:12:53,859 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5853611459334691, 'Total loss': 0.5853611459334691} | train loss {'Reaction outcome loss': 0.7707588808438943, 'Total loss': 0.7707588808438943}
2022-12-31 03:12:53,859 INFO:     Found new best model at epoch 0
2022-12-31 03:12:53,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:53,861 INFO:     Epoch: 1
2022-12-31 03:12:55,490 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5382531364758809, 'Total loss': 0.5382531364758809} | train loss {'Reaction outcome loss': 0.5185346260153945, 'Total loss': 0.5185346260153945}
2022-12-31 03:12:55,490 INFO:     Found new best model at epoch 1
2022-12-31 03:12:55,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:55,491 INFO:     Epoch: 2
2022-12-31 03:12:57,114 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46396597226460773, 'Total loss': 0.46396597226460773} | train loss {'Reaction outcome loss': 0.44827302541512914, 'Total loss': 0.44827302541512914}
2022-12-31 03:12:57,114 INFO:     Found new best model at epoch 2
2022-12-31 03:12:57,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:57,115 INFO:     Epoch: 3
2022-12-31 03:12:58,744 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46219162245591483, 'Total loss': 0.46219162245591483} | train loss {'Reaction outcome loss': 0.4105521057718906, 'Total loss': 0.4105521057718906}
2022-12-31 03:12:58,744 INFO:     Found new best model at epoch 3
2022-12-31 03:12:58,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:12:58,745 INFO:     Epoch: 4
2022-12-31 03:13:00,374 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4511028756697973, 'Total loss': 0.4511028756697973} | train loss {'Reaction outcome loss': 0.37886076853855216, 'Total loss': 0.37886076853855216}
2022-12-31 03:13:00,374 INFO:     Found new best model at epoch 4
2022-12-31 03:13:00,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:00,375 INFO:     Epoch: 5
2022-12-31 03:13:01,990 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4314825793107351, 'Total loss': 0.4314825793107351} | train loss {'Reaction outcome loss': 0.35560548698697897, 'Total loss': 0.35560548698697897}
2022-12-31 03:13:01,991 INFO:     Found new best model at epoch 5
2022-12-31 03:13:01,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:01,992 INFO:     Epoch: 6
2022-12-31 03:13:03,616 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42517435252666474, 'Total loss': 0.42517435252666474} | train loss {'Reaction outcome loss': 0.33598731884705846, 'Total loss': 0.33598731884705846}
2022-12-31 03:13:03,616 INFO:     Found new best model at epoch 6
2022-12-31 03:13:03,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:03,617 INFO:     Epoch: 7
2022-12-31 03:13:05,241 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42940688828627266, 'Total loss': 0.42940688828627266} | train loss {'Reaction outcome loss': 0.3269750665927279, 'Total loss': 0.3269750665927279}
2022-12-31 03:13:05,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:05,241 INFO:     Epoch: 8
2022-12-31 03:13:06,860 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4240801294644674, 'Total loss': 0.4240801294644674} | train loss {'Reaction outcome loss': 0.3170118337000241, 'Total loss': 0.3170118337000241}
2022-12-31 03:13:06,860 INFO:     Found new best model at epoch 8
2022-12-31 03:13:06,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:06,861 INFO:     Epoch: 9
2022-12-31 03:13:08,485 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4150504489739736, 'Total loss': 0.4150504489739736} | train loss {'Reaction outcome loss': 0.2902434822627201, 'Total loss': 0.2902434822627201}
2022-12-31 03:13:08,486 INFO:     Found new best model at epoch 9
2022-12-31 03:13:08,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:08,487 INFO:     Epoch: 10
2022-12-31 03:13:10,111 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41960377792517345, 'Total loss': 0.41960377792517345} | train loss {'Reaction outcome loss': 0.2773606912626259, 'Total loss': 0.2773606912626259}
2022-12-31 03:13:10,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:10,111 INFO:     Epoch: 11
2022-12-31 03:13:11,729 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43909997344017027, 'Total loss': 0.43909997344017027} | train loss {'Reaction outcome loss': 0.26644451525019086, 'Total loss': 0.26644451525019086}
2022-12-31 03:13:11,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:11,729 INFO:     Epoch: 12
2022-12-31 03:13:13,355 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39510452846686045, 'Total loss': 0.39510452846686045} | train loss {'Reaction outcome loss': 0.26071782155718276, 'Total loss': 0.26071782155718276}
2022-12-31 03:13:13,355 INFO:     Found new best model at epoch 12
2022-12-31 03:13:13,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:13,356 INFO:     Epoch: 13
2022-12-31 03:13:14,971 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41112579802672067, 'Total loss': 0.41112579802672067} | train loss {'Reaction outcome loss': 0.2502924958950736, 'Total loss': 0.2502924958950736}
2022-12-31 03:13:14,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:14,972 INFO:     Epoch: 14
2022-12-31 03:13:16,592 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4181018074353536, 'Total loss': 0.4181018074353536} | train loss {'Reaction outcome loss': 0.24325542111442253, 'Total loss': 0.24325542111442253}
2022-12-31 03:13:16,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:16,593 INFO:     Epoch: 15
2022-12-31 03:13:18,215 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4441368778546651, 'Total loss': 0.4441368778546651} | train loss {'Reaction outcome loss': 0.2322367763119763, 'Total loss': 0.2322367763119763}
2022-12-31 03:13:18,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:18,215 INFO:     Epoch: 16
2022-12-31 03:13:19,838 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42637631595134734, 'Total loss': 0.42637631595134734} | train loss {'Reaction outcome loss': 0.23536034052570662, 'Total loss': 0.23536034052570662}
2022-12-31 03:13:19,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:19,838 INFO:     Epoch: 17
2022-12-31 03:13:21,503 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43355296353499095, 'Total loss': 0.43355296353499095} | train loss {'Reaction outcome loss': 0.22787703497538198, 'Total loss': 0.22787703497538198}
2022-12-31 03:13:21,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:21,504 INFO:     Epoch: 18
2022-12-31 03:13:23,124 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.414573410153389, 'Total loss': 0.414573410153389} | train loss {'Reaction outcome loss': 0.2169861091518913, 'Total loss': 0.2169861091518913}
2022-12-31 03:13:23,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:23,126 INFO:     Epoch: 19
2022-12-31 03:13:24,766 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4371309958398342, 'Total loss': 0.4371309958398342} | train loss {'Reaction outcome loss': 0.20825083181346377, 'Total loss': 0.20825083181346377}
2022-12-31 03:13:24,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:24,766 INFO:     Epoch: 20
2022-12-31 03:13:26,388 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4397614697615306, 'Total loss': 0.4397614697615306} | train loss {'Reaction outcome loss': 0.20931934977314717, 'Total loss': 0.20931934977314717}
2022-12-31 03:13:26,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:26,388 INFO:     Epoch: 21
2022-12-31 03:13:28,009 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4189926952123642, 'Total loss': 0.4189926952123642} | train loss {'Reaction outcome loss': 0.19996882552123166, 'Total loss': 0.19996882552123166}
2022-12-31 03:13:28,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:28,009 INFO:     Epoch: 22
2022-12-31 03:13:29,661 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4154224788149198, 'Total loss': 0.4154224788149198} | train loss {'Reaction outcome loss': 0.19448980191204548, 'Total loss': 0.19448980191204548}
2022-12-31 03:13:29,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:29,662 INFO:     Epoch: 23
2022-12-31 03:13:31,282 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43313632210095726, 'Total loss': 0.43313632210095726} | train loss {'Reaction outcome loss': 0.1918529258042142, 'Total loss': 0.1918529258042142}
2022-12-31 03:13:31,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:31,282 INFO:     Epoch: 24
2022-12-31 03:13:32,897 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44046802520751954, 'Total loss': 0.44046802520751954} | train loss {'Reaction outcome loss': 0.1886530622428256, 'Total loss': 0.1886530622428256}
2022-12-31 03:13:32,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:32,897 INFO:     Epoch: 25
2022-12-31 03:13:34,518 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41792233288288116, 'Total loss': 0.41792233288288116} | train loss {'Reaction outcome loss': 0.18553029783505853, 'Total loss': 0.18553029783505853}
2022-12-31 03:13:34,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:34,518 INFO:     Epoch: 26
2022-12-31 03:13:36,146 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42711867690086364, 'Total loss': 0.42711867690086364} | train loss {'Reaction outcome loss': 0.17882982259750174, 'Total loss': 0.17882982259750174}
2022-12-31 03:13:36,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:36,146 INFO:     Epoch: 27
2022-12-31 03:13:37,765 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4482087870438894, 'Total loss': 0.4482087870438894} | train loss {'Reaction outcome loss': 0.17823972737929528, 'Total loss': 0.17823972737929528}
2022-12-31 03:13:37,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:37,765 INFO:     Epoch: 28
2022-12-31 03:13:39,389 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42473498980204266, 'Total loss': 0.42473498980204266} | train loss {'Reaction outcome loss': 0.17381191105127125, 'Total loss': 0.17381191105127125}
2022-12-31 03:13:39,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:39,389 INFO:     Epoch: 29
2022-12-31 03:13:41,014 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4213695605595907, 'Total loss': 0.4213695605595907} | train loss {'Reaction outcome loss': 0.17174648669248016, 'Total loss': 0.17174648669248016}
2022-12-31 03:13:41,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:41,015 INFO:     Epoch: 30
2022-12-31 03:13:42,646 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4350322663784027, 'Total loss': 0.4350322663784027} | train loss {'Reaction outcome loss': 0.16698034342730156, 'Total loss': 0.16698034342730156}
2022-12-31 03:13:42,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:42,647 INFO:     Epoch: 31
2022-12-31 03:13:44,265 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45050072272618613, 'Total loss': 0.45050072272618613} | train loss {'Reaction outcome loss': 0.16531649332021028, 'Total loss': 0.16531649332021028}
2022-12-31 03:13:44,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:44,266 INFO:     Epoch: 32
2022-12-31 03:13:45,885 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40911122461160027, 'Total loss': 0.40911122461160027} | train loss {'Reaction outcome loss': 0.16262176865036937, 'Total loss': 0.16262176865036937}
2022-12-31 03:13:45,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:45,886 INFO:     Epoch: 33
2022-12-31 03:13:47,509 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44109296997388203, 'Total loss': 0.44109296997388203} | train loss {'Reaction outcome loss': 0.16170627016243458, 'Total loss': 0.16170627016243458}
2022-12-31 03:13:47,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:47,509 INFO:     Epoch: 34
2022-12-31 03:13:49,173 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4265387713909149, 'Total loss': 0.4265387713909149} | train loss {'Reaction outcome loss': 0.15780763468870462, 'Total loss': 0.15780763468870462}
2022-12-31 03:13:49,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:49,173 INFO:     Epoch: 35
2022-12-31 03:13:50,836 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4397270103295644, 'Total loss': 0.4397270103295644} | train loss {'Reaction outcome loss': 0.15670416133197368, 'Total loss': 0.15670416133197368}
2022-12-31 03:13:50,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:50,836 INFO:     Epoch: 36
2022-12-31 03:13:52,484 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4280263801415761, 'Total loss': 0.4280263801415761} | train loss {'Reaction outcome loss': 0.15547846187668704, 'Total loss': 0.15547846187668704}
2022-12-31 03:13:52,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:52,485 INFO:     Epoch: 37
2022-12-31 03:13:54,148 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41414829194545744, 'Total loss': 0.41414829194545744} | train loss {'Reaction outcome loss': 0.1511326887226407, 'Total loss': 0.1511326887226407}
2022-12-31 03:13:54,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:54,150 INFO:     Epoch: 38
2022-12-31 03:13:55,768 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4398452291886012, 'Total loss': 0.4398452291886012} | train loss {'Reaction outcome loss': 0.15048540121305437, 'Total loss': 0.15048540121305437}
2022-12-31 03:13:55,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:55,768 INFO:     Epoch: 39
2022-12-31 03:13:57,419 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46607921918233236, 'Total loss': 0.46607921918233236} | train loss {'Reaction outcome loss': 0.15013193101217243, 'Total loss': 0.15013193101217243}
2022-12-31 03:13:57,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:57,419 INFO:     Epoch: 40
2022-12-31 03:13:59,083 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42753073473771414, 'Total loss': 0.42753073473771414} | train loss {'Reaction outcome loss': 0.1504339268317183, 'Total loss': 0.1504339268317183}
2022-12-31 03:13:59,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:13:59,083 INFO:     Epoch: 41
2022-12-31 03:14:00,735 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4255000958840052, 'Total loss': 0.4255000958840052} | train loss {'Reaction outcome loss': 0.14541547534115482, 'Total loss': 0.14541547534115482}
2022-12-31 03:14:00,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:00,736 INFO:     Epoch: 42
2022-12-31 03:14:02,378 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45362940778334937, 'Total loss': 0.45362940778334937} | train loss {'Reaction outcome loss': 0.1427802413135119, 'Total loss': 0.1427802413135119}
2022-12-31 03:14:02,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:02,378 INFO:     Epoch: 43
2022-12-31 03:14:03,996 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44240556259950004, 'Total loss': 0.44240556259950004} | train loss {'Reaction outcome loss': 0.14435523471869258, 'Total loss': 0.14435523471869258}
2022-12-31 03:14:03,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:03,996 INFO:     Epoch: 44
2022-12-31 03:14:05,483 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4380926529566447, 'Total loss': 0.4380926529566447} | train loss {'Reaction outcome loss': 0.14181409154148045, 'Total loss': 0.14181409154148045}
2022-12-31 03:14:05,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:05,483 INFO:     Epoch: 45
2022-12-31 03:14:06,601 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43487450579802195, 'Total loss': 0.43487450579802195} | train loss {'Reaction outcome loss': 0.1532129722201743, 'Total loss': 0.1532129722201743}
2022-12-31 03:14:06,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:06,601 INFO:     Epoch: 46
2022-12-31 03:14:07,713 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40583562354246777, 'Total loss': 0.40583562354246777} | train loss {'Reaction outcome loss': 0.14088285813256557, 'Total loss': 0.14088285813256557}
2022-12-31 03:14:07,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:07,713 INFO:     Epoch: 47
2022-12-31 03:14:08,885 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42770644028981525, 'Total loss': 0.42770644028981525} | train loss {'Reaction outcome loss': 0.13557216171276473, 'Total loss': 0.13557216171276473}
2022-12-31 03:14:08,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:08,886 INFO:     Epoch: 48
2022-12-31 03:14:10,185 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44895115892092385, 'Total loss': 0.44895115892092385} | train loss {'Reaction outcome loss': 0.1364427483031118, 'Total loss': 0.1364427483031118}
2022-12-31 03:14:10,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:10,186 INFO:     Epoch: 49
2022-12-31 03:14:11,847 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4693942685921987, 'Total loss': 0.4693942685921987} | train loss {'Reaction outcome loss': 0.13367566271462356, 'Total loss': 0.13367566271462356}
2022-12-31 03:14:11,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:11,848 INFO:     Epoch: 50
2022-12-31 03:14:13,510 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47008459170659384, 'Total loss': 0.47008459170659384} | train loss {'Reaction outcome loss': 0.13514165081409557, 'Total loss': 0.13514165081409557}
2022-12-31 03:14:13,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:13,510 INFO:     Epoch: 51
2022-12-31 03:14:15,127 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43209028045336406, 'Total loss': 0.43209028045336406} | train loss {'Reaction outcome loss': 0.1321624165782165, 'Total loss': 0.1321624165782165}
2022-12-31 03:14:15,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:15,127 INFO:     Epoch: 52
2022-12-31 03:14:16,774 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4572540839513143, 'Total loss': 0.4572540839513143} | train loss {'Reaction outcome loss': 0.13284335309562384, 'Total loss': 0.13284335309562384}
2022-12-31 03:14:16,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:16,774 INFO:     Epoch: 53
2022-12-31 03:14:18,397 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4720348328351974, 'Total loss': 0.4720348328351974} | train loss {'Reaction outcome loss': 0.13286505594505402, 'Total loss': 0.13286505594505402}
2022-12-31 03:14:18,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:18,397 INFO:     Epoch: 54
2022-12-31 03:14:20,019 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4519195452332497, 'Total loss': 0.4519195452332497} | train loss {'Reaction outcome loss': 0.14052500988926087, 'Total loss': 0.14052500988926087}
2022-12-31 03:14:20,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:20,019 INFO:     Epoch: 55
2022-12-31 03:14:21,650 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4714563588301341, 'Total loss': 0.4714563588301341} | train loss {'Reaction outcome loss': 0.12825386338880745, 'Total loss': 0.12825386338880745}
2022-12-31 03:14:21,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:21,650 INFO:     Epoch: 56
2022-12-31 03:14:23,279 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4365959972143173, 'Total loss': 0.4365959972143173} | train loss {'Reaction outcome loss': 0.12751483206272457, 'Total loss': 0.12751483206272457}
2022-12-31 03:14:23,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:23,279 INFO:     Epoch: 57
2022-12-31 03:14:24,909 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4614618775745233, 'Total loss': 0.4614618775745233} | train loss {'Reaction outcome loss': 0.12735490134809221, 'Total loss': 0.12735490134809221}
2022-12-31 03:14:24,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:24,910 INFO:     Epoch: 58
2022-12-31 03:14:26,534 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4202670658628146, 'Total loss': 0.4202670658628146} | train loss {'Reaction outcome loss': 0.14752885259435244, 'Total loss': 0.14752885259435244}
2022-12-31 03:14:26,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:26,534 INFO:     Epoch: 59
2022-12-31 03:14:28,149 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4762952466805776, 'Total loss': 0.4762952466805776} | train loss {'Reaction outcome loss': 0.13003630599047503, 'Total loss': 0.13003630599047503}
2022-12-31 03:14:28,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:28,150 INFO:     Epoch: 60
2022-12-31 03:14:29,783 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47908244530359906, 'Total loss': 0.47908244530359906} | train loss {'Reaction outcome loss': 0.1282836917088771, 'Total loss': 0.1282836917088771}
2022-12-31 03:14:29,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:29,784 INFO:     Epoch: 61
2022-12-31 03:14:31,409 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44189839661121366, 'Total loss': 0.44189839661121366} | train loss {'Reaction outcome loss': 0.12762355541405423, 'Total loss': 0.12762355541405423}
2022-12-31 03:14:31,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:31,409 INFO:     Epoch: 62
2022-12-31 03:14:33,038 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5069687406222025, 'Total loss': 0.5069687406222025} | train loss {'Reaction outcome loss': 0.12130847841457369, 'Total loss': 0.12130847841457369}
2022-12-31 03:14:33,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:33,038 INFO:     Epoch: 63
2022-12-31 03:14:34,663 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4534322212139765, 'Total loss': 0.4534322212139765} | train loss {'Reaction outcome loss': 0.12225007857805527, 'Total loss': 0.12225007857805527}
2022-12-31 03:14:34,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:34,663 INFO:     Epoch: 64
2022-12-31 03:14:36,270 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45555501282215116, 'Total loss': 0.45555501282215116} | train loss {'Reaction outcome loss': 0.12250542758083348, 'Total loss': 0.12250542758083348}
2022-12-31 03:14:36,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:36,271 INFO:     Epoch: 65
2022-12-31 03:14:37,887 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4858434667189916, 'Total loss': 0.4858434667189916} | train loss {'Reaction outcome loss': 0.11854964096484943, 'Total loss': 0.11854964096484943}
2022-12-31 03:14:37,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:37,887 INFO:     Epoch: 66
2022-12-31 03:14:39,552 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4557225301861763, 'Total loss': 0.4557225301861763} | train loss {'Reaction outcome loss': 0.12422003649407998, 'Total loss': 0.12422003649407998}
2022-12-31 03:14:39,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:39,553 INFO:     Epoch: 67
2022-12-31 03:14:41,167 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4636670708656311, 'Total loss': 0.4636670708656311} | train loss {'Reaction outcome loss': 0.1221331902601068, 'Total loss': 0.1221331902601068}
2022-12-31 03:14:41,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:41,167 INFO:     Epoch: 68
2022-12-31 03:14:42,782 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4884268899758657, 'Total loss': 0.4884268899758657} | train loss {'Reaction outcome loss': 0.11896414586164505, 'Total loss': 0.11896414586164505}
2022-12-31 03:14:42,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:42,783 INFO:     Epoch: 69
2022-12-31 03:14:44,396 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4363233963648478, 'Total loss': 0.4363233963648478} | train loss {'Reaction outcome loss': 0.1214103598132446, 'Total loss': 0.1214103598132446}
2022-12-31 03:14:44,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:44,396 INFO:     Epoch: 70
2022-12-31 03:14:46,023 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43811723987261453, 'Total loss': 0.43811723987261453} | train loss {'Reaction outcome loss': 0.12582894890996008, 'Total loss': 0.12582894890996008}
2022-12-31 03:14:46,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:46,024 INFO:     Epoch: 71
2022-12-31 03:14:47,644 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5195401897033055, 'Total loss': 0.5195401897033055} | train loss {'Reaction outcome loss': 0.12251179651618746, 'Total loss': 0.12251179651618746}
2022-12-31 03:14:47,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:47,644 INFO:     Epoch: 72
2022-12-31 03:14:49,269 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46972498794396716, 'Total loss': 0.46972498794396716} | train loss {'Reaction outcome loss': 0.1251918786598464, 'Total loss': 0.1251918786598464}
2022-12-31 03:14:49,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:49,270 INFO:     Epoch: 73
2022-12-31 03:14:50,898 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4720515315731367, 'Total loss': 0.4720515315731367} | train loss {'Reaction outcome loss': 0.12648997136115003, 'Total loss': 0.12648997136115003}
2022-12-31 03:14:50,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:50,898 INFO:     Epoch: 74
2022-12-31 03:14:52,520 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45770245492458345, 'Total loss': 0.45770245492458345} | train loss {'Reaction outcome loss': 0.1418037819304922, 'Total loss': 0.1418037819304922}
2022-12-31 03:14:52,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:52,520 INFO:     Epoch: 75
2022-12-31 03:14:54,145 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44803685148557026, 'Total loss': 0.44803685148557026} | train loss {'Reaction outcome loss': 0.1202244311702932, 'Total loss': 0.1202244311702932}
2022-12-31 03:14:54,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:54,145 INFO:     Epoch: 76
2022-12-31 03:14:55,785 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4790138304233551, 'Total loss': 0.4790138304233551} | train loss {'Reaction outcome loss': 0.11515454594589992, 'Total loss': 0.11515454594589992}
2022-12-31 03:14:55,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:55,785 INFO:     Epoch: 77
2022-12-31 03:14:57,446 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45235641350348793, 'Total loss': 0.45235641350348793} | train loss {'Reaction outcome loss': 0.11751883233850147, 'Total loss': 0.11751883233850147}
2022-12-31 03:14:57,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:57,447 INFO:     Epoch: 78
2022-12-31 03:14:59,107 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43922004103660583, 'Total loss': 0.43922004103660583} | train loss {'Reaction outcome loss': 0.11417226691946121, 'Total loss': 0.11417226691946121}
2022-12-31 03:14:59,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:14:59,107 INFO:     Epoch: 79
2022-12-31 03:15:00,724 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4784913053115209, 'Total loss': 0.4784913053115209} | train loss {'Reaction outcome loss': 0.11690184472562008, 'Total loss': 0.11690184472562008}
2022-12-31 03:15:00,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:00,724 INFO:     Epoch: 80
2022-12-31 03:15:02,340 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45879008968671164, 'Total loss': 0.45879008968671164} | train loss {'Reaction outcome loss': 0.11976726544763432, 'Total loss': 0.11976726544763432}
2022-12-31 03:15:02,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:02,340 INFO:     Epoch: 81
2022-12-31 03:15:03,961 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4669689526160558, 'Total loss': 0.4669689526160558} | train loss {'Reaction outcome loss': 0.11981996840610087, 'Total loss': 0.11981996840610087}
2022-12-31 03:15:03,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:03,961 INFO:     Epoch: 82
2022-12-31 03:15:05,579 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4395768488446871, 'Total loss': 0.4395768488446871} | train loss {'Reaction outcome loss': 0.11856155322849467, 'Total loss': 0.11856155322849467}
2022-12-31 03:15:05,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:05,580 INFO:     Epoch: 83
2022-12-31 03:15:07,195 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4317528516054153, 'Total loss': 0.4317528516054153} | train loss {'Reaction outcome loss': 0.11497186125287018, 'Total loss': 0.11497186125287018}
2022-12-31 03:15:07,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:07,195 INFO:     Epoch: 84
2022-12-31 03:15:08,813 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4479572360714277, 'Total loss': 0.4479572360714277} | train loss {'Reaction outcome loss': 0.11443736491492018, 'Total loss': 0.11443736491492018}
2022-12-31 03:15:08,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:08,814 INFO:     Epoch: 85
2022-12-31 03:15:10,424 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4431569548944632, 'Total loss': 0.4431569548944632} | train loss {'Reaction outcome loss': 0.11177936993097293, 'Total loss': 0.11177936993097293}
2022-12-31 03:15:10,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:10,424 INFO:     Epoch: 86
2022-12-31 03:15:12,036 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4768183300892512, 'Total loss': 0.4768183300892512} | train loss {'Reaction outcome loss': 0.11197490463791178, 'Total loss': 0.11197490463791178}
2022-12-31 03:15:12,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:12,037 INFO:     Epoch: 87
2022-12-31 03:15:13,655 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45473816990852356, 'Total loss': 0.45473816990852356} | train loss {'Reaction outcome loss': 0.1145297517963416, 'Total loss': 0.1145297517963416}
2022-12-31 03:15:13,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:13,655 INFO:     Epoch: 88
2022-12-31 03:15:15,269 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4379513402779897, 'Total loss': 0.4379513402779897} | train loss {'Reaction outcome loss': 0.12067457050274032, 'Total loss': 0.12067457050274032}
2022-12-31 03:15:15,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:15,269 INFO:     Epoch: 89
2022-12-31 03:15:16,882 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45672453542550406, 'Total loss': 0.45672453542550406} | train loss {'Reaction outcome loss': 0.11978416674031431, 'Total loss': 0.11978416674031431}
2022-12-31 03:15:16,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:16,883 INFO:     Epoch: 90
2022-12-31 03:15:18,497 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4692860424518585, 'Total loss': 0.4692860424518585} | train loss {'Reaction outcome loss': 0.11502124234296691, 'Total loss': 0.11502124234296691}
2022-12-31 03:15:18,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:18,497 INFO:     Epoch: 91
2022-12-31 03:15:20,111 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45888870023190975, 'Total loss': 0.45888870023190975} | train loss {'Reaction outcome loss': 0.11386681111247711, 'Total loss': 0.11386681111247711}
2022-12-31 03:15:20,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:20,111 INFO:     Epoch: 92
2022-12-31 03:15:21,736 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4508816421031952, 'Total loss': 0.4508816421031952} | train loss {'Reaction outcome loss': 0.11810636701420003, 'Total loss': 0.11810636701420003}
2022-12-31 03:15:21,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:21,736 INFO:     Epoch: 93
2022-12-31 03:15:23,359 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42727773189544677, 'Total loss': 0.42727773189544677} | train loss {'Reaction outcome loss': 0.11614264588528042, 'Total loss': 0.11614264588528042}
2022-12-31 03:15:23,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:23,359 INFO:     Epoch: 94
2022-12-31 03:15:24,987 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4841559370358785, 'Total loss': 0.4841559370358785} | train loss {'Reaction outcome loss': 0.11160041922182469, 'Total loss': 0.11160041922182469}
2022-12-31 03:15:24,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:24,988 INFO:     Epoch: 95
2022-12-31 03:15:26,614 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47104546626408894, 'Total loss': 0.47104546626408894} | train loss {'Reaction outcome loss': 0.10917746012379159, 'Total loss': 0.10917746012379159}
2022-12-31 03:15:26,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:26,615 INFO:     Epoch: 96
2022-12-31 03:15:28,243 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.448975400129954, 'Total loss': 0.448975400129954} | train loss {'Reaction outcome loss': 0.10679217023214838, 'Total loss': 0.10679217023214838}
2022-12-31 03:15:28,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:28,243 INFO:     Epoch: 97
2022-12-31 03:15:29,874 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44874300956726076, 'Total loss': 0.44874300956726076} | train loss {'Reaction outcome loss': 0.10992306848021124, 'Total loss': 0.10992306848021124}
2022-12-31 03:15:29,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:29,874 INFO:     Epoch: 98
2022-12-31 03:15:31,537 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4572619636853536, 'Total loss': 0.4572619636853536} | train loss {'Reaction outcome loss': 0.11702971827775321, 'Total loss': 0.11702971827775321}
2022-12-31 03:15:31,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:31,537 INFO:     Epoch: 99
2022-12-31 03:15:33,146 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.433403122673432, 'Total loss': 0.433403122673432} | train loss {'Reaction outcome loss': 0.11430617118299857, 'Total loss': 0.11430617118299857}
2022-12-31 03:15:33,147 INFO:     Best model found after epoch 13 of 100.
2022-12-31 03:15:33,147 INFO:   Done with stage: TRAINING
2022-12-31 03:15:33,147 INFO:   Starting stage: EVALUATION
2022-12-31 03:15:33,277 INFO:   Done with stage: EVALUATION
2022-12-31 03:15:33,277 INFO:   Leaving out SEQ value Fold_2
2022-12-31 03:15:33,290 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 03:15:33,290 INFO:   Starting stage: FEATURE SCALING
2022-12-31 03:15:33,934 INFO:   Done with stage: FEATURE SCALING
2022-12-31 03:15:33,934 INFO:   Starting stage: SCALING TARGETS
2022-12-31 03:15:34,006 INFO:   Done with stage: SCALING TARGETS
2022-12-31 03:15:34,006 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:15:34,006 INFO:     No hyperparam tuning for this model
2022-12-31 03:15:34,006 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:15:34,006 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 03:15:34,007 INFO:     None feature selector for col prot
2022-12-31 03:15:34,007 INFO:     None feature selector for col prot
2022-12-31 03:15:34,007 INFO:     None feature selector for col prot
2022-12-31 03:15:34,007 INFO:     None feature selector for col chem
2022-12-31 03:15:34,007 INFO:     None feature selector for col chem
2022-12-31 03:15:34,008 INFO:     None feature selector for col chem
2022-12-31 03:15:34,008 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 03:15:34,008 INFO:   Starting stage: BUILD MODEL
2022-12-31 03:15:34,009 INFO:     Number of params in model 224011
2022-12-31 03:15:34,013 INFO:   Done with stage: BUILD MODEL
2022-12-31 03:15:34,013 INFO:   Starting stage: TRAINING
2022-12-31 03:15:34,058 INFO:     Val loss before train {'Reaction outcome loss': 1.1240380684534708, 'Total loss': 1.1240380684534708}
2022-12-31 03:15:34,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:34,058 INFO:     Epoch: 0
2022-12-31 03:15:35,665 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7067799468835195, 'Total loss': 0.7067799468835195} | train loss {'Reaction outcome loss': 0.8021825631387043, 'Total loss': 0.8021825631387043}
2022-12-31 03:15:35,665 INFO:     Found new best model at epoch 0
2022-12-31 03:15:35,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:35,666 INFO:     Epoch: 1
2022-12-31 03:15:37,271 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5643368025620779, 'Total loss': 0.5643368025620779} | train loss {'Reaction outcome loss': 0.5245064599235563, 'Total loss': 0.5245064599235563}
2022-12-31 03:15:37,271 INFO:     Found new best model at epoch 1
2022-12-31 03:15:37,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:37,272 INFO:     Epoch: 2
2022-12-31 03:15:38,898 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5505312085151672, 'Total loss': 0.5505312085151672} | train loss {'Reaction outcome loss': 0.45333764000530663, 'Total loss': 0.45333764000530663}
2022-12-31 03:15:38,898 INFO:     Found new best model at epoch 2
2022-12-31 03:15:38,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:38,899 INFO:     Epoch: 3
2022-12-31 03:15:40,515 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5445147275924682, 'Total loss': 0.5445147275924682} | train loss {'Reaction outcome loss': 0.4135638511855237, 'Total loss': 0.4135638511855237}
2022-12-31 03:15:40,516 INFO:     Found new best model at epoch 3
2022-12-31 03:15:40,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:40,517 INFO:     Epoch: 4
2022-12-31 03:15:42,141 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5152571002642313, 'Total loss': 0.5152571002642313} | train loss {'Reaction outcome loss': 0.3813387280071739, 'Total loss': 0.3813387280071739}
2022-12-31 03:15:42,141 INFO:     Found new best model at epoch 4
2022-12-31 03:15:42,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:42,142 INFO:     Epoch: 5
2022-12-31 03:15:43,763 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.537203828493754, 'Total loss': 0.537203828493754} | train loss {'Reaction outcome loss': 0.3557325641821771, 'Total loss': 0.3557325641821771}
2022-12-31 03:15:43,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:43,764 INFO:     Epoch: 6
2022-12-31 03:15:45,382 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.507701204220454, 'Total loss': 0.507701204220454} | train loss {'Reaction outcome loss': 0.34187966068513204, 'Total loss': 0.34187966068513204}
2022-12-31 03:15:45,382 INFO:     Found new best model at epoch 6
2022-12-31 03:15:45,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:45,383 INFO:     Epoch: 7
2022-12-31 03:15:46,998 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5264969192445278, 'Total loss': 0.5264969192445278} | train loss {'Reaction outcome loss': 0.32004360120444403, 'Total loss': 0.32004360120444403}
2022-12-31 03:15:46,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:46,999 INFO:     Epoch: 8
2022-12-31 03:15:48,604 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.514087000489235, 'Total loss': 0.514087000489235} | train loss {'Reaction outcome loss': 0.3054978027259999, 'Total loss': 0.3054978027259999}
2022-12-31 03:15:48,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:48,605 INFO:     Epoch: 9
2022-12-31 03:15:50,235 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5218183120091756, 'Total loss': 0.5218183120091756} | train loss {'Reaction outcome loss': 0.2906578461619189, 'Total loss': 0.2906578461619189}
2022-12-31 03:15:50,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:50,236 INFO:     Epoch: 10
2022-12-31 03:15:51,842 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5035783857107162, 'Total loss': 0.5035783857107162} | train loss {'Reaction outcome loss': 0.28090534932965777, 'Total loss': 0.28090534932965777}
2022-12-31 03:15:51,842 INFO:     Found new best model at epoch 10
2022-12-31 03:15:51,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:51,843 INFO:     Epoch: 11
2022-12-31 03:15:53,448 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4746103609601657, 'Total loss': 0.4746103609601657} | train loss {'Reaction outcome loss': 0.26700454327638135, 'Total loss': 0.26700454327638135}
2022-12-31 03:15:53,448 INFO:     Found new best model at epoch 11
2022-12-31 03:15:53,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:53,449 INFO:     Epoch: 12
2022-12-31 03:15:55,055 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5033583164215087, 'Total loss': 0.5033583164215087} | train loss {'Reaction outcome loss': 0.25803145917173287, 'Total loss': 0.25803145917173287}
2022-12-31 03:15:55,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:55,056 INFO:     Epoch: 13
2022-12-31 03:15:56,686 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4902075131734212, 'Total loss': 0.4902075131734212} | train loss {'Reaction outcome loss': 0.248175474169263, 'Total loss': 0.248175474169263}
2022-12-31 03:15:56,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:56,686 INFO:     Epoch: 14
2022-12-31 03:15:58,329 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4869797507921855, 'Total loss': 0.4869797507921855} | train loss {'Reaction outcome loss': 0.23978080289832648, 'Total loss': 0.23978080289832648}
2022-12-31 03:15:58,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:58,329 INFO:     Epoch: 15
2022-12-31 03:15:59,936 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5052442898352941, 'Total loss': 0.5052442898352941} | train loss {'Reaction outcome loss': 0.23031766444145546, 'Total loss': 0.23031766444145546}
2022-12-31 03:15:59,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:15:59,937 INFO:     Epoch: 16
2022-12-31 03:16:01,541 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49405187865098316, 'Total loss': 0.49405187865098316} | train loss {'Reaction outcome loss': 0.22228671644345252, 'Total loss': 0.22228671644345252}
2022-12-31 03:16:01,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:01,542 INFO:     Epoch: 17
2022-12-31 03:16:03,196 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49581528306007383, 'Total loss': 0.49581528306007383} | train loss {'Reaction outcome loss': 0.21609509532700164, 'Total loss': 0.21609509532700164}
2022-12-31 03:16:03,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:03,196 INFO:     Epoch: 18
2022-12-31 03:16:04,801 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4477278977632523, 'Total loss': 0.4477278977632523} | train loss {'Reaction outcome loss': 0.21137304510241442, 'Total loss': 0.21137304510241442}
2022-12-31 03:16:04,801 INFO:     Found new best model at epoch 18
2022-12-31 03:16:04,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:04,802 INFO:     Epoch: 19
2022-12-31 03:16:06,434 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4554356967409452, 'Total loss': 0.4554356967409452} | train loss {'Reaction outcome loss': 0.20129629381572026, 'Total loss': 0.20129629381572026}
2022-12-31 03:16:06,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:06,434 INFO:     Epoch: 20
2022-12-31 03:16:08,071 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5161071995894114, 'Total loss': 0.5161071995894114} | train loss {'Reaction outcome loss': 0.1999144403087179, 'Total loss': 0.1999144403087179}
2022-12-31 03:16:08,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:08,071 INFO:     Epoch: 21
2022-12-31 03:16:09,690 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4732866853475571, 'Total loss': 0.4732866853475571} | train loss {'Reaction outcome loss': 0.19701100237681157, 'Total loss': 0.19701100237681157}
2022-12-31 03:16:09,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:09,691 INFO:     Epoch: 22
2022-12-31 03:16:11,310 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4676033020019531, 'Total loss': 0.4676033020019531} | train loss {'Reaction outcome loss': 0.18840116046940106, 'Total loss': 0.18840116046940106}
2022-12-31 03:16:11,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:11,310 INFO:     Epoch: 23
2022-12-31 03:16:12,930 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47078829209009804, 'Total loss': 0.47078829209009804} | train loss {'Reaction outcome loss': 0.18418680221168665, 'Total loss': 0.18418680221168665}
2022-12-31 03:16:12,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:12,930 INFO:     Epoch: 24
2022-12-31 03:16:14,541 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4679894437392553, 'Total loss': 0.4679894437392553} | train loss {'Reaction outcome loss': 0.18316576678142713, 'Total loss': 0.18316576678142713}
2022-12-31 03:16:14,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:14,541 INFO:     Epoch: 25
2022-12-31 03:16:16,160 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.531141209602356, 'Total loss': 0.531141209602356} | train loss {'Reaction outcome loss': 0.18414926071766846, 'Total loss': 0.18414926071766846}
2022-12-31 03:16:16,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:16,160 INFO:     Epoch: 26
2022-12-31 03:16:17,771 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4630620370308558, 'Total loss': 0.4630620370308558} | train loss {'Reaction outcome loss': 0.1751758120614138, 'Total loss': 0.1751758120614138}
2022-12-31 03:16:17,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:17,772 INFO:     Epoch: 27
2022-12-31 03:16:19,388 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47977951069672903, 'Total loss': 0.47977951069672903} | train loss {'Reaction outcome loss': 0.17446391790575028, 'Total loss': 0.17446391790575028}
2022-12-31 03:16:19,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:19,388 INFO:     Epoch: 28
2022-12-31 03:16:21,009 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47676891287167866, 'Total loss': 0.47676891287167866} | train loss {'Reaction outcome loss': 0.17065466293915563, 'Total loss': 0.17065466293915563}
2022-12-31 03:16:21,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:21,009 INFO:     Epoch: 29
2022-12-31 03:16:22,627 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4868473579486211, 'Total loss': 0.4868473579486211} | train loss {'Reaction outcome loss': 0.17269605459359877, 'Total loss': 0.17269605459359877}
2022-12-31 03:16:22,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:22,628 INFO:     Epoch: 30
2022-12-31 03:16:24,250 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4897249981760979, 'Total loss': 0.4897249981760979} | train loss {'Reaction outcome loss': 0.16215575846714259, 'Total loss': 0.16215575846714259}
2022-12-31 03:16:24,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:24,251 INFO:     Epoch: 31
2022-12-31 03:16:25,856 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4760359625021617, 'Total loss': 0.4760359625021617} | train loss {'Reaction outcome loss': 0.16831037369182836, 'Total loss': 0.16831037369182836}
2022-12-31 03:16:25,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:25,856 INFO:     Epoch: 32
2022-12-31 03:16:27,467 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5145184218883514, 'Total loss': 0.5145184218883514} | train loss {'Reaction outcome loss': 0.16029633818547764, 'Total loss': 0.16029633818547764}
2022-12-31 03:16:27,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:27,467 INFO:     Epoch: 33
2022-12-31 03:16:29,086 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4640203225115935, 'Total loss': 0.4640203225115935} | train loss {'Reaction outcome loss': 0.16028856195128746, 'Total loss': 0.16028856195128746}
2022-12-31 03:16:29,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:29,086 INFO:     Epoch: 34
2022-12-31 03:16:30,707 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4883149787783623, 'Total loss': 0.4883149787783623} | train loss {'Reaction outcome loss': 0.1611206444612548, 'Total loss': 0.1611206444612548}
2022-12-31 03:16:30,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:30,708 INFO:     Epoch: 35
2022-12-31 03:16:32,329 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47651102344195045, 'Total loss': 0.47651102344195045} | train loss {'Reaction outcome loss': 0.15791780979501724, 'Total loss': 0.15791780979501724}
2022-12-31 03:16:32,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:32,329 INFO:     Epoch: 36
2022-12-31 03:16:33,939 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4588679908464352, 'Total loss': 0.4588679908464352} | train loss {'Reaction outcome loss': 0.15173925084816495, 'Total loss': 0.15173925084816495}
2022-12-31 03:16:33,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:33,939 INFO:     Epoch: 37
2022-12-31 03:16:35,548 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4937964727481206, 'Total loss': 0.4937964727481206} | train loss {'Reaction outcome loss': 0.15165456608413672, 'Total loss': 0.15165456608413672}
2022-12-31 03:16:35,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:35,548 INFO:     Epoch: 38
2022-12-31 03:16:37,151 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.493579692641894, 'Total loss': 0.493579692641894} | train loss {'Reaction outcome loss': 0.14966431788991402, 'Total loss': 0.14966431788991402}
2022-12-31 03:16:37,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:37,152 INFO:     Epoch: 39
2022-12-31 03:16:38,759 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49642331103483833, 'Total loss': 0.49642331103483833} | train loss {'Reaction outcome loss': 0.15151585641922088, 'Total loss': 0.15151585641922088}
2022-12-31 03:16:38,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:38,759 INFO:     Epoch: 40
2022-12-31 03:16:40,412 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4940290004014969, 'Total loss': 0.4940290004014969} | train loss {'Reaction outcome loss': 0.148070034299073, 'Total loss': 0.148070034299073}
2022-12-31 03:16:40,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:40,412 INFO:     Epoch: 41
2022-12-31 03:16:42,052 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5099633395671844, 'Total loss': 0.5099633395671844} | train loss {'Reaction outcome loss': 0.15049667375325396, 'Total loss': 0.15049667375325396}
2022-12-31 03:16:42,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:42,053 INFO:     Epoch: 42
2022-12-31 03:16:43,661 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4909407536188761, 'Total loss': 0.4909407536188761} | train loss {'Reaction outcome loss': 0.14659055207183, 'Total loss': 0.14659055207183}
2022-12-31 03:16:43,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:43,661 INFO:     Epoch: 43
2022-12-31 03:16:45,272 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.49019590417544046, 'Total loss': 0.49019590417544046} | train loss {'Reaction outcome loss': 0.14012325939511622, 'Total loss': 0.14012325939511622}
2022-12-31 03:16:45,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:45,272 INFO:     Epoch: 44
2022-12-31 03:16:46,925 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5210674583911896, 'Total loss': 0.5210674583911896} | train loss {'Reaction outcome loss': 0.1429766831022218, 'Total loss': 0.1429766831022218}
2022-12-31 03:16:46,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:46,925 INFO:     Epoch: 45
2022-12-31 03:16:48,533 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.497087229291598, 'Total loss': 0.497087229291598} | train loss {'Reaction outcome loss': 0.1421451233514333, 'Total loss': 0.1421451233514333}
2022-12-31 03:16:48,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:48,533 INFO:     Epoch: 46
2022-12-31 03:16:50,186 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47032852868239083, 'Total loss': 0.47032852868239083} | train loss {'Reaction outcome loss': 0.13971587189602375, 'Total loss': 0.13971587189602375}
2022-12-31 03:16:50,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:50,186 INFO:     Epoch: 47
2022-12-31 03:16:51,807 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5008854905764262, 'Total loss': 0.5008854905764262} | train loss {'Reaction outcome loss': 0.1421860335156811, 'Total loss': 0.1421860335156811}
2022-12-31 03:16:51,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:51,807 INFO:     Epoch: 48
2022-12-31 03:16:53,420 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49497832854588825, 'Total loss': 0.49497832854588825} | train loss {'Reaction outcome loss': 0.14319162421356751, 'Total loss': 0.14319162421356751}
2022-12-31 03:16:53,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:53,421 INFO:     Epoch: 49
2022-12-31 03:16:55,072 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47357431103785835, 'Total loss': 0.47357431103785835} | train loss {'Reaction outcome loss': 0.1389278565332919, 'Total loss': 0.1389278565332919}
2022-12-31 03:16:55,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:55,072 INFO:     Epoch: 50
2022-12-31 03:16:56,683 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4965351730585098, 'Total loss': 0.4965351730585098} | train loss {'Reaction outcome loss': 0.13668130358585912, 'Total loss': 0.13668130358585912}
2022-12-31 03:16:56,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:56,683 INFO:     Epoch: 51
2022-12-31 03:16:58,336 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4960344523191452, 'Total loss': 0.4960344523191452} | train loss {'Reaction outcome loss': 0.13635884496267803, 'Total loss': 0.13635884496267803}
2022-12-31 03:16:58,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:58,336 INFO:     Epoch: 52
2022-12-31 03:16:59,946 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49113922615846, 'Total loss': 0.49113922615846} | train loss {'Reaction outcome loss': 0.13481800241844497, 'Total loss': 0.13481800241844497}
2022-12-31 03:16:59,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:16:59,947 INFO:     Epoch: 53
2022-12-31 03:17:01,593 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4678187917297085, 'Total loss': 0.4678187917297085} | train loss {'Reaction outcome loss': 0.1329726593273209, 'Total loss': 0.1329726593273209}
2022-12-31 03:17:01,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:01,593 INFO:     Epoch: 54
2022-12-31 03:17:03,223 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5075157582759857, 'Total loss': 0.5075157582759857} | train loss {'Reaction outcome loss': 0.13870081216110475, 'Total loss': 0.13870081216110475}
2022-12-31 03:17:03,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:03,223 INFO:     Epoch: 55
2022-12-31 03:17:04,841 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4640101581811905, 'Total loss': 0.4640101581811905} | train loss {'Reaction outcome loss': 0.1352956398750526, 'Total loss': 0.1352956398750526}
2022-12-31 03:17:04,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:04,842 INFO:     Epoch: 56
2022-12-31 03:17:06,452 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4955869883298874, 'Total loss': 0.4955869883298874} | train loss {'Reaction outcome loss': 0.1294294914577401, 'Total loss': 0.1294294914577401}
2022-12-31 03:17:06,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:06,452 INFO:     Epoch: 57
2022-12-31 03:17:08,056 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48110738197962444, 'Total loss': 0.48110738197962444} | train loss {'Reaction outcome loss': 0.13170256164523153, 'Total loss': 0.13170256164523153}
2022-12-31 03:17:08,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:08,056 INFO:     Epoch: 58
2022-12-31 03:17:09,660 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5155796150366465, 'Total loss': 0.5155796150366465} | train loss {'Reaction outcome loss': 0.1275769703720703, 'Total loss': 0.1275769703720703}
2022-12-31 03:17:09,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:09,661 INFO:     Epoch: 59
2022-12-31 03:17:11,278 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5033507953087489, 'Total loss': 0.5033507953087489} | train loss {'Reaction outcome loss': 0.1295512355158758, 'Total loss': 0.1295512355158758}
2022-12-31 03:17:11,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:11,278 INFO:     Epoch: 60
2022-12-31 03:17:12,881 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48417488634586336, 'Total loss': 0.48417488634586336} | train loss {'Reaction outcome loss': 0.13120797378126614, 'Total loss': 0.13120797378126614}
2022-12-31 03:17:12,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:12,882 INFO:     Epoch: 61
2022-12-31 03:17:14,493 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45584045102198917, 'Total loss': 0.45584045102198917} | train loss {'Reaction outcome loss': 0.1255749431872115, 'Total loss': 0.1255749431872115}
2022-12-31 03:17:14,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:14,493 INFO:     Epoch: 62
2022-12-31 03:17:16,104 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45674400130907694, 'Total loss': 0.45674400130907694} | train loss {'Reaction outcome loss': 0.1244334414343003, 'Total loss': 0.1244334414343003}
2022-12-31 03:17:16,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:16,104 INFO:     Epoch: 63
2022-12-31 03:17:17,757 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4666927133997281, 'Total loss': 0.4666927133997281} | train loss {'Reaction outcome loss': 0.12478054281371734, 'Total loss': 0.12478054281371734}
2022-12-31 03:17:17,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:17,758 INFO:     Epoch: 64
2022-12-31 03:17:19,371 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4538304646809896, 'Total loss': 0.4538304646809896} | train loss {'Reaction outcome loss': 0.12565133661154088, 'Total loss': 0.12565133661154088}
2022-12-31 03:17:19,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:19,372 INFO:     Epoch: 65
2022-12-31 03:17:20,982 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45493730455636977, 'Total loss': 0.45493730455636977} | train loss {'Reaction outcome loss': 0.1260189057572534, 'Total loss': 0.1260189057572534}
2022-12-31 03:17:20,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:20,983 INFO:     Epoch: 66
2022-12-31 03:17:22,639 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4996374626954397, 'Total loss': 0.4996374626954397} | train loss {'Reaction outcome loss': 0.1283116956720686, 'Total loss': 0.1283116956720686}
2022-12-31 03:17:22,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:22,639 INFO:     Epoch: 67
2022-12-31 03:17:24,247 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4942198624213537, 'Total loss': 0.4942198624213537} | train loss {'Reaction outcome loss': 0.12340725260535187, 'Total loss': 0.12340725260535187}
2022-12-31 03:17:24,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:24,247 INFO:     Epoch: 68
2022-12-31 03:17:25,900 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48899044990539553, 'Total loss': 0.48899044990539553} | train loss {'Reaction outcome loss': 0.12132293253756353, 'Total loss': 0.12132293253756353}
2022-12-31 03:17:25,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:25,901 INFO:     Epoch: 69
2022-12-31 03:17:27,507 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4943074653546015, 'Total loss': 0.4943074653546015} | train loss {'Reaction outcome loss': 0.12160207402219411, 'Total loss': 0.12160207402219411}
2022-12-31 03:17:27,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:27,508 INFO:     Epoch: 70
2022-12-31 03:17:29,162 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48316388527552284, 'Total loss': 0.48316388527552284} | train loss {'Reaction outcome loss': 0.12611301788502802, 'Total loss': 0.12611301788502802}
2022-12-31 03:17:29,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:29,164 INFO:     Epoch: 71
2022-12-31 03:17:30,762 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49057454069455464, 'Total loss': 0.49057454069455464} | train loss {'Reaction outcome loss': 0.1218107661001221, 'Total loss': 0.1218107661001221}
2022-12-31 03:17:30,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:30,763 INFO:     Epoch: 72
2022-12-31 03:17:32,414 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49843448400497437, 'Total loss': 0.49843448400497437} | train loss {'Reaction outcome loss': 0.12439289117694227, 'Total loss': 0.12439289117694227}
2022-12-31 03:17:32,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:32,415 INFO:     Epoch: 73
2022-12-31 03:17:34,023 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5031261990467707, 'Total loss': 0.5031261990467707} | train loss {'Reaction outcome loss': 0.12191225126399284, 'Total loss': 0.12191225126399284}
2022-12-31 03:17:34,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:34,023 INFO:     Epoch: 74
2022-12-31 03:17:35,676 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.484973281621933, 'Total loss': 0.484973281621933} | train loss {'Reaction outcome loss': 0.11989004778111503, 'Total loss': 0.11989004778111503}
2022-12-31 03:17:35,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:35,677 INFO:     Epoch: 75
2022-12-31 03:17:37,299 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5181527435779572, 'Total loss': 0.5181527435779572} | train loss {'Reaction outcome loss': 0.12256851877480147, 'Total loss': 0.12256851877480147}
2022-12-31 03:17:37,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:37,299 INFO:     Epoch: 76
2022-12-31 03:17:38,905 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4721753478050232, 'Total loss': 0.4721753478050232} | train loss {'Reaction outcome loss': 0.11653279423387382, 'Total loss': 0.11653279423387382}
2022-12-31 03:17:38,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:38,905 INFO:     Epoch: 77
2022-12-31 03:17:40,533 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.465072559316953, 'Total loss': 0.465072559316953} | train loss {'Reaction outcome loss': 0.11831297408313537, 'Total loss': 0.11831297408313537}
2022-12-31 03:17:40,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:40,533 INFO:     Epoch: 78
2022-12-31 03:17:42,145 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4565356343984604, 'Total loss': 0.4565356343984604} | train loss {'Reaction outcome loss': 0.11658901228046004, 'Total loss': 0.11658901228046004}
2022-12-31 03:17:42,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:42,145 INFO:     Epoch: 79
2022-12-31 03:17:43,754 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44255397518475853, 'Total loss': 0.44255397518475853} | train loss {'Reaction outcome loss': 0.117856972895046, 'Total loss': 0.117856972895046}
2022-12-31 03:17:43,754 INFO:     Found new best model at epoch 79
2022-12-31 03:17:43,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:43,755 INFO:     Epoch: 80
2022-12-31 03:17:45,365 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4487318329513073, 'Total loss': 0.4487318329513073} | train loss {'Reaction outcome loss': 0.11232865279723965, 'Total loss': 0.11232865279723965}
2022-12-31 03:17:45,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:45,365 INFO:     Epoch: 81
2022-12-31 03:17:46,971 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4797137419382731, 'Total loss': 0.4797137419382731} | train loss {'Reaction outcome loss': 0.11286060822903295, 'Total loss': 0.11286060822903295}
2022-12-31 03:17:46,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:46,971 INFO:     Epoch: 82
2022-12-31 03:17:48,577 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48243270119031273, 'Total loss': 0.48243270119031273} | train loss {'Reaction outcome loss': 0.12159164782008496, 'Total loss': 0.12159164782008496}
2022-12-31 03:17:48,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:48,578 INFO:     Epoch: 83
2022-12-31 03:17:50,191 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48770263890425364, 'Total loss': 0.48770263890425364} | train loss {'Reaction outcome loss': 0.11401695053664165, 'Total loss': 0.11401695053664165}
2022-12-31 03:17:50,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:50,191 INFO:     Epoch: 84
2022-12-31 03:17:51,805 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4973939706881841, 'Total loss': 0.4973939706881841} | train loss {'Reaction outcome loss': 0.11456918214910058, 'Total loss': 0.11456918214910058}
2022-12-31 03:17:51,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:51,805 INFO:     Epoch: 85
2022-12-31 03:17:53,417 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4766617784897486, 'Total loss': 0.4766617784897486} | train loss {'Reaction outcome loss': 0.11810616377306028, 'Total loss': 0.11810616377306028}
2022-12-31 03:17:53,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:53,417 INFO:     Epoch: 86
2022-12-31 03:17:55,021 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46123773356278736, 'Total loss': 0.46123773356278736} | train loss {'Reaction outcome loss': 0.11913195000086184, 'Total loss': 0.11913195000086184}
2022-12-31 03:17:55,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:55,022 INFO:     Epoch: 87
2022-12-31 03:17:56,636 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43362678984800973, 'Total loss': 0.43362678984800973} | train loss {'Reaction outcome loss': 0.11083616095554275, 'Total loss': 0.11083616095554275}
2022-12-31 03:17:56,636 INFO:     Found new best model at epoch 87
2022-12-31 03:17:56,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:56,637 INFO:     Epoch: 88
2022-12-31 03:17:58,242 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.471011021733284, 'Total loss': 0.471011021733284} | train loss {'Reaction outcome loss': 0.11297779752750521, 'Total loss': 0.11297779752750521}
2022-12-31 03:17:58,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:58,242 INFO:     Epoch: 89
2022-12-31 03:17:59,860 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4495351443688075, 'Total loss': 0.4495351443688075} | train loss {'Reaction outcome loss': 0.11562233659044506, 'Total loss': 0.11562233659044506}
2022-12-31 03:17:59,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:17:59,860 INFO:     Epoch: 90
2022-12-31 03:18:01,477 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4938126544157664, 'Total loss': 0.4938126544157664} | train loss {'Reaction outcome loss': 0.11558128486346644, 'Total loss': 0.11558128486346644}
2022-12-31 03:18:01,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:01,477 INFO:     Epoch: 91
2022-12-31 03:18:03,093 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5008714218934377, 'Total loss': 0.5008714218934377} | train loss {'Reaction outcome loss': 0.11392622192417455, 'Total loss': 0.11392622192417455}
2022-12-31 03:18:03,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:03,094 INFO:     Epoch: 92
2022-12-31 03:18:04,708 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45633494555950166, 'Total loss': 0.45633494555950166} | train loss {'Reaction outcome loss': 0.11124400839542657, 'Total loss': 0.11124400839542657}
2022-12-31 03:18:04,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:04,709 INFO:     Epoch: 93
2022-12-31 03:18:06,315 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5082414815823237, 'Total loss': 0.5082414815823237} | train loss {'Reaction outcome loss': 0.11115841512112831, 'Total loss': 0.11115841512112831}
2022-12-31 03:18:06,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:06,315 INFO:     Epoch: 94
2022-12-31 03:18:07,932 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45650707979997, 'Total loss': 0.45650707979997} | train loss {'Reaction outcome loss': 0.1157194807578259, 'Total loss': 0.1157194807578259}
2022-12-31 03:18:07,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:07,932 INFO:     Epoch: 95
2022-12-31 03:18:09,552 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4856848468383153, 'Total loss': 0.4856848468383153} | train loss {'Reaction outcome loss': 0.11683471340271406, 'Total loss': 0.11683471340271406}
2022-12-31 03:18:09,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:09,552 INFO:     Epoch: 96
2022-12-31 03:18:11,174 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46031078894933064, 'Total loss': 0.46031078894933064} | train loss {'Reaction outcome loss': 0.11358465811230894, 'Total loss': 0.11358465811230894}
2022-12-31 03:18:11,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:11,175 INFO:     Epoch: 97
2022-12-31 03:18:12,794 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47839486996332803, 'Total loss': 0.47839486996332803} | train loss {'Reaction outcome loss': 0.11651481938952865, 'Total loss': 0.11651481938952865}
2022-12-31 03:18:12,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:12,794 INFO:     Epoch: 98
2022-12-31 03:18:14,391 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4805703192949295, 'Total loss': 0.4805703192949295} | train loss {'Reaction outcome loss': 0.11163471737557029, 'Total loss': 0.11163471737557029}
2022-12-31 03:18:14,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:14,391 INFO:     Epoch: 99
2022-12-31 03:18:16,016 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4501663496096929, 'Total loss': 0.4501663496096929} | train loss {'Reaction outcome loss': 0.1038176280609502, 'Total loss': 0.1038176280609502}
2022-12-31 03:18:16,016 INFO:     Best model found after epoch 88 of 100.
2022-12-31 03:18:16,017 INFO:   Done with stage: TRAINING
2022-12-31 03:18:16,017 INFO:   Starting stage: EVALUATION
2022-12-31 03:18:16,153 INFO:   Done with stage: EVALUATION
2022-12-31 03:18:16,153 INFO:   Leaving out SEQ value Fold_3
2022-12-31 03:18:16,166 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 03:18:16,166 INFO:   Starting stage: FEATURE SCALING
2022-12-31 03:18:16,807 INFO:   Done with stage: FEATURE SCALING
2022-12-31 03:18:16,807 INFO:   Starting stage: SCALING TARGETS
2022-12-31 03:18:16,879 INFO:   Done with stage: SCALING TARGETS
2022-12-31 03:18:16,879 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:18:16,879 INFO:     No hyperparam tuning for this model
2022-12-31 03:18:16,879 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:18:16,880 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 03:18:16,880 INFO:     None feature selector for col prot
2022-12-31 03:18:16,880 INFO:     None feature selector for col prot
2022-12-31 03:18:16,880 INFO:     None feature selector for col prot
2022-12-31 03:18:16,881 INFO:     None feature selector for col chem
2022-12-31 03:18:16,881 INFO:     None feature selector for col chem
2022-12-31 03:18:16,881 INFO:     None feature selector for col chem
2022-12-31 03:18:16,881 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 03:18:16,881 INFO:   Starting stage: BUILD MODEL
2022-12-31 03:18:16,883 INFO:     Number of params in model 224011
2022-12-31 03:18:16,886 INFO:   Done with stage: BUILD MODEL
2022-12-31 03:18:16,886 INFO:   Starting stage: TRAINING
2022-12-31 03:18:16,932 INFO:     Val loss before train {'Reaction outcome loss': 0.9713932315508524, 'Total loss': 0.9713932315508524}
2022-12-31 03:18:16,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:16,932 INFO:     Epoch: 0
2022-12-31 03:18:18,538 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5350144823392232, 'Total loss': 0.5350144823392232} | train loss {'Reaction outcome loss': 0.7770344772181668, 'Total loss': 0.7770344772181668}
2022-12-31 03:18:18,538 INFO:     Found new best model at epoch 0
2022-12-31 03:18:18,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:18,539 INFO:     Epoch: 1
2022-12-31 03:18:20,142 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.550930509964625, 'Total loss': 0.550930509964625} | train loss {'Reaction outcome loss': 0.49201327327625216, 'Total loss': 0.49201327327625216}
2022-12-31 03:18:20,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:20,142 INFO:     Epoch: 2
2022-12-31 03:18:21,771 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.51577561100324, 'Total loss': 0.51577561100324} | train loss {'Reaction outcome loss': 0.4296254494906345, 'Total loss': 0.4296254494906345}
2022-12-31 03:18:21,771 INFO:     Found new best model at epoch 2
2022-12-31 03:18:21,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:21,772 INFO:     Epoch: 3
2022-12-31 03:18:23,384 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4817674358685811, 'Total loss': 0.4817674358685811} | train loss {'Reaction outcome loss': 0.394097795798665, 'Total loss': 0.394097795798665}
2022-12-31 03:18:23,385 INFO:     Found new best model at epoch 3
2022-12-31 03:18:23,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:23,386 INFO:     Epoch: 4
2022-12-31 03:18:24,985 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47716445426146187, 'Total loss': 0.47716445426146187} | train loss {'Reaction outcome loss': 0.370285811932969, 'Total loss': 0.370285811932969}
2022-12-31 03:18:24,985 INFO:     Found new best model at epoch 4
2022-12-31 03:18:24,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:24,986 INFO:     Epoch: 5
2022-12-31 03:18:26,625 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4542360762755076, 'Total loss': 0.4542360762755076} | train loss {'Reaction outcome loss': 0.3477666396306548, 'Total loss': 0.3477666396306548}
2022-12-31 03:18:26,625 INFO:     Found new best model at epoch 5
2022-12-31 03:18:26,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:26,626 INFO:     Epoch: 6
2022-12-31 03:18:28,232 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49122453729311627, 'Total loss': 0.49122453729311627} | train loss {'Reaction outcome loss': 0.32610041668618117, 'Total loss': 0.32610041668618117}
2022-12-31 03:18:28,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:28,232 INFO:     Epoch: 7
2022-12-31 03:18:29,840 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4456612249215444, 'Total loss': 0.4456612249215444} | train loss {'Reaction outcome loss': 0.31227399700836384, 'Total loss': 0.31227399700836384}
2022-12-31 03:18:29,840 INFO:     Found new best model at epoch 7
2022-12-31 03:18:29,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:29,841 INFO:     Epoch: 8
2022-12-31 03:18:31,486 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4499478449424108, 'Total loss': 0.4499478449424108} | train loss {'Reaction outcome loss': 0.2937946048302528, 'Total loss': 0.2937946048302528}
2022-12-31 03:18:31,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:31,486 INFO:     Epoch: 9
2022-12-31 03:18:33,101 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46888379057248436, 'Total loss': 0.46888379057248436} | train loss {'Reaction outcome loss': 0.2818484207949577, 'Total loss': 0.2818484207949577}
2022-12-31 03:18:33,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:33,101 INFO:     Epoch: 10
2022-12-31 03:18:34,711 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43108707666397095, 'Total loss': 0.43108707666397095} | train loss {'Reaction outcome loss': 0.27301555732776833, 'Total loss': 0.27301555732776833}
2022-12-31 03:18:34,711 INFO:     Found new best model at epoch 10
2022-12-31 03:18:34,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:34,712 INFO:     Epoch: 11
2022-12-31 03:18:36,323 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43003640373547874, 'Total loss': 0.43003640373547874} | train loss {'Reaction outcome loss': 0.2610755237876932, 'Total loss': 0.2610755237876932}
2022-12-31 03:18:36,323 INFO:     Found new best model at epoch 11
2022-12-31 03:18:36,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:36,324 INFO:     Epoch: 12
2022-12-31 03:18:37,935 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4544934034347534, 'Total loss': 0.4544934034347534} | train loss {'Reaction outcome loss': 0.24732154145181834, 'Total loss': 0.24732154145181834}
2022-12-31 03:18:37,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:37,935 INFO:     Epoch: 13
2022-12-31 03:18:39,548 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45050552090009055, 'Total loss': 0.45050552090009055} | train loss {'Reaction outcome loss': 0.2429078218557841, 'Total loss': 0.2429078218557841}
2022-12-31 03:18:39,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:39,549 INFO:     Epoch: 14
2022-12-31 03:18:41,156 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4388651212056478, 'Total loss': 0.4388651212056478} | train loss {'Reaction outcome loss': 0.23264275375931037, 'Total loss': 0.23264275375931037}
2022-12-31 03:18:41,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:41,157 INFO:     Epoch: 15
2022-12-31 03:18:42,761 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4431081533432007, 'Total loss': 0.4431081533432007} | train loss {'Reaction outcome loss': 0.22626534279012855, 'Total loss': 0.22626534279012855}
2022-12-31 03:18:42,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:42,761 INFO:     Epoch: 16
2022-12-31 03:18:44,372 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46471924483776095, 'Total loss': 0.46471924483776095} | train loss {'Reaction outcome loss': 0.2213254395954229, 'Total loss': 0.2213254395954229}
2022-12-31 03:18:44,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:44,372 INFO:     Epoch: 17
2022-12-31 03:18:45,986 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42699094911416374, 'Total loss': 0.42699094911416374} | train loss {'Reaction outcome loss': 0.21566863538826997, 'Total loss': 0.21566863538826997}
2022-12-31 03:18:45,986 INFO:     Found new best model at epoch 17
2022-12-31 03:18:45,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:45,987 INFO:     Epoch: 18
2022-12-31 03:18:47,604 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4412977168957392, 'Total loss': 0.4412977168957392} | train loss {'Reaction outcome loss': 0.21094966390521536, 'Total loss': 0.21094966390521536}
2022-12-31 03:18:47,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:47,605 INFO:     Epoch: 19
2022-12-31 03:18:49,248 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4642673283815384, 'Total loss': 0.4642673283815384} | train loss {'Reaction outcome loss': 0.20250596766762655, 'Total loss': 0.20250596766762655}
2022-12-31 03:18:49,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:49,248 INFO:     Epoch: 20
2022-12-31 03:18:50,868 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42870271801948545, 'Total loss': 0.42870271801948545} | train loss {'Reaction outcome loss': 0.20084918362016863, 'Total loss': 0.20084918362016863}
2022-12-31 03:18:50,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:50,868 INFO:     Epoch: 21
2022-12-31 03:18:52,489 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4889388640721639, 'Total loss': 0.4889388640721639} | train loss {'Reaction outcome loss': 0.1938084152701137, 'Total loss': 0.1938084152701137}
2022-12-31 03:18:52,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:52,489 INFO:     Epoch: 22
2022-12-31 03:18:54,112 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4237832367420197, 'Total loss': 0.4237832367420197} | train loss {'Reaction outcome loss': 0.19060183838419206, 'Total loss': 0.19060183838419206}
2022-12-31 03:18:54,112 INFO:     Found new best model at epoch 22
2022-12-31 03:18:54,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:54,113 INFO:     Epoch: 23
2022-12-31 03:18:55,731 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4457467466592789, 'Total loss': 0.4457467466592789} | train loss {'Reaction outcome loss': 0.1885872832994103, 'Total loss': 0.1885872832994103}
2022-12-31 03:18:55,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:55,731 INFO:     Epoch: 24
2022-12-31 03:18:57,437 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4629821389913559, 'Total loss': 0.4629821389913559} | train loss {'Reaction outcome loss': 0.18568215760037357, 'Total loss': 0.18568215760037357}
2022-12-31 03:18:57,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:57,437 INFO:     Epoch: 25
2022-12-31 03:18:59,046 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4294680078824361, 'Total loss': 0.4294680078824361} | train loss {'Reaction outcome loss': 0.17895912558468052, 'Total loss': 0.17895912558468052}
2022-12-31 03:18:59,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:18:59,046 INFO:     Epoch: 26
2022-12-31 03:19:00,662 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5039539158344268, 'Total loss': 0.5039539158344268} | train loss {'Reaction outcome loss': 0.1811178965910232, 'Total loss': 0.1811178965910232}
2022-12-31 03:19:00,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:00,663 INFO:     Epoch: 27
2022-12-31 03:19:02,270 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47082741955916085, 'Total loss': 0.47082741955916085} | train loss {'Reaction outcome loss': 0.17480604417772191, 'Total loss': 0.17480604417772191}
2022-12-31 03:19:02,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:02,270 INFO:     Epoch: 28
2022-12-31 03:19:03,888 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4463882803916931, 'Total loss': 0.4463882803916931} | train loss {'Reaction outcome loss': 0.17638018219680576, 'Total loss': 0.17638018219680576}
2022-12-31 03:19:03,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:03,888 INFO:     Epoch: 29
2022-12-31 03:19:05,502 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4572217404842377, 'Total loss': 0.4572217404842377} | train loss {'Reaction outcome loss': 0.16801242561731147, 'Total loss': 0.16801242561731147}
2022-12-31 03:19:05,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:05,502 INFO:     Epoch: 30
2022-12-31 03:19:07,125 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4945993800957998, 'Total loss': 0.4945993800957998} | train loss {'Reaction outcome loss': 0.17013519717851183, 'Total loss': 0.17013519717851183}
2022-12-31 03:19:07,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:07,126 INFO:     Epoch: 31
2022-12-31 03:19:08,730 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4572337796290716, 'Total loss': 0.4572337796290716} | train loss {'Reaction outcome loss': 0.16657229556596323, 'Total loss': 0.16657229556596323}
2022-12-31 03:19:08,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:08,730 INFO:     Epoch: 32
2022-12-31 03:19:10,340 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44945130149523416, 'Total loss': 0.44945130149523416} | train loss {'Reaction outcome loss': 0.15891475403585878, 'Total loss': 0.15891475403585878}
2022-12-31 03:19:10,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:10,340 INFO:     Epoch: 33
2022-12-31 03:19:12,013 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44981196721394856, 'Total loss': 0.44981196721394856} | train loss {'Reaction outcome loss': 0.16124477237462997, 'Total loss': 0.16124477237462997}
2022-12-31 03:19:12,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:12,013 INFO:     Epoch: 34
2022-12-31 03:19:13,678 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4198205182949702, 'Total loss': 0.4198205182949702} | train loss {'Reaction outcome loss': 0.1570184494508601, 'Total loss': 0.1570184494508601}
2022-12-31 03:19:13,678 INFO:     Found new best model at epoch 34
2022-12-31 03:19:13,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:13,679 INFO:     Epoch: 35
2022-12-31 03:19:15,341 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46843772927920024, 'Total loss': 0.46843772927920024} | train loss {'Reaction outcome loss': 0.15563066043607862, 'Total loss': 0.15563066043607862}
2022-12-31 03:19:15,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:15,341 INFO:     Epoch: 36
2022-12-31 03:19:16,982 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4405449661115805, 'Total loss': 0.4405449661115805} | train loss {'Reaction outcome loss': 0.1532687150494574, 'Total loss': 0.1532687150494574}
2022-12-31 03:19:16,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:16,983 INFO:     Epoch: 37
2022-12-31 03:19:18,660 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46425481836001076, 'Total loss': 0.46425481836001076} | train loss {'Reaction outcome loss': 0.1524255473738973, 'Total loss': 0.1524255473738973}
2022-12-31 03:19:18,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:18,660 INFO:     Epoch: 38
2022-12-31 03:19:20,305 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4697044988473256, 'Total loss': 0.4697044988473256} | train loss {'Reaction outcome loss': 0.15093882163584013, 'Total loss': 0.15093882163584013}
2022-12-31 03:19:20,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:20,305 INFO:     Epoch: 39
2022-12-31 03:19:21,961 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43725215693314873, 'Total loss': 0.43725215693314873} | train loss {'Reaction outcome loss': 0.15094204863615251, 'Total loss': 0.15094204863615251}
2022-12-31 03:19:21,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:21,961 INFO:     Epoch: 40
2022-12-31 03:19:23,605 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4885973791281382, 'Total loss': 0.4885973791281382} | train loss {'Reaction outcome loss': 0.14350963842069164, 'Total loss': 0.14350963842069164}
2022-12-31 03:19:23,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:23,605 INFO:     Epoch: 41
2022-12-31 03:19:25,216 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4723691314458847, 'Total loss': 0.4723691314458847} | train loss {'Reaction outcome loss': 0.14545229010816133, 'Total loss': 0.14545229010816133}
2022-12-31 03:19:25,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:25,216 INFO:     Epoch: 42
2022-12-31 03:19:26,611 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4666471680005391, 'Total loss': 0.4666471680005391} | train loss {'Reaction outcome loss': 0.14571375168276604, 'Total loss': 0.14571375168276604}
2022-12-31 03:19:26,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:26,611 INFO:     Epoch: 43
2022-12-31 03:19:27,713 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4487797732154528, 'Total loss': 0.4487797732154528} | train loss {'Reaction outcome loss': 0.14176797590835954, 'Total loss': 0.14176797590835954}
2022-12-31 03:19:27,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:27,714 INFO:     Epoch: 44
2022-12-31 03:19:29,104 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42415059606234234, 'Total loss': 0.42415059606234234} | train loss {'Reaction outcome loss': 0.1402691460245258, 'Total loss': 0.1402691460245258}
2022-12-31 03:19:29,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:29,104 INFO:     Epoch: 45
2022-12-31 03:19:30,508 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43450711568196615, 'Total loss': 0.43450711568196615} | train loss {'Reaction outcome loss': 0.1393050645433721, 'Total loss': 0.1393050645433721}
2022-12-31 03:19:30,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:30,508 INFO:     Epoch: 46
2022-12-31 03:19:32,115 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4580689013004303, 'Total loss': 0.4580689013004303} | train loss {'Reaction outcome loss': 0.13710503487322384, 'Total loss': 0.13710503487322384}
2022-12-31 03:19:32,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:32,115 INFO:     Epoch: 47
2022-12-31 03:19:33,725 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4691073407729467, 'Total loss': 0.4691073407729467} | train loss {'Reaction outcome loss': 0.13710491257402432, 'Total loss': 0.13710491257402432}
2022-12-31 03:19:33,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:33,725 INFO:     Epoch: 48
2022-12-31 03:19:35,337 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4649052272240321, 'Total loss': 0.4649052272240321} | train loss {'Reaction outcome loss': 0.13970378628205304, 'Total loss': 0.13970378628205304}
2022-12-31 03:19:35,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:35,338 INFO:     Epoch: 49
2022-12-31 03:19:36,941 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45705747803052266, 'Total loss': 0.45705747803052266} | train loss {'Reaction outcome loss': 0.13544101473080478, 'Total loss': 0.13544101473080478}
2022-12-31 03:19:36,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:36,941 INFO:     Epoch: 50
2022-12-31 03:19:38,550 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44834580396612483, 'Total loss': 0.44834580396612483} | train loss {'Reaction outcome loss': 0.13895574170966452, 'Total loss': 0.13895574170966452}
2022-12-31 03:19:38,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:38,550 INFO:     Epoch: 51
2022-12-31 03:19:40,170 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45719017619267105, 'Total loss': 0.45719017619267105} | train loss {'Reaction outcome loss': 0.1340249093887379, 'Total loss': 0.1340249093887379}
2022-12-31 03:19:40,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:40,171 INFO:     Epoch: 52
2022-12-31 03:19:41,793 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4435394585132599, 'Total loss': 0.4435394585132599} | train loss {'Reaction outcome loss': 0.1353435954897777, 'Total loss': 0.1353435954897777}
2022-12-31 03:19:41,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:41,793 INFO:     Epoch: 53
2022-12-31 03:19:43,408 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5007084349791209, 'Total loss': 0.5007084349791209} | train loss {'Reaction outcome loss': 0.13266061471208876, 'Total loss': 0.13266061471208876}
2022-12-31 03:19:43,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:43,408 INFO:     Epoch: 54
2022-12-31 03:19:45,062 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4382231126228968, 'Total loss': 0.4382231126228968} | train loss {'Reaction outcome loss': 0.1305663805444735, 'Total loss': 0.1305663805444735}
2022-12-31 03:19:45,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:45,062 INFO:     Epoch: 55
2022-12-31 03:19:46,679 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4856537530819575, 'Total loss': 0.4856537530819575} | train loss {'Reaction outcome loss': 0.12666245174317897, 'Total loss': 0.12666245174317897}
2022-12-31 03:19:46,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:46,679 INFO:     Epoch: 56
2022-12-31 03:19:48,291 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4715842217206955, 'Total loss': 0.4715842217206955} | train loss {'Reaction outcome loss': 0.125961762663632, 'Total loss': 0.125961762663632}
2022-12-31 03:19:48,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:48,291 INFO:     Epoch: 57
2022-12-31 03:19:49,918 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4656737873951594, 'Total loss': 0.4656737873951594} | train loss {'Reaction outcome loss': 0.12825255777052308, 'Total loss': 0.12825255777052308}
2022-12-31 03:19:49,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:49,918 INFO:     Epoch: 58
2022-12-31 03:19:51,564 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4376244309047858, 'Total loss': 0.4376244309047858} | train loss {'Reaction outcome loss': 0.12439738449405183, 'Total loss': 0.12439738449405183}
2022-12-31 03:19:51,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:51,565 INFO:     Epoch: 59
2022-12-31 03:19:53,165 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49020736714204155, 'Total loss': 0.49020736714204155} | train loss {'Reaction outcome loss': 0.127422897783091, 'Total loss': 0.127422897783091}
2022-12-31 03:19:53,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:53,165 INFO:     Epoch: 60
2022-12-31 03:19:54,808 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4636369287967682, 'Total loss': 0.4636369287967682} | train loss {'Reaction outcome loss': 0.12702019319395388, 'Total loss': 0.12702019319395388}
2022-12-31 03:19:54,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:54,808 INFO:     Epoch: 61
2022-12-31 03:19:56,417 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4408728549877802, 'Total loss': 0.4408728549877802} | train loss {'Reaction outcome loss': 0.12790361612066353, 'Total loss': 0.12790361612066353}
2022-12-31 03:19:56,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:56,417 INFO:     Epoch: 62
2022-12-31 03:19:58,027 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43230067392190297, 'Total loss': 0.43230067392190297} | train loss {'Reaction outcome loss': 0.12570749413931653, 'Total loss': 0.12570749413931653}
2022-12-31 03:19:58,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:58,028 INFO:     Epoch: 63
2022-12-31 03:19:59,661 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48735853234926857, 'Total loss': 0.48735853234926857} | train loss {'Reaction outcome loss': 0.12668388192251925, 'Total loss': 0.12668388192251925}
2022-12-31 03:19:59,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:19:59,661 INFO:     Epoch: 64
2022-12-31 03:20:01,265 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5254324018955231, 'Total loss': 0.5254324018955231} | train loss {'Reaction outcome loss': 0.12487267822388819, 'Total loss': 0.12487267822388819}
2022-12-31 03:20:01,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:01,265 INFO:     Epoch: 65
2022-12-31 03:20:02,912 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4698893497387568, 'Total loss': 0.4698893497387568} | train loss {'Reaction outcome loss': 0.1277637614974336, 'Total loss': 0.1277637614974336}
2022-12-31 03:20:02,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:02,912 INFO:     Epoch: 66
2022-12-31 03:20:04,537 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48960335552692413, 'Total loss': 0.48960335552692413} | train loss {'Reaction outcome loss': 0.11935754843830598, 'Total loss': 0.11935754843830598}
2022-12-31 03:20:04,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:04,537 INFO:     Epoch: 67
2022-12-31 03:20:06,145 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44286796152591706, 'Total loss': 0.44286796152591706} | train loss {'Reaction outcome loss': 0.12145572622569326, 'Total loss': 0.12145572622569326}
2022-12-31 03:20:06,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:06,145 INFO:     Epoch: 68
2022-12-31 03:20:07,739 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4789607365926107, 'Total loss': 0.4789607365926107} | train loss {'Reaction outcome loss': 0.12171575750374396, 'Total loss': 0.12171575750374396}
2022-12-31 03:20:07,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:07,740 INFO:     Epoch: 69
2022-12-31 03:20:09,387 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5134555518627166, 'Total loss': 0.5134555518627166} | train loss {'Reaction outcome loss': 0.12051361582443228, 'Total loss': 0.12051361582443228}
2022-12-31 03:20:09,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:09,387 INFO:     Epoch: 70
2022-12-31 03:20:10,985 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48180476427078245, 'Total loss': 0.48180476427078245} | train loss {'Reaction outcome loss': 0.12660451446943013, 'Total loss': 0.12660451446943013}
2022-12-31 03:20:10,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:10,986 INFO:     Epoch: 71
2022-12-31 03:20:12,582 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.482318260272344, 'Total loss': 0.482318260272344} | train loss {'Reaction outcome loss': 0.11783915300914956, 'Total loss': 0.11783915300914956}
2022-12-31 03:20:12,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:12,582 INFO:     Epoch: 72
2022-12-31 03:20:14,192 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4916910409927368, 'Total loss': 0.4916910409927368} | train loss {'Reaction outcome loss': 0.11850624253134151, 'Total loss': 0.11850624253134151}
2022-12-31 03:20:14,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:14,193 INFO:     Epoch: 73
2022-12-31 03:20:15,801 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4991566429535548, 'Total loss': 0.4991566429535548} | train loss {'Reaction outcome loss': 0.11779339201518099, 'Total loss': 0.11779339201518099}
2022-12-31 03:20:15,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:15,801 INFO:     Epoch: 74
2022-12-31 03:20:17,420 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4938897728919983, 'Total loss': 0.4938897728919983} | train loss {'Reaction outcome loss': 0.11960649468182098, 'Total loss': 0.11960649468182098}
2022-12-31 03:20:17,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:17,420 INFO:     Epoch: 75
2022-12-31 03:20:19,066 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5203412274519602, 'Total loss': 0.5203412274519602} | train loss {'Reaction outcome loss': 0.11899779924454215, 'Total loss': 0.11899779924454215}
2022-12-31 03:20:19,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:19,067 INFO:     Epoch: 76
2022-12-31 03:20:20,667 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5236859515309333, 'Total loss': 0.5236859515309333} | train loss {'Reaction outcome loss': 0.11719534291643581, 'Total loss': 0.11719534291643581}
2022-12-31 03:20:20,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:20,667 INFO:     Epoch: 77
2022-12-31 03:20:22,308 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43182602524757385, 'Total loss': 0.43182602524757385} | train loss {'Reaction outcome loss': 0.11467449968482876, 'Total loss': 0.11467449968482876}
2022-12-31 03:20:22,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:22,309 INFO:     Epoch: 78
2022-12-31 03:20:23,918 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47566751688718795, 'Total loss': 0.47566751688718795} | train loss {'Reaction outcome loss': 0.11966661258256096, 'Total loss': 0.11966661258256096}
2022-12-31 03:20:23,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:23,918 INFO:     Epoch: 79
2022-12-31 03:20:25,521 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48206919282674787, 'Total loss': 0.48206919282674787} | train loss {'Reaction outcome loss': 0.11539076727340783, 'Total loss': 0.11539076727340783}
2022-12-31 03:20:25,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:25,521 INFO:     Epoch: 80
2022-12-31 03:20:27,113 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4279627037389825, 'Total loss': 0.4279627037389825} | train loss {'Reaction outcome loss': 0.1179832049727358, 'Total loss': 0.1179832049727358}
2022-12-31 03:20:27,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:27,113 INFO:     Epoch: 81
2022-12-31 03:20:28,761 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5134771744410197, 'Total loss': 0.5134771744410197} | train loss {'Reaction outcome loss': 0.1210742760910192, 'Total loss': 0.1210742760910192}
2022-12-31 03:20:28,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:28,761 INFO:     Epoch: 82
2022-12-31 03:20:30,360 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4492597262064616, 'Total loss': 0.4492597262064616} | train loss {'Reaction outcome loss': 0.11435579642868386, 'Total loss': 0.11435579642868386}
2022-12-31 03:20:30,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:30,360 INFO:     Epoch: 83
2022-12-31 03:20:31,982 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46124999622503915, 'Total loss': 0.46124999622503915} | train loss {'Reaction outcome loss': 0.1147474286030473, 'Total loss': 0.1147474286030473}
2022-12-31 03:20:31,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:31,983 INFO:     Epoch: 84
2022-12-31 03:20:33,588 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47709066470464073, 'Total loss': 0.47709066470464073} | train loss {'Reaction outcome loss': 0.11624823983600056, 'Total loss': 0.11624823983600056}
2022-12-31 03:20:33,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:33,588 INFO:     Epoch: 85
2022-12-31 03:20:35,182 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4713928689559301, 'Total loss': 0.4713928689559301} | train loss {'Reaction outcome loss': 0.1113262714514502, 'Total loss': 0.1113262714514502}
2022-12-31 03:20:35,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:35,182 INFO:     Epoch: 86
2022-12-31 03:20:36,781 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4429508576790492, 'Total loss': 0.4429508576790492} | train loss {'Reaction outcome loss': 0.11634781538686227, 'Total loss': 0.11634781538686227}
2022-12-31 03:20:36,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:36,781 INFO:     Epoch: 87
2022-12-31 03:20:38,428 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4631339977184931, 'Total loss': 0.4631339977184931} | train loss {'Reaction outcome loss': 0.10960880871145771, 'Total loss': 0.10960880871145771}
2022-12-31 03:20:38,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:38,429 INFO:     Epoch: 88
2022-12-31 03:20:40,076 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4780946493148804, 'Total loss': 0.4780946493148804} | train loss {'Reaction outcome loss': 0.11669725361331315, 'Total loss': 0.11669725361331315}
2022-12-31 03:20:40,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:40,076 INFO:     Epoch: 89
2022-12-31 03:20:41,686 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4627639126032591, 'Total loss': 0.4627639126032591} | train loss {'Reaction outcome loss': 0.11223883203217153, 'Total loss': 0.11223883203217153}
2022-12-31 03:20:41,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:41,686 INFO:     Epoch: 90
2022-12-31 03:20:43,314 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4278384337822596, 'Total loss': 0.4278384337822596} | train loss {'Reaction outcome loss': 0.11233388466740048, 'Total loss': 0.11233388466740048}
2022-12-31 03:20:43,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:43,315 INFO:     Epoch: 91
2022-12-31 03:20:44,946 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4764097049832344, 'Total loss': 0.4764097049832344} | train loss {'Reaction outcome loss': 0.11492094662613593, 'Total loss': 0.11492094662613593}
2022-12-31 03:20:44,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:44,946 INFO:     Epoch: 92
2022-12-31 03:20:46,582 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4680727372566859, 'Total loss': 0.4680727372566859} | train loss {'Reaction outcome loss': 0.11227096100730119, 'Total loss': 0.11227096100730119}
2022-12-31 03:20:46,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:46,583 INFO:     Epoch: 93
2022-12-31 03:20:48,230 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4337091476966937, 'Total loss': 0.4337091476966937} | train loss {'Reaction outcome loss': 0.11188189028045879, 'Total loss': 0.11188189028045879}
2022-12-31 03:20:48,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:48,230 INFO:     Epoch: 94
2022-12-31 03:20:49,868 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4432717541853587, 'Total loss': 0.4432717541853587} | train loss {'Reaction outcome loss': 0.1125260523951957, 'Total loss': 0.1125260523951957}
2022-12-31 03:20:49,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:49,868 INFO:     Epoch: 95
2022-12-31 03:20:51,465 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5013980001211167, 'Total loss': 0.5013980001211167} | train loss {'Reaction outcome loss': 0.10860538048048814, 'Total loss': 0.10860538048048814}
2022-12-31 03:20:51,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:51,465 INFO:     Epoch: 96
2022-12-31 03:20:53,060 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4581804066896439, 'Total loss': 0.4581804066896439} | train loss {'Reaction outcome loss': 0.10930576418772094, 'Total loss': 0.10930576418772094}
2022-12-31 03:20:53,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:53,061 INFO:     Epoch: 97
2022-12-31 03:20:54,652 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47824806372324624, 'Total loss': 0.47824806372324624} | train loss {'Reaction outcome loss': 0.11046392816432749, 'Total loss': 0.11046392816432749}
2022-12-31 03:20:54,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:54,652 INFO:     Epoch: 98
2022-12-31 03:20:56,250 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5219278129438559, 'Total loss': 0.5219278129438559} | train loss {'Reaction outcome loss': 0.1138891821246144, 'Total loss': 0.1138891821246144}
2022-12-31 03:20:56,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:56,250 INFO:     Epoch: 99
2022-12-31 03:20:57,897 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47492006023724875, 'Total loss': 0.47492006023724875} | train loss {'Reaction outcome loss': 0.11287523069906802, 'Total loss': 0.11287523069906802}
2022-12-31 03:20:57,897 INFO:     Best model found after epoch 35 of 100.
2022-12-31 03:20:57,898 INFO:   Done with stage: TRAINING
2022-12-31 03:20:57,898 INFO:   Starting stage: EVALUATION
2022-12-31 03:20:58,042 INFO:   Done with stage: EVALUATION
2022-12-31 03:20:58,042 INFO:   Leaving out SEQ value Fold_4
2022-12-31 03:20:58,054 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 03:20:58,055 INFO:   Starting stage: FEATURE SCALING
2022-12-31 03:20:58,699 INFO:   Done with stage: FEATURE SCALING
2022-12-31 03:20:58,699 INFO:   Starting stage: SCALING TARGETS
2022-12-31 03:20:58,772 INFO:   Done with stage: SCALING TARGETS
2022-12-31 03:20:58,772 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:20:58,772 INFO:     No hyperparam tuning for this model
2022-12-31 03:20:58,772 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:20:58,772 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 03:20:58,773 INFO:     None feature selector for col prot
2022-12-31 03:20:58,773 INFO:     None feature selector for col prot
2022-12-31 03:20:58,773 INFO:     None feature selector for col prot
2022-12-31 03:20:58,773 INFO:     None feature selector for col chem
2022-12-31 03:20:58,774 INFO:     None feature selector for col chem
2022-12-31 03:20:58,774 INFO:     None feature selector for col chem
2022-12-31 03:20:58,774 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 03:20:58,774 INFO:   Starting stage: BUILD MODEL
2022-12-31 03:20:58,776 INFO:     Number of params in model 224011
2022-12-31 03:20:58,779 INFO:   Done with stage: BUILD MODEL
2022-12-31 03:20:58,779 INFO:   Starting stage: TRAINING
2022-12-31 03:20:58,824 INFO:     Val loss before train {'Reaction outcome loss': 0.9922686616579691, 'Total loss': 0.9922686616579691}
2022-12-31 03:20:58,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:20:58,824 INFO:     Epoch: 0
2022-12-31 03:21:00,429 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.617928562561671, 'Total loss': 0.617928562561671} | train loss {'Reaction outcome loss': 0.7888604089291427, 'Total loss': 0.7888604089291427}
2022-12-31 03:21:00,429 INFO:     Found new best model at epoch 0
2022-12-31 03:21:00,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:00,431 INFO:     Epoch: 1
2022-12-31 03:21:02,040 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5224852502346039, 'Total loss': 0.5224852502346039} | train loss {'Reaction outcome loss': 0.5236515582804262, 'Total loss': 0.5236515582804262}
2022-12-31 03:21:02,040 INFO:     Found new best model at epoch 1
2022-12-31 03:21:02,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:02,041 INFO:     Epoch: 2
2022-12-31 03:21:03,646 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5100085020065308, 'Total loss': 0.5100085020065308} | train loss {'Reaction outcome loss': 0.44699109389181557, 'Total loss': 0.44699109389181557}
2022-12-31 03:21:03,646 INFO:     Found new best model at epoch 2
2022-12-31 03:21:03,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:03,647 INFO:     Epoch: 3
2022-12-31 03:21:05,252 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4932720084985097, 'Total loss': 0.4932720084985097} | train loss {'Reaction outcome loss': 0.4048320492933484, 'Total loss': 0.4048320492933484}
2022-12-31 03:21:05,252 INFO:     Found new best model at epoch 3
2022-12-31 03:21:05,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:05,253 INFO:     Epoch: 4
2022-12-31 03:21:06,860 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.475999387105306, 'Total loss': 0.475999387105306} | train loss {'Reaction outcome loss': 0.376183655330517, 'Total loss': 0.376183655330517}
2022-12-31 03:21:06,860 INFO:     Found new best model at epoch 4
2022-12-31 03:21:06,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:06,861 INFO:     Epoch: 5
2022-12-31 03:21:08,468 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4953990419705709, 'Total loss': 0.4953990419705709} | train loss {'Reaction outcome loss': 0.34877434038441546, 'Total loss': 0.34877434038441546}
2022-12-31 03:21:08,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:08,469 INFO:     Epoch: 6
2022-12-31 03:21:10,088 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4926880617936452, 'Total loss': 0.4926880617936452} | train loss {'Reaction outcome loss': 0.3300191224110823, 'Total loss': 0.3300191224110823}
2022-12-31 03:21:10,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:10,089 INFO:     Epoch: 7
2022-12-31 03:21:11,714 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45551586151123047, 'Total loss': 0.45551586151123047} | train loss {'Reaction outcome loss': 0.3130778695055603, 'Total loss': 0.3130778695055603}
2022-12-31 03:21:11,714 INFO:     Found new best model at epoch 7
2022-12-31 03:21:11,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:11,715 INFO:     Epoch: 8
2022-12-31 03:21:13,351 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4430429130792618, 'Total loss': 0.4430429130792618} | train loss {'Reaction outcome loss': 0.30149615434997706, 'Total loss': 0.30149615434997706}
2022-12-31 03:21:13,352 INFO:     Found new best model at epoch 8
2022-12-31 03:21:13,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:13,353 INFO:     Epoch: 9
2022-12-31 03:21:14,953 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46554973622163137, 'Total loss': 0.46554973622163137} | train loss {'Reaction outcome loss': 0.28526077547321355, 'Total loss': 0.28526077547321355}
2022-12-31 03:21:14,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:14,953 INFO:     Epoch: 10
2022-12-31 03:21:16,603 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46658142407735187, 'Total loss': 0.46658142407735187} | train loss {'Reaction outcome loss': 0.2763598017856805, 'Total loss': 0.2763598017856805}
2022-12-31 03:21:16,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:16,603 INFO:     Epoch: 11
2022-12-31 03:21:18,205 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4309228946765264, 'Total loss': 0.4309228946765264} | train loss {'Reaction outcome loss': 0.2633138916108513, 'Total loss': 0.2633138916108513}
2022-12-31 03:21:18,205 INFO:     Found new best model at epoch 11
2022-12-31 03:21:18,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:18,206 INFO:     Epoch: 12
2022-12-31 03:21:19,811 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44766291975975037, 'Total loss': 0.44766291975975037} | train loss {'Reaction outcome loss': 0.24990059325240388, 'Total loss': 0.24990059325240388}
2022-12-31 03:21:19,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:19,811 INFO:     Epoch: 13
2022-12-31 03:21:21,454 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44917440017064414, 'Total loss': 0.44917440017064414} | train loss {'Reaction outcome loss': 0.24229767294532625, 'Total loss': 0.24229767294532625}
2022-12-31 03:21:21,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:21,454 INFO:     Epoch: 14
2022-12-31 03:21:23,058 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4422109683354696, 'Total loss': 0.4422109683354696} | train loss {'Reaction outcome loss': 0.23594398582422169, 'Total loss': 0.23594398582422169}
2022-12-31 03:21:23,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:23,058 INFO:     Epoch: 15
2022-12-31 03:21:24,711 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44492433468500775, 'Total loss': 0.44492433468500775} | train loss {'Reaction outcome loss': 0.2267290514615113, 'Total loss': 0.2267290514615113}
2022-12-31 03:21:24,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:24,713 INFO:     Epoch: 16
2022-12-31 03:21:26,316 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4572471290826797, 'Total loss': 0.4572471290826797} | train loss {'Reaction outcome loss': 0.2245108085772852, 'Total loss': 0.2245108085772852}
2022-12-31 03:21:26,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:26,316 INFO:     Epoch: 17
2022-12-31 03:21:27,922 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43192348976929984, 'Total loss': 0.43192348976929984} | train loss {'Reaction outcome loss': 0.21595394673900012, 'Total loss': 0.21595394673900012}
2022-12-31 03:21:27,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:27,922 INFO:     Epoch: 18
2022-12-31 03:21:29,542 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4589893182118734, 'Total loss': 0.4589893182118734} | train loss {'Reaction outcome loss': 0.2066598179049953, 'Total loss': 0.2066598179049953}
2022-12-31 03:21:29,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:29,542 INFO:     Epoch: 19
2022-12-31 03:21:31,171 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4352495610713959, 'Total loss': 0.4352495610713959} | train loss {'Reaction outcome loss': 0.20093970532345512, 'Total loss': 0.20093970532345512}
2022-12-31 03:21:31,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:31,172 INFO:     Epoch: 20
2022-12-31 03:21:32,772 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45767938494682314, 'Total loss': 0.45767938494682314} | train loss {'Reaction outcome loss': 0.19776767275438908, 'Total loss': 0.19776767275438908}
2022-12-31 03:21:32,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:32,773 INFO:     Epoch: 21
2022-12-31 03:21:34,407 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4486960669358571, 'Total loss': 0.4486960669358571} | train loss {'Reaction outcome loss': 0.19233881369450667, 'Total loss': 0.19233881369450667}
2022-12-31 03:21:34,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:34,408 INFO:     Epoch: 22
2022-12-31 03:21:36,006 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43869451284408567, 'Total loss': 0.43869451284408567} | train loss {'Reaction outcome loss': 0.19033155864933982, 'Total loss': 0.19033155864933982}
2022-12-31 03:21:36,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:36,006 INFO:     Epoch: 23
2022-12-31 03:21:37,659 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4194895605246226, 'Total loss': 0.4194895605246226} | train loss {'Reaction outcome loss': 0.18548601967738057, 'Total loss': 0.18548601967738057}
2022-12-31 03:21:37,659 INFO:     Found new best model at epoch 23
2022-12-31 03:21:37,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:37,660 INFO:     Epoch: 24
2022-12-31 03:21:39,268 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4737886548042297, 'Total loss': 0.4737886548042297} | train loss {'Reaction outcome loss': 0.1819392950545969, 'Total loss': 0.1819392950545969}
2022-12-31 03:21:39,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:39,268 INFO:     Epoch: 25
2022-12-31 03:21:40,920 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4234277735153834, 'Total loss': 0.4234277735153834} | train loss {'Reaction outcome loss': 0.17317780304061126, 'Total loss': 0.17317780304061126}
2022-12-31 03:21:40,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:40,921 INFO:     Epoch: 26
2022-12-31 03:21:42,572 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4428553283214569, 'Total loss': 0.4428553283214569} | train loss {'Reaction outcome loss': 0.17185677946919073, 'Total loss': 0.17185677946919073}
2022-12-31 03:21:42,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:42,573 INFO:     Epoch: 27
2022-12-31 03:21:44,173 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44729391833146415, 'Total loss': 0.44729391833146415} | train loss {'Reaction outcome loss': 0.16666803452573772, 'Total loss': 0.16666803452573772}
2022-12-31 03:21:44,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:44,174 INFO:     Epoch: 28
2022-12-31 03:21:45,791 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4700268497069677, 'Total loss': 0.4700268497069677} | train loss {'Reaction outcome loss': 0.16589208344595818, 'Total loss': 0.16589208344595818}
2022-12-31 03:21:45,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:45,791 INFO:     Epoch: 29
2022-12-31 03:21:47,402 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.455719581246376, 'Total loss': 0.455719581246376} | train loss {'Reaction outcome loss': 0.1625658375700514, 'Total loss': 0.1625658375700514}
2022-12-31 03:21:47,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:47,402 INFO:     Epoch: 30
2022-12-31 03:21:49,007 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43465722948312757, 'Total loss': 0.43465722948312757} | train loss {'Reaction outcome loss': 0.16058815641831742, 'Total loss': 0.16058815641831742}
2022-12-31 03:21:49,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:49,007 INFO:     Epoch: 31
2022-12-31 03:21:50,659 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44625998934110006, 'Total loss': 0.44625998934110006} | train loss {'Reaction outcome loss': 0.1566019433713688, 'Total loss': 0.1566019433713688}
2022-12-31 03:21:50,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:50,660 INFO:     Epoch: 32
2022-12-31 03:21:52,292 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4466261645158132, 'Total loss': 0.4466261645158132} | train loss {'Reaction outcome loss': 0.1538193608892497, 'Total loss': 0.1538193608892497}
2022-12-31 03:21:52,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:52,293 INFO:     Epoch: 33
2022-12-31 03:21:53,916 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44931815564632416, 'Total loss': 0.44931815564632416} | train loss {'Reaction outcome loss': 0.15117446646896482, 'Total loss': 0.15117446646896482}
2022-12-31 03:21:53,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:53,916 INFO:     Epoch: 34
2022-12-31 03:21:55,522 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4525061776240667, 'Total loss': 0.4525061776240667} | train loss {'Reaction outcome loss': 0.15368862025589294, 'Total loss': 0.15368862025589294}
2022-12-31 03:21:55,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:55,522 INFO:     Epoch: 35
2022-12-31 03:21:57,139 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4457111756006877, 'Total loss': 0.4457111756006877} | train loss {'Reaction outcome loss': 0.14540084188695263, 'Total loss': 0.14540084188695263}
2022-12-31 03:21:57,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:57,139 INFO:     Epoch: 36
2022-12-31 03:21:58,793 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4346807743112246, 'Total loss': 0.4346807743112246} | train loss {'Reaction outcome loss': 0.14520015896563113, 'Total loss': 0.14520015896563113}
2022-12-31 03:21:58,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:21:58,793 INFO:     Epoch: 37
2022-12-31 03:22:00,450 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4651707410812378, 'Total loss': 0.4651707410812378} | train loss {'Reaction outcome loss': 0.1465312859560125, 'Total loss': 0.1465312859560125}
2022-12-31 03:22:00,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:00,452 INFO:     Epoch: 38
2022-12-31 03:22:02,064 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4727074389656385, 'Total loss': 0.4727074389656385} | train loss {'Reaction outcome loss': 0.14350608785901844, 'Total loss': 0.14350608785901844}
2022-12-31 03:22:02,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:02,065 INFO:     Epoch: 39
2022-12-31 03:22:03,700 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44579053620497383, 'Total loss': 0.44579053620497383} | train loss {'Reaction outcome loss': 0.14511141478403533, 'Total loss': 0.14511141478403533}
2022-12-31 03:22:03,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:03,701 INFO:     Epoch: 40
2022-12-31 03:22:05,355 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4481862336397171, 'Total loss': 0.4481862336397171} | train loss {'Reaction outcome loss': 0.14354316232875533, 'Total loss': 0.14354316232875533}
2022-12-31 03:22:05,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:05,355 INFO:     Epoch: 41
2022-12-31 03:22:06,968 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.460970409711202, 'Total loss': 0.460970409711202} | train loss {'Reaction outcome loss': 0.13836744418503702, 'Total loss': 0.13836744418503702}
2022-12-31 03:22:06,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:06,969 INFO:     Epoch: 42
2022-12-31 03:22:08,589 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45411912898222606, 'Total loss': 0.45411912898222606} | train loss {'Reaction outcome loss': 0.13749521143605292, 'Total loss': 0.13749521143605292}
2022-12-31 03:22:08,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:08,589 INFO:     Epoch: 43
2022-12-31 03:22:10,210 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4459479848543803, 'Total loss': 0.4459479848543803} | train loss {'Reaction outcome loss': 0.13871695549927487, 'Total loss': 0.13871695549927487}
2022-12-31 03:22:10,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:10,210 INFO:     Epoch: 44
2022-12-31 03:22:11,822 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.501946496963501, 'Total loss': 0.501946496963501} | train loss {'Reaction outcome loss': 0.13489687773161127, 'Total loss': 0.13489687773161127}
2022-12-31 03:22:11,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:11,823 INFO:     Epoch: 45
2022-12-31 03:22:13,443 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4778522292772929, 'Total loss': 0.4778522292772929} | train loss {'Reaction outcome loss': 0.13470721760098517, 'Total loss': 0.13470721760098517}
2022-12-31 03:22:13,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:13,444 INFO:     Epoch: 46
2022-12-31 03:22:15,052 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44832570950190226, 'Total loss': 0.44832570950190226} | train loss {'Reaction outcome loss': 0.13760305273543744, 'Total loss': 0.13760305273543744}
2022-12-31 03:22:15,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:15,052 INFO:     Epoch: 47
2022-12-31 03:22:16,657 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42433298627535504, 'Total loss': 0.42433298627535504} | train loss {'Reaction outcome loss': 0.1306015759210245, 'Total loss': 0.1306015759210245}
2022-12-31 03:22:16,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:16,657 INFO:     Epoch: 48
2022-12-31 03:22:18,263 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46399664084116615, 'Total loss': 0.46399664084116615} | train loss {'Reaction outcome loss': 0.12884798774284983, 'Total loss': 0.12884798774284983}
2022-12-31 03:22:18,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:18,263 INFO:     Epoch: 49
2022-12-31 03:22:19,875 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45970617135365804, 'Total loss': 0.45970617135365804} | train loss {'Reaction outcome loss': 0.1319844968698538, 'Total loss': 0.1319844968698538}
2022-12-31 03:22:19,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:19,876 INFO:     Epoch: 50
2022-12-31 03:22:21,487 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45019918084144595, 'Total loss': 0.45019918084144595} | train loss {'Reaction outcome loss': 0.13027887213057465, 'Total loss': 0.13027887213057465}
2022-12-31 03:22:21,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:21,487 INFO:     Epoch: 51
2022-12-31 03:22:23,143 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.459907466173172, 'Total loss': 0.459907466173172} | train loss {'Reaction outcome loss': 0.1315322574873856, 'Total loss': 0.1315322574873856}
2022-12-31 03:22:23,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:23,143 INFO:     Epoch: 52
2022-12-31 03:22:24,781 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44364987313747406, 'Total loss': 0.44364987313747406} | train loss {'Reaction outcome loss': 0.1286590995987619, 'Total loss': 0.1286590995987619}
2022-12-31 03:22:24,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:24,782 INFO:     Epoch: 53
2022-12-31 03:22:26,434 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47462282329797745, 'Total loss': 0.47462282329797745} | train loss {'Reaction outcome loss': 0.12908129381818056, 'Total loss': 0.12908129381818056}
2022-12-31 03:22:26,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:26,435 INFO:     Epoch: 54
2022-12-31 03:22:28,087 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.494827468196551, 'Total loss': 0.494827468196551} | train loss {'Reaction outcome loss': 0.1274242532086035, 'Total loss': 0.1274242532086035}
2022-12-31 03:22:28,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:28,087 INFO:     Epoch: 55
2022-12-31 03:22:29,739 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4387025813261668, 'Total loss': 0.4387025813261668} | train loss {'Reaction outcome loss': 0.12572883120160142, 'Total loss': 0.12572883120160142}
2022-12-31 03:22:29,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:29,739 INFO:     Epoch: 56
2022-12-31 03:22:31,360 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46514846533536913, 'Total loss': 0.46514846533536913} | train loss {'Reaction outcome loss': 0.12811793798213675, 'Total loss': 0.12811793798213675}
2022-12-31 03:22:31,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:31,360 INFO:     Epoch: 57
2022-12-31 03:22:32,983 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.448120845357577, 'Total loss': 0.448120845357577} | train loss {'Reaction outcome loss': 0.12333425206139031, 'Total loss': 0.12333425206139031}
2022-12-31 03:22:32,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:32,983 INFO:     Epoch: 58
2022-12-31 03:22:34,582 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4492357353369395, 'Total loss': 0.4492357353369395} | train loss {'Reaction outcome loss': 0.11961315483208337, 'Total loss': 0.11961315483208337}
2022-12-31 03:22:34,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:34,582 INFO:     Epoch: 59
2022-12-31 03:22:36,233 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.439571605126063, 'Total loss': 0.439571605126063} | train loss {'Reaction outcome loss': 0.11715951610533316, 'Total loss': 0.11715951610533316}
2022-12-31 03:22:36,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:36,235 INFO:     Epoch: 60
2022-12-31 03:22:37,841 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4235362003246943, 'Total loss': 0.4235362003246943} | train loss {'Reaction outcome loss': 0.12199972002311563, 'Total loss': 0.12199972002311563}
2022-12-31 03:22:37,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:37,841 INFO:     Epoch: 61
2022-12-31 03:22:39,475 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4337083985408147, 'Total loss': 0.4337083985408147} | train loss {'Reaction outcome loss': 0.12224869392506343, 'Total loss': 0.12224869392506343}
2022-12-31 03:22:39,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:39,475 INFO:     Epoch: 62
2022-12-31 03:22:41,094 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4745551347732544, 'Total loss': 0.4745551347732544} | train loss {'Reaction outcome loss': 0.1191553506264327, 'Total loss': 0.1191553506264327}
2022-12-31 03:22:41,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:41,095 INFO:     Epoch: 63
2022-12-31 03:22:42,710 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45974815885225934, 'Total loss': 0.45974815885225934} | train loss {'Reaction outcome loss': 0.12301134602863505, 'Total loss': 0.12301134602863505}
2022-12-31 03:22:42,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:42,710 INFO:     Epoch: 64
2022-12-31 03:22:44,320 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4536487927039464, 'Total loss': 0.4536487927039464} | train loss {'Reaction outcome loss': 0.1253131262356429, 'Total loss': 0.1253131262356429}
2022-12-31 03:22:44,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:44,320 INFO:     Epoch: 65
2022-12-31 03:22:45,930 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4358054568370183, 'Total loss': 0.4358054568370183} | train loss {'Reaction outcome loss': 0.12348758838017111, 'Total loss': 0.12348758838017111}
2022-12-31 03:22:45,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:45,930 INFO:     Epoch: 66
2022-12-31 03:22:47,582 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4359846591949463, 'Total loss': 0.4359846591949463} | train loss {'Reaction outcome loss': 0.12066695804666919, 'Total loss': 0.12066695804666919}
2022-12-31 03:22:47,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:47,583 INFO:     Epoch: 67
2022-12-31 03:22:49,210 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43111903170744575, 'Total loss': 0.43111903170744575} | train loss {'Reaction outcome loss': 0.12423641651012275, 'Total loss': 0.12423641651012275}
2022-12-31 03:22:49,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:49,211 INFO:     Epoch: 68
2022-12-31 03:22:50,817 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4225213666756948, 'Total loss': 0.4225213666756948} | train loss {'Reaction outcome loss': 0.11472698373390348, 'Total loss': 0.11472698373390348}
2022-12-31 03:22:50,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:50,817 INFO:     Epoch: 69
2022-12-31 03:22:52,418 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47570053339004514, 'Total loss': 0.47570053339004514} | train loss {'Reaction outcome loss': 0.11470169194865237, 'Total loss': 0.11470169194865237}
2022-12-31 03:22:52,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:52,418 INFO:     Epoch: 70
2022-12-31 03:22:54,029 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46355696121851603, 'Total loss': 0.46355696121851603} | train loss {'Reaction outcome loss': 0.11475567479046864, 'Total loss': 0.11475567479046864}
2022-12-31 03:22:54,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:54,029 INFO:     Epoch: 71
2022-12-31 03:22:55,643 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45090387264887494, 'Total loss': 0.45090387264887494} | train loss {'Reaction outcome loss': 0.11493311361851592, 'Total loss': 0.11493311361851592}
2022-12-31 03:22:55,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:55,644 INFO:     Epoch: 72
2022-12-31 03:22:57,250 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44346136252085366, 'Total loss': 0.44346136252085366} | train loss {'Reaction outcome loss': 0.11944746535210224, 'Total loss': 0.11944746535210224}
2022-12-31 03:22:57,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:57,250 INFO:     Epoch: 73
2022-12-31 03:22:58,850 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4558212737242381, 'Total loss': 0.4558212737242381} | train loss {'Reaction outcome loss': 0.11928756817679063, 'Total loss': 0.11928756817679063}
2022-12-31 03:22:58,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:22:58,850 INFO:     Epoch: 74
2022-12-31 03:23:00,492 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4670872430006663, 'Total loss': 0.4670872430006663} | train loss {'Reaction outcome loss': 0.11848775305390956, 'Total loss': 0.11848775305390956}
2022-12-31 03:23:00,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:00,493 INFO:     Epoch: 75
2022-12-31 03:23:02,098 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4738184551397959, 'Total loss': 0.4738184551397959} | train loss {'Reaction outcome loss': 0.1226428685213582, 'Total loss': 0.1226428685213582}
2022-12-31 03:23:02,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:02,098 INFO:     Epoch: 76
2022-12-31 03:23:03,750 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43209251513083774, 'Total loss': 0.43209251513083774} | train loss {'Reaction outcome loss': 0.11925411731494169, 'Total loss': 0.11925411731494169}
2022-12-31 03:23:03,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:03,750 INFO:     Epoch: 77
2022-12-31 03:23:05,356 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.447529536485672, 'Total loss': 0.447529536485672} | train loss {'Reaction outcome loss': 0.11078100952822852, 'Total loss': 0.11078100952822852}
2022-12-31 03:23:05,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:05,356 INFO:     Epoch: 78
2022-12-31 03:23:06,967 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4709368149439494, 'Total loss': 0.4709368149439494} | train loss {'Reaction outcome loss': 0.11186908356281147, 'Total loss': 0.11186908356281147}
2022-12-31 03:23:06,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:06,967 INFO:     Epoch: 79
2022-12-31 03:23:08,619 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5171561747789383, 'Total loss': 0.5171561747789383} | train loss {'Reaction outcome loss': 0.1145517415074754, 'Total loss': 0.1145517415074754}
2022-12-31 03:23:08,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:08,619 INFO:     Epoch: 80
2022-12-31 03:23:10,220 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4579533110062281, 'Total loss': 0.4579533110062281} | train loss {'Reaction outcome loss': 0.11911849946932473, 'Total loss': 0.11911849946932473}
2022-12-31 03:23:10,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:10,220 INFO:     Epoch: 81
2022-12-31 03:23:11,873 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43656686196724576, 'Total loss': 0.43656686196724576} | train loss {'Reaction outcome loss': 0.11153758713808998, 'Total loss': 0.11153758713808998}
2022-12-31 03:23:11,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:11,874 INFO:     Epoch: 82
2022-12-31 03:23:13,479 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4421034663915634, 'Total loss': 0.4421034663915634} | train loss {'Reaction outcome loss': 0.11375328054631224, 'Total loss': 0.11375328054631224}
2022-12-31 03:23:13,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:13,479 INFO:     Epoch: 83
2022-12-31 03:23:15,131 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46829042037328084, 'Total loss': 0.46829042037328084} | train loss {'Reaction outcome loss': 0.10792752625429188, 'Total loss': 0.10792752625429188}
2022-12-31 03:23:15,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:15,131 INFO:     Epoch: 84
2022-12-31 03:23:16,744 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44541388054688774, 'Total loss': 0.44541388054688774} | train loss {'Reaction outcome loss': 0.10728061814150046, 'Total loss': 0.10728061814150046}
2022-12-31 03:23:16,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:16,745 INFO:     Epoch: 85
2022-12-31 03:23:18,397 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4552058090766271, 'Total loss': 0.4552058090766271} | train loss {'Reaction outcome loss': 0.10794335842322912, 'Total loss': 0.10794335842322912}
2022-12-31 03:23:18,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:18,398 INFO:     Epoch: 86
2022-12-31 03:23:20,007 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45364604343970616, 'Total loss': 0.45364604343970616} | train loss {'Reaction outcome loss': 0.10866025974634137, 'Total loss': 0.10866025974634137}
2022-12-31 03:23:20,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:20,007 INFO:     Epoch: 87
2022-12-31 03:23:21,659 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4442959229151408, 'Total loss': 0.4442959229151408} | train loss {'Reaction outcome loss': 0.11092435232751126, 'Total loss': 0.11092435232751126}
2022-12-31 03:23:21,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:21,660 INFO:     Epoch: 88
2022-12-31 03:23:23,270 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4333970973889033, 'Total loss': 0.4333970973889033} | train loss {'Reaction outcome loss': 0.11503372644711571, 'Total loss': 0.11503372644711571}
2022-12-31 03:23:23,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:23,270 INFO:     Epoch: 89
2022-12-31 03:23:24,911 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44603177209695183, 'Total loss': 0.44603177209695183} | train loss {'Reaction outcome loss': 0.1103607440098821, 'Total loss': 0.1103607440098821}
2022-12-31 03:23:24,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:24,911 INFO:     Epoch: 90
2022-12-31 03:23:26,588 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4543694943189621, 'Total loss': 0.4543694943189621} | train loss {'Reaction outcome loss': 0.11135838772374185, 'Total loss': 0.11135838772374185}
2022-12-31 03:23:26,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:26,588 INFO:     Epoch: 91
2022-12-31 03:23:28,206 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4505007932583491, 'Total loss': 0.4505007932583491} | train loss {'Reaction outcome loss': 0.10852297959954607, 'Total loss': 0.10852297959954607}
2022-12-31 03:23:28,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:28,206 INFO:     Epoch: 92
2022-12-31 03:23:29,813 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4745864192644755, 'Total loss': 0.4745864192644755} | train loss {'Reaction outcome loss': 0.11097695331265946, 'Total loss': 0.11097695331265946}
2022-12-31 03:23:29,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:29,813 INFO:     Epoch: 93
2022-12-31 03:23:31,421 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4523308426141739, 'Total loss': 0.4523308426141739} | train loss {'Reaction outcome loss': 0.10748900796871387, 'Total loss': 0.10748900796871387}
2022-12-31 03:23:31,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:31,422 INFO:     Epoch: 94
2022-12-31 03:23:33,031 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4731198271115621, 'Total loss': 0.4731198271115621} | train loss {'Reaction outcome loss': 0.1071380458374501, 'Total loss': 0.1071380458374501}
2022-12-31 03:23:33,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:33,031 INFO:     Epoch: 95
2022-12-31 03:23:34,640 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45201636155446373, 'Total loss': 0.45201636155446373} | train loss {'Reaction outcome loss': 0.10312448381565266, 'Total loss': 0.10312448381565266}
2022-12-31 03:23:34,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:34,640 INFO:     Epoch: 96
2022-12-31 03:23:36,246 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4580534040927887, 'Total loss': 0.4580534040927887} | train loss {'Reaction outcome loss': 0.1065011670095778, 'Total loss': 0.1065011670095778}
2022-12-31 03:23:36,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:36,247 INFO:     Epoch: 97
2022-12-31 03:23:37,869 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4601332902908325, 'Total loss': 0.4601332902908325} | train loss {'Reaction outcome loss': 0.11226335172643409, 'Total loss': 0.11226335172643409}
2022-12-31 03:23:37,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:37,869 INFO:     Epoch: 98
2022-12-31 03:23:39,480 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4696288973093033, 'Total loss': 0.4696288973093033} | train loss {'Reaction outcome loss': 0.10917376548079026, 'Total loss': 0.10917376548079026}
2022-12-31 03:23:39,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:39,480 INFO:     Epoch: 99
2022-12-31 03:23:41,133 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47705543438593545, 'Total loss': 0.47705543438593545} | train loss {'Reaction outcome loss': 0.10395547235979406, 'Total loss': 0.10395547235979406}
2022-12-31 03:23:41,133 INFO:     Best model found after epoch 24 of 100.
2022-12-31 03:23:41,133 INFO:   Done with stage: TRAINING
2022-12-31 03:23:41,133 INFO:   Starting stage: EVALUATION
2022-12-31 03:23:41,267 INFO:   Done with stage: EVALUATION
2022-12-31 03:23:41,268 INFO:   Leaving out SEQ value Fold_5
2022-12-31 03:23:41,280 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 03:23:41,280 INFO:   Starting stage: FEATURE SCALING
2022-12-31 03:23:41,952 INFO:   Done with stage: FEATURE SCALING
2022-12-31 03:23:41,953 INFO:   Starting stage: SCALING TARGETS
2022-12-31 03:23:42,025 INFO:   Done with stage: SCALING TARGETS
2022-12-31 03:23:42,025 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:23:42,025 INFO:     No hyperparam tuning for this model
2022-12-31 03:23:42,025 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:23:42,025 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 03:23:42,026 INFO:     None feature selector for col prot
2022-12-31 03:23:42,026 INFO:     None feature selector for col prot
2022-12-31 03:23:42,026 INFO:     None feature selector for col prot
2022-12-31 03:23:42,027 INFO:     None feature selector for col chem
2022-12-31 03:23:42,027 INFO:     None feature selector for col chem
2022-12-31 03:23:42,027 INFO:     None feature selector for col chem
2022-12-31 03:23:42,027 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 03:23:42,027 INFO:   Starting stage: BUILD MODEL
2022-12-31 03:23:42,029 INFO:     Number of params in model 224011
2022-12-31 03:23:42,032 INFO:   Done with stage: BUILD MODEL
2022-12-31 03:23:42,032 INFO:   Starting stage: TRAINING
2022-12-31 03:23:42,077 INFO:     Val loss before train {'Reaction outcome loss': 1.0715654532114665, 'Total loss': 1.0715654532114665}
2022-12-31 03:23:42,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:42,077 INFO:     Epoch: 0
2022-12-31 03:23:43,711 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6307788054148357, 'Total loss': 0.6307788054148357} | train loss {'Reaction outcome loss': 0.7657825300011082, 'Total loss': 0.7657825300011082}
2022-12-31 03:23:43,711 INFO:     Found new best model at epoch 0
2022-12-31 03:23:43,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:43,712 INFO:     Epoch: 1
2022-12-31 03:23:45,325 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5313648025194804, 'Total loss': 0.5313648025194804} | train loss {'Reaction outcome loss': 0.5147546525147029, 'Total loss': 0.5147546525147029}
2022-12-31 03:23:45,325 INFO:     Found new best model at epoch 1
2022-12-31 03:23:45,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:45,326 INFO:     Epoch: 2
2022-12-31 03:23:46,937 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49261187116305033, 'Total loss': 0.49261187116305033} | train loss {'Reaction outcome loss': 0.4506823337582898, 'Total loss': 0.4506823337582898}
2022-12-31 03:23:46,937 INFO:     Found new best model at epoch 2
2022-12-31 03:23:46,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:46,938 INFO:     Epoch: 3
2022-12-31 03:23:48,555 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4994896630446116, 'Total loss': 0.4994896630446116} | train loss {'Reaction outcome loss': 0.4150708212206761, 'Total loss': 0.4150708212206761}
2022-12-31 03:23:48,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:48,556 INFO:     Epoch: 4
2022-12-31 03:23:50,173 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4426005959510803, 'Total loss': 0.4426005959510803} | train loss {'Reaction outcome loss': 0.39287187341108, 'Total loss': 0.39287187341108}
2022-12-31 03:23:50,173 INFO:     Found new best model at epoch 4
2022-12-31 03:23:50,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:50,174 INFO:     Epoch: 5
2022-12-31 03:23:51,795 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43601523836453754, 'Total loss': 0.43601523836453754} | train loss {'Reaction outcome loss': 0.35957918876690953, 'Total loss': 0.35957918876690953}
2022-12-31 03:23:51,795 INFO:     Found new best model at epoch 5
2022-12-31 03:23:51,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:51,796 INFO:     Epoch: 6
2022-12-31 03:23:53,410 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4063137392203013, 'Total loss': 0.4063137392203013} | train loss {'Reaction outcome loss': 0.33793622781471955, 'Total loss': 0.33793622781471955}
2022-12-31 03:23:53,410 INFO:     Found new best model at epoch 6
2022-12-31 03:23:53,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:53,411 INFO:     Epoch: 7
2022-12-31 03:23:55,020 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42537006735801697, 'Total loss': 0.42537006735801697} | train loss {'Reaction outcome loss': 0.31778441044667305, 'Total loss': 0.31778441044667305}
2022-12-31 03:23:55,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:55,020 INFO:     Epoch: 8
2022-12-31 03:23:56,635 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.38682949443658193, 'Total loss': 0.38682949443658193} | train loss {'Reaction outcome loss': 0.30332746767047525, 'Total loss': 0.30332746767047525}
2022-12-31 03:23:56,635 INFO:     Found new best model at epoch 8
2022-12-31 03:23:56,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:56,636 INFO:     Epoch: 9
2022-12-31 03:23:58,248 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3875606079896291, 'Total loss': 0.3875606079896291} | train loss {'Reaction outcome loss': 0.29250335331628285, 'Total loss': 0.29250335331628285}
2022-12-31 03:23:58,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:58,249 INFO:     Epoch: 10
2022-12-31 03:23:59,861 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3902705003817876, 'Total loss': 0.3902705003817876} | train loss {'Reaction outcome loss': 0.284704579256367, 'Total loss': 0.284704579256367}
2022-12-31 03:23:59,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:23:59,862 INFO:     Epoch: 11
2022-12-31 03:24:01,510 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41924633383750914, 'Total loss': 0.41924633383750914} | train loss {'Reaction outcome loss': 0.27353445061759185, 'Total loss': 0.27353445061759185}
2022-12-31 03:24:01,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:01,511 INFO:     Epoch: 12
2022-12-31 03:24:03,126 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3824850822488467, 'Total loss': 0.3824850822488467} | train loss {'Reaction outcome loss': 0.26003988849781995, 'Total loss': 0.26003988849781995}
2022-12-31 03:24:03,126 INFO:     Found new best model at epoch 12
2022-12-31 03:24:03,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:03,127 INFO:     Epoch: 13
2022-12-31 03:24:04,744 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.398394975066185, 'Total loss': 0.398394975066185} | train loss {'Reaction outcome loss': 0.25107884898755833, 'Total loss': 0.25107884898755833}
2022-12-31 03:24:04,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:04,744 INFO:     Epoch: 14
2022-12-31 03:24:06,406 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4068368971347809, 'Total loss': 0.4068368971347809} | train loss {'Reaction outcome loss': 0.24170244512134703, 'Total loss': 0.24170244512134703}
2022-12-31 03:24:06,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:06,406 INFO:     Epoch: 15
2022-12-31 03:24:08,022 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3812357584635417, 'Total loss': 0.3812357584635417} | train loss {'Reaction outcome loss': 0.23446197846678316, 'Total loss': 0.23446197846678316}
2022-12-31 03:24:08,022 INFO:     Found new best model at epoch 15
2022-12-31 03:24:08,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:08,023 INFO:     Epoch: 16
2022-12-31 03:24:09,636 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39475749830404916, 'Total loss': 0.39475749830404916} | train loss {'Reaction outcome loss': 0.22520691484374844, 'Total loss': 0.22520691484374844}
2022-12-31 03:24:09,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:09,636 INFO:     Epoch: 17
2022-12-31 03:24:11,245 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39511390328407286, 'Total loss': 0.39511390328407286} | train loss {'Reaction outcome loss': 0.22082206358512244, 'Total loss': 0.22082206358512244}
2022-12-31 03:24:11,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:11,245 INFO:     Epoch: 18
2022-12-31 03:24:12,900 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.37036257609725, 'Total loss': 0.37036257609725} | train loss {'Reaction outcome loss': 0.2142961245840854, 'Total loss': 0.2142961245840854}
2022-12-31 03:24:12,900 INFO:     Found new best model at epoch 18
2022-12-31 03:24:12,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:12,901 INFO:     Epoch: 19
2022-12-31 03:24:14,523 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3876356154680252, 'Total loss': 0.3876356154680252} | train loss {'Reaction outcome loss': 0.20904505614231786, 'Total loss': 0.20904505614231786}
2022-12-31 03:24:14,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:14,523 INFO:     Epoch: 20
2022-12-31 03:24:16,148 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3699658547838529, 'Total loss': 0.3699658547838529} | train loss {'Reaction outcome loss': 0.20521543990264984, 'Total loss': 0.20521543990264984}
2022-12-31 03:24:16,148 INFO:     Found new best model at epoch 20
2022-12-31 03:24:16,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:16,149 INFO:     Epoch: 21
2022-12-31 03:24:17,774 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3894926836093267, 'Total loss': 0.3894926836093267} | train loss {'Reaction outcome loss': 0.1971174391337495, 'Total loss': 0.1971174391337495}
2022-12-31 03:24:17,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:17,776 INFO:     Epoch: 22
2022-12-31 03:24:19,399 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39828159312407174, 'Total loss': 0.39828159312407174} | train loss {'Reaction outcome loss': 0.1947371342744125, 'Total loss': 0.1947371342744125}
2022-12-31 03:24:19,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:19,399 INFO:     Epoch: 23
2022-12-31 03:24:21,061 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4068814992904663, 'Total loss': 0.4068814992904663} | train loss {'Reaction outcome loss': 0.19069815169822887, 'Total loss': 0.19069815169822887}
2022-12-31 03:24:21,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:21,061 INFO:     Epoch: 24
2022-12-31 03:24:22,669 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3914453059434891, 'Total loss': 0.3914453059434891} | train loss {'Reaction outcome loss': 0.18451755581612606, 'Total loss': 0.18451755581612606}
2022-12-31 03:24:22,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:22,669 INFO:     Epoch: 25
2022-12-31 03:24:24,282 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.38179673701524736, 'Total loss': 0.38179673701524736} | train loss {'Reaction outcome loss': 0.19050308075342057, 'Total loss': 0.19050308075342057}
2022-12-31 03:24:24,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:24,283 INFO:     Epoch: 26
2022-12-31 03:24:25,894 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3761995474497477, 'Total loss': 0.3761995474497477} | train loss {'Reaction outcome loss': 0.1943395495831467, 'Total loss': 0.1943395495831467}
2022-12-31 03:24:25,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:25,894 INFO:     Epoch: 27
2022-12-31 03:24:27,505 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3751245677471161, 'Total loss': 0.3751245677471161} | train loss {'Reaction outcome loss': 0.17970183940390902, 'Total loss': 0.17970183940390902}
2022-12-31 03:24:27,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:27,505 INFO:     Epoch: 28
2022-12-31 03:24:29,156 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3948103388150533, 'Total loss': 0.3948103388150533} | train loss {'Reaction outcome loss': 0.1699165523387964, 'Total loss': 0.1699165523387964}
2022-12-31 03:24:29,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:29,157 INFO:     Epoch: 29
2022-12-31 03:24:30,771 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.363257838288943, 'Total loss': 0.363257838288943} | train loss {'Reaction outcome loss': 0.17195436163867428, 'Total loss': 0.17195436163867428}
2022-12-31 03:24:30,771 INFO:     Found new best model at epoch 29
2022-12-31 03:24:30,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:30,772 INFO:     Epoch: 30
2022-12-31 03:24:32,420 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3814711670080821, 'Total loss': 0.3814711670080821} | train loss {'Reaction outcome loss': 0.16537306918020267, 'Total loss': 0.16537306918020267}
2022-12-31 03:24:32,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:32,420 INFO:     Epoch: 31
2022-12-31 03:24:34,085 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38346213748057684, 'Total loss': 0.38346213748057684} | train loss {'Reaction outcome loss': 0.16715514612471874, 'Total loss': 0.16715514612471874}
2022-12-31 03:24:34,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:34,085 INFO:     Epoch: 32
2022-12-31 03:24:35,701 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3604361047347387, 'Total loss': 0.3604361047347387} | train loss {'Reaction outcome loss': 0.15975139408871747, 'Total loss': 0.15975139408871747}
2022-12-31 03:24:35,701 INFO:     Found new best model at epoch 32
2022-12-31 03:24:35,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:35,702 INFO:     Epoch: 33
2022-12-31 03:24:37,320 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.36029933790365853, 'Total loss': 0.36029933790365853} | train loss {'Reaction outcome loss': 0.15916296413870176, 'Total loss': 0.15916296413870176}
2022-12-31 03:24:37,321 INFO:     Found new best model at epoch 33
2022-12-31 03:24:37,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:37,322 INFO:     Epoch: 34
2022-12-31 03:24:38,988 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3769401711722215, 'Total loss': 0.3769401711722215} | train loss {'Reaction outcome loss': 0.15997448346942014, 'Total loss': 0.15997448346942014}
2022-12-31 03:24:38,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:38,988 INFO:     Epoch: 35
2022-12-31 03:24:40,610 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.36320989603797593, 'Total loss': 0.36320989603797593} | train loss {'Reaction outcome loss': 0.15586496199703898, 'Total loss': 0.15586496199703898}
2022-12-31 03:24:40,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:40,610 INFO:     Epoch: 36
2022-12-31 03:24:42,274 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37311632335186007, 'Total loss': 0.37311632335186007} | train loss {'Reaction outcome loss': 0.15822823312929898, 'Total loss': 0.15822823312929898}
2022-12-31 03:24:42,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:42,275 INFO:     Epoch: 37
2022-12-31 03:24:43,893 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3786264846722285, 'Total loss': 0.3786264846722285} | train loss {'Reaction outcome loss': 0.14987931368818533, 'Total loss': 0.14987931368818533}
2022-12-31 03:24:43,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:43,893 INFO:     Epoch: 38
2022-12-31 03:24:45,511 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3546082484225432, 'Total loss': 0.3546082484225432} | train loss {'Reaction outcome loss': 0.15115544470988782, 'Total loss': 0.15115544470988782}
2022-12-31 03:24:45,511 INFO:     Found new best model at epoch 38
2022-12-31 03:24:45,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:45,513 INFO:     Epoch: 39
2022-12-31 03:24:47,122 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3767993900304039, 'Total loss': 0.3767993900304039} | train loss {'Reaction outcome loss': 0.15235817141533978, 'Total loss': 0.15235817141533978}
2022-12-31 03:24:47,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:47,122 INFO:     Epoch: 40
2022-12-31 03:24:48,740 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41021054486433667, 'Total loss': 0.41021054486433667} | train loss {'Reaction outcome loss': 0.16575105767022225, 'Total loss': 0.16575105767022225}
2022-12-31 03:24:48,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:48,741 INFO:     Epoch: 41
2022-12-31 03:24:50,362 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3656458054979642, 'Total loss': 0.3656458054979642} | train loss {'Reaction outcome loss': 0.14466292106004877, 'Total loss': 0.14466292106004877}
2022-12-31 03:24:50,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:50,362 INFO:     Epoch: 42
2022-12-31 03:24:52,028 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3611451278130213, 'Total loss': 0.3611451278130213} | train loss {'Reaction outcome loss': 0.14287099042448445, 'Total loss': 0.14287099042448445}
2022-12-31 03:24:52,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:52,028 INFO:     Epoch: 43
2022-12-31 03:24:53,648 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.37688779532909394, 'Total loss': 0.37688779532909394} | train loss {'Reaction outcome loss': 0.145629366640355, 'Total loss': 0.145629366640355}
2022-12-31 03:24:53,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:53,648 INFO:     Epoch: 44
2022-12-31 03:24:55,271 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3646223577360312, 'Total loss': 0.3646223577360312} | train loss {'Reaction outcome loss': 0.140870265170014, 'Total loss': 0.140870265170014}
2022-12-31 03:24:55,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:55,271 INFO:     Epoch: 45
2022-12-31 03:24:56,889 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3812705640991529, 'Total loss': 0.3812705640991529} | train loss {'Reaction outcome loss': 0.14367232025192672, 'Total loss': 0.14367232025192672}
2022-12-31 03:24:56,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:56,889 INFO:     Epoch: 46
2022-12-31 03:24:58,543 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3527573630213737, 'Total loss': 0.3527573630213737} | train loss {'Reaction outcome loss': 0.13779512585803616, 'Total loss': 0.13779512585803616}
2022-12-31 03:24:58,543 INFO:     Found new best model at epoch 46
2022-12-31 03:24:58,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:24:58,544 INFO:     Epoch: 47
2022-12-31 03:25:00,210 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.36883330742518106, 'Total loss': 0.36883330742518106} | train loss {'Reaction outcome loss': 0.13891334876836112, 'Total loss': 0.13891334876836112}
2022-12-31 03:25:00,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:00,211 INFO:     Epoch: 48
2022-12-31 03:25:01,875 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3587215542793274, 'Total loss': 0.3587215542793274} | train loss {'Reaction outcome loss': 0.15756712353069577, 'Total loss': 0.15756712353069577}
2022-12-31 03:25:01,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:01,876 INFO:     Epoch: 49
2022-12-31 03:25:03,540 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40784914046525955, 'Total loss': 0.40784914046525955} | train loss {'Reaction outcome loss': 0.13986804259964603, 'Total loss': 0.13986804259964603}
2022-12-31 03:25:03,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:03,540 INFO:     Epoch: 50
2022-12-31 03:25:05,179 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41445564130942025, 'Total loss': 0.41445564130942025} | train loss {'Reaction outcome loss': 0.1351692786514489, 'Total loss': 0.1351692786514489}
2022-12-31 03:25:05,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:05,179 INFO:     Epoch: 51
2022-12-31 03:25:06,843 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3618865430355072, 'Total loss': 0.3618865430355072} | train loss {'Reaction outcome loss': 0.13616871978223755, 'Total loss': 0.13616871978223755}
2022-12-31 03:25:06,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:06,843 INFO:     Epoch: 52
2022-12-31 03:25:08,492 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42362939318021137, 'Total loss': 0.42362939318021137} | train loss {'Reaction outcome loss': 0.1350889156366474, 'Total loss': 0.1350889156366474}
2022-12-31 03:25:08,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:08,493 INFO:     Epoch: 53
2022-12-31 03:25:10,112 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3830608050028483, 'Total loss': 0.3830608050028483} | train loss {'Reaction outcome loss': 0.1335631111497849, 'Total loss': 0.1335631111497849}
2022-12-31 03:25:10,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:10,112 INFO:     Epoch: 54
2022-12-31 03:25:11,776 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3917248477538427, 'Total loss': 0.3917248477538427} | train loss {'Reaction outcome loss': 0.13127707380065828, 'Total loss': 0.13127707380065828}
2022-12-31 03:25:11,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:11,777 INFO:     Epoch: 55
2022-12-31 03:25:13,441 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4170501589775085, 'Total loss': 0.4170501589775085} | train loss {'Reaction outcome loss': 0.12720715182312878, 'Total loss': 0.12720715182312878}
2022-12-31 03:25:13,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:13,441 INFO:     Epoch: 56
2022-12-31 03:25:15,061 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3915257980426153, 'Total loss': 0.3915257980426153} | train loss {'Reaction outcome loss': 0.1349421779166047, 'Total loss': 0.1349421779166047}
2022-12-31 03:25:15,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:15,062 INFO:     Epoch: 57
2022-12-31 03:25:16,690 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3881658454736074, 'Total loss': 0.3881658454736074} | train loss {'Reaction outcome loss': 0.13300075648146667, 'Total loss': 0.13300075648146667}
2022-12-31 03:25:16,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:16,690 INFO:     Epoch: 58
2022-12-31 03:25:18,304 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3831047649184863, 'Total loss': 0.3831047649184863} | train loss {'Reaction outcome loss': 0.1276775266466849, 'Total loss': 0.1276775266466849}
2022-12-31 03:25:18,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:18,304 INFO:     Epoch: 59
2022-12-31 03:25:19,922 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4059009745717049, 'Total loss': 0.4059009745717049} | train loss {'Reaction outcome loss': 0.1261401936318852, 'Total loss': 0.1261401936318852}
2022-12-31 03:25:19,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:19,924 INFO:     Epoch: 60
2022-12-31 03:25:21,541 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4144905313849449, 'Total loss': 0.4144905313849449} | train loss {'Reaction outcome loss': 0.12914321322054806, 'Total loss': 0.12914321322054806}
2022-12-31 03:25:21,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:21,541 INFO:     Epoch: 61
2022-12-31 03:25:23,154 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37705938468376793, 'Total loss': 0.37705938468376793} | train loss {'Reaction outcome loss': 0.1452647588923118, 'Total loss': 0.1452647588923118}
2022-12-31 03:25:23,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:23,154 INFO:     Epoch: 62
2022-12-31 03:25:24,779 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.36621462894060336, 'Total loss': 0.36621462894060336} | train loss {'Reaction outcome loss': 0.13054816928638172, 'Total loss': 0.13054816928638172}
2022-12-31 03:25:24,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:24,779 INFO:     Epoch: 63
2022-12-31 03:25:26,406 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3921023468176524, 'Total loss': 0.3921023468176524} | train loss {'Reaction outcome loss': 0.13120834507803986, 'Total loss': 0.13120834507803986}
2022-12-31 03:25:26,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:26,407 INFO:     Epoch: 64
2022-12-31 03:25:28,023 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3930779109398524, 'Total loss': 0.3930779109398524} | train loss {'Reaction outcome loss': 0.1409727369536995, 'Total loss': 0.1409727369536995}
2022-12-31 03:25:28,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:28,023 INFO:     Epoch: 65
2022-12-31 03:25:29,688 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3601291929682096, 'Total loss': 0.3601291929682096} | train loss {'Reaction outcome loss': 0.12200925004182626, 'Total loss': 0.12200925004182626}
2022-12-31 03:25:29,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:29,688 INFO:     Epoch: 66
2022-12-31 03:25:31,355 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3877706915140152, 'Total loss': 0.3877706915140152} | train loss {'Reaction outcome loss': 0.12215302106451945, 'Total loss': 0.12215302106451945}
2022-12-31 03:25:31,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:31,355 INFO:     Epoch: 67
2022-12-31 03:25:33,007 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3764606609940529, 'Total loss': 0.3764606609940529} | train loss {'Reaction outcome loss': 0.12094806965425327, 'Total loss': 0.12094806965425327}
2022-12-31 03:25:33,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:33,007 INFO:     Epoch: 68
2022-12-31 03:25:34,672 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3583638628323873, 'Total loss': 0.3583638628323873} | train loss {'Reaction outcome loss': 0.1198531014142909, 'Total loss': 0.1198531014142909}
2022-12-31 03:25:34,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:34,672 INFO:     Epoch: 69
2022-12-31 03:25:36,282 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3646274616320928, 'Total loss': 0.3646274616320928} | train loss {'Reaction outcome loss': 0.11861834491174124, 'Total loss': 0.11861834491174124}
2022-12-31 03:25:36,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:36,282 INFO:     Epoch: 70
2022-12-31 03:25:37,947 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3929841270049413, 'Total loss': 0.3929841270049413} | train loss {'Reaction outcome loss': 0.11826336248639668, 'Total loss': 0.11826336248639668}
2022-12-31 03:25:37,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:37,948 INFO:     Epoch: 71
2022-12-31 03:25:39,613 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37387237648169197, 'Total loss': 0.37387237648169197} | train loss {'Reaction outcome loss': 0.12481479015474653, 'Total loss': 0.12481479015474653}
2022-12-31 03:25:39,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:39,614 INFO:     Epoch: 72
2022-12-31 03:25:41,230 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41254943708578745, 'Total loss': 0.41254943708578745} | train loss {'Reaction outcome loss': 0.12261941674607468, 'Total loss': 0.12261941674607468}
2022-12-31 03:25:41,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:41,231 INFO:     Epoch: 73
2022-12-31 03:25:42,852 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3810719947020213, 'Total loss': 0.3810719947020213} | train loss {'Reaction outcome loss': 0.12209140263639974, 'Total loss': 0.12209140263639974}
2022-12-31 03:25:42,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:42,853 INFO:     Epoch: 74
2022-12-31 03:25:44,502 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3855243608355522, 'Total loss': 0.3855243608355522} | train loss {'Reaction outcome loss': 0.12174450889553713, 'Total loss': 0.12174450889553713}
2022-12-31 03:25:44,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:44,503 INFO:     Epoch: 75
2022-12-31 03:25:46,167 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40331651270389557, 'Total loss': 0.40331651270389557} | train loss {'Reaction outcome loss': 0.11947085492863772, 'Total loss': 0.11947085492863772}
2022-12-31 03:25:46,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:46,168 INFO:     Epoch: 76
2022-12-31 03:25:47,832 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4255911817153295, 'Total loss': 0.4255911817153295} | train loss {'Reaction outcome loss': 0.11743909118640526, 'Total loss': 0.11743909118640526}
2022-12-31 03:25:47,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:47,832 INFO:     Epoch: 77
2022-12-31 03:25:49,453 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42652398844559986, 'Total loss': 0.42652398844559986} | train loss {'Reaction outcome loss': 0.11950109026667263, 'Total loss': 0.11950109026667263}
2022-12-31 03:25:49,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:49,453 INFO:     Epoch: 78
2022-12-31 03:25:51,092 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4057386040687561, 'Total loss': 0.4057386040687561} | train loss {'Reaction outcome loss': 0.1200448072505305, 'Total loss': 0.1200448072505305}
2022-12-31 03:25:51,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:51,092 INFO:     Epoch: 79
2022-12-31 03:25:52,756 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4093833287556966, 'Total loss': 0.4093833287556966} | train loss {'Reaction outcome loss': 0.12941838307027786, 'Total loss': 0.12941838307027786}
2022-12-31 03:25:52,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:52,757 INFO:     Epoch: 80
2022-12-31 03:25:54,389 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41961479286352793, 'Total loss': 0.41961479286352793} | train loss {'Reaction outcome loss': 0.12001021167236393, 'Total loss': 0.12001021167236393}
2022-12-31 03:25:54,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:54,390 INFO:     Epoch: 81
2022-12-31 03:25:56,037 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4316595753033956, 'Total loss': 0.4316595753033956} | train loss {'Reaction outcome loss': 0.11747957164988147, 'Total loss': 0.11747957164988147}
2022-12-31 03:25:56,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:56,038 INFO:     Epoch: 82
2022-12-31 03:25:57,653 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4204727470874786, 'Total loss': 0.4204727470874786} | train loss {'Reaction outcome loss': 0.11709750887651656, 'Total loss': 0.11709750887651656}
2022-12-31 03:25:57,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:57,653 INFO:     Epoch: 83
2022-12-31 03:25:59,317 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4128859301408132, 'Total loss': 0.4128859301408132} | train loss {'Reaction outcome loss': 0.11392156505726102, 'Total loss': 0.11392156505726102}
2022-12-31 03:25:59,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:25:59,318 INFO:     Epoch: 84
2022-12-31 03:26:00,946 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41766219089428586, 'Total loss': 0.41766219089428586} | train loss {'Reaction outcome loss': 0.11623669463712587, 'Total loss': 0.11623669463712587}
2022-12-31 03:26:00,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:00,946 INFO:     Epoch: 85
2022-12-31 03:26:02,573 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40847455759843193, 'Total loss': 0.40847455759843193} | train loss {'Reaction outcome loss': 0.11995876338071379, 'Total loss': 0.11995876338071379}
2022-12-31 03:26:02,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:02,574 INFO:     Epoch: 86
2022-12-31 03:26:04,199 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38574239338437716, 'Total loss': 0.38574239338437716} | train loss {'Reaction outcome loss': 0.12019960030042769, 'Total loss': 0.12019960030042769}
2022-12-31 03:26:04,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:04,199 INFO:     Epoch: 87
2022-12-31 03:26:05,821 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42289014955361687, 'Total loss': 0.42289014955361687} | train loss {'Reaction outcome loss': 0.1161649318063333, 'Total loss': 0.1161649318063333}
2022-12-31 03:26:05,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:05,821 INFO:     Epoch: 88
2022-12-31 03:26:07,441 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41311290065447487, 'Total loss': 0.41311290065447487} | train loss {'Reaction outcome loss': 0.11285399349762357, 'Total loss': 0.11285399349762357}
2022-12-31 03:26:07,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:07,441 INFO:     Epoch: 89
2022-12-31 03:26:09,064 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39975042045116427, 'Total loss': 0.39975042045116427} | train loss {'Reaction outcome loss': 0.11521342592343412, 'Total loss': 0.11521342592343412}
2022-12-31 03:26:09,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:09,064 INFO:     Epoch: 90
2022-12-31 03:26:10,693 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3898472189903259, 'Total loss': 0.3898472189903259} | train loss {'Reaction outcome loss': 0.11433558952083568, 'Total loss': 0.11433558952083568}
2022-12-31 03:26:10,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:10,693 INFO:     Epoch: 91
2022-12-31 03:26:12,313 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4125564287106196, 'Total loss': 0.4125564287106196} | train loss {'Reaction outcome loss': 0.11843101385212335, 'Total loss': 0.11843101385212335}
2022-12-31 03:26:12,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:12,313 INFO:     Epoch: 92
2022-12-31 03:26:13,946 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.405862424770991, 'Total loss': 0.405862424770991} | train loss {'Reaction outcome loss': 0.11241145090805704, 'Total loss': 0.11241145090805704}
2022-12-31 03:26:13,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:13,946 INFO:     Epoch: 93
2022-12-31 03:26:15,575 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3821248064438502, 'Total loss': 0.3821248064438502} | train loss {'Reaction outcome loss': 0.1098569413508707, 'Total loss': 0.1098569413508707}
2022-12-31 03:26:15,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:15,576 INFO:     Epoch: 94
2022-12-31 03:26:17,202 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4323245088259379, 'Total loss': 0.4323245088259379} | train loss {'Reaction outcome loss': 0.11051815543180345, 'Total loss': 0.11051815543180345}
2022-12-31 03:26:17,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:17,202 INFO:     Epoch: 95
2022-12-31 03:26:18,822 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40704393684864043, 'Total loss': 0.40704393684864043} | train loss {'Reaction outcome loss': 0.11401293904413436, 'Total loss': 0.11401293904413436}
2022-12-31 03:26:18,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:18,822 INFO:     Epoch: 96
2022-12-31 03:26:20,439 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40152523418267566, 'Total loss': 0.40152523418267566} | train loss {'Reaction outcome loss': 0.11959986288000937, 'Total loss': 0.11959986288000937}
2022-12-31 03:26:20,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:20,439 INFO:     Epoch: 97
2022-12-31 03:26:22,056 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.417691699663798, 'Total loss': 0.417691699663798} | train loss {'Reaction outcome loss': 0.11765888495030094, 'Total loss': 0.11765888495030094}
2022-12-31 03:26:22,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:22,056 INFO:     Epoch: 98
2022-12-31 03:26:23,722 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43348378539085386, 'Total loss': 0.43348378539085386} | train loss {'Reaction outcome loss': 0.11602846723711253, 'Total loss': 0.11602846723711253}
2022-12-31 03:26:23,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:23,722 INFO:     Epoch: 99
2022-12-31 03:26:25,341 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39095252752304077, 'Total loss': 0.39095252752304077} | train loss {'Reaction outcome loss': 0.13274016915807885, 'Total loss': 0.13274016915807885}
2022-12-31 03:26:25,341 INFO:     Best model found after epoch 47 of 100.
2022-12-31 03:26:25,341 INFO:   Done with stage: TRAINING
2022-12-31 03:26:25,341 INFO:   Starting stage: EVALUATION
2022-12-31 03:26:25,472 INFO:   Done with stage: EVALUATION
2022-12-31 03:26:25,472 INFO:   Leaving out SEQ value Fold_6
2022-12-31 03:26:25,485 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 03:26:25,485 INFO:   Starting stage: FEATURE SCALING
2022-12-31 03:26:26,125 INFO:   Done with stage: FEATURE SCALING
2022-12-31 03:26:26,125 INFO:   Starting stage: SCALING TARGETS
2022-12-31 03:26:26,197 INFO:   Done with stage: SCALING TARGETS
2022-12-31 03:26:26,198 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:26:26,198 INFO:     No hyperparam tuning for this model
2022-12-31 03:26:26,198 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:26:26,198 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 03:26:26,198 INFO:     None feature selector for col prot
2022-12-31 03:26:26,199 INFO:     None feature selector for col prot
2022-12-31 03:26:26,199 INFO:     None feature selector for col prot
2022-12-31 03:26:26,199 INFO:     None feature selector for col chem
2022-12-31 03:26:26,199 INFO:     None feature selector for col chem
2022-12-31 03:26:26,199 INFO:     None feature selector for col chem
2022-12-31 03:26:26,199 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 03:26:26,199 INFO:   Starting stage: BUILD MODEL
2022-12-31 03:26:26,201 INFO:     Number of params in model 224011
2022-12-31 03:26:26,204 INFO:   Done with stage: BUILD MODEL
2022-12-31 03:26:26,205 INFO:   Starting stage: TRAINING
2022-12-31 03:26:26,248 INFO:     Val loss before train {'Reaction outcome loss': 1.054989258448283, 'Total loss': 1.054989258448283}
2022-12-31 03:26:26,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:26,249 INFO:     Epoch: 0
2022-12-31 03:26:27,869 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6253085454305013, 'Total loss': 0.6253085454305013} | train loss {'Reaction outcome loss': 0.7751338508800479, 'Total loss': 0.7751338508800479}
2022-12-31 03:26:27,869 INFO:     Found new best model at epoch 0
2022-12-31 03:26:27,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:27,870 INFO:     Epoch: 1
2022-12-31 03:26:29,491 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.540135399500529, 'Total loss': 0.540135399500529} | train loss {'Reaction outcome loss': 0.5068984316789716, 'Total loss': 0.5068984316789716}
2022-12-31 03:26:29,491 INFO:     Found new best model at epoch 1
2022-12-31 03:26:29,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:29,492 INFO:     Epoch: 2
2022-12-31 03:26:31,125 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5237355728944143, 'Total loss': 0.5237355728944143} | train loss {'Reaction outcome loss': 0.43553553091274705, 'Total loss': 0.43553553091274705}
2022-12-31 03:26:31,126 INFO:     Found new best model at epoch 2
2022-12-31 03:26:31,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:31,127 INFO:     Epoch: 3
2022-12-31 03:26:32,765 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5089937488238017, 'Total loss': 0.5089937488238017} | train loss {'Reaction outcome loss': 0.3973030862448878, 'Total loss': 0.3973030862448878}
2022-12-31 03:26:32,765 INFO:     Found new best model at epoch 3
2022-12-31 03:26:32,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:32,766 INFO:     Epoch: 4
2022-12-31 03:26:34,404 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48797581990559896, 'Total loss': 0.48797581990559896} | train loss {'Reaction outcome loss': 0.36462623693237234, 'Total loss': 0.36462623693237234}
2022-12-31 03:26:34,404 INFO:     Found new best model at epoch 4
2022-12-31 03:26:34,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:34,405 INFO:     Epoch: 5
2022-12-31 03:26:36,036 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5103755295276642, 'Total loss': 0.5103755295276642} | train loss {'Reaction outcome loss': 0.33968065289060995, 'Total loss': 0.33968065289060995}
2022-12-31 03:26:36,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:36,036 INFO:     Epoch: 6
2022-12-31 03:26:37,700 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4753414124250412, 'Total loss': 0.4753414124250412} | train loss {'Reaction outcome loss': 0.3258827217595672, 'Total loss': 0.3258827217595672}
2022-12-31 03:26:37,701 INFO:     Found new best model at epoch 6
2022-12-31 03:26:37,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:37,702 INFO:     Epoch: 7
2022-12-31 03:26:39,332 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4715167005856832, 'Total loss': 0.4715167005856832} | train loss {'Reaction outcome loss': 0.3102712295545998, 'Total loss': 0.3102712295545998}
2022-12-31 03:26:39,332 INFO:     Found new best model at epoch 7
2022-12-31 03:26:39,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:39,333 INFO:     Epoch: 8
2022-12-31 03:26:40,955 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46463916897773744, 'Total loss': 0.46463916897773744} | train loss {'Reaction outcome loss': 0.2922188313375311, 'Total loss': 0.2922188313375311}
2022-12-31 03:26:40,955 INFO:     Found new best model at epoch 8
2022-12-31 03:26:40,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:40,956 INFO:     Epoch: 9
2022-12-31 03:26:42,577 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44261214733123777, 'Total loss': 0.44261214733123777} | train loss {'Reaction outcome loss': 0.27841302117716105, 'Total loss': 0.27841302117716105}
2022-12-31 03:26:42,577 INFO:     Found new best model at epoch 9
2022-12-31 03:26:42,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:42,578 INFO:     Epoch: 10
2022-12-31 03:26:44,201 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4964597404003143, 'Total loss': 0.4964597404003143} | train loss {'Reaction outcome loss': 0.267224326030442, 'Total loss': 0.267224326030442}
2022-12-31 03:26:44,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:44,201 INFO:     Epoch: 11
2022-12-31 03:26:45,839 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45359258155028026, 'Total loss': 0.45359258155028026} | train loss {'Reaction outcome loss': 0.25598736234439623, 'Total loss': 0.25598736234439623}
2022-12-31 03:26:45,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:45,839 INFO:     Epoch: 12
2022-12-31 03:26:47,480 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4585799237092336, 'Total loss': 0.4585799237092336} | train loss {'Reaction outcome loss': 0.24479503471014302, 'Total loss': 0.24479503471014302}
2022-12-31 03:26:47,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:47,480 INFO:     Epoch: 13
2022-12-31 03:26:49,134 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4659646252791087, 'Total loss': 0.4659646252791087} | train loss {'Reaction outcome loss': 0.23633310383031084, 'Total loss': 0.23633310383031084}
2022-12-31 03:26:49,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:49,135 INFO:     Epoch: 14
2022-12-31 03:26:50,806 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4640745371580124, 'Total loss': 0.4640745371580124} | train loss {'Reaction outcome loss': 0.22986416955098563, 'Total loss': 0.22986416955098563}
2022-12-31 03:26:50,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:50,807 INFO:     Epoch: 15
2022-12-31 03:26:52,431 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44830246021350223, 'Total loss': 0.44830246021350223} | train loss {'Reaction outcome loss': 0.22402885883024454, 'Total loss': 0.22402885883024454}
2022-12-31 03:26:52,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:52,432 INFO:     Epoch: 16
2022-12-31 03:26:54,092 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4704145173231761, 'Total loss': 0.4704145173231761} | train loss {'Reaction outcome loss': 0.21531709222398726, 'Total loss': 0.21531709222398726}
2022-12-31 03:26:54,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:54,092 INFO:     Epoch: 17
2022-12-31 03:26:55,733 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44970099329948426, 'Total loss': 0.44970099329948426} | train loss {'Reaction outcome loss': 0.20774667996523183, 'Total loss': 0.20774667996523183}
2022-12-31 03:26:55,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:55,733 INFO:     Epoch: 18
2022-12-31 03:26:57,365 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4569264610608419, 'Total loss': 0.4569264610608419} | train loss {'Reaction outcome loss': 0.19772140083612624, 'Total loss': 0.19772140083612624}
2022-12-31 03:26:57,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:57,365 INFO:     Epoch: 19
2022-12-31 03:26:59,000 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4526324098308881, 'Total loss': 0.4526324098308881} | train loss {'Reaction outcome loss': 0.19081370889911906, 'Total loss': 0.19081370889911906}
2022-12-31 03:26:59,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:26:59,000 INFO:     Epoch: 20
2022-12-31 03:27:00,672 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45289730628331504, 'Total loss': 0.45289730628331504} | train loss {'Reaction outcome loss': 0.1854978591365074, 'Total loss': 0.1854978591365074}
2022-12-31 03:27:00,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:00,672 INFO:     Epoch: 21
2022-12-31 03:27:02,344 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4592798819144567, 'Total loss': 0.4592798819144567} | train loss {'Reaction outcome loss': 0.18627020401295127, 'Total loss': 0.18627020401295127}
2022-12-31 03:27:02,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:02,345 INFO:     Epoch: 22
2022-12-31 03:27:03,987 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4960949033498764, 'Total loss': 0.4960949033498764} | train loss {'Reaction outcome loss': 0.17586289398163718, 'Total loss': 0.17586289398163718}
2022-12-31 03:27:03,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:03,987 INFO:     Epoch: 23
2022-12-31 03:27:05,659 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4510203262170156, 'Total loss': 0.4510203262170156} | train loss {'Reaction outcome loss': 0.17766587387111427, 'Total loss': 0.17766587387111427}
2022-12-31 03:27:05,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:05,660 INFO:     Epoch: 24
2022-12-31 03:27:07,289 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48254019717375435, 'Total loss': 0.48254019717375435} | train loss {'Reaction outcome loss': 0.17274067498447662, 'Total loss': 0.17274067498447662}
2022-12-31 03:27:07,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:07,289 INFO:     Epoch: 25
2022-12-31 03:27:08,925 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45537311434745786, 'Total loss': 0.45537311434745786} | train loss {'Reaction outcome loss': 0.16654847842718504, 'Total loss': 0.16654847842718504}
2022-12-31 03:27:08,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:08,926 INFO:     Epoch: 26
2022-12-31 03:27:10,561 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44677758514881133, 'Total loss': 0.44677758514881133} | train loss {'Reaction outcome loss': 0.16433677937337854, 'Total loss': 0.16433677937337854}
2022-12-31 03:27:10,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:10,562 INFO:     Epoch: 27
2022-12-31 03:27:12,196 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48575409650802615, 'Total loss': 0.48575409650802615} | train loss {'Reaction outcome loss': 0.16312172610164766, 'Total loss': 0.16312172610164766}
2022-12-31 03:27:12,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:12,196 INFO:     Epoch: 28
2022-12-31 03:27:13,856 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.432433545589447, 'Total loss': 0.432433545589447} | train loss {'Reaction outcome loss': 0.15990778473995976, 'Total loss': 0.15990778473995976}
2022-12-31 03:27:13,856 INFO:     Found new best model at epoch 28
2022-12-31 03:27:13,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:13,857 INFO:     Epoch: 29
2022-12-31 03:27:15,476 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46618500153223674, 'Total loss': 0.46618500153223674} | train loss {'Reaction outcome loss': 0.15647517408274572, 'Total loss': 0.15647517408274572}
2022-12-31 03:27:15,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:15,476 INFO:     Epoch: 30
2022-12-31 03:27:17,113 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4460504998763402, 'Total loss': 0.4460504998763402} | train loss {'Reaction outcome loss': 0.15465424960102578, 'Total loss': 0.15465424960102578}
2022-12-31 03:27:17,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:17,113 INFO:     Epoch: 31
2022-12-31 03:27:18,750 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46020377477010094, 'Total loss': 0.46020377477010094} | train loss {'Reaction outcome loss': 0.15070586283405443, 'Total loss': 0.15070586283405443}
2022-12-31 03:27:18,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:18,751 INFO:     Epoch: 32
2022-12-31 03:27:20,386 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45553857485453286, 'Total loss': 0.45553857485453286} | train loss {'Reaction outcome loss': 0.14938227054646191, 'Total loss': 0.14938227054646191}
2022-12-31 03:27:20,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:20,386 INFO:     Epoch: 33
2022-12-31 03:27:22,022 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4481385250886281, 'Total loss': 0.4481385250886281} | train loss {'Reaction outcome loss': 0.14616202743596227, 'Total loss': 0.14616202743596227}
2022-12-31 03:27:22,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:22,023 INFO:     Epoch: 34
2022-12-31 03:27:23,653 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43936832348505656, 'Total loss': 0.43936832348505656} | train loss {'Reaction outcome loss': 0.14296321560786734, 'Total loss': 0.14296321560786734}
2022-12-31 03:27:23,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:23,653 INFO:     Epoch: 35
2022-12-31 03:27:25,297 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42813741515080134, 'Total loss': 0.42813741515080134} | train loss {'Reaction outcome loss': 0.14452341013329123, 'Total loss': 0.14452341013329123}
2022-12-31 03:27:25,297 INFO:     Found new best model at epoch 35
2022-12-31 03:27:25,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:25,298 INFO:     Epoch: 36
2022-12-31 03:27:26,939 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4144748985767365, 'Total loss': 0.4144748985767365} | train loss {'Reaction outcome loss': 0.1425113694839825, 'Total loss': 0.1425113694839825}
2022-12-31 03:27:26,939 INFO:     Found new best model at epoch 36
2022-12-31 03:27:26,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:26,940 INFO:     Epoch: 37
2022-12-31 03:27:28,571 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43455075671275456, 'Total loss': 0.43455075671275456} | train loss {'Reaction outcome loss': 0.13959103918698237, 'Total loss': 0.13959103918698237}
2022-12-31 03:27:28,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:28,572 INFO:     Epoch: 38
2022-12-31 03:27:30,242 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4646498292684555, 'Total loss': 0.4646498292684555} | train loss {'Reaction outcome loss': 0.13749745568186583, 'Total loss': 0.13749745568186583}
2022-12-31 03:27:30,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:30,242 INFO:     Epoch: 39
2022-12-31 03:27:31,870 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45315340360005696, 'Total loss': 0.45315340360005696} | train loss {'Reaction outcome loss': 0.14117286604449206, 'Total loss': 0.14117286604449206}
2022-12-31 03:27:31,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:31,871 INFO:     Epoch: 40
2022-12-31 03:27:33,496 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4734096199274063, 'Total loss': 0.4734096199274063} | train loss {'Reaction outcome loss': 0.13674151432945894, 'Total loss': 0.13674151432945894}
2022-12-31 03:27:33,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:33,498 INFO:     Epoch: 41
2022-12-31 03:27:35,127 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4411975502967834, 'Total loss': 0.4411975502967834} | train loss {'Reaction outcome loss': 0.1345243848732501, 'Total loss': 0.1345243848732501}
2022-12-31 03:27:35,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:35,127 INFO:     Epoch: 42
2022-12-31 03:27:36,759 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4497382263342539, 'Total loss': 0.4497382263342539} | train loss {'Reaction outcome loss': 0.1324783876565174, 'Total loss': 0.1324783876565174}
2022-12-31 03:27:36,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:36,759 INFO:     Epoch: 43
2022-12-31 03:27:38,390 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4505191852649053, 'Total loss': 0.4505191852649053} | train loss {'Reaction outcome loss': 0.1363020123012821, 'Total loss': 0.1363020123012821}
2022-12-31 03:27:38,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:38,390 INFO:     Epoch: 44
2022-12-31 03:27:40,013 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4410643219947815, 'Total loss': 0.4410643219947815} | train loss {'Reaction outcome loss': 0.13237691620896008, 'Total loss': 0.13237691620896008}
2022-12-31 03:27:40,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:40,014 INFO:     Epoch: 45
2022-12-31 03:27:41,645 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4536407063404719, 'Total loss': 0.4536407063404719} | train loss {'Reaction outcome loss': 0.13382128888357847, 'Total loss': 0.13382128888357847}
2022-12-31 03:27:41,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:41,645 INFO:     Epoch: 46
2022-12-31 03:27:43,284 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4608118325471878, 'Total loss': 0.4608118325471878} | train loss {'Reaction outcome loss': 0.12934945938295084, 'Total loss': 0.12934945938295084}
2022-12-31 03:27:43,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:43,284 INFO:     Epoch: 47
2022-12-31 03:27:44,953 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4432223270336787, 'Total loss': 0.4432223270336787} | train loss {'Reaction outcome loss': 0.1244805139432315, 'Total loss': 0.1244805139432315}
2022-12-31 03:27:44,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:44,953 INFO:     Epoch: 48
2022-12-31 03:27:46,620 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45575009485085805, 'Total loss': 0.45575009485085805} | train loss {'Reaction outcome loss': 0.1260218471725764, 'Total loss': 0.1260218471725764}
2022-12-31 03:27:46,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:46,620 INFO:     Epoch: 49
2022-12-31 03:27:48,287 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4273633477588495, 'Total loss': 0.4273633477588495} | train loss {'Reaction outcome loss': 0.12855550162964888, 'Total loss': 0.12855550162964888}
2022-12-31 03:27:48,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:48,288 INFO:     Epoch: 50
2022-12-31 03:27:49,910 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4596093783775965, 'Total loss': 0.4596093783775965} | train loss {'Reaction outcome loss': 0.12459841845826068, 'Total loss': 0.12459841845826068}
2022-12-31 03:27:49,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:49,911 INFO:     Epoch: 51
2022-12-31 03:27:51,577 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44129331409931183, 'Total loss': 0.44129331409931183} | train loss {'Reaction outcome loss': 0.12422488609476802, 'Total loss': 0.12422488609476802}
2022-12-31 03:27:51,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:51,577 INFO:     Epoch: 52
2022-12-31 03:27:53,201 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4058390974998474, 'Total loss': 0.4058390974998474} | train loss {'Reaction outcome loss': 0.12324616996174685, 'Total loss': 0.12324616996174685}
2022-12-31 03:27:53,202 INFO:     Found new best model at epoch 52
2022-12-31 03:27:53,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:53,203 INFO:     Epoch: 53
2022-12-31 03:27:54,825 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48042025764783225, 'Total loss': 0.48042025764783225} | train loss {'Reaction outcome loss': 0.12230891693006891, 'Total loss': 0.12230891693006891}
2022-12-31 03:27:54,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:54,825 INFO:     Epoch: 54
2022-12-31 03:27:56,493 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4585092494885127, 'Total loss': 0.4585092494885127} | train loss {'Reaction outcome loss': 0.12065229469503441, 'Total loss': 0.12065229469503441}
2022-12-31 03:27:56,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:56,493 INFO:     Epoch: 55
2022-12-31 03:27:58,150 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47549994190533956, 'Total loss': 0.47549994190533956} | train loss {'Reaction outcome loss': 0.12400635959587265, 'Total loss': 0.12400635959587265}
2022-12-31 03:27:58,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:58,150 INFO:     Epoch: 56
2022-12-31 03:27:59,764 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45496340493361154, 'Total loss': 0.45496340493361154} | train loss {'Reaction outcome loss': 0.12139031445331845, 'Total loss': 0.12139031445331845}
2022-12-31 03:27:59,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:27:59,764 INFO:     Epoch: 57
2022-12-31 03:28:01,412 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44657596449057263, 'Total loss': 0.44657596449057263} | train loss {'Reaction outcome loss': 0.1183175744845226, 'Total loss': 0.1183175744845226}
2022-12-31 03:28:01,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:01,412 INFO:     Epoch: 58
2022-12-31 03:28:03,047 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44912483394145963, 'Total loss': 0.44912483394145963} | train loss {'Reaction outcome loss': 0.1200553975513521, 'Total loss': 0.1200553975513521}
2022-12-31 03:28:03,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:03,048 INFO:     Epoch: 59
2022-12-31 03:28:04,682 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43080304364363353, 'Total loss': 0.43080304364363353} | train loss {'Reaction outcome loss': 0.11793044823749724, 'Total loss': 0.11793044823749724}
2022-12-31 03:28:04,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:04,683 INFO:     Epoch: 60
2022-12-31 03:28:06,318 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4528048987189929, 'Total loss': 0.4528048987189929} | train loss {'Reaction outcome loss': 0.12003258273714905, 'Total loss': 0.12003258273714905}
2022-12-31 03:28:06,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:06,319 INFO:     Epoch: 61
2022-12-31 03:28:07,947 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4487440804640452, 'Total loss': 0.4487440804640452} | train loss {'Reaction outcome loss': 0.11905387530459717, 'Total loss': 0.11905387530459717}
2022-12-31 03:28:07,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:07,949 INFO:     Epoch: 62
2022-12-31 03:28:09,583 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4809166371822357, 'Total loss': 0.4809166371822357} | train loss {'Reaction outcome loss': 0.11671094644465063, 'Total loss': 0.11671094644465063}
2022-12-31 03:28:09,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:09,583 INFO:     Epoch: 63
2022-12-31 03:28:11,209 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4449273347854614, 'Total loss': 0.4449273347854614} | train loss {'Reaction outcome loss': 0.11843887173792596, 'Total loss': 0.11843887173792596}
2022-12-31 03:28:11,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:11,209 INFO:     Epoch: 64
2022-12-31 03:28:12,844 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44818708995978035, 'Total loss': 0.44818708995978035} | train loss {'Reaction outcome loss': 0.11671351531977742, 'Total loss': 0.11671351531977742}
2022-12-31 03:28:12,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:12,845 INFO:     Epoch: 65
2022-12-31 03:28:14,478 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4486634065707525, 'Total loss': 0.4486634065707525} | train loss {'Reaction outcome loss': 0.11403913096279336, 'Total loss': 0.11403913096279336}
2022-12-31 03:28:14,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:14,479 INFO:     Epoch: 66
2022-12-31 03:28:16,114 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45814001858234404, 'Total loss': 0.45814001858234404} | train loss {'Reaction outcome loss': 0.11484939877333838, 'Total loss': 0.11484939877333838}
2022-12-31 03:28:16,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:16,114 INFO:     Epoch: 67
2022-12-31 03:28:17,743 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4489673346281052, 'Total loss': 0.4489673346281052} | train loss {'Reaction outcome loss': 0.11840901460283393, 'Total loss': 0.11840901460283393}
2022-12-31 03:28:17,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:17,743 INFO:     Epoch: 68
2022-12-31 03:28:19,371 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44237590531508125, 'Total loss': 0.44237590531508125} | train loss {'Reaction outcome loss': 0.11635654597855863, 'Total loss': 0.11635654597855863}
2022-12-31 03:28:19,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:19,372 INFO:     Epoch: 69
2022-12-31 03:28:21,017 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4455378313859304, 'Total loss': 0.4455378313859304} | train loss {'Reaction outcome loss': 0.11117538315872746, 'Total loss': 0.11117538315872746}
2022-12-31 03:28:21,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:21,017 INFO:     Epoch: 70
2022-12-31 03:28:22,685 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4423675646384557, 'Total loss': 0.4423675646384557} | train loss {'Reaction outcome loss': 0.1115809801582664, 'Total loss': 0.1115809801582664}
2022-12-31 03:28:22,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:22,685 INFO:     Epoch: 71
2022-12-31 03:28:24,352 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48253574669361116, 'Total loss': 0.48253574669361116} | train loss {'Reaction outcome loss': 0.1121028980512562, 'Total loss': 0.1121028980512562}
2022-12-31 03:28:24,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:24,353 INFO:     Epoch: 72
2022-12-31 03:28:25,971 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4746499518553416, 'Total loss': 0.4746499518553416} | train loss {'Reaction outcome loss': 0.11660143993425079, 'Total loss': 0.11660143993425079}
2022-12-31 03:28:25,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:25,971 INFO:     Epoch: 73
2022-12-31 03:28:27,637 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4634915471076965, 'Total loss': 0.4634915471076965} | train loss {'Reaction outcome loss': 0.11384784259466918, 'Total loss': 0.11384784259466918}
2022-12-31 03:28:27,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:27,638 INFO:     Epoch: 74
2022-12-31 03:28:29,251 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4434309770663579, 'Total loss': 0.4434309770663579} | train loss {'Reaction outcome loss': 0.1165041600703682, 'Total loss': 0.1165041600703682}
2022-12-31 03:28:29,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:29,251 INFO:     Epoch: 75
2022-12-31 03:28:30,910 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43580838441848757, 'Total loss': 0.43580838441848757} | train loss {'Reaction outcome loss': 0.10850341109952315, 'Total loss': 0.10850341109952315}
2022-12-31 03:28:30,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:30,911 INFO:     Epoch: 76
2022-12-31 03:28:32,546 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44530579447746277, 'Total loss': 0.44530579447746277} | train loss {'Reaction outcome loss': 0.1108777800714429, 'Total loss': 0.1108777800714429}
2022-12-31 03:28:32,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:32,547 INFO:     Epoch: 77
2022-12-31 03:28:34,181 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41257260193427403, 'Total loss': 0.41257260193427403} | train loss {'Reaction outcome loss': 0.10874500074205308, 'Total loss': 0.10874500074205308}
2022-12-31 03:28:34,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:34,182 INFO:     Epoch: 78
2022-12-31 03:28:35,803 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47879359424114226, 'Total loss': 0.47879359424114226} | train loss {'Reaction outcome loss': 0.1115851975214207, 'Total loss': 0.1115851975214207}
2022-12-31 03:28:35,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:35,803 INFO:     Epoch: 79
2022-12-31 03:28:37,423 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4826708475748698, 'Total loss': 0.4826708475748698} | train loss {'Reaction outcome loss': 0.10920148662926918, 'Total loss': 0.10920148662926918}
2022-12-31 03:28:37,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:37,423 INFO:     Epoch: 80
2022-12-31 03:28:39,038 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46137474377950033, 'Total loss': 0.46137474377950033} | train loss {'Reaction outcome loss': 0.10810746599849488, 'Total loss': 0.10810746599849488}
2022-12-31 03:28:39,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:39,038 INFO:     Epoch: 81
2022-12-31 03:28:40,675 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4732484457393487, 'Total loss': 0.4732484457393487} | train loss {'Reaction outcome loss': 0.11099511948968906, 'Total loss': 0.11099511948968906}
2022-12-31 03:28:40,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:40,675 INFO:     Epoch: 82
2022-12-31 03:28:42,302 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46868510246276857, 'Total loss': 0.46868510246276857} | train loss {'Reaction outcome loss': 0.1111535332232902, 'Total loss': 0.1111535332232902}
2022-12-31 03:28:42,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:42,302 INFO:     Epoch: 83
2022-12-31 03:28:43,951 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4321529229482015, 'Total loss': 0.4321529229482015} | train loss {'Reaction outcome loss': 0.10837894439989774, 'Total loss': 0.10837894439989774}
2022-12-31 03:28:43,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:43,953 INFO:     Epoch: 84
2022-12-31 03:28:45,578 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47825242082277936, 'Total loss': 0.47825242082277936} | train loss {'Reaction outcome loss': 0.10901754612056035, 'Total loss': 0.10901754612056035}
2022-12-31 03:28:45,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:45,578 INFO:     Epoch: 85
2022-12-31 03:28:47,197 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4662323330839475, 'Total loss': 0.4662323330839475} | train loss {'Reaction outcome loss': 0.10785579903552221, 'Total loss': 0.10785579903552221}
2022-12-31 03:28:47,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:47,197 INFO:     Epoch: 86
2022-12-31 03:28:48,856 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48418514132499696, 'Total loss': 0.48418514132499696} | train loss {'Reaction outcome loss': 0.11362860235805869, 'Total loss': 0.11362860235805869}
2022-12-31 03:28:48,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:48,856 INFO:     Epoch: 87
2022-12-31 03:28:50,475 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47240943610668185, 'Total loss': 0.47240943610668185} | train loss {'Reaction outcome loss': 0.1058257109206506, 'Total loss': 0.1058257109206506}
2022-12-31 03:28:50,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:50,475 INFO:     Epoch: 88
2022-12-31 03:28:52,092 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4774867524703344, 'Total loss': 0.4774867524703344} | train loss {'Reaction outcome loss': 0.1082856221702824, 'Total loss': 0.1082856221702824}
2022-12-31 03:28:52,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:52,093 INFO:     Epoch: 89
2022-12-31 03:28:53,715 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4635031392176946, 'Total loss': 0.4635031392176946} | train loss {'Reaction outcome loss': 0.105943745049221, 'Total loss': 0.105943745049221}
2022-12-31 03:28:53,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:53,716 INFO:     Epoch: 90
2022-12-31 03:28:55,337 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46034375925858817, 'Total loss': 0.46034375925858817} | train loss {'Reaction outcome loss': 0.11137643353324317, 'Total loss': 0.11137643353324317}
2022-12-31 03:28:55,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:55,337 INFO:     Epoch: 91
2022-12-31 03:28:56,964 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4561119616031647, 'Total loss': 0.4561119616031647} | train loss {'Reaction outcome loss': 0.10293377325231283, 'Total loss': 0.10293377325231283}
2022-12-31 03:28:56,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:56,964 INFO:     Epoch: 92
2022-12-31 03:28:58,627 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4657696634531021, 'Total loss': 0.4657696634531021} | train loss {'Reaction outcome loss': 0.10341287872901973, 'Total loss': 0.10341287872901973}
2022-12-31 03:28:58,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:28:58,627 INFO:     Epoch: 93
2022-12-31 03:29:00,296 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44604715357224145, 'Total loss': 0.44604715357224145} | train loss {'Reaction outcome loss': 0.10116081182686915, 'Total loss': 0.10116081182686915}
2022-12-31 03:29:00,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:00,296 INFO:     Epoch: 94
2022-12-31 03:29:01,924 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46066250602404274, 'Total loss': 0.46066250602404274} | train loss {'Reaction outcome loss': 0.10733252089632009, 'Total loss': 0.10733252089632009}
2022-12-31 03:29:01,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:01,924 INFO:     Epoch: 95
2022-12-31 03:29:03,551 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4625276605288188, 'Total loss': 0.4625276605288188} | train loss {'Reaction outcome loss': 0.10821147338362808, 'Total loss': 0.10821147338362808}
2022-12-31 03:29:03,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:03,552 INFO:     Epoch: 96
2022-12-31 03:29:05,182 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4878197933236758, 'Total loss': 0.4878197933236758} | train loss {'Reaction outcome loss': 0.10243058563563098, 'Total loss': 0.10243058563563098}
2022-12-31 03:29:05,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:05,182 INFO:     Epoch: 97
2022-12-31 03:29:06,812 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4284735669692357, 'Total loss': 0.4284735669692357} | train loss {'Reaction outcome loss': 0.10359615844082666, 'Total loss': 0.10359615844082666}
2022-12-31 03:29:06,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:06,812 INFO:     Epoch: 98
2022-12-31 03:29:08,435 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4403875390688578, 'Total loss': 0.4403875390688578} | train loss {'Reaction outcome loss': 0.10663763569610778, 'Total loss': 0.10663763569610778}
2022-12-31 03:29:08,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:08,435 INFO:     Epoch: 99
2022-12-31 03:29:10,090 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4373834729194641, 'Total loss': 0.4373834729194641} | train loss {'Reaction outcome loss': 0.10781366087114674, 'Total loss': 0.10781366087114674}
2022-12-31 03:29:10,090 INFO:     Best model found after epoch 53 of 100.
2022-12-31 03:29:10,090 INFO:   Done with stage: TRAINING
2022-12-31 03:29:10,091 INFO:   Starting stage: EVALUATION
2022-12-31 03:29:10,216 INFO:   Done with stage: EVALUATION
2022-12-31 03:29:10,216 INFO:   Leaving out SEQ value Fold_7
2022-12-31 03:29:10,229 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 03:29:10,229 INFO:   Starting stage: FEATURE SCALING
2022-12-31 03:29:10,880 INFO:   Done with stage: FEATURE SCALING
2022-12-31 03:29:10,880 INFO:   Starting stage: SCALING TARGETS
2022-12-31 03:29:10,953 INFO:   Done with stage: SCALING TARGETS
2022-12-31 03:29:10,953 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:29:10,953 INFO:     No hyperparam tuning for this model
2022-12-31 03:29:10,953 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:29:10,953 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 03:29:10,954 INFO:     None feature selector for col prot
2022-12-31 03:29:10,954 INFO:     None feature selector for col prot
2022-12-31 03:29:10,954 INFO:     None feature selector for col prot
2022-12-31 03:29:10,955 INFO:     None feature selector for col chem
2022-12-31 03:29:10,955 INFO:     None feature selector for col chem
2022-12-31 03:29:10,955 INFO:     None feature selector for col chem
2022-12-31 03:29:10,955 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 03:29:10,955 INFO:   Starting stage: BUILD MODEL
2022-12-31 03:29:10,957 INFO:     Number of params in model 224011
2022-12-31 03:29:10,960 INFO:   Done with stage: BUILD MODEL
2022-12-31 03:29:10,960 INFO:   Starting stage: TRAINING
2022-12-31 03:29:11,007 INFO:     Val loss before train {'Reaction outcome loss': 1.036533232529958, 'Total loss': 1.036533232529958}
2022-12-31 03:29:11,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:11,007 INFO:     Epoch: 0
2022-12-31 03:29:12,646 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.627073981364568, 'Total loss': 0.627073981364568} | train loss {'Reaction outcome loss': 0.7709659637096556, 'Total loss': 0.7709659637096556}
2022-12-31 03:29:12,646 INFO:     Found new best model at epoch 0
2022-12-31 03:29:12,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:12,647 INFO:     Epoch: 1
2022-12-31 03:29:14,272 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5914660851160686, 'Total loss': 0.5914660851160686} | train loss {'Reaction outcome loss': 0.5003963263456572, 'Total loss': 0.5003963263456572}
2022-12-31 03:29:14,272 INFO:     Found new best model at epoch 1
2022-12-31 03:29:14,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:14,273 INFO:     Epoch: 2
2022-12-31 03:29:15,908 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5315142929553985, 'Total loss': 0.5315142929553985} | train loss {'Reaction outcome loss': 0.43718784364337093, 'Total loss': 0.43718784364337093}
2022-12-31 03:29:15,908 INFO:     Found new best model at epoch 2
2022-12-31 03:29:15,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:15,909 INFO:     Epoch: 3
2022-12-31 03:29:17,547 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.523296320438385, 'Total loss': 0.523296320438385} | train loss {'Reaction outcome loss': 0.39593097537971145, 'Total loss': 0.39593097537971145}
2022-12-31 03:29:17,547 INFO:     Found new best model at epoch 3
2022-12-31 03:29:17,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:17,548 INFO:     Epoch: 4
2022-12-31 03:29:19,186 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5026141981283824, 'Total loss': 0.5026141981283824} | train loss {'Reaction outcome loss': 0.3693526345523686, 'Total loss': 0.3693526345523686}
2022-12-31 03:29:19,187 INFO:     Found new best model at epoch 4
2022-12-31 03:29:19,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:19,188 INFO:     Epoch: 5
2022-12-31 03:29:20,558 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5094145645697912, 'Total loss': 0.5094145645697912} | train loss {'Reaction outcome loss': 0.34773883359365515, 'Total loss': 0.34773883359365515}
2022-12-31 03:29:20,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:20,559 INFO:     Epoch: 6
2022-12-31 03:29:21,695 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5083021640777587, 'Total loss': 0.5083021640777587} | train loss {'Reaction outcome loss': 0.3275377681001429, 'Total loss': 0.3275377681001429}
2022-12-31 03:29:21,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:21,695 INFO:     Epoch: 7
2022-12-31 03:29:22,853 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5000855763753255, 'Total loss': 0.5000855763753255} | train loss {'Reaction outcome loss': 0.3143529399476327, 'Total loss': 0.3143529399476327}
2022-12-31 03:29:22,853 INFO:     Found new best model at epoch 7
2022-12-31 03:29:22,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:22,854 INFO:     Epoch: 8
2022-12-31 03:29:23,993 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5245056708653768, 'Total loss': 0.5245056708653768} | train loss {'Reaction outcome loss': 0.3003915650534716, 'Total loss': 0.3003915650534716}
2022-12-31 03:29:23,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:23,993 INFO:     Epoch: 9
2022-12-31 03:29:25,441 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4843726247549057, 'Total loss': 0.4843726247549057} | train loss {'Reaction outcome loss': 0.280102959944991, 'Total loss': 0.280102959944991}
2022-12-31 03:29:25,441 INFO:     Found new best model at epoch 9
2022-12-31 03:29:25,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:25,442 INFO:     Epoch: 10
2022-12-31 03:29:27,112 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5034948289394379, 'Total loss': 0.5034948289394379} | train loss {'Reaction outcome loss': 0.2751867466132133, 'Total loss': 0.2751867466132133}
2022-12-31 03:29:27,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:27,112 INFO:     Epoch: 11
2022-12-31 03:29:28,736 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4666177868843079, 'Total loss': 0.4666177868843079} | train loss {'Reaction outcome loss': 0.2627018148126585, 'Total loss': 0.2627018148126585}
2022-12-31 03:29:28,736 INFO:     Found new best model at epoch 11
2022-12-31 03:29:28,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:28,737 INFO:     Epoch: 12
2022-12-31 03:29:30,378 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48385129968325297, 'Total loss': 0.48385129968325297} | train loss {'Reaction outcome loss': 0.2524583843210544, 'Total loss': 0.2524583843210544}
2022-12-31 03:29:30,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:30,379 INFO:     Epoch: 13
2022-12-31 03:29:32,013 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47851183215777077, 'Total loss': 0.47851183215777077} | train loss {'Reaction outcome loss': 0.24307895353608613, 'Total loss': 0.24307895353608613}
2022-12-31 03:29:32,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:32,013 INFO:     Epoch: 14
2022-12-31 03:29:33,644 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48569437066713966, 'Total loss': 0.48569437066713966} | train loss {'Reaction outcome loss': 0.23579070451484474, 'Total loss': 0.23579070451484474}
2022-12-31 03:29:33,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:33,645 INFO:     Epoch: 15
2022-12-31 03:29:35,258 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4573410371939341, 'Total loss': 0.4573410371939341} | train loss {'Reaction outcome loss': 0.23077331915067423, 'Total loss': 0.23077331915067423}
2022-12-31 03:29:35,258 INFO:     Found new best model at epoch 15
2022-12-31 03:29:35,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:35,260 INFO:     Epoch: 16
2022-12-31 03:29:36,877 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48293868800004325, 'Total loss': 0.48293868800004325} | train loss {'Reaction outcome loss': 0.2198718635479681, 'Total loss': 0.2198718635479681}
2022-12-31 03:29:36,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:36,877 INFO:     Epoch: 17
2022-12-31 03:29:38,540 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4967530926068624, 'Total loss': 0.4967530926068624} | train loss {'Reaction outcome loss': 0.2180320283512346, 'Total loss': 0.2180320283512346}
2022-12-31 03:29:38,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:38,541 INFO:     Epoch: 18
2022-12-31 03:29:40,164 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4973232587178548, 'Total loss': 0.4973232587178548} | train loss {'Reaction outcome loss': 0.20810461974961664, 'Total loss': 0.20810461974961664}
2022-12-31 03:29:40,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:40,165 INFO:     Epoch: 19
2022-12-31 03:29:41,798 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4768232693274816, 'Total loss': 0.4768232693274816} | train loss {'Reaction outcome loss': 0.20276380556934792, 'Total loss': 0.20276380556934792}
2022-12-31 03:29:41,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:41,798 INFO:     Epoch: 20
2022-12-31 03:29:43,424 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.474820613861084, 'Total loss': 0.474820613861084} | train loss {'Reaction outcome loss': 0.200621505419216, 'Total loss': 0.200621505419216}
2022-12-31 03:29:43,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:43,424 INFO:     Epoch: 21
2022-12-31 03:29:45,059 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47457533081372577, 'Total loss': 0.47457533081372577} | train loss {'Reaction outcome loss': 0.1953598395501018, 'Total loss': 0.1953598395501018}
2022-12-31 03:29:45,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:45,060 INFO:     Epoch: 22
2022-12-31 03:29:46,693 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48924732208251953, 'Total loss': 0.48924732208251953} | train loss {'Reaction outcome loss': 0.18671172667657857, 'Total loss': 0.18671172667657857}
2022-12-31 03:29:46,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:46,693 INFO:     Epoch: 23
2022-12-31 03:29:48,323 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.49561784267425535, 'Total loss': 0.49561784267425535} | train loss {'Reaction outcome loss': 0.18261591362050777, 'Total loss': 0.18261591362050777}
2022-12-31 03:29:48,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:48,323 INFO:     Epoch: 24
2022-12-31 03:29:49,984 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5059448639551799, 'Total loss': 0.5059448639551799} | train loss {'Reaction outcome loss': 0.18270235460433126, 'Total loss': 0.18270235460433126}
2022-12-31 03:29:49,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:49,984 INFO:     Epoch: 25
2022-12-31 03:29:51,620 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.474852795402209, 'Total loss': 0.474852795402209} | train loss {'Reaction outcome loss': 0.17831178773060063, 'Total loss': 0.17831178773060063}
2022-12-31 03:29:51,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:51,620 INFO:     Epoch: 26
2022-12-31 03:29:53,263 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4604829400777817, 'Total loss': 0.4604829400777817} | train loss {'Reaction outcome loss': 0.17498193412938487, 'Total loss': 0.17498193412938487}
2022-12-31 03:29:53,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:53,264 INFO:     Epoch: 27
2022-12-31 03:29:54,934 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4578678915898005, 'Total loss': 0.4578678915898005} | train loss {'Reaction outcome loss': 0.17054022820363837, 'Total loss': 0.17054022820363837}
2022-12-31 03:29:54,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:54,934 INFO:     Epoch: 28
2022-12-31 03:29:56,555 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4894464761018753, 'Total loss': 0.4894464761018753} | train loss {'Reaction outcome loss': 0.1694953359750903, 'Total loss': 0.1694953359750903}
2022-12-31 03:29:56,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:56,557 INFO:     Epoch: 29
2022-12-31 03:29:58,198 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4728914598623912, 'Total loss': 0.4728914598623912} | train loss {'Reaction outcome loss': 0.16873249632141651, 'Total loss': 0.16873249632141651}
2022-12-31 03:29:58,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:58,198 INFO:     Epoch: 30
2022-12-31 03:29:59,863 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47409451802571617, 'Total loss': 0.47409451802571617} | train loss {'Reaction outcome loss': 0.16458813355569912, 'Total loss': 0.16458813355569912}
2022-12-31 03:29:59,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:29:59,864 INFO:     Epoch: 31
2022-12-31 03:30:01,512 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48208587169647216, 'Total loss': 0.48208587169647216} | train loss {'Reaction outcome loss': 0.1618398073455487, 'Total loss': 0.1618398073455487}
2022-12-31 03:30:01,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:01,512 INFO:     Epoch: 32
2022-12-31 03:30:03,177 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46838020384311674, 'Total loss': 0.46838020384311674} | train loss {'Reaction outcome loss': 0.15903071402185445, 'Total loss': 0.15903071402185445}
2022-12-31 03:30:03,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:03,178 INFO:     Epoch: 33
2022-12-31 03:30:04,794 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48826815088589987, 'Total loss': 0.48826815088589987} | train loss {'Reaction outcome loss': 0.16130095464093375, 'Total loss': 0.16130095464093375}
2022-12-31 03:30:04,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:04,794 INFO:     Epoch: 34
2022-12-31 03:30:06,453 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5095479687054952, 'Total loss': 0.5095479687054952} | train loss {'Reaction outcome loss': 0.15700484185550187, 'Total loss': 0.15700484185550187}
2022-12-31 03:30:06,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:06,453 INFO:     Epoch: 35
2022-12-31 03:30:08,115 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49271590014298755, 'Total loss': 0.49271590014298755} | train loss {'Reaction outcome loss': 0.15491496762496146, 'Total loss': 0.15491496762496146}
2022-12-31 03:30:08,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:08,115 INFO:     Epoch: 36
2022-12-31 03:30:09,780 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47394497990608214, 'Total loss': 0.47394497990608214} | train loss {'Reaction outcome loss': 0.1526723428921848, 'Total loss': 0.1526723428921848}
2022-12-31 03:30:09,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:09,780 INFO:     Epoch: 37
2022-12-31 03:30:11,401 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4612782816092173, 'Total loss': 0.4612782816092173} | train loss {'Reaction outcome loss': 0.15282848041793767, 'Total loss': 0.15282848041793767}
2022-12-31 03:30:11,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:11,401 INFO:     Epoch: 38
2022-12-31 03:30:13,066 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4655179480711619, 'Total loss': 0.4655179480711619} | train loss {'Reaction outcome loss': 0.15071626185079776, 'Total loss': 0.15071626185079776}
2022-12-31 03:30:13,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:13,066 INFO:     Epoch: 39
2022-12-31 03:30:14,732 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47172571420669557, 'Total loss': 0.47172571420669557} | train loss {'Reaction outcome loss': 0.14731711022797905, 'Total loss': 0.14731711022797905}
2022-12-31 03:30:14,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:14,733 INFO:     Epoch: 40
2022-12-31 03:30:16,355 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4660451392332713, 'Total loss': 0.4660451392332713} | train loss {'Reaction outcome loss': 0.14797871211873173, 'Total loss': 0.14797871211873173}
2022-12-31 03:30:16,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:16,356 INFO:     Epoch: 41
2022-12-31 03:30:17,974 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4973857283592224, 'Total loss': 0.4973857283592224} | train loss {'Reaction outcome loss': 0.14519589305065222, 'Total loss': 0.14519589305065222}
2022-12-31 03:30:17,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:17,974 INFO:     Epoch: 42
2022-12-31 03:30:19,625 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4673660725355148, 'Total loss': 0.4673660725355148} | train loss {'Reaction outcome loss': 0.1435203196763293, 'Total loss': 0.1435203196763293}
2022-12-31 03:30:19,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:19,626 INFO:     Epoch: 43
2022-12-31 03:30:21,293 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.496592590212822, 'Total loss': 0.496592590212822} | train loss {'Reaction outcome loss': 0.1410052460998243, 'Total loss': 0.1410052460998243}
2022-12-31 03:30:21,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:21,293 INFO:     Epoch: 44
2022-12-31 03:30:22,910 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44535820186138153, 'Total loss': 0.44535820186138153} | train loss {'Reaction outcome loss': 0.141892068430156, 'Total loss': 0.141892068430156}
2022-12-31 03:30:22,910 INFO:     Found new best model at epoch 44
2022-12-31 03:30:22,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:22,911 INFO:     Epoch: 45
2022-12-31 03:30:24,530 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4710768908262253, 'Total loss': 0.4710768908262253} | train loss {'Reaction outcome loss': 0.13947068455558445, 'Total loss': 0.13947068455558445}
2022-12-31 03:30:24,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:24,531 INFO:     Epoch: 46
2022-12-31 03:30:26,152 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47714004665613174, 'Total loss': 0.47714004665613174} | train loss {'Reaction outcome loss': 0.1379568558959593, 'Total loss': 0.1379568558959593}
2022-12-31 03:30:26,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:26,153 INFO:     Epoch: 47
2022-12-31 03:30:27,783 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4649721066157023, 'Total loss': 0.4649721066157023} | train loss {'Reaction outcome loss': 0.13782584504140305, 'Total loss': 0.13782584504140305}
2022-12-31 03:30:27,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:27,784 INFO:     Epoch: 48
2022-12-31 03:30:29,399 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4844680349032084, 'Total loss': 0.4844680349032084} | train loss {'Reaction outcome loss': 0.132577063796524, 'Total loss': 0.132577063796524}
2022-12-31 03:30:29,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:29,399 INFO:     Epoch: 49
2022-12-31 03:30:31,064 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46665683686733245, 'Total loss': 0.46665683686733245} | train loss {'Reaction outcome loss': 0.1332105371230265, 'Total loss': 0.1332105371230265}
2022-12-31 03:30:31,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:31,065 INFO:     Epoch: 50
2022-12-31 03:30:32,688 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4658679008483887, 'Total loss': 0.4658679008483887} | train loss {'Reaction outcome loss': 0.13550322743583243, 'Total loss': 0.13550322743583243}
2022-12-31 03:30:32,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:32,689 INFO:     Epoch: 51
2022-12-31 03:30:34,315 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4750035434961319, 'Total loss': 0.4750035434961319} | train loss {'Reaction outcome loss': 0.13225026639844106, 'Total loss': 0.13225026639844106}
2022-12-31 03:30:34,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:34,316 INFO:     Epoch: 52
2022-12-31 03:30:35,982 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4632656365633011, 'Total loss': 0.4632656365633011} | train loss {'Reaction outcome loss': 0.1316620397620199, 'Total loss': 0.1316620397620199}
2022-12-31 03:30:35,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:35,983 INFO:     Epoch: 53
2022-12-31 03:30:37,646 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4856833646694819, 'Total loss': 0.4856833646694819} | train loss {'Reaction outcome loss': 0.1300726559026577, 'Total loss': 0.1300726559026577}
2022-12-31 03:30:37,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:37,646 INFO:     Epoch: 54
2022-12-31 03:30:39,257 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47033573786417643, 'Total loss': 0.47033573786417643} | train loss {'Reaction outcome loss': 0.12869491024591728, 'Total loss': 0.12869491024591728}
2022-12-31 03:30:39,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:39,258 INFO:     Epoch: 55
2022-12-31 03:30:40,876 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47201236585776013, 'Total loss': 0.47201236585776013} | train loss {'Reaction outcome loss': 0.12862119060480423, 'Total loss': 0.12862119060480423}
2022-12-31 03:30:40,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:40,876 INFO:     Epoch: 56
2022-12-31 03:30:42,540 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4808709919452667, 'Total loss': 0.4808709919452667} | train loss {'Reaction outcome loss': 0.1244032399322071, 'Total loss': 0.1244032399322071}
2022-12-31 03:30:42,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:42,541 INFO:     Epoch: 57
2022-12-31 03:30:44,191 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4575141797463099, 'Total loss': 0.4575141797463099} | train loss {'Reaction outcome loss': 0.1270379283942874, 'Total loss': 0.1270379283942874}
2022-12-31 03:30:44,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:44,191 INFO:     Epoch: 58
2022-12-31 03:30:45,808 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45587768852710725, 'Total loss': 0.45587768852710725} | train loss {'Reaction outcome loss': 0.13059755868449915, 'Total loss': 0.13059755868449915}
2022-12-31 03:30:45,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:45,808 INFO:     Epoch: 59
2022-12-31 03:30:47,459 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4719017088413239, 'Total loss': 0.4719017088413239} | train loss {'Reaction outcome loss': 0.12834610783626133, 'Total loss': 0.12834610783626133}
2022-12-31 03:30:47,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:47,459 INFO:     Epoch: 60
2022-12-31 03:30:49,078 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4592142005761464, 'Total loss': 0.4592142005761464} | train loss {'Reaction outcome loss': 0.12480910352703574, 'Total loss': 0.12480910352703574}
2022-12-31 03:30:49,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:49,078 INFO:     Epoch: 61
2022-12-31 03:30:50,744 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4571773499250412, 'Total loss': 0.4571773499250412} | train loss {'Reaction outcome loss': 0.12605002375205285, 'Total loss': 0.12605002375205285}
2022-12-31 03:30:50,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:50,744 INFO:     Epoch: 62
2022-12-31 03:30:52,374 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48365913033485414, 'Total loss': 0.48365913033485414} | train loss {'Reaction outcome loss': 0.12193934796277152, 'Total loss': 0.12193934796277152}
2022-12-31 03:30:52,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:52,375 INFO:     Epoch: 63
2022-12-31 03:30:54,010 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4925035794576009, 'Total loss': 0.4925035794576009} | train loss {'Reaction outcome loss': 0.12333457620935481, 'Total loss': 0.12333457620935481}
2022-12-31 03:30:54,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:54,010 INFO:     Epoch: 64
2022-12-31 03:30:55,642 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.48389736711978915, 'Total loss': 0.48389736711978915} | train loss {'Reaction outcome loss': 0.12546243521280667, 'Total loss': 0.12546243521280667}
2022-12-31 03:30:55,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:55,642 INFO:     Epoch: 65
2022-12-31 03:30:57,295 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4764697348078092, 'Total loss': 0.4764697348078092} | train loss {'Reaction outcome loss': 0.1207247617627605, 'Total loss': 0.1207247617627605}
2022-12-31 03:30:57,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:57,295 INFO:     Epoch: 66
2022-12-31 03:30:58,921 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4664530987540881, 'Total loss': 0.4664530987540881} | train loss {'Reaction outcome loss': 0.12400925802974709, 'Total loss': 0.12400925802974709}
2022-12-31 03:30:58,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:30:58,921 INFO:     Epoch: 67
2022-12-31 03:31:00,591 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4633362988630931, 'Total loss': 0.4633362988630931} | train loss {'Reaction outcome loss': 0.11803016152412761, 'Total loss': 0.11803016152412761}
2022-12-31 03:31:00,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:00,591 INFO:     Epoch: 68
2022-12-31 03:31:02,217 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4670673102140427, 'Total loss': 0.4670673102140427} | train loss {'Reaction outcome loss': 0.11760646289732267, 'Total loss': 0.11760646289732267}
2022-12-31 03:31:02,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:02,217 INFO:     Epoch: 69
2022-12-31 03:31:03,886 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4670920540889104, 'Total loss': 0.4670920540889104} | train loss {'Reaction outcome loss': 0.11849431291521806, 'Total loss': 0.11849431291521806}
2022-12-31 03:31:03,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:03,887 INFO:     Epoch: 70
2022-12-31 03:31:05,510 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4668770631154378, 'Total loss': 0.4668770631154378} | train loss {'Reaction outcome loss': 0.12101630573261811, 'Total loss': 0.12101630573261811}
2022-12-31 03:31:05,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:05,510 INFO:     Epoch: 71
2022-12-31 03:31:07,179 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4686155865589778, 'Total loss': 0.4686155865589778} | train loss {'Reaction outcome loss': 0.12142634345218539, 'Total loss': 0.12142634345218539}
2022-12-31 03:31:07,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:07,180 INFO:     Epoch: 72
2022-12-31 03:31:08,804 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4247336397568385, 'Total loss': 0.4247336397568385} | train loss {'Reaction outcome loss': 0.11955267713499333, 'Total loss': 0.11955267713499333}
2022-12-31 03:31:08,804 INFO:     Found new best model at epoch 72
2022-12-31 03:31:08,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:08,805 INFO:     Epoch: 73
2022-12-31 03:31:10,434 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4601160263021787, 'Total loss': 0.4601160263021787} | train loss {'Reaction outcome loss': 0.11735010477596565, 'Total loss': 0.11735010477596565}
2022-12-31 03:31:10,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:10,434 INFO:     Epoch: 74
2022-12-31 03:31:12,105 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4733529155453046, 'Total loss': 0.4733529155453046} | train loss {'Reaction outcome loss': 0.11859625263058914, 'Total loss': 0.11859625263058914}
2022-12-31 03:31:12,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:12,105 INFO:     Epoch: 75
2022-12-31 03:31:13,774 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4923013627529144, 'Total loss': 0.4923013627529144} | train loss {'Reaction outcome loss': 0.11430838650818713, 'Total loss': 0.11430838650818713}
2022-12-31 03:31:13,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:13,775 INFO:     Epoch: 76
2022-12-31 03:31:15,416 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4806075135866801, 'Total loss': 0.4806075135866801} | train loss {'Reaction outcome loss': 0.11334742670071846, 'Total loss': 0.11334742670071846}
2022-12-31 03:31:15,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:15,416 INFO:     Epoch: 77
2022-12-31 03:31:17,038 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4945576836665471, 'Total loss': 0.4945576836665471} | train loss {'Reaction outcome loss': 0.11617628465463754, 'Total loss': 0.11617628465463754}
2022-12-31 03:31:17,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:17,038 INFO:     Epoch: 78
2022-12-31 03:31:18,707 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49944037248690926, 'Total loss': 0.49944037248690926} | train loss {'Reaction outcome loss': 0.11503888613339312, 'Total loss': 0.11503888613339312}
2022-12-31 03:31:18,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:18,707 INFO:     Epoch: 79
2022-12-31 03:31:20,362 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5168608243266741, 'Total loss': 0.5168608243266741} | train loss {'Reaction outcome loss': 0.119344199404107, 'Total loss': 0.119344199404107}
2022-12-31 03:31:20,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:20,362 INFO:     Epoch: 80
2022-12-31 03:31:22,032 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4821582595507304, 'Total loss': 0.4821582595507304} | train loss {'Reaction outcome loss': 0.11706388579758846, 'Total loss': 0.11706388579758846}
2022-12-31 03:31:22,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:22,032 INFO:     Epoch: 81
2022-12-31 03:31:23,648 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46817440489927925, 'Total loss': 0.46817440489927925} | train loss {'Reaction outcome loss': 0.11758144037286997, 'Total loss': 0.11758144037286997}
2022-12-31 03:31:23,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:23,648 INFO:     Epoch: 82
2022-12-31 03:31:25,268 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4977218886216482, 'Total loss': 0.4977218886216482} | train loss {'Reaction outcome loss': 0.11410416278144217, 'Total loss': 0.11410416278144217}
2022-12-31 03:31:25,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:25,269 INFO:     Epoch: 83
2022-12-31 03:31:26,939 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49443629880746204, 'Total loss': 0.49443629880746204} | train loss {'Reaction outcome loss': 0.11589963099035007, 'Total loss': 0.11589963099035007}
2022-12-31 03:31:26,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:26,940 INFO:     Epoch: 84
2022-12-31 03:31:28,560 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4867805242538452, 'Total loss': 0.4867805242538452} | train loss {'Reaction outcome loss': 0.11346896896676735, 'Total loss': 0.11346896896676735}
2022-12-31 03:31:28,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:28,561 INFO:     Epoch: 85
2022-12-31 03:31:30,186 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5065249860286712, 'Total loss': 0.5065249860286712} | train loss {'Reaction outcome loss': 0.11333241106165634, 'Total loss': 0.11333241106165634}
2022-12-31 03:31:30,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:30,186 INFO:     Epoch: 86
2022-12-31 03:31:31,819 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47360353072484335, 'Total loss': 0.47360353072484335} | train loss {'Reaction outcome loss': 0.11285957331695201, 'Total loss': 0.11285957331695201}
2022-12-31 03:31:31,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:31,819 INFO:     Epoch: 87
2022-12-31 03:31:33,444 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4925300469001134, 'Total loss': 0.4925300469001134} | train loss {'Reaction outcome loss': 0.11355566811606638, 'Total loss': 0.11355566811606638}
2022-12-31 03:31:33,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:33,444 INFO:     Epoch: 88
2022-12-31 03:31:35,081 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4872437477111816, 'Total loss': 0.4872437477111816} | train loss {'Reaction outcome loss': 0.11282823368022722, 'Total loss': 0.11282823368022722}
2022-12-31 03:31:35,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:35,081 INFO:     Epoch: 89
2022-12-31 03:31:36,709 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4364413877328237, 'Total loss': 0.4364413877328237} | train loss {'Reaction outcome loss': 0.11572144534573335, 'Total loss': 0.11572144534573335}
2022-12-31 03:31:36,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:36,709 INFO:     Epoch: 90
2022-12-31 03:31:38,329 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49360889693101245, 'Total loss': 0.49360889693101245} | train loss {'Reaction outcome loss': 0.11831073183230115, 'Total loss': 0.11831073183230115}
2022-12-31 03:31:38,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:38,329 INFO:     Epoch: 91
2022-12-31 03:31:39,957 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48236649930477143, 'Total loss': 0.48236649930477143} | train loss {'Reaction outcome loss': 0.11198424686096098, 'Total loss': 0.11198424686096098}
2022-12-31 03:31:39,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:39,957 INFO:     Epoch: 92
2022-12-31 03:31:41,683 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48230904738108316, 'Total loss': 0.48230904738108316} | train loss {'Reaction outcome loss': 0.11437581155099485, 'Total loss': 0.11437581155099485}
2022-12-31 03:31:41,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:41,683 INFO:     Epoch: 93
2022-12-31 03:31:43,307 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4644214749336243, 'Total loss': 0.4644214749336243} | train loss {'Reaction outcome loss': 0.1195679777839796, 'Total loss': 0.1195679777839796}
2022-12-31 03:31:43,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:43,308 INFO:     Epoch: 94
2022-12-31 03:31:44,941 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.499880584081014, 'Total loss': 0.499880584081014} | train loss {'Reaction outcome loss': 0.11118773398214837, 'Total loss': 0.11118773398214837}
2022-12-31 03:31:44,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:44,941 INFO:     Epoch: 95
2022-12-31 03:31:46,574 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4450994034608205, 'Total loss': 0.4450994034608205} | train loss {'Reaction outcome loss': 0.11189603393675511, 'Total loss': 0.11189603393675511}
2022-12-31 03:31:46,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:46,574 INFO:     Epoch: 96
2022-12-31 03:31:48,214 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4741898144284884, 'Total loss': 0.4741898144284884} | train loss {'Reaction outcome loss': 0.11097014391381253, 'Total loss': 0.11097014391381253}
2022-12-31 03:31:48,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:48,215 INFO:     Epoch: 97
2022-12-31 03:31:49,940 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46419843037923175, 'Total loss': 0.46419843037923175} | train loss {'Reaction outcome loss': 0.1099881680652042, 'Total loss': 0.1099881680652042}
2022-12-31 03:31:49,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:49,941 INFO:     Epoch: 98
2022-12-31 03:31:51,573 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4784771104653676, 'Total loss': 0.4784771104653676} | train loss {'Reaction outcome loss': 0.10930108735615233, 'Total loss': 0.10930108735615233}
2022-12-31 03:31:51,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:51,573 INFO:     Epoch: 99
2022-12-31 03:31:53,298 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5123765945434571, 'Total loss': 0.5123765945434571} | train loss {'Reaction outcome loss': 0.10935011434970618, 'Total loss': 0.10935011434970618}
2022-12-31 03:31:53,298 INFO:     Best model found after epoch 73 of 100.
2022-12-31 03:31:53,299 INFO:   Done with stage: TRAINING
2022-12-31 03:31:53,299 INFO:   Starting stage: EVALUATION
2022-12-31 03:31:53,425 INFO:   Done with stage: EVALUATION
2022-12-31 03:31:53,425 INFO:   Leaving out SEQ value Fold_8
2022-12-31 03:31:53,437 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 03:31:53,437 INFO:   Starting stage: FEATURE SCALING
2022-12-31 03:31:54,097 INFO:   Done with stage: FEATURE SCALING
2022-12-31 03:31:54,097 INFO:   Starting stage: SCALING TARGETS
2022-12-31 03:31:54,169 INFO:   Done with stage: SCALING TARGETS
2022-12-31 03:31:54,169 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:31:54,169 INFO:     No hyperparam tuning for this model
2022-12-31 03:31:54,169 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:31:54,169 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 03:31:54,170 INFO:     None feature selector for col prot
2022-12-31 03:31:54,170 INFO:     None feature selector for col prot
2022-12-31 03:31:54,170 INFO:     None feature selector for col prot
2022-12-31 03:31:54,171 INFO:     None feature selector for col chem
2022-12-31 03:31:54,171 INFO:     None feature selector for col chem
2022-12-31 03:31:54,171 INFO:     None feature selector for col chem
2022-12-31 03:31:54,171 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 03:31:54,171 INFO:   Starting stage: BUILD MODEL
2022-12-31 03:31:54,173 INFO:     Number of params in model 224011
2022-12-31 03:31:54,176 INFO:   Done with stage: BUILD MODEL
2022-12-31 03:31:54,176 INFO:   Starting stage: TRAINING
2022-12-31 03:31:54,222 INFO:     Val loss before train {'Reaction outcome loss': 1.113386829694112, 'Total loss': 1.113386829694112}
2022-12-31 03:31:54,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:54,222 INFO:     Epoch: 0
2022-12-31 03:31:55,935 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6335838516553243, 'Total loss': 0.6335838516553243} | train loss {'Reaction outcome loss': 0.7796062535565832, 'Total loss': 0.7796062535565832}
2022-12-31 03:31:55,935 INFO:     Found new best model at epoch 0
2022-12-31 03:31:55,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:55,936 INFO:     Epoch: 1
2022-12-31 03:31:57,561 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5416235029697418, 'Total loss': 0.5416235029697418} | train loss {'Reaction outcome loss': 0.5054908013848615, 'Total loss': 0.5054908013848615}
2022-12-31 03:31:57,561 INFO:     Found new best model at epoch 1
2022-12-31 03:31:57,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:57,562 INFO:     Epoch: 2
2022-12-31 03:31:59,178 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5312666157881419, 'Total loss': 0.5312666157881419} | train loss {'Reaction outcome loss': 0.438853175796069, 'Total loss': 0.438853175796069}
2022-12-31 03:31:59,178 INFO:     Found new best model at epoch 2
2022-12-31 03:31:59,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:31:59,180 INFO:     Epoch: 3
2022-12-31 03:32:00,796 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49577121635278065, 'Total loss': 0.49577121635278065} | train loss {'Reaction outcome loss': 0.400073637564977, 'Total loss': 0.400073637564977}
2022-12-31 03:32:00,797 INFO:     Found new best model at epoch 3
2022-12-31 03:32:00,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:00,798 INFO:     Epoch: 4
2022-12-31 03:32:02,420 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4877626518408457, 'Total loss': 0.4877626518408457} | train loss {'Reaction outcome loss': 0.37397952090216585, 'Total loss': 0.37397952090216585}
2022-12-31 03:32:02,420 INFO:     Found new best model at epoch 4
2022-12-31 03:32:02,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:02,421 INFO:     Epoch: 5
2022-12-31 03:32:04,043 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4903742343187332, 'Total loss': 0.4903742343187332} | train loss {'Reaction outcome loss': 0.3458380553773537, 'Total loss': 0.3458380553773537}
2022-12-31 03:32:04,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:04,043 INFO:     Epoch: 6
2022-12-31 03:32:05,692 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4639117916425069, 'Total loss': 0.4639117916425069} | train loss {'Reaction outcome loss': 0.3311720693996851, 'Total loss': 0.3311720693996851}
2022-12-31 03:32:05,693 INFO:     Found new best model at epoch 6
2022-12-31 03:32:05,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:05,694 INFO:     Epoch: 7
2022-12-31 03:32:07,314 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4613930861155192, 'Total loss': 0.4613930861155192} | train loss {'Reaction outcome loss': 0.3137257276550003, 'Total loss': 0.3137257276550003}
2022-12-31 03:32:07,315 INFO:     Found new best model at epoch 7
2022-12-31 03:32:07,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:07,316 INFO:     Epoch: 8
2022-12-31 03:32:08,934 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5014976561069489, 'Total loss': 0.5014976561069489} | train loss {'Reaction outcome loss': 0.2977971602231264, 'Total loss': 0.2977971602231264}
2022-12-31 03:32:08,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:08,934 INFO:     Epoch: 9
2022-12-31 03:32:10,589 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46060791810353596, 'Total loss': 0.46060791810353596} | train loss {'Reaction outcome loss': 0.2924565022306827, 'Total loss': 0.2924565022306827}
2022-12-31 03:32:10,589 INFO:     Found new best model at epoch 9
2022-12-31 03:32:10,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:10,590 INFO:     Epoch: 10
2022-12-31 03:32:12,200 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4755406449238459, 'Total loss': 0.4755406449238459} | train loss {'Reaction outcome loss': 0.2730470104965523, 'Total loss': 0.2730470104965523}
2022-12-31 03:32:12,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:12,200 INFO:     Epoch: 11
2022-12-31 03:32:13,814 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4310232927401861, 'Total loss': 0.4310232927401861} | train loss {'Reaction outcome loss': 0.26263450669460103, 'Total loss': 0.26263450669460103}
2022-12-31 03:32:13,815 INFO:     Found new best model at epoch 11
2022-12-31 03:32:13,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:13,816 INFO:     Epoch: 12
2022-12-31 03:32:15,433 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4634310106436412, 'Total loss': 0.4634310106436412} | train loss {'Reaction outcome loss': 0.2516809524293395, 'Total loss': 0.2516809524293395}
2022-12-31 03:32:15,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:15,434 INFO:     Epoch: 13
2022-12-31 03:32:17,056 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47766966223716734, 'Total loss': 0.47766966223716734} | train loss {'Reaction outcome loss': 0.2470923523567077, 'Total loss': 0.2470923523567077}
2022-12-31 03:32:17,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:17,056 INFO:     Epoch: 14
2022-12-31 03:32:18,671 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44792493085066476, 'Total loss': 0.44792493085066476} | train loss {'Reaction outcome loss': 0.23851259726275137, 'Total loss': 0.23851259726275137}
2022-12-31 03:32:18,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:18,671 INFO:     Epoch: 15
2022-12-31 03:32:20,288 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42847716212272646, 'Total loss': 0.42847716212272646} | train loss {'Reaction outcome loss': 0.2337876144391641, 'Total loss': 0.2337876144391641}
2022-12-31 03:32:20,288 INFO:     Found new best model at epoch 15
2022-12-31 03:32:20,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:20,289 INFO:     Epoch: 16
2022-12-31 03:32:21,895 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44366073310375215, 'Total loss': 0.44366073310375215} | train loss {'Reaction outcome loss': 0.21977330327280326, 'Total loss': 0.21977330327280326}
2022-12-31 03:32:21,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:21,895 INFO:     Epoch: 17
2022-12-31 03:32:23,504 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4739875505367915, 'Total loss': 0.4739875505367915} | train loss {'Reaction outcome loss': 0.21390114140345046, 'Total loss': 0.21390114140345046}
2022-12-31 03:32:23,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:23,505 INFO:     Epoch: 18
2022-12-31 03:32:25,127 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.477343742052714, 'Total loss': 0.477343742052714} | train loss {'Reaction outcome loss': 0.20771313242300454, 'Total loss': 0.20771313242300454}
2022-12-31 03:32:25,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:25,127 INFO:     Epoch: 19
2022-12-31 03:32:26,750 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49074701468149823, 'Total loss': 0.49074701468149823} | train loss {'Reaction outcome loss': 0.20253500851728293, 'Total loss': 0.20253500851728293}
2022-12-31 03:32:26,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:26,750 INFO:     Epoch: 20
2022-12-31 03:32:28,395 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47081608374913536, 'Total loss': 0.47081608374913536} | train loss {'Reaction outcome loss': 0.19765961452967662, 'Total loss': 0.19765961452967662}
2022-12-31 03:32:28,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:28,395 INFO:     Epoch: 21
2022-12-31 03:32:30,017 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4888142665227254, 'Total loss': 0.4888142665227254} | train loss {'Reaction outcome loss': 0.1953912423518689, 'Total loss': 0.1953912423518689}
2022-12-31 03:32:30,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:30,018 INFO:     Epoch: 22
2022-12-31 03:32:31,638 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4796073228120804, 'Total loss': 0.4796073228120804} | train loss {'Reaction outcome loss': 0.18992922187074632, 'Total loss': 0.18992922187074632}
2022-12-31 03:32:31,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:31,638 INFO:     Epoch: 23
2022-12-31 03:32:33,266 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4801871160666148, 'Total loss': 0.4801871160666148} | train loss {'Reaction outcome loss': 0.18389498754286382, 'Total loss': 0.18389498754286382}
2022-12-31 03:32:33,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:33,267 INFO:     Epoch: 24
2022-12-31 03:32:34,888 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.49968974391619364, 'Total loss': 0.49968974391619364} | train loss {'Reaction outcome loss': 0.1865850831876333, 'Total loss': 0.1865850831876333}
2022-12-31 03:32:34,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:34,888 INFO:     Epoch: 25
2022-12-31 03:32:36,500 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48453585505485536, 'Total loss': 0.48453585505485536} | train loss {'Reaction outcome loss': 0.1800844721896072, 'Total loss': 0.1800844721896072}
2022-12-31 03:32:36,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:36,501 INFO:     Epoch: 26
2022-12-31 03:32:38,119 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4911947349707286, 'Total loss': 0.4911947349707286} | train loss {'Reaction outcome loss': 0.17476244536363453, 'Total loss': 0.17476244536363453}
2022-12-31 03:32:38,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:38,120 INFO:     Epoch: 27
2022-12-31 03:32:39,737 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4785045812527339, 'Total loss': 0.4785045812527339} | train loss {'Reaction outcome loss': 0.17275518424381134, 'Total loss': 0.17275518424381134}
2022-12-31 03:32:39,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:39,737 INFO:     Epoch: 28
2022-12-31 03:32:41,370 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47847279409567517, 'Total loss': 0.47847279409567517} | train loss {'Reaction outcome loss': 0.18463226880176345, 'Total loss': 0.18463226880176345}
2022-12-31 03:32:41,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:41,370 INFO:     Epoch: 29
2022-12-31 03:32:43,033 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4769059220949809, 'Total loss': 0.4769059220949809} | train loss {'Reaction outcome loss': 0.1850169110516815, 'Total loss': 0.1850169110516815}
2022-12-31 03:32:43,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:43,033 INFO:     Epoch: 30
2022-12-31 03:32:44,651 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47814808984597523, 'Total loss': 0.47814808984597523} | train loss {'Reaction outcome loss': 0.16822557370650812, 'Total loss': 0.16822557370650812}
2022-12-31 03:32:44,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:44,651 INFO:     Epoch: 31
2022-12-31 03:32:46,264 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4697765916585922, 'Total loss': 0.4697765916585922} | train loss {'Reaction outcome loss': 0.1603034816735485, 'Total loss': 0.1603034816735485}
2022-12-31 03:32:46,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:46,265 INFO:     Epoch: 32
2022-12-31 03:32:47,883 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47773536341264844, 'Total loss': 0.47773536341264844} | train loss {'Reaction outcome loss': 0.15919527059364172, 'Total loss': 0.15919527059364172}
2022-12-31 03:32:47,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:47,883 INFO:     Epoch: 33
2022-12-31 03:32:49,498 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5056108951568603, 'Total loss': 0.5056108951568603} | train loss {'Reaction outcome loss': 0.16078746499513966, 'Total loss': 0.16078746499513966}
2022-12-31 03:32:49,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:49,499 INFO:     Epoch: 34
2022-12-31 03:32:51,120 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4730857213338216, 'Total loss': 0.4730857213338216} | train loss {'Reaction outcome loss': 0.15813030211074217, 'Total loss': 0.15813030211074217}
2022-12-31 03:32:51,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:51,121 INFO:     Epoch: 35
2022-12-31 03:32:52,738 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5001696387926737, 'Total loss': 0.5001696387926737} | train loss {'Reaction outcome loss': 0.15699233360731119, 'Total loss': 0.15699233360731119}
2022-12-31 03:32:52,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:52,738 INFO:     Epoch: 36
2022-12-31 03:32:54,356 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5197391668955486, 'Total loss': 0.5197391668955486} | train loss {'Reaction outcome loss': 0.1550131612917149, 'Total loss': 0.1550131612917149}
2022-12-31 03:32:54,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:54,356 INFO:     Epoch: 37
2022-12-31 03:32:56,010 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.48526346882184346, 'Total loss': 0.48526346882184346} | train loss {'Reaction outcome loss': 0.15094686472097554, 'Total loss': 0.15094686472097554}
2022-12-31 03:32:56,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:56,011 INFO:     Epoch: 38
2022-12-31 03:32:57,625 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.526004250595967, 'Total loss': 0.526004250595967} | train loss {'Reaction outcome loss': 0.153542256676187, 'Total loss': 0.153542256676187}
2022-12-31 03:32:57,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:57,625 INFO:     Epoch: 39
2022-12-31 03:32:59,239 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49160927881797156, 'Total loss': 0.49160927881797156} | train loss {'Reaction outcome loss': 0.15429296548329835, 'Total loss': 0.15429296548329835}
2022-12-31 03:32:59,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:32:59,239 INFO:     Epoch: 40
2022-12-31 03:33:00,855 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4831028898557027, 'Total loss': 0.4831028898557027} | train loss {'Reaction outcome loss': 0.1596820779381862, 'Total loss': 0.1596820779381862}
2022-12-31 03:33:00,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:00,855 INFO:     Epoch: 41
2022-12-31 03:33:02,479 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5117990414301554, 'Total loss': 0.5117990414301554} | train loss {'Reaction outcome loss': 0.14905769284308443, 'Total loss': 0.14905769284308443}
2022-12-31 03:33:02,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:02,479 INFO:     Epoch: 42
2022-12-31 03:33:04,094 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5139733612537384, 'Total loss': 0.5139733612537384} | train loss {'Reaction outcome loss': 0.15012565158658486, 'Total loss': 0.15012565158658486}
2022-12-31 03:33:04,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:04,095 INFO:     Epoch: 43
2022-12-31 03:33:05,717 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5212114572525024, 'Total loss': 0.5212114572525024} | train loss {'Reaction outcome loss': 0.14546306262069475, 'Total loss': 0.14546306262069475}
2022-12-31 03:33:05,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:05,718 INFO:     Epoch: 44
2022-12-31 03:33:07,341 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49304069181283317, 'Total loss': 0.49304069181283317} | train loss {'Reaction outcome loss': 0.14373898349341302, 'Total loss': 0.14373898349341302}
2022-12-31 03:33:07,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:07,341 INFO:     Epoch: 45
2022-12-31 03:33:08,960 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47456480960051217, 'Total loss': 0.47456480960051217} | train loss {'Reaction outcome loss': 0.14576798485612255, 'Total loss': 0.14576798485612255}
2022-12-31 03:33:08,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:08,961 INFO:     Epoch: 46
2022-12-31 03:33:10,590 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47920627196629845, 'Total loss': 0.47920627196629845} | train loss {'Reaction outcome loss': 0.14122877893828115, 'Total loss': 0.14122877893828115}
2022-12-31 03:33:10,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:10,590 INFO:     Epoch: 47
2022-12-31 03:33:12,220 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5075255513191224, 'Total loss': 0.5075255513191224} | train loss {'Reaction outcome loss': 0.13786153326901657, 'Total loss': 0.13786153326901657}
2022-12-31 03:33:12,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:12,220 INFO:     Epoch: 48
2022-12-31 03:33:13,843 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.483128692706426, 'Total loss': 0.483128692706426} | train loss {'Reaction outcome loss': 0.13833418917045862, 'Total loss': 0.13833418917045862}
2022-12-31 03:33:13,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:13,843 INFO:     Epoch: 49
2022-12-31 03:33:15,465 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5036775171756744, 'Total loss': 0.5036775171756744} | train loss {'Reaction outcome loss': 0.1449408568509355, 'Total loss': 0.1449408568509355}
2022-12-31 03:33:15,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:15,466 INFO:     Epoch: 50
2022-12-31 03:33:17,092 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5181901117165884, 'Total loss': 0.5181901117165884} | train loss {'Reaction outcome loss': 0.13889800606504676, 'Total loss': 0.13889800606504676}
2022-12-31 03:33:17,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:17,093 INFO:     Epoch: 51
2022-12-31 03:33:18,733 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5202947080135345, 'Total loss': 0.5202947080135345} | train loss {'Reaction outcome loss': 0.1366182901110733, 'Total loss': 0.1366182901110733}
2022-12-31 03:33:18,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:18,733 INFO:     Epoch: 52
2022-12-31 03:33:20,452 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5061954319477081, 'Total loss': 0.5061954319477081} | train loss {'Reaction outcome loss': 0.1381063861735511, 'Total loss': 0.1381063861735511}
2022-12-31 03:33:20,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:20,452 INFO:     Epoch: 53
2022-12-31 03:33:22,072 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5052465587854386, 'Total loss': 0.5052465587854386} | train loss {'Reaction outcome loss': 0.13245533812374377, 'Total loss': 0.13245533812374377}
2022-12-31 03:33:22,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:22,072 INFO:     Epoch: 54
2022-12-31 03:33:23,792 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5231766521930694, 'Total loss': 0.5231766521930694} | train loss {'Reaction outcome loss': 0.13032781798940868, 'Total loss': 0.13032781798940868}
2022-12-31 03:33:23,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:23,792 INFO:     Epoch: 55
2022-12-31 03:33:25,410 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5678696582714716, 'Total loss': 0.5678696582714716} | train loss {'Reaction outcome loss': 0.13311276255357687, 'Total loss': 0.13311276255357687}
2022-12-31 03:33:25,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:25,412 INFO:     Epoch: 56
2022-12-31 03:33:27,035 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.49004942178726196, 'Total loss': 0.49004942178726196} | train loss {'Reaction outcome loss': 0.1342641189508815, 'Total loss': 0.1342641189508815}
2022-12-31 03:33:27,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:27,035 INFO:     Epoch: 57
2022-12-31 03:33:28,697 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5022210399309794, 'Total loss': 0.5022210399309794} | train loss {'Reaction outcome loss': 0.1290638048946389, 'Total loss': 0.1290638048946389}
2022-12-31 03:33:28,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:28,698 INFO:     Epoch: 58
2022-12-31 03:33:30,328 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4876019994417826, 'Total loss': 0.4876019994417826} | train loss {'Reaction outcome loss': 0.13094426000896128, 'Total loss': 0.13094426000896128}
2022-12-31 03:33:30,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:30,329 INFO:     Epoch: 59
2022-12-31 03:33:31,947 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4808490534623464, 'Total loss': 0.4808490534623464} | train loss {'Reaction outcome loss': 0.12972402863248345, 'Total loss': 0.12972402863248345}
2022-12-31 03:33:31,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:31,948 INFO:     Epoch: 60
2022-12-31 03:33:33,576 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5027631059288978, 'Total loss': 0.5027631059288978} | train loss {'Reaction outcome loss': 0.13195937446663805, 'Total loss': 0.13195937446663805}
2022-12-31 03:33:33,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:33,576 INFO:     Epoch: 61
2022-12-31 03:33:35,202 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5376397887865703, 'Total loss': 0.5376397887865703} | train loss {'Reaction outcome loss': 0.13094102952332384, 'Total loss': 0.13094102952332384}
2022-12-31 03:33:35,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:35,203 INFO:     Epoch: 62
2022-12-31 03:33:36,815 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4837406724691391, 'Total loss': 0.4837406724691391} | train loss {'Reaction outcome loss': 0.1532911337066569, 'Total loss': 0.1532911337066569}
2022-12-31 03:33:36,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:36,815 INFO:     Epoch: 63
2022-12-31 03:33:38,432 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49812310536702475, 'Total loss': 0.49812310536702475} | train loss {'Reaction outcome loss': 0.13214265412070614, 'Total loss': 0.13214265412070614}
2022-12-31 03:33:38,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:38,432 INFO:     Epoch: 64
2022-12-31 03:33:40,089 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5213498999675115, 'Total loss': 0.5213498999675115} | train loss {'Reaction outcome loss': 0.12172369865963803, 'Total loss': 0.12172369865963803}
2022-12-31 03:33:40,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:40,089 INFO:     Epoch: 65
2022-12-31 03:33:41,713 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5104901015758514, 'Total loss': 0.5104901015758514} | train loss {'Reaction outcome loss': 0.12098389062515892, 'Total loss': 0.12098389062515892}
2022-12-31 03:33:41,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:41,713 INFO:     Epoch: 66
2022-12-31 03:33:43,344 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.500115821758906, 'Total loss': 0.500115821758906} | train loss {'Reaction outcome loss': 0.12213046541538737, 'Total loss': 0.12213046541538737}
2022-12-31 03:33:43,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:43,344 INFO:     Epoch: 67
2022-12-31 03:33:44,967 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5108405709266662, 'Total loss': 0.5108405709266662} | train loss {'Reaction outcome loss': 0.12369567380195856, 'Total loss': 0.12369567380195856}
2022-12-31 03:33:44,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:44,968 INFO:     Epoch: 68
2022-12-31 03:33:46,576 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5201063632965088, 'Total loss': 0.5201063632965088} | train loss {'Reaction outcome loss': 0.12298805765175055, 'Total loss': 0.12298805765175055}
2022-12-31 03:33:46,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:46,576 INFO:     Epoch: 69
2022-12-31 03:33:48,240 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.544260349869728, 'Total loss': 0.544260349869728} | train loss {'Reaction outcome loss': 0.12382216224753959, 'Total loss': 0.12382216224753959}
2022-12-31 03:33:48,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:48,240 INFO:     Epoch: 70
2022-12-31 03:33:49,856 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5483473738034567, 'Total loss': 0.5483473738034567} | train loss {'Reaction outcome loss': 0.12441168408132279, 'Total loss': 0.12441168408132279}
2022-12-31 03:33:49,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:49,857 INFO:     Epoch: 71
2022-12-31 03:33:51,486 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5485716452201207, 'Total loss': 0.5485716452201207} | train loss {'Reaction outcome loss': 0.12321760036908361, 'Total loss': 0.12321760036908361}
2022-12-31 03:33:51,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:51,486 INFO:     Epoch: 72
2022-12-31 03:33:53,118 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49038761854171753, 'Total loss': 0.49038761854171753} | train loss {'Reaction outcome loss': 0.11953865230231937, 'Total loss': 0.11953865230231937}
2022-12-31 03:33:53,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:53,118 INFO:     Epoch: 73
2022-12-31 03:33:54,749 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.524185906847318, 'Total loss': 0.524185906847318} | train loss {'Reaction outcome loss': 0.11978668292167773, 'Total loss': 0.11978668292167773}
2022-12-31 03:33:54,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:54,749 INFO:     Epoch: 74
2022-12-31 03:33:56,369 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.518477867046992, 'Total loss': 0.518477867046992} | train loss {'Reaction outcome loss': 0.1188513466108091, 'Total loss': 0.1188513466108091}
2022-12-31 03:33:56,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:56,369 INFO:     Epoch: 75
2022-12-31 03:33:57,993 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4864445927242438, 'Total loss': 0.4864445927242438} | train loss {'Reaction outcome loss': 0.11997350773310535, 'Total loss': 0.11997350773310535}
2022-12-31 03:33:57,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:57,993 INFO:     Epoch: 76
2022-12-31 03:33:59,643 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49787447452545164, 'Total loss': 0.49787447452545164} | train loss {'Reaction outcome loss': 0.12012479704909323, 'Total loss': 0.12012479704909323}
2022-12-31 03:33:59,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:33:59,644 INFO:     Epoch: 77
2022-12-31 03:34:01,306 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5063635826110839, 'Total loss': 0.5063635826110839} | train loss {'Reaction outcome loss': 0.11926264543275254, 'Total loss': 0.11926264543275254}
2022-12-31 03:34:01,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:01,308 INFO:     Epoch: 78
2022-12-31 03:34:02,926 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.545787321527799, 'Total loss': 0.545787321527799} | train loss {'Reaction outcome loss': 0.11929397931711772, 'Total loss': 0.11929397931711772}
2022-12-31 03:34:02,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:02,926 INFO:     Epoch: 79
2022-12-31 03:34:04,577 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5127746264139811, 'Total loss': 0.5127746264139811} | train loss {'Reaction outcome loss': 0.12072297590569087, 'Total loss': 0.12072297590569087}
2022-12-31 03:34:04,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:04,577 INFO:     Epoch: 80
2022-12-31 03:34:06,240 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4868966743350029, 'Total loss': 0.4868966743350029} | train loss {'Reaction outcome loss': 0.11729930625955129, 'Total loss': 0.11729930625955129}
2022-12-31 03:34:06,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:06,241 INFO:     Epoch: 81
2022-12-31 03:34:07,853 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5025533040364584, 'Total loss': 0.5025533040364584} | train loss {'Reaction outcome loss': 0.12028919624253172, 'Total loss': 0.12028919624253172}
2022-12-31 03:34:07,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:07,854 INFO:     Epoch: 82
2022-12-31 03:34:09,472 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4786569893360138, 'Total loss': 0.4786569893360138} | train loss {'Reaction outcome loss': 0.11591883068836793, 'Total loss': 0.11591883068836793}
2022-12-31 03:34:09,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:09,472 INFO:     Epoch: 83
2022-12-31 03:34:11,136 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5324955900510152, 'Total loss': 0.5324955900510152} | train loss {'Reaction outcome loss': 0.11490211731193069, 'Total loss': 0.11490211731193069}
2022-12-31 03:34:11,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:11,136 INFO:     Epoch: 84
2022-12-31 03:34:12,756 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48385611871878303, 'Total loss': 0.48385611871878303} | train loss {'Reaction outcome loss': 0.11334942772816209, 'Total loss': 0.11334942772816209}
2022-12-31 03:34:12,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:12,756 INFO:     Epoch: 85
2022-12-31 03:34:14,403 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5446670631567637, 'Total loss': 0.5446670631567637} | train loss {'Reaction outcome loss': 0.11851824440823887, 'Total loss': 0.11851824440823887}
2022-12-31 03:34:14,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:14,403 INFO:     Epoch: 86
2022-12-31 03:34:16,036 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5197369962930679, 'Total loss': 0.5197369962930679} | train loss {'Reaction outcome loss': 0.11917710608898799, 'Total loss': 0.11917710608898799}
2022-12-31 03:34:16,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:16,036 INFO:     Epoch: 87
2022-12-31 03:34:17,676 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5172499110301335, 'Total loss': 0.5172499110301335} | train loss {'Reaction outcome loss': 0.11532475998090218, 'Total loss': 0.11532475998090218}
2022-12-31 03:34:17,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:17,677 INFO:     Epoch: 88
2022-12-31 03:34:19,340 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5353567610184352, 'Total loss': 0.5353567610184352} | train loss {'Reaction outcome loss': 0.11592048046957748, 'Total loss': 0.11592048046957748}
2022-12-31 03:34:19,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:19,341 INFO:     Epoch: 89
2022-12-31 03:34:21,004 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5014464080333709, 'Total loss': 0.5014464080333709} | train loss {'Reaction outcome loss': 0.1114211163605986, 'Total loss': 0.1114211163605986}
2022-12-31 03:34:21,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:21,004 INFO:     Epoch: 90
2022-12-31 03:34:22,640 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.521045732498169, 'Total loss': 0.521045732498169} | train loss {'Reaction outcome loss': 0.11043287410301264, 'Total loss': 0.11043287410301264}
2022-12-31 03:34:22,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:22,641 INFO:     Epoch: 91
2022-12-31 03:34:24,273 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.485780169069767, 'Total loss': 0.485780169069767} | train loss {'Reaction outcome loss': 0.11514805514277701, 'Total loss': 0.11514805514277701}
2022-12-31 03:34:24,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:24,273 INFO:     Epoch: 92
2022-12-31 03:34:25,896 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5302862266699473, 'Total loss': 0.5302862266699473} | train loss {'Reaction outcome loss': 0.1129824363377839, 'Total loss': 0.1129824363377839}
2022-12-31 03:34:25,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:25,897 INFO:     Epoch: 93
2022-12-31 03:34:27,557 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49246116876602175, 'Total loss': 0.49246116876602175} | train loss {'Reaction outcome loss': 0.11693967177711455, 'Total loss': 0.11693967177711455}
2022-12-31 03:34:27,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:27,557 INFO:     Epoch: 94
2022-12-31 03:34:29,176 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5124459624290466, 'Total loss': 0.5124459624290466} | train loss {'Reaction outcome loss': 0.14313746883915196, 'Total loss': 0.14313746883915196}
2022-12-31 03:34:29,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:29,176 INFO:     Epoch: 95
2022-12-31 03:34:30,835 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5002178644140561, 'Total loss': 0.5002178644140561} | train loss {'Reaction outcome loss': 0.11306433752516581, 'Total loss': 0.11306433752516581}
2022-12-31 03:34:30,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:30,836 INFO:     Epoch: 96
2022-12-31 03:34:32,457 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4903881748517354, 'Total loss': 0.4903881748517354} | train loss {'Reaction outcome loss': 0.11407220335356702, 'Total loss': 0.11407220335356702}
2022-12-31 03:34:32,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:32,457 INFO:     Epoch: 97
2022-12-31 03:34:34,076 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5178097933530807, 'Total loss': 0.5178097933530807} | train loss {'Reaction outcome loss': 0.11156413815705742, 'Total loss': 0.11156413815705742}
2022-12-31 03:34:34,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:34,076 INFO:     Epoch: 98
2022-12-31 03:34:35,715 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5162014518243571, 'Total loss': 0.5162014518243571} | train loss {'Reaction outcome loss': 0.11410868480797418, 'Total loss': 0.11410868480797418}
2022-12-31 03:34:35,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:35,715 INFO:     Epoch: 99
2022-12-31 03:34:37,349 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5352587262789409, 'Total loss': 0.5352587262789409} | train loss {'Reaction outcome loss': 0.11145962949594453, 'Total loss': 0.11145962949594453}
2022-12-31 03:34:37,350 INFO:     Best model found after epoch 16 of 100.
2022-12-31 03:34:37,350 INFO:   Done with stage: TRAINING
2022-12-31 03:34:37,350 INFO:   Starting stage: EVALUATION
2022-12-31 03:34:37,481 INFO:   Done with stage: EVALUATION
2022-12-31 03:34:37,481 INFO:   Leaving out SEQ value Fold_9
2022-12-31 03:34:37,494 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 03:34:37,494 INFO:   Starting stage: FEATURE SCALING
2022-12-31 03:34:38,136 INFO:   Done with stage: FEATURE SCALING
2022-12-31 03:34:38,136 INFO:   Starting stage: SCALING TARGETS
2022-12-31 03:34:38,208 INFO:   Done with stage: SCALING TARGETS
2022-12-31 03:34:38,208 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:34:38,208 INFO:     No hyperparam tuning for this model
2022-12-31 03:34:38,208 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:34:38,208 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 03:34:38,209 INFO:     None feature selector for col prot
2022-12-31 03:34:38,209 INFO:     None feature selector for col prot
2022-12-31 03:34:38,209 INFO:     None feature selector for col prot
2022-12-31 03:34:38,210 INFO:     None feature selector for col chem
2022-12-31 03:34:38,210 INFO:     None feature selector for col chem
2022-12-31 03:34:38,210 INFO:     None feature selector for col chem
2022-12-31 03:34:38,210 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 03:34:38,210 INFO:   Starting stage: BUILD MODEL
2022-12-31 03:34:38,212 INFO:     Number of params in model 224011
2022-12-31 03:34:38,215 INFO:   Done with stage: BUILD MODEL
2022-12-31 03:34:38,215 INFO:   Starting stage: TRAINING
2022-12-31 03:34:38,259 INFO:     Val loss before train {'Reaction outcome loss': 1.0044400294621785, 'Total loss': 1.0044400294621785}
2022-12-31 03:34:38,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:38,260 INFO:     Epoch: 0
2022-12-31 03:34:39,881 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5922416826089223, 'Total loss': 0.5922416826089223} | train loss {'Reaction outcome loss': 0.7792104823709826, 'Total loss': 0.7792104823709826}
2022-12-31 03:34:39,881 INFO:     Found new best model at epoch 0
2022-12-31 03:34:39,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:39,882 INFO:     Epoch: 1
2022-12-31 03:34:41,023 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4763534645239512, 'Total loss': 0.4763534645239512} | train loss {'Reaction outcome loss': 0.5205031543001801, 'Total loss': 0.5205031543001801}
2022-12-31 03:34:41,023 INFO:     Found new best model at epoch 1
2022-12-31 03:34:41,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:41,024 INFO:     Epoch: 2
2022-12-31 03:34:42,166 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4435035228729248, 'Total loss': 0.4435035228729248} | train loss {'Reaction outcome loss': 0.4560320275946645, 'Total loss': 0.4560320275946645}
2022-12-31 03:34:42,166 INFO:     Found new best model at epoch 2
2022-12-31 03:34:42,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:42,167 INFO:     Epoch: 3
2022-12-31 03:34:43,362 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.41815319458643596, 'Total loss': 0.41815319458643596} | train loss {'Reaction outcome loss': 0.4148743749202804, 'Total loss': 0.4148743749202804}
2022-12-31 03:34:43,363 INFO:     Found new best model at epoch 3
2022-12-31 03:34:43,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:43,364 INFO:     Epoch: 4
2022-12-31 03:34:44,560 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.40045892894268037, 'Total loss': 0.40045892894268037} | train loss {'Reaction outcome loss': 0.3840568255538975, 'Total loss': 0.3840568255538975}
2022-12-31 03:34:44,560 INFO:     Found new best model at epoch 4
2022-12-31 03:34:44,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:44,561 INFO:     Epoch: 5
2022-12-31 03:34:46,228 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.406023512283961, 'Total loss': 0.406023512283961} | train loss {'Reaction outcome loss': 0.3609521758039936, 'Total loss': 0.3609521758039936}
2022-12-31 03:34:46,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:46,228 INFO:     Epoch: 6
2022-12-31 03:34:47,854 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.38093559443950653, 'Total loss': 0.38093559443950653} | train loss {'Reaction outcome loss': 0.33789611272917325, 'Total loss': 0.33789611272917325}
2022-12-31 03:34:47,855 INFO:     Found new best model at epoch 6
2022-12-31 03:34:47,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:47,856 INFO:     Epoch: 7
2022-12-31 03:34:49,482 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.38914619088172914, 'Total loss': 0.38914619088172914} | train loss {'Reaction outcome loss': 0.31925618600113725, 'Total loss': 0.31925618600113725}
2022-12-31 03:34:49,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:49,483 INFO:     Epoch: 8
2022-12-31 03:34:51,151 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41243781050046285, 'Total loss': 0.41243781050046285} | train loss {'Reaction outcome loss': 0.3029054814431857, 'Total loss': 0.3029054814431857}
2022-12-31 03:34:51,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:51,151 INFO:     Epoch: 9
2022-12-31 03:34:52,777 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3991464575131734, 'Total loss': 0.3991464575131734} | train loss {'Reaction outcome loss': 0.2920014291383084, 'Total loss': 0.2920014291383084}
2022-12-31 03:34:52,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:52,777 INFO:     Epoch: 10
2022-12-31 03:34:54,419 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40671513279279076, 'Total loss': 0.40671513279279076} | train loss {'Reaction outcome loss': 0.27595644960657356, 'Total loss': 0.27595644960657356}
2022-12-31 03:34:54,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:54,419 INFO:     Epoch: 11
2022-12-31 03:34:56,090 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.37575590908527373, 'Total loss': 0.37575590908527373} | train loss {'Reaction outcome loss': 0.2636162484138666, 'Total loss': 0.2636162484138666}
2022-12-31 03:34:56,091 INFO:     Found new best model at epoch 11
2022-12-31 03:34:56,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:56,092 INFO:     Epoch: 12
2022-12-31 03:34:57,716 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3751619617144267, 'Total loss': 0.3751619617144267} | train loss {'Reaction outcome loss': 0.2547019775755139, 'Total loss': 0.2547019775755139}
2022-12-31 03:34:57,716 INFO:     Found new best model at epoch 12
2022-12-31 03:34:57,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:57,717 INFO:     Epoch: 13
2022-12-31 03:34:59,340 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.386046490073204, 'Total loss': 0.386046490073204} | train loss {'Reaction outcome loss': 0.24292497024854598, 'Total loss': 0.24292497024854598}
2022-12-31 03:34:59,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:34:59,340 INFO:     Epoch: 14
2022-12-31 03:35:00,989 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.38129206498463947, 'Total loss': 0.38129206498463947} | train loss {'Reaction outcome loss': 0.23963455737497832, 'Total loss': 0.23963455737497832}
2022-12-31 03:35:00,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:00,989 INFO:     Epoch: 15
2022-12-31 03:35:02,625 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.37424897998571394, 'Total loss': 0.37424897998571394} | train loss {'Reaction outcome loss': 0.23029952839232093, 'Total loss': 0.23029952839232093}
2022-12-31 03:35:02,625 INFO:     Found new best model at epoch 15
2022-12-31 03:35:02,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:02,626 INFO:     Epoch: 16
2022-12-31 03:35:04,283 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3922093470891317, 'Total loss': 0.3922093470891317} | train loss {'Reaction outcome loss': 0.2213895470307407, 'Total loss': 0.2213895470307407}
2022-12-31 03:35:04,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:04,283 INFO:     Epoch: 17
2022-12-31 03:35:05,952 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4152859737475713, 'Total loss': 0.4152859737475713} | train loss {'Reaction outcome loss': 0.21203217762337478, 'Total loss': 0.21203217762337478}
2022-12-31 03:35:05,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:05,952 INFO:     Epoch: 18
2022-12-31 03:35:07,621 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4129698693752289, 'Total loss': 0.4129698693752289} | train loss {'Reaction outcome loss': 0.20554472674827498, 'Total loss': 0.20554472674827498}
2022-12-31 03:35:07,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:07,621 INFO:     Epoch: 19
2022-12-31 03:35:09,291 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40104710360368095, 'Total loss': 0.40104710360368095} | train loss {'Reaction outcome loss': 0.20304186609893068, 'Total loss': 0.20304186609893068}
2022-12-31 03:35:09,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:09,292 INFO:     Epoch: 20
2022-12-31 03:35:10,907 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44052490293979646, 'Total loss': 0.44052490293979646} | train loss {'Reaction outcome loss': 0.19672211108978044, 'Total loss': 0.19672211108978044}
2022-12-31 03:35:10,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:10,907 INFO:     Epoch: 21
2022-12-31 03:35:12,564 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.38607318699359894, 'Total loss': 0.38607318699359894} | train loss {'Reaction outcome loss': 0.19517381955610608, 'Total loss': 0.19517381955610608}
2022-12-31 03:35:12,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:12,565 INFO:     Epoch: 22
2022-12-31 03:35:14,233 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3801091849803925, 'Total loss': 0.3801091849803925} | train loss {'Reaction outcome loss': 0.18855068634267533, 'Total loss': 0.18855068634267533}
2022-12-31 03:35:14,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:14,233 INFO:     Epoch: 23
2022-12-31 03:35:15,902 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3955420836806297, 'Total loss': 0.3955420836806297} | train loss {'Reaction outcome loss': 0.18353928663240013, 'Total loss': 0.18353928663240013}
2022-12-31 03:35:15,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:15,903 INFO:     Epoch: 24
2022-12-31 03:35:17,529 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4199924026926359, 'Total loss': 0.4199924026926359} | train loss {'Reaction outcome loss': 0.18187213916371875, 'Total loss': 0.18187213916371875}
2022-12-31 03:35:17,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:17,529 INFO:     Epoch: 25
2022-12-31 03:35:19,192 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40700335601965587, 'Total loss': 0.40700335601965587} | train loss {'Reaction outcome loss': 0.17860014865087473, 'Total loss': 0.17860014865087473}
2022-12-31 03:35:19,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:19,192 INFO:     Epoch: 26
2022-12-31 03:35:20,817 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39479511181513466, 'Total loss': 0.39479511181513466} | train loss {'Reaction outcome loss': 0.17619420670726024, 'Total loss': 0.17619420670726024}
2022-12-31 03:35:20,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:20,817 INFO:     Epoch: 27
2022-12-31 03:35:22,474 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43220481971899666, 'Total loss': 0.43220481971899666} | train loss {'Reaction outcome loss': 0.17488418313899895, 'Total loss': 0.17488418313899895}
2022-12-31 03:35:22,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:22,474 INFO:     Epoch: 28
2022-12-31 03:35:24,145 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39489997128645576, 'Total loss': 0.39489997128645576} | train loss {'Reaction outcome loss': 0.16757647541523088, 'Total loss': 0.16757647541523088}
2022-12-31 03:35:24,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:24,146 INFO:     Epoch: 29
2022-12-31 03:35:25,773 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.417765008409818, 'Total loss': 0.417765008409818} | train loss {'Reaction outcome loss': 0.16645089481429395, 'Total loss': 0.16645089481429395}
2022-12-31 03:35:25,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:25,773 INFO:     Epoch: 30
2022-12-31 03:35:27,444 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4082836478948593, 'Total loss': 0.4082836478948593} | train loss {'Reaction outcome loss': 0.16264949131434253, 'Total loss': 0.16264949131434253}
2022-12-31 03:35:27,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:27,444 INFO:     Epoch: 31
2022-12-31 03:35:29,067 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.400585608681043, 'Total loss': 0.400585608681043} | train loss {'Reaction outcome loss': 0.16215244576751864, 'Total loss': 0.16215244576751864}
2022-12-31 03:35:29,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:29,068 INFO:     Epoch: 32
2022-12-31 03:35:30,695 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4106741060813268, 'Total loss': 0.4106741060813268} | train loss {'Reaction outcome loss': 0.16191222703602123, 'Total loss': 0.16191222703602123}
2022-12-31 03:35:30,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:30,695 INFO:     Epoch: 33
2022-12-31 03:35:32,365 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42310074269771575, 'Total loss': 0.42310074269771575} | train loss {'Reaction outcome loss': 0.15777710025679548, 'Total loss': 0.15777710025679548}
2022-12-31 03:35:32,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:32,365 INFO:     Epoch: 34
2022-12-31 03:35:33,988 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43908725678920746, 'Total loss': 0.43908725678920746} | train loss {'Reaction outcome loss': 0.15321143662274583, 'Total loss': 0.15321143662274583}
2022-12-31 03:35:33,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:33,988 INFO:     Epoch: 35
2022-12-31 03:35:35,658 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4223382512728373, 'Total loss': 0.4223382512728373} | train loss {'Reaction outcome loss': 0.15518016664862685, 'Total loss': 0.15518016664862685}
2022-12-31 03:35:35,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:35,658 INFO:     Epoch: 36
2022-12-31 03:35:37,276 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.417784654100736, 'Total loss': 0.417784654100736} | train loss {'Reaction outcome loss': 0.15324339600253029, 'Total loss': 0.15324339600253029}
2022-12-31 03:35:37,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:37,276 INFO:     Epoch: 37
2022-12-31 03:35:38,899 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4507192095120748, 'Total loss': 0.4507192095120748} | train loss {'Reaction outcome loss': 0.15280224603436054, 'Total loss': 0.15280224603436054}
2022-12-31 03:35:38,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:38,899 INFO:     Epoch: 38
2022-12-31 03:35:40,515 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4200107673803965, 'Total loss': 0.4200107673803965} | train loss {'Reaction outcome loss': 0.1464854670749029, 'Total loss': 0.1464854670749029}
2022-12-31 03:35:40,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:40,516 INFO:     Epoch: 39
2022-12-31 03:35:42,139 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4231584995985031, 'Total loss': 0.4231584995985031} | train loss {'Reaction outcome loss': 0.1486329876881644, 'Total loss': 0.1486329876881644}
2022-12-31 03:35:42,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:42,139 INFO:     Epoch: 40
2022-12-31 03:35:43,765 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4271279230713844, 'Total loss': 0.4271279230713844} | train loss {'Reaction outcome loss': 0.14323945669289206, 'Total loss': 0.14323945669289206}
2022-12-31 03:35:43,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:43,766 INFO:     Epoch: 41
2022-12-31 03:35:45,390 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42062644263108573, 'Total loss': 0.42062644263108573} | train loss {'Reaction outcome loss': 0.14673657256887976, 'Total loss': 0.14673657256887976}
2022-12-31 03:35:45,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:45,390 INFO:     Epoch: 42
2022-12-31 03:35:47,010 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4438013255596161, 'Total loss': 0.4438013255596161} | train loss {'Reaction outcome loss': 0.14434060054269723, 'Total loss': 0.14434060054269723}
2022-12-31 03:35:47,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:47,011 INFO:     Epoch: 43
2022-12-31 03:35:48,634 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41216752827167513, 'Total loss': 0.41216752827167513} | train loss {'Reaction outcome loss': 0.14369396774252938, 'Total loss': 0.14369396774252938}
2022-12-31 03:35:48,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:48,634 INFO:     Epoch: 44
2022-12-31 03:35:50,256 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4419548640648524, 'Total loss': 0.4419548640648524} | train loss {'Reaction outcome loss': 0.13852202562474064, 'Total loss': 0.13852202562474064}
2022-12-31 03:35:50,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:50,257 INFO:     Epoch: 45
2022-12-31 03:35:51,882 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4296579534808795, 'Total loss': 0.4296579534808795} | train loss {'Reaction outcome loss': 0.14057256800411705, 'Total loss': 0.14057256800411705}
2022-12-31 03:35:51,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:51,882 INFO:     Epoch: 46
2022-12-31 03:35:53,552 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43273912370204926, 'Total loss': 0.43273912370204926} | train loss {'Reaction outcome loss': 0.13510122578187647, 'Total loss': 0.13510122578187647}
2022-12-31 03:35:53,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:53,553 INFO:     Epoch: 47
2022-12-31 03:35:55,178 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44439096252123517, 'Total loss': 0.44439096252123517} | train loss {'Reaction outcome loss': 0.13852095470800727, 'Total loss': 0.13852095470800727}
2022-12-31 03:35:55,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:55,179 INFO:     Epoch: 48
2022-12-31 03:35:56,836 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.420769701898098, 'Total loss': 0.420769701898098} | train loss {'Reaction outcome loss': 0.14077993435617064, 'Total loss': 0.14077993435617064}
2022-12-31 03:35:56,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:56,836 INFO:     Epoch: 49
2022-12-31 03:35:58,490 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40528788045048714, 'Total loss': 0.40528788045048714} | train loss {'Reaction outcome loss': 0.13574639539694958, 'Total loss': 0.13574639539694958}
2022-12-31 03:35:58,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:35:58,490 INFO:     Epoch: 50
2022-12-31 03:36:00,113 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.428524050116539, 'Total loss': 0.428524050116539} | train loss {'Reaction outcome loss': 0.13264268604426607, 'Total loss': 0.13264268604426607}
2022-12-31 03:36:00,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:00,113 INFO:     Epoch: 51
2022-12-31 03:36:01,736 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.417362479865551, 'Total loss': 0.417362479865551} | train loss {'Reaction outcome loss': 0.13281735014136786, 'Total loss': 0.13281735014136786}
2022-12-31 03:36:01,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:01,736 INFO:     Epoch: 52
2022-12-31 03:36:03,360 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41630760331948596, 'Total loss': 0.41630760331948596} | train loss {'Reaction outcome loss': 0.13100335610667344, 'Total loss': 0.13100335610667344}
2022-12-31 03:36:03,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:03,361 INFO:     Epoch: 53
2022-12-31 03:36:04,988 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46145639022191365, 'Total loss': 0.46145639022191365} | train loss {'Reaction outcome loss': 0.128939590902683, 'Total loss': 0.128939590902683}
2022-12-31 03:36:04,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:04,988 INFO:     Epoch: 54
2022-12-31 03:36:06,610 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4529816667238871, 'Total loss': 0.4529816667238871} | train loss {'Reaction outcome loss': 0.13457267244417045, 'Total loss': 0.13457267244417045}
2022-12-31 03:36:06,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:06,610 INFO:     Epoch: 55
2022-12-31 03:36:08,232 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4166718805829684, 'Total loss': 0.4166718805829684} | train loss {'Reaction outcome loss': 0.12926106660589845, 'Total loss': 0.12926106660589845}
2022-12-31 03:36:08,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:08,233 INFO:     Epoch: 56
2022-12-31 03:36:09,864 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42210682332515714, 'Total loss': 0.42210682332515714} | train loss {'Reaction outcome loss': 0.12875665451605076, 'Total loss': 0.12875665451605076}
2022-12-31 03:36:09,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:09,864 INFO:     Epoch: 57
2022-12-31 03:36:11,499 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44051726957162224, 'Total loss': 0.44051726957162224} | train loss {'Reaction outcome loss': 0.12624966579704588, 'Total loss': 0.12624966579704588}
2022-12-31 03:36:11,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:11,499 INFO:     Epoch: 58
2022-12-31 03:36:13,132 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44303376575311026, 'Total loss': 0.44303376575311026} | train loss {'Reaction outcome loss': 0.12478167160720118, 'Total loss': 0.12478167160720118}
2022-12-31 03:36:13,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:13,132 INFO:     Epoch: 59
2022-12-31 03:36:14,754 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4784892002741496, 'Total loss': 0.4784892002741496} | train loss {'Reaction outcome loss': 0.12456806951172193, 'Total loss': 0.12456806951172193}
2022-12-31 03:36:14,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:14,754 INFO:     Epoch: 60
2022-12-31 03:36:16,384 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41998419587810837, 'Total loss': 0.41998419587810837} | train loss {'Reaction outcome loss': 0.12263037061776011, 'Total loss': 0.12263037061776011}
2022-12-31 03:36:16,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:16,384 INFO:     Epoch: 61
2022-12-31 03:36:18,007 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4406692365805308, 'Total loss': 0.4406692365805308} | train loss {'Reaction outcome loss': 0.1250046520369524, 'Total loss': 0.1250046520369524}
2022-12-31 03:36:18,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:18,007 INFO:     Epoch: 62
2022-12-31 03:36:19,632 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4625681231419245, 'Total loss': 0.4625681231419245} | train loss {'Reaction outcome loss': 0.12714577163317467, 'Total loss': 0.12714577163317467}
2022-12-31 03:36:19,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:19,633 INFO:     Epoch: 63
2022-12-31 03:36:21,255 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43715728918711344, 'Total loss': 0.43715728918711344} | train loss {'Reaction outcome loss': 0.12740550254091673, 'Total loss': 0.12740550254091673}
2022-12-31 03:36:21,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:21,256 INFO:     Epoch: 64
2022-12-31 03:36:22,882 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4394567499558131, 'Total loss': 0.4394567499558131} | train loss {'Reaction outcome loss': 0.12401390265646502, 'Total loss': 0.12401390265646502}
2022-12-31 03:36:22,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:22,883 INFO:     Epoch: 65
2022-12-31 03:36:24,554 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4881414115428925, 'Total loss': 0.4881414115428925} | train loss {'Reaction outcome loss': 0.12135608515295365, 'Total loss': 0.12135608515295365}
2022-12-31 03:36:24,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:24,554 INFO:     Epoch: 66
2022-12-31 03:36:26,205 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4706005911032359, 'Total loss': 0.4706005911032359} | train loss {'Reaction outcome loss': 0.11931982084718745, 'Total loss': 0.11931982084718745}
2022-12-31 03:36:26,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:26,206 INFO:     Epoch: 67
2022-12-31 03:36:27,828 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4586429923772812, 'Total loss': 0.4586429923772812} | train loss {'Reaction outcome loss': 0.12228548583416571, 'Total loss': 0.12228548583416571}
2022-12-31 03:36:27,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:27,828 INFO:     Epoch: 68
2022-12-31 03:36:29,442 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44427500168482464, 'Total loss': 0.44427500168482464} | train loss {'Reaction outcome loss': 0.11794095691831426, 'Total loss': 0.11794095691831426}
2022-12-31 03:36:29,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:29,442 INFO:     Epoch: 69
2022-12-31 03:36:31,113 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48700378437836966, 'Total loss': 0.48700378437836966} | train loss {'Reaction outcome loss': 0.11957659841673146, 'Total loss': 0.11957659841673146}
2022-12-31 03:36:31,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:31,114 INFO:     Epoch: 70
2022-12-31 03:36:32,740 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4472635845343272, 'Total loss': 0.4472635845343272} | train loss {'Reaction outcome loss': 0.12266234846597383, 'Total loss': 0.12266234846597383}
2022-12-31 03:36:32,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:32,740 INFO:     Epoch: 71
2022-12-31 03:36:34,359 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43757023016611735, 'Total loss': 0.43757023016611735} | train loss {'Reaction outcome loss': 0.12197855342387992, 'Total loss': 0.12197855342387992}
2022-12-31 03:36:34,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:34,360 INFO:     Epoch: 72
2022-12-31 03:36:35,982 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4580697685480118, 'Total loss': 0.4580697685480118} | train loss {'Reaction outcome loss': 0.12013105498559584, 'Total loss': 0.12013105498559584}
2022-12-31 03:36:35,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:35,983 INFO:     Epoch: 73
2022-12-31 03:36:37,596 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4757474422454834, 'Total loss': 0.4757474422454834} | train loss {'Reaction outcome loss': 0.12217523716390133, 'Total loss': 0.12217523716390133}
2022-12-31 03:36:37,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:37,596 INFO:     Epoch: 74
2022-12-31 03:36:39,267 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4656895560522874, 'Total loss': 0.4656895560522874} | train loss {'Reaction outcome loss': 0.1173066189579854, 'Total loss': 0.1173066189579854}
2022-12-31 03:36:39,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:39,268 INFO:     Epoch: 75
2022-12-31 03:36:40,889 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4333436121543249, 'Total loss': 0.4333436121543249} | train loss {'Reaction outcome loss': 0.11420835859044741, 'Total loss': 0.11420835859044741}
2022-12-31 03:36:40,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:40,889 INFO:     Epoch: 76
2022-12-31 03:36:42,506 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4242376506328583, 'Total loss': 0.4242376506328583} | train loss {'Reaction outcome loss': 0.11656974785245067, 'Total loss': 0.11656974785245067}
2022-12-31 03:36:42,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:42,507 INFO:     Epoch: 77
2022-12-31 03:36:44,140 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4374905149141947, 'Total loss': 0.4374905149141947} | train loss {'Reaction outcome loss': 0.11824194583470264, 'Total loss': 0.11824194583470264}
2022-12-31 03:36:44,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:44,140 INFO:     Epoch: 78
2022-12-31 03:36:45,772 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4298805544773738, 'Total loss': 0.4298805544773738} | train loss {'Reaction outcome loss': 0.11798430095588122, 'Total loss': 0.11798430095588122}
2022-12-31 03:36:45,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:45,772 INFO:     Epoch: 79
2022-12-31 03:36:47,407 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4370575984319051, 'Total loss': 0.4370575984319051} | train loss {'Reaction outcome loss': 0.11614774137782437, 'Total loss': 0.11614774137782437}
2022-12-31 03:36:47,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:47,407 INFO:     Epoch: 80
2022-12-31 03:36:49,041 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46863245765368144, 'Total loss': 0.46863245765368144} | train loss {'Reaction outcome loss': 0.11492192011750185, 'Total loss': 0.11492192011750185}
2022-12-31 03:36:49,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:49,041 INFO:     Epoch: 81
2022-12-31 03:36:50,679 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44308092147111894, 'Total loss': 0.44308092147111894} | train loss {'Reaction outcome loss': 0.11338681000325197, 'Total loss': 0.11338681000325197}
2022-12-31 03:36:50,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:50,679 INFO:     Epoch: 82
2022-12-31 03:36:52,305 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44177473584810895, 'Total loss': 0.44177473584810895} | train loss {'Reaction outcome loss': 0.11702215127539334, 'Total loss': 0.11702215127539334}
2022-12-31 03:36:52,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:52,305 INFO:     Epoch: 83
2022-12-31 03:36:53,970 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4636733482281367, 'Total loss': 0.4636733482281367} | train loss {'Reaction outcome loss': 0.11690263518986262, 'Total loss': 0.11690263518986262}
2022-12-31 03:36:53,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:53,971 INFO:     Epoch: 84
2022-12-31 03:36:55,640 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43072688722362124, 'Total loss': 0.43072688722362124} | train loss {'Reaction outcome loss': 0.1160530179406143, 'Total loss': 0.1160530179406143}
2022-12-31 03:36:55,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:55,641 INFO:     Epoch: 85
2022-12-31 03:36:57,296 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47868665953477224, 'Total loss': 0.47868665953477224} | train loss {'Reaction outcome loss': 0.11036734875553836, 'Total loss': 0.11036734875553836}
2022-12-31 03:36:57,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:57,296 INFO:     Epoch: 86
2022-12-31 03:36:58,916 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45215359230836233, 'Total loss': 0.45215359230836233} | train loss {'Reaction outcome loss': 0.11567959880005797, 'Total loss': 0.11567959880005797}
2022-12-31 03:36:58,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:36:58,916 INFO:     Epoch: 87
2022-12-31 03:37:00,566 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4427285112440586, 'Total loss': 0.4427285112440586} | train loss {'Reaction outcome loss': 0.11487037321007962, 'Total loss': 0.11487037321007962}
2022-12-31 03:37:00,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:00,567 INFO:     Epoch: 88
2022-12-31 03:37:02,206 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44209750145673754, 'Total loss': 0.44209750145673754} | train loss {'Reaction outcome loss': 0.11820095136470837, 'Total loss': 0.11820095136470837}
2022-12-31 03:37:02,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:02,207 INFO:     Epoch: 89
2022-12-31 03:37:03,827 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4568173935015996, 'Total loss': 0.4568173935015996} | train loss {'Reaction outcome loss': 0.11465705545545163, 'Total loss': 0.11465705545545163}
2022-12-31 03:37:03,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:03,827 INFO:     Epoch: 90
2022-12-31 03:37:05,496 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4334426740805308, 'Total loss': 0.4334426740805308} | train loss {'Reaction outcome loss': 0.11208182086139272, 'Total loss': 0.11208182086139272}
2022-12-31 03:37:05,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:05,496 INFO:     Epoch: 91
2022-12-31 03:37:07,117 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4405683939655622, 'Total loss': 0.4405683939655622} | train loss {'Reaction outcome loss': 0.11043597154642056, 'Total loss': 0.11043597154642056}
2022-12-31 03:37:07,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:07,117 INFO:     Epoch: 92
2022-12-31 03:37:08,772 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4725252131621043, 'Total loss': 0.4725252131621043} | train loss {'Reaction outcome loss': 0.1141928211606817, 'Total loss': 0.1141928211606817}
2022-12-31 03:37:08,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:08,772 INFO:     Epoch: 93
2022-12-31 03:37:10,442 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47149013380209603, 'Total loss': 0.47149013380209603} | train loss {'Reaction outcome loss': 0.1168181286395161, 'Total loss': 0.1168181286395161}
2022-12-31 03:37:10,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:10,442 INFO:     Epoch: 94
2022-12-31 03:37:12,071 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4478703558444977, 'Total loss': 0.4478703558444977} | train loss {'Reaction outcome loss': 0.11209317867388606, 'Total loss': 0.11209317867388606}
2022-12-31 03:37:12,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:12,071 INFO:     Epoch: 95
2022-12-31 03:37:13,734 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44888034959634143, 'Total loss': 0.44888034959634143} | train loss {'Reaction outcome loss': 0.10782773959591635, 'Total loss': 0.10782773959591635}
2022-12-31 03:37:13,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:13,734 INFO:     Epoch: 96
2022-12-31 03:37:15,405 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.460548131664594, 'Total loss': 0.460548131664594} | train loss {'Reaction outcome loss': 0.11187200139895323, 'Total loss': 0.11187200139895323}
2022-12-31 03:37:15,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:15,406 INFO:     Epoch: 97
2022-12-31 03:37:17,026 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4400428205728531, 'Total loss': 0.4400428205728531} | train loss {'Reaction outcome loss': 0.11417063917554511, 'Total loss': 0.11417063917554511}
2022-12-31 03:37:17,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:17,026 INFO:     Epoch: 98
2022-12-31 03:37:18,659 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46519449750582376, 'Total loss': 0.46519449750582376} | train loss {'Reaction outcome loss': 0.11963420273023338, 'Total loss': 0.11963420273023338}
2022-12-31 03:37:18,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:18,659 INFO:     Epoch: 99
2022-12-31 03:37:20,278 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4358898937702179, 'Total loss': 0.4358898937702179} | train loss {'Reaction outcome loss': 0.11391708921533522, 'Total loss': 0.11391708921533522}
2022-12-31 03:37:20,278 INFO:     Best model found after epoch 16 of 100.
2022-12-31 03:37:20,279 INFO:   Done with stage: TRAINING
2022-12-31 03:37:20,279 INFO:   Starting stage: EVALUATION
2022-12-31 03:37:20,403 INFO:   Done with stage: EVALUATION
2022-12-31 03:37:20,412 INFO:   Leaving out SEQ value Fold_0
2022-12-31 03:37:20,425 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 03:37:20,425 INFO:   Starting stage: FEATURE SCALING
2022-12-31 03:37:21,073 INFO:   Done with stage: FEATURE SCALING
2022-12-31 03:37:21,073 INFO:   Starting stage: SCALING TARGETS
2022-12-31 03:37:21,145 INFO:   Done with stage: SCALING TARGETS
2022-12-31 03:37:21,145 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:37:21,145 INFO:     No hyperparam tuning for this model
2022-12-31 03:37:21,145 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:37:21,145 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 03:37:21,146 INFO:     None feature selector for col prot
2022-12-31 03:37:21,146 INFO:     None feature selector for col prot
2022-12-31 03:37:21,146 INFO:     None feature selector for col prot
2022-12-31 03:37:21,146 INFO:     None feature selector for col chem
2022-12-31 03:37:21,147 INFO:     None feature selector for col chem
2022-12-31 03:37:21,147 INFO:     None feature selector for col chem
2022-12-31 03:37:21,147 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 03:37:21,147 INFO:   Starting stage: BUILD MODEL
2022-12-31 03:37:21,149 INFO:     Number of params in model 224011
2022-12-31 03:37:21,152 INFO:   Done with stage: BUILD MODEL
2022-12-31 03:37:21,152 INFO:   Starting stage: TRAINING
2022-12-31 03:37:21,196 INFO:     Val loss before train {'Reaction outcome loss': 0.994490098953247, 'Total loss': 0.994490098953247}
2022-12-31 03:37:21,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:21,196 INFO:     Epoch: 0
2022-12-31 03:37:22,797 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5635715186595917, 'Total loss': 0.5635715186595917} | train loss {'Reaction outcome loss': 0.7832040736710069, 'Total loss': 0.7832040736710069}
2022-12-31 03:37:22,797 INFO:     Found new best model at epoch 0
2022-12-31 03:37:22,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:22,798 INFO:     Epoch: 1
2022-12-31 03:37:24,399 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.47961998681227364, 'Total loss': 0.47961998681227364} | train loss {'Reaction outcome loss': 0.5119844168207072, 'Total loss': 0.5119844168207072}
2022-12-31 03:37:24,399 INFO:     Found new best model at epoch 1
2022-12-31 03:37:24,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:24,400 INFO:     Epoch: 2
2022-12-31 03:37:25,998 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4747108370065689, 'Total loss': 0.4747108370065689} | train loss {'Reaction outcome loss': 0.4429996831573709, 'Total loss': 0.4429996831573709}
2022-12-31 03:37:26,000 INFO:     Found new best model at epoch 2
2022-12-31 03:37:26,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:26,001 INFO:     Epoch: 3
2022-12-31 03:37:27,641 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4495591710011164, 'Total loss': 0.4495591710011164} | train loss {'Reaction outcome loss': 0.4006438129139643, 'Total loss': 0.4006438129139643}
2022-12-31 03:37:27,641 INFO:     Found new best model at epoch 3
2022-12-31 03:37:27,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:27,642 INFO:     Epoch: 4
2022-12-31 03:37:29,255 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44603431224823, 'Total loss': 0.44603431224823} | train loss {'Reaction outcome loss': 0.3720441944081418, 'Total loss': 0.3720441944081418}
2022-12-31 03:37:29,255 INFO:     Found new best model at epoch 4
2022-12-31 03:37:29,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:29,256 INFO:     Epoch: 5
2022-12-31 03:37:30,867 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4203907877206802, 'Total loss': 0.4203907877206802} | train loss {'Reaction outcome loss': 0.34884606709663013, 'Total loss': 0.34884606709663013}
2022-12-31 03:37:30,868 INFO:     Found new best model at epoch 5
2022-12-31 03:37:30,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:30,869 INFO:     Epoch: 6
2022-12-31 03:37:32,476 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42110641996065773, 'Total loss': 0.42110641996065773} | train loss {'Reaction outcome loss': 0.3302199171217036, 'Total loss': 0.3302199171217036}
2022-12-31 03:37:32,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:32,477 INFO:     Epoch: 7
2022-12-31 03:37:34,080 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44955797791481017, 'Total loss': 0.44955797791481017} | train loss {'Reaction outcome loss': 0.3077954825312987, 'Total loss': 0.3077954825312987}
2022-12-31 03:37:34,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:34,080 INFO:     Epoch: 8
2022-12-31 03:37:35,706 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4081750879685084, 'Total loss': 0.4081750879685084} | train loss {'Reaction outcome loss': 0.2957054820917819, 'Total loss': 0.2957054820917819}
2022-12-31 03:37:35,706 INFO:     Found new best model at epoch 8
2022-12-31 03:37:35,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:35,707 INFO:     Epoch: 9
2022-12-31 03:37:37,313 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.37476749941706655, 'Total loss': 0.37476749941706655} | train loss {'Reaction outcome loss': 0.2787899622748042, 'Total loss': 0.2787899622748042}
2022-12-31 03:37:37,313 INFO:     Found new best model at epoch 9
2022-12-31 03:37:37,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:37,314 INFO:     Epoch: 10
2022-12-31 03:37:38,913 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.38748026043176653, 'Total loss': 0.38748026043176653} | train loss {'Reaction outcome loss': 0.269044912481395, 'Total loss': 0.269044912481395}
2022-12-31 03:37:38,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:38,914 INFO:     Epoch: 11
2022-12-31 03:37:40,565 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4161796073118846, 'Total loss': 0.4161796073118846} | train loss {'Reaction outcome loss': 0.258770826388232, 'Total loss': 0.258770826388232}
2022-12-31 03:37:40,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:40,565 INFO:     Epoch: 12
2022-12-31 03:37:42,168 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.38677365332841873, 'Total loss': 0.38677365332841873} | train loss {'Reaction outcome loss': 0.2505060409052964, 'Total loss': 0.2505060409052964}
2022-12-31 03:37:42,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:42,168 INFO:     Epoch: 13
2022-12-31 03:37:43,791 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39746082822481793, 'Total loss': 0.39746082822481793} | train loss {'Reaction outcome loss': 0.24089638623714882, 'Total loss': 0.24089638623714882}
2022-12-31 03:37:43,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:43,791 INFO:     Epoch: 14
2022-12-31 03:37:45,427 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41942880749702455, 'Total loss': 0.41942880749702455} | train loss {'Reaction outcome loss': 0.23414326865688292, 'Total loss': 0.23414326865688292}
2022-12-31 03:37:45,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:45,428 INFO:     Epoch: 15
2022-12-31 03:37:47,051 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.38108910620212555, 'Total loss': 0.38108910620212555} | train loss {'Reaction outcome loss': 0.22628594418974035, 'Total loss': 0.22628594418974035}
2022-12-31 03:37:47,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:47,052 INFO:     Epoch: 16
2022-12-31 03:37:48,663 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40804433127244316, 'Total loss': 0.40804433127244316} | train loss {'Reaction outcome loss': 0.22064593488717602, 'Total loss': 0.22064593488717602}
2022-12-31 03:37:48,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:48,663 INFO:     Epoch: 17
2022-12-31 03:37:50,277 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3858160346746445, 'Total loss': 0.3858160346746445} | train loss {'Reaction outcome loss': 0.211688272988111, 'Total loss': 0.211688272988111}
2022-12-31 03:37:50,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:50,277 INFO:     Epoch: 18
2022-12-31 03:37:51,895 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41540464957555134, 'Total loss': 0.41540464957555134} | train loss {'Reaction outcome loss': 0.20881189475937265, 'Total loss': 0.20881189475937265}
2022-12-31 03:37:51,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:51,896 INFO:     Epoch: 19
2022-12-31 03:37:53,524 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41224601765473684, 'Total loss': 0.41224601765473684} | train loss {'Reaction outcome loss': 0.20060237607558387, 'Total loss': 0.20060237607558387}
2022-12-31 03:37:53,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:53,524 INFO:     Epoch: 20
2022-12-31 03:37:55,128 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40630141434570155, 'Total loss': 0.40630141434570155} | train loss {'Reaction outcome loss': 0.19497896781204826, 'Total loss': 0.19497896781204826}
2022-12-31 03:37:55,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:55,128 INFO:     Epoch: 21
2022-12-31 03:37:56,741 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4333378235499064, 'Total loss': 0.4333378235499064} | train loss {'Reaction outcome loss': 0.1909637159198849, 'Total loss': 0.1909637159198849}
2022-12-31 03:37:56,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:56,742 INFO:     Epoch: 22
2022-12-31 03:37:58,357 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4230916957060496, 'Total loss': 0.4230916957060496} | train loss {'Reaction outcome loss': 0.18609027001313375, 'Total loss': 0.18609027001313375}
2022-12-31 03:37:58,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:58,357 INFO:     Epoch: 23
2022-12-31 03:37:59,971 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41264920035998026, 'Total loss': 0.41264920035998026} | train loss {'Reaction outcome loss': 0.18080786669654023, 'Total loss': 0.18080786669654023}
2022-12-31 03:37:59,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:37:59,971 INFO:     Epoch: 24
2022-12-31 03:38:01,622 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4386881560087204, 'Total loss': 0.4386881560087204} | train loss {'Reaction outcome loss': 0.18234097413433187, 'Total loss': 0.18234097413433187}
2022-12-31 03:38:01,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:01,622 INFO:     Epoch: 25
2022-12-31 03:38:03,246 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41423459549744923, 'Total loss': 0.41423459549744923} | train loss {'Reaction outcome loss': 0.17650195621429896, 'Total loss': 0.17650195621429896}
2022-12-31 03:38:03,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:03,247 INFO:     Epoch: 26
2022-12-31 03:38:04,857 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4103526751200358, 'Total loss': 0.4103526751200358} | train loss {'Reaction outcome loss': 0.16971026193758432, 'Total loss': 0.16971026193758432}
2022-12-31 03:38:04,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:04,857 INFO:     Epoch: 27
2022-12-31 03:38:06,506 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4315415322780609, 'Total loss': 0.4315415322780609} | train loss {'Reaction outcome loss': 0.16844621952963026, 'Total loss': 0.16844621952963026}
2022-12-31 03:38:06,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:06,506 INFO:     Epoch: 28
2022-12-31 03:38:08,158 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4107570966084798, 'Total loss': 0.4107570966084798} | train loss {'Reaction outcome loss': 0.16751466862802958, 'Total loss': 0.16751466862802958}
2022-12-31 03:38:08,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:08,158 INFO:     Epoch: 29
2022-12-31 03:38:09,764 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47066004772981007, 'Total loss': 0.47066004772981007} | train loss {'Reaction outcome loss': 0.16268447289297724, 'Total loss': 0.16268447289297724}
2022-12-31 03:38:09,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:09,765 INFO:     Epoch: 30
2022-12-31 03:38:11,373 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42740881045659385, 'Total loss': 0.42740881045659385} | train loss {'Reaction outcome loss': 0.1626252394176367, 'Total loss': 0.1626252394176367}
2022-12-31 03:38:11,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:11,374 INFO:     Epoch: 31
2022-12-31 03:38:12,978 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4233454217513402, 'Total loss': 0.4233454217513402} | train loss {'Reaction outcome loss': 0.1583350439535549, 'Total loss': 0.1583350439535549}
2022-12-31 03:38:12,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:12,978 INFO:     Epoch: 32
2022-12-31 03:38:14,615 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43484384516874947, 'Total loss': 0.43484384516874947} | train loss {'Reaction outcome loss': 0.15758380714300885, 'Total loss': 0.15758380714300885}
2022-12-31 03:38:14,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:14,616 INFO:     Epoch: 33
2022-12-31 03:38:16,225 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4498414302865664, 'Total loss': 0.4498414302865664} | train loss {'Reaction outcome loss': 0.15907008070022846, 'Total loss': 0.15907008070022846}
2022-12-31 03:38:16,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:16,226 INFO:     Epoch: 34
2022-12-31 03:38:17,833 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4443214108546575, 'Total loss': 0.4443214108546575} | train loss {'Reaction outcome loss': 0.15178542362906747, 'Total loss': 0.15178542362906747}
2022-12-31 03:38:17,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:17,833 INFO:     Epoch: 35
2022-12-31 03:38:19,485 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4205310265223185, 'Total loss': 0.4205310265223185} | train loss {'Reaction outcome loss': 0.15376120476038568, 'Total loss': 0.15376120476038568}
2022-12-31 03:38:19,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:19,485 INFO:     Epoch: 36
2022-12-31 03:38:21,091 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42902778685092924, 'Total loss': 0.42902778685092924} | train loss {'Reaction outcome loss': 0.14768608539181688, 'Total loss': 0.14768608539181688}
2022-12-31 03:38:21,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:21,092 INFO:     Epoch: 37
2022-12-31 03:38:22,743 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4542262474695841, 'Total loss': 0.4542262474695841} | train loss {'Reaction outcome loss': 0.14531855094994345, 'Total loss': 0.14531855094994345}
2022-12-31 03:38:22,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:22,744 INFO:     Epoch: 38
2022-12-31 03:38:24,339 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4422037462393443, 'Total loss': 0.4422037462393443} | train loss {'Reaction outcome loss': 0.14662426634331363, 'Total loss': 0.14662426634331363}
2022-12-31 03:38:24,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:24,340 INFO:     Epoch: 39
2022-12-31 03:38:25,991 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4801058312257131, 'Total loss': 0.4801058312257131} | train loss {'Reaction outcome loss': 0.14207638771082853, 'Total loss': 0.14207638771082853}
2022-12-31 03:38:25,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:25,991 INFO:     Epoch: 40
2022-12-31 03:38:27,642 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4438241948684057, 'Total loss': 0.4438241948684057} | train loss {'Reaction outcome loss': 0.14333852120321652, 'Total loss': 0.14333852120321652}
2022-12-31 03:38:27,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:27,642 INFO:     Epoch: 41
2022-12-31 03:38:29,294 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4546422819296519, 'Total loss': 0.4546422819296519} | train loss {'Reaction outcome loss': 0.14279503005821884, 'Total loss': 0.14279503005821884}
2022-12-31 03:38:29,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:29,295 INFO:     Epoch: 42
2022-12-31 03:38:30,904 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4668205748001734, 'Total loss': 0.4668205748001734} | train loss {'Reaction outcome loss': 0.1403909702853293, 'Total loss': 0.1403909702853293}
2022-12-31 03:38:30,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:30,905 INFO:     Epoch: 43
2022-12-31 03:38:32,516 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44707861840724944, 'Total loss': 0.44707861840724944} | train loss {'Reaction outcome loss': 0.13833593636458863, 'Total loss': 0.13833593636458863}
2022-12-31 03:38:32,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:32,516 INFO:     Epoch: 44
2022-12-31 03:38:34,126 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47773973445097606, 'Total loss': 0.47773973445097606} | train loss {'Reaction outcome loss': 0.13864321475610628, 'Total loss': 0.13864321475610628}
2022-12-31 03:38:34,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:34,127 INFO:     Epoch: 45
2022-12-31 03:38:35,736 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46797046562035877, 'Total loss': 0.46797046562035877} | train loss {'Reaction outcome loss': 0.13774529219618625, 'Total loss': 0.13774529219618625}
2022-12-31 03:38:35,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:35,737 INFO:     Epoch: 46
2022-12-31 03:38:37,389 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4484969804684321, 'Total loss': 0.4484969804684321} | train loss {'Reaction outcome loss': 0.13540719956309147, 'Total loss': 0.13540719956309147}
2022-12-31 03:38:37,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:37,389 INFO:     Epoch: 47
2022-12-31 03:38:38,995 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46113174557685854, 'Total loss': 0.46113174557685854} | train loss {'Reaction outcome loss': 0.13330571889965692, 'Total loss': 0.13330571889965692}
2022-12-31 03:38:38,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:38,997 INFO:     Epoch: 48
2022-12-31 03:38:40,597 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.470743989944458, 'Total loss': 0.470743989944458} | train loss {'Reaction outcome loss': 0.13376199996547541, 'Total loss': 0.13376199996547541}
2022-12-31 03:38:40,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:40,597 INFO:     Epoch: 49
2022-12-31 03:38:42,216 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43706221183141075, 'Total loss': 0.43706221183141075} | train loss {'Reaction outcome loss': 0.1341168069770138, 'Total loss': 0.1341168069770138}
2022-12-31 03:38:42,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:42,217 INFO:     Epoch: 50
2022-12-31 03:38:43,831 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4487318346897761, 'Total loss': 0.4487318346897761} | train loss {'Reaction outcome loss': 0.133566478959006, 'Total loss': 0.133566478959006}
2022-12-31 03:38:43,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:43,831 INFO:     Epoch: 51
2022-12-31 03:38:45,446 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48065062165260314, 'Total loss': 0.48065062165260314} | train loss {'Reaction outcome loss': 0.1342010981518857, 'Total loss': 0.1342010981518857}
2022-12-31 03:38:45,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:45,447 INFO:     Epoch: 52
2022-12-31 03:38:47,065 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44896179338296255, 'Total loss': 0.44896179338296255} | train loss {'Reaction outcome loss': 0.13019127936958994, 'Total loss': 0.13019127936958994}
2022-12-31 03:38:47,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:47,065 INFO:     Epoch: 53
2022-12-31 03:38:48,677 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4652070124944051, 'Total loss': 0.4652070124944051} | train loss {'Reaction outcome loss': 0.12976000981786065, 'Total loss': 0.12976000981786065}
2022-12-31 03:38:48,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:48,677 INFO:     Epoch: 54
2022-12-31 03:38:50,286 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41230335645377636, 'Total loss': 0.41230335645377636} | train loss {'Reaction outcome loss': 0.1272047219702797, 'Total loss': 0.1272047219702797}
2022-12-31 03:38:50,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:50,286 INFO:     Epoch: 55
2022-12-31 03:38:51,922 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46343273917833966, 'Total loss': 0.46343273917833966} | train loss {'Reaction outcome loss': 0.13044046932477912, 'Total loss': 0.13044046932477912}
2022-12-31 03:38:51,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:51,923 INFO:     Epoch: 56
2022-12-31 03:38:53,533 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4832264189918836, 'Total loss': 0.4832264189918836} | train loss {'Reaction outcome loss': 0.1297883990655796, 'Total loss': 0.1297883990655796}
2022-12-31 03:38:53,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:53,533 INFO:     Epoch: 57
2022-12-31 03:38:55,184 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44759335269530615, 'Total loss': 0.44759335269530615} | train loss {'Reaction outcome loss': 0.12373078866168367, 'Total loss': 0.12373078866168367}
2022-12-31 03:38:55,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:55,184 INFO:     Epoch: 58
2022-12-31 03:38:56,794 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46451202034950256, 'Total loss': 0.46451202034950256} | train loss {'Reaction outcome loss': 0.12656608076738943, 'Total loss': 0.12656608076738943}
2022-12-31 03:38:56,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:56,794 INFO:     Epoch: 59
2022-12-31 03:38:58,409 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4484244724114736, 'Total loss': 0.4484244724114736} | train loss {'Reaction outcome loss': 0.123701801588147, 'Total loss': 0.123701801588147}
2022-12-31 03:38:58,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:38:58,410 INFO:     Epoch: 60
2022-12-31 03:39:00,016 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4713846410314242, 'Total loss': 0.4713846410314242} | train loss {'Reaction outcome loss': 0.12421714065827592, 'Total loss': 0.12421714065827592}
2022-12-31 03:39:00,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:00,016 INFO:     Epoch: 61
2022-12-31 03:39:01,663 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4171800275643667, 'Total loss': 0.4171800275643667} | train loss {'Reaction outcome loss': 0.1233234711987286, 'Total loss': 0.1233234711987286}
2022-12-31 03:39:01,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:01,663 INFO:     Epoch: 62
2022-12-31 03:39:03,311 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.469548425078392, 'Total loss': 0.469548425078392} | train loss {'Reaction outcome loss': 0.11937744159380613, 'Total loss': 0.11937744159380613}
2022-12-31 03:39:03,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:03,311 INFO:     Epoch: 63
2022-12-31 03:39:04,916 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4382467379172643, 'Total loss': 0.4382467379172643} | train loss {'Reaction outcome loss': 0.119432450647731, 'Total loss': 0.119432450647731}
2022-12-31 03:39:04,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:04,917 INFO:     Epoch: 64
2022-12-31 03:39:06,561 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4885771781206131, 'Total loss': 0.4885771781206131} | train loss {'Reaction outcome loss': 0.12104775788548001, 'Total loss': 0.12104775788548001}
2022-12-31 03:39:06,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:06,562 INFO:     Epoch: 65
2022-12-31 03:39:08,200 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4655767967303594, 'Total loss': 0.4655767967303594} | train loss {'Reaction outcome loss': 0.12347455655163439, 'Total loss': 0.12347455655163439}
2022-12-31 03:39:08,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:08,200 INFO:     Epoch: 66
2022-12-31 03:39:09,805 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4422467569510142, 'Total loss': 0.4422467569510142} | train loss {'Reaction outcome loss': 0.11907752171111205, 'Total loss': 0.11907752171111205}
2022-12-31 03:39:09,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:09,806 INFO:     Epoch: 67
2022-12-31 03:39:11,410 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4570599983135859, 'Total loss': 0.4570599983135859} | train loss {'Reaction outcome loss': 0.12005939696963033, 'Total loss': 0.12005939696963033}
2022-12-31 03:39:11,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:11,410 INFO:     Epoch: 68
2022-12-31 03:39:13,059 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4830231490544975, 'Total loss': 0.4830231490544975} | train loss {'Reaction outcome loss': 0.11772277876717739, 'Total loss': 0.11772277876717739}
2022-12-31 03:39:13,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:13,059 INFO:     Epoch: 69
2022-12-31 03:39:14,706 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4982302109400431, 'Total loss': 0.4982302109400431} | train loss {'Reaction outcome loss': 0.11852716484589733, 'Total loss': 0.11852716484589733}
2022-12-31 03:39:14,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:14,708 INFO:     Epoch: 70
2022-12-31 03:39:16,301 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48316663429141044, 'Total loss': 0.48316663429141044} | train loss {'Reaction outcome loss': 0.11783709007580459, 'Total loss': 0.11783709007580459}
2022-12-31 03:39:16,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:16,301 INFO:     Epoch: 71
2022-12-31 03:39:17,939 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4702240983645121, 'Total loss': 0.4702240983645121} | train loss {'Reaction outcome loss': 0.12028968527430438, 'Total loss': 0.12028968527430438}
2022-12-31 03:39:17,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:17,940 INFO:     Epoch: 72
2022-12-31 03:39:19,535 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4233923022945722, 'Total loss': 0.4233923022945722} | train loss {'Reaction outcome loss': 0.11736011666069011, 'Total loss': 0.11736011666069011}
2022-12-31 03:39:19,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:19,535 INFO:     Epoch: 73
2022-12-31 03:39:21,183 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4864996373653412, 'Total loss': 0.4864996373653412} | train loss {'Reaction outcome loss': 0.11502653633645415, 'Total loss': 0.11502653633645415}
2022-12-31 03:39:21,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:21,184 INFO:     Epoch: 74
2022-12-31 03:39:22,781 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4741458475589752, 'Total loss': 0.4741458475589752} | train loss {'Reaction outcome loss': 0.11470737422724683, 'Total loss': 0.11470737422724683}
2022-12-31 03:39:22,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:22,782 INFO:     Epoch: 75
2022-12-31 03:39:24,429 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.466900172829628, 'Total loss': 0.466900172829628} | train loss {'Reaction outcome loss': 0.11433332736678693, 'Total loss': 0.11433332736678693}
2022-12-31 03:39:24,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:24,430 INFO:     Epoch: 76
2022-12-31 03:39:26,061 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45630355974038445, 'Total loss': 0.45630355974038445} | train loss {'Reaction outcome loss': 0.11423707561207133, 'Total loss': 0.11423707561207133}
2022-12-31 03:39:26,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:26,061 INFO:     Epoch: 77
2022-12-31 03:39:27,683 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4517791266242663, 'Total loss': 0.4517791266242663} | train loss {'Reaction outcome loss': 0.11382008748159601, 'Total loss': 0.11382008748159601}
2022-12-31 03:39:27,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:27,684 INFO:     Epoch: 78
2022-12-31 03:39:29,293 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4988461514314016, 'Total loss': 0.4988461514314016} | train loss {'Reaction outcome loss': 0.1097372760154973, 'Total loss': 0.1097372760154973}
2022-12-31 03:39:29,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:29,294 INFO:     Epoch: 79
2022-12-31 03:39:30,902 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4946051468451818, 'Total loss': 0.4946051468451818} | train loss {'Reaction outcome loss': 0.11091598927512439, 'Total loss': 0.11091598927512439}
2022-12-31 03:39:30,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:30,903 INFO:     Epoch: 80
2022-12-31 03:39:32,509 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4255831321080526, 'Total loss': 0.4255831321080526} | train loss {'Reaction outcome loss': 0.1130060529978742, 'Total loss': 0.1130060529978742}
2022-12-31 03:39:32,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:32,509 INFO:     Epoch: 81
2022-12-31 03:39:34,108 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45951740505794686, 'Total loss': 0.45951740505794686} | train loss {'Reaction outcome loss': 0.11730998266066839, 'Total loss': 0.11730998266066839}
2022-12-31 03:39:34,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:34,109 INFO:     Epoch: 82
2022-12-31 03:39:35,716 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4619688053925832, 'Total loss': 0.4619688053925832} | train loss {'Reaction outcome loss': 0.11408301735939254, 'Total loss': 0.11408301735939254}
2022-12-31 03:39:35,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:35,716 INFO:     Epoch: 83
2022-12-31 03:39:37,344 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5050418158372243, 'Total loss': 0.5050418158372243} | train loss {'Reaction outcome loss': 0.12193217992028017, 'Total loss': 0.12193217992028017}
2022-12-31 03:39:37,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:37,344 INFO:     Epoch: 84
2022-12-31 03:39:38,992 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4987725555896759, 'Total loss': 0.4987725555896759} | train loss {'Reaction outcome loss': 0.1135551906377757, 'Total loss': 0.1135551906377757}
2022-12-31 03:39:38,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:38,992 INFO:     Epoch: 85
2022-12-31 03:39:40,641 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48577464719613395, 'Total loss': 0.48577464719613395} | train loss {'Reaction outcome loss': 0.11126631053324354, 'Total loss': 0.11126631053324354}
2022-12-31 03:39:40,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:40,642 INFO:     Epoch: 86
2022-12-31 03:39:42,289 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4851875166098277, 'Total loss': 0.4851875166098277} | train loss {'Reaction outcome loss': 0.1105761148127299, 'Total loss': 0.1105761148127299}
2022-12-31 03:39:42,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:42,290 INFO:     Epoch: 87
2022-12-31 03:39:43,922 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4959317515293757, 'Total loss': 0.4959317515293757} | train loss {'Reaction outcome loss': 0.11073278330341253, 'Total loss': 0.11073278330341253}
2022-12-31 03:39:43,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:43,922 INFO:     Epoch: 88
2022-12-31 03:39:45,553 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5261567046244939, 'Total loss': 0.5261567046244939} | train loss {'Reaction outcome loss': 0.11013323097170269, 'Total loss': 0.11013323097170269}
2022-12-31 03:39:45,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:45,554 INFO:     Epoch: 89
2022-12-31 03:39:47,163 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4590462177991867, 'Total loss': 0.4590462177991867} | train loss {'Reaction outcome loss': 0.1081492415201055, 'Total loss': 0.1081492415201055}
2022-12-31 03:39:47,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:47,163 INFO:     Epoch: 90
2022-12-31 03:39:48,772 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.489661173025767, 'Total loss': 0.489661173025767} | train loss {'Reaction outcome loss': 0.11141885760117894, 'Total loss': 0.11141885760117894}
2022-12-31 03:39:48,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:48,772 INFO:     Epoch: 91
2022-12-31 03:39:50,384 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47635696132977806, 'Total loss': 0.47635696132977806} | train loss {'Reaction outcome loss': 0.11489598337139417, 'Total loss': 0.11489598337139417}
2022-12-31 03:39:50,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:50,385 INFO:     Epoch: 92
2022-12-31 03:39:51,994 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4634326100349426, 'Total loss': 0.4634326100349426} | train loss {'Reaction outcome loss': 0.10938003613022122, 'Total loss': 0.10938003613022122}
2022-12-31 03:39:51,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:51,994 INFO:     Epoch: 93
2022-12-31 03:39:53,602 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4649470160404841, 'Total loss': 0.4649470160404841} | train loss {'Reaction outcome loss': 0.10650937483020562, 'Total loss': 0.10650937483020562}
2022-12-31 03:39:53,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:53,603 INFO:     Epoch: 94
2022-12-31 03:39:55,235 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4807979623476664, 'Total loss': 0.4807979623476664} | train loss {'Reaction outcome loss': 0.11012719079756933, 'Total loss': 0.11012719079756933}
2022-12-31 03:39:55,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:55,236 INFO:     Epoch: 95
2022-12-31 03:39:56,883 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4858637849489848, 'Total loss': 0.4858637849489848} | train loss {'Reaction outcome loss': 0.10887063992376284, 'Total loss': 0.10887063992376284}
2022-12-31 03:39:56,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:56,884 INFO:     Epoch: 96
2022-12-31 03:39:58,488 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4915781925121943, 'Total loss': 0.4915781925121943} | train loss {'Reaction outcome loss': 0.10990950883277793, 'Total loss': 0.10990950883277793}
2022-12-31 03:39:58,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:39:58,489 INFO:     Epoch: 97
2022-12-31 03:40:00,136 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47929398020108543, 'Total loss': 0.47929398020108543} | train loss {'Reaction outcome loss': 0.11068816516415834, 'Total loss': 0.11068816516415834}
2022-12-31 03:40:00,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:00,136 INFO:     Epoch: 98
2022-12-31 03:40:01,732 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47599188884099325, 'Total loss': 0.47599188884099325} | train loss {'Reaction outcome loss': 0.1091545812095631, 'Total loss': 0.1091545812095631}
2022-12-31 03:40:01,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:01,732 INFO:     Epoch: 99
2022-12-31 03:40:03,379 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4587224692106247, 'Total loss': 0.4587224692106247} | train loss {'Reaction outcome loss': 0.10905022684138023, 'Total loss': 0.10905022684138023}
2022-12-31 03:40:03,380 INFO:     Best model found after epoch 10 of 100.
2022-12-31 03:40:03,380 INFO:   Done with stage: TRAINING
2022-12-31 03:40:03,380 INFO:   Starting stage: EVALUATION
2022-12-31 03:40:03,515 INFO:   Done with stage: EVALUATION
2022-12-31 03:40:03,515 INFO:   Leaving out SEQ value Fold_1
2022-12-31 03:40:03,528 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2022-12-31 03:40:03,528 INFO:   Starting stage: FEATURE SCALING
2022-12-31 03:40:04,257 INFO:   Done with stage: FEATURE SCALING
2022-12-31 03:40:04,257 INFO:   Starting stage: SCALING TARGETS
2022-12-31 03:40:04,329 INFO:   Done with stage: SCALING TARGETS
2022-12-31 03:40:04,329 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:40:04,329 INFO:     No hyperparam tuning for this model
2022-12-31 03:40:04,329 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:40:04,329 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 03:40:04,330 INFO:     None feature selector for col prot
2022-12-31 03:40:04,330 INFO:     None feature selector for col prot
2022-12-31 03:40:04,330 INFO:     None feature selector for col prot
2022-12-31 03:40:04,331 INFO:     None feature selector for col chem
2022-12-31 03:40:04,331 INFO:     None feature selector for col chem
2022-12-31 03:40:04,331 INFO:     None feature selector for col chem
2022-12-31 03:40:04,331 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 03:40:04,331 INFO:   Starting stage: BUILD MODEL
2022-12-31 03:40:04,333 INFO:     Number of params in model 224011
2022-12-31 03:40:04,336 INFO:   Done with stage: BUILD MODEL
2022-12-31 03:40:04,336 INFO:   Starting stage: TRAINING
2022-12-31 03:40:04,381 INFO:     Val loss before train {'Reaction outcome loss': 0.9960043887297313, 'Total loss': 0.9960043887297313}
2022-12-31 03:40:04,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:04,381 INFO:     Epoch: 0
2022-12-31 03:40:05,960 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.577352241675059, 'Total loss': 0.577352241675059} | train loss {'Reaction outcome loss': 0.7738247995446969, 'Total loss': 0.7738247995446969}
2022-12-31 03:40:05,960 INFO:     Found new best model at epoch 0
2022-12-31 03:40:05,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:05,961 INFO:     Epoch: 1
2022-12-31 03:40:07,539 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5010214308897655, 'Total loss': 0.5010214308897655} | train loss {'Reaction outcome loss': 0.510930032747698, 'Total loss': 0.510930032747698}
2022-12-31 03:40:07,539 INFO:     Found new best model at epoch 1
2022-12-31 03:40:07,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:07,541 INFO:     Epoch: 2
2022-12-31 03:40:09,120 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4955313801765442, 'Total loss': 0.4955313801765442} | train loss {'Reaction outcome loss': 0.4426307805239934, 'Total loss': 0.4426307805239934}
2022-12-31 03:40:09,120 INFO:     Found new best model at epoch 2
2022-12-31 03:40:09,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:09,121 INFO:     Epoch: 3
2022-12-31 03:40:10,700 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.43383705243468285, 'Total loss': 0.43383705243468285} | train loss {'Reaction outcome loss': 0.39605158955078723, 'Total loss': 0.39605158955078723}
2022-12-31 03:40:10,700 INFO:     Found new best model at epoch 3
2022-12-31 03:40:10,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:10,701 INFO:     Epoch: 4
2022-12-31 03:40:12,283 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4626805245876312, 'Total loss': 0.4626805245876312} | train loss {'Reaction outcome loss': 0.366301544423033, 'Total loss': 0.366301544423033}
2022-12-31 03:40:12,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:12,283 INFO:     Epoch: 5
2022-12-31 03:40:13,913 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4541801373163859, 'Total loss': 0.4541801373163859} | train loss {'Reaction outcome loss': 0.3434630352247685, 'Total loss': 0.3434630352247685}
2022-12-31 03:40:13,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:13,913 INFO:     Epoch: 6
2022-12-31 03:40:15,501 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4351162388920784, 'Total loss': 0.4351162388920784} | train loss {'Reaction outcome loss': 0.32276092505433024, 'Total loss': 0.32276092505433024}
2022-12-31 03:40:15,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:15,502 INFO:     Epoch: 7
2022-12-31 03:40:17,131 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4575585683186849, 'Total loss': 0.4575585683186849} | train loss {'Reaction outcome loss': 0.30577038165278103, 'Total loss': 0.30577038165278103}
2022-12-31 03:40:17,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:17,132 INFO:     Epoch: 8
2022-12-31 03:40:18,716 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4556069056193034, 'Total loss': 0.4556069056193034} | train loss {'Reaction outcome loss': 0.2873546486218697, 'Total loss': 0.2873546486218697}
2022-12-31 03:40:18,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:18,717 INFO:     Epoch: 9
2022-12-31 03:40:20,311 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4705023149649302, 'Total loss': 0.4705023149649302} | train loss {'Reaction outcome loss': 0.27545251249167313, 'Total loss': 0.27545251249167313}
2022-12-31 03:40:20,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:20,311 INFO:     Epoch: 10
2022-12-31 03:40:21,907 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4076455811659495, 'Total loss': 0.4076455811659495} | train loss {'Reaction outcome loss': 0.2639556016044423, 'Total loss': 0.2639556016044423}
2022-12-31 03:40:21,907 INFO:     Found new best model at epoch 10
2022-12-31 03:40:21,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:21,908 INFO:     Epoch: 11
2022-12-31 03:40:23,489 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4548400561014811, 'Total loss': 0.4548400561014811} | train loss {'Reaction outcome loss': 0.25559048999334616, 'Total loss': 0.25559048999334616}
2022-12-31 03:40:23,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:23,489 INFO:     Epoch: 12
2022-12-31 03:40:25,120 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44456225832303364, 'Total loss': 0.44456225832303364} | train loss {'Reaction outcome loss': 0.24447264767001037, 'Total loss': 0.24447264767001037}
2022-12-31 03:40:25,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:25,120 INFO:     Epoch: 13
2022-12-31 03:40:26,752 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4569581106305122, 'Total loss': 0.4569581106305122} | train loss {'Reaction outcome loss': 0.23774471488606005, 'Total loss': 0.23774471488606005}
2022-12-31 03:40:26,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:26,753 INFO:     Epoch: 14
2022-12-31 03:40:28,332 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42966462336480615, 'Total loss': 0.42966462336480615} | train loss {'Reaction outcome loss': 0.22544300952768193, 'Total loss': 0.22544300952768193}
2022-12-31 03:40:28,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:28,332 INFO:     Epoch: 15
2022-12-31 03:40:29,954 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47217997709910076, 'Total loss': 0.47217997709910076} | train loss {'Reaction outcome loss': 0.22405648521556626, 'Total loss': 0.22405648521556626}
2022-12-31 03:40:29,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:29,954 INFO:     Epoch: 16
2022-12-31 03:40:31,575 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4352759993324677, 'Total loss': 0.4352759993324677} | train loss {'Reaction outcome loss': 0.21358996669579697, 'Total loss': 0.21358996669579697}
2022-12-31 03:40:31,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:31,576 INFO:     Epoch: 17
2022-12-31 03:40:33,206 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49743063052495323, 'Total loss': 0.49743063052495323} | train loss {'Reaction outcome loss': 0.2077718007058675, 'Total loss': 0.2077718007058675}
2022-12-31 03:40:33,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:33,206 INFO:     Epoch: 18
2022-12-31 03:40:34,794 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4630409856637319, 'Total loss': 0.4630409856637319} | train loss {'Reaction outcome loss': 0.20358573789691134, 'Total loss': 0.20358573789691134}
2022-12-31 03:40:34,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:34,794 INFO:     Epoch: 19
2022-12-31 03:40:36,424 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44018768668174746, 'Total loss': 0.44018768668174746} | train loss {'Reaction outcome loss': 0.19415826743599235, 'Total loss': 0.19415826743599235}
2022-12-31 03:40:36,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:36,424 INFO:     Epoch: 20
2022-12-31 03:40:38,007 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46232933054367703, 'Total loss': 0.46232933054367703} | train loss {'Reaction outcome loss': 0.19215138622892958, 'Total loss': 0.19215138622892958}
2022-12-31 03:40:38,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:38,007 INFO:     Epoch: 21
2022-12-31 03:40:39,630 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4090988007684549, 'Total loss': 0.4090988007684549} | train loss {'Reaction outcome loss': 0.18620070800652583, 'Total loss': 0.18620070800652583}
2022-12-31 03:40:39,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:39,631 INFO:     Epoch: 22
2022-12-31 03:40:41,254 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4739895542462667, 'Total loss': 0.4739895542462667} | train loss {'Reaction outcome loss': 0.18586981115086051, 'Total loss': 0.18586981115086051}
2022-12-31 03:40:41,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:41,254 INFO:     Epoch: 23
2022-12-31 03:40:42,885 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.452339834968249, 'Total loss': 0.452339834968249} | train loss {'Reaction outcome loss': 0.18011400690542817, 'Total loss': 0.18011400690542817}
2022-12-31 03:40:42,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:42,885 INFO:     Epoch: 24
2022-12-31 03:40:44,517 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4435897320508957, 'Total loss': 0.4435897320508957} | train loss {'Reaction outcome loss': 0.17867159890182785, 'Total loss': 0.17867159890182785}
2022-12-31 03:40:44,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:44,517 INFO:     Epoch: 25
2022-12-31 03:40:46,149 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4708609938621521, 'Total loss': 0.4708609938621521} | train loss {'Reaction outcome loss': 0.17341305513443542, 'Total loss': 0.17341305513443542}
2022-12-31 03:40:46,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:46,150 INFO:     Epoch: 26
2022-12-31 03:40:47,727 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43983619213104247, 'Total loss': 0.43983619213104247} | train loss {'Reaction outcome loss': 0.17437718227863092, 'Total loss': 0.17437718227863092}
2022-12-31 03:40:47,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:47,727 INFO:     Epoch: 27
2022-12-31 03:40:49,333 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45534221331278485, 'Total loss': 0.45534221331278485} | train loss {'Reaction outcome loss': 0.16600102832973884, 'Total loss': 0.16600102832973884}
2022-12-31 03:40:49,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:49,334 INFO:     Epoch: 28
2022-12-31 03:40:50,932 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4603783746560415, 'Total loss': 0.4603783746560415} | train loss {'Reaction outcome loss': 0.1626089217959185, 'Total loss': 0.1626089217959185}
2022-12-31 03:40:50,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:50,932 INFO:     Epoch: 29
2022-12-31 03:40:52,530 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47500407695770264, 'Total loss': 0.47500407695770264} | train loss {'Reaction outcome loss': 0.1576743550887297, 'Total loss': 0.1576743550887297}
2022-12-31 03:40:52,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:52,530 INFO:     Epoch: 30
2022-12-31 03:40:54,128 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44430880347887675, 'Total loss': 0.44430880347887675} | train loss {'Reaction outcome loss': 0.1616505412694163, 'Total loss': 0.1616505412694163}
2022-12-31 03:40:54,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:54,129 INFO:     Epoch: 31
2022-12-31 03:40:55,728 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43858318229516347, 'Total loss': 0.43858318229516347} | train loss {'Reaction outcome loss': 0.15307012253966717, 'Total loss': 0.15307012253966717}
2022-12-31 03:40:55,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:55,728 INFO:     Epoch: 32
2022-12-31 03:40:57,317 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5200988789399464, 'Total loss': 0.5200988789399464} | train loss {'Reaction outcome loss': 0.1568380551880081, 'Total loss': 0.1568380551880081}
2022-12-31 03:40:57,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:57,317 INFO:     Epoch: 33
2022-12-31 03:40:58,923 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4794866979122162, 'Total loss': 0.4794866979122162} | train loss {'Reaction outcome loss': 0.14819726211661507, 'Total loss': 0.14819726211661507}
2022-12-31 03:40:58,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:40:58,923 INFO:     Epoch: 34
2022-12-31 03:41:00,554 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48947259386380515, 'Total loss': 0.48947259386380515} | train loss {'Reaction outcome loss': 0.15004441301197474, 'Total loss': 0.15004441301197474}
2022-12-31 03:41:00,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:00,554 INFO:     Epoch: 35
2022-12-31 03:41:02,183 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4704937756061554, 'Total loss': 0.4704937756061554} | train loss {'Reaction outcome loss': 0.14725191609562818, 'Total loss': 0.14725191609562818}
2022-12-31 03:41:02,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:02,185 INFO:     Epoch: 36
2022-12-31 03:41:03,769 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4478449573119481, 'Total loss': 0.4478449573119481} | train loss {'Reaction outcome loss': 0.14787516602730838, 'Total loss': 0.14787516602730838}
2022-12-31 03:41:03,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:03,769 INFO:     Epoch: 37
2022-12-31 03:41:05,357 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44259569346904754, 'Total loss': 0.44259569346904754} | train loss {'Reaction outcome loss': 0.14389967435551634, 'Total loss': 0.14389967435551634}
2022-12-31 03:41:05,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:05,357 INFO:     Epoch: 38
2022-12-31 03:41:06,987 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45485913058122, 'Total loss': 0.45485913058122} | train loss {'Reaction outcome loss': 0.14590210822922936, 'Total loss': 0.14590210822922936}
2022-12-31 03:41:06,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:06,987 INFO:     Epoch: 39
2022-12-31 03:41:08,577 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4603093276421229, 'Total loss': 0.4603093276421229} | train loss {'Reaction outcome loss': 0.1433055626530874, 'Total loss': 0.1433055626530874}
2022-12-31 03:41:08,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:08,578 INFO:     Epoch: 40
2022-12-31 03:41:10,174 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4326873833934466, 'Total loss': 0.4326873833934466} | train loss {'Reaction outcome loss': 0.14339641248979143, 'Total loss': 0.14339641248979143}
2022-12-31 03:41:10,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:10,174 INFO:     Epoch: 41
2022-12-31 03:41:11,770 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46267095108826956, 'Total loss': 0.46267095108826956} | train loss {'Reaction outcome loss': 0.13699536800137085, 'Total loss': 0.13699536800137085}
2022-12-31 03:41:11,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:11,770 INFO:     Epoch: 42
2022-12-31 03:41:13,368 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4533772826194763, 'Total loss': 0.4533772826194763} | train loss {'Reaction outcome loss': 0.13993022321101375, 'Total loss': 0.13993022321101375}
2022-12-31 03:41:13,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:13,369 INFO:     Epoch: 43
2022-12-31 03:41:14,972 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45396841963132223, 'Total loss': 0.45396841963132223} | train loss {'Reaction outcome loss': 0.13655685021359873, 'Total loss': 0.13655685021359873}
2022-12-31 03:41:14,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:14,972 INFO:     Epoch: 44
2022-12-31 03:41:16,584 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49283355673154194, 'Total loss': 0.49283355673154194} | train loss {'Reaction outcome loss': 0.1364962479298955, 'Total loss': 0.1364962479298955}
2022-12-31 03:41:16,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:16,584 INFO:     Epoch: 45
2022-12-31 03:41:18,215 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45741408864657085, 'Total loss': 0.45741408864657085} | train loss {'Reaction outcome loss': 0.13740319984439225, 'Total loss': 0.13740319984439225}
2022-12-31 03:41:18,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:18,215 INFO:     Epoch: 46
2022-12-31 03:41:19,845 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4660531491041183, 'Total loss': 0.4660531491041183} | train loss {'Reaction outcome loss': 0.13130847735818463, 'Total loss': 0.13130847735818463}
2022-12-31 03:41:19,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:19,846 INFO:     Epoch: 47
2022-12-31 03:41:21,429 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4548087079698841, 'Total loss': 0.4548087079698841} | train loss {'Reaction outcome loss': 0.134621142158869, 'Total loss': 0.134621142158869}
2022-12-31 03:41:21,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:21,430 INFO:     Epoch: 48
2022-12-31 03:41:23,013 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4325290421644847, 'Total loss': 0.4325290421644847} | train loss {'Reaction outcome loss': 0.13206003426928142, 'Total loss': 0.13206003426928142}
2022-12-31 03:41:23,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:23,013 INFO:     Epoch: 49
2022-12-31 03:41:24,608 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4530669609705607, 'Total loss': 0.4530669609705607} | train loss {'Reaction outcome loss': 0.13041255298857593, 'Total loss': 0.13041255298857593}
2022-12-31 03:41:24,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:24,608 INFO:     Epoch: 50
2022-12-31 03:41:26,196 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42893107533454894, 'Total loss': 0.42893107533454894} | train loss {'Reaction outcome loss': 0.13298200948225727, 'Total loss': 0.13298200948225727}
2022-12-31 03:41:26,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:26,196 INFO:     Epoch: 51
2022-12-31 03:41:27,794 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4222353513042132, 'Total loss': 0.4222353513042132} | train loss {'Reaction outcome loss': 0.12694887239812458, 'Total loss': 0.12694887239812458}
2022-12-31 03:41:27,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:27,794 INFO:     Epoch: 52
2022-12-31 03:41:29,392 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48088630735874177, 'Total loss': 0.48088630735874177} | train loss {'Reaction outcome loss': 0.12728535079799344, 'Total loss': 0.12728535079799344}
2022-12-31 03:41:29,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:29,392 INFO:     Epoch: 53
2022-12-31 03:41:30,992 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45778180261452994, 'Total loss': 0.45778180261452994} | train loss {'Reaction outcome loss': 0.12877452775073062, 'Total loss': 0.12877452775073062}
2022-12-31 03:41:30,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:30,992 INFO:     Epoch: 54
2022-12-31 03:41:32,582 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4544542943437894, 'Total loss': 0.4544542943437894} | train loss {'Reaction outcome loss': 0.12332100583570305, 'Total loss': 0.12332100583570305}
2022-12-31 03:41:32,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:32,582 INFO:     Epoch: 55
2022-12-31 03:41:34,178 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48076395789782206, 'Total loss': 0.48076395789782206} | train loss {'Reaction outcome loss': 0.12450830095079882, 'Total loss': 0.12450830095079882}
2022-12-31 03:41:34,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:34,178 INFO:     Epoch: 56
2022-12-31 03:41:35,750 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47150212625662485, 'Total loss': 0.47150212625662485} | train loss {'Reaction outcome loss': 0.12693246726695848, 'Total loss': 0.12693246726695848}
2022-12-31 03:41:35,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:35,750 INFO:     Epoch: 57
2022-12-31 03:41:37,381 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4831320931514104, 'Total loss': 0.4831320931514104} | train loss {'Reaction outcome loss': 0.12596146132439595, 'Total loss': 0.12596146132439595}
2022-12-31 03:41:37,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:37,382 INFO:     Epoch: 58
2022-12-31 03:41:38,959 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4301147133111954, 'Total loss': 0.4301147133111954} | train loss {'Reaction outcome loss': 0.12565694980983144, 'Total loss': 0.12565694980983144}
2022-12-31 03:41:38,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:38,959 INFO:     Epoch: 59
2022-12-31 03:41:40,590 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48322507441043855, 'Total loss': 0.48322507441043855} | train loss {'Reaction outcome loss': 0.1250446075564972, 'Total loss': 0.1250446075564972}
2022-12-31 03:41:40,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:40,591 INFO:     Epoch: 60
2022-12-31 03:41:42,197 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4424165343244871, 'Total loss': 0.4424165343244871} | train loss {'Reaction outcome loss': 0.1233157976444577, 'Total loss': 0.1233157976444577}
2022-12-31 03:41:42,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:42,197 INFO:     Epoch: 61
2022-12-31 03:41:43,791 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4450355410575867, 'Total loss': 0.4450355410575867} | train loss {'Reaction outcome loss': 0.12342626875355785, 'Total loss': 0.12342626875355785}
2022-12-31 03:41:43,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:43,792 INFO:     Epoch: 62
2022-12-31 03:41:45,376 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44690479934215543, 'Total loss': 0.44690479934215543} | train loss {'Reaction outcome loss': 0.12085213395766914, 'Total loss': 0.12085213395766914}
2022-12-31 03:41:45,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:45,376 INFO:     Epoch: 63
2022-12-31 03:41:47,006 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4550265481074651, 'Total loss': 0.4550265481074651} | train loss {'Reaction outcome loss': 0.12032198732223953, 'Total loss': 0.12032198732223953}
2022-12-31 03:41:47,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:47,007 INFO:     Epoch: 64
2022-12-31 03:41:48,591 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4446672449509303, 'Total loss': 0.4446672449509303} | train loss {'Reaction outcome loss': 0.12102140071440996, 'Total loss': 0.12102140071440996}
2022-12-31 03:41:48,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:48,591 INFO:     Epoch: 65
2022-12-31 03:41:50,221 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4621081926083813, 'Total loss': 0.4621081926083813} | train loss {'Reaction outcome loss': 0.1202302954651113, 'Total loss': 0.1202302954651113}
2022-12-31 03:41:50,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:50,222 INFO:     Epoch: 66
2022-12-31 03:41:51,800 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5033193334937096, 'Total loss': 0.5033193334937096} | train loss {'Reaction outcome loss': 0.12235685047174621, 'Total loss': 0.12235685047174621}
2022-12-31 03:41:51,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:51,800 INFO:     Epoch: 67
2022-12-31 03:41:53,403 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44137744084000585, 'Total loss': 0.44137744084000585} | train loss {'Reaction outcome loss': 0.12081053730175999, 'Total loss': 0.12081053730175999}
2022-12-31 03:41:53,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:53,403 INFO:     Epoch: 68
2022-12-31 03:41:55,001 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4799883981545766, 'Total loss': 0.4799883981545766} | train loss {'Reaction outcome loss': 0.12004086083467926, 'Total loss': 0.12004086083467926}
2022-12-31 03:41:55,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:55,001 INFO:     Epoch: 69
2022-12-31 03:41:56,598 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49833641449610394, 'Total loss': 0.49833641449610394} | train loss {'Reaction outcome loss': 0.11734913221158334, 'Total loss': 0.11734913221158334}
2022-12-31 03:41:56,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:56,599 INFO:     Epoch: 70
2022-12-31 03:41:58,196 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44589678893486656, 'Total loss': 0.44589678893486656} | train loss {'Reaction outcome loss': 0.11879246343765751, 'Total loss': 0.11879246343765751}
2022-12-31 03:41:58,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:58,196 INFO:     Epoch: 71
2022-12-31 03:41:59,787 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4235477862569193, 'Total loss': 0.4235477862569193} | train loss {'Reaction outcome loss': 0.11991413185421061, 'Total loss': 0.11991413185421061}
2022-12-31 03:41:59,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:41:59,787 INFO:     Epoch: 72
2022-12-31 03:42:01,364 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5135456303755442, 'Total loss': 0.5135456303755442} | train loss {'Reaction outcome loss': 0.11608780473917447, 'Total loss': 0.11608780473917447}
2022-12-31 03:42:01,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:01,365 INFO:     Epoch: 73
2022-12-31 03:42:02,983 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45519291460514066, 'Total loss': 0.45519291460514066} | train loss {'Reaction outcome loss': 0.11874204742760017, 'Total loss': 0.11874204742760017}
2022-12-31 03:42:02,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:02,983 INFO:     Epoch: 74
2022-12-31 03:42:04,616 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46905742784341176, 'Total loss': 0.46905742784341176} | train loss {'Reaction outcome loss': 0.11918948059454836, 'Total loss': 0.11918948059454836}
2022-12-31 03:42:04,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:04,616 INFO:     Epoch: 75
2022-12-31 03:42:06,200 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5077637831370035, 'Total loss': 0.5077637831370035} | train loss {'Reaction outcome loss': 0.12105835023133352, 'Total loss': 0.12105835023133352}
2022-12-31 03:42:06,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:06,200 INFO:     Epoch: 76
2022-12-31 03:42:07,832 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4410081263631582, 'Total loss': 0.4410081263631582} | train loss {'Reaction outcome loss': 0.11840255572924535, 'Total loss': 0.11840255572924535}
2022-12-31 03:42:07,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:07,833 INFO:     Epoch: 77
2022-12-31 03:42:09,415 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47409720009503264, 'Total loss': 0.47409720009503264} | train loss {'Reaction outcome loss': 0.11485445676921313, 'Total loss': 0.11485445676921313}
2022-12-31 03:42:09,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:09,415 INFO:     Epoch: 78
2022-12-31 03:42:11,028 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4862882787361741, 'Total loss': 0.4862882787361741} | train loss {'Reaction outcome loss': 0.11404345525820427, 'Total loss': 0.11404345525820427}
2022-12-31 03:42:11,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:11,028 INFO:     Epoch: 79
2022-12-31 03:42:12,659 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4812647799650828, 'Total loss': 0.4812647799650828} | train loss {'Reaction outcome loss': 0.11854076696855335, 'Total loss': 0.11854076696855335}
2022-12-31 03:42:12,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:12,660 INFO:     Epoch: 80
2022-12-31 03:42:14,275 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4857833027839661, 'Total loss': 0.4857833027839661} | train loss {'Reaction outcome loss': 0.11477374320169327, 'Total loss': 0.11477374320169327}
2022-12-31 03:42:14,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:14,276 INFO:     Epoch: 81
2022-12-31 03:42:15,859 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4638262708981832, 'Total loss': 0.4638262708981832} | train loss {'Reaction outcome loss': 0.11452863521090403, 'Total loss': 0.11452863521090403}
2022-12-31 03:42:15,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:15,859 INFO:     Epoch: 82
2022-12-31 03:42:17,490 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48815183291832603, 'Total loss': 0.48815183291832603} | train loss {'Reaction outcome loss': 0.11408307401092235, 'Total loss': 0.11408307401092235}
2022-12-31 03:42:17,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:17,490 INFO:     Epoch: 83
2022-12-31 03:42:19,079 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47381403942902883, 'Total loss': 0.47381403942902883} | train loss {'Reaction outcome loss': 0.11502101337124776, 'Total loss': 0.11502101337124776}
2022-12-31 03:42:19,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:19,079 INFO:     Epoch: 84
2022-12-31 03:42:20,676 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49007242123285927, 'Total loss': 0.49007242123285927} | train loss {'Reaction outcome loss': 0.11459514636175219, 'Total loss': 0.11459514636175219}
2022-12-31 03:42:20,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:20,676 INFO:     Epoch: 85
2022-12-31 03:42:22,307 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4751651922861735, 'Total loss': 0.4751651922861735} | train loss {'Reaction outcome loss': 0.11465401568439723, 'Total loss': 0.11465401568439723}
2022-12-31 03:42:22,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:22,307 INFO:     Epoch: 86
2022-12-31 03:42:23,938 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4690118701507648, 'Total loss': 0.4690118701507648} | train loss {'Reaction outcome loss': 0.11894356180841577, 'Total loss': 0.11894356180841577}
2022-12-31 03:42:23,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:23,939 INFO:     Epoch: 87
2022-12-31 03:42:25,525 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4583916539947192, 'Total loss': 0.4583916539947192} | train loss {'Reaction outcome loss': 0.11630555584243193, 'Total loss': 0.11630555584243193}
2022-12-31 03:42:25,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:25,525 INFO:     Epoch: 88
2022-12-31 03:42:27,110 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5228365659713745, 'Total loss': 0.5228365659713745} | train loss {'Reaction outcome loss': 0.11480079553815162, 'Total loss': 0.11480079553815162}
2022-12-31 03:42:27,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:27,111 INFO:     Epoch: 89
2022-12-31 03:42:28,688 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4836176365613937, 'Total loss': 0.4836176365613937} | train loss {'Reaction outcome loss': 0.11095516920962621, 'Total loss': 0.11095516920962621}
2022-12-31 03:42:28,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:28,688 INFO:     Epoch: 90
2022-12-31 03:42:30,303 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5296900441249212, 'Total loss': 0.5296900441249212} | train loss {'Reaction outcome loss': 0.11158135732312814, 'Total loss': 0.11158135732312814}
2022-12-31 03:42:30,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:30,303 INFO:     Epoch: 91
2022-12-31 03:42:31,934 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46899321939175326, 'Total loss': 0.46899321939175326} | train loss {'Reaction outcome loss': 0.1141758987033994, 'Total loss': 0.1141758987033994}
2022-12-31 03:42:31,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:31,935 INFO:     Epoch: 92
2022-12-31 03:42:33,570 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5404737124840419, 'Total loss': 0.5404737124840419} | train loss {'Reaction outcome loss': 0.11191313854174695, 'Total loss': 0.11191313854174695}
2022-12-31 03:42:33,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:33,570 INFO:     Epoch: 93
2022-12-31 03:42:35,154 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47938256760438286, 'Total loss': 0.47938256760438286} | train loss {'Reaction outcome loss': 0.1096583975838133, 'Total loss': 0.1096583975838133}
2022-12-31 03:42:35,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:35,154 INFO:     Epoch: 94
2022-12-31 03:42:36,762 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47277940611044567, 'Total loss': 0.47277940611044567} | train loss {'Reaction outcome loss': 0.11343940285230365, 'Total loss': 0.11343940285230365}
2022-12-31 03:42:36,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:36,762 INFO:     Epoch: 95
2022-12-31 03:42:38,382 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.50695521235466, 'Total loss': 0.50695521235466} | train loss {'Reaction outcome loss': 0.11147965419078693, 'Total loss': 0.11147965419078693}
2022-12-31 03:42:38,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:38,383 INFO:     Epoch: 96
2022-12-31 03:42:40,015 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.49688939452171327, 'Total loss': 0.49688939452171327} | train loss {'Reaction outcome loss': 0.11450035075014423, 'Total loss': 0.11450035075014423}
2022-12-31 03:42:40,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:40,015 INFO:     Epoch: 97
2022-12-31 03:42:41,601 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49528148770332336, 'Total loss': 0.49528148770332336} | train loss {'Reaction outcome loss': 0.1105451954526971, 'Total loss': 0.1105451954526971}
2022-12-31 03:42:41,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:41,601 INFO:     Epoch: 98
2022-12-31 03:42:43,232 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5000365336736043, 'Total loss': 0.5000365336736043} | train loss {'Reaction outcome loss': 0.11173504669171143, 'Total loss': 0.11173504669171143}
2022-12-31 03:42:43,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:43,232 INFO:     Epoch: 99
2022-12-31 03:42:44,816 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4840421477953593, 'Total loss': 0.4840421477953593} | train loss {'Reaction outcome loss': 0.11180289307045596, 'Total loss': 0.11180289307045596}
2022-12-31 03:42:44,817 INFO:     Best model found after epoch 11 of 100.
2022-12-31 03:42:44,817 INFO:   Done with stage: TRAINING
2022-12-31 03:42:44,817 INFO:   Starting stage: EVALUATION
2022-12-31 03:42:44,966 INFO:   Done with stage: EVALUATION
2022-12-31 03:42:44,966 INFO:   Leaving out SEQ value Fold_2
2022-12-31 03:42:44,979 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 03:42:44,979 INFO:   Starting stage: FEATURE SCALING
2022-12-31 03:42:45,630 INFO:   Done with stage: FEATURE SCALING
2022-12-31 03:42:45,630 INFO:   Starting stage: SCALING TARGETS
2022-12-31 03:42:45,703 INFO:   Done with stage: SCALING TARGETS
2022-12-31 03:42:45,703 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:42:45,703 INFO:     No hyperparam tuning for this model
2022-12-31 03:42:45,703 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:42:45,703 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 03:42:45,704 INFO:     None feature selector for col prot
2022-12-31 03:42:45,704 INFO:     None feature selector for col prot
2022-12-31 03:42:45,704 INFO:     None feature selector for col prot
2022-12-31 03:42:45,704 INFO:     None feature selector for col chem
2022-12-31 03:42:45,705 INFO:     None feature selector for col chem
2022-12-31 03:42:45,705 INFO:     None feature selector for col chem
2022-12-31 03:42:45,705 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 03:42:45,705 INFO:   Starting stage: BUILD MODEL
2022-12-31 03:42:45,706 INFO:     Number of params in model 224011
2022-12-31 03:42:45,710 INFO:   Done with stage: BUILD MODEL
2022-12-31 03:42:45,710 INFO:   Starting stage: TRAINING
2022-12-31 03:42:45,753 INFO:     Val loss before train {'Reaction outcome loss': 0.9135956088701884, 'Total loss': 0.9135956088701884}
2022-12-31 03:42:45,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:45,753 INFO:     Epoch: 0
2022-12-31 03:42:47,371 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5475035826365153, 'Total loss': 0.5475035826365153} | train loss {'Reaction outcome loss': 0.7622440541333914, 'Total loss': 0.7622440541333914}
2022-12-31 03:42:47,371 INFO:     Found new best model at epoch 0
2022-12-31 03:42:47,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:47,372 INFO:     Epoch: 1
2022-12-31 03:42:48,990 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4790020634730657, 'Total loss': 0.4790020634730657} | train loss {'Reaction outcome loss': 0.5018057156948076, 'Total loss': 0.5018057156948076}
2022-12-31 03:42:48,991 INFO:     Found new best model at epoch 1
2022-12-31 03:42:48,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:48,992 INFO:     Epoch: 2
2022-12-31 03:42:50,606 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.44777831236521404, 'Total loss': 0.44777831236521404} | train loss {'Reaction outcome loss': 0.4368267170207548, 'Total loss': 0.4368267170207548}
2022-12-31 03:42:50,606 INFO:     Found new best model at epoch 2
2022-12-31 03:42:50,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:50,607 INFO:     Epoch: 3
2022-12-31 03:42:52,223 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4363733887672424, 'Total loss': 0.4363733887672424} | train loss {'Reaction outcome loss': 0.3970201458862942, 'Total loss': 0.3970201458862942}
2022-12-31 03:42:52,223 INFO:     Found new best model at epoch 3
2022-12-31 03:42:52,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:52,224 INFO:     Epoch: 4
2022-12-31 03:42:53,840 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4150289903084437, 'Total loss': 0.4150289903084437} | train loss {'Reaction outcome loss': 0.3703474763382658, 'Total loss': 0.3703474763382658}
2022-12-31 03:42:53,840 INFO:     Found new best model at epoch 4
2022-12-31 03:42:53,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:53,841 INFO:     Epoch: 5
2022-12-31 03:42:55,449 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3946782271067301, 'Total loss': 0.3946782271067301} | train loss {'Reaction outcome loss': 0.3465255764785452, 'Total loss': 0.3465255764785452}
2022-12-31 03:42:55,449 INFO:     Found new best model at epoch 5
2022-12-31 03:42:55,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:55,450 INFO:     Epoch: 6
2022-12-31 03:42:57,088 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.41591497461001076, 'Total loss': 0.41591497461001076} | train loss {'Reaction outcome loss': 0.3270827252270702, 'Total loss': 0.3270827252270702}
2022-12-31 03:42:57,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:57,089 INFO:     Epoch: 7
2022-12-31 03:42:58,713 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4033977657556534, 'Total loss': 0.4033977657556534} | train loss {'Reaction outcome loss': 0.31276643628497486, 'Total loss': 0.31276643628497486}
2022-12-31 03:42:58,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:42:58,713 INFO:     Epoch: 8
2022-12-31 03:43:00,330 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3933633933464686, 'Total loss': 0.3933633933464686} | train loss {'Reaction outcome loss': 0.304094044291718, 'Total loss': 0.304094044291718}
2022-12-31 03:43:00,330 INFO:     Found new best model at epoch 8
2022-12-31 03:43:00,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:00,331 INFO:     Epoch: 9
2022-12-31 03:43:01,950 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4085907051960627, 'Total loss': 0.4085907051960627} | train loss {'Reaction outcome loss': 0.28043113294436317, 'Total loss': 0.28043113294436317}
2022-12-31 03:43:01,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:01,950 INFO:     Epoch: 10
2022-12-31 03:43:03,569 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4113045925895373, 'Total loss': 0.4113045925895373} | train loss {'Reaction outcome loss': 0.2673005509558066, 'Total loss': 0.2673005509558066}
2022-12-31 03:43:03,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:03,570 INFO:     Epoch: 11
2022-12-31 03:43:05,187 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.38409112791220346, 'Total loss': 0.38409112791220346} | train loss {'Reaction outcome loss': 0.25769511891353497, 'Total loss': 0.25769511891353497}
2022-12-31 03:43:05,187 INFO:     Found new best model at epoch 11
2022-12-31 03:43:05,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:05,189 INFO:     Epoch: 12
2022-12-31 03:43:06,808 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41572071810563405, 'Total loss': 0.41572071810563405} | train loss {'Reaction outcome loss': 0.2498495211129657, 'Total loss': 0.2498495211129657}
2022-12-31 03:43:06,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:06,808 INFO:     Epoch: 13
2022-12-31 03:43:08,429 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40305803418159486, 'Total loss': 0.40305803418159486} | train loss {'Reaction outcome loss': 0.24002707731552367, 'Total loss': 0.24002707731552367}
2022-12-31 03:43:08,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:08,429 INFO:     Epoch: 14
2022-12-31 03:43:10,049 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3915755897760391, 'Total loss': 0.3915755897760391} | train loss {'Reaction outcome loss': 0.2351775733295126, 'Total loss': 0.2351775733295126}
2022-12-31 03:43:10,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:10,050 INFO:     Epoch: 15
2022-12-31 03:43:11,673 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3740052103996277, 'Total loss': 0.3740052103996277} | train loss {'Reaction outcome loss': 0.23085243957905113, 'Total loss': 0.23085243957905113}
2022-12-31 03:43:11,673 INFO:     Found new best model at epoch 15
2022-12-31 03:43:11,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:11,674 INFO:     Epoch: 16
2022-12-31 03:43:13,306 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.360067014892896, 'Total loss': 0.360067014892896} | train loss {'Reaction outcome loss': 0.2218661884803821, 'Total loss': 0.2218661884803821}
2022-12-31 03:43:13,306 INFO:     Found new best model at epoch 16
2022-12-31 03:43:13,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:13,307 INFO:     Epoch: 17
2022-12-31 03:43:14,922 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39241692920525867, 'Total loss': 0.39241692920525867} | train loss {'Reaction outcome loss': 0.2155692532289085, 'Total loss': 0.2155692532289085}
2022-12-31 03:43:14,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:14,923 INFO:     Epoch: 18
2022-12-31 03:43:16,536 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3889929170409838, 'Total loss': 0.3889929170409838} | train loss {'Reaction outcome loss': 0.20823208676713123, 'Total loss': 0.20823208676713123}
2022-12-31 03:43:16,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:16,537 INFO:     Epoch: 19
2022-12-31 03:43:18,195 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.37888171821832656, 'Total loss': 0.37888171821832656} | train loss {'Reaction outcome loss': 0.20214536761024804, 'Total loss': 0.20214536761024804}
2022-12-31 03:43:18,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:18,195 INFO:     Epoch: 20
2022-12-31 03:43:19,810 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38102271060148873, 'Total loss': 0.38102271060148873} | train loss {'Reaction outcome loss': 0.19864228639061618, 'Total loss': 0.19864228639061618}
2022-12-31 03:43:19,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:19,810 INFO:     Epoch: 21
2022-12-31 03:43:21,466 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3699873059988022, 'Total loss': 0.3699873059988022} | train loss {'Reaction outcome loss': 0.19379445024948666, 'Total loss': 0.19379445024948666}
2022-12-31 03:43:21,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:21,467 INFO:     Epoch: 22
2022-12-31 03:43:23,126 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3996638059616089, 'Total loss': 0.3996638059616089} | train loss {'Reaction outcome loss': 0.1874997878305452, 'Total loss': 0.1874997878305452}
2022-12-31 03:43:23,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:23,126 INFO:     Epoch: 23
2022-12-31 03:43:24,742 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.35739397406578066, 'Total loss': 0.35739397406578066} | train loss {'Reaction outcome loss': 0.1830781737656292, 'Total loss': 0.1830781737656292}
2022-12-31 03:43:24,742 INFO:     Found new best model at epoch 23
2022-12-31 03:43:24,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:24,743 INFO:     Epoch: 24
2022-12-31 03:43:26,365 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3827218213429054, 'Total loss': 0.3827218213429054} | train loss {'Reaction outcome loss': 0.18146589377758335, 'Total loss': 0.18146589377758335}
2022-12-31 03:43:26,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:26,365 INFO:     Epoch: 25
2022-12-31 03:43:27,988 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3749523083368937, 'Total loss': 0.3749523083368937} | train loss {'Reaction outcome loss': 0.17601317229433544, 'Total loss': 0.17601317229433544}
2022-12-31 03:43:27,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:27,989 INFO:     Epoch: 26
2022-12-31 03:43:29,613 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39215148190657295, 'Total loss': 0.39215148190657295} | train loss {'Reaction outcome loss': 0.17517263520731713, 'Total loss': 0.17517263520731713}
2022-12-31 03:43:29,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:29,613 INFO:     Epoch: 27
2022-12-31 03:43:31,234 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.371271538734436, 'Total loss': 0.371271538734436} | train loss {'Reaction outcome loss': 0.17032375259989657, 'Total loss': 0.17032375259989657}
2022-12-31 03:43:31,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:31,235 INFO:     Epoch: 28
2022-12-31 03:43:32,855 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4035617907842, 'Total loss': 0.4035617907842} | train loss {'Reaction outcome loss': 0.16823089874578992, 'Total loss': 0.16823089874578992}
2022-12-31 03:43:32,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:32,856 INFO:     Epoch: 29
2022-12-31 03:43:34,522 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40811150670051577, 'Total loss': 0.40811150670051577} | train loss {'Reaction outcome loss': 0.164834619372361, 'Total loss': 0.164834619372361}
2022-12-31 03:43:34,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:34,522 INFO:     Epoch: 30
2022-12-31 03:43:36,136 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3916842579841614, 'Total loss': 0.3916842579841614} | train loss {'Reaction outcome loss': 0.16068444128377715, 'Total loss': 0.16068444128377715}
2022-12-31 03:43:36,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:36,136 INFO:     Epoch: 31
2022-12-31 03:43:37,795 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3919989337523778, 'Total loss': 0.3919989337523778} | train loss {'Reaction outcome loss': 0.1595280344962426, 'Total loss': 0.1595280344962426}
2022-12-31 03:43:37,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:37,795 INFO:     Epoch: 32
2022-12-31 03:43:39,408 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40432725350062054, 'Total loss': 0.40432725350062054} | train loss {'Reaction outcome loss': 0.15653848073586984, 'Total loss': 0.15653848073586984}
2022-12-31 03:43:39,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:39,408 INFO:     Epoch: 33
2022-12-31 03:43:41,057 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40842319329579674, 'Total loss': 0.40842319329579674} | train loss {'Reaction outcome loss': 0.15393210881714814, 'Total loss': 0.15393210881714814}
2022-12-31 03:43:41,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:41,057 INFO:     Epoch: 34
2022-12-31 03:43:42,676 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41800668835639954, 'Total loss': 0.41800668835639954} | train loss {'Reaction outcome loss': 0.15155181336972484, 'Total loss': 0.15155181336972484}
2022-12-31 03:43:42,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:42,676 INFO:     Epoch: 35
2022-12-31 03:43:44,336 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4125489771366119, 'Total loss': 0.4125489771366119} | train loss {'Reaction outcome loss': 0.14869341960655985, 'Total loss': 0.14869341960655985}
2022-12-31 03:43:44,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:44,336 INFO:     Epoch: 36
2022-12-31 03:43:45,953 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40929323236147563, 'Total loss': 0.40929323236147563} | train loss {'Reaction outcome loss': 0.14661949553250242, 'Total loss': 0.14661949553250242}
2022-12-31 03:43:45,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:45,955 INFO:     Epoch: 37
2022-12-31 03:43:47,572 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3978553771972656, 'Total loss': 0.3978553771972656} | train loss {'Reaction outcome loss': 0.1455505858057354, 'Total loss': 0.1455505858057354}
2022-12-31 03:43:47,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:47,572 INFO:     Epoch: 38
2022-12-31 03:43:49,178 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3959001421928406, 'Total loss': 0.3959001421928406} | train loss {'Reaction outcome loss': 0.146363666668997, 'Total loss': 0.146363666668997}
2022-12-31 03:43:49,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:49,178 INFO:     Epoch: 39
2022-12-31 03:43:50,823 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4109353184700012, 'Total loss': 0.4109353184700012} | train loss {'Reaction outcome loss': 0.14301033005282027, 'Total loss': 0.14301033005282027}
2022-12-31 03:43:50,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:50,823 INFO:     Epoch: 40
2022-12-31 03:43:52,482 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.444230326016744, 'Total loss': 0.444230326016744} | train loss {'Reaction outcome loss': 0.13845796819330883, 'Total loss': 0.13845796819330883}
2022-12-31 03:43:52,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:52,483 INFO:     Epoch: 41
2022-12-31 03:43:54,098 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40175818900267285, 'Total loss': 0.40175818900267285} | train loss {'Reaction outcome loss': 0.14109451046670732, 'Total loss': 0.14109451046670732}
2022-12-31 03:43:54,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:54,099 INFO:     Epoch: 42
2022-12-31 03:43:55,714 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39777253518501915, 'Total loss': 0.39777253518501915} | train loss {'Reaction outcome loss': 0.13592120399635346, 'Total loss': 0.13592120399635346}
2022-12-31 03:43:55,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:55,714 INFO:     Epoch: 43
2022-12-31 03:43:57,373 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39380365014076235, 'Total loss': 0.39380365014076235} | train loss {'Reaction outcome loss': 0.1369402591913915, 'Total loss': 0.1369402591913915}
2022-12-31 03:43:57,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:57,374 INFO:     Epoch: 44
2022-12-31 03:43:59,004 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4231245776017507, 'Total loss': 0.4231245776017507} | train loss {'Reaction outcome loss': 0.13303795216659414, 'Total loss': 0.13303795216659414}
2022-12-31 03:43:59,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:43:59,004 INFO:     Epoch: 45
2022-12-31 03:44:00,622 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40298840006192527, 'Total loss': 0.40298840006192527} | train loss {'Reaction outcome loss': 0.13570275439828486, 'Total loss': 0.13570275439828486}
2022-12-31 03:44:00,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:00,622 INFO:     Epoch: 46
2022-12-31 03:44:02,281 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38763274202744163, 'Total loss': 0.38763274202744163} | train loss {'Reaction outcome loss': 0.13368177781112667, 'Total loss': 0.13368177781112667}
2022-12-31 03:44:02,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:02,281 INFO:     Epoch: 47
2022-12-31 03:44:03,895 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4223710646231969, 'Total loss': 0.4223710646231969} | train loss {'Reaction outcome loss': 0.1341027751483995, 'Total loss': 0.1341027751483995}
2022-12-31 03:44:03,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:03,896 INFO:     Epoch: 48
2022-12-31 03:44:05,555 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41536041100819904, 'Total loss': 0.41536041100819904} | train loss {'Reaction outcome loss': 0.1445870764496183, 'Total loss': 0.1445870764496183}
2022-12-31 03:44:05,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:05,556 INFO:     Epoch: 49
2022-12-31 03:44:07,168 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39320224324862163, 'Total loss': 0.39320224324862163} | train loss {'Reaction outcome loss': 0.13623057903991784, 'Total loss': 0.13623057903991784}
2022-12-31 03:44:07,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:07,168 INFO:     Epoch: 50
2022-12-31 03:44:08,784 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39105860789616903, 'Total loss': 0.39105860789616903} | train loss {'Reaction outcome loss': 0.1300854541182491, 'Total loss': 0.1300854541182491}
2022-12-31 03:44:08,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:08,784 INFO:     Epoch: 51
2022-12-31 03:44:10,387 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41108188331127166, 'Total loss': 0.41108188331127166} | train loss {'Reaction outcome loss': 0.12566159354215758, 'Total loss': 0.12566159354215758}
2022-12-31 03:44:10,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:10,387 INFO:     Epoch: 52
2022-12-31 03:44:12,048 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3952035278081894, 'Total loss': 0.3952035278081894} | train loss {'Reaction outcome loss': 0.1278283487232672, 'Total loss': 0.1278283487232672}
2022-12-31 03:44:12,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:12,048 INFO:     Epoch: 53
2022-12-31 03:44:13,659 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40757244726022085, 'Total loss': 0.40757244726022085} | train loss {'Reaction outcome loss': 0.12746345233134218, 'Total loss': 0.12746345233134218}
2022-12-31 03:44:13,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:13,659 INFO:     Epoch: 54
2022-12-31 03:44:15,271 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4192898064851761, 'Total loss': 0.4192898064851761} | train loss {'Reaction outcome loss': 0.12696485129698346, 'Total loss': 0.12696485129698346}
2022-12-31 03:44:15,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:15,271 INFO:     Epoch: 55
2022-12-31 03:44:16,876 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4136874164144198, 'Total loss': 0.4136874164144198} | train loss {'Reaction outcome loss': 0.12519300340479106, 'Total loss': 0.12519300340479106}
2022-12-31 03:44:16,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:16,876 INFO:     Epoch: 56
2022-12-31 03:44:18,487 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43710585484902065, 'Total loss': 0.43710585484902065} | train loss {'Reaction outcome loss': 0.12822507887208107, 'Total loss': 0.12822507887208107}
2022-12-31 03:44:18,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:18,487 INFO:     Epoch: 57
2022-12-31 03:44:20,109 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41006022691726685, 'Total loss': 0.41006022691726685} | train loss {'Reaction outcome loss': 0.13343746891157512, 'Total loss': 0.13343746891157512}
2022-12-31 03:44:20,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:20,110 INFO:     Epoch: 58
2022-12-31 03:44:21,732 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4247823586066564, 'Total loss': 0.4247823586066564} | train loss {'Reaction outcome loss': 0.12937077645767495, 'Total loss': 0.12937077645767495}
2022-12-31 03:44:21,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:21,733 INFO:     Epoch: 59
2022-12-31 03:44:23,353 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40735115508238473, 'Total loss': 0.40735115508238473} | train loss {'Reaction outcome loss': 0.12568037693331396, 'Total loss': 0.12568037693331396}
2022-12-31 03:44:23,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:23,353 INFO:     Epoch: 60
2022-12-31 03:44:24,977 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4196204125881195, 'Total loss': 0.4196204125881195} | train loss {'Reaction outcome loss': 0.1251943479494556, 'Total loss': 0.1251943479494556}
2022-12-31 03:44:24,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:24,977 INFO:     Epoch: 61
2022-12-31 03:44:26,601 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39797297591964403, 'Total loss': 0.39797297591964403} | train loss {'Reaction outcome loss': 0.11868370628455549, 'Total loss': 0.11868370628455549}
2022-12-31 03:44:26,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:26,602 INFO:     Epoch: 62
2022-12-31 03:44:28,218 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4376292243599892, 'Total loss': 0.4376292243599892} | train loss {'Reaction outcome loss': 0.11749767669328097, 'Total loss': 0.11749767669328097}
2022-12-31 03:44:28,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:28,219 INFO:     Epoch: 63
2022-12-31 03:44:29,844 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4193673640489578, 'Total loss': 0.4193673640489578} | train loss {'Reaction outcome loss': 0.12017679200895752, 'Total loss': 0.12017679200895752}
2022-12-31 03:44:29,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:29,844 INFO:     Epoch: 64
2022-12-31 03:44:31,471 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.434184471766154, 'Total loss': 0.434184471766154} | train loss {'Reaction outcome loss': 0.11761464612673213, 'Total loss': 0.11761464612673213}
2022-12-31 03:44:31,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:31,471 INFO:     Epoch: 65
2022-12-31 03:44:33,096 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4435537795225779, 'Total loss': 0.4435537795225779} | train loss {'Reaction outcome loss': 0.13210036621118584, 'Total loss': 0.13210036621118584}
2022-12-31 03:44:33,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:33,096 INFO:     Epoch: 66
2022-12-31 03:44:34,629 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4218524205187956, 'Total loss': 0.4218524205187956} | train loss {'Reaction outcome loss': 0.12409048351000293, 'Total loss': 0.12409048351000293}
2022-12-31 03:44:34,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:34,630 INFO:     Epoch: 67
2022-12-31 03:44:35,788 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4050793468952179, 'Total loss': 0.4050793468952179} | train loss {'Reaction outcome loss': 0.11575537164699726, 'Total loss': 0.11575537164699726}
2022-12-31 03:44:35,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:35,788 INFO:     Epoch: 68
2022-12-31 03:44:36,913 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39654597640037537, 'Total loss': 0.39654597640037537} | train loss {'Reaction outcome loss': 0.12221943038056834, 'Total loss': 0.12221943038056834}
2022-12-31 03:44:36,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:36,913 INFO:     Epoch: 69
2022-12-31 03:44:38,034 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42075784504413605, 'Total loss': 0.42075784504413605} | train loss {'Reaction outcome loss': 0.13072175693298999, 'Total loss': 0.13072175693298999}
2022-12-31 03:44:38,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:38,035 INFO:     Epoch: 70
2022-12-31 03:44:39,276 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43087197840213776, 'Total loss': 0.43087197840213776} | train loss {'Reaction outcome loss': 0.11943987100992513, 'Total loss': 0.11943987100992513}
2022-12-31 03:44:39,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:39,276 INFO:     Epoch: 71
2022-12-31 03:44:40,934 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4102129856745402, 'Total loss': 0.4102129856745402} | train loss {'Reaction outcome loss': 0.11686238358168444, 'Total loss': 0.11686238358168444}
2022-12-31 03:44:40,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:40,935 INFO:     Epoch: 72
2022-12-31 03:44:42,558 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4180178442349037, 'Total loss': 0.4180178442349037} | train loss {'Reaction outcome loss': 0.11801318043001009, 'Total loss': 0.11801318043001009}
2022-12-31 03:44:42,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:42,558 INFO:     Epoch: 73
2022-12-31 03:44:44,178 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4367871234814326, 'Total loss': 0.4367871234814326} | train loss {'Reaction outcome loss': 0.11878369809077728, 'Total loss': 0.11878369809077728}
2022-12-31 03:44:44,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:44,179 INFO:     Epoch: 74
2022-12-31 03:44:45,790 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4411691258351008, 'Total loss': 0.4411691258351008} | train loss {'Reaction outcome loss': 0.11471368665798513, 'Total loss': 0.11471368665798513}
2022-12-31 03:44:45,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:45,790 INFO:     Epoch: 75
2022-12-31 03:44:47,402 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4569802359988292, 'Total loss': 0.4569802359988292} | train loss {'Reaction outcome loss': 0.11695656158785889, 'Total loss': 0.11695656158785889}
2022-12-31 03:44:47,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:47,402 INFO:     Epoch: 76
2022-12-31 03:44:49,016 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4684719771146774, 'Total loss': 0.4684719771146774} | train loss {'Reaction outcome loss': 0.11515848615807414, 'Total loss': 0.11515848615807414}
2022-12-31 03:44:49,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:49,016 INFO:     Epoch: 77
2022-12-31 03:44:50,639 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47219762007395427, 'Total loss': 0.47219762007395427} | train loss {'Reaction outcome loss': 0.12119786411041286, 'Total loss': 0.12119786411041286}
2022-12-31 03:44:50,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:50,640 INFO:     Epoch: 78
2022-12-31 03:44:52,258 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43560810883839923, 'Total loss': 0.43560810883839923} | train loss {'Reaction outcome loss': 0.14003327291069634, 'Total loss': 0.14003327291069634}
2022-12-31 03:44:52,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:52,258 INFO:     Epoch: 79
2022-12-31 03:44:53,870 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4461982508500417, 'Total loss': 0.4461982508500417} | train loss {'Reaction outcome loss': 0.11952580965589732, 'Total loss': 0.11952580965589732}
2022-12-31 03:44:53,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:53,871 INFO:     Epoch: 80
2022-12-31 03:44:55,490 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4456904282172521, 'Total loss': 0.4456904282172521} | train loss {'Reaction outcome loss': 0.11529663093118132, 'Total loss': 0.11529663093118132}
2022-12-31 03:44:55,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:55,491 INFO:     Epoch: 81
2022-12-31 03:44:57,103 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4066355377435684, 'Total loss': 0.4066355377435684} | train loss {'Reaction outcome loss': 0.1135370251742669, 'Total loss': 0.1135370251742669}
2022-12-31 03:44:57,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:57,104 INFO:     Epoch: 82
2022-12-31 03:44:58,715 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4172049547235171, 'Total loss': 0.4172049547235171} | train loss {'Reaction outcome loss': 0.11357305832659578, 'Total loss': 0.11357305832659578}
2022-12-31 03:44:58,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:44:58,715 INFO:     Epoch: 83
2022-12-31 03:45:00,327 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4376534014940262, 'Total loss': 0.4376534014940262} | train loss {'Reaction outcome loss': 0.11038403511359492, 'Total loss': 0.11038403511359492}
2022-12-31 03:45:00,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:00,328 INFO:     Epoch: 84
2022-12-31 03:45:01,962 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41253649989763896, 'Total loss': 0.41253649989763896} | train loss {'Reaction outcome loss': 0.1111743570418448, 'Total loss': 0.1111743570418448}
2022-12-31 03:45:01,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:01,962 INFO:     Epoch: 85
2022-12-31 03:45:03,584 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4521126478910446, 'Total loss': 0.4521126478910446} | train loss {'Reaction outcome loss': 0.11138208157322167, 'Total loss': 0.11138208157322167}
2022-12-31 03:45:03,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:03,585 INFO:     Epoch: 86
2022-12-31 03:45:05,212 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46602954069773356, 'Total loss': 0.46602954069773356} | train loss {'Reaction outcome loss': 0.11094445571348921, 'Total loss': 0.11094445571348921}
2022-12-31 03:45:05,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:05,213 INFO:     Epoch: 87
2022-12-31 03:45:06,830 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4297069122393926, 'Total loss': 0.4297069122393926} | train loss {'Reaction outcome loss': 0.11181426720134408, 'Total loss': 0.11181426720134408}
2022-12-31 03:45:06,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:06,830 INFO:     Epoch: 88
2022-12-31 03:45:08,457 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4385374993085861, 'Total loss': 0.4385374993085861} | train loss {'Reaction outcome loss': 0.11105540239773488, 'Total loss': 0.11105540239773488}
2022-12-31 03:45:08,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:08,457 INFO:     Epoch: 89
2022-12-31 03:45:10,084 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4706304887930552, 'Total loss': 0.4706304887930552} | train loss {'Reaction outcome loss': 0.11133728072393527, 'Total loss': 0.11133728072393527}
2022-12-31 03:45:10,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:10,085 INFO:     Epoch: 90
2022-12-31 03:45:11,698 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4387261919677258, 'Total loss': 0.4387261919677258} | train loss {'Reaction outcome loss': 0.10991827451178561, 'Total loss': 0.10991827451178561}
2022-12-31 03:45:11,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:11,699 INFO:     Epoch: 91
2022-12-31 03:45:13,323 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4006840215685467, 'Total loss': 0.4006840215685467} | train loss {'Reaction outcome loss': 0.1198727010565378, 'Total loss': 0.1198727010565378}
2022-12-31 03:45:13,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:13,323 INFO:     Epoch: 92
2022-12-31 03:45:14,946 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4023472839345535, 'Total loss': 0.4023472839345535} | train loss {'Reaction outcome loss': 0.11498619358694734, 'Total loss': 0.11498619358694734}
2022-12-31 03:45:14,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:14,946 INFO:     Epoch: 93
2022-12-31 03:45:16,561 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44981500109036765, 'Total loss': 0.44981500109036765} | train loss {'Reaction outcome loss': 0.10769370214193655, 'Total loss': 0.10769370214193655}
2022-12-31 03:45:16,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:16,562 INFO:     Epoch: 94
2022-12-31 03:45:18,186 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4217377652724584, 'Total loss': 0.4217377652724584} | train loss {'Reaction outcome loss': 0.10336769694057417, 'Total loss': 0.10336769694057417}
2022-12-31 03:45:18,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:18,186 INFO:     Epoch: 95
2022-12-31 03:45:19,806 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4147511621316274, 'Total loss': 0.4147511621316274} | train loss {'Reaction outcome loss': 0.10811267302293952, 'Total loss': 0.10811267302293952}
2022-12-31 03:45:19,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:19,806 INFO:     Epoch: 96
2022-12-31 03:45:21,426 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4391761382420858, 'Total loss': 0.4391761382420858} | train loss {'Reaction outcome loss': 0.10702169989847302, 'Total loss': 0.10702169989847302}
2022-12-31 03:45:21,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:21,426 INFO:     Epoch: 97
2022-12-31 03:45:23,088 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42133616904417676, 'Total loss': 0.42133616904417676} | train loss {'Reaction outcome loss': 0.11168019755986398, 'Total loss': 0.11168019755986398}
2022-12-31 03:45:23,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:23,088 INFO:     Epoch: 98
2022-12-31 03:45:24,699 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4255145569642385, 'Total loss': 0.4255145569642385} | train loss {'Reaction outcome loss': 0.11185159058795366, 'Total loss': 0.11185159058795366}
2022-12-31 03:45:24,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:24,700 INFO:     Epoch: 99
2022-12-31 03:45:26,363 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4385965382059415, 'Total loss': 0.4385965382059415} | train loss {'Reaction outcome loss': 0.11220613261734863, 'Total loss': 0.11220613261734863}
2022-12-31 03:45:26,363 INFO:     Best model found after epoch 24 of 100.
2022-12-31 03:45:26,364 INFO:   Done with stage: TRAINING
2022-12-31 03:45:26,364 INFO:   Starting stage: EVALUATION
2022-12-31 03:45:26,493 INFO:   Done with stage: EVALUATION
2022-12-31 03:45:26,493 INFO:   Leaving out SEQ value Fold_3
2022-12-31 03:45:26,506 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 03:45:26,506 INFO:   Starting stage: FEATURE SCALING
2022-12-31 03:45:27,151 INFO:   Done with stage: FEATURE SCALING
2022-12-31 03:45:27,151 INFO:   Starting stage: SCALING TARGETS
2022-12-31 03:45:27,222 INFO:   Done with stage: SCALING TARGETS
2022-12-31 03:45:27,222 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:45:27,222 INFO:     No hyperparam tuning for this model
2022-12-31 03:45:27,222 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:45:27,222 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 03:45:27,223 INFO:     None feature selector for col prot
2022-12-31 03:45:27,223 INFO:     None feature selector for col prot
2022-12-31 03:45:27,223 INFO:     None feature selector for col prot
2022-12-31 03:45:27,224 INFO:     None feature selector for col chem
2022-12-31 03:45:27,224 INFO:     None feature selector for col chem
2022-12-31 03:45:27,224 INFO:     None feature selector for col chem
2022-12-31 03:45:27,224 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 03:45:27,224 INFO:   Starting stage: BUILD MODEL
2022-12-31 03:45:27,226 INFO:     Number of params in model 224011
2022-12-31 03:45:27,229 INFO:   Done with stage: BUILD MODEL
2022-12-31 03:45:27,229 INFO:   Starting stage: TRAINING
2022-12-31 03:45:27,275 INFO:     Val loss before train {'Reaction outcome loss': 1.024578372637431, 'Total loss': 1.024578372637431}
2022-12-31 03:45:27,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:27,276 INFO:     Epoch: 0
2022-12-31 03:45:28,889 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5448116918404897, 'Total loss': 0.5448116918404897} | train loss {'Reaction outcome loss': 0.7658215564685863, 'Total loss': 0.7658215564685863}
2022-12-31 03:45:28,889 INFO:     Found new best model at epoch 0
2022-12-31 03:45:28,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:28,890 INFO:     Epoch: 1
2022-12-31 03:45:30,506 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5102465709050497, 'Total loss': 0.5102465709050497} | train loss {'Reaction outcome loss': 0.5007646321267872, 'Total loss': 0.5007646321267872}
2022-12-31 03:45:30,506 INFO:     Found new best model at epoch 1
2022-12-31 03:45:30,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:30,507 INFO:     Epoch: 2
2022-12-31 03:45:32,124 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46485885977745056, 'Total loss': 0.46485885977745056} | train loss {'Reaction outcome loss': 0.435603900911498, 'Total loss': 0.435603900911498}
2022-12-31 03:45:32,124 INFO:     Found new best model at epoch 2
2022-12-31 03:45:32,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:32,126 INFO:     Epoch: 3
2022-12-31 03:45:33,740 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4506604552268982, 'Total loss': 0.4506604552268982} | train loss {'Reaction outcome loss': 0.40113579571902097, 'Total loss': 0.40113579571902097}
2022-12-31 03:45:33,741 INFO:     Found new best model at epoch 3
2022-12-31 03:45:33,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:33,742 INFO:     Epoch: 4
2022-12-31 03:45:35,388 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4242498050133387, 'Total loss': 0.4242498050133387} | train loss {'Reaction outcome loss': 0.37300831547532326, 'Total loss': 0.37300831547532326}
2022-12-31 03:45:35,388 INFO:     Found new best model at epoch 4
2022-12-31 03:45:35,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:35,389 INFO:     Epoch: 5
2022-12-31 03:45:37,000 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41869930426279706, 'Total loss': 0.41869930426279706} | train loss {'Reaction outcome loss': 0.3490186277981643, 'Total loss': 0.3490186277981643}
2022-12-31 03:45:37,000 INFO:     Found new best model at epoch 5
2022-12-31 03:45:37,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:37,001 INFO:     Epoch: 6
2022-12-31 03:45:38,611 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.40436347126960753, 'Total loss': 0.40436347126960753} | train loss {'Reaction outcome loss': 0.3341440444627961, 'Total loss': 0.3341440444627961}
2022-12-31 03:45:38,611 INFO:     Found new best model at epoch 6
2022-12-31 03:45:38,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:38,612 INFO:     Epoch: 7
2022-12-31 03:45:40,232 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42835369110107424, 'Total loss': 0.42835369110107424} | train loss {'Reaction outcome loss': 0.31950675428677827, 'Total loss': 0.31950675428677827}
2022-12-31 03:45:40,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:40,233 INFO:     Epoch: 8
2022-12-31 03:45:41,880 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42919813791910805, 'Total loss': 0.42919813791910805} | train loss {'Reaction outcome loss': 0.3044858685295497, 'Total loss': 0.3044858685295497}
2022-12-31 03:45:41,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:41,880 INFO:     Epoch: 9
2022-12-31 03:45:43,495 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41793436706066134, 'Total loss': 0.41793436706066134} | train loss {'Reaction outcome loss': 0.2903097113901442, 'Total loss': 0.2903097113901442}
2022-12-31 03:45:43,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:43,496 INFO:     Epoch: 10
2022-12-31 03:45:45,111 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41020827839771906, 'Total loss': 0.41020827839771906} | train loss {'Reaction outcome loss': 0.2786382294529469, 'Total loss': 0.2786382294529469}
2022-12-31 03:45:45,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:45,111 INFO:     Epoch: 11
2022-12-31 03:45:46,716 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.433697838584582, 'Total loss': 0.433697838584582} | train loss {'Reaction outcome loss': 0.2714309892565994, 'Total loss': 0.2714309892565994}
2022-12-31 03:45:46,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:46,717 INFO:     Epoch: 12
2022-12-31 03:45:48,314 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4181473108008504, 'Total loss': 0.4181473108008504} | train loss {'Reaction outcome loss': 0.2570059247634326, 'Total loss': 0.2570059247634326}
2022-12-31 03:45:48,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:48,314 INFO:     Epoch: 13
2022-12-31 03:45:49,917 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4289442906777064, 'Total loss': 0.4289442906777064} | train loss {'Reaction outcome loss': 0.24922081753065733, 'Total loss': 0.24922081753065733}
2022-12-31 03:45:49,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:49,917 INFO:     Epoch: 14
2022-12-31 03:45:51,545 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.38208764493465425, 'Total loss': 0.38208764493465425} | train loss {'Reaction outcome loss': 0.24052803605904072, 'Total loss': 0.24052803605904072}
2022-12-31 03:45:51,545 INFO:     Found new best model at epoch 14
2022-12-31 03:45:51,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:51,546 INFO:     Epoch: 15
2022-12-31 03:45:53,152 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.419199992219607, 'Total loss': 0.419199992219607} | train loss {'Reaction outcome loss': 0.23208468187695894, 'Total loss': 0.23208468187695894}
2022-12-31 03:45:53,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:53,152 INFO:     Epoch: 16
2022-12-31 03:45:54,798 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3960947553316752, 'Total loss': 0.3960947553316752} | train loss {'Reaction outcome loss': 0.22314775977522516, 'Total loss': 0.22314775977522516}
2022-12-31 03:45:54,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:54,798 INFO:     Epoch: 17
2022-12-31 03:45:56,432 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40558827072381975, 'Total loss': 0.40558827072381975} | train loss {'Reaction outcome loss': 0.21811856172685495, 'Total loss': 0.21811856172685495}
2022-12-31 03:45:56,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:56,432 INFO:     Epoch: 18
2022-12-31 03:45:58,074 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4002418915430705, 'Total loss': 0.4002418915430705} | train loss {'Reaction outcome loss': 0.21563364759824433, 'Total loss': 0.21563364759824433}
2022-12-31 03:45:58,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:58,075 INFO:     Epoch: 19
2022-12-31 03:45:59,674 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41791358788808186, 'Total loss': 0.41791358788808186} | train loss {'Reaction outcome loss': 0.20615748412934415, 'Total loss': 0.20615748412934415}
2022-12-31 03:45:59,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:45:59,675 INFO:     Epoch: 20
2022-12-31 03:46:01,280 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4057395040988922, 'Total loss': 0.4057395040988922} | train loss {'Reaction outcome loss': 0.20070667396685032, 'Total loss': 0.20070667396685032}
2022-12-31 03:46:01,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:01,281 INFO:     Epoch: 21
2022-12-31 03:46:02,895 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41249862958987554, 'Total loss': 0.41249862958987554} | train loss {'Reaction outcome loss': 0.1951359763755139, 'Total loss': 0.1951359763755139}
2022-12-31 03:46:02,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:02,895 INFO:     Epoch: 22
2022-12-31 03:46:04,514 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3722188981405149, 'Total loss': 0.3722188981405149} | train loss {'Reaction outcome loss': 0.19170550057910138, 'Total loss': 0.19170550057910138}
2022-12-31 03:46:04,514 INFO:     Found new best model at epoch 22
2022-12-31 03:46:04,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:04,515 INFO:     Epoch: 23
2022-12-31 03:46:06,121 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41736962894598645, 'Total loss': 0.41736962894598645} | train loss {'Reaction outcome loss': 0.18633233029190654, 'Total loss': 0.18633233029190654}
2022-12-31 03:46:06,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:06,121 INFO:     Epoch: 24
2022-12-31 03:46:07,735 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3878335142508149, 'Total loss': 0.3878335142508149} | train loss {'Reaction outcome loss': 0.18665536510120162, 'Total loss': 0.18665536510120162}
2022-12-31 03:46:07,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:07,735 INFO:     Epoch: 25
2022-12-31 03:46:09,351 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.450653874874115, 'Total loss': 0.450653874874115} | train loss {'Reaction outcome loss': 0.18022479026598837, 'Total loss': 0.18022479026598837}
2022-12-31 03:46:09,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:09,351 INFO:     Epoch: 26
2022-12-31 03:46:10,978 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42747011681397756, 'Total loss': 0.42747011681397756} | train loss {'Reaction outcome loss': 0.17540508122592754, 'Total loss': 0.17540508122592754}
2022-12-31 03:46:10,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:10,978 INFO:     Epoch: 27
2022-12-31 03:46:12,582 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4257187416156133, 'Total loss': 0.4257187416156133} | train loss {'Reaction outcome loss': 0.1732017437385006, 'Total loss': 0.1732017437385006}
2022-12-31 03:46:12,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:12,582 INFO:     Epoch: 28
2022-12-31 03:46:14,212 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4054842115069429, 'Total loss': 0.4054842115069429} | train loss {'Reaction outcome loss': 0.16698183084159215, 'Total loss': 0.16698183084159215}
2022-12-31 03:46:14,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:14,213 INFO:     Epoch: 29
2022-12-31 03:46:15,829 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4346452295780182, 'Total loss': 0.4346452295780182} | train loss {'Reaction outcome loss': 0.168644548721284, 'Total loss': 0.168644548721284}
2022-12-31 03:46:15,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:15,829 INFO:     Epoch: 30
2022-12-31 03:46:17,463 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4443577830990156, 'Total loss': 0.4443577830990156} | train loss {'Reaction outcome loss': 0.16535131578357556, 'Total loss': 0.16535131578357556}
2022-12-31 03:46:17,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:17,464 INFO:     Epoch: 31
2022-12-31 03:46:19,069 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41753656094272934, 'Total loss': 0.41753656094272934} | train loss {'Reaction outcome loss': 0.16434345445715082, 'Total loss': 0.16434345445715082}
2022-12-31 03:46:19,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:19,069 INFO:     Epoch: 32
2022-12-31 03:46:20,704 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39548632005850476, 'Total loss': 0.39548632005850476} | train loss {'Reaction outcome loss': 0.16014892401876468, 'Total loss': 0.16014892401876468}
2022-12-31 03:46:20,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:20,704 INFO:     Epoch: 33
2022-12-31 03:46:22,321 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.410599073767662, 'Total loss': 0.410599073767662} | train loss {'Reaction outcome loss': 0.15673054719255083, 'Total loss': 0.15673054719255083}
2022-12-31 03:46:22,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:22,321 INFO:     Epoch: 34
2022-12-31 03:46:23,925 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41273530361553035, 'Total loss': 0.41273530361553035} | train loss {'Reaction outcome loss': 0.16027882202245267, 'Total loss': 0.16027882202245267}
2022-12-31 03:46:23,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:23,925 INFO:     Epoch: 35
2022-12-31 03:46:25,532 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4270073523124059, 'Total loss': 0.4270073523124059} | train loss {'Reaction outcome loss': 0.1570449953373426, 'Total loss': 0.1570449953373426}
2022-12-31 03:46:25,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:25,532 INFO:     Epoch: 36
2022-12-31 03:46:27,133 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40274273306131364, 'Total loss': 0.40274273306131364} | train loss {'Reaction outcome loss': 0.15918013375702794, 'Total loss': 0.15918013375702794}
2022-12-31 03:46:27,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:27,134 INFO:     Epoch: 37
2022-12-31 03:46:28,758 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4371082325776418, 'Total loss': 0.4371082325776418} | train loss {'Reaction outcome loss': 0.15595998018024823, 'Total loss': 0.15595998018024823}
2022-12-31 03:46:28,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:28,759 INFO:     Epoch: 38
2022-12-31 03:46:30,375 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3962101032336553, 'Total loss': 0.3962101032336553} | train loss {'Reaction outcome loss': 0.151690326777761, 'Total loss': 0.151690326777761}
2022-12-31 03:46:30,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:30,375 INFO:     Epoch: 39
2022-12-31 03:46:31,988 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4139857769012451, 'Total loss': 0.4139857769012451} | train loss {'Reaction outcome loss': 0.14737715767594156, 'Total loss': 0.14737715767594156}
2022-12-31 03:46:31,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:31,988 INFO:     Epoch: 40
2022-12-31 03:46:33,590 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42154190242290496, 'Total loss': 0.42154190242290496} | train loss {'Reaction outcome loss': 0.14755358049499329, 'Total loss': 0.14755358049499329}
2022-12-31 03:46:33,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:33,590 INFO:     Epoch: 41
2022-12-31 03:46:35,211 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4174087822437286, 'Total loss': 0.4174087822437286} | train loss {'Reaction outcome loss': 0.14314702933742887, 'Total loss': 0.14314702933742887}
2022-12-31 03:46:35,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:35,212 INFO:     Epoch: 42
2022-12-31 03:46:36,820 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40648259222507477, 'Total loss': 0.40648259222507477} | train loss {'Reaction outcome loss': 0.14853381528263235, 'Total loss': 0.14853381528263235}
2022-12-31 03:46:36,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:36,820 INFO:     Epoch: 43
2022-12-31 03:46:38,413 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4576971024274826, 'Total loss': 0.4576971024274826} | train loss {'Reaction outcome loss': 0.1460222672558502, 'Total loss': 0.1460222672558502}
2022-12-31 03:46:38,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:38,413 INFO:     Epoch: 44
2022-12-31 03:46:40,040 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42293427189191185, 'Total loss': 0.42293427189191185} | train loss {'Reaction outcome loss': 0.14196906719295369, 'Total loss': 0.14196906719295369}
2022-12-31 03:46:40,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:40,040 INFO:     Epoch: 45
2022-12-31 03:46:41,661 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4289215644200643, 'Total loss': 0.4289215644200643} | train loss {'Reaction outcome loss': 0.14077345590915655, 'Total loss': 0.14077345590915655}
2022-12-31 03:46:41,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:41,662 INFO:     Epoch: 46
2022-12-31 03:46:43,255 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4188008248806, 'Total loss': 0.4188008248806} | train loss {'Reaction outcome loss': 0.13787076552142644, 'Total loss': 0.13787076552142644}
2022-12-31 03:46:43,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:43,256 INFO:     Epoch: 47
2022-12-31 03:46:44,898 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4342573210597038, 'Total loss': 0.4342573210597038} | train loss {'Reaction outcome loss': 0.14163069252006627, 'Total loss': 0.14163069252006627}
2022-12-31 03:46:44,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:44,899 INFO:     Epoch: 48
2022-12-31 03:46:46,488 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41284710466861724, 'Total loss': 0.41284710466861724} | train loss {'Reaction outcome loss': 0.14154731475785648, 'Total loss': 0.14154731475785648}
2022-12-31 03:46:46,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:46,488 INFO:     Epoch: 49
2022-12-31 03:46:48,089 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4139028588930766, 'Total loss': 0.4139028588930766} | train loss {'Reaction outcome loss': 0.13460716859338592, 'Total loss': 0.13460716859338592}
2022-12-31 03:46:48,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:48,089 INFO:     Epoch: 50
2022-12-31 03:46:49,687 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4426178214450677, 'Total loss': 0.4426178214450677} | train loss {'Reaction outcome loss': 0.13622413862551197, 'Total loss': 0.13622413862551197}
2022-12-31 03:46:49,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:49,687 INFO:     Epoch: 51
2022-12-31 03:46:51,285 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44158480763435365, 'Total loss': 0.44158480763435365} | train loss {'Reaction outcome loss': 0.13882867478332295, 'Total loss': 0.13882867478332295}
2022-12-31 03:46:51,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:51,285 INFO:     Epoch: 52
2022-12-31 03:46:52,893 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4535916974147161, 'Total loss': 0.4535916974147161} | train loss {'Reaction outcome loss': 0.13222046571718904, 'Total loss': 0.13222046571718904}
2022-12-31 03:46:52,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:52,894 INFO:     Epoch: 53
2022-12-31 03:46:54,501 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4389819319049517, 'Total loss': 0.4389819319049517} | train loss {'Reaction outcome loss': 0.1349781354797165, 'Total loss': 0.1349781354797165}
2022-12-31 03:46:54,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:54,502 INFO:     Epoch: 54
2022-12-31 03:46:56,112 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42684232592582705, 'Total loss': 0.42684232592582705} | train loss {'Reaction outcome loss': 0.13469509785865252, 'Total loss': 0.13469509785865252}
2022-12-31 03:46:56,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:56,113 INFO:     Epoch: 55
2022-12-31 03:46:57,705 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44140958388646445, 'Total loss': 0.44140958388646445} | train loss {'Reaction outcome loss': 0.13310779670795814, 'Total loss': 0.13310779670795814}
2022-12-31 03:46:57,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:57,706 INFO:     Epoch: 56
2022-12-31 03:46:59,299 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4320338308811188, 'Total loss': 0.4320338308811188} | train loss {'Reaction outcome loss': 0.13285215524786012, 'Total loss': 0.13285215524786012}
2022-12-31 03:46:59,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:46:59,300 INFO:     Epoch: 57
2022-12-31 03:47:00,885 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40111868642270565, 'Total loss': 0.40111868642270565} | train loss {'Reaction outcome loss': 0.13221906911114387, 'Total loss': 0.13221906911114387}
2022-12-31 03:47:00,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:00,885 INFO:     Epoch: 58
2022-12-31 03:47:02,480 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42226923008759815, 'Total loss': 0.42226923008759815} | train loss {'Reaction outcome loss': 0.13047583879827906, 'Total loss': 0.13047583879827906}
2022-12-31 03:47:02,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:02,480 INFO:     Epoch: 59
2022-12-31 03:47:04,122 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43250722785790763, 'Total loss': 0.43250722785790763} | train loss {'Reaction outcome loss': 0.13034877320580976, 'Total loss': 0.13034877320580976}
2022-12-31 03:47:04,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:04,123 INFO:     Epoch: 60
2022-12-31 03:47:05,726 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4368508726358414, 'Total loss': 0.4368508726358414} | train loss {'Reaction outcome loss': 0.13119524869139923, 'Total loss': 0.13119524869139923}
2022-12-31 03:47:05,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:05,726 INFO:     Epoch: 61
2022-12-31 03:47:07,331 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.436910950144132, 'Total loss': 0.436910950144132} | train loss {'Reaction outcome loss': 0.13591987360609975, 'Total loss': 0.13591987360609975}
2022-12-31 03:47:07,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:07,331 INFO:     Epoch: 62
2022-12-31 03:47:08,928 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.428904460867246, 'Total loss': 0.428904460867246} | train loss {'Reaction outcome loss': 0.12947236707659213, 'Total loss': 0.12947236707659213}
2022-12-31 03:47:08,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:08,928 INFO:     Epoch: 63
2022-12-31 03:47:10,571 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4752168834209442, 'Total loss': 0.4752168834209442} | train loss {'Reaction outcome loss': 0.1294006206565997, 'Total loss': 0.1294006206565997}
2022-12-31 03:47:10,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:10,572 INFO:     Epoch: 64
2022-12-31 03:47:12,166 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41228384474913277, 'Total loss': 0.41228384474913277} | train loss {'Reaction outcome loss': 0.1262877380953856, 'Total loss': 0.1262877380953856}
2022-12-31 03:47:12,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:12,166 INFO:     Epoch: 65
2022-12-31 03:47:13,766 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4276445652047793, 'Total loss': 0.4276445652047793} | train loss {'Reaction outcome loss': 0.12604784985983764, 'Total loss': 0.12604784985983764}
2022-12-31 03:47:13,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:13,766 INFO:     Epoch: 66
2022-12-31 03:47:15,366 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44105960726737975, 'Total loss': 0.44105960726737975} | train loss {'Reaction outcome loss': 0.1268961257761815, 'Total loss': 0.1268961257761815}
2022-12-31 03:47:15,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:15,367 INFO:     Epoch: 67
2022-12-31 03:47:16,968 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.440019820133845, 'Total loss': 0.440019820133845} | train loss {'Reaction outcome loss': 0.12958506988225021, 'Total loss': 0.12958506988225021}
2022-12-31 03:47:16,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:16,969 INFO:     Epoch: 68
2022-12-31 03:47:18,578 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4515207042296728, 'Total loss': 0.4515207042296728} | train loss {'Reaction outcome loss': 0.12678811246965885, 'Total loss': 0.12678811246965885}
2022-12-31 03:47:18,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:18,578 INFO:     Epoch: 69
2022-12-31 03:47:20,173 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3949359784523646, 'Total loss': 0.3949359784523646} | train loss {'Reaction outcome loss': 0.12373228443636398, 'Total loss': 0.12373228443636398}
2022-12-31 03:47:20,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:20,174 INFO:     Epoch: 70
2022-12-31 03:47:21,771 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4370323191086451, 'Total loss': 0.4370323191086451} | train loss {'Reaction outcome loss': 0.12214284696131808, 'Total loss': 0.12214284696131808}
2022-12-31 03:47:21,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:21,772 INFO:     Epoch: 71
2022-12-31 03:47:23,365 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41861030956109363, 'Total loss': 0.41861030956109363} | train loss {'Reaction outcome loss': 0.1229603731656795, 'Total loss': 0.1229603731656795}
2022-12-31 03:47:23,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:23,365 INFO:     Epoch: 72
2022-12-31 03:47:24,963 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4259326674044132, 'Total loss': 0.4259326674044132} | train loss {'Reaction outcome loss': 0.12093503833445635, 'Total loss': 0.12093503833445635}
2022-12-31 03:47:24,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:24,964 INFO:     Epoch: 73
2022-12-31 03:47:26,601 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4277706518769264, 'Total loss': 0.4277706518769264} | train loss {'Reaction outcome loss': 0.12482676153913849, 'Total loss': 0.12482676153913849}
2022-12-31 03:47:26,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:26,601 INFO:     Epoch: 74
2022-12-31 03:47:28,232 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.407486172268788, 'Total loss': 0.407486172268788} | train loss {'Reaction outcome loss': 0.11836764320471893, 'Total loss': 0.11836764320471893}
2022-12-31 03:47:28,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:28,232 INFO:     Epoch: 75
2022-12-31 03:47:29,836 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47728115518887837, 'Total loss': 0.47728115518887837} | train loss {'Reaction outcome loss': 0.12097676365462305, 'Total loss': 0.12097676365462305}
2022-12-31 03:47:29,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:29,837 INFO:     Epoch: 76
2022-12-31 03:47:31,443 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42271743662810574, 'Total loss': 0.42271743662810574} | train loss {'Reaction outcome loss': 0.12778237009260654, 'Total loss': 0.12778237009260654}
2022-12-31 03:47:31,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:31,443 INFO:     Epoch: 77
2022-12-31 03:47:33,046 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44821892281373343, 'Total loss': 0.44821892281373343} | train loss {'Reaction outcome loss': 0.12053735661849162, 'Total loss': 0.12053735661849162}
2022-12-31 03:47:33,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:33,046 INFO:     Epoch: 78
2022-12-31 03:47:34,687 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4343135982751846, 'Total loss': 0.4343135982751846} | train loss {'Reaction outcome loss': 0.12062332054920795, 'Total loss': 0.12062332054920795}
2022-12-31 03:47:34,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:34,687 INFO:     Epoch: 79
2022-12-31 03:47:36,311 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4391014198462168, 'Total loss': 0.4391014198462168} | train loss {'Reaction outcome loss': 0.12228623587951992, 'Total loss': 0.12228623587951992}
2022-12-31 03:47:36,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:36,311 INFO:     Epoch: 80
2022-12-31 03:47:37,903 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4559695432583491, 'Total loss': 0.4559695432583491} | train loss {'Reaction outcome loss': 0.11875915262402946, 'Total loss': 0.11875915262402946}
2022-12-31 03:47:37,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:37,903 INFO:     Epoch: 81
2022-12-31 03:47:39,518 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42796338001887, 'Total loss': 0.42796338001887} | train loss {'Reaction outcome loss': 0.12618591685544003, 'Total loss': 0.12618591685544003}
2022-12-31 03:47:39,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:39,518 INFO:     Epoch: 82
2022-12-31 03:47:41,151 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41275886197884876, 'Total loss': 0.41275886197884876} | train loss {'Reaction outcome loss': 0.12259466468694281, 'Total loss': 0.12259466468694281}
2022-12-31 03:47:41,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:41,153 INFO:     Epoch: 83
2022-12-31 03:47:42,747 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4493333031733831, 'Total loss': 0.4493333031733831} | train loss {'Reaction outcome loss': 0.1183658758939104, 'Total loss': 0.1183658758939104}
2022-12-31 03:47:42,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:42,747 INFO:     Epoch: 84
2022-12-31 03:47:44,403 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4565031938254833, 'Total loss': 0.4565031938254833} | train loss {'Reaction outcome loss': 0.11678025021384923, 'Total loss': 0.11678025021384923}
2022-12-31 03:47:44,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:44,403 INFO:     Epoch: 85
2022-12-31 03:47:46,004 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43194003105163575, 'Total loss': 0.43194003105163575} | train loss {'Reaction outcome loss': 0.1156371245936801, 'Total loss': 0.1156371245936801}
2022-12-31 03:47:46,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:46,004 INFO:     Epoch: 86
2022-12-31 03:47:47,602 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4187057634194692, 'Total loss': 0.4187057634194692} | train loss {'Reaction outcome loss': 0.11454889004463296, 'Total loss': 0.11454889004463296}
2022-12-31 03:47:47,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:47,603 INFO:     Epoch: 87
2022-12-31 03:47:49,198 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4199642986059189, 'Total loss': 0.4199642986059189} | train loss {'Reaction outcome loss': 0.11811361740080592, 'Total loss': 0.11811361740080592}
2022-12-31 03:47:49,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:49,198 INFO:     Epoch: 88
2022-12-31 03:47:50,831 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4390242576599121, 'Total loss': 0.4390242576599121} | train loss {'Reaction outcome loss': 0.11597797483540116, 'Total loss': 0.11597797483540116}
2022-12-31 03:47:50,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:50,831 INFO:     Epoch: 89
2022-12-31 03:47:52,474 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42121214618285496, 'Total loss': 0.42121214618285496} | train loss {'Reaction outcome loss': 0.11301736708136868, 'Total loss': 0.11301736708136868}
2022-12-31 03:47:52,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:52,474 INFO:     Epoch: 90
2022-12-31 03:47:54,064 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4680204590161641, 'Total loss': 0.4680204590161641} | train loss {'Reaction outcome loss': 0.11250671901443339, 'Total loss': 0.11250671901443339}
2022-12-31 03:47:54,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:54,064 INFO:     Epoch: 91
2022-12-31 03:47:55,664 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4209277622401714, 'Total loss': 0.4209277622401714} | train loss {'Reaction outcome loss': 0.11402799411601773, 'Total loss': 0.11402799411601773}
2022-12-31 03:47:55,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:55,664 INFO:     Epoch: 92
2022-12-31 03:47:57,273 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43557062645753225, 'Total loss': 0.43557062645753225} | train loss {'Reaction outcome loss': 0.12496266099573164, 'Total loss': 0.12496266099573164}
2022-12-31 03:47:57,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:57,273 INFO:     Epoch: 93
2022-12-31 03:47:58,884 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4453170865774155, 'Total loss': 0.4453170865774155} | train loss {'Reaction outcome loss': 0.11617779244725071, 'Total loss': 0.11617779244725071}
2022-12-31 03:47:58,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:47:58,885 INFO:     Epoch: 94
2022-12-31 03:48:00,483 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41343224545319873, 'Total loss': 0.41343224545319873} | train loss {'Reaction outcome loss': 0.11730600229461059, 'Total loss': 0.11730600229461059}
2022-12-31 03:48:00,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:00,484 INFO:     Epoch: 95
2022-12-31 03:48:02,090 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43438528378804525, 'Total loss': 0.43438528378804525} | train loss {'Reaction outcome loss': 0.11069775845739485, 'Total loss': 0.11069775845739485}
2022-12-31 03:48:02,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:02,090 INFO:     Epoch: 96
2022-12-31 03:48:03,695 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42086786925792696, 'Total loss': 0.42086786925792696} | train loss {'Reaction outcome loss': 0.1119834848847189, 'Total loss': 0.1119834848847189}
2022-12-31 03:48:03,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:03,695 INFO:     Epoch: 97
2022-12-31 03:48:05,337 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4124881426493327, 'Total loss': 0.4124881426493327} | train loss {'Reaction outcome loss': 0.11435381536569869, 'Total loss': 0.11435381536569869}
2022-12-31 03:48:05,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:05,337 INFO:     Epoch: 98
2022-12-31 03:48:06,935 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.472047059237957, 'Total loss': 0.472047059237957} | train loss {'Reaction outcome loss': 0.12146483136011772, 'Total loss': 0.12146483136011772}
2022-12-31 03:48:06,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:06,935 INFO:     Epoch: 99
2022-12-31 03:48:08,557 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42586171527703603, 'Total loss': 0.42586171527703603} | train loss {'Reaction outcome loss': 0.11178423555980645, 'Total loss': 0.11178423555980645}
2022-12-31 03:48:08,558 INFO:     Best model found after epoch 23 of 100.
2022-12-31 03:48:08,558 INFO:   Done with stage: TRAINING
2022-12-31 03:48:08,558 INFO:   Starting stage: EVALUATION
2022-12-31 03:48:08,700 INFO:   Done with stage: EVALUATION
2022-12-31 03:48:08,700 INFO:   Leaving out SEQ value Fold_4
2022-12-31 03:48:08,712 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 03:48:08,713 INFO:   Starting stage: FEATURE SCALING
2022-12-31 03:48:09,361 INFO:   Done with stage: FEATURE SCALING
2022-12-31 03:48:09,361 INFO:   Starting stage: SCALING TARGETS
2022-12-31 03:48:09,432 INFO:   Done with stage: SCALING TARGETS
2022-12-31 03:48:09,433 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:48:09,433 INFO:     No hyperparam tuning for this model
2022-12-31 03:48:09,433 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:48:09,433 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 03:48:09,433 INFO:     None feature selector for col prot
2022-12-31 03:48:09,434 INFO:     None feature selector for col prot
2022-12-31 03:48:09,434 INFO:     None feature selector for col prot
2022-12-31 03:48:09,434 INFO:     None feature selector for col chem
2022-12-31 03:48:09,434 INFO:     None feature selector for col chem
2022-12-31 03:48:09,434 INFO:     None feature selector for col chem
2022-12-31 03:48:09,434 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 03:48:09,435 INFO:   Starting stage: BUILD MODEL
2022-12-31 03:48:09,436 INFO:     Number of params in model 224011
2022-12-31 03:48:09,439 INFO:   Done with stage: BUILD MODEL
2022-12-31 03:48:09,440 INFO:   Starting stage: TRAINING
2022-12-31 03:48:09,484 INFO:     Val loss before train {'Reaction outcome loss': 1.0700576027234396, 'Total loss': 1.0700576027234396}
2022-12-31 03:48:09,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:09,484 INFO:     Epoch: 0
2022-12-31 03:48:11,098 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6372734308242798, 'Total loss': 0.6372734308242798} | train loss {'Reaction outcome loss': 0.784050955077371, 'Total loss': 0.784050955077371}
2022-12-31 03:48:11,098 INFO:     Found new best model at epoch 0
2022-12-31 03:48:11,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:11,099 INFO:     Epoch: 1
2022-12-31 03:48:12,705 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5656873166561127, 'Total loss': 0.5656873166561127} | train loss {'Reaction outcome loss': 0.5262254055333913, 'Total loss': 0.5262254055333913}
2022-12-31 03:48:12,705 INFO:     Found new best model at epoch 1
2022-12-31 03:48:12,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:12,706 INFO:     Epoch: 2
2022-12-31 03:48:14,318 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4968096435070038, 'Total loss': 0.4968096435070038} | train loss {'Reaction outcome loss': 0.4543229817322015, 'Total loss': 0.4543229817322015}
2022-12-31 03:48:14,319 INFO:     Found new best model at epoch 2
2022-12-31 03:48:14,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:14,321 INFO:     Epoch: 3
2022-12-31 03:48:15,985 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49564828077952067, 'Total loss': 0.49564828077952067} | train loss {'Reaction outcome loss': 0.4107879151183345, 'Total loss': 0.4107879151183345}
2022-12-31 03:48:15,985 INFO:     Found new best model at epoch 3
2022-12-31 03:48:15,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:15,986 INFO:     Epoch: 4
2022-12-31 03:48:17,598 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46318132877349855, 'Total loss': 0.46318132877349855} | train loss {'Reaction outcome loss': 0.37698961614163773, 'Total loss': 0.37698961614163773}
2022-12-31 03:48:17,598 INFO:     Found new best model at epoch 4
2022-12-31 03:48:17,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:17,599 INFO:     Epoch: 5
2022-12-31 03:48:19,219 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4433587123950323, 'Total loss': 0.4433587123950323} | train loss {'Reaction outcome loss': 0.35172422437353684, 'Total loss': 0.35172422437353684}
2022-12-31 03:48:19,219 INFO:     Found new best model at epoch 5
2022-12-31 03:48:19,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:19,220 INFO:     Epoch: 6
2022-12-31 03:48:20,840 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4297245134909948, 'Total loss': 0.4297245134909948} | train loss {'Reaction outcome loss': 0.3281941134953327, 'Total loss': 0.3281941134953327}
2022-12-31 03:48:20,841 INFO:     Found new best model at epoch 6
2022-12-31 03:48:20,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:20,842 INFO:     Epoch: 7
2022-12-31 03:48:22,452 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42265547513961793, 'Total loss': 0.42265547513961793} | train loss {'Reaction outcome loss': 0.3092073560541072, 'Total loss': 0.3092073560541072}
2022-12-31 03:48:22,452 INFO:     Found new best model at epoch 7
2022-12-31 03:48:22,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:22,453 INFO:     Epoch: 8
2022-12-31 03:48:24,068 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4175517186522484, 'Total loss': 0.4175517186522484} | train loss {'Reaction outcome loss': 0.2993807092524177, 'Total loss': 0.2993807092524177}
2022-12-31 03:48:24,068 INFO:     Found new best model at epoch 8
2022-12-31 03:48:24,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:24,069 INFO:     Epoch: 9
2022-12-31 03:48:25,684 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43811401426792146, 'Total loss': 0.43811401426792146} | train loss {'Reaction outcome loss': 0.2833222598913344, 'Total loss': 0.2833222598913344}
2022-12-31 03:48:25,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:25,684 INFO:     Epoch: 10
2022-12-31 03:48:27,335 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4491205076376597, 'Total loss': 0.4491205076376597} | train loss {'Reaction outcome loss': 0.2693007152379635, 'Total loss': 0.2693007152379635}
2022-12-31 03:48:27,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:27,335 INFO:     Epoch: 11
2022-12-31 03:48:28,959 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42598920861879985, 'Total loss': 0.42598920861879985} | train loss {'Reaction outcome loss': 0.2585176111262843, 'Total loss': 0.2585176111262843}
2022-12-31 03:48:28,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:28,959 INFO:     Epoch: 12
2022-12-31 03:48:30,591 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4183539052804311, 'Total loss': 0.4183539052804311} | train loss {'Reaction outcome loss': 0.2491961625616473, 'Total loss': 0.2491961625616473}
2022-12-31 03:48:30,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:30,592 INFO:     Epoch: 13
2022-12-31 03:48:32,211 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43562093476454417, 'Total loss': 0.43562093476454417} | train loss {'Reaction outcome loss': 0.2365154077295577, 'Total loss': 0.2365154077295577}
2022-12-31 03:48:32,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:32,211 INFO:     Epoch: 14
2022-12-31 03:48:33,831 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41294024387995404, 'Total loss': 0.41294024387995404} | train loss {'Reaction outcome loss': 0.22988850795512594, 'Total loss': 0.22988850795512594}
2022-12-31 03:48:33,832 INFO:     Found new best model at epoch 14
2022-12-31 03:48:33,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:33,833 INFO:     Epoch: 15
2022-12-31 03:48:35,445 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4173942257960637, 'Total loss': 0.4173942257960637} | train loss {'Reaction outcome loss': 0.22112552356983564, 'Total loss': 0.22112552356983564}
2022-12-31 03:48:35,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:35,446 INFO:     Epoch: 16
2022-12-31 03:48:37,074 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.429411772886912, 'Total loss': 0.429411772886912} | train loss {'Reaction outcome loss': 0.21172457002775763, 'Total loss': 0.21172457002775763}
2022-12-31 03:48:37,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:37,074 INFO:     Epoch: 17
2022-12-31 03:48:38,697 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41036938230196635, 'Total loss': 0.41036938230196635} | train loss {'Reaction outcome loss': 0.2066171872648091, 'Total loss': 0.2066171872648091}
2022-12-31 03:48:38,698 INFO:     Found new best model at epoch 17
2022-12-31 03:48:38,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:38,699 INFO:     Epoch: 18
2022-12-31 03:48:40,348 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41567279895146686, 'Total loss': 0.41567279895146686} | train loss {'Reaction outcome loss': 0.20222910758551707, 'Total loss': 0.20222910758551707}
2022-12-31 03:48:40,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:40,349 INFO:     Epoch: 19
2022-12-31 03:48:41,968 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4398906767368317, 'Total loss': 0.4398906767368317} | train loss {'Reaction outcome loss': 0.19416568228564754, 'Total loss': 0.19416568228564754}
2022-12-31 03:48:41,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:41,970 INFO:     Epoch: 20
2022-12-31 03:48:43,588 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4140199273824692, 'Total loss': 0.4140199273824692} | train loss {'Reaction outcome loss': 0.18854002539566062, 'Total loss': 0.18854002539566062}
2022-12-31 03:48:43,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:43,588 INFO:     Epoch: 21
2022-12-31 03:48:45,211 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4066917027036349, 'Total loss': 0.4066917027036349} | train loss {'Reaction outcome loss': 0.18680902427257398, 'Total loss': 0.18680902427257398}
2022-12-31 03:48:45,212 INFO:     Found new best model at epoch 21
2022-12-31 03:48:45,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:45,213 INFO:     Epoch: 22
2022-12-31 03:48:46,835 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4389934321244558, 'Total loss': 0.4389934321244558} | train loss {'Reaction outcome loss': 0.18074301395242504, 'Total loss': 0.18074301395242504}
2022-12-31 03:48:46,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:46,835 INFO:     Epoch: 23
2022-12-31 03:48:48,479 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4416090726852417, 'Total loss': 0.4416090726852417} | train loss {'Reaction outcome loss': 0.17667706193072916, 'Total loss': 0.17667706193072916}
2022-12-31 03:48:48,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:48,480 INFO:     Epoch: 24
2022-12-31 03:48:50,112 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41608637273311616, 'Total loss': 0.41608637273311616} | train loss {'Reaction outcome loss': 0.17734581493984383, 'Total loss': 0.17734581493984383}
2022-12-31 03:48:50,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:50,113 INFO:     Epoch: 25
2022-12-31 03:48:51,747 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4413632720708847, 'Total loss': 0.4413632720708847} | train loss {'Reaction outcome loss': 0.17044772561437818, 'Total loss': 0.17044772561437818}
2022-12-31 03:48:51,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:51,747 INFO:     Epoch: 26
2022-12-31 03:48:53,371 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42447528342405955, 'Total loss': 0.42447528342405955} | train loss {'Reaction outcome loss': 0.1678842907899231, 'Total loss': 0.1678842907899231}
2022-12-31 03:48:53,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:53,371 INFO:     Epoch: 27
2022-12-31 03:48:55,000 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4248853753010432, 'Total loss': 0.4248853753010432} | train loss {'Reaction outcome loss': 0.1646993270325424, 'Total loss': 0.1646993270325424}
2022-12-31 03:48:55,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:55,001 INFO:     Epoch: 28
2022-12-31 03:48:56,631 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43313093557953836, 'Total loss': 0.43313093557953836} | train loss {'Reaction outcome loss': 0.15962311006840385, 'Total loss': 0.15962311006840385}
2022-12-31 03:48:56,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:56,631 INFO:     Epoch: 29
2022-12-31 03:48:58,276 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42027245660622914, 'Total loss': 0.42027245660622914} | train loss {'Reaction outcome loss': 0.1588395847350574, 'Total loss': 0.1588395847350574}
2022-12-31 03:48:58,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:58,276 INFO:     Epoch: 30
2022-12-31 03:48:59,896 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4283215851833423, 'Total loss': 0.4283215851833423} | train loss {'Reaction outcome loss': 0.15536344263850566, 'Total loss': 0.15536344263850566}
2022-12-31 03:48:59,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:48:59,897 INFO:     Epoch: 31
2022-12-31 03:49:01,564 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4298528651396433, 'Total loss': 0.4298528651396433} | train loss {'Reaction outcome loss': 0.15417217743828462, 'Total loss': 0.15417217743828462}
2022-12-31 03:49:01,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:01,565 INFO:     Epoch: 32
2022-12-31 03:49:03,180 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4337761253118515, 'Total loss': 0.4337761253118515} | train loss {'Reaction outcome loss': 0.14961951461012074, 'Total loss': 0.14961951461012074}
2022-12-31 03:49:03,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:03,180 INFO:     Epoch: 33
2022-12-31 03:49:04,847 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45062556564807893, 'Total loss': 0.45062556564807893} | train loss {'Reaction outcome loss': 0.14639853295409508, 'Total loss': 0.14639853295409508}
2022-12-31 03:49:04,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:04,847 INFO:     Epoch: 34
2022-12-31 03:49:06,497 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4632861385742823, 'Total loss': 0.4632861385742823} | train loss {'Reaction outcome loss': 0.15220870219830035, 'Total loss': 0.15220870219830035}
2022-12-31 03:49:06,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:06,497 INFO:     Epoch: 35
2022-12-31 03:49:08,163 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45050591230392456, 'Total loss': 0.45050591230392456} | train loss {'Reaction outcome loss': 0.14699553082687006, 'Total loss': 0.14699553082687006}
2022-12-31 03:49:08,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:08,164 INFO:     Epoch: 36
2022-12-31 03:49:09,829 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45102740079164505, 'Total loss': 0.45102740079164505} | train loss {'Reaction outcome loss': 0.14598596434273658, 'Total loss': 0.14598596434273658}
2022-12-31 03:49:09,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:09,829 INFO:     Epoch: 37
2022-12-31 03:49:11,440 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4534497956434886, 'Total loss': 0.4534497956434886} | train loss {'Reaction outcome loss': 0.14367508462088902, 'Total loss': 0.14367508462088902}
2022-12-31 03:49:11,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:11,440 INFO:     Epoch: 38
2022-12-31 03:49:13,055 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44371073444684345, 'Total loss': 0.44371073444684345} | train loss {'Reaction outcome loss': 0.14014913724392436, 'Total loss': 0.14014913724392436}
2022-12-31 03:49:13,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:13,055 INFO:     Epoch: 39
2022-12-31 03:49:14,721 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41491676568984986, 'Total loss': 0.41491676568984986} | train loss {'Reaction outcome loss': 0.1405629750672351, 'Total loss': 0.1405629750672351}
2022-12-31 03:49:14,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:14,721 INFO:     Epoch: 40
2022-12-31 03:49:16,342 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47078606188297273, 'Total loss': 0.47078606188297273} | train loss {'Reaction outcome loss': 0.13689316734537105, 'Total loss': 0.13689316734537105}
2022-12-31 03:49:16,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:16,342 INFO:     Epoch: 41
2022-12-31 03:49:18,010 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46917932828267417, 'Total loss': 0.46917932828267417} | train loss {'Reaction outcome loss': 0.13980929380356727, 'Total loss': 0.13980929380356727}
2022-12-31 03:49:18,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:18,011 INFO:     Epoch: 42
2022-12-31 03:49:19,634 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42783384944001834, 'Total loss': 0.42783384944001834} | train loss {'Reaction outcome loss': 0.13817604229405575, 'Total loss': 0.13817604229405575}
2022-12-31 03:49:19,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:19,635 INFO:     Epoch: 43
2022-12-31 03:49:21,274 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42896443605422974, 'Total loss': 0.42896443605422974} | train loss {'Reaction outcome loss': 0.13459766312546032, 'Total loss': 0.13459766312546032}
2022-12-31 03:49:21,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:21,274 INFO:     Epoch: 44
2022-12-31 03:49:22,945 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47092850009600323, 'Total loss': 0.47092850009600323} | train loss {'Reaction outcome loss': 0.13699095546762166, 'Total loss': 0.13699095546762166}
2022-12-31 03:49:22,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:22,945 INFO:     Epoch: 45
2022-12-31 03:49:24,579 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46621564428011575, 'Total loss': 0.46621564428011575} | train loss {'Reaction outcome loss': 0.1351879471543141, 'Total loss': 0.1351879471543141}
2022-12-31 03:49:24,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:24,580 INFO:     Epoch: 46
2022-12-31 03:49:26,209 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4283760895331701, 'Total loss': 0.4283760895331701} | train loss {'Reaction outcome loss': 0.13143093397820685, 'Total loss': 0.13143093397820685}
2022-12-31 03:49:26,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:26,210 INFO:     Epoch: 47
2022-12-31 03:49:27,879 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44500048259894054, 'Total loss': 0.44500048259894054} | train loss {'Reaction outcome loss': 0.13250329846092618, 'Total loss': 0.13250329846092618}
2022-12-31 03:49:27,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:27,880 INFO:     Epoch: 48
2022-12-31 03:49:29,551 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46167776683966316, 'Total loss': 0.46167776683966316} | train loss {'Reaction outcome loss': 0.12910810569368492, 'Total loss': 0.12910810569368492}
2022-12-31 03:49:29,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:29,552 INFO:     Epoch: 49
2022-12-31 03:49:31,212 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46495380997657776, 'Total loss': 0.46495380997657776} | train loss {'Reaction outcome loss': 0.13021489932615352, 'Total loss': 0.13021489932615352}
2022-12-31 03:49:31,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:31,212 INFO:     Epoch: 50
2022-12-31 03:49:32,831 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43295374015967053, 'Total loss': 0.43295374015967053} | train loss {'Reaction outcome loss': 0.13084822360406015, 'Total loss': 0.13084822360406015}
2022-12-31 03:49:32,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:32,831 INFO:     Epoch: 51
2022-12-31 03:49:34,479 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42405382295449573, 'Total loss': 0.42405382295449573} | train loss {'Reaction outcome loss': 0.12995978676216402, 'Total loss': 0.12995978676216402}
2022-12-31 03:49:34,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:34,479 INFO:     Epoch: 52
2022-12-31 03:49:36,119 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45551475485165915, 'Total loss': 0.45551475485165915} | train loss {'Reaction outcome loss': 0.12613661894373032, 'Total loss': 0.12613661894373032}
2022-12-31 03:49:36,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:36,120 INFO:     Epoch: 53
2022-12-31 03:49:37,758 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41146094103654224, 'Total loss': 0.41146094103654224} | train loss {'Reaction outcome loss': 0.12644009987255458, 'Total loss': 0.12644009987255458}
2022-12-31 03:49:37,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:37,759 INFO:     Epoch: 54
2022-12-31 03:49:39,393 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46101371248563133, 'Total loss': 0.46101371248563133} | train loss {'Reaction outcome loss': 0.12345392690359577, 'Total loss': 0.12345392690359577}
2022-12-31 03:49:39,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:39,393 INFO:     Epoch: 55
2022-12-31 03:49:41,064 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4353085378805796, 'Total loss': 0.4353085378805796} | train loss {'Reaction outcome loss': 0.12624196396360599, 'Total loss': 0.12624196396360599}
2022-12-31 03:49:41,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:41,064 INFO:     Epoch: 56
2022-12-31 03:49:42,694 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4464627275864283, 'Total loss': 0.4464627275864283} | train loss {'Reaction outcome loss': 0.1206597120480928, 'Total loss': 0.1206597120480928}
2022-12-31 03:49:42,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:42,694 INFO:     Epoch: 57
2022-12-31 03:49:44,350 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43068020045757294, 'Total loss': 0.43068020045757294} | train loss {'Reaction outcome loss': 0.12119356609060554, 'Total loss': 0.12119356609060554}
2022-12-31 03:49:44,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:44,351 INFO:     Epoch: 58
2022-12-31 03:49:45,974 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49731398026148477, 'Total loss': 0.49731398026148477} | train loss {'Reaction outcome loss': 0.12191465831553355, 'Total loss': 0.12191465831553355}
2022-12-31 03:49:45,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:45,974 INFO:     Epoch: 59
2022-12-31 03:49:47,625 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4292861943443616, 'Total loss': 0.4292861943443616} | train loss {'Reaction outcome loss': 0.12456618675067752, 'Total loss': 0.12456618675067752}
2022-12-31 03:49:47,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:47,626 INFO:     Epoch: 60
2022-12-31 03:49:49,250 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43501156369845073, 'Total loss': 0.43501156369845073} | train loss {'Reaction outcome loss': 0.12286515925113206, 'Total loss': 0.12286515925113206}
2022-12-31 03:49:49,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:49,252 INFO:     Epoch: 61
2022-12-31 03:49:50,877 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4158915976683299, 'Total loss': 0.4158915976683299} | train loss {'Reaction outcome loss': 0.11885545517079237, 'Total loss': 0.11885545517079237}
2022-12-31 03:49:50,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:50,878 INFO:     Epoch: 62
2022-12-31 03:49:52,449 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46000736256440483, 'Total loss': 0.46000736256440483} | train loss {'Reaction outcome loss': 0.11853900327034536, 'Total loss': 0.11853900327034536}
2022-12-31 03:49:52,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:52,450 INFO:     Epoch: 63
2022-12-31 03:49:53,861 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4290990591049194, 'Total loss': 0.4290990591049194} | train loss {'Reaction outcome loss': 0.12094381925001041, 'Total loss': 0.12094381925001041}
2022-12-31 03:49:53,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:53,862 INFO:     Epoch: 64
2022-12-31 03:49:55,268 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4391292651494344, 'Total loss': 0.4391292651494344} | train loss {'Reaction outcome loss': 0.11906643024232198, 'Total loss': 0.11906643024232198}
2022-12-31 03:49:55,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:55,269 INFO:     Epoch: 65
2022-12-31 03:49:56,391 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4518039631346861, 'Total loss': 0.4518039631346861} | train loss {'Reaction outcome loss': 0.11737504546170792, 'Total loss': 0.11737504546170792}
2022-12-31 03:49:56,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:56,391 INFO:     Epoch: 66
2022-12-31 03:49:57,919 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4515726904074351, 'Total loss': 0.4515726904074351} | train loss {'Reaction outcome loss': 0.11672689287338257, 'Total loss': 0.11672689287338257}
2022-12-31 03:49:57,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:57,919 INFO:     Epoch: 67
2022-12-31 03:49:59,554 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45615738332271577, 'Total loss': 0.45615738332271577} | train loss {'Reaction outcome loss': 0.1112745313935439, 'Total loss': 0.1112745313935439}
2022-12-31 03:49:59,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:49:59,554 INFO:     Epoch: 68
2022-12-31 03:50:01,190 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4503904342651367, 'Total loss': 0.4503904342651367} | train loss {'Reaction outcome loss': 0.11262295339491878, 'Total loss': 0.11262295339491878}
2022-12-31 03:50:01,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:01,191 INFO:     Epoch: 69
2022-12-31 03:50:02,827 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4622612208127975, 'Total loss': 0.4622612208127975} | train loss {'Reaction outcome loss': 0.11673906306645393, 'Total loss': 0.11673906306645393}
2022-12-31 03:50:02,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:02,827 INFO:     Epoch: 70
2022-12-31 03:50:04,466 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4504561374584834, 'Total loss': 0.4504561374584834} | train loss {'Reaction outcome loss': 0.11752131321914629, 'Total loss': 0.11752131321914629}
2022-12-31 03:50:04,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:04,466 INFO:     Epoch: 71
2022-12-31 03:50:06,085 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45859607458114626, 'Total loss': 0.45859607458114626} | train loss {'Reaction outcome loss': 0.11586104868659043, 'Total loss': 0.11586104868659043}
2022-12-31 03:50:06,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:06,085 INFO:     Epoch: 72
2022-12-31 03:50:07,721 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45980575531721113, 'Total loss': 0.45980575531721113} | train loss {'Reaction outcome loss': 0.11763603901423325, 'Total loss': 0.11763603901423325}
2022-12-31 03:50:07,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:07,722 INFO:     Epoch: 73
2022-12-31 03:50:09,359 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44470950663089753, 'Total loss': 0.44470950663089753} | train loss {'Reaction outcome loss': 0.11397567334322642, 'Total loss': 0.11397567334322642}
2022-12-31 03:50:09,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:09,359 INFO:     Epoch: 74
2022-12-31 03:50:10,995 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4818587491909663, 'Total loss': 0.4818587491909663} | train loss {'Reaction outcome loss': 0.10940741767454557, 'Total loss': 0.10940741767454557}
2022-12-31 03:50:10,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:10,996 INFO:     Epoch: 75
2022-12-31 03:50:12,630 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4406742662191391, 'Total loss': 0.4406742662191391} | train loss {'Reaction outcome loss': 0.11616637682229522, 'Total loss': 0.11616637682229522}
2022-12-31 03:50:12,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:12,630 INFO:     Epoch: 76
2022-12-31 03:50:14,261 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44389655093352, 'Total loss': 0.44389655093352} | train loss {'Reaction outcome loss': 0.11396764949744144, 'Total loss': 0.11396764949744144}
2022-12-31 03:50:14,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:14,261 INFO:     Epoch: 77
2022-12-31 03:50:15,873 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42519192695617675, 'Total loss': 0.42519192695617675} | train loss {'Reaction outcome loss': 0.11068910346551385, 'Total loss': 0.11068910346551385}
2022-12-31 03:50:15,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:15,873 INFO:     Epoch: 78
2022-12-31 03:50:17,500 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4307185883323352, 'Total loss': 0.4307185883323352} | train loss {'Reaction outcome loss': 0.11211941946997217, 'Total loss': 0.11211941946997217}
2022-12-31 03:50:17,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:17,500 INFO:     Epoch: 79
2022-12-31 03:50:19,123 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4555070380369822, 'Total loss': 0.4555070380369822} | train loss {'Reaction outcome loss': 0.11209479101432575, 'Total loss': 0.11209479101432575}
2022-12-31 03:50:19,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:19,124 INFO:     Epoch: 80
2022-12-31 03:50:20,748 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4420102109511693, 'Total loss': 0.4420102109511693} | train loss {'Reaction outcome loss': 0.11077774986280095, 'Total loss': 0.11077774986280095}
2022-12-31 03:50:20,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:20,748 INFO:     Epoch: 81
2022-12-31 03:50:22,373 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44796865781148276, 'Total loss': 0.44796865781148276} | train loss {'Reaction outcome loss': 0.11234778215745565, 'Total loss': 0.11234778215745565}
2022-12-31 03:50:22,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:22,374 INFO:     Epoch: 82
2022-12-31 03:50:24,034 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45911138753096264, 'Total loss': 0.45911138753096264} | train loss {'Reaction outcome loss': 0.10951227312806712, 'Total loss': 0.10951227312806712}
2022-12-31 03:50:24,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:24,034 INFO:     Epoch: 83
2022-12-31 03:50:25,734 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4409585287173589, 'Total loss': 0.4409585287173589} | train loss {'Reaction outcome loss': 0.11053182624468734, 'Total loss': 0.11053182624468734}
2022-12-31 03:50:25,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:25,735 INFO:     Epoch: 84
2022-12-31 03:50:27,441 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.423765700062116, 'Total loss': 0.423765700062116} | train loss {'Reaction outcome loss': 0.10975863464388472, 'Total loss': 0.10975863464388472}
2022-12-31 03:50:27,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:27,441 INFO:     Epoch: 85
2022-12-31 03:50:29,110 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4255888024965922, 'Total loss': 0.4255888024965922} | train loss {'Reaction outcome loss': 0.10369856569441943, 'Total loss': 0.10369856569441943}
2022-12-31 03:50:29,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:29,110 INFO:     Epoch: 86
2022-12-31 03:50:30,735 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4606326311826706, 'Total loss': 0.4606326311826706} | train loss {'Reaction outcome loss': 0.10855846701438676, 'Total loss': 0.10855846701438676}
2022-12-31 03:50:30,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:30,735 INFO:     Epoch: 87
2022-12-31 03:50:32,463 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47237457235654196, 'Total loss': 0.47237457235654196} | train loss {'Reaction outcome loss': 0.11504808593363189, 'Total loss': 0.11504808593363189}
2022-12-31 03:50:32,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:32,463 INFO:     Epoch: 88
2022-12-31 03:50:34,126 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4372652808825175, 'Total loss': 0.4372652808825175} | train loss {'Reaction outcome loss': 0.11198276019779568, 'Total loss': 0.11198276019779568}
2022-12-31 03:50:34,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:34,126 INFO:     Epoch: 89
2022-12-31 03:50:35,837 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4248276943961779, 'Total loss': 0.4248276943961779} | train loss {'Reaction outcome loss': 0.1120880199579475, 'Total loss': 0.1120880199579475}
2022-12-31 03:50:35,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:35,837 INFO:     Epoch: 90
2022-12-31 03:50:37,508 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4799822628498077, 'Total loss': 0.4799822628498077} | train loss {'Reaction outcome loss': 0.1080704609113695, 'Total loss': 0.1080704609113695}
2022-12-31 03:50:37,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:37,508 INFO:     Epoch: 91
2022-12-31 03:50:39,177 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45290322999159494, 'Total loss': 0.45290322999159494} | train loss {'Reaction outcome loss': 0.10833422928823272, 'Total loss': 0.10833422928823272}
2022-12-31 03:50:39,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:39,177 INFO:     Epoch: 92
2022-12-31 03:50:40,801 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.444490776459376, 'Total loss': 0.444490776459376} | train loss {'Reaction outcome loss': 0.10358557707566217, 'Total loss': 0.10358557707566217}
2022-12-31 03:50:40,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:40,801 INFO:     Epoch: 93
2022-12-31 03:50:42,427 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4689107298851013, 'Total loss': 0.4689107298851013} | train loss {'Reaction outcome loss': 0.1064010633051476, 'Total loss': 0.1064010633051476}
2022-12-31 03:50:42,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:42,427 INFO:     Epoch: 94
2022-12-31 03:50:44,056 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44605447314679625, 'Total loss': 0.44605447314679625} | train loss {'Reaction outcome loss': 0.10617557374696628, 'Total loss': 0.10617557374696628}
2022-12-31 03:50:44,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:44,056 INFO:     Epoch: 95
2022-12-31 03:50:45,691 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45491628100474674, 'Total loss': 0.45491628100474674} | train loss {'Reaction outcome loss': 0.1088774039953046, 'Total loss': 0.1088774039953046}
2022-12-31 03:50:45,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:45,692 INFO:     Epoch: 96
2022-12-31 03:50:47,328 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4562365606427193, 'Total loss': 0.4562365606427193} | train loss {'Reaction outcome loss': 0.104899373168583, 'Total loss': 0.104899373168583}
2022-12-31 03:50:47,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:47,328 INFO:     Epoch: 97
2022-12-31 03:50:48,963 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4480399747689565, 'Total loss': 0.4480399747689565} | train loss {'Reaction outcome loss': 0.10399401640949858, 'Total loss': 0.10399401640949858}
2022-12-31 03:50:48,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:48,964 INFO:     Epoch: 98
2022-12-31 03:50:50,600 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4423372363050779, 'Total loss': 0.4423372363050779} | train loss {'Reaction outcome loss': 0.10627138230357898, 'Total loss': 0.10627138230357898}
2022-12-31 03:50:50,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:50,600 INFO:     Epoch: 99
2022-12-31 03:50:52,229 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45396894340713817, 'Total loss': 0.45396894340713817} | train loss {'Reaction outcome loss': 0.1134196575941175, 'Total loss': 0.1134196575941175}
2022-12-31 03:50:52,229 INFO:     Best model found after epoch 22 of 100.
2022-12-31 03:50:52,230 INFO:   Done with stage: TRAINING
2022-12-31 03:50:52,230 INFO:   Starting stage: EVALUATION
2022-12-31 03:50:52,357 INFO:   Done with stage: EVALUATION
2022-12-31 03:50:52,357 INFO:   Leaving out SEQ value Fold_5
2022-12-31 03:50:52,370 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 03:50:52,370 INFO:   Starting stage: FEATURE SCALING
2022-12-31 03:50:53,020 INFO:   Done with stage: FEATURE SCALING
2022-12-31 03:50:53,021 INFO:   Starting stage: SCALING TARGETS
2022-12-31 03:50:53,095 INFO:   Done with stage: SCALING TARGETS
2022-12-31 03:50:53,095 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:50:53,095 INFO:     No hyperparam tuning for this model
2022-12-31 03:50:53,095 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:50:53,095 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 03:50:53,096 INFO:     None feature selector for col prot
2022-12-31 03:50:53,096 INFO:     None feature selector for col prot
2022-12-31 03:50:53,096 INFO:     None feature selector for col prot
2022-12-31 03:50:53,096 INFO:     None feature selector for col chem
2022-12-31 03:50:53,096 INFO:     None feature selector for col chem
2022-12-31 03:50:53,097 INFO:     None feature selector for col chem
2022-12-31 03:50:53,097 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 03:50:53,097 INFO:   Starting stage: BUILD MODEL
2022-12-31 03:50:53,099 INFO:     Number of params in model 224011
2022-12-31 03:50:53,102 INFO:   Done with stage: BUILD MODEL
2022-12-31 03:50:53,102 INFO:   Starting stage: TRAINING
2022-12-31 03:50:53,148 INFO:     Val loss before train {'Reaction outcome loss': 1.0629977146784464, 'Total loss': 1.0629977146784464}
2022-12-31 03:50:53,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:53,148 INFO:     Epoch: 0
2022-12-31 03:50:54,766 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5482600251833598, 'Total loss': 0.5482600251833598} | train loss {'Reaction outcome loss': 0.7843265024189284, 'Total loss': 0.7843265024189284}
2022-12-31 03:50:54,766 INFO:     Found new best model at epoch 0
2022-12-31 03:50:54,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:54,767 INFO:     Epoch: 1
2022-12-31 03:50:56,398 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4797617514928182, 'Total loss': 0.4797617514928182} | train loss {'Reaction outcome loss': 0.5077038225532253, 'Total loss': 0.5077038225532253}
2022-12-31 03:50:56,399 INFO:     Found new best model at epoch 1
2022-12-31 03:50:56,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:56,400 INFO:     Epoch: 2
2022-12-31 03:50:58,025 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4701113243897756, 'Total loss': 0.4701113243897756} | train loss {'Reaction outcome loss': 0.46226018262298213, 'Total loss': 0.46226018262298213}
2022-12-31 03:50:58,025 INFO:     Found new best model at epoch 2
2022-12-31 03:50:58,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:58,026 INFO:     Epoch: 3
2022-12-31 03:50:59,662 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4410324037075043, 'Total loss': 0.4410324037075043} | train loss {'Reaction outcome loss': 0.4154809799038576, 'Total loss': 0.4154809799038576}
2022-12-31 03:50:59,662 INFO:     Found new best model at epoch 3
2022-12-31 03:50:59,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:50:59,663 INFO:     Epoch: 4
2022-12-31 03:51:01,281 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4292638977368673, 'Total loss': 0.4292638977368673} | train loss {'Reaction outcome loss': 0.3799640407913999, 'Total loss': 0.3799640407913999}
2022-12-31 03:51:01,281 INFO:     Found new best model at epoch 4
2022-12-31 03:51:01,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:01,282 INFO:     Epoch: 5
2022-12-31 03:51:02,915 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4227811505397161, 'Total loss': 0.4227811505397161} | train loss {'Reaction outcome loss': 0.3580487142182023, 'Total loss': 0.3580487142182023}
2022-12-31 03:51:02,916 INFO:     Found new best model at epoch 5
2022-12-31 03:51:02,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:02,917 INFO:     Epoch: 6
2022-12-31 03:51:04,552 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43500855267047883, 'Total loss': 0.43500855267047883} | train loss {'Reaction outcome loss': 0.33851902166192094, 'Total loss': 0.33851902166192094}
2022-12-31 03:51:04,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:04,552 INFO:     Epoch: 7
2022-12-31 03:51:06,187 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.41885313789049783, 'Total loss': 0.41885313789049783} | train loss {'Reaction outcome loss': 0.32142845076083654, 'Total loss': 0.32142845076083654}
2022-12-31 03:51:06,187 INFO:     Found new best model at epoch 7
2022-12-31 03:51:06,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:06,188 INFO:     Epoch: 8
2022-12-31 03:51:07,821 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3968288610378901, 'Total loss': 0.3968288610378901} | train loss {'Reaction outcome loss': 0.316525569199112, 'Total loss': 0.316525569199112}
2022-12-31 03:51:07,822 INFO:     Found new best model at epoch 8
2022-12-31 03:51:07,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:07,823 INFO:     Epoch: 9
2022-12-31 03:51:09,449 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40351835687955223, 'Total loss': 0.40351835687955223} | train loss {'Reaction outcome loss': 0.3037798739695564, 'Total loss': 0.3037798739695564}
2022-12-31 03:51:09,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:09,449 INFO:     Epoch: 10
2022-12-31 03:51:11,061 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4303225303689639, 'Total loss': 0.4303225303689639} | train loss {'Reaction outcome loss': 0.2814041181885894, 'Total loss': 0.2814041181885894}
2022-12-31 03:51:11,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:11,061 INFO:     Epoch: 11
2022-12-31 03:51:12,675 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4130653570095698, 'Total loss': 0.4130653570095698} | train loss {'Reaction outcome loss': 0.29631779755911103, 'Total loss': 0.29631779755911103}
2022-12-31 03:51:12,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:12,675 INFO:     Epoch: 12
2022-12-31 03:51:14,338 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4143591011563937, 'Total loss': 0.4143591011563937} | train loss {'Reaction outcome loss': 0.2569559862756211, 'Total loss': 0.2569559862756211}
2022-12-31 03:51:14,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:14,339 INFO:     Epoch: 13
2022-12-31 03:51:15,952 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43083845178286234, 'Total loss': 0.43083845178286234} | train loss {'Reaction outcome loss': 0.2502349174136053, 'Total loss': 0.2502349174136053}
2022-12-31 03:51:15,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:15,953 INFO:     Epoch: 14
2022-12-31 03:51:17,566 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4130331402023633, 'Total loss': 0.4130331402023633} | train loss {'Reaction outcome loss': 0.24971898530097003, 'Total loss': 0.24971898530097003}
2022-12-31 03:51:17,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:17,566 INFO:     Epoch: 15
2022-12-31 03:51:19,173 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42850843171278635, 'Total loss': 0.42850843171278635} | train loss {'Reaction outcome loss': 0.23343567856489614, 'Total loss': 0.23343567856489614}
2022-12-31 03:51:19,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:19,173 INFO:     Epoch: 16
2022-12-31 03:51:20,811 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4046585520108541, 'Total loss': 0.4046585520108541} | train loss {'Reaction outcome loss': 0.2248011258383538, 'Total loss': 0.2248011258383538}
2022-12-31 03:51:20,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:20,811 INFO:     Epoch: 17
2022-12-31 03:51:22,450 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4271020700534185, 'Total loss': 0.4271020700534185} | train loss {'Reaction outcome loss': 0.22339692005914621, 'Total loss': 0.22339692005914621}
2022-12-31 03:51:22,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:22,450 INFO:     Epoch: 18
2022-12-31 03:51:24,087 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41445547342300415, 'Total loss': 0.41445547342300415} | train loss {'Reaction outcome loss': 0.2144892494585635, 'Total loss': 0.2144892494585635}
2022-12-31 03:51:24,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:24,087 INFO:     Epoch: 19
2022-12-31 03:51:25,724 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4125118543704351, 'Total loss': 0.4125118543704351} | train loss {'Reaction outcome loss': 0.2086593193521696, 'Total loss': 0.2086593193521696}
2022-12-31 03:51:25,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:25,726 INFO:     Epoch: 20
2022-12-31 03:51:27,356 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4278041750192642, 'Total loss': 0.4278041750192642} | train loss {'Reaction outcome loss': 0.20522553698780635, 'Total loss': 0.20522553698780635}
2022-12-31 03:51:27,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:27,356 INFO:     Epoch: 21
2022-12-31 03:51:28,982 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43134315609931945, 'Total loss': 0.43134315609931945} | train loss {'Reaction outcome loss': 0.1985614599990726, 'Total loss': 0.1985614599990726}
2022-12-31 03:51:28,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:28,983 INFO:     Epoch: 22
2022-12-31 03:51:30,619 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43598975936571754, 'Total loss': 0.43598975936571754} | train loss {'Reaction outcome loss': 0.1943051304330726, 'Total loss': 0.1943051304330726}
2022-12-31 03:51:30,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:30,619 INFO:     Epoch: 23
2022-12-31 03:51:32,250 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.422536297639211, 'Total loss': 0.422536297639211} | train loss {'Reaction outcome loss': 0.19416650620194664, 'Total loss': 0.19416650620194664}
2022-12-31 03:51:32,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:32,251 INFO:     Epoch: 24
2022-12-31 03:51:33,888 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4489905526240667, 'Total loss': 0.4489905526240667} | train loss {'Reaction outcome loss': 0.18888148454958895, 'Total loss': 0.18888148454958895}
2022-12-31 03:51:33,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:33,888 INFO:     Epoch: 25
2022-12-31 03:51:35,524 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40356326500574746, 'Total loss': 0.40356326500574746} | train loss {'Reaction outcome loss': 0.1867127689563305, 'Total loss': 0.1867127689563305}
2022-12-31 03:51:35,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:35,524 INFO:     Epoch: 26
2022-12-31 03:51:37,150 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42518392304579417, 'Total loss': 0.42518392304579417} | train loss {'Reaction outcome loss': 0.18518541940695443, 'Total loss': 0.18518541940695443}
2022-12-31 03:51:37,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:37,151 INFO:     Epoch: 27
2022-12-31 03:51:38,808 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4392702559630076, 'Total loss': 0.4392702559630076} | train loss {'Reaction outcome loss': 0.18092633832186591, 'Total loss': 0.18092633832186591}
2022-12-31 03:51:38,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:38,808 INFO:     Epoch: 28
2022-12-31 03:51:40,471 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41487228175004326, 'Total loss': 0.41487228175004326} | train loss {'Reaction outcome loss': 0.1772412887349028, 'Total loss': 0.1772412887349028}
2022-12-31 03:51:40,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:40,471 INFO:     Epoch: 29
2022-12-31 03:51:42,134 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3971397126714388, 'Total loss': 0.3971397126714388} | train loss {'Reaction outcome loss': 0.17087239618379407, 'Total loss': 0.17087239618379407}
2022-12-31 03:51:42,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:42,135 INFO:     Epoch: 30
2022-12-31 03:51:43,798 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41176575471957527, 'Total loss': 0.41176575471957527} | train loss {'Reaction outcome loss': 0.171883961101454, 'Total loss': 0.171883961101454}
2022-12-31 03:51:43,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:43,798 INFO:     Epoch: 31
2022-12-31 03:51:45,460 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3905631721019745, 'Total loss': 0.3905631721019745} | train loss {'Reaction outcome loss': 0.16877129675128305, 'Total loss': 0.16877129675128305}
2022-12-31 03:51:45,461 INFO:     Found new best model at epoch 31
2022-12-31 03:51:45,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:45,462 INFO:     Epoch: 32
2022-12-31 03:51:47,072 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39716709752877555, 'Total loss': 0.39716709752877555} | train loss {'Reaction outcome loss': 0.16399429729234927, 'Total loss': 0.16399429729234927}
2022-12-31 03:51:47,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:47,072 INFO:     Epoch: 33
2022-12-31 03:51:48,703 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4015231748421987, 'Total loss': 0.4015231748421987} | train loss {'Reaction outcome loss': 0.16317535500607133, 'Total loss': 0.16317535500607133}
2022-12-31 03:51:48,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:48,704 INFO:     Epoch: 34
2022-12-31 03:51:50,335 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3873375157515208, 'Total loss': 0.3873375157515208} | train loss {'Reaction outcome loss': 0.16288946704520166, 'Total loss': 0.16288946704520166}
2022-12-31 03:51:50,336 INFO:     Found new best model at epoch 34
2022-12-31 03:51:50,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:50,337 INFO:     Epoch: 35
2022-12-31 03:51:51,972 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41026774098475777, 'Total loss': 0.41026774098475777} | train loss {'Reaction outcome loss': 0.16098090074777155, 'Total loss': 0.16098090074777155}
2022-12-31 03:51:51,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:51,972 INFO:     Epoch: 36
2022-12-31 03:51:53,602 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4121750324964523, 'Total loss': 0.4121750324964523} | train loss {'Reaction outcome loss': 0.1587036315702236, 'Total loss': 0.1587036315702236}
2022-12-31 03:51:53,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:53,602 INFO:     Epoch: 37
2022-12-31 03:51:55,223 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37525662978490193, 'Total loss': 0.37525662978490193} | train loss {'Reaction outcome loss': 0.1579173691098349, 'Total loss': 0.1579173691098349}
2022-12-31 03:51:55,223 INFO:     Found new best model at epoch 37
2022-12-31 03:51:55,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:55,224 INFO:     Epoch: 38
2022-12-31 03:51:56,847 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41997575759887695, 'Total loss': 0.41997575759887695} | train loss {'Reaction outcome loss': 0.14990839402700026, 'Total loss': 0.14990839402700026}
2022-12-31 03:51:56,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:56,848 INFO:     Epoch: 39
2022-12-31 03:51:58,484 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.414769184589386, 'Total loss': 0.414769184589386} | train loss {'Reaction outcome loss': 0.14936837648628684, 'Total loss': 0.14936837648628684}
2022-12-31 03:51:58,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:51:58,484 INFO:     Epoch: 40
2022-12-31 03:52:00,121 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4057265510161718, 'Total loss': 0.4057265510161718} | train loss {'Reaction outcome loss': 0.14908440149325095, 'Total loss': 0.14908440149325095}
2022-12-31 03:52:00,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:00,121 INFO:     Epoch: 41
2022-12-31 03:52:01,755 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.417085799574852, 'Total loss': 0.417085799574852} | train loss {'Reaction outcome loss': 0.147631719555225, 'Total loss': 0.147631719555225}
2022-12-31 03:52:01,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:01,756 INFO:     Epoch: 42
2022-12-31 03:52:03,392 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4479536513487498, 'Total loss': 0.4479536513487498} | train loss {'Reaction outcome loss': 0.15038724030640865, 'Total loss': 0.15038724030640865}
2022-12-31 03:52:03,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:03,392 INFO:     Epoch: 43
2022-12-31 03:52:05,017 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42819089194138843, 'Total loss': 0.42819089194138843} | train loss {'Reaction outcome loss': 0.14502394036558605, 'Total loss': 0.14502394036558605}
2022-12-31 03:52:05,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:05,017 INFO:     Epoch: 44
2022-12-31 03:52:06,681 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40415715873241426, 'Total loss': 0.40415715873241426} | train loss {'Reaction outcome loss': 0.1477199446697183, 'Total loss': 0.1477199446697183}
2022-12-31 03:52:06,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:06,681 INFO:     Epoch: 45
2022-12-31 03:52:08,302 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3912629585713148, 'Total loss': 0.3912629585713148} | train loss {'Reaction outcome loss': 0.1424291687044124, 'Total loss': 0.1424291687044124}
2022-12-31 03:52:08,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:08,303 INFO:     Epoch: 46
2022-12-31 03:52:09,922 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3869048893451691, 'Total loss': 0.3869048893451691} | train loss {'Reaction outcome loss': 0.14104664383795235, 'Total loss': 0.14104664383795235}
2022-12-31 03:52:09,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:09,922 INFO:     Epoch: 47
2022-12-31 03:52:11,586 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4162181024750074, 'Total loss': 0.4162181024750074} | train loss {'Reaction outcome loss': 0.1451638146047143, 'Total loss': 0.1451638146047143}
2022-12-31 03:52:11,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:11,587 INFO:     Epoch: 48
2022-12-31 03:52:13,247 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4147762099901835, 'Total loss': 0.4147762099901835} | train loss {'Reaction outcome loss': 0.13915997274570924, 'Total loss': 0.13915997274570924}
2022-12-31 03:52:13,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:13,247 INFO:     Epoch: 49
2022-12-31 03:52:14,865 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4314180662234624, 'Total loss': 0.4314180662234624} | train loss {'Reaction outcome loss': 0.13996756716443232, 'Total loss': 0.13996756716443232}
2022-12-31 03:52:14,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:14,865 INFO:     Epoch: 50
2022-12-31 03:52:16,502 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4069307883580526, 'Total loss': 0.4069307883580526} | train loss {'Reaction outcome loss': 0.13485203219064767, 'Total loss': 0.13485203219064767}
2022-12-31 03:52:16,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:16,503 INFO:     Epoch: 51
2022-12-31 03:52:18,138 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40774404207865395, 'Total loss': 0.40774404207865395} | train loss {'Reaction outcome loss': 0.14261586538286528, 'Total loss': 0.14261586538286528}
2022-12-31 03:52:18,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:18,139 INFO:     Epoch: 52
2022-12-31 03:52:19,775 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44610940515995023, 'Total loss': 0.44610940515995023} | train loss {'Reaction outcome loss': 0.15376561912547704, 'Total loss': 0.15376561912547704}
2022-12-31 03:52:19,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:19,775 INFO:     Epoch: 53
2022-12-31 03:52:21,413 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41512008806069695, 'Total loss': 0.41512008806069695} | train loss {'Reaction outcome loss': 0.13920682687202698, 'Total loss': 0.13920682687202698}
2022-12-31 03:52:21,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:21,413 INFO:     Epoch: 54
2022-12-31 03:52:23,028 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4218548814455668, 'Total loss': 0.4218548814455668} | train loss {'Reaction outcome loss': 0.13615426409692652, 'Total loss': 0.13615426409692652}
2022-12-31 03:52:23,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:23,028 INFO:     Epoch: 55
2022-12-31 03:52:24,640 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40808102091153464, 'Total loss': 0.40808102091153464} | train loss {'Reaction outcome loss': 0.15397183224896266, 'Total loss': 0.15397183224896266}
2022-12-31 03:52:24,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:24,640 INFO:     Epoch: 56
2022-12-31 03:52:26,305 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.427564345796903, 'Total loss': 0.427564345796903} | train loss {'Reaction outcome loss': 0.13436988651570256, 'Total loss': 0.13436988651570256}
2022-12-31 03:52:26,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:26,305 INFO:     Epoch: 57
2022-12-31 03:52:27,919 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42213476995627086, 'Total loss': 0.42213476995627086} | train loss {'Reaction outcome loss': 0.13403096257884434, 'Total loss': 0.13403096257884434}
2022-12-31 03:52:27,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:27,919 INFO:     Epoch: 58
2022-12-31 03:52:29,536 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43465364575386045, 'Total loss': 0.43465364575386045} | train loss {'Reaction outcome loss': 0.12505704565378634, 'Total loss': 0.12505704565378634}
2022-12-31 03:52:29,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:29,536 INFO:     Epoch: 59
2022-12-31 03:52:31,154 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4247613072395325, 'Total loss': 0.4247613072395325} | train loss {'Reaction outcome loss': 0.1376526149570186, 'Total loss': 0.1376526149570186}
2022-12-31 03:52:31,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:31,154 INFO:     Epoch: 60
2022-12-31 03:52:32,769 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4389453838268916, 'Total loss': 0.4389453838268916} | train loss {'Reaction outcome loss': 0.13723966156038037, 'Total loss': 0.13723966156038037}
2022-12-31 03:52:32,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:32,769 INFO:     Epoch: 61
2022-12-31 03:52:34,389 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4522432625293732, 'Total loss': 0.4522432625293732} | train loss {'Reaction outcome loss': 0.14204915604806845, 'Total loss': 0.14204915604806845}
2022-12-31 03:52:34,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:34,390 INFO:     Epoch: 62
2022-12-31 03:52:36,009 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41436934073766074, 'Total loss': 0.41436934073766074} | train loss {'Reaction outcome loss': 0.12994417572559358, 'Total loss': 0.12994417572559358}
2022-12-31 03:52:36,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:36,010 INFO:     Epoch: 63
2022-12-31 03:52:37,629 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44121015071868896, 'Total loss': 0.44121015071868896} | train loss {'Reaction outcome loss': 0.15015835607714573, 'Total loss': 0.15015835607714573}
2022-12-31 03:52:37,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:37,630 INFO:     Epoch: 64
2022-12-31 03:52:39,250 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4229282756646474, 'Total loss': 0.4229282756646474} | train loss {'Reaction outcome loss': 0.13996558148832317, 'Total loss': 0.13996558148832317}
2022-12-31 03:52:39,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:39,250 INFO:     Epoch: 65
2022-12-31 03:52:40,869 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4623881906270981, 'Total loss': 0.4623881906270981} | train loss {'Reaction outcome loss': 0.13780807830524913, 'Total loss': 0.13780807830524913}
2022-12-31 03:52:40,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:40,869 INFO:     Epoch: 66
2022-12-31 03:52:42,521 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45820830563704174, 'Total loss': 0.45820830563704174} | train loss {'Reaction outcome loss': 0.1220954533257126, 'Total loss': 0.1220954533257126}
2022-12-31 03:52:42,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:42,521 INFO:     Epoch: 67
2022-12-31 03:52:44,134 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4044248819351196, 'Total loss': 0.4044248819351196} | train loss {'Reaction outcome loss': 0.12457283664847953, 'Total loss': 0.12457283664847953}
2022-12-31 03:52:44,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:44,135 INFO:     Epoch: 68
2022-12-31 03:52:45,741 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44798168043295544, 'Total loss': 0.44798168043295544} | train loss {'Reaction outcome loss': 0.12152040191332175, 'Total loss': 0.12152040191332175}
2022-12-31 03:52:45,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:45,741 INFO:     Epoch: 69
2022-12-31 03:52:47,355 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47738874951998395, 'Total loss': 0.47738874951998395} | train loss {'Reaction outcome loss': 0.12105679709086384, 'Total loss': 0.12105679709086384}
2022-12-31 03:52:47,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:47,356 INFO:     Epoch: 70
2022-12-31 03:52:48,968 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4451647778352102, 'Total loss': 0.4451647778352102} | train loss {'Reaction outcome loss': 0.11640598967708196, 'Total loss': 0.11640598967708196}
2022-12-31 03:52:48,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:48,968 INFO:     Epoch: 71
2022-12-31 03:52:50,582 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.435182652870814, 'Total loss': 0.435182652870814} | train loss {'Reaction outcome loss': 0.11765869639381982, 'Total loss': 0.11765869639381982}
2022-12-31 03:52:50,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:50,582 INFO:     Epoch: 72
2022-12-31 03:52:52,198 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47169600079456964, 'Total loss': 0.47169600079456964} | train loss {'Reaction outcome loss': 0.12101038310156319, 'Total loss': 0.12101038310156319}
2022-12-31 03:52:52,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:52,199 INFO:     Epoch: 73
2022-12-31 03:52:53,862 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48428816397984825, 'Total loss': 0.48428816397984825} | train loss {'Reaction outcome loss': 0.1244056621889404, 'Total loss': 0.1244056621889404}
2022-12-31 03:52:53,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:53,862 INFO:     Epoch: 74
2022-12-31 03:52:55,482 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4542570938666662, 'Total loss': 0.4542570938666662} | train loss {'Reaction outcome loss': 0.12186989721511424, 'Total loss': 0.12186989721511424}
2022-12-31 03:52:55,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:55,482 INFO:     Epoch: 75
2022-12-31 03:52:57,146 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4287440598011017, 'Total loss': 0.4287440598011017} | train loss {'Reaction outcome loss': 0.1358865142196853, 'Total loss': 0.1358865142196853}
2022-12-31 03:52:57,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:57,147 INFO:     Epoch: 76
2022-12-31 03:52:58,761 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4273418108622233, 'Total loss': 0.4273418108622233} | train loss {'Reaction outcome loss': 0.12065538824907085, 'Total loss': 0.12065538824907085}
2022-12-31 03:52:58,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:52:58,762 INFO:     Epoch: 77
2022-12-31 03:53:00,379 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4326628128687541, 'Total loss': 0.4326628128687541} | train loss {'Reaction outcome loss': 0.11964574731583538, 'Total loss': 0.11964574731583538}
2022-12-31 03:53:00,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:00,379 INFO:     Epoch: 78
2022-12-31 03:53:02,042 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4234521761536598, 'Total loss': 0.4234521761536598} | train loss {'Reaction outcome loss': 0.11749725193763827, 'Total loss': 0.11749725193763827}
2022-12-31 03:53:02,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:02,042 INFO:     Epoch: 79
2022-12-31 03:53:03,706 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4200058956940969, 'Total loss': 0.4200058956940969} | train loss {'Reaction outcome loss': 0.11446897981780542, 'Total loss': 0.11446897981780542}
2022-12-31 03:53:03,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:03,706 INFO:     Epoch: 80
2022-12-31 03:53:05,323 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42573065757751466, 'Total loss': 0.42573065757751466} | train loss {'Reaction outcome loss': 0.11652809527257214, 'Total loss': 0.11652809527257214}
2022-12-31 03:53:05,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:05,323 INFO:     Epoch: 81
2022-12-31 03:53:06,987 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4579055647055308, 'Total loss': 0.4579055647055308} | train loss {'Reaction outcome loss': 0.11658397416244227, 'Total loss': 0.11658397416244227}
2022-12-31 03:53:06,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:06,987 INFO:     Epoch: 82
2022-12-31 03:53:08,598 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4059334655602773, 'Total loss': 0.4059334655602773} | train loss {'Reaction outcome loss': 0.11659393798966092, 'Total loss': 0.11659393798966092}
2022-12-31 03:53:08,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:08,599 INFO:     Epoch: 83
2022-12-31 03:53:10,215 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46543277700742086, 'Total loss': 0.46543277700742086} | train loss {'Reaction outcome loss': 0.11493418704233499, 'Total loss': 0.11493418704233499}
2022-12-31 03:53:10,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:10,215 INFO:     Epoch: 84
2022-12-31 03:53:11,879 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44232526123523713, 'Total loss': 0.44232526123523713} | train loss {'Reaction outcome loss': 0.12013056883217255, 'Total loss': 0.12013056883217255}
2022-12-31 03:53:11,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:11,879 INFO:     Epoch: 85
2022-12-31 03:53:13,494 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47294609944025673, 'Total loss': 0.47294609944025673} | train loss {'Reaction outcome loss': 0.11801536308527263, 'Total loss': 0.11801536308527263}
2022-12-31 03:53:13,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:13,495 INFO:     Epoch: 86
2022-12-31 03:53:15,158 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45856943130493166, 'Total loss': 0.45856943130493166} | train loss {'Reaction outcome loss': 0.1145314138181899, 'Total loss': 0.1145314138181899}
2022-12-31 03:53:15,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:15,159 INFO:     Epoch: 87
2022-12-31 03:53:16,776 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42650967041651405, 'Total loss': 0.42650967041651405} | train loss {'Reaction outcome loss': 0.12070733000402233, 'Total loss': 0.12070733000402233}
2022-12-31 03:53:16,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:16,776 INFO:     Epoch: 88
2022-12-31 03:53:18,392 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4037237803141276, 'Total loss': 0.4037237803141276} | train loss {'Reaction outcome loss': 0.11433789730105764, 'Total loss': 0.11433789730105764}
2022-12-31 03:53:18,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:18,392 INFO:     Epoch: 89
2022-12-31 03:53:20,056 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39426706631978353, 'Total loss': 0.39426706631978353} | train loss {'Reaction outcome loss': 0.1112199275475164, 'Total loss': 0.1112199275475164}
2022-12-31 03:53:20,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:20,056 INFO:     Epoch: 90
2022-12-31 03:53:21,720 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4335880289475123, 'Total loss': 0.4335880289475123} | train loss {'Reaction outcome loss': 0.10977605886190482, 'Total loss': 0.10977605886190482}
2022-12-31 03:53:21,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:21,720 INFO:     Epoch: 91
2022-12-31 03:53:23,385 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42760657966136933, 'Total loss': 0.42760657966136933} | train loss {'Reaction outcome loss': 0.11149584583303743, 'Total loss': 0.11149584583303743}
2022-12-31 03:53:23,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:23,386 INFO:     Epoch: 92
2022-12-31 03:53:25,002 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3923414597908656, 'Total loss': 0.3923414597908656} | train loss {'Reaction outcome loss': 0.1173496347447194, 'Total loss': 0.1173496347447194}
2022-12-31 03:53:25,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:25,002 INFO:     Epoch: 93
2022-12-31 03:53:26,644 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42110545734564464, 'Total loss': 0.42110545734564464} | train loss {'Reaction outcome loss': 0.11486187548987378, 'Total loss': 0.11486187548987378}
2022-12-31 03:53:26,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:26,644 INFO:     Epoch: 94
2022-12-31 03:53:28,254 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40962932718296846, 'Total loss': 0.40962932718296846} | train loss {'Reaction outcome loss': 0.11471497854454092, 'Total loss': 0.11471497854454092}
2022-12-31 03:53:28,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:28,255 INFO:     Epoch: 95
2022-12-31 03:53:29,865 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4568810592095057, 'Total loss': 0.4568810592095057} | train loss {'Reaction outcome loss': 0.11858184529684376, 'Total loss': 0.11858184529684376}
2022-12-31 03:53:29,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:29,865 INFO:     Epoch: 96
2022-12-31 03:53:31,529 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46326748629411063, 'Total loss': 0.46326748629411063} | train loss {'Reaction outcome loss': 0.1251876801033032, 'Total loss': 0.1251876801033032}
2022-12-31 03:53:31,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:31,530 INFO:     Epoch: 97
2022-12-31 03:53:33,138 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43372932970523836, 'Total loss': 0.43372932970523836} | train loss {'Reaction outcome loss': 0.1305029006789614, 'Total loss': 0.1305029006789614}
2022-12-31 03:53:33,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:33,138 INFO:     Epoch: 98
2022-12-31 03:53:34,749 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4138587454954783, 'Total loss': 0.4138587454954783} | train loss {'Reaction outcome loss': 0.12051364491101897, 'Total loss': 0.12051364491101897}
2022-12-31 03:53:34,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:34,749 INFO:     Epoch: 99
2022-12-31 03:53:36,388 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4378133257230123, 'Total loss': 0.4378133257230123} | train loss {'Reaction outcome loss': 0.11315217620669527, 'Total loss': 0.11315217620669527}
2022-12-31 03:53:36,388 INFO:     Best model found after epoch 38 of 100.
2022-12-31 03:53:36,388 INFO:   Done with stage: TRAINING
2022-12-31 03:53:36,388 INFO:   Starting stage: EVALUATION
2022-12-31 03:53:36,518 INFO:   Done with stage: EVALUATION
2022-12-31 03:53:36,518 INFO:   Leaving out SEQ value Fold_6
2022-12-31 03:53:36,531 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 03:53:36,531 INFO:   Starting stage: FEATURE SCALING
2022-12-31 03:53:37,178 INFO:   Done with stage: FEATURE SCALING
2022-12-31 03:53:37,178 INFO:   Starting stage: SCALING TARGETS
2022-12-31 03:53:37,251 INFO:   Done with stage: SCALING TARGETS
2022-12-31 03:53:37,251 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:53:37,251 INFO:     No hyperparam tuning for this model
2022-12-31 03:53:37,251 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:53:37,252 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 03:53:37,252 INFO:     None feature selector for col prot
2022-12-31 03:53:37,252 INFO:     None feature selector for col prot
2022-12-31 03:53:37,252 INFO:     None feature selector for col prot
2022-12-31 03:53:37,253 INFO:     None feature selector for col chem
2022-12-31 03:53:37,253 INFO:     None feature selector for col chem
2022-12-31 03:53:37,253 INFO:     None feature selector for col chem
2022-12-31 03:53:37,253 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 03:53:37,253 INFO:   Starting stage: BUILD MODEL
2022-12-31 03:53:37,255 INFO:     Number of params in model 224011
2022-12-31 03:53:37,258 INFO:   Done with stage: BUILD MODEL
2022-12-31 03:53:37,258 INFO:   Starting stage: TRAINING
2022-12-31 03:53:37,303 INFO:     Val loss before train {'Reaction outcome loss': 0.991812813282013, 'Total loss': 0.991812813282013}
2022-12-31 03:53:37,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:37,303 INFO:     Epoch: 0
2022-12-31 03:53:38,922 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6254940887292226, 'Total loss': 0.6254940887292226} | train loss {'Reaction outcome loss': 0.7875646126829761, 'Total loss': 0.7875646126829761}
2022-12-31 03:53:38,923 INFO:     Found new best model at epoch 0
2022-12-31 03:53:38,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:38,924 INFO:     Epoch: 1
2022-12-31 03:53:40,538 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5061222910881042, 'Total loss': 0.5061222910881042} | train loss {'Reaction outcome loss': 0.5215692908002151, 'Total loss': 0.5215692908002151}
2022-12-31 03:53:40,539 INFO:     Found new best model at epoch 1
2022-12-31 03:53:40,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:40,540 INFO:     Epoch: 2
2022-12-31 03:53:42,154 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48179763356844585, 'Total loss': 0.48179763356844585} | train loss {'Reaction outcome loss': 0.44665362879580106, 'Total loss': 0.44665362879580106}
2022-12-31 03:53:42,154 INFO:     Found new best model at epoch 2
2022-12-31 03:53:42,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:42,155 INFO:     Epoch: 3
2022-12-31 03:53:43,769 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4472060302893321, 'Total loss': 0.4472060302893321} | train loss {'Reaction outcome loss': 0.41028177590253984, 'Total loss': 0.41028177590253984}
2022-12-31 03:53:43,769 INFO:     Found new best model at epoch 3
2022-12-31 03:53:43,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:43,770 INFO:     Epoch: 4
2022-12-31 03:53:45,377 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43403826852639515, 'Total loss': 0.43403826852639515} | train loss {'Reaction outcome loss': 0.3765646992822847, 'Total loss': 0.3765646992822847}
2022-12-31 03:53:45,378 INFO:     Found new best model at epoch 4
2022-12-31 03:53:45,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:45,379 INFO:     Epoch: 5
2022-12-31 03:53:47,001 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43516768713792164, 'Total loss': 0.43516768713792164} | train loss {'Reaction outcome loss': 0.35553087369414443, 'Total loss': 0.35553087369414443}
2022-12-31 03:53:47,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:47,001 INFO:     Epoch: 6
2022-12-31 03:53:48,624 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4407699783643087, 'Total loss': 0.4407699783643087} | train loss {'Reaction outcome loss': 0.33465979062693213, 'Total loss': 0.33465979062693213}
2022-12-31 03:53:48,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:48,624 INFO:     Epoch: 7
2022-12-31 03:53:50,247 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4283439576625824, 'Total loss': 0.4283439576625824} | train loss {'Reaction outcome loss': 0.3189922089584252, 'Total loss': 0.3189922089584252}
2022-12-31 03:53:50,247 INFO:     Found new best model at epoch 7
2022-12-31 03:53:50,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:50,248 INFO:     Epoch: 8
2022-12-31 03:53:51,871 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43783123095830284, 'Total loss': 0.43783123095830284} | train loss {'Reaction outcome loss': 0.3009296574626481, 'Total loss': 0.3009296574626481}
2022-12-31 03:53:51,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:51,872 INFO:     Epoch: 9
2022-12-31 03:53:53,488 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.425199153025945, 'Total loss': 0.425199153025945} | train loss {'Reaction outcome loss': 0.2875426926579501, 'Total loss': 0.2875426926579501}
2022-12-31 03:53:53,488 INFO:     Found new best model at epoch 9
2022-12-31 03:53:53,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:53,489 INFO:     Epoch: 10
2022-12-31 03:53:55,152 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41336481273174286, 'Total loss': 0.41336481273174286} | train loss {'Reaction outcome loss': 0.2775339281408365, 'Total loss': 0.2775339281408365}
2022-12-31 03:53:55,153 INFO:     Found new best model at epoch 10
2022-12-31 03:53:55,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:55,154 INFO:     Epoch: 11
2022-12-31 03:53:56,774 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.450223575035731, 'Total loss': 0.450223575035731} | train loss {'Reaction outcome loss': 0.2647606857820323, 'Total loss': 0.2647606857820323}
2022-12-31 03:53:56,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:56,774 INFO:     Epoch: 12
2022-12-31 03:53:58,441 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4018715888261795, 'Total loss': 0.4018715888261795} | train loss {'Reaction outcome loss': 0.2508542437092922, 'Total loss': 0.2508542437092922}
2022-12-31 03:53:58,442 INFO:     Found new best model at epoch 12
2022-12-31 03:53:58,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:53:58,443 INFO:     Epoch: 13
2022-12-31 03:54:00,110 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43892888029416405, 'Total loss': 0.43892888029416405} | train loss {'Reaction outcome loss': 0.24578204147168015, 'Total loss': 0.24578204147168015}
2022-12-31 03:54:00,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:00,111 INFO:     Epoch: 14
2022-12-31 03:54:01,729 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45130250851313275, 'Total loss': 0.45130250851313275} | train loss {'Reaction outcome loss': 0.2345579325722443, 'Total loss': 0.2345579325722443}
2022-12-31 03:54:01,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:01,729 INFO:     Epoch: 15
2022-12-31 03:54:03,343 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.412983630100886, 'Total loss': 0.412983630100886} | train loss {'Reaction outcome loss': 0.22869869786909772, 'Total loss': 0.22869869786909772}
2022-12-31 03:54:03,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:03,344 INFO:     Epoch: 16
2022-12-31 03:54:04,959 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43495375514030454, 'Total loss': 0.43495375514030454} | train loss {'Reaction outcome loss': 0.22210544062650592, 'Total loss': 0.22210544062650592}
2022-12-31 03:54:04,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:04,960 INFO:     Epoch: 17
2022-12-31 03:54:06,578 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47591324845949806, 'Total loss': 0.47591324845949806} | train loss {'Reaction outcome loss': 0.21379506023136718, 'Total loss': 0.21379506023136718}
2022-12-31 03:54:06,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:06,578 INFO:     Epoch: 18
2022-12-31 03:54:08,246 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4349191943804423, 'Total loss': 0.4349191943804423} | train loss {'Reaction outcome loss': 0.20793192158537221, 'Total loss': 0.20793192158537221}
2022-12-31 03:54:08,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:08,247 INFO:     Epoch: 19
2022-12-31 03:54:09,861 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4438641329606374, 'Total loss': 0.4438641329606374} | train loss {'Reaction outcome loss': 0.20381193451368207, 'Total loss': 0.20381193451368207}
2022-12-31 03:54:09,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:09,863 INFO:     Epoch: 20
2022-12-31 03:54:11,481 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4058723161617915, 'Total loss': 0.4058723161617915} | train loss {'Reaction outcome loss': 0.19593998599488166, 'Total loss': 0.19593998599488166}
2022-12-31 03:54:11,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:11,481 INFO:     Epoch: 21
2022-12-31 03:54:13,096 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44570065041383106, 'Total loss': 0.44570065041383106} | train loss {'Reaction outcome loss': 0.1926991287551632, 'Total loss': 0.1926991287551632}
2022-12-31 03:54:13,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:13,096 INFO:     Epoch: 22
2022-12-31 03:54:14,713 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4226696183284124, 'Total loss': 0.4226696183284124} | train loss {'Reaction outcome loss': 0.1864581316413647, 'Total loss': 0.1864581316413647}
2022-12-31 03:54:14,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:14,713 INFO:     Epoch: 23
2022-12-31 03:54:16,328 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4262457032998403, 'Total loss': 0.4262457032998403} | train loss {'Reaction outcome loss': 0.18327033777959942, 'Total loss': 0.18327033777959942}
2022-12-31 03:54:16,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:16,329 INFO:     Epoch: 24
2022-12-31 03:54:17,946 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41265116340170305, 'Total loss': 0.41265116340170305} | train loss {'Reaction outcome loss': 0.18254569462006273, 'Total loss': 0.18254569462006273}
2022-12-31 03:54:17,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:17,946 INFO:     Epoch: 25
2022-12-31 03:54:19,567 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4661052485307058, 'Total loss': 0.4661052485307058} | train loss {'Reaction outcome loss': 0.17362711415205836, 'Total loss': 0.17362711415205836}
2022-12-31 03:54:19,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:19,567 INFO:     Epoch: 26
2022-12-31 03:54:21,187 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4346131458878517, 'Total loss': 0.4346131458878517} | train loss {'Reaction outcome loss': 0.17419562753733744, 'Total loss': 0.17419562753733744}
2022-12-31 03:54:21,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:21,188 INFO:     Epoch: 27
2022-12-31 03:54:22,854 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4375132232904434, 'Total loss': 0.4375132232904434} | train loss {'Reaction outcome loss': 0.17046249681404566, 'Total loss': 0.17046249681404566}
2022-12-31 03:54:22,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:22,854 INFO:     Epoch: 28
2022-12-31 03:54:24,483 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4534370392560959, 'Total loss': 0.4534370392560959} | train loss {'Reaction outcome loss': 0.16833024784680523, 'Total loss': 0.16833024784680523}
2022-12-31 03:54:24,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:24,484 INFO:     Epoch: 29
2022-12-31 03:54:26,150 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43481460387508075, 'Total loss': 0.43481460387508075} | train loss {'Reaction outcome loss': 0.16418000297546925, 'Total loss': 0.16418000297546925}
2022-12-31 03:54:26,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:26,151 INFO:     Epoch: 30
2022-12-31 03:54:27,818 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43775521616141, 'Total loss': 0.43775521616141} | train loss {'Reaction outcome loss': 0.16256035117277814, 'Total loss': 0.16256035117277814}
2022-12-31 03:54:27,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:27,818 INFO:     Epoch: 31
2022-12-31 03:54:29,445 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4550869176785151, 'Total loss': 0.4550869176785151} | train loss {'Reaction outcome loss': 0.16045281577465337, 'Total loss': 0.16045281577465337}
2022-12-31 03:54:29,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:29,446 INFO:     Epoch: 32
2022-12-31 03:54:31,070 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43946211884419123, 'Total loss': 0.43946211884419123} | train loss {'Reaction outcome loss': 0.1595393490779217, 'Total loss': 0.1595393490779217}
2022-12-31 03:54:31,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:31,071 INFO:     Epoch: 33
2022-12-31 03:54:32,705 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45976545810699465, 'Total loss': 0.45976545810699465} | train loss {'Reaction outcome loss': 0.15769645341399668, 'Total loss': 0.15769645341399668}
2022-12-31 03:54:32,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:32,705 INFO:     Epoch: 34
2022-12-31 03:54:34,339 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4575700600941976, 'Total loss': 0.4575700600941976} | train loss {'Reaction outcome loss': 0.15266012496546932, 'Total loss': 0.15266012496546932}
2022-12-31 03:54:34,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:34,339 INFO:     Epoch: 35
2022-12-31 03:54:35,973 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4586215813954671, 'Total loss': 0.4586215813954671} | train loss {'Reaction outcome loss': 0.15354266624211835, 'Total loss': 0.15354266624211835}
2022-12-31 03:54:35,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:35,973 INFO:     Epoch: 36
2022-12-31 03:54:37,607 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43447096248467765, 'Total loss': 0.43447096248467765} | train loss {'Reaction outcome loss': 0.15221257362050755, 'Total loss': 0.15221257362050755}
2022-12-31 03:54:37,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:37,607 INFO:     Epoch: 37
2022-12-31 03:54:39,223 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45929541885852815, 'Total loss': 0.45929541885852815} | train loss {'Reaction outcome loss': 0.1500508750550153, 'Total loss': 0.1500508750550153}
2022-12-31 03:54:39,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:39,223 INFO:     Epoch: 38
2022-12-31 03:54:40,849 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47592613101005554, 'Total loss': 0.47592613101005554} | train loss {'Reaction outcome loss': 0.14924526823825784, 'Total loss': 0.14924526823825784}
2022-12-31 03:54:40,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:40,850 INFO:     Epoch: 39
2022-12-31 03:54:42,476 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4860931381583214, 'Total loss': 0.4860931381583214} | train loss {'Reaction outcome loss': 0.1473575152006229, 'Total loss': 0.1473575152006229}
2022-12-31 03:54:42,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:42,476 INFO:     Epoch: 40
2022-12-31 03:54:44,102 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4614939957857132, 'Total loss': 0.4614939957857132} | train loss {'Reaction outcome loss': 0.14675082078048898, 'Total loss': 0.14675082078048898}
2022-12-31 03:54:44,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:44,102 INFO:     Epoch: 41
2022-12-31 03:54:45,728 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4588326374689738, 'Total loss': 0.4588326374689738} | train loss {'Reaction outcome loss': 0.14217848942483968, 'Total loss': 0.14217848942483968}
2022-12-31 03:54:45,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:45,728 INFO:     Epoch: 42
2022-12-31 03:54:47,353 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4492663005987803, 'Total loss': 0.4492663005987803} | train loss {'Reaction outcome loss': 0.14074761719469803, 'Total loss': 0.14074761719469803}
2022-12-31 03:54:47,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:47,354 INFO:     Epoch: 43
2022-12-31 03:54:48,966 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44226132209102315, 'Total loss': 0.44226132209102315} | train loss {'Reaction outcome loss': 0.13950638933988146, 'Total loss': 0.13950638933988146}
2022-12-31 03:54:48,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:48,966 INFO:     Epoch: 44
2022-12-31 03:54:50,595 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48049782315889994, 'Total loss': 0.48049782315889994} | train loss {'Reaction outcome loss': 0.14270989731666953, 'Total loss': 0.14270989731666953}
2022-12-31 03:54:50,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:50,595 INFO:     Epoch: 45
2022-12-31 03:54:52,222 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47029268741607666, 'Total loss': 0.47029268741607666} | train loss {'Reaction outcome loss': 0.13838098431174184, 'Total loss': 0.13838098431174184}
2022-12-31 03:54:52,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:52,222 INFO:     Epoch: 46
2022-12-31 03:54:53,850 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48463790615399677, 'Total loss': 0.48463790615399677} | train loss {'Reaction outcome loss': 0.13452636284269526, 'Total loss': 0.13452636284269526}
2022-12-31 03:54:53,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:53,850 INFO:     Epoch: 47
2022-12-31 03:54:55,477 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47253051201502483, 'Total loss': 0.47253051201502483} | train loss {'Reaction outcome loss': 0.1384863718227897, 'Total loss': 0.1384863718227897}
2022-12-31 03:54:55,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:55,477 INFO:     Epoch: 48
2022-12-31 03:54:57,093 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49773097137610117, 'Total loss': 0.49773097137610117} | train loss {'Reaction outcome loss': 0.13782035088711267, 'Total loss': 0.13782035088711267}
2022-12-31 03:54:57,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:57,093 INFO:     Epoch: 49
2022-12-31 03:54:58,715 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4808751086393992, 'Total loss': 0.4808751086393992} | train loss {'Reaction outcome loss': 0.1333303036427105, 'Total loss': 0.1333303036427105}
2022-12-31 03:54:58,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:54:58,715 INFO:     Epoch: 50
2022-12-31 03:55:00,338 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4597490817308426, 'Total loss': 0.4597490817308426} | train loss {'Reaction outcome loss': 0.13410754439619366, 'Total loss': 0.13410754439619366}
2022-12-31 03:55:00,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:00,339 INFO:     Epoch: 51
2022-12-31 03:55:01,960 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.468403418858846, 'Total loss': 0.468403418858846} | train loss {'Reaction outcome loss': 0.1361167762825259, 'Total loss': 0.1361167762825259}
2022-12-31 03:55:01,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:01,960 INFO:     Epoch: 52
2022-12-31 03:55:03,580 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4811314145723979, 'Total loss': 0.4811314145723979} | train loss {'Reaction outcome loss': 0.13479069242210193, 'Total loss': 0.13479069242210193}
2022-12-31 03:55:03,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:03,580 INFO:     Epoch: 53
2022-12-31 03:55:05,202 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47437463800112406, 'Total loss': 0.47437463800112406} | train loss {'Reaction outcome loss': 0.1326865054438368, 'Total loss': 0.1326865054438368}
2022-12-31 03:55:05,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:05,203 INFO:     Epoch: 54
2022-12-31 03:55:06,811 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4724243978659312, 'Total loss': 0.4724243978659312} | train loss {'Reaction outcome loss': 0.13090031996154183, 'Total loss': 0.13090031996154183}
2022-12-31 03:55:06,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:06,811 INFO:     Epoch: 55
2022-12-31 03:55:08,436 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45811645686626434, 'Total loss': 0.45811645686626434} | train loss {'Reaction outcome loss': 0.12851440120784277, 'Total loss': 0.12851440120784277}
2022-12-31 03:55:08,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:08,436 INFO:     Epoch: 56
2022-12-31 03:55:10,061 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4624983638525009, 'Total loss': 0.4624983638525009} | train loss {'Reaction outcome loss': 0.1311355216650541, 'Total loss': 0.1311355216650541}
2022-12-31 03:55:10,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:10,061 INFO:     Epoch: 57
2022-12-31 03:55:11,681 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4718018651008606, 'Total loss': 0.4718018651008606} | train loss {'Reaction outcome loss': 0.12744094124769906, 'Total loss': 0.12744094124769906}
2022-12-31 03:55:11,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:11,682 INFO:     Epoch: 58
2022-12-31 03:55:13,299 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4850617488225301, 'Total loss': 0.4850617488225301} | train loss {'Reaction outcome loss': 0.12681141847220084, 'Total loss': 0.12681141847220084}
2022-12-31 03:55:13,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:13,299 INFO:     Epoch: 59
2022-12-31 03:55:14,918 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4810104445243875, 'Total loss': 0.4810104445243875} | train loss {'Reaction outcome loss': 0.13104741197476158, 'Total loss': 0.13104741197476158}
2022-12-31 03:55:14,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:14,919 INFO:     Epoch: 60
2022-12-31 03:55:16,530 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4797140657901764, 'Total loss': 0.4797140657901764} | train loss {'Reaction outcome loss': 0.1257330517953645, 'Total loss': 0.1257330517953645}
2022-12-31 03:55:16,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:16,531 INFO:     Epoch: 61
2022-12-31 03:55:18,147 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.463296032945315, 'Total loss': 0.463296032945315} | train loss {'Reaction outcome loss': 0.1271491245961738, 'Total loss': 0.1271491245961738}
2022-12-31 03:55:18,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:18,148 INFO:     Epoch: 62
2022-12-31 03:55:19,763 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4721822405854861, 'Total loss': 0.4721822405854861} | train loss {'Reaction outcome loss': 0.12480740403817019, 'Total loss': 0.12480740403817019}
2022-12-31 03:55:19,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:19,764 INFO:     Epoch: 63
2022-12-31 03:55:21,381 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48107257386048635, 'Total loss': 0.48107257386048635} | train loss {'Reaction outcome loss': 0.1264609303216144, 'Total loss': 0.1264609303216144}
2022-12-31 03:55:21,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:21,381 INFO:     Epoch: 64
2022-12-31 03:55:22,996 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4738925208648046, 'Total loss': 0.4738925208648046} | train loss {'Reaction outcome loss': 0.1244453942514149, 'Total loss': 0.1244453942514149}
2022-12-31 03:55:22,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:22,996 INFO:     Epoch: 65
2022-12-31 03:55:24,611 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47743064165115356, 'Total loss': 0.47743064165115356} | train loss {'Reaction outcome loss': 0.12261376471934497, 'Total loss': 0.12261376471934497}
2022-12-31 03:55:24,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:24,611 INFO:     Epoch: 66
2022-12-31 03:55:26,278 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4671689361333847, 'Total loss': 0.4671689361333847} | train loss {'Reaction outcome loss': 0.12595922121314151, 'Total loss': 0.12595922121314151}
2022-12-31 03:55:26,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:26,278 INFO:     Epoch: 67
2022-12-31 03:55:27,906 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.467176761229833, 'Total loss': 0.467176761229833} | train loss {'Reaction outcome loss': 0.12432734769960657, 'Total loss': 0.12432734769960657}
2022-12-31 03:55:27,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:27,906 INFO:     Epoch: 68
2022-12-31 03:55:29,574 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4499531010786692, 'Total loss': 0.4499531010786692} | train loss {'Reaction outcome loss': 0.11908200978795705, 'Total loss': 0.11908200978795705}
2022-12-31 03:55:29,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:29,574 INFO:     Epoch: 69
2022-12-31 03:55:31,208 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48727039297421776, 'Total loss': 0.48727039297421776} | train loss {'Reaction outcome loss': 0.11921661072040804, 'Total loss': 0.11921661072040804}
2022-12-31 03:55:31,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:31,208 INFO:     Epoch: 70
2022-12-31 03:55:32,826 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48313963214556377, 'Total loss': 0.48313963214556377} | train loss {'Reaction outcome loss': 0.12143371749790352, 'Total loss': 0.12143371749790352}
2022-12-31 03:55:32,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:32,826 INFO:     Epoch: 71
2022-12-31 03:55:34,447 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46959245403607686, 'Total loss': 0.46959245403607686} | train loss {'Reaction outcome loss': 0.1259455049119634, 'Total loss': 0.1259455049119634}
2022-12-31 03:55:34,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:34,448 INFO:     Epoch: 72
2022-12-31 03:55:36,081 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4811143323779106, 'Total loss': 0.4811143323779106} | train loss {'Reaction outcome loss': 0.11937640357379287, 'Total loss': 0.11937640357379287}
2022-12-31 03:55:36,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:36,081 INFO:     Epoch: 73
2022-12-31 03:55:37,715 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46793546676635744, 'Total loss': 0.46793546676635744} | train loss {'Reaction outcome loss': 0.11764646408615452, 'Total loss': 0.11764646408615452}
2022-12-31 03:55:37,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:37,715 INFO:     Epoch: 74
2022-12-31 03:55:39,348 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46888937552769977, 'Total loss': 0.46888937552769977} | train loss {'Reaction outcome loss': 0.11774810196391378, 'Total loss': 0.11774810196391378}
2022-12-31 03:55:39,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:39,348 INFO:     Epoch: 75
2022-12-31 03:55:40,979 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4645711193482081, 'Total loss': 0.4645711193482081} | train loss {'Reaction outcome loss': 0.12007193048467812, 'Total loss': 0.12007193048467812}
2022-12-31 03:55:40,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:40,979 INFO:     Epoch: 76
2022-12-31 03:55:42,599 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46762027939160666, 'Total loss': 0.46762027939160666} | train loss {'Reaction outcome loss': 0.12137798794851191, 'Total loss': 0.12137798794851191}
2022-12-31 03:55:42,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:42,600 INFO:     Epoch: 77
2022-12-31 03:55:44,219 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46378197222948075, 'Total loss': 0.46378197222948075} | train loss {'Reaction outcome loss': 0.1184541258733175, 'Total loss': 0.1184541258733175}
2022-12-31 03:55:44,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:44,220 INFO:     Epoch: 78
2022-12-31 03:55:45,886 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5063374837239584, 'Total loss': 0.5063374837239584} | train loss {'Reaction outcome loss': 0.11580497698206119, 'Total loss': 0.11580497698206119}
2022-12-31 03:55:45,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:45,887 INFO:     Epoch: 79
2022-12-31 03:55:47,508 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47095597883065543, 'Total loss': 0.47095597883065543} | train loss {'Reaction outcome loss': 0.12500371228288254, 'Total loss': 0.12500371228288254}
2022-12-31 03:55:47,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:47,509 INFO:     Epoch: 80
2022-12-31 03:55:49,176 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47463445564111073, 'Total loss': 0.47463445564111073} | train loss {'Reaction outcome loss': 0.11530698918559276, 'Total loss': 0.11530698918559276}
2022-12-31 03:55:49,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:49,177 INFO:     Epoch: 81
2022-12-31 03:55:50,797 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4794932007789612, 'Total loss': 0.4794932007789612} | train loss {'Reaction outcome loss': 0.11457347981917541, 'Total loss': 0.11457347981917541}
2022-12-31 03:55:50,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:50,798 INFO:     Epoch: 82
2022-12-31 03:55:52,424 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47396986981232964, 'Total loss': 0.47396986981232964} | train loss {'Reaction outcome loss': 0.11225776730058211, 'Total loss': 0.11225776730058211}
2022-12-31 03:55:52,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:52,424 INFO:     Epoch: 83
2022-12-31 03:55:54,091 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45925716161727903, 'Total loss': 0.45925716161727903} | train loss {'Reaction outcome loss': 0.11685274393778523, 'Total loss': 0.11685274393778523}
2022-12-31 03:55:54,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:54,091 INFO:     Epoch: 84
2022-12-31 03:55:55,711 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46575217247009276, 'Total loss': 0.46575217247009276} | train loss {'Reaction outcome loss': 0.11491797471650966, 'Total loss': 0.11491797471650966}
2022-12-31 03:55:55,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:55,712 INFO:     Epoch: 85
2022-12-31 03:55:57,379 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46118534306685127, 'Total loss': 0.46118534306685127} | train loss {'Reaction outcome loss': 0.11457333439584512, 'Total loss': 0.11457333439584512}
2022-12-31 03:55:57,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:57,379 INFO:     Epoch: 86
2022-12-31 03:55:59,000 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44655071993668877, 'Total loss': 0.44655071993668877} | train loss {'Reaction outcome loss': 0.11839966999454296, 'Total loss': 0.11839966999454296}
2022-12-31 03:55:59,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:55:59,001 INFO:     Epoch: 87
2022-12-31 03:56:00,638 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.507471094528834, 'Total loss': 0.507471094528834} | train loss {'Reaction outcome loss': 0.11609855330791258, 'Total loss': 0.11609855330791258}
2022-12-31 03:56:00,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:00,638 INFO:     Epoch: 88
2022-12-31 03:56:02,268 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5032247881094615, 'Total loss': 0.5032247881094615} | train loss {'Reaction outcome loss': 0.11675130665329174, 'Total loss': 0.11675130665329174}
2022-12-31 03:56:02,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:02,269 INFO:     Epoch: 89
2022-12-31 03:56:03,899 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4788014113903046, 'Total loss': 0.4788014113903046} | train loss {'Reaction outcome loss': 0.11481002965330109, 'Total loss': 0.11481002965330109}
2022-12-31 03:56:03,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:03,899 INFO:     Epoch: 90
2022-12-31 03:56:05,529 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48147289752960204, 'Total loss': 0.48147289752960204} | train loss {'Reaction outcome loss': 0.11487124659564844, 'Total loss': 0.11487124659564844}
2022-12-31 03:56:05,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:05,529 INFO:     Epoch: 91
2022-12-31 03:56:07,159 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4808952311674754, 'Total loss': 0.4808952311674754} | train loss {'Reaction outcome loss': 0.11864879100570044, 'Total loss': 0.11864879100570044}
2022-12-31 03:56:07,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:07,160 INFO:     Epoch: 92
2022-12-31 03:56:08,789 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4801615337530772, 'Total loss': 0.4801615337530772} | train loss {'Reaction outcome loss': 0.1163060712520477, 'Total loss': 0.1163060712520477}
2022-12-31 03:56:08,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:08,789 INFO:     Epoch: 93
2022-12-31 03:56:10,422 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49638448705275856, 'Total loss': 0.49638448705275856} | train loss {'Reaction outcome loss': 0.11056171818796061, 'Total loss': 0.11056171818796061}
2022-12-31 03:56:10,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:10,422 INFO:     Epoch: 94
2022-12-31 03:56:12,048 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47781339585781096, 'Total loss': 0.47781339585781096} | train loss {'Reaction outcome loss': 0.10847325282447066, 'Total loss': 0.10847325282447066}
2022-12-31 03:56:12,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:12,048 INFO:     Epoch: 95
2022-12-31 03:56:13,678 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5050176203250885, 'Total loss': 0.5050176203250885} | train loss {'Reaction outcome loss': 0.11276853543333037, 'Total loss': 0.11276853543333037}
2022-12-31 03:56:13,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:13,680 INFO:     Epoch: 96
2022-12-31 03:56:15,299 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4810758978128433, 'Total loss': 0.4810758978128433} | train loss {'Reaction outcome loss': 0.1159505149860621, 'Total loss': 0.1159505149860621}
2022-12-31 03:56:15,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:15,300 INFO:     Epoch: 97
2022-12-31 03:56:16,918 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47984952926635743, 'Total loss': 0.47984952926635743} | train loss {'Reaction outcome loss': 0.11246867715515572, 'Total loss': 0.11246867715515572}
2022-12-31 03:56:16,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:16,918 INFO:     Epoch: 98
2022-12-31 03:56:18,529 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4791295349597931, 'Total loss': 0.4791295349597931} | train loss {'Reaction outcome loss': 0.11318425505358175, 'Total loss': 0.11318425505358175}
2022-12-31 03:56:18,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:18,529 INFO:     Epoch: 99
2022-12-31 03:56:20,183 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43719128966331483, 'Total loss': 0.43719128966331483} | train loss {'Reaction outcome loss': 0.11194188137696753, 'Total loss': 0.11194188137696753}
2022-12-31 03:56:20,184 INFO:     Best model found after epoch 13 of 100.
2022-12-31 03:56:20,184 INFO:   Done with stage: TRAINING
2022-12-31 03:56:20,184 INFO:   Starting stage: EVALUATION
2022-12-31 03:56:20,310 INFO:   Done with stage: EVALUATION
2022-12-31 03:56:20,310 INFO:   Leaving out SEQ value Fold_7
2022-12-31 03:56:20,323 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 03:56:20,323 INFO:   Starting stage: FEATURE SCALING
2022-12-31 03:56:20,970 INFO:   Done with stage: FEATURE SCALING
2022-12-31 03:56:20,970 INFO:   Starting stage: SCALING TARGETS
2022-12-31 03:56:21,044 INFO:   Done with stage: SCALING TARGETS
2022-12-31 03:56:21,044 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:56:21,044 INFO:     No hyperparam tuning for this model
2022-12-31 03:56:21,044 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:56:21,044 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 03:56:21,045 INFO:     None feature selector for col prot
2022-12-31 03:56:21,045 INFO:     None feature selector for col prot
2022-12-31 03:56:21,045 INFO:     None feature selector for col prot
2022-12-31 03:56:21,045 INFO:     None feature selector for col chem
2022-12-31 03:56:21,046 INFO:     None feature selector for col chem
2022-12-31 03:56:21,046 INFO:     None feature selector for col chem
2022-12-31 03:56:21,046 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 03:56:21,046 INFO:   Starting stage: BUILD MODEL
2022-12-31 03:56:21,048 INFO:     Number of params in model 224011
2022-12-31 03:56:21,051 INFO:   Done with stage: BUILD MODEL
2022-12-31 03:56:21,051 INFO:   Starting stage: TRAINING
2022-12-31 03:56:21,095 INFO:     Val loss before train {'Reaction outcome loss': 1.0484355648358663, 'Total loss': 1.0484355648358663}
2022-12-31 03:56:21,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:21,096 INFO:     Epoch: 0
2022-12-31 03:56:22,699 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5313222408294678, 'Total loss': 0.5313222408294678} | train loss {'Reaction outcome loss': 0.7760022723109182, 'Total loss': 0.7760022723109182}
2022-12-31 03:56:22,699 INFO:     Found new best model at epoch 0
2022-12-31 03:56:22,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:22,700 INFO:     Epoch: 1
2022-12-31 03:56:24,303 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4323106348514557, 'Total loss': 0.4323106348514557} | train loss {'Reaction outcome loss': 0.5054878729538326, 'Total loss': 0.5054878729538326}
2022-12-31 03:56:24,303 INFO:     Found new best model at epoch 1
2022-12-31 03:56:24,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:24,304 INFO:     Epoch: 2
2022-12-31 03:56:25,907 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4295665840307871, 'Total loss': 0.4295665840307871} | train loss {'Reaction outcome loss': 0.44176245622173715, 'Total loss': 0.44176245622173715}
2022-12-31 03:56:25,907 INFO:     Found new best model at epoch 2
2022-12-31 03:56:25,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:25,908 INFO:     Epoch: 3
2022-12-31 03:56:27,503 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.39348670095205307, 'Total loss': 0.39348670095205307} | train loss {'Reaction outcome loss': 0.40410274715863004, 'Total loss': 0.40410274715863004}
2022-12-31 03:56:27,504 INFO:     Found new best model at epoch 3
2022-12-31 03:56:27,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:27,505 INFO:     Epoch: 4
2022-12-31 03:56:29,108 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.39469437996546425, 'Total loss': 0.39469437996546425} | train loss {'Reaction outcome loss': 0.37767456267980765, 'Total loss': 0.37767456267980765}
2022-12-31 03:56:29,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:29,109 INFO:     Epoch: 5
2022-12-31 03:56:30,758 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4159858971834183, 'Total loss': 0.4159858971834183} | train loss {'Reaction outcome loss': 0.3583741833313103, 'Total loss': 0.3583741833313103}
2022-12-31 03:56:30,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:30,758 INFO:     Epoch: 6
2022-12-31 03:56:32,407 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3866284896930059, 'Total loss': 0.3866284896930059} | train loss {'Reaction outcome loss': 0.34196969551326584, 'Total loss': 0.34196969551326584}
2022-12-31 03:56:32,408 INFO:     Found new best model at epoch 6
2022-12-31 03:56:32,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:32,409 INFO:     Epoch: 7
2022-12-31 03:56:34,058 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40499280095100404, 'Total loss': 0.40499280095100404} | train loss {'Reaction outcome loss': 0.31837870683656994, 'Total loss': 0.31837870683656994}
2022-12-31 03:56:34,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:34,058 INFO:     Epoch: 8
2022-12-31 03:56:35,659 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.39875228703022003, 'Total loss': 0.39875228703022003} | train loss {'Reaction outcome loss': 0.3024012757070961, 'Total loss': 0.3024012757070961}
2022-12-31 03:56:35,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:35,659 INFO:     Epoch: 9
2022-12-31 03:56:37,279 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4094349612792333, 'Total loss': 0.4094349612792333} | train loss {'Reaction outcome loss': 0.2942790326451624, 'Total loss': 0.2942790326451624}
2022-12-31 03:56:37,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:37,279 INFO:     Epoch: 10
2022-12-31 03:56:38,928 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.37818792710701626, 'Total loss': 0.37818792710701626} | train loss {'Reaction outcome loss': 0.28201443462693776, 'Total loss': 0.28201443462693776}
2022-12-31 03:56:38,928 INFO:     Found new best model at epoch 10
2022-12-31 03:56:38,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:38,929 INFO:     Epoch: 11
2022-12-31 03:56:40,533 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4307633916536967, 'Total loss': 0.4307633916536967} | train loss {'Reaction outcome loss': 0.26954935870412056, 'Total loss': 0.26954935870412056}
2022-12-31 03:56:40,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:40,534 INFO:     Epoch: 12
2022-12-31 03:56:42,185 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3738624463478724, 'Total loss': 0.3738624463478724} | train loss {'Reaction outcome loss': 0.2557387475440972, 'Total loss': 0.2557387475440972}
2022-12-31 03:56:42,185 INFO:     Found new best model at epoch 12
2022-12-31 03:56:42,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:42,186 INFO:     Epoch: 13
2022-12-31 03:56:43,798 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4361898809671402, 'Total loss': 0.4361898809671402} | train loss {'Reaction outcome loss': 0.24502392517008487, 'Total loss': 0.24502392517008487}
2022-12-31 03:56:43,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:43,798 INFO:     Epoch: 14
2022-12-31 03:56:45,410 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3923788120349248, 'Total loss': 0.3923788120349248} | train loss {'Reaction outcome loss': 0.23657815080190445, 'Total loss': 0.23657815080190445}
2022-12-31 03:56:45,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:45,410 INFO:     Epoch: 15
2022-12-31 03:56:47,047 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.38062052528063456, 'Total loss': 0.38062052528063456} | train loss {'Reaction outcome loss': 0.23333100697202405, 'Total loss': 0.23333100697202405}
2022-12-31 03:56:47,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:47,048 INFO:     Epoch: 16
2022-12-31 03:56:48,695 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3912643939256668, 'Total loss': 0.3912643939256668} | train loss {'Reaction outcome loss': 0.22263527809078024, 'Total loss': 0.22263527809078024}
2022-12-31 03:56:48,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:48,697 INFO:     Epoch: 17
2022-12-31 03:56:50,295 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3891987909873327, 'Total loss': 0.3891987909873327} | train loss {'Reaction outcome loss': 0.21199695693913603, 'Total loss': 0.21199695693913603}
2022-12-31 03:56:50,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:50,295 INFO:     Epoch: 18
2022-12-31 03:56:51,896 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3683403953909874, 'Total loss': 0.3683403953909874} | train loss {'Reaction outcome loss': 0.20708519335237952, 'Total loss': 0.20708519335237952}
2022-12-31 03:56:51,896 INFO:     Found new best model at epoch 18
2022-12-31 03:56:51,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:51,897 INFO:     Epoch: 19
2022-12-31 03:56:53,498 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41042582392692567, 'Total loss': 0.41042582392692567} | train loss {'Reaction outcome loss': 0.20312954087055077, 'Total loss': 0.20312954087055077}
2022-12-31 03:56:53,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:53,498 INFO:     Epoch: 20
2022-12-31 03:56:55,109 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38129156033198036, 'Total loss': 0.38129156033198036} | train loss {'Reaction outcome loss': 0.20004034270770357, 'Total loss': 0.20004034270770357}
2022-12-31 03:56:55,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:55,110 INFO:     Epoch: 21
2022-12-31 03:56:56,740 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3895316446820895, 'Total loss': 0.3895316446820895} | train loss {'Reaction outcome loss': 0.19437488860171967, 'Total loss': 0.19437488860171967}
2022-12-31 03:56:56,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:56,740 INFO:     Epoch: 22
2022-12-31 03:56:58,340 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4080501283208529, 'Total loss': 0.4080501283208529} | train loss {'Reaction outcome loss': 0.18982645534114898, 'Total loss': 0.18982645534114898}
2022-12-31 03:56:58,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:58,340 INFO:     Epoch: 23
2022-12-31 03:56:59,938 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41442335546016695, 'Total loss': 0.41442335546016695} | train loss {'Reaction outcome loss': 0.18502315288803872, 'Total loss': 0.18502315288803872}
2022-12-31 03:56:59,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:56:59,938 INFO:     Epoch: 24
2022-12-31 03:57:01,536 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4242291991909345, 'Total loss': 0.4242291991909345} | train loss {'Reaction outcome loss': 0.18296923966276168, 'Total loss': 0.18296923966276168}
2022-12-31 03:57:01,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:01,536 INFO:     Epoch: 25
2022-12-31 03:57:03,186 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40610509912172954, 'Total loss': 0.40610509912172954} | train loss {'Reaction outcome loss': 0.17998910464523157, 'Total loss': 0.17998910464523157}
2022-12-31 03:57:03,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:03,186 INFO:     Epoch: 26
2022-12-31 03:57:04,782 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4222591896851858, 'Total loss': 0.4222591896851858} | train loss {'Reaction outcome loss': 0.177324195616763, 'Total loss': 0.177324195616763}
2022-12-31 03:57:04,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:04,782 INFO:     Epoch: 27
2022-12-31 03:57:06,395 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4004610965649287, 'Total loss': 0.4004610965649287} | train loss {'Reaction outcome loss': 0.169700960173224, 'Total loss': 0.169700960173224}
2022-12-31 03:57:06,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:06,395 INFO:     Epoch: 28
2022-12-31 03:57:08,010 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3874697506427765, 'Total loss': 0.3874697506427765} | train loss {'Reaction outcome loss': 0.16995190440874247, 'Total loss': 0.16995190440874247}
2022-12-31 03:57:08,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:08,011 INFO:     Epoch: 29
2022-12-31 03:57:09,624 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39429382185141243, 'Total loss': 0.39429382185141243} | train loss {'Reaction outcome loss': 0.16700034802031777, 'Total loss': 0.16700034802031777}
2022-12-31 03:57:09,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:09,625 INFO:     Epoch: 30
2022-12-31 03:57:11,238 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4121157666047414, 'Total loss': 0.4121157666047414} | train loss {'Reaction outcome loss': 0.16309009849290995, 'Total loss': 0.16309009849290995}
2022-12-31 03:57:11,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:11,238 INFO:     Epoch: 31
2022-12-31 03:57:12,834 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4259560619791349, 'Total loss': 0.4259560619791349} | train loss {'Reaction outcome loss': 0.15929447212698358, 'Total loss': 0.15929447212698358}
2022-12-31 03:57:12,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:12,834 INFO:     Epoch: 32
2022-12-31 03:57:14,479 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4233395293354988, 'Total loss': 0.4233395293354988} | train loss {'Reaction outcome loss': 0.1591342924244321, 'Total loss': 0.1591342924244321}
2022-12-31 03:57:14,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:14,479 INFO:     Epoch: 33
2022-12-31 03:57:16,078 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4255290538072586, 'Total loss': 0.4255290538072586} | train loss {'Reaction outcome loss': 0.16203961072720752, 'Total loss': 0.16203961072720752}
2022-12-31 03:57:16,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:16,078 INFO:     Epoch: 34
2022-12-31 03:57:17,689 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40068399012088773, 'Total loss': 0.40068399012088773} | train loss {'Reaction outcome loss': 0.1557419705680524, 'Total loss': 0.1557419705680524}
2022-12-31 03:57:17,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:17,689 INFO:     Epoch: 35
2022-12-31 03:57:19,339 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4038995772600174, 'Total loss': 0.4038995772600174} | train loss {'Reaction outcome loss': 0.15116673024765548, 'Total loss': 0.15116673024765548}
2022-12-31 03:57:19,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:19,340 INFO:     Epoch: 36
2022-12-31 03:57:20,949 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3968043675025304, 'Total loss': 0.3968043675025304} | train loss {'Reaction outcome loss': 0.15021705611466166, 'Total loss': 0.15021705611466166}
2022-12-31 03:57:20,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:20,949 INFO:     Epoch: 37
2022-12-31 03:57:22,568 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3873190189401309, 'Total loss': 0.3873190189401309} | train loss {'Reaction outcome loss': 0.15222759111818387, 'Total loss': 0.15222759111818387}
2022-12-31 03:57:22,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:22,569 INFO:     Epoch: 38
2022-12-31 03:57:24,179 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3936455170313517, 'Total loss': 0.3936455170313517} | train loss {'Reaction outcome loss': 0.14731567967207218, 'Total loss': 0.14731567967207218}
2022-12-31 03:57:24,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:24,179 INFO:     Epoch: 39
2022-12-31 03:57:25,829 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.37648536066214244, 'Total loss': 0.37648536066214244} | train loss {'Reaction outcome loss': 0.14602514020894675, 'Total loss': 0.14602514020894675}
2022-12-31 03:57:25,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:25,830 INFO:     Epoch: 40
2022-12-31 03:57:27,459 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4181139558553696, 'Total loss': 0.4181139558553696} | train loss {'Reaction outcome loss': 0.14216578025778714, 'Total loss': 0.14216578025778714}
2022-12-31 03:57:27,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:27,459 INFO:     Epoch: 41
2022-12-31 03:57:29,109 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4091408014297485, 'Total loss': 0.4091408014297485} | train loss {'Reaction outcome loss': 0.14481768259833003, 'Total loss': 0.14481768259833003}
2022-12-31 03:57:29,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:29,109 INFO:     Epoch: 42
2022-12-31 03:57:30,717 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.389102574189504, 'Total loss': 0.389102574189504} | train loss {'Reaction outcome loss': 0.1450292724184692, 'Total loss': 0.1450292724184692}
2022-12-31 03:57:30,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:30,717 INFO:     Epoch: 43
2022-12-31 03:57:32,311 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4354368289311727, 'Total loss': 0.4354368289311727} | train loss {'Reaction outcome loss': 0.14261316611383953, 'Total loss': 0.14261316611383953}
2022-12-31 03:57:32,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:32,311 INFO:     Epoch: 44
2022-12-31 03:57:33,925 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39445816179116566, 'Total loss': 0.39445816179116566} | train loss {'Reaction outcome loss': 0.13912646627108002, 'Total loss': 0.13912646627108002}
2022-12-31 03:57:33,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:33,925 INFO:     Epoch: 45
2022-12-31 03:57:35,542 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.37950137853622434, 'Total loss': 0.37950137853622434} | train loss {'Reaction outcome loss': 0.14017133421883204, 'Total loss': 0.14017133421883204}
2022-12-31 03:57:35,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:35,542 INFO:     Epoch: 46
2022-12-31 03:57:37,155 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.407292377948761, 'Total loss': 0.407292377948761} | train loss {'Reaction outcome loss': 0.13521813293986948, 'Total loss': 0.13521813293986948}
2022-12-31 03:57:37,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:37,155 INFO:     Epoch: 47
2022-12-31 03:57:38,770 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3612748650213083, 'Total loss': 0.3612748650213083} | train loss {'Reaction outcome loss': 0.13723580185391934, 'Total loss': 0.13723580185391934}
2022-12-31 03:57:38,770 INFO:     Found new best model at epoch 47
2022-12-31 03:57:38,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:38,771 INFO:     Epoch: 48
2022-12-31 03:57:40,359 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4078718473513921, 'Total loss': 0.4078718473513921} | train loss {'Reaction outcome loss': 0.1342256268431997, 'Total loss': 0.1342256268431997}
2022-12-31 03:57:40,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:40,359 INFO:     Epoch: 49
2022-12-31 03:57:41,974 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3946392764647802, 'Total loss': 0.3946392764647802} | train loss {'Reaction outcome loss': 0.13429631116752425, 'Total loss': 0.13429631116752425}
2022-12-31 03:57:41,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:41,974 INFO:     Epoch: 50
2022-12-31 03:57:43,588 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38108353813489276, 'Total loss': 0.38108353813489276} | train loss {'Reaction outcome loss': 0.13201734118153388, 'Total loss': 0.13201734118153388}
2022-12-31 03:57:43,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:43,588 INFO:     Epoch: 51
2022-12-31 03:57:45,202 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3698791593313217, 'Total loss': 0.3698791593313217} | train loss {'Reaction outcome loss': 0.13069977712253258, 'Total loss': 0.13069977712253258}
2022-12-31 03:57:45,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:45,202 INFO:     Epoch: 52
2022-12-31 03:57:46,813 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3760380268096924, 'Total loss': 0.3760380268096924} | train loss {'Reaction outcome loss': 0.1307645067232695, 'Total loss': 0.1307645067232695}
2022-12-31 03:57:46,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:46,813 INFO:     Epoch: 53
2022-12-31 03:57:48,428 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4012663558125496, 'Total loss': 0.4012663558125496} | train loss {'Reaction outcome loss': 0.13102742674400228, 'Total loss': 0.13102742674400228}
2022-12-31 03:57:48,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:48,428 INFO:     Epoch: 54
2022-12-31 03:57:50,031 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3900561292966207, 'Total loss': 0.3900561292966207} | train loss {'Reaction outcome loss': 0.1310412204334934, 'Total loss': 0.1310412204334934}
2022-12-31 03:57:50,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:50,032 INFO:     Epoch: 55
2022-12-31 03:57:51,646 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4051140323281288, 'Total loss': 0.4051140323281288} | train loss {'Reaction outcome loss': 0.12371086501890291, 'Total loss': 0.12371086501890291}
2022-12-31 03:57:51,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:51,646 INFO:     Epoch: 56
2022-12-31 03:57:53,298 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38585250576337177, 'Total loss': 0.38585250576337177} | train loss {'Reaction outcome loss': 0.12737531838666674, 'Total loss': 0.12737531838666674}
2022-12-31 03:57:53,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:53,298 INFO:     Epoch: 57
2022-12-31 03:57:54,948 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4245945145686468, 'Total loss': 0.4245945145686468} | train loss {'Reaction outcome loss': 0.1254684124422348, 'Total loss': 0.1254684124422348}
2022-12-31 03:57:54,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:54,948 INFO:     Epoch: 58
2022-12-31 03:57:56,552 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3850995237628619, 'Total loss': 0.3850995237628619} | train loss {'Reaction outcome loss': 0.1259122731905077, 'Total loss': 0.1259122731905077}
2022-12-31 03:57:56,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:56,553 INFO:     Epoch: 59
2022-12-31 03:57:58,155 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4401930054028829, 'Total loss': 0.4401930054028829} | train loss {'Reaction outcome loss': 0.12230117966074251, 'Total loss': 0.12230117966074251}
2022-12-31 03:57:58,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:58,155 INFO:     Epoch: 60
2022-12-31 03:57:59,731 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4048873245716095, 'Total loss': 0.4048873245716095} | train loss {'Reaction outcome loss': 0.1271331077186649, 'Total loss': 0.1271331077186649}
2022-12-31 03:57:59,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:57:59,731 INFO:     Epoch: 61
2022-12-31 03:58:01,340 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4096305454770724, 'Total loss': 0.4096305454770724} | train loss {'Reaction outcome loss': 0.12390154050017306, 'Total loss': 0.12390154050017306}
2022-12-31 03:58:01,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:01,340 INFO:     Epoch: 62
2022-12-31 03:58:02,950 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37173913220564525, 'Total loss': 0.37173913220564525} | train loss {'Reaction outcome loss': 0.12398070326911109, 'Total loss': 0.12398070326911109}
2022-12-31 03:58:02,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:02,950 INFO:     Epoch: 63
2022-12-31 03:58:04,557 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39119912981987, 'Total loss': 0.39119912981987} | train loss {'Reaction outcome loss': 0.12108633207347598, 'Total loss': 0.12108633207347598}
2022-12-31 03:58:04,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:04,557 INFO:     Epoch: 64
2022-12-31 03:58:06,230 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3742712845404943, 'Total loss': 0.3742712845404943} | train loss {'Reaction outcome loss': 0.12418000289769232, 'Total loss': 0.12418000289769232}
2022-12-31 03:58:06,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:06,230 INFO:     Epoch: 65
2022-12-31 03:58:07,847 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40272728403409325, 'Total loss': 0.40272728403409325} | train loss {'Reaction outcome loss': 0.12178842993079256, 'Total loss': 0.12178842993079256}
2022-12-31 03:58:07,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:07,848 INFO:     Epoch: 66
2022-12-31 03:58:09,498 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.38361509268482524, 'Total loss': 0.38361509268482524} | train loss {'Reaction outcome loss': 0.12029893020419472, 'Total loss': 0.12029893020419472}
2022-12-31 03:58:09,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:09,499 INFO:     Epoch: 67
2022-12-31 03:58:11,102 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4147752419114113, 'Total loss': 0.4147752419114113} | train loss {'Reaction outcome loss': 0.11860712013465699, 'Total loss': 0.11860712013465699}
2022-12-31 03:58:11,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:11,102 INFO:     Epoch: 68
2022-12-31 03:58:12,706 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3694525554776192, 'Total loss': 0.3694525554776192} | train loss {'Reaction outcome loss': 0.11894633161434293, 'Total loss': 0.11894633161434293}
2022-12-31 03:58:12,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:12,706 INFO:     Epoch: 69
2022-12-31 03:58:14,356 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4242029796044032, 'Total loss': 0.4242029796044032} | train loss {'Reaction outcome loss': 0.11582061190865119, 'Total loss': 0.11582061190865119}
2022-12-31 03:58:14,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:14,356 INFO:     Epoch: 70
2022-12-31 03:58:15,963 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41505766411622363, 'Total loss': 0.41505766411622363} | train loss {'Reaction outcome loss': 0.11866062787364842, 'Total loss': 0.11866062787364842}
2022-12-31 03:58:15,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:15,963 INFO:     Epoch: 71
2022-12-31 03:58:17,527 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3916294927398364, 'Total loss': 0.3916294927398364} | train loss {'Reaction outcome loss': 0.12029010505095994, 'Total loss': 0.12029010505095994}
2022-12-31 03:58:17,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:17,527 INFO:     Epoch: 72
2022-12-31 03:58:19,134 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38307472268740334, 'Total loss': 0.38307472268740334} | train loss {'Reaction outcome loss': 0.11184292016414939, 'Total loss': 0.11184292016414939}
2022-12-31 03:58:19,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:19,134 INFO:     Epoch: 73
2022-12-31 03:58:20,741 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4086019456386566, 'Total loss': 0.4086019456386566} | train loss {'Reaction outcome loss': 0.1219957729165925, 'Total loss': 0.1219957729165925}
2022-12-31 03:58:20,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:20,742 INFO:     Epoch: 74
2022-12-31 03:58:22,349 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3769415895144145, 'Total loss': 0.3769415895144145} | train loss {'Reaction outcome loss': 0.11605045736859124, 'Total loss': 0.11605045736859124}
2022-12-31 03:58:22,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:22,349 INFO:     Epoch: 75
2022-12-31 03:58:23,955 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3947628120581309, 'Total loss': 0.3947628120581309} | train loss {'Reaction outcome loss': 0.11311023645646816, 'Total loss': 0.11311023645646816}
2022-12-31 03:58:23,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:23,955 INFO:     Epoch: 76
2022-12-31 03:58:25,603 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3651641460135579, 'Total loss': 0.3651641460135579} | train loss {'Reaction outcome loss': 0.11315717452450445, 'Total loss': 0.11315717452450445}
2022-12-31 03:58:25,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:25,604 INFO:     Epoch: 77
2022-12-31 03:58:27,178 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40473972658316293, 'Total loss': 0.40473972658316293} | train loss {'Reaction outcome loss': 0.11372163308356094, 'Total loss': 0.11372163308356094}
2022-12-31 03:58:27,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:27,179 INFO:     Epoch: 78
2022-12-31 03:58:28,787 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38985486775636674, 'Total loss': 0.38985486775636674} | train loss {'Reaction outcome loss': 0.11547844250428144, 'Total loss': 0.11547844250428144}
2022-12-31 03:58:28,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:28,787 INFO:     Epoch: 79
2022-12-31 03:58:30,438 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3683603892723719, 'Total loss': 0.3683603892723719} | train loss {'Reaction outcome loss': 0.11347580210129003, 'Total loss': 0.11347580210129003}
2022-12-31 03:58:30,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:30,438 INFO:     Epoch: 80
2022-12-31 03:58:32,090 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3869677369793256, 'Total loss': 0.3869677369793256} | train loss {'Reaction outcome loss': 0.11669396135503983, 'Total loss': 0.11669396135503983}
2022-12-31 03:58:32,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:32,090 INFO:     Epoch: 81
2022-12-31 03:58:33,697 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3626178851040701, 'Total loss': 0.3626178851040701} | train loss {'Reaction outcome loss': 0.11273105064726496, 'Total loss': 0.11273105064726496}
2022-12-31 03:58:33,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:33,697 INFO:     Epoch: 82
2022-12-31 03:58:35,291 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3966525043050448, 'Total loss': 0.3966525043050448} | train loss {'Reaction outcome loss': 0.11259515946017185, 'Total loss': 0.11259515946017185}
2022-12-31 03:58:35,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:35,292 INFO:     Epoch: 83
2022-12-31 03:58:36,942 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4011835537850857, 'Total loss': 0.4011835537850857} | train loss {'Reaction outcome loss': 0.11351835761341626, 'Total loss': 0.11351835761341626}
2022-12-31 03:58:36,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:36,942 INFO:     Epoch: 84
2022-12-31 03:58:38,546 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4000445673863093, 'Total loss': 0.4000445673863093} | train loss {'Reaction outcome loss': 0.10994587579646903, 'Total loss': 0.10994587579646903}
2022-12-31 03:58:38,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:38,546 INFO:     Epoch: 85
2022-12-31 03:58:40,198 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39579377075036365, 'Total loss': 0.39579377075036365} | train loss {'Reaction outcome loss': 0.10850463989003813, 'Total loss': 0.10850463989003813}
2022-12-31 03:58:40,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:40,198 INFO:     Epoch: 86
2022-12-31 03:58:41,808 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3975834200779597, 'Total loss': 0.3975834200779597} | train loss {'Reaction outcome loss': 0.10950364227012398, 'Total loss': 0.10950364227012398}
2022-12-31 03:58:41,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:41,808 INFO:     Epoch: 87
2022-12-31 03:58:43,460 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4072682981689771, 'Total loss': 0.4072682981689771} | train loss {'Reaction outcome loss': 0.10605750234124597, 'Total loss': 0.10605750234124597}
2022-12-31 03:58:43,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:43,460 INFO:     Epoch: 88
2022-12-31 03:58:45,055 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3897142271200816, 'Total loss': 0.3897142271200816} | train loss {'Reaction outcome loss': 0.110684444801542, 'Total loss': 0.110684444801542}
2022-12-31 03:58:45,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:45,055 INFO:     Epoch: 89
2022-12-31 03:58:46,706 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41419628461201985, 'Total loss': 0.41419628461201985} | train loss {'Reaction outcome loss': 0.1155232406802557, 'Total loss': 0.1155232406802557}
2022-12-31 03:58:46,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:46,707 INFO:     Epoch: 90
2022-12-31 03:58:48,357 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38762611051400503, 'Total loss': 0.38762611051400503} | train loss {'Reaction outcome loss': 0.11171685367394375, 'Total loss': 0.11171685367394375}
2022-12-31 03:58:48,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:48,357 INFO:     Epoch: 91
2022-12-31 03:58:49,969 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4212994863589605, 'Total loss': 0.4212994863589605} | train loss {'Reaction outcome loss': 0.10731480252099679, 'Total loss': 0.10731480252099679}
2022-12-31 03:58:49,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:49,969 INFO:     Epoch: 92
2022-12-31 03:58:51,620 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4053734133640925, 'Total loss': 0.4053734133640925} | train loss {'Reaction outcome loss': 0.11806075254040532, 'Total loss': 0.11806075254040532}
2022-12-31 03:58:51,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:51,621 INFO:     Epoch: 93
2022-12-31 03:58:53,228 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4027422418196996, 'Total loss': 0.4027422418196996} | train loss {'Reaction outcome loss': 0.1066902240136652, 'Total loss': 0.1066902240136652}
2022-12-31 03:58:53,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:53,229 INFO:     Epoch: 94
2022-12-31 03:58:54,808 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3838203544418017, 'Total loss': 0.3838203544418017} | train loss {'Reaction outcome loss': 0.1104560135693772, 'Total loss': 0.1104560135693772}
2022-12-31 03:58:54,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:54,809 INFO:     Epoch: 95
2022-12-31 03:58:56,422 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4311029940843582, 'Total loss': 0.4311029940843582} | train loss {'Reaction outcome loss': 0.10860920588513089, 'Total loss': 0.10860920588513089}
2022-12-31 03:58:56,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:56,422 INFO:     Epoch: 96
2022-12-31 03:58:58,035 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41149593591690065, 'Total loss': 0.41149593591690065} | train loss {'Reaction outcome loss': 0.1114130283750077, 'Total loss': 0.1114130283750077}
2022-12-31 03:58:58,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:58,036 INFO:     Epoch: 97
2022-12-31 03:58:59,650 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38975595037142435, 'Total loss': 0.38975595037142435} | train loss {'Reaction outcome loss': 0.10342355895903044, 'Total loss': 0.10342355895903044}
2022-12-31 03:58:59,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:58:59,650 INFO:     Epoch: 98
2022-12-31 03:59:01,263 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3951241354147593, 'Total loss': 0.3951241354147593} | train loss {'Reaction outcome loss': 0.10566552421613426, 'Total loss': 0.10566552421613426}
2022-12-31 03:59:01,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:01,263 INFO:     Epoch: 99
2022-12-31 03:59:02,823 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4002102958659331, 'Total loss': 0.4002102958659331} | train loss {'Reaction outcome loss': 0.10770140825362917, 'Total loss': 0.10770140825362917}
2022-12-31 03:59:02,823 INFO:     Best model found after epoch 48 of 100.
2022-12-31 03:59:02,823 INFO:   Done with stage: TRAINING
2022-12-31 03:59:02,824 INFO:   Starting stage: EVALUATION
2022-12-31 03:59:02,961 INFO:   Done with stage: EVALUATION
2022-12-31 03:59:02,961 INFO:   Leaving out SEQ value Fold_8
2022-12-31 03:59:02,973 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 03:59:02,973 INFO:   Starting stage: FEATURE SCALING
2022-12-31 03:59:03,645 INFO:   Done with stage: FEATURE SCALING
2022-12-31 03:59:03,645 INFO:   Starting stage: SCALING TARGETS
2022-12-31 03:59:03,717 INFO:   Done with stage: SCALING TARGETS
2022-12-31 03:59:03,717 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:59:03,718 INFO:     No hyperparam tuning for this model
2022-12-31 03:59:03,718 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 03:59:03,718 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 03:59:03,718 INFO:     None feature selector for col prot
2022-12-31 03:59:03,719 INFO:     None feature selector for col prot
2022-12-31 03:59:03,719 INFO:     None feature selector for col prot
2022-12-31 03:59:03,719 INFO:     None feature selector for col chem
2022-12-31 03:59:03,719 INFO:     None feature selector for col chem
2022-12-31 03:59:03,719 INFO:     None feature selector for col chem
2022-12-31 03:59:03,719 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 03:59:03,719 INFO:   Starting stage: BUILD MODEL
2022-12-31 03:59:03,721 INFO:     Number of params in model 224011
2022-12-31 03:59:03,725 INFO:   Done with stage: BUILD MODEL
2022-12-31 03:59:03,725 INFO:   Starting stage: TRAINING
2022-12-31 03:59:03,769 INFO:     Val loss before train {'Reaction outcome loss': 0.9371834794680277, 'Total loss': 0.9371834794680277}
2022-12-31 03:59:03,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:03,769 INFO:     Epoch: 0
2022-12-31 03:59:05,385 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.48408741553624474, 'Total loss': 0.48408741553624474} | train loss {'Reaction outcome loss': 0.7747307869501493, 'Total loss': 0.7747307869501493}
2022-12-31 03:59:05,386 INFO:     Found new best model at epoch 0
2022-12-31 03:59:05,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:05,387 INFO:     Epoch: 1
2022-12-31 03:59:07,004 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4217004716396332, 'Total loss': 0.4217004716396332} | train loss {'Reaction outcome loss': 0.5138214869081759, 'Total loss': 0.5138214869081759}
2022-12-31 03:59:07,004 INFO:     Found new best model at epoch 1
2022-12-31 03:59:07,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:07,005 INFO:     Epoch: 2
2022-12-31 03:59:08,622 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.41280112266540525, 'Total loss': 0.41280112266540525} | train loss {'Reaction outcome loss': 0.4460319946066137, 'Total loss': 0.4460319946066137}
2022-12-31 03:59:08,622 INFO:     Found new best model at epoch 2
2022-12-31 03:59:08,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:08,623 INFO:     Epoch: 3
2022-12-31 03:59:10,239 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.397603964805603, 'Total loss': 0.397603964805603} | train loss {'Reaction outcome loss': 0.4026104171461147, 'Total loss': 0.4026104171461147}
2022-12-31 03:59:10,240 INFO:     Found new best model at epoch 3
2022-12-31 03:59:10,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:10,241 INFO:     Epoch: 4
2022-12-31 03:59:11,802 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.38864277104536693, 'Total loss': 0.38864277104536693} | train loss {'Reaction outcome loss': 0.37841941956901376, 'Total loss': 0.37841941956901376}
2022-12-31 03:59:11,802 INFO:     Found new best model at epoch 4
2022-12-31 03:59:11,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:11,803 INFO:     Epoch: 5
2022-12-31 03:59:13,431 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.38500955800215403, 'Total loss': 0.38500955800215403} | train loss {'Reaction outcome loss': 0.35573768126189925, 'Total loss': 0.35573768126189925}
2022-12-31 03:59:13,431 INFO:     Found new best model at epoch 5
2022-12-31 03:59:13,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:13,432 INFO:     Epoch: 6
2022-12-31 03:59:15,060 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3824045399824778, 'Total loss': 0.3824045399824778} | train loss {'Reaction outcome loss': 0.33409617671790104, 'Total loss': 0.33409617671790104}
2022-12-31 03:59:15,060 INFO:     Found new best model at epoch 6
2022-12-31 03:59:15,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:15,061 INFO:     Epoch: 7
2022-12-31 03:59:16,682 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3865498264630636, 'Total loss': 0.3865498264630636} | train loss {'Reaction outcome loss': 0.3171696593776507, 'Total loss': 0.3171696593776507}
2022-12-31 03:59:16,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:16,683 INFO:     Epoch: 8
2022-12-31 03:59:18,350 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3705817838509878, 'Total loss': 0.3705817838509878} | train loss {'Reaction outcome loss': 0.3004074952286073, 'Total loss': 0.3004074952286073}
2022-12-31 03:59:18,351 INFO:     Found new best model at epoch 8
2022-12-31 03:59:18,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:18,352 INFO:     Epoch: 9
2022-12-31 03:59:19,973 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.37669069866339366, 'Total loss': 0.37669069866339366} | train loss {'Reaction outcome loss': 0.28684511283136876, 'Total loss': 0.28684511283136876}
2022-12-31 03:59:19,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:19,974 INFO:     Epoch: 10
2022-12-31 03:59:21,572 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40331639846165973, 'Total loss': 0.40331639846165973} | train loss {'Reaction outcome loss': 0.27435702144669283, 'Total loss': 0.27435702144669283}
2022-12-31 03:59:21,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:21,572 INFO:     Epoch: 11
2022-12-31 03:59:23,192 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39040957887967426, 'Total loss': 0.39040957887967426} | train loss {'Reaction outcome loss': 0.26431610014303064, 'Total loss': 0.26431610014303064}
2022-12-31 03:59:23,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:23,193 INFO:     Epoch: 12
2022-12-31 03:59:24,812 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3755088210105896, 'Total loss': 0.3755088210105896} | train loss {'Reaction outcome loss': 0.2568691513275842, 'Total loss': 0.2568691513275842}
2022-12-31 03:59:24,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:24,812 INFO:     Epoch: 13
2022-12-31 03:59:26,474 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.36752082804838815, 'Total loss': 0.36752082804838815} | train loss {'Reaction outcome loss': 0.2415742524681001, 'Total loss': 0.2415742524681001}
2022-12-31 03:59:26,474 INFO:     Found new best model at epoch 13
2022-12-31 03:59:26,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:26,475 INFO:     Epoch: 14
2022-12-31 03:59:28,103 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3542322511474291, 'Total loss': 0.3542322511474291} | train loss {'Reaction outcome loss': 0.2379631135303406, 'Total loss': 0.2379631135303406}
2022-12-31 03:59:28,103 INFO:     Found new best model at epoch 14
2022-12-31 03:59:28,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:28,104 INFO:     Epoch: 15
2022-12-31 03:59:29,660 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.37701501200596493, 'Total loss': 0.37701501200596493} | train loss {'Reaction outcome loss': 0.2269463182463973, 'Total loss': 0.2269463182463973}
2022-12-31 03:59:29,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:29,661 INFO:     Epoch: 16
2022-12-31 03:59:31,291 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3792839705944061, 'Total loss': 0.3792839705944061} | train loss {'Reaction outcome loss': 0.22400235244836186, 'Total loss': 0.22400235244836186}
2022-12-31 03:59:31,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:31,291 INFO:     Epoch: 17
2022-12-31 03:59:32,959 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.36920217076937356, 'Total loss': 0.36920217076937356} | train loss {'Reaction outcome loss': 0.21244744697605875, 'Total loss': 0.21244744697605875}
2022-12-31 03:59:32,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:32,959 INFO:     Epoch: 18
2022-12-31 03:59:34,588 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.37979086513320603, 'Total loss': 0.37979086513320603} | train loss {'Reaction outcome loss': 0.21095925295180792, 'Total loss': 0.21095925295180792}
2022-12-31 03:59:34,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:34,588 INFO:     Epoch: 19
2022-12-31 03:59:36,257 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38258948028087614, 'Total loss': 0.38258948028087614} | train loss {'Reaction outcome loss': 0.20154082865222267, 'Total loss': 0.20154082865222267}
2022-12-31 03:59:36,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:36,257 INFO:     Epoch: 20
2022-12-31 03:59:37,882 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3769313211242358, 'Total loss': 0.3769313211242358} | train loss {'Reaction outcome loss': 0.19615224159796746, 'Total loss': 0.19615224159796746}
2022-12-31 03:59:37,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:37,882 INFO:     Epoch: 21
2022-12-31 03:59:39,452 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39174824158350624, 'Total loss': 0.39174824158350624} | train loss {'Reaction outcome loss': 0.1952990947042454, 'Total loss': 0.1952990947042454}
2022-12-31 03:59:39,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:39,452 INFO:     Epoch: 22
2022-12-31 03:59:41,089 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39599024256070453, 'Total loss': 0.39599024256070453} | train loss {'Reaction outcome loss': 0.19433568372300386, 'Total loss': 0.19433568372300386}
2022-12-31 03:59:41,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:41,089 INFO:     Epoch: 23
2022-12-31 03:59:42,723 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4091283102830251, 'Total loss': 0.4091283102830251} | train loss {'Reaction outcome loss': 0.1862064536512974, 'Total loss': 0.1862064536512974}
2022-12-31 03:59:42,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:42,724 INFO:     Epoch: 24
2022-12-31 03:59:44,334 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40210358798503876, 'Total loss': 0.40210358798503876} | train loss {'Reaction outcome loss': 0.18186273694119084, 'Total loss': 0.18186273694119084}
2022-12-31 03:59:44,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:44,334 INFO:     Epoch: 25
2022-12-31 03:59:46,002 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4004968762397766, 'Total loss': 0.4004968762397766} | train loss {'Reaction outcome loss': 0.18139358815679912, 'Total loss': 0.18139358815679912}
2022-12-31 03:59:46,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:46,002 INFO:     Epoch: 26
2022-12-31 03:59:47,571 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3888881276051203, 'Total loss': 0.3888881276051203} | train loss {'Reaction outcome loss': 0.1759429416595706, 'Total loss': 0.1759429416595706}
2022-12-31 03:59:47,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:47,571 INFO:     Epoch: 27
2022-12-31 03:59:48,702 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4065027077992757, 'Total loss': 0.4065027077992757} | train loss {'Reaction outcome loss': 0.17083943972451485, 'Total loss': 0.17083943972451485}
2022-12-31 03:59:48,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:48,702 INFO:     Epoch: 28
2022-12-31 03:59:49,825 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4178858687480291, 'Total loss': 0.4178858687480291} | train loss {'Reaction outcome loss': 0.1716899022540676, 'Total loss': 0.1716899022540676}
2022-12-31 03:59:49,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:49,825 INFO:     Epoch: 29
2022-12-31 03:59:50,951 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3842185487349828, 'Total loss': 0.3842185487349828} | train loss {'Reaction outcome loss': 0.16852153492721625, 'Total loss': 0.16852153492721625}
2022-12-31 03:59:50,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:50,951 INFO:     Epoch: 30
2022-12-31 03:59:52,073 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38298895955085754, 'Total loss': 0.38298895955085754} | train loss {'Reaction outcome loss': 0.16503704751132306, 'Total loss': 0.16503704751132306}
2022-12-31 03:59:52,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:52,073 INFO:     Epoch: 31
2022-12-31 03:59:53,667 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3808790385723114, 'Total loss': 0.3808790385723114} | train loss {'Reaction outcome loss': 0.1654720309287955, 'Total loss': 0.1654720309287955}
2022-12-31 03:59:53,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:53,667 INFO:     Epoch: 32
2022-12-31 03:59:55,282 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3952254762252172, 'Total loss': 0.3952254762252172} | train loss {'Reaction outcome loss': 0.16316533782637077, 'Total loss': 0.16316533782637077}
2022-12-31 03:59:55,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:55,282 INFO:     Epoch: 33
2022-12-31 03:59:56,946 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.36643940520783264, 'Total loss': 0.36643940520783264} | train loss {'Reaction outcome loss': 0.16103347396942036, 'Total loss': 0.16103347396942036}
2022-12-31 03:59:56,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:56,946 INFO:     Epoch: 34
2022-12-31 03:59:58,612 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39198827048142754, 'Total loss': 0.39198827048142754} | train loss {'Reaction outcome loss': 0.15493137995957898, 'Total loss': 0.15493137995957898}
2022-12-31 03:59:58,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 03:59:58,613 INFO:     Epoch: 35
2022-12-31 04:00:00,231 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4262975792090098, 'Total loss': 0.4262975792090098} | train loss {'Reaction outcome loss': 0.15543604773445735, 'Total loss': 0.15543604773445735}
2022-12-31 04:00:00,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:00,231 INFO:     Epoch: 36
2022-12-31 04:00:01,867 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3847214718659719, 'Total loss': 0.3847214718659719} | train loss {'Reaction outcome loss': 0.15396176834022526, 'Total loss': 0.15396176834022526}
2022-12-31 04:00:01,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:01,867 INFO:     Epoch: 37
2022-12-31 04:00:03,502 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4323273708422979, 'Total loss': 0.4323273708422979} | train loss {'Reaction outcome loss': 0.14816432038409508, 'Total loss': 0.14816432038409508}
2022-12-31 04:00:03,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:03,502 INFO:     Epoch: 38
2022-12-31 04:00:05,128 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41603428274393084, 'Total loss': 0.41603428274393084} | train loss {'Reaction outcome loss': 0.15360459921350333, 'Total loss': 0.15360459921350333}
2022-12-31 04:00:05,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:05,129 INFO:     Epoch: 39
2022-12-31 04:00:06,765 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39451153874397277, 'Total loss': 0.39451153874397277} | train loss {'Reaction outcome loss': 0.14836602298280607, 'Total loss': 0.14836602298280607}
2022-12-31 04:00:06,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:06,765 INFO:     Epoch: 40
2022-12-31 04:00:08,427 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38724664797385533, 'Total loss': 0.38724664797385533} | train loss {'Reaction outcome loss': 0.14360595918142838, 'Total loss': 0.14360595918142838}
2022-12-31 04:00:08,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:08,427 INFO:     Epoch: 41
2022-12-31 04:00:10,040 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41461448272069296, 'Total loss': 0.41461448272069296} | train loss {'Reaction outcome loss': 0.14355522475208723, 'Total loss': 0.14355522475208723}
2022-12-31 04:00:10,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:10,040 INFO:     Epoch: 42
2022-12-31 04:00:11,662 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3945727402965228, 'Total loss': 0.3945727402965228} | train loss {'Reaction outcome loss': 0.14054160499239227, 'Total loss': 0.14054160499239227}
2022-12-31 04:00:11,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:11,663 INFO:     Epoch: 43
2022-12-31 04:00:13,297 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3919671893119812, 'Total loss': 0.3919671893119812} | train loss {'Reaction outcome loss': 0.1399123940401667, 'Total loss': 0.1399123940401667}
2022-12-31 04:00:13,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:13,297 INFO:     Epoch: 44
2022-12-31 04:00:14,919 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4061839361985525, 'Total loss': 0.4061839361985525} | train loss {'Reaction outcome loss': 0.14366791175429572, 'Total loss': 0.14366791175429572}
2022-12-31 04:00:14,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:14,919 INFO:     Epoch: 45
2022-12-31 04:00:16,540 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3886493548750877, 'Total loss': 0.3886493548750877} | train loss {'Reaction outcome loss': 0.13739563449074108, 'Total loss': 0.13739563449074108}
2022-12-31 04:00:16,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:16,540 INFO:     Epoch: 46
2022-12-31 04:00:18,207 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.372066722313563, 'Total loss': 0.372066722313563} | train loss {'Reaction outcome loss': 0.14224240843825284, 'Total loss': 0.14224240843825284}
2022-12-31 04:00:18,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:18,208 INFO:     Epoch: 47
2022-12-31 04:00:19,826 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3879657842218876, 'Total loss': 0.3879657842218876} | train loss {'Reaction outcome loss': 0.13814176639562156, 'Total loss': 0.13814176639562156}
2022-12-31 04:00:19,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:19,826 INFO:     Epoch: 48
2022-12-31 04:00:21,492 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3953939124941826, 'Total loss': 0.3953939124941826} | train loss {'Reaction outcome loss': 0.13701829534622467, 'Total loss': 0.13701829534622467}
2022-12-31 04:00:21,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:21,492 INFO:     Epoch: 49
2022-12-31 04:00:23,120 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38221986095110577, 'Total loss': 0.38221986095110577} | train loss {'Reaction outcome loss': 0.13614368783343678, 'Total loss': 0.13614368783343678}
2022-12-31 04:00:23,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:23,121 INFO:     Epoch: 50
2022-12-31 04:00:24,754 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39266653135418894, 'Total loss': 0.39266653135418894} | train loss {'Reaction outcome loss': 0.1354165048765469, 'Total loss': 0.1354165048765469}
2022-12-31 04:00:24,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:24,755 INFO:     Epoch: 51
2022-12-31 04:00:26,388 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3863016943136851, 'Total loss': 0.3863016943136851} | train loss {'Reaction outcome loss': 0.13600404649999814, 'Total loss': 0.13600404649999814}
2022-12-31 04:00:26,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:26,389 INFO:     Epoch: 52
2022-12-31 04:00:28,022 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4077026456594467, 'Total loss': 0.4077026456594467} | train loss {'Reaction outcome loss': 0.13523908445295552, 'Total loss': 0.13523908445295552}
2022-12-31 04:00:28,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:28,022 INFO:     Epoch: 53
2022-12-31 04:00:29,663 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3889024376869202, 'Total loss': 0.3889024376869202} | train loss {'Reaction outcome loss': 0.1331903036861993, 'Total loss': 0.1331903036861993}
2022-12-31 04:00:29,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:29,664 INFO:     Epoch: 54
2022-12-31 04:00:31,278 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3939633756875992, 'Total loss': 0.3939633756875992} | train loss {'Reaction outcome loss': 0.1320893933092133, 'Total loss': 0.1320893933092133}
2022-12-31 04:00:31,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:31,278 INFO:     Epoch: 55
2022-12-31 04:00:32,896 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3941336846599976, 'Total loss': 0.3941336846599976} | train loss {'Reaction outcome loss': 0.13058877513417805, 'Total loss': 0.13058877513417805}
2022-12-31 04:00:32,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:32,896 INFO:     Epoch: 56
2022-12-31 04:00:34,511 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41005204419294994, 'Total loss': 0.41005204419294994} | train loss {'Reaction outcome loss': 0.1290294493410723, 'Total loss': 0.1290294493410723}
2022-12-31 04:00:34,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:34,511 INFO:     Epoch: 57
2022-12-31 04:00:36,176 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3949952637155851, 'Total loss': 0.3949952637155851} | train loss {'Reaction outcome loss': 0.13099057887368146, 'Total loss': 0.13099057887368146}
2022-12-31 04:00:36,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:36,177 INFO:     Epoch: 58
2022-12-31 04:00:37,853 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.421535354355971, 'Total loss': 0.421535354355971} | train loss {'Reaction outcome loss': 0.12857855148008263, 'Total loss': 0.12857855148008263}
2022-12-31 04:00:37,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:37,853 INFO:     Epoch: 59
2022-12-31 04:00:39,486 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38882776846488315, 'Total loss': 0.38882776846488315} | train loss {'Reaction outcome loss': 0.12417055017799004, 'Total loss': 0.12417055017799004}
2022-12-31 04:00:39,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:39,486 INFO:     Epoch: 60
2022-12-31 04:00:41,112 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4190323626001676, 'Total loss': 0.4190323626001676} | train loss {'Reaction outcome loss': 0.1268493501815797, 'Total loss': 0.1268493501815797}
2022-12-31 04:00:41,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:41,113 INFO:     Epoch: 61
2022-12-31 04:00:42,746 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3697381834189097, 'Total loss': 0.3697381834189097} | train loss {'Reaction outcome loss': 0.12449112794082948, 'Total loss': 0.12449112794082948}
2022-12-31 04:00:42,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:42,746 INFO:     Epoch: 62
2022-12-31 04:00:44,379 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3923105170329412, 'Total loss': 0.3923105170329412} | train loss {'Reaction outcome loss': 0.1273556540246098, 'Total loss': 0.1273556540246098}
2022-12-31 04:00:44,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:44,379 INFO:     Epoch: 63
2022-12-31 04:00:46,011 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41419502794742585, 'Total loss': 0.41419502794742585} | train loss {'Reaction outcome loss': 0.12473413789987779, 'Total loss': 0.12473413789987779}
2022-12-31 04:00:46,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:46,011 INFO:     Epoch: 64
2022-12-31 04:00:47,638 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3864691232641538, 'Total loss': 0.3864691232641538} | train loss {'Reaction outcome loss': 0.12427563485201946, 'Total loss': 0.12427563485201946}
2022-12-31 04:00:47,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:47,638 INFO:     Epoch: 65
2022-12-31 04:00:49,263 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40548297862211863, 'Total loss': 0.40548297862211863} | train loss {'Reaction outcome loss': 0.13039744159522793, 'Total loss': 0.13039744159522793}
2022-12-31 04:00:49,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:49,264 INFO:     Epoch: 66
2022-12-31 04:00:50,930 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37637313405672707, 'Total loss': 0.37637313405672707} | train loss {'Reaction outcome loss': 0.12496300961734855, 'Total loss': 0.12496300961734855}
2022-12-31 04:00:50,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:50,931 INFO:     Epoch: 67
2022-12-31 04:00:52,598 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3878963823119799, 'Total loss': 0.3878963823119799} | train loss {'Reaction outcome loss': 0.12470230529932069, 'Total loss': 0.12470230529932069}
2022-12-31 04:00:52,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:52,598 INFO:     Epoch: 68
2022-12-31 04:00:54,220 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41382528046766914, 'Total loss': 0.41382528046766914} | train loss {'Reaction outcome loss': 0.129311105004421, 'Total loss': 0.129311105004421}
2022-12-31 04:00:54,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:54,220 INFO:     Epoch: 69
2022-12-31 04:00:55,887 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41315695295731225, 'Total loss': 0.41315695295731225} | train loss {'Reaction outcome loss': 0.12118318773022708, 'Total loss': 0.12118318773022708}
2022-12-31 04:00:55,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:55,888 INFO:     Epoch: 70
2022-12-31 04:00:57,503 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40415036529302595, 'Total loss': 0.40415036529302595} | train loss {'Reaction outcome loss': 0.12393167750432496, 'Total loss': 0.12393167750432496}
2022-12-31 04:00:57,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:57,503 INFO:     Epoch: 71
2022-12-31 04:00:59,143 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39576771383484205, 'Total loss': 0.39576771383484205} | train loss {'Reaction outcome loss': 0.12587464522126565, 'Total loss': 0.12587464522126565}
2022-12-31 04:00:59,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:00:59,143 INFO:     Epoch: 72
2022-12-31 04:01:00,777 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3994078516960144, 'Total loss': 0.3994078516960144} | train loss {'Reaction outcome loss': 0.11956380056015582, 'Total loss': 0.11956380056015582}
2022-12-31 04:01:00,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:00,777 INFO:     Epoch: 73
2022-12-31 04:01:02,411 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39669878681500753, 'Total loss': 0.39669878681500753} | train loss {'Reaction outcome loss': 0.1224113235414862, 'Total loss': 0.1224113235414862}
2022-12-31 04:01:02,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:02,412 INFO:     Epoch: 74
2022-12-31 04:01:04,046 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.415251412242651, 'Total loss': 0.415251412242651} | train loss {'Reaction outcome loss': 0.12252717025221631, 'Total loss': 0.12252717025221631}
2022-12-31 04:01:04,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:04,046 INFO:     Epoch: 75
2022-12-31 04:01:05,673 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4160702909032504, 'Total loss': 0.4160702909032504} | train loss {'Reaction outcome loss': 0.12197949272657775, 'Total loss': 0.12197949272657775}
2022-12-31 04:01:05,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:05,674 INFO:     Epoch: 76
2022-12-31 04:01:07,305 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39081655542055765, 'Total loss': 0.39081655542055765} | train loss {'Reaction outcome loss': 0.12013209684640976, 'Total loss': 0.12013209684640976}
2022-12-31 04:01:07,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:07,305 INFO:     Epoch: 77
2022-12-31 04:01:08,929 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4217602610588074, 'Total loss': 0.4217602610588074} | train loss {'Reaction outcome loss': 0.1171600130489197, 'Total loss': 0.1171600130489197}
2022-12-31 04:01:08,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:08,929 INFO:     Epoch: 78
2022-12-31 04:01:10,546 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4305764575799306, 'Total loss': 0.4305764575799306} | train loss {'Reaction outcome loss': 0.11824004984517929, 'Total loss': 0.11824004984517929}
2022-12-31 04:01:10,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:10,546 INFO:     Epoch: 79
2022-12-31 04:01:12,163 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.37788468301296235, 'Total loss': 0.37788468301296235} | train loss {'Reaction outcome loss': 0.11841011005672307, 'Total loss': 0.11841011005672307}
2022-12-31 04:01:12,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:12,164 INFO:     Epoch: 80
2022-12-31 04:01:13,779 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4146347383658091, 'Total loss': 0.4146347383658091} | train loss {'Reaction outcome loss': 0.12020619764977844, 'Total loss': 0.12020619764977844}
2022-12-31 04:01:13,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:13,779 INFO:     Epoch: 81
2022-12-31 04:01:15,399 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3910161554813385, 'Total loss': 0.3910161554813385} | train loss {'Reaction outcome loss': 0.12178942680674931, 'Total loss': 0.12178942680674931}
2022-12-31 04:01:15,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:15,399 INFO:     Epoch: 82
2022-12-31 04:01:17,040 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4006150374809901, 'Total loss': 0.4006150374809901} | train loss {'Reaction outcome loss': 0.11924845870880121, 'Total loss': 0.11924845870880121}
2022-12-31 04:01:17,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:17,040 INFO:     Epoch: 83
2022-12-31 04:01:18,656 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39992204134662945, 'Total loss': 0.39992204134662945} | train loss {'Reaction outcome loss': 0.1161366937133998, 'Total loss': 0.1161366937133998}
2022-12-31 04:01:18,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:18,657 INFO:     Epoch: 84
2022-12-31 04:01:20,273 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4423805236816406, 'Total loss': 0.4423805236816406} | train loss {'Reaction outcome loss': 0.11891017193546256, 'Total loss': 0.11891017193546256}
2022-12-31 04:01:20,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:20,273 INFO:     Epoch: 85
2022-12-31 04:01:21,939 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41452099978923795, 'Total loss': 0.41452099978923795} | train loss {'Reaction outcome loss': 0.119261089993123, 'Total loss': 0.119261089993123}
2022-12-31 04:01:21,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:21,939 INFO:     Epoch: 86
2022-12-31 04:01:23,560 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40560434957345326, 'Total loss': 0.40560434957345326} | train loss {'Reaction outcome loss': 0.11717130891501312, 'Total loss': 0.11717130891501312}
2022-12-31 04:01:23,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:23,560 INFO:     Epoch: 87
2022-12-31 04:01:25,226 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42627508540948233, 'Total loss': 0.42627508540948233} | train loss {'Reaction outcome loss': 0.11847628819813368, 'Total loss': 0.11847628819813368}
2022-12-31 04:01:25,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:25,227 INFO:     Epoch: 88
2022-12-31 04:01:26,836 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41927715241909025, 'Total loss': 0.41927715241909025} | train loss {'Reaction outcome loss': 0.11902601188569857, 'Total loss': 0.11902601188569857}
2022-12-31 04:01:26,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:26,837 INFO:     Epoch: 89
2022-12-31 04:01:28,455 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43873336911201477, 'Total loss': 0.43873336911201477} | train loss {'Reaction outcome loss': 0.11513598395733411, 'Total loss': 0.11513598395733411}
2022-12-31 04:01:28,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:28,455 INFO:     Epoch: 90
2022-12-31 04:01:30,121 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41128650059302646, 'Total loss': 0.41128650059302646} | train loss {'Reaction outcome loss': 0.11598896547405567, 'Total loss': 0.11598896547405567}
2022-12-31 04:01:30,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:30,121 INFO:     Epoch: 91
2022-12-31 04:01:31,746 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4211360873654485, 'Total loss': 0.4211360873654485} | train loss {'Reaction outcome loss': 0.12257790139166887, 'Total loss': 0.12257790139166887}
2022-12-31 04:01:31,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:31,746 INFO:     Epoch: 92
2022-12-31 04:01:33,360 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4205162430802981, 'Total loss': 0.4205162430802981} | train loss {'Reaction outcome loss': 0.11745398889618526, 'Total loss': 0.11745398889618526}
2022-12-31 04:01:33,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:33,360 INFO:     Epoch: 93
2022-12-31 04:01:34,982 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41698920329411826, 'Total loss': 0.41698920329411826} | train loss {'Reaction outcome loss': 0.11609086177113469, 'Total loss': 0.11609086177113469}
2022-12-31 04:01:34,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:34,982 INFO:     Epoch: 94
2022-12-31 04:01:36,618 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4229408750931422, 'Total loss': 0.4229408750931422} | train loss {'Reaction outcome loss': 0.11739230853596211, 'Total loss': 0.11739230853596211}
2022-12-31 04:01:36,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:36,619 INFO:     Epoch: 95
2022-12-31 04:01:38,258 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4246147284905116, 'Total loss': 0.4246147284905116} | train loss {'Reaction outcome loss': 0.11949183954605126, 'Total loss': 0.11949183954605126}
2022-12-31 04:01:38,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:38,258 INFO:     Epoch: 96
2022-12-31 04:01:39,891 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4015788368880749, 'Total loss': 0.4015788368880749} | train loss {'Reaction outcome loss': 0.11523981913688865, 'Total loss': 0.11523981913688865}
2022-12-31 04:01:39,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:39,891 INFO:     Epoch: 97
2022-12-31 04:01:41,519 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41953018109003704, 'Total loss': 0.41953018109003704} | train loss {'Reaction outcome loss': 0.11652155469813878, 'Total loss': 0.11652155469813878}
2022-12-31 04:01:41,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:41,520 INFO:     Epoch: 98
2022-12-31 04:01:43,181 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39465026259422303, 'Total loss': 0.39465026259422303} | train loss {'Reaction outcome loss': 0.11426254933605824, 'Total loss': 0.11426254933605824}
2022-12-31 04:01:43,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:43,181 INFO:     Epoch: 99
2022-12-31 04:01:44,836 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42949866155783334, 'Total loss': 0.42949866155783334} | train loss {'Reaction outcome loss': 0.11541126217249283, 'Total loss': 0.11541126217249283}
2022-12-31 04:01:44,837 INFO:     Best model found after epoch 15 of 100.
2022-12-31 04:01:44,837 INFO:   Done with stage: TRAINING
2022-12-31 04:01:44,837 INFO:   Starting stage: EVALUATION
2022-12-31 04:01:44,963 INFO:   Done with stage: EVALUATION
2022-12-31 04:01:44,963 INFO:   Leaving out SEQ value Fold_9
2022-12-31 04:01:44,975 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 04:01:44,976 INFO:   Starting stage: FEATURE SCALING
2022-12-31 04:01:45,626 INFO:   Done with stage: FEATURE SCALING
2022-12-31 04:01:45,626 INFO:   Starting stage: SCALING TARGETS
2022-12-31 04:01:45,698 INFO:   Done with stage: SCALING TARGETS
2022-12-31 04:01:45,698 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:01:45,698 INFO:     No hyperparam tuning for this model
2022-12-31 04:01:45,698 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:01:45,698 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 04:01:45,699 INFO:     None feature selector for col prot
2022-12-31 04:01:45,699 INFO:     None feature selector for col prot
2022-12-31 04:01:45,699 INFO:     None feature selector for col prot
2022-12-31 04:01:45,700 INFO:     None feature selector for col chem
2022-12-31 04:01:45,700 INFO:     None feature selector for col chem
2022-12-31 04:01:45,700 INFO:     None feature selector for col chem
2022-12-31 04:01:45,700 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 04:01:45,700 INFO:   Starting stage: BUILD MODEL
2022-12-31 04:01:45,702 INFO:     Number of params in model 224011
2022-12-31 04:01:45,705 INFO:   Done with stage: BUILD MODEL
2022-12-31 04:01:45,705 INFO:   Starting stage: TRAINING
2022-12-31 04:01:45,749 INFO:     Val loss before train {'Reaction outcome loss': 0.9780218203862509, 'Total loss': 0.9780218203862509}
2022-12-31 04:01:45,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:45,750 INFO:     Epoch: 0
2022-12-31 04:01:47,363 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5672511696815491, 'Total loss': 0.5672511696815491} | train loss {'Reaction outcome loss': 0.7684460170567036, 'Total loss': 0.7684460170567036}
2022-12-31 04:01:47,364 INFO:     Found new best model at epoch 0
2022-12-31 04:01:47,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:47,365 INFO:     Epoch: 1
2022-12-31 04:01:48,978 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4868515650431315, 'Total loss': 0.4868515650431315} | train loss {'Reaction outcome loss': 0.5079419232526983, 'Total loss': 0.5079419232526983}
2022-12-31 04:01:48,979 INFO:     Found new best model at epoch 1
2022-12-31 04:01:48,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:48,980 INFO:     Epoch: 2
2022-12-31 04:01:50,599 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.51845916112264, 'Total loss': 0.51845916112264} | train loss {'Reaction outcome loss': 0.4471856563527515, 'Total loss': 0.4471856563527515}
2022-12-31 04:01:50,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:50,599 INFO:     Epoch: 3
2022-12-31 04:01:52,215 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.481055760383606, 'Total loss': 0.481055760383606} | train loss {'Reaction outcome loss': 0.40846439098801796, 'Total loss': 0.40846439098801796}
2022-12-31 04:01:52,215 INFO:     Found new best model at epoch 3
2022-12-31 04:01:52,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:52,216 INFO:     Epoch: 4
2022-12-31 04:01:53,862 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4379931817452113, 'Total loss': 0.4379931817452113} | train loss {'Reaction outcome loss': 0.3733061149226479, 'Total loss': 0.3733061149226479}
2022-12-31 04:01:53,862 INFO:     Found new best model at epoch 4
2022-12-31 04:01:53,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:53,863 INFO:     Epoch: 5
2022-12-31 04:01:55,478 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4630865971247355, 'Total loss': 0.4630865971247355} | train loss {'Reaction outcome loss': 0.35060390673469805, 'Total loss': 0.35060390673469805}
2022-12-31 04:01:55,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:55,479 INFO:     Epoch: 6
2022-12-31 04:01:57,094 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43550338546435036, 'Total loss': 0.43550338546435036} | train loss {'Reaction outcome loss': 0.3285149367276471, 'Total loss': 0.3285149367276471}
2022-12-31 04:01:57,094 INFO:     Found new best model at epoch 6
2022-12-31 04:01:57,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:57,095 INFO:     Epoch: 7
2022-12-31 04:01:58,711 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4392503996690114, 'Total loss': 0.4392503996690114} | train loss {'Reaction outcome loss': 0.3167643723671959, 'Total loss': 0.3167643723671959}
2022-12-31 04:01:58,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:01:58,711 INFO:     Epoch: 8
2022-12-31 04:02:00,329 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4626572638750076, 'Total loss': 0.4626572638750076} | train loss {'Reaction outcome loss': 0.3055155558808558, 'Total loss': 0.3055155558808558}
2022-12-31 04:02:00,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:00,329 INFO:     Epoch: 9
2022-12-31 04:02:01,973 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4852133055528005, 'Total loss': 0.4852133055528005} | train loss {'Reaction outcome loss': 0.2933634023614012, 'Total loss': 0.2933634023614012}
2022-12-31 04:02:01,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:01,974 INFO:     Epoch: 10
2022-12-31 04:02:03,591 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47792042096455895, 'Total loss': 0.47792042096455895} | train loss {'Reaction outcome loss': 0.27471034238249925, 'Total loss': 0.27471034238249925}
2022-12-31 04:02:03,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:03,592 INFO:     Epoch: 11
2022-12-31 04:02:05,211 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46461796561876934, 'Total loss': 0.46461796561876934} | train loss {'Reaction outcome loss': 0.26438894620219217, 'Total loss': 0.26438894620219217}
2022-12-31 04:02:05,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:05,211 INFO:     Epoch: 12
2022-12-31 04:02:06,829 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4267966647942861, 'Total loss': 0.4267966647942861} | train loss {'Reaction outcome loss': 0.25458520009060914, 'Total loss': 0.25458520009060914}
2022-12-31 04:02:06,830 INFO:     Found new best model at epoch 12
2022-12-31 04:02:06,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:06,831 INFO:     Epoch: 13
2022-12-31 04:02:08,444 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4770807762940725, 'Total loss': 0.4770807762940725} | train loss {'Reaction outcome loss': 0.2501164086675946, 'Total loss': 0.2501164086675946}
2022-12-31 04:02:08,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:08,444 INFO:     Epoch: 14
2022-12-31 04:02:10,096 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4654885490735372, 'Total loss': 0.4654885490735372} | train loss {'Reaction outcome loss': 0.25818985534525657, 'Total loss': 0.25818985534525657}
2022-12-31 04:02:10,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:10,096 INFO:     Epoch: 15
2022-12-31 04:02:11,713 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4821341986457507, 'Total loss': 0.4821341986457507} | train loss {'Reaction outcome loss': 0.22908683793376322, 'Total loss': 0.22908683793376322}
2022-12-31 04:02:11,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:11,713 INFO:     Epoch: 16
2022-12-31 04:02:13,374 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4349363535642624, 'Total loss': 0.4349363535642624} | train loss {'Reaction outcome loss': 0.22233058131035027, 'Total loss': 0.22233058131035027}
2022-12-31 04:02:13,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:13,374 INFO:     Epoch: 17
2022-12-31 04:02:14,996 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4462406814098358, 'Total loss': 0.4462406814098358} | train loss {'Reaction outcome loss': 0.21579008756637358, 'Total loss': 0.21579008756637358}
2022-12-31 04:02:14,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:14,997 INFO:     Epoch: 18
2022-12-31 04:02:16,657 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42830546100934347, 'Total loss': 0.42830546100934347} | train loss {'Reaction outcome loss': 0.21045144044562578, 'Total loss': 0.21045144044562578}
2022-12-31 04:02:16,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:16,659 INFO:     Epoch: 19
2022-12-31 04:02:18,284 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4346019417047501, 'Total loss': 0.4346019417047501} | train loss {'Reaction outcome loss': 0.20469819190169591, 'Total loss': 0.20469819190169591}
2022-12-31 04:02:18,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:18,285 INFO:     Epoch: 20
2022-12-31 04:02:19,896 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4455619146426519, 'Total loss': 0.4455619146426519} | train loss {'Reaction outcome loss': 0.21167377397928183, 'Total loss': 0.21167377397928183}
2022-12-31 04:02:19,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:19,896 INFO:     Epoch: 21
2022-12-31 04:02:21,512 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4442653884490331, 'Total loss': 0.4442653884490331} | train loss {'Reaction outcome loss': 0.1974080467623645, 'Total loss': 0.1974080467623645}
2022-12-31 04:02:21,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:21,512 INFO:     Epoch: 22
2022-12-31 04:02:23,129 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43400360494852064, 'Total loss': 0.43400360494852064} | train loss {'Reaction outcome loss': 0.19354008009954207, 'Total loss': 0.19354008009954207}
2022-12-31 04:02:23,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:23,130 INFO:     Epoch: 23
2022-12-31 04:02:24,747 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4540579169988632, 'Total loss': 0.4540579169988632} | train loss {'Reaction outcome loss': 0.19824510333389786, 'Total loss': 0.19824510333389786}
2022-12-31 04:02:24,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:24,747 INFO:     Epoch: 24
2022-12-31 04:02:26,357 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4559464335441589, 'Total loss': 0.4559464335441589} | train loss {'Reaction outcome loss': 0.1861522089954791, 'Total loss': 0.1861522089954791}
2022-12-31 04:02:26,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:26,357 INFO:     Epoch: 25
2022-12-31 04:02:27,972 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44906896700461707, 'Total loss': 0.44906896700461707} | train loss {'Reaction outcome loss': 0.1805863788628114, 'Total loss': 0.1805863788628114}
2022-12-31 04:02:27,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:27,972 INFO:     Epoch: 26
2022-12-31 04:02:29,603 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45978342965245245, 'Total loss': 0.45978342965245245} | train loss {'Reaction outcome loss': 0.17420142570483513, 'Total loss': 0.17420142570483513}
2022-12-31 04:02:29,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:29,603 INFO:     Epoch: 27
2022-12-31 04:02:31,263 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43704553445180255, 'Total loss': 0.43704553445180255} | train loss {'Reaction outcome loss': 0.1730524310639695, 'Total loss': 0.1730524310639695}
2022-12-31 04:02:31,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:31,264 INFO:     Epoch: 28
2022-12-31 04:02:32,924 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4406060516834259, 'Total loss': 0.4406060516834259} | train loss {'Reaction outcome loss': 0.17203206526102038, 'Total loss': 0.17203206526102038}
2022-12-31 04:02:32,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:32,924 INFO:     Epoch: 29
2022-12-31 04:02:34,586 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46079386323690413, 'Total loss': 0.46079386323690413} | train loss {'Reaction outcome loss': 0.19303750865504338, 'Total loss': 0.19303750865504338}
2022-12-31 04:02:34,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:34,586 INFO:     Epoch: 30
2022-12-31 04:02:36,198 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4318674663702647, 'Total loss': 0.4318674663702647} | train loss {'Reaction outcome loss': 0.172599420179208, 'Total loss': 0.172599420179208}
2022-12-31 04:02:36,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:36,199 INFO:     Epoch: 31
2022-12-31 04:02:37,824 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4266261438528697, 'Total loss': 0.4266261438528697} | train loss {'Reaction outcome loss': 0.18295867006679106, 'Total loss': 0.18295867006679106}
2022-12-31 04:02:37,824 INFO:     Found new best model at epoch 31
2022-12-31 04:02:37,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:37,825 INFO:     Epoch: 32
2022-12-31 04:02:39,422 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4717200537522634, 'Total loss': 0.4717200537522634} | train loss {'Reaction outcome loss': 0.1735505647316197, 'Total loss': 0.1735505647316197}
2022-12-31 04:02:39,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:39,422 INFO:     Epoch: 33
2022-12-31 04:02:41,058 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4447934443751971, 'Total loss': 0.4447934443751971} | train loss {'Reaction outcome loss': 0.16052841086038033, 'Total loss': 0.16052841086038033}
2022-12-31 04:02:41,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:41,058 INFO:     Epoch: 34
2022-12-31 04:02:42,718 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46183517202734947, 'Total loss': 0.46183517202734947} | train loss {'Reaction outcome loss': 0.1569670160224632, 'Total loss': 0.1569670160224632}
2022-12-31 04:02:42,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:42,719 INFO:     Epoch: 35
2022-12-31 04:02:44,370 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4586598028739293, 'Total loss': 0.4586598028739293} | train loss {'Reaction outcome loss': 0.15417418101350305, 'Total loss': 0.15417418101350305}
2022-12-31 04:02:44,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:44,370 INFO:     Epoch: 36
2022-12-31 04:02:45,986 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4858291555196047, 'Total loss': 0.4858291555196047} | train loss {'Reaction outcome loss': 0.15019328033014206, 'Total loss': 0.15019328033014206}
2022-12-31 04:02:45,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:45,986 INFO:     Epoch: 37
2022-12-31 04:02:47,596 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46945019364356994, 'Total loss': 0.46945019364356994} | train loss {'Reaction outcome loss': 0.1487878299882615, 'Total loss': 0.1487878299882615}
2022-12-31 04:02:47,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:47,597 INFO:     Epoch: 38
2022-12-31 04:02:49,220 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45183498164017993, 'Total loss': 0.45183498164017993} | train loss {'Reaction outcome loss': 0.144827400382264, 'Total loss': 0.144827400382264}
2022-12-31 04:02:49,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:49,221 INFO:     Epoch: 39
2022-12-31 04:02:50,845 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4371924171845118, 'Total loss': 0.4371924171845118} | train loss {'Reaction outcome loss': 0.14692875785829898, 'Total loss': 0.14692875785829898}
2022-12-31 04:02:50,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:50,845 INFO:     Epoch: 40
2022-12-31 04:02:52,469 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47465899884700774, 'Total loss': 0.47465899884700774} | train loss {'Reaction outcome loss': 0.14437512766765564, 'Total loss': 0.14437512766765564}
2022-12-31 04:02:52,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:52,469 INFO:     Epoch: 41
2022-12-31 04:02:54,088 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4785427371660868, 'Total loss': 0.4785427371660868} | train loss {'Reaction outcome loss': 0.15284917992708422, 'Total loss': 0.15284917992708422}
2022-12-31 04:02:54,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:54,089 INFO:     Epoch: 42
2022-12-31 04:02:55,708 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46644777059555054, 'Total loss': 0.46644777059555054} | train loss {'Reaction outcome loss': 0.17099587799210617, 'Total loss': 0.17099587799210617}
2022-12-31 04:02:55,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:55,708 INFO:     Epoch: 43
2022-12-31 04:02:57,324 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4696798975269, 'Total loss': 0.4696798975269} | train loss {'Reaction outcome loss': 0.14020156546873783, 'Total loss': 0.14020156546873783}
2022-12-31 04:02:57,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:57,324 INFO:     Epoch: 44
2022-12-31 04:02:58,948 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4587566938251257, 'Total loss': 0.4587566938251257} | train loss {'Reaction outcome loss': 0.13903902856417108, 'Total loss': 0.13903902856417108}
2022-12-31 04:02:58,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:02:58,948 INFO:     Epoch: 45
2022-12-31 04:03:00,573 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48305058081944785, 'Total loss': 0.48305058081944785} | train loss {'Reaction outcome loss': 0.1370354036874799, 'Total loss': 0.1370354036874799}
2022-12-31 04:03:00,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:00,573 INFO:     Epoch: 46
2022-12-31 04:03:02,200 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4867441092928251, 'Total loss': 0.4867441092928251} | train loss {'Reaction outcome loss': 0.14633990578231929, 'Total loss': 0.14633990578231929}
2022-12-31 04:03:02,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:02,201 INFO:     Epoch: 47
2022-12-31 04:03:03,818 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4799242744843165, 'Total loss': 0.4799242744843165} | train loss {'Reaction outcome loss': 0.16276172620406293, 'Total loss': 0.16276172620406293}
2022-12-31 04:03:03,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:03,819 INFO:     Epoch: 48
2022-12-31 04:03:05,468 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46519048015276593, 'Total loss': 0.46519048015276593} | train loss {'Reaction outcome loss': 0.1449797645082994, 'Total loss': 0.1449797645082994}
2022-12-31 04:03:05,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:05,468 INFO:     Epoch: 49
2022-12-31 04:03:07,095 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43283050258954364, 'Total loss': 0.43283050258954364} | train loss {'Reaction outcome loss': 0.14080084706116738, 'Total loss': 0.14080084706116738}
2022-12-31 04:03:07,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:07,096 INFO:     Epoch: 50
2022-12-31 04:03:08,719 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4709168563286463, 'Total loss': 0.4709168563286463} | train loss {'Reaction outcome loss': 0.1344551885651553, 'Total loss': 0.1344551885651553}
2022-12-31 04:03:08,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:08,719 INFO:     Epoch: 51
2022-12-31 04:03:10,342 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4374760796626409, 'Total loss': 0.4374760796626409} | train loss {'Reaction outcome loss': 0.13292450512982096, 'Total loss': 0.13292450512982096}
2022-12-31 04:03:10,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:10,342 INFO:     Epoch: 52
2022-12-31 04:03:11,963 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4376486028234164, 'Total loss': 0.4376486028234164} | train loss {'Reaction outcome loss': 0.1319807498017537, 'Total loss': 0.1319807498017537}
2022-12-31 04:03:11,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:11,963 INFO:     Epoch: 53
2022-12-31 04:03:13,576 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4540590981642405, 'Total loss': 0.4540590981642405} | train loss {'Reaction outcome loss': 0.13158703457557366, 'Total loss': 0.13158703457557366}
2022-12-31 04:03:13,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:13,577 INFO:     Epoch: 54
2022-12-31 04:03:15,191 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44286676943302156, 'Total loss': 0.44286676943302156} | train loss {'Reaction outcome loss': 0.136324030167708, 'Total loss': 0.136324030167708}
2022-12-31 04:03:15,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:15,191 INFO:     Epoch: 55
2022-12-31 04:03:16,814 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47824600835641223, 'Total loss': 0.47824600835641223} | train loss {'Reaction outcome loss': 0.1301560196755589, 'Total loss': 0.1301560196755589}
2022-12-31 04:03:16,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:16,814 INFO:     Epoch: 56
2022-12-31 04:03:18,436 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44033620655536654, 'Total loss': 0.44033620655536654} | train loss {'Reaction outcome loss': 0.1309908391733684, 'Total loss': 0.1309908391733684}
2022-12-31 04:03:18,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:18,436 INFO:     Epoch: 57
2022-12-31 04:03:20,061 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4555392940839132, 'Total loss': 0.4555392940839132} | train loss {'Reaction outcome loss': 0.12872322071411146, 'Total loss': 0.12872322071411146}
2022-12-31 04:03:20,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:20,062 INFO:     Epoch: 58
2022-12-31 04:03:21,674 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4812520225842794, 'Total loss': 0.4812520225842794} | train loss {'Reaction outcome loss': 0.13019837513464785, 'Total loss': 0.13019837513464785}
2022-12-31 04:03:21,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:21,675 INFO:     Epoch: 59
2022-12-31 04:03:23,296 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4744088153044383, 'Total loss': 0.4744088153044383} | train loss {'Reaction outcome loss': 0.13028648333367554, 'Total loss': 0.13028648333367554}
2022-12-31 04:03:23,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:23,297 INFO:     Epoch: 60
2022-12-31 04:03:24,950 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46298165023326876, 'Total loss': 0.46298165023326876} | train loss {'Reaction outcome loss': 0.12984747406554178, 'Total loss': 0.12984747406554178}
2022-12-31 04:03:24,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:24,951 INFO:     Epoch: 61
2022-12-31 04:03:26,567 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4539324217631171, 'Total loss': 0.4539324217631171} | train loss {'Reaction outcome loss': 0.1283053796547735, 'Total loss': 0.1283053796547735}
2022-12-31 04:03:26,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:26,567 INFO:     Epoch: 62
2022-12-31 04:03:28,228 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46758485237757363, 'Total loss': 0.46758485237757363} | train loss {'Reaction outcome loss': 0.12560391025128437, 'Total loss': 0.12560391025128437}
2022-12-31 04:03:28,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:28,228 INFO:     Epoch: 63
2022-12-31 04:03:29,844 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5097859042386214, 'Total loss': 0.5097859042386214} | train loss {'Reaction outcome loss': 0.12750867940822913, 'Total loss': 0.12750867940822913}
2022-12-31 04:03:29,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:29,845 INFO:     Epoch: 64
2022-12-31 04:03:31,450 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5005638937155406, 'Total loss': 0.5005638937155406} | train loss {'Reaction outcome loss': 0.148231580011771, 'Total loss': 0.148231580011771}
2022-12-31 04:03:31,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:31,450 INFO:     Epoch: 65
2022-12-31 04:03:33,069 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4632945795853933, 'Total loss': 0.4632945795853933} | train loss {'Reaction outcome loss': 0.13260909895847284, 'Total loss': 0.13260909895847284}
2022-12-31 04:03:33,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:33,069 INFO:     Epoch: 66
2022-12-31 04:03:34,730 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46848810811837516, 'Total loss': 0.46848810811837516} | train loss {'Reaction outcome loss': 0.12378124743311976, 'Total loss': 0.12378124743311976}
2022-12-31 04:03:34,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:34,730 INFO:     Epoch: 67
2022-12-31 04:03:36,392 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4618045081694921, 'Total loss': 0.4618045081694921} | train loss {'Reaction outcome loss': 0.12114943107970222, 'Total loss': 0.12114943107970222}
2022-12-31 04:03:36,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:36,393 INFO:     Epoch: 68
2022-12-31 04:03:38,012 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4767976333697637, 'Total loss': 0.4767976333697637} | train loss {'Reaction outcome loss': 0.11537310833607436, 'Total loss': 0.11537310833607436}
2022-12-31 04:03:38,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:38,012 INFO:     Epoch: 69
2022-12-31 04:03:39,661 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.446548788746198, 'Total loss': 0.446548788746198} | train loss {'Reaction outcome loss': 0.11469177805575663, 'Total loss': 0.11469177805575663}
2022-12-31 04:03:39,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:39,661 INFO:     Epoch: 70
2022-12-31 04:03:41,288 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5165965567032497, 'Total loss': 0.5165965567032497} | train loss {'Reaction outcome loss': 0.11597780577932904, 'Total loss': 0.11597780577932904}
2022-12-31 04:03:41,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:41,289 INFO:     Epoch: 71
2022-12-31 04:03:42,909 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4752739081780116, 'Total loss': 0.4752739081780116} | train loss {'Reaction outcome loss': 0.12233186416425809, 'Total loss': 0.12233186416425809}
2022-12-31 04:03:42,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:42,910 INFO:     Epoch: 72
2022-12-31 04:03:44,539 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46329770187536873, 'Total loss': 0.46329770187536873} | train loss {'Reaction outcome loss': 0.1220945237530058, 'Total loss': 0.1220945237530058}
2022-12-31 04:03:44,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:44,539 INFO:     Epoch: 73
2022-12-31 04:03:46,169 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45622411568959553, 'Total loss': 0.45622411568959553} | train loss {'Reaction outcome loss': 0.11780250218420195, 'Total loss': 0.11780250218420195}
2022-12-31 04:03:46,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:46,169 INFO:     Epoch: 74
2022-12-31 04:03:47,800 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4655802011489868, 'Total loss': 0.4655802011489868} | train loss {'Reaction outcome loss': 0.1167983049029093, 'Total loss': 0.1167983049029093}
2022-12-31 04:03:47,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:47,800 INFO:     Epoch: 75
2022-12-31 04:03:49,436 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46311990221341454, 'Total loss': 0.46311990221341454} | train loss {'Reaction outcome loss': 0.11939027011259526, 'Total loss': 0.11939027011259526}
2022-12-31 04:03:49,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:49,436 INFO:     Epoch: 76
2022-12-31 04:03:51,047 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4619466006755829, 'Total loss': 0.4619466006755829} | train loss {'Reaction outcome loss': 0.1143921978420648, 'Total loss': 0.1143921978420648}
2022-12-31 04:03:51,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:51,047 INFO:     Epoch: 77
2022-12-31 04:03:52,709 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4905098428328832, 'Total loss': 0.4905098428328832} | train loss {'Reaction outcome loss': 0.11184875457378887, 'Total loss': 0.11184875457378887}
2022-12-31 04:03:52,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:52,710 INFO:     Epoch: 78
2022-12-31 04:03:54,343 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4758484313885371, 'Total loss': 0.4758484313885371} | train loss {'Reaction outcome loss': 0.11549600262272482, 'Total loss': 0.11549600262272482}
2022-12-31 04:03:54,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:54,345 INFO:     Epoch: 79
2022-12-31 04:03:55,962 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4743548035621643, 'Total loss': 0.4743548035621643} | train loss {'Reaction outcome loss': 0.11051558356553288, 'Total loss': 0.11051558356553288}
2022-12-31 04:03:55,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:55,962 INFO:     Epoch: 80
2022-12-31 04:03:57,624 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4584196701645851, 'Total loss': 0.4584196701645851} | train loss {'Reaction outcome loss': 0.1102349420779965, 'Total loss': 0.1102349420779965}
2022-12-31 04:03:57,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:57,624 INFO:     Epoch: 81
2022-12-31 04:03:59,244 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49069594343503314, 'Total loss': 0.49069594343503314} | train loss {'Reaction outcome loss': 0.11437938129065382, 'Total loss': 0.11437938129065382}
2022-12-31 04:03:59,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:03:59,244 INFO:     Epoch: 82
2022-12-31 04:04:00,864 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4636134843031565, 'Total loss': 0.4636134843031565} | train loss {'Reaction outcome loss': 0.11583206605480856, 'Total loss': 0.11583206605480856}
2022-12-31 04:04:00,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:00,865 INFO:     Epoch: 83
2022-12-31 04:04:02,490 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5070403665304184, 'Total loss': 0.5070403665304184} | train loss {'Reaction outcome loss': 0.11480694608566198, 'Total loss': 0.11480694608566198}
2022-12-31 04:04:02,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:02,490 INFO:     Epoch: 84
2022-12-31 04:04:04,115 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4487695244451364, 'Total loss': 0.4487695244451364} | train loss {'Reaction outcome loss': 0.11834257531881207, 'Total loss': 0.11834257531881207}
2022-12-31 04:04:04,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:04,115 INFO:     Epoch: 85
2022-12-31 04:04:05,740 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4586842477321625, 'Total loss': 0.4586842477321625} | train loss {'Reaction outcome loss': 0.11302666489991943, 'Total loss': 0.11302666489991943}
2022-12-31 04:04:05,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:05,740 INFO:     Epoch: 86
2022-12-31 04:04:07,363 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49088703592618305, 'Total loss': 0.49088703592618305} | train loss {'Reaction outcome loss': 0.11230174814324752, 'Total loss': 0.11230174814324752}
2022-12-31 04:04:07,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:07,363 INFO:     Epoch: 87
2022-12-31 04:04:08,981 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44961705108483635, 'Total loss': 0.44961705108483635} | train loss {'Reaction outcome loss': 0.11101009573384664, 'Total loss': 0.11101009573384664}
2022-12-31 04:04:08,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:08,981 INFO:     Epoch: 88
2022-12-31 04:04:10,609 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4853385771314303, 'Total loss': 0.4853385771314303} | train loss {'Reaction outcome loss': 0.1043403241585137, 'Total loss': 0.1043403241585137}
2022-12-31 04:04:10,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:10,609 INFO:     Epoch: 89
2022-12-31 04:04:12,270 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4732258439064026, 'Total loss': 0.4732258439064026} | train loss {'Reaction outcome loss': 0.10622719315089879, 'Total loss': 0.10622719315089879}
2022-12-31 04:04:12,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:12,270 INFO:     Epoch: 90
2022-12-31 04:04:13,931 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5065118859211604, 'Total loss': 0.5065118859211604} | train loss {'Reaction outcome loss': 0.10933001145747477, 'Total loss': 0.10933001145747477}
2022-12-31 04:04:13,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:13,932 INFO:     Epoch: 91
2022-12-31 04:04:15,552 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4676215877135595, 'Total loss': 0.4676215877135595} | train loss {'Reaction outcome loss': 0.10830815727620022, 'Total loss': 0.10830815727620022}
2022-12-31 04:04:15,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:15,552 INFO:     Epoch: 92
2022-12-31 04:04:17,177 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5129562834898631, 'Total loss': 0.5129562834898631} | train loss {'Reaction outcome loss': 0.1238332678744421, 'Total loss': 0.1238332678744421}
2022-12-31 04:04:17,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:17,177 INFO:     Epoch: 93
2022-12-31 04:04:18,814 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49013957877953845, 'Total loss': 0.49013957877953845} | train loss {'Reaction outcome loss': 0.112610523320694, 'Total loss': 0.112610523320694}
2022-12-31 04:04:18,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:18,815 INFO:     Epoch: 94
2022-12-31 04:04:20,447 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47618137001991273, 'Total loss': 0.47618137001991273} | train loss {'Reaction outcome loss': 0.1178431745139423, 'Total loss': 0.1178431745139423}
2022-12-31 04:04:20,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:20,447 INFO:     Epoch: 95
2022-12-31 04:04:22,082 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46676594217618306, 'Total loss': 0.46676594217618306} | train loss {'Reaction outcome loss': 0.11230762159655147, 'Total loss': 0.11230762159655147}
2022-12-31 04:04:22,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:22,082 INFO:     Epoch: 96
2022-12-31 04:04:23,716 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46589644253253937, 'Total loss': 0.46589644253253937} | train loss {'Reaction outcome loss': 0.10921748347312171, 'Total loss': 0.10921748347312171}
2022-12-31 04:04:23,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:23,716 INFO:     Epoch: 97
2022-12-31 04:04:25,340 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.512984057267507, 'Total loss': 0.512984057267507} | train loss {'Reaction outcome loss': 0.11138997074727819, 'Total loss': 0.11138997074727819}
2022-12-31 04:04:25,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:25,341 INFO:     Epoch: 98
2022-12-31 04:04:26,960 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4670323431491852, 'Total loss': 0.4670323431491852} | train loss {'Reaction outcome loss': 0.10733806229436069, 'Total loss': 0.10733806229436069}
2022-12-31 04:04:26,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:26,960 INFO:     Epoch: 99
2022-12-31 04:04:28,583 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5161657849947612, 'Total loss': 0.5161657849947612} | train loss {'Reaction outcome loss': 0.10398169382444947, 'Total loss': 0.10398169382444947}
2022-12-31 04:04:28,583 INFO:     Best model found after epoch 32 of 100.
2022-12-31 04:04:28,583 INFO:   Done with stage: TRAINING
2022-12-31 04:04:28,583 INFO:   Starting stage: EVALUATION
2022-12-31 04:04:28,715 INFO:   Done with stage: EVALUATION
2022-12-31 04:04:28,723 INFO:   Leaving out SEQ value Fold_0
2022-12-31 04:04:28,736 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 04:04:28,736 INFO:   Starting stage: FEATURE SCALING
2022-12-31 04:04:29,379 INFO:   Done with stage: FEATURE SCALING
2022-12-31 04:04:29,380 INFO:   Starting stage: SCALING TARGETS
2022-12-31 04:04:29,452 INFO:   Done with stage: SCALING TARGETS
2022-12-31 04:04:29,452 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:04:29,452 INFO:     No hyperparam tuning for this model
2022-12-31 04:04:29,452 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:04:29,452 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 04:04:29,453 INFO:     None feature selector for col prot
2022-12-31 04:04:29,453 INFO:     None feature selector for col prot
2022-12-31 04:04:29,453 INFO:     None feature selector for col prot
2022-12-31 04:04:29,454 INFO:     None feature selector for col chem
2022-12-31 04:04:29,454 INFO:     None feature selector for col chem
2022-12-31 04:04:29,454 INFO:     None feature selector for col chem
2022-12-31 04:04:29,454 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 04:04:29,454 INFO:   Starting stage: BUILD MODEL
2022-12-31 04:04:29,456 INFO:     Number of params in model 224011
2022-12-31 04:04:29,459 INFO:   Done with stage: BUILD MODEL
2022-12-31 04:04:29,459 INFO:   Starting stage: TRAINING
2022-12-31 04:04:29,504 INFO:     Val loss before train {'Reaction outcome loss': 1.0059111833572387, 'Total loss': 1.0059111833572387}
2022-12-31 04:04:29,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:29,504 INFO:     Epoch: 0
2022-12-31 04:04:31,118 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5852394958337148, 'Total loss': 0.5852394958337148} | train loss {'Reaction outcome loss': 0.7655306438895038, 'Total loss': 0.7655306438895038}
2022-12-31 04:04:31,118 INFO:     Found new best model at epoch 0
2022-12-31 04:04:31,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:31,119 INFO:     Epoch: 1
2022-12-31 04:04:32,723 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5185605903466542, 'Total loss': 0.5185605903466542} | train loss {'Reaction outcome loss': 0.5118706710908535, 'Total loss': 0.5118706710908535}
2022-12-31 04:04:32,723 INFO:     Found new best model at epoch 1
2022-12-31 04:04:32,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:32,724 INFO:     Epoch: 2
2022-12-31 04:04:34,319 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49143805901209514, 'Total loss': 0.49143805901209514} | train loss {'Reaction outcome loss': 0.44277085614030376, 'Total loss': 0.44277085614030376}
2022-12-31 04:04:34,320 INFO:     Found new best model at epoch 2
2022-12-31 04:04:34,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:34,321 INFO:     Epoch: 3
2022-12-31 04:04:35,927 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4388800859451294, 'Total loss': 0.4388800859451294} | train loss {'Reaction outcome loss': 0.4034524880295252, 'Total loss': 0.4034524880295252}
2022-12-31 04:04:35,928 INFO:     Found new best model at epoch 3
2022-12-31 04:04:35,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:35,929 INFO:     Epoch: 4
2022-12-31 04:04:37,536 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43397093216578164, 'Total loss': 0.43397093216578164} | train loss {'Reaction outcome loss': 0.373475731479643, 'Total loss': 0.373475731479643}
2022-12-31 04:04:37,536 INFO:     Found new best model at epoch 4
2022-12-31 04:04:37,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:37,537 INFO:     Epoch: 5
2022-12-31 04:04:39,144 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4494485805432002, 'Total loss': 0.4494485805432002} | train loss {'Reaction outcome loss': 0.3481957862140053, 'Total loss': 0.3481957862140053}
2022-12-31 04:04:39,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:39,144 INFO:     Epoch: 6
2022-12-31 04:04:40,752 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4361049234867096, 'Total loss': 0.4361049234867096} | train loss {'Reaction outcome loss': 0.3279812604080152, 'Total loss': 0.3279812604080152}
2022-12-31 04:04:40,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:40,752 INFO:     Epoch: 7
2022-12-31 04:04:42,362 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4239309320847193, 'Total loss': 0.4239309320847193} | train loss {'Reaction outcome loss': 0.31058014192394096, 'Total loss': 0.31058014192394096}
2022-12-31 04:04:42,362 INFO:     Found new best model at epoch 7
2022-12-31 04:04:42,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:42,363 INFO:     Epoch: 8
2022-12-31 04:04:43,982 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42311257421970366, 'Total loss': 0.42311257421970366} | train loss {'Reaction outcome loss': 0.29898628842656627, 'Total loss': 0.29898628842656627}
2022-12-31 04:04:43,982 INFO:     Found new best model at epoch 8
2022-12-31 04:04:43,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:43,983 INFO:     Epoch: 9
2022-12-31 04:04:45,588 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44060133000214896, 'Total loss': 0.44060133000214896} | train loss {'Reaction outcome loss': 0.28159963255272297, 'Total loss': 0.28159963255272297}
2022-12-31 04:04:45,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:45,588 INFO:     Epoch: 10
2022-12-31 04:04:47,205 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42839313944180807, 'Total loss': 0.42839313944180807} | train loss {'Reaction outcome loss': 0.27279051824262107, 'Total loss': 0.27279051824262107}
2022-12-31 04:04:47,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:47,205 INFO:     Epoch: 11
2022-12-31 04:04:48,823 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4063184499740601, 'Total loss': 0.4063184499740601} | train loss {'Reaction outcome loss': 0.25850579245899713, 'Total loss': 0.25850579245899713}
2022-12-31 04:04:48,824 INFO:     Found new best model at epoch 11
2022-12-31 04:04:48,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:48,825 INFO:     Epoch: 12
2022-12-31 04:04:50,441 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4505862752596537, 'Total loss': 0.4505862752596537} | train loss {'Reaction outcome loss': 0.24936842994533315, 'Total loss': 0.24936842994533315}
2022-12-31 04:04:50,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:50,441 INFO:     Epoch: 13
2022-12-31 04:04:52,057 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42114393909772235, 'Total loss': 0.42114393909772235} | train loss {'Reaction outcome loss': 0.23919173330068588, 'Total loss': 0.23919173330068588}
2022-12-31 04:04:52,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:52,058 INFO:     Epoch: 14
2022-12-31 04:04:53,692 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4217902660369873, 'Total loss': 0.4217902660369873} | train loss {'Reaction outcome loss': 0.2354610611201964, 'Total loss': 0.2354610611201964}
2022-12-31 04:04:53,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:53,692 INFO:     Epoch: 15
2022-12-31 04:04:55,311 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4457296351591746, 'Total loss': 0.4457296351591746} | train loss {'Reaction outcome loss': 0.22480480455161228, 'Total loss': 0.22480480455161228}
2022-12-31 04:04:55,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:55,311 INFO:     Epoch: 16
2022-12-31 04:04:56,927 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4443685233592987, 'Total loss': 0.4443685233592987} | train loss {'Reaction outcome loss': 0.21739999206233634, 'Total loss': 0.21739999206233634}
2022-12-31 04:04:56,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:56,927 INFO:     Epoch: 17
2022-12-31 04:04:58,543 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40859744350115457, 'Total loss': 0.40859744350115457} | train loss {'Reaction outcome loss': 0.21355793588407282, 'Total loss': 0.21355793588407282}
2022-12-31 04:04:58,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:04:58,544 INFO:     Epoch: 18
2022-12-31 04:05:00,160 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4417173127333323, 'Total loss': 0.4417173127333323} | train loss {'Reaction outcome loss': 0.2065682289034237, 'Total loss': 0.2065682289034237}
2022-12-31 04:05:00,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:00,160 INFO:     Epoch: 19
2022-12-31 04:05:01,768 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4153936177492142, 'Total loss': 0.4153936177492142} | train loss {'Reaction outcome loss': 0.198672157372382, 'Total loss': 0.198672157372382}
2022-12-31 04:05:01,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:01,769 INFO:     Epoch: 20
2022-12-31 04:05:03,413 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40767040898402535, 'Total loss': 0.40767040898402535} | train loss {'Reaction outcome loss': 0.1970788619215906, 'Total loss': 0.1970788619215906}
2022-12-31 04:05:03,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:03,413 INFO:     Epoch: 21
2022-12-31 04:05:04,820 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4363775014877319, 'Total loss': 0.4363775014877319} | train loss {'Reaction outcome loss': 0.19284315129578875, 'Total loss': 0.19284315129578875}
2022-12-31 04:05:04,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:04,820 INFO:     Epoch: 22
2022-12-31 04:05:05,917 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4262970954179764, 'Total loss': 0.4262970954179764} | train loss {'Reaction outcome loss': 0.18772205816119583, 'Total loss': 0.18772205816119583}
2022-12-31 04:05:05,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:05,918 INFO:     Epoch: 23
2022-12-31 04:05:07,014 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42490602334340416, 'Total loss': 0.42490602334340416} | train loss {'Reaction outcome loss': 0.1837692286294076, 'Total loss': 0.1837692286294076}
2022-12-31 04:05:07,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:07,014 INFO:     Epoch: 24
2022-12-31 04:05:08,178 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4416886548201243, 'Total loss': 0.4416886548201243} | train loss {'Reaction outcome loss': 0.18344314237648662, 'Total loss': 0.18344314237648662}
2022-12-31 04:05:08,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:08,179 INFO:     Epoch: 25
2022-12-31 04:05:09,792 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43581872681776684, 'Total loss': 0.43581872681776684} | train loss {'Reaction outcome loss': 0.17411393390791693, 'Total loss': 0.17411393390791693}
2022-12-31 04:05:09,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:09,792 INFO:     Epoch: 26
2022-12-31 04:05:11,439 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4260297417640686, 'Total loss': 0.4260297417640686} | train loss {'Reaction outcome loss': 0.17467171531578485, 'Total loss': 0.17467171531578485}
2022-12-31 04:05:11,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:11,439 INFO:     Epoch: 27
2022-12-31 04:05:13,087 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.431123944123586, 'Total loss': 0.431123944123586} | train loss {'Reaction outcome loss': 0.16920812715212033, 'Total loss': 0.16920812715212033}
2022-12-31 04:05:13,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:13,088 INFO:     Epoch: 28
2022-12-31 04:05:14,692 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4270864265660445, 'Total loss': 0.4270864265660445} | train loss {'Reaction outcome loss': 0.16664648327609374, 'Total loss': 0.16664648327609374}
2022-12-31 04:05:14,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:14,692 INFO:     Epoch: 29
2022-12-31 04:05:16,341 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40392113079627356, 'Total loss': 0.40392113079627356} | train loss {'Reaction outcome loss': 0.1647291364705693, 'Total loss': 0.1647291364705693}
2022-12-31 04:05:16,341 INFO:     Found new best model at epoch 29
2022-12-31 04:05:16,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:16,342 INFO:     Epoch: 30
2022-12-31 04:05:17,955 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41875869234402974, 'Total loss': 0.41875869234402974} | train loss {'Reaction outcome loss': 0.16145932346745565, 'Total loss': 0.16145932346745565}
2022-12-31 04:05:17,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:17,956 INFO:     Epoch: 31
2022-12-31 04:05:19,562 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40747851530710855, 'Total loss': 0.40747851530710855} | train loss {'Reaction outcome loss': 0.16083456613259375, 'Total loss': 0.16083456613259375}
2022-12-31 04:05:19,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:19,562 INFO:     Epoch: 32
2022-12-31 04:05:21,175 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4414622843265533, 'Total loss': 0.4414622843265533} | train loss {'Reaction outcome loss': 0.15794351931328265, 'Total loss': 0.15794351931328265}
2022-12-31 04:05:21,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:21,175 INFO:     Epoch: 33
2022-12-31 04:05:22,787 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41548970639705657, 'Total loss': 0.41548970639705657} | train loss {'Reaction outcome loss': 0.1585669719162023, 'Total loss': 0.1585669719162023}
2022-12-31 04:05:22,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:22,787 INFO:     Epoch: 34
2022-12-31 04:05:24,398 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40764551212390265, 'Total loss': 0.40764551212390265} | train loss {'Reaction outcome loss': 0.15439415138459553, 'Total loss': 0.15439415138459553}
2022-12-31 04:05:24,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:24,399 INFO:     Epoch: 35
2022-12-31 04:05:26,011 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4173559943834941, 'Total loss': 0.4173559943834941} | train loss {'Reaction outcome loss': 0.15289365094032709, 'Total loss': 0.15289365094032709}
2022-12-31 04:05:26,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:26,012 INFO:     Epoch: 36
2022-12-31 04:05:27,616 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4353995035092036, 'Total loss': 0.4353995035092036} | train loss {'Reaction outcome loss': 0.1505903254269901, 'Total loss': 0.1505903254269901}
2022-12-31 04:05:27,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:27,616 INFO:     Epoch: 37
2022-12-31 04:05:29,265 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41308265924453735, 'Total loss': 0.41308265924453735} | train loss {'Reaction outcome loss': 0.14622513668434897, 'Total loss': 0.14622513668434897}
2022-12-31 04:05:29,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:29,265 INFO:     Epoch: 38
2022-12-31 04:05:30,869 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39871954172849655, 'Total loss': 0.39871954172849655} | train loss {'Reaction outcome loss': 0.14700567274164056, 'Total loss': 0.14700567274164056}
2022-12-31 04:05:30,869 INFO:     Found new best model at epoch 38
2022-12-31 04:05:30,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:30,870 INFO:     Epoch: 39
2022-12-31 04:05:32,470 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4513684074083964, 'Total loss': 0.4513684074083964} | train loss {'Reaction outcome loss': 0.14194716198750548, 'Total loss': 0.14194716198750548}
2022-12-31 04:05:32,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:32,471 INFO:     Epoch: 40
2022-12-31 04:05:34,118 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40980974535147346, 'Total loss': 0.40980974535147346} | train loss {'Reaction outcome loss': 0.146725525943576, 'Total loss': 0.146725525943576}
2022-12-31 04:05:34,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:34,119 INFO:     Epoch: 41
2022-12-31 04:05:35,748 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43263481160004935, 'Total loss': 0.43263481160004935} | train loss {'Reaction outcome loss': 0.14054923944929817, 'Total loss': 0.14054923944929817}
2022-12-31 04:05:35,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:35,748 INFO:     Epoch: 42
2022-12-31 04:05:37,351 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40672575185696286, 'Total loss': 0.40672575185696286} | train loss {'Reaction outcome loss': 0.1416918139490061, 'Total loss': 0.1416918139490061}
2022-12-31 04:05:37,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:37,351 INFO:     Epoch: 43
2022-12-31 04:05:38,958 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4326653629541397, 'Total loss': 0.4326653629541397} | train loss {'Reaction outcome loss': 0.14175894276415726, 'Total loss': 0.14175894276415726}
2022-12-31 04:05:38,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:38,958 INFO:     Epoch: 44
2022-12-31 04:05:40,565 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.432108736038208, 'Total loss': 0.432108736038208} | train loss {'Reaction outcome loss': 0.13975646286475452, 'Total loss': 0.13975646286475452}
2022-12-31 04:05:40,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:40,565 INFO:     Epoch: 45
2022-12-31 04:05:42,170 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4521242400010427, 'Total loss': 0.4521242400010427} | train loss {'Reaction outcome loss': 0.13967116197815885, 'Total loss': 0.13967116197815885}
2022-12-31 04:05:42,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:42,171 INFO:     Epoch: 46
2022-12-31 04:05:43,777 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4010975055396557, 'Total loss': 0.4010975055396557} | train loss {'Reaction outcome loss': 0.1384428846853765, 'Total loss': 0.1384428846853765}
2022-12-31 04:05:43,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:43,777 INFO:     Epoch: 47
2022-12-31 04:05:45,389 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4017377749706308, 'Total loss': 0.4017377749706308} | train loss {'Reaction outcome loss': 0.1357414434480406, 'Total loss': 0.1357414434480406}
2022-12-31 04:05:45,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:45,389 INFO:     Epoch: 48
2022-12-31 04:05:46,992 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44097467958927156, 'Total loss': 0.44097467958927156} | train loss {'Reaction outcome loss': 0.1313619625288993, 'Total loss': 0.1313619625288993}
2022-12-31 04:05:46,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:46,992 INFO:     Epoch: 49
2022-12-31 04:05:48,638 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41102802405754724, 'Total loss': 0.41102802405754724} | train loss {'Reaction outcome loss': 0.13177872296884982, 'Total loss': 0.13177872296884982}
2022-12-31 04:05:48,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:48,639 INFO:     Epoch: 50
2022-12-31 04:05:50,244 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38620859384536743, 'Total loss': 0.38620859384536743} | train loss {'Reaction outcome loss': 0.13017224013315934, 'Total loss': 0.13017224013315934}
2022-12-31 04:05:50,244 INFO:     Found new best model at epoch 50
2022-12-31 04:05:50,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:50,245 INFO:     Epoch: 51
2022-12-31 04:05:51,851 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3964379008859396, 'Total loss': 0.3964379008859396} | train loss {'Reaction outcome loss': 0.13259278449916492, 'Total loss': 0.13259278449916492}
2022-12-31 04:05:51,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:51,852 INFO:     Epoch: 52
2022-12-31 04:05:53,501 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39251956989367803, 'Total loss': 0.39251956989367803} | train loss {'Reaction outcome loss': 0.1338088792454737, 'Total loss': 0.1338088792454737}
2022-12-31 04:05:53,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:53,501 INFO:     Epoch: 53
2022-12-31 04:05:55,126 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.439381867647171, 'Total loss': 0.439381867647171} | train loss {'Reaction outcome loss': 0.12792998373960518, 'Total loss': 0.12792998373960518}
2022-12-31 04:05:55,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:55,126 INFO:     Epoch: 54
2022-12-31 04:05:56,725 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4461243604620298, 'Total loss': 0.4461243604620298} | train loss {'Reaction outcome loss': 0.12763737198169323, 'Total loss': 0.12763737198169323}
2022-12-31 04:05:56,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:56,726 INFO:     Epoch: 55
2022-12-31 04:05:58,374 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38628923197587334, 'Total loss': 0.38628923197587334} | train loss {'Reaction outcome loss': 0.127086666286889, 'Total loss': 0.127086666286889}
2022-12-31 04:05:58,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:58,375 INFO:     Epoch: 56
2022-12-31 04:05:59,979 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3944071799516678, 'Total loss': 0.3944071799516678} | train loss {'Reaction outcome loss': 0.12588006378929845, 'Total loss': 0.12588006378929845}
2022-12-31 04:05:59,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:05:59,979 INFO:     Epoch: 57
2022-12-31 04:06:01,628 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4182031363248825, 'Total loss': 0.4182031363248825} | train loss {'Reaction outcome loss': 0.12483864422907957, 'Total loss': 0.12483864422907957}
2022-12-31 04:06:01,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:01,629 INFO:     Epoch: 58
2022-12-31 04:06:03,225 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41334411799907683, 'Total loss': 0.41334411799907683} | train loss {'Reaction outcome loss': 0.12751528940394685, 'Total loss': 0.12751528940394685}
2022-12-31 04:06:03,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:03,226 INFO:     Epoch: 59
2022-12-31 04:06:04,835 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4148548096418381, 'Total loss': 0.4148548096418381} | train loss {'Reaction outcome loss': 0.12113602784926235, 'Total loss': 0.12113602784926235}
2022-12-31 04:06:04,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:04,835 INFO:     Epoch: 60
2022-12-31 04:06:06,451 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43433206230401994, 'Total loss': 0.43433206230401994} | train loss {'Reaction outcome loss': 0.12283473914101666, 'Total loss': 0.12283473914101666}
2022-12-31 04:06:06,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:06,451 INFO:     Epoch: 61
2022-12-31 04:06:08,062 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4014596608777841, 'Total loss': 0.4014596608777841} | train loss {'Reaction outcome loss': 0.1250461962458127, 'Total loss': 0.1250461962458127}
2022-12-31 04:06:08,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:08,062 INFO:     Epoch: 62
2022-12-31 04:06:09,679 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43649556040763854, 'Total loss': 0.43649556040763854} | train loss {'Reaction outcome loss': 0.12231425386275688, 'Total loss': 0.12231425386275688}
2022-12-31 04:06:09,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:09,679 INFO:     Epoch: 63
2022-12-31 04:06:11,294 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4039449284474055, 'Total loss': 0.4039449284474055} | train loss {'Reaction outcome loss': 0.12064658582336303, 'Total loss': 0.12064658582336303}
2022-12-31 04:06:11,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:11,294 INFO:     Epoch: 64
2022-12-31 04:06:12,905 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38646650897959867, 'Total loss': 0.38646650897959867} | train loss {'Reaction outcome loss': 0.12589500937780815, 'Total loss': 0.12589500937780815}
2022-12-31 04:06:12,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:12,906 INFO:     Epoch: 65
2022-12-31 04:06:14,554 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39478992720445, 'Total loss': 0.39478992720445} | train loss {'Reaction outcome loss': 0.1242345066462392, 'Total loss': 0.1242345066462392}
2022-12-31 04:06:14,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:14,555 INFO:     Epoch: 66
2022-12-31 04:06:16,157 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4263276084015767, 'Total loss': 0.4263276084015767} | train loss {'Reaction outcome loss': 0.11721421683285331, 'Total loss': 0.11721421683285331}
2022-12-31 04:06:16,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:16,158 INFO:     Epoch: 67
2022-12-31 04:06:17,758 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4085767457882563, 'Total loss': 0.4085767457882563} | train loss {'Reaction outcome loss': 0.1145112060212673, 'Total loss': 0.1145112060212673}
2022-12-31 04:06:17,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:17,759 INFO:     Epoch: 68
2022-12-31 04:06:19,359 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41148804823557533, 'Total loss': 0.41148804823557533} | train loss {'Reaction outcome loss': 0.11984216383773916, 'Total loss': 0.11984216383773916}
2022-12-31 04:06:19,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:19,359 INFO:     Epoch: 69
2022-12-31 04:06:20,998 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40429417192935946, 'Total loss': 0.40429417192935946} | train loss {'Reaction outcome loss': 0.11757133122156273, 'Total loss': 0.11757133122156273}
2022-12-31 04:06:20,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:20,999 INFO:     Epoch: 70
2022-12-31 04:06:22,616 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3883971964319547, 'Total loss': 0.3883971964319547} | train loss {'Reaction outcome loss': 0.11481856881899175, 'Total loss': 0.11481856881899175}
2022-12-31 04:06:22,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:22,616 INFO:     Epoch: 71
2022-12-31 04:06:24,233 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4147588908672333, 'Total loss': 0.4147588908672333} | train loss {'Reaction outcome loss': 0.11627417137628815, 'Total loss': 0.11627417137628815}
2022-12-31 04:06:24,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:24,234 INFO:     Epoch: 72
2022-12-31 04:06:25,850 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4059622739752134, 'Total loss': 0.4059622739752134} | train loss {'Reaction outcome loss': 0.11369317810537198, 'Total loss': 0.11369317810537198}
2022-12-31 04:06:25,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:25,850 INFO:     Epoch: 73
2022-12-31 04:06:27,464 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41493429044882457, 'Total loss': 0.41493429044882457} | train loss {'Reaction outcome loss': 0.1127965802472955, 'Total loss': 0.1127965802472955}
2022-12-31 04:06:27,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:27,465 INFO:     Epoch: 74
2022-12-31 04:06:29,081 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4687193423509598, 'Total loss': 0.4687193423509598} | train loss {'Reaction outcome loss': 0.1172475261532151, 'Total loss': 0.1172475261532151}
2022-12-31 04:06:29,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:29,081 INFO:     Epoch: 75
2022-12-31 04:06:30,689 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4066868339975675, 'Total loss': 0.4066868339975675} | train loss {'Reaction outcome loss': 0.12304408473547303, 'Total loss': 0.12304408473547303}
2022-12-31 04:06:30,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:30,689 INFO:     Epoch: 76
2022-12-31 04:06:32,294 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3936253398656845, 'Total loss': 0.3936253398656845} | train loss {'Reaction outcome loss': 0.11172413998147486, 'Total loss': 0.11172413998147486}
2022-12-31 04:06:32,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:32,294 INFO:     Epoch: 77
2022-12-31 04:06:33,909 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41329127290907003, 'Total loss': 0.41329127290907003} | train loss {'Reaction outcome loss': 0.11138423672030905, 'Total loss': 0.11138423672030905}
2022-12-31 04:06:33,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:33,909 INFO:     Epoch: 78
2022-12-31 04:06:35,526 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41607860003908476, 'Total loss': 0.41607860003908476} | train loss {'Reaction outcome loss': 0.11659500535482364, 'Total loss': 0.11659500535482364}
2022-12-31 04:06:35,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:35,526 INFO:     Epoch: 79
2022-12-31 04:06:37,141 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41776717801888785, 'Total loss': 0.41776717801888785} | train loss {'Reaction outcome loss': 0.11944896251857144, 'Total loss': 0.11944896251857144}
2022-12-31 04:06:37,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:37,142 INFO:     Epoch: 80
2022-12-31 04:06:38,755 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4102378137409687, 'Total loss': 0.4102378137409687} | train loss {'Reaction outcome loss': 0.12009552551304283, 'Total loss': 0.12009552551304283}
2022-12-31 04:06:38,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:38,755 INFO:     Epoch: 81
2022-12-31 04:06:40,352 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42253934939702353, 'Total loss': 0.42253934939702353} | train loss {'Reaction outcome loss': 0.11664205090989134, 'Total loss': 0.11664205090989134}
2022-12-31 04:06:40,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:40,352 INFO:     Epoch: 82
2022-12-31 04:06:41,967 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40842228643596173, 'Total loss': 0.40842228643596173} | train loss {'Reaction outcome loss': 0.11021346676870365, 'Total loss': 0.11021346676870365}
2022-12-31 04:06:41,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:41,967 INFO:     Epoch: 83
2022-12-31 04:06:43,579 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41164978394905727, 'Total loss': 0.41164978394905727} | train loss {'Reaction outcome loss': 0.10944666312905504, 'Total loss': 0.10944666312905504}
2022-12-31 04:06:43,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:43,580 INFO:     Epoch: 84
2022-12-31 04:06:45,195 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4459991067647934, 'Total loss': 0.4459991067647934} | train loss {'Reaction outcome loss': 0.10754310282841188, 'Total loss': 0.10754310282841188}
2022-12-31 04:06:45,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:45,195 INFO:     Epoch: 85
2022-12-31 04:06:46,811 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42372758984565734, 'Total loss': 0.42372758984565734} | train loss {'Reaction outcome loss': 0.11195771525576574, 'Total loss': 0.11195771525576574}
2022-12-31 04:06:46,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:46,811 INFO:     Epoch: 86
2022-12-31 04:06:48,416 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42683220009009043, 'Total loss': 0.42683220009009043} | train loss {'Reaction outcome loss': 0.1082013957852491, 'Total loss': 0.1082013957852491}
2022-12-31 04:06:48,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:48,416 INFO:     Epoch: 87
2022-12-31 04:06:50,023 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4029858832557996, 'Total loss': 0.4029858832557996} | train loss {'Reaction outcome loss': 0.11634918619423126, 'Total loss': 0.11634918619423126}
2022-12-31 04:06:50,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:50,024 INFO:     Epoch: 88
2022-12-31 04:06:51,639 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4019893693427245, 'Total loss': 0.4019893693427245} | train loss {'Reaction outcome loss': 0.11059753201055565, 'Total loss': 0.11059753201055565}
2022-12-31 04:06:51,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:51,639 INFO:     Epoch: 89
2022-12-31 04:06:53,270 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45130670766035713, 'Total loss': 0.45130670766035713} | train loss {'Reaction outcome loss': 0.11172977413380532, 'Total loss': 0.11172977413380532}
2022-12-31 04:06:53,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:53,271 INFO:     Epoch: 90
2022-12-31 04:06:54,894 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45507737845182417, 'Total loss': 0.45507737845182417} | train loss {'Reaction outcome loss': 0.11246624667143082, 'Total loss': 0.11246624667143082}
2022-12-31 04:06:54,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:54,894 INFO:     Epoch: 91
2022-12-31 04:06:56,547 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4186305244763692, 'Total loss': 0.4186305244763692} | train loss {'Reaction outcome loss': 0.1097900186007652, 'Total loss': 0.1097900186007652}
2022-12-31 04:06:56,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:56,547 INFO:     Epoch: 92
2022-12-31 04:06:58,189 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4396019488573074, 'Total loss': 0.4396019488573074} | train loss {'Reaction outcome loss': 0.10921084314387591, 'Total loss': 0.10921084314387591}
2022-12-31 04:06:58,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:58,189 INFO:     Epoch: 93
2022-12-31 04:06:59,790 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43110212634007133, 'Total loss': 0.43110212634007133} | train loss {'Reaction outcome loss': 0.1133528299022969, 'Total loss': 0.1133528299022969}
2022-12-31 04:06:59,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:06:59,791 INFO:     Epoch: 94
2022-12-31 04:07:01,393 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44161807248989743, 'Total loss': 0.44161807248989743} | train loss {'Reaction outcome loss': 0.10727541084761602, 'Total loss': 0.10727541084761602}
2022-12-31 04:07:01,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:01,394 INFO:     Epoch: 95
2022-12-31 04:07:03,041 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4010945439338684, 'Total loss': 0.4010945439338684} | train loss {'Reaction outcome loss': 0.1095680716565647, 'Total loss': 0.1095680716565647}
2022-12-31 04:07:03,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:03,041 INFO:     Epoch: 96
2022-12-31 04:07:04,688 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39783509373664855, 'Total loss': 0.39783509373664855} | train loss {'Reaction outcome loss': 0.10517635171294865, 'Total loss': 0.10517635171294865}
2022-12-31 04:07:04,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:04,688 INFO:     Epoch: 97
2022-12-31 04:07:06,335 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4215807100137075, 'Total loss': 0.4215807100137075} | train loss {'Reaction outcome loss': 0.1050108334994501, 'Total loss': 0.1050108334994501}
2022-12-31 04:07:06,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:06,336 INFO:     Epoch: 98
2022-12-31 04:07:07,942 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44843982060750326, 'Total loss': 0.44843982060750326} | train loss {'Reaction outcome loss': 0.1144767217435806, 'Total loss': 0.1144767217435806}
2022-12-31 04:07:07,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:07,942 INFO:     Epoch: 99
2022-12-31 04:07:09,593 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39960509339968364, 'Total loss': 0.39960509339968364} | train loss {'Reaction outcome loss': 0.11204940727130122, 'Total loss': 0.11204940727130122}
2022-12-31 04:07:09,593 INFO:     Best model found after epoch 51 of 100.
2022-12-31 04:07:09,593 INFO:   Done with stage: TRAINING
2022-12-31 04:07:09,593 INFO:   Starting stage: EVALUATION
2022-12-31 04:07:09,730 INFO:   Done with stage: EVALUATION
2022-12-31 04:07:09,730 INFO:   Leaving out SEQ value Fold_1
2022-12-31 04:07:09,743 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 04:07:09,743 INFO:   Starting stage: FEATURE SCALING
2022-12-31 04:07:10,386 INFO:   Done with stage: FEATURE SCALING
2022-12-31 04:07:10,386 INFO:   Starting stage: SCALING TARGETS
2022-12-31 04:07:10,458 INFO:   Done with stage: SCALING TARGETS
2022-12-31 04:07:10,458 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:07:10,458 INFO:     No hyperparam tuning for this model
2022-12-31 04:07:10,458 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:07:10,458 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 04:07:10,459 INFO:     None feature selector for col prot
2022-12-31 04:07:10,459 INFO:     None feature selector for col prot
2022-12-31 04:07:10,459 INFO:     None feature selector for col prot
2022-12-31 04:07:10,460 INFO:     None feature selector for col chem
2022-12-31 04:07:10,460 INFO:     None feature selector for col chem
2022-12-31 04:07:10,460 INFO:     None feature selector for col chem
2022-12-31 04:07:10,460 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 04:07:10,460 INFO:   Starting stage: BUILD MODEL
2022-12-31 04:07:10,462 INFO:     Number of params in model 224011
2022-12-31 04:07:10,465 INFO:   Done with stage: BUILD MODEL
2022-12-31 04:07:10,465 INFO:   Starting stage: TRAINING
2022-12-31 04:07:10,511 INFO:     Val loss before train {'Reaction outcome loss': 0.9796998659769695, 'Total loss': 0.9796998659769695}
2022-12-31 04:07:10,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:10,511 INFO:     Epoch: 0
2022-12-31 04:07:12,120 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5259406914313635, 'Total loss': 0.5259406914313635} | train loss {'Reaction outcome loss': 0.7723712604628862, 'Total loss': 0.7723712604628862}
2022-12-31 04:07:12,121 INFO:     Found new best model at epoch 0
2022-12-31 04:07:12,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:12,122 INFO:     Epoch: 1
2022-12-31 04:07:13,728 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48663172920544945, 'Total loss': 0.48663172920544945} | train loss {'Reaction outcome loss': 0.49627190268170224, 'Total loss': 0.49627190268170224}
2022-12-31 04:07:13,729 INFO:     Found new best model at epoch 1
2022-12-31 04:07:13,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:13,730 INFO:     Epoch: 2
2022-12-31 04:07:15,335 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45664675732453663, 'Total loss': 0.45664675732453663} | train loss {'Reaction outcome loss': 0.4309489433891582, 'Total loss': 0.4309489433891582}
2022-12-31 04:07:15,335 INFO:     Found new best model at epoch 2
2022-12-31 04:07:15,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:15,336 INFO:     Epoch: 3
2022-12-31 04:07:16,932 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.44943481087684634, 'Total loss': 0.44943481087684634} | train loss {'Reaction outcome loss': 0.399686884379735, 'Total loss': 0.399686884379735}
2022-12-31 04:07:16,932 INFO:     Found new best model at epoch 3
2022-12-31 04:07:16,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:16,933 INFO:     Epoch: 4
2022-12-31 04:07:18,541 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4063471456368764, 'Total loss': 0.4063471456368764} | train loss {'Reaction outcome loss': 0.36754599651389747, 'Total loss': 0.36754599651389747}
2022-12-31 04:07:18,541 INFO:     Found new best model at epoch 4
2022-12-31 04:07:18,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:18,542 INFO:     Epoch: 5
2022-12-31 04:07:20,147 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4218675673007965, 'Total loss': 0.4218675673007965} | train loss {'Reaction outcome loss': 0.34777647977436543, 'Total loss': 0.34777647977436543}
2022-12-31 04:07:20,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:20,147 INFO:     Epoch: 6
2022-12-31 04:07:21,752 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4177752484877904, 'Total loss': 0.4177752484877904} | train loss {'Reaction outcome loss': 0.3272706692100224, 'Total loss': 0.3272706692100224}
2022-12-31 04:07:21,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:21,752 INFO:     Epoch: 7
2022-12-31 04:07:23,362 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43280229767163597, 'Total loss': 0.43280229767163597} | train loss {'Reaction outcome loss': 0.307739607187627, 'Total loss': 0.307739607187627}
2022-12-31 04:07:23,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:23,363 INFO:     Epoch: 8
2022-12-31 04:07:24,960 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.444881804784139, 'Total loss': 0.444881804784139} | train loss {'Reaction outcome loss': 0.29370373544575523, 'Total loss': 0.29370373544575523}
2022-12-31 04:07:24,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:24,961 INFO:     Epoch: 9
2022-12-31 04:07:26,567 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45461297035217285, 'Total loss': 0.45461297035217285} | train loss {'Reaction outcome loss': 0.28053884722129274, 'Total loss': 0.28053884722129274}
2022-12-31 04:07:26,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:26,567 INFO:     Epoch: 10
2022-12-31 04:07:28,175 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45320812265078225, 'Total loss': 0.45320812265078225} | train loss {'Reaction outcome loss': 0.26581559230974555, 'Total loss': 0.26581559230974555}
2022-12-31 04:07:28,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:28,175 INFO:     Epoch: 11
2022-12-31 04:07:29,792 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4458911418914795, 'Total loss': 0.4458911418914795} | train loss {'Reaction outcome loss': 0.25725337909194673, 'Total loss': 0.25725337909194673}
2022-12-31 04:07:29,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:29,793 INFO:     Epoch: 12
2022-12-31 04:07:31,403 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46413495441277824, 'Total loss': 0.46413495441277824} | train loss {'Reaction outcome loss': 0.24776249665794145, 'Total loss': 0.24776249665794145}
2022-12-31 04:07:31,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:31,404 INFO:     Epoch: 13
2022-12-31 04:07:33,013 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43825409313042957, 'Total loss': 0.43825409313042957} | train loss {'Reaction outcome loss': 0.23697642118663248, 'Total loss': 0.23697642118663248}
2022-12-31 04:07:33,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:33,013 INFO:     Epoch: 14
2022-12-31 04:07:34,604 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4283300846815109, 'Total loss': 0.4283300846815109} | train loss {'Reaction outcome loss': 0.23245926002842665, 'Total loss': 0.23245926002842665}
2022-12-31 04:07:34,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:34,605 INFO:     Epoch: 15
2022-12-31 04:07:36,211 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4303989549477895, 'Total loss': 0.4303989549477895} | train loss {'Reaction outcome loss': 0.22500494180967773, 'Total loss': 0.22500494180967773}
2022-12-31 04:07:36,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:36,211 INFO:     Epoch: 16
2022-12-31 04:07:37,822 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4174496024847031, 'Total loss': 0.4174496024847031} | train loss {'Reaction outcome loss': 0.21640209294855595, 'Total loss': 0.21640209294855595}
2022-12-31 04:07:37,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:37,823 INFO:     Epoch: 17
2022-12-31 04:07:39,434 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4202548682689667, 'Total loss': 0.4202548682689667} | train loss {'Reaction outcome loss': 0.21154168557484437, 'Total loss': 0.21154168557484437}
2022-12-31 04:07:39,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:39,434 INFO:     Epoch: 18
2022-12-31 04:07:41,062 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4218602607647578, 'Total loss': 0.4218602607647578} | train loss {'Reaction outcome loss': 0.20575217033539267, 'Total loss': 0.20575217033539267}
2022-12-31 04:07:41,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:41,063 INFO:     Epoch: 19
2022-12-31 04:07:42,699 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.411817629635334, 'Total loss': 0.411817629635334} | train loss {'Reaction outcome loss': 0.20508358744482924, 'Total loss': 0.20508358744482924}
2022-12-31 04:07:42,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:42,700 INFO:     Epoch: 20
2022-12-31 04:07:44,298 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44474985003471373, 'Total loss': 0.44474985003471373} | train loss {'Reaction outcome loss': 0.19649361636843124, 'Total loss': 0.19649361636843124}
2022-12-31 04:07:44,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:44,298 INFO:     Epoch: 21
2022-12-31 04:07:45,946 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42556622326374055, 'Total loss': 0.42556622326374055} | train loss {'Reaction outcome loss': 0.19256844258370953, 'Total loss': 0.19256844258370953}
2022-12-31 04:07:45,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:45,946 INFO:     Epoch: 22
2022-12-31 04:07:47,594 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43294249176979066, 'Total loss': 0.43294249176979066} | train loss {'Reaction outcome loss': 0.19018079897891865, 'Total loss': 0.19018079897891865}
2022-12-31 04:07:47,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:47,594 INFO:     Epoch: 23
2022-12-31 04:07:49,202 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4091193546851476, 'Total loss': 0.4091193546851476} | train loss {'Reaction outcome loss': 0.18751563757222933, 'Total loss': 0.18751563757222933}
2022-12-31 04:07:49,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:49,202 INFO:     Epoch: 24
2022-12-31 04:07:50,850 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4451636185248693, 'Total loss': 0.4451636185248693} | train loss {'Reaction outcome loss': 0.18248026241568754, 'Total loss': 0.18248026241568754}
2022-12-31 04:07:50,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:50,850 INFO:     Epoch: 25
2022-12-31 04:07:52,470 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.415418795744578, 'Total loss': 0.415418795744578} | train loss {'Reaction outcome loss': 0.1822695653328169, 'Total loss': 0.1822695653328169}
2022-12-31 04:07:52,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:52,470 INFO:     Epoch: 26
2022-12-31 04:07:54,082 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42804056853055955, 'Total loss': 0.42804056853055955} | train loss {'Reaction outcome loss': 0.17076875913181228, 'Total loss': 0.17076875913181228}
2022-12-31 04:07:54,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:54,083 INFO:     Epoch: 27
2022-12-31 04:07:55,696 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44210334718227384, 'Total loss': 0.44210334718227384} | train loss {'Reaction outcome loss': 0.17060386237049352, 'Total loss': 0.17060386237049352}
2022-12-31 04:07:55,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:55,696 INFO:     Epoch: 28
2022-12-31 04:07:57,311 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44349063535531363, 'Total loss': 0.44349063535531363} | train loss {'Reaction outcome loss': 0.17162641348915486, 'Total loss': 0.17162641348915486}
2022-12-31 04:07:57,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:57,311 INFO:     Epoch: 29
2022-12-31 04:07:58,928 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4462150245904922, 'Total loss': 0.4462150245904922} | train loss {'Reaction outcome loss': 0.16619497962146454, 'Total loss': 0.16619497962146454}
2022-12-31 04:07:58,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:07:58,928 INFO:     Epoch: 30
2022-12-31 04:08:00,539 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44162707527478534, 'Total loss': 0.44162707527478534} | train loss {'Reaction outcome loss': 0.16447156802989052, 'Total loss': 0.16447156802989052}
2022-12-31 04:08:00,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:00,539 INFO:     Epoch: 31
2022-12-31 04:08:02,184 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43516040346585216, 'Total loss': 0.43516040346585216} | train loss {'Reaction outcome loss': 0.16130629521760628, 'Total loss': 0.16130629521760628}
2022-12-31 04:08:02,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:02,185 INFO:     Epoch: 32
2022-12-31 04:08:03,837 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.400220454732577, 'Total loss': 0.400220454732577} | train loss {'Reaction outcome loss': 0.15967116224831038, 'Total loss': 0.15967116224831038}
2022-12-31 04:08:03,837 INFO:     Found new best model at epoch 32
2022-12-31 04:08:03,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:03,838 INFO:     Epoch: 33
2022-12-31 04:08:05,437 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43928864200909934, 'Total loss': 0.43928864200909934} | train loss {'Reaction outcome loss': 0.1561682266081228, 'Total loss': 0.1561682266081228}
2022-12-31 04:08:05,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:05,438 INFO:     Epoch: 34
2022-12-31 04:08:07,090 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44272265434265134, 'Total loss': 0.44272265434265134} | train loss {'Reaction outcome loss': 0.1549910437740576, 'Total loss': 0.1549910437740576}
2022-12-31 04:08:07,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:07,090 INFO:     Epoch: 35
2022-12-31 04:08:08,743 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4566670566797256, 'Total loss': 0.4566670566797256} | train loss {'Reaction outcome loss': 0.15515574092643647, 'Total loss': 0.15515574092643647}
2022-12-31 04:08:08,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:08,743 INFO:     Epoch: 36
2022-12-31 04:08:10,377 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4549028992652893, 'Total loss': 0.4549028992652893} | train loss {'Reaction outcome loss': 0.15414357391342412, 'Total loss': 0.15414357391342412}
2022-12-31 04:08:10,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:10,377 INFO:     Epoch: 37
2022-12-31 04:08:11,990 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43585849106311797, 'Total loss': 0.43585849106311797} | train loss {'Reaction outcome loss': 0.14898575334231892, 'Total loss': 0.14898575334231892}
2022-12-31 04:08:11,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:11,990 INFO:     Epoch: 38
2022-12-31 04:08:13,642 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41483202308105926, 'Total loss': 0.41483202308105926} | train loss {'Reaction outcome loss': 0.150411587327474, 'Total loss': 0.150411587327474}
2022-12-31 04:08:13,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:13,643 INFO:     Epoch: 39
2022-12-31 04:08:15,250 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42982160349686943, 'Total loss': 0.42982160349686943} | train loss {'Reaction outcome loss': 0.15015641541600935, 'Total loss': 0.15015641541600935}
2022-12-31 04:08:15,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:15,251 INFO:     Epoch: 40
2022-12-31 04:08:16,902 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4304091274738312, 'Total loss': 0.4304091274738312} | train loss {'Reaction outcome loss': 0.14430451166075076, 'Total loss': 0.14430451166075076}
2022-12-31 04:08:16,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:16,902 INFO:     Epoch: 41
2022-12-31 04:08:18,512 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45033122301101686, 'Total loss': 0.45033122301101686} | train loss {'Reaction outcome loss': 0.1476950153409347, 'Total loss': 0.1476950153409347}
2022-12-31 04:08:18,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:18,512 INFO:     Epoch: 42
2022-12-31 04:08:20,135 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42328278223673504, 'Total loss': 0.42328278223673504} | train loss {'Reaction outcome loss': 0.14266387522084653, 'Total loss': 0.14266387522084653}
2022-12-31 04:08:20,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:20,136 INFO:     Epoch: 43
2022-12-31 04:08:21,756 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4382005115350088, 'Total loss': 0.4382005115350088} | train loss {'Reaction outcome loss': 0.13890323839762186, 'Total loss': 0.13890323839762186}
2022-12-31 04:08:21,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:21,756 INFO:     Epoch: 44
2022-12-31 04:08:23,364 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40543436457713444, 'Total loss': 0.40543436457713444} | train loss {'Reaction outcome loss': 0.13812783852484703, 'Total loss': 0.13812783852484703}
2022-12-31 04:08:23,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:23,364 INFO:     Epoch: 45
2022-12-31 04:08:24,985 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4550726920366287, 'Total loss': 0.4550726920366287} | train loss {'Reaction outcome loss': 0.1361150508678525, 'Total loss': 0.1361150508678525}
2022-12-31 04:08:24,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:24,986 INFO:     Epoch: 46
2022-12-31 04:08:26,610 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43735129237174986, 'Total loss': 0.43735129237174986} | train loss {'Reaction outcome loss': 0.13994092335516628, 'Total loss': 0.13994092335516628}
2022-12-31 04:08:26,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:26,611 INFO:     Epoch: 47
2022-12-31 04:08:28,220 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4291907777388891, 'Total loss': 0.4291907777388891} | train loss {'Reaction outcome loss': 0.1380187426064925, 'Total loss': 0.1380187426064925}
2022-12-31 04:08:28,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:28,220 INFO:     Epoch: 48
2022-12-31 04:08:29,832 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41384197523196536, 'Total loss': 0.41384197523196536} | train loss {'Reaction outcome loss': 0.13923536637546427, 'Total loss': 0.13923536637546427}
2022-12-31 04:08:29,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:29,832 INFO:     Epoch: 49
2022-12-31 04:08:31,458 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.442282580335935, 'Total loss': 0.442282580335935} | train loss {'Reaction outcome loss': 0.13400169642621745, 'Total loss': 0.13400169642621745}
2022-12-31 04:08:31,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:31,458 INFO:     Epoch: 50
2022-12-31 04:08:33,080 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46154034733772276, 'Total loss': 0.46154034733772276} | train loss {'Reaction outcome loss': 0.1341039339049862, 'Total loss': 0.1341039339049862}
2022-12-31 04:08:33,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:33,081 INFO:     Epoch: 51
2022-12-31 04:08:34,700 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43755231499671937, 'Total loss': 0.43755231499671937} | train loss {'Reaction outcome loss': 0.13548112804083712, 'Total loss': 0.13548112804083712}
2022-12-31 04:08:34,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:34,701 INFO:     Epoch: 52
2022-12-31 04:08:36,323 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42682663003603616, 'Total loss': 0.42682663003603616} | train loss {'Reaction outcome loss': 0.13534443707368507, 'Total loss': 0.13534443707368507}
2022-12-31 04:08:36,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:36,323 INFO:     Epoch: 53
2022-12-31 04:08:37,945 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4244352598985036, 'Total loss': 0.4244352598985036} | train loss {'Reaction outcome loss': 0.13504407845818214, 'Total loss': 0.13504407845818214}
2022-12-31 04:08:37,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:37,945 INFO:     Epoch: 54
2022-12-31 04:08:39,584 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4131662845611572, 'Total loss': 0.4131662845611572} | train loss {'Reaction outcome loss': 0.13108383290245312, 'Total loss': 0.13108383290245312}
2022-12-31 04:08:39,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:39,584 INFO:     Epoch: 55
2022-12-31 04:08:41,241 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4364370763301849, 'Total loss': 0.4364370763301849} | train loss {'Reaction outcome loss': 0.12844988009994374, 'Total loss': 0.12844988009994374}
2022-12-31 04:08:41,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:41,241 INFO:     Epoch: 56
2022-12-31 04:08:42,860 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4557803273200989, 'Total loss': 0.4557803273200989} | train loss {'Reaction outcome loss': 0.12712370993290775, 'Total loss': 0.12712370993290775}
2022-12-31 04:08:42,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:42,860 INFO:     Epoch: 57
2022-12-31 04:08:44,513 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4796457568804423, 'Total loss': 0.4796457568804423} | train loss {'Reaction outcome loss': 0.12470023042308234, 'Total loss': 0.12470023042308234}
2022-12-31 04:08:44,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:44,514 INFO:     Epoch: 58
2022-12-31 04:08:46,129 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4506672070051233, 'Total loss': 0.4506672070051233} | train loss {'Reaction outcome loss': 0.13130743085087215, 'Total loss': 0.13130743085087215}
2022-12-31 04:08:46,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:46,130 INFO:     Epoch: 59
2022-12-31 04:08:47,731 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47116203904151915, 'Total loss': 0.47116203904151915} | train loss {'Reaction outcome loss': 0.12860359175871705, 'Total loss': 0.12860359175871705}
2022-12-31 04:08:47,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:47,731 INFO:     Epoch: 60
2022-12-31 04:08:49,353 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48039506872495014, 'Total loss': 0.48039506872495014} | train loss {'Reaction outcome loss': 0.12916998773809849, 'Total loss': 0.12916998773809849}
2022-12-31 04:08:49,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:49,353 INFO:     Epoch: 61
2022-12-31 04:08:50,978 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4457337290048599, 'Total loss': 0.4457337290048599} | train loss {'Reaction outcome loss': 0.1287286383589308, 'Total loss': 0.1287286383589308}
2022-12-31 04:08:50,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:50,978 INFO:     Epoch: 62
2022-12-31 04:08:52,600 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48524232804775236, 'Total loss': 0.48524232804775236} | train loss {'Reaction outcome loss': 0.12667777754339207, 'Total loss': 0.12667777754339207}
2022-12-31 04:08:52,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:52,600 INFO:     Epoch: 63
2022-12-31 04:08:54,224 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43555403451124824, 'Total loss': 0.43555403451124824} | train loss {'Reaction outcome loss': 0.1273358754693007, 'Total loss': 0.1273358754693007}
2022-12-31 04:08:54,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:54,225 INFO:     Epoch: 64
2022-12-31 04:08:55,839 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4896644373734792, 'Total loss': 0.4896644373734792} | train loss {'Reaction outcome loss': 0.124864176617609, 'Total loss': 0.124864176617609}
2022-12-31 04:08:55,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:55,841 INFO:     Epoch: 65
2022-12-31 04:08:57,467 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4572606886426608, 'Total loss': 0.4572606886426608} | train loss {'Reaction outcome loss': 0.12533929337489072, 'Total loss': 0.12533929337489072}
2022-12-31 04:08:57,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:57,468 INFO:     Epoch: 66
2022-12-31 04:08:59,122 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46716753045717874, 'Total loss': 0.46716753045717874} | train loss {'Reaction outcome loss': 0.123814827125234, 'Total loss': 0.123814827125234}
2022-12-31 04:08:59,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:08:59,122 INFO:     Epoch: 67
2022-12-31 04:09:00,775 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49057987133661907, 'Total loss': 0.49057987133661907} | train loss {'Reaction outcome loss': 0.129145214818486, 'Total loss': 0.129145214818486}
2022-12-31 04:09:00,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:00,776 INFO:     Epoch: 68
2022-12-31 04:09:02,384 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41275239214301107, 'Total loss': 0.41275239214301107} | train loss {'Reaction outcome loss': 0.12708512895203528, 'Total loss': 0.12708512895203528}
2022-12-31 04:09:02,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:02,385 INFO:     Epoch: 69
2022-12-31 04:09:03,994 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44109798868497213, 'Total loss': 0.44109798868497213} | train loss {'Reaction outcome loss': 0.12330364179670009, 'Total loss': 0.12330364179670009}
2022-12-31 04:09:03,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:03,994 INFO:     Epoch: 70
2022-12-31 04:09:05,636 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44896321892738345, 'Total loss': 0.44896321892738345} | train loss {'Reaction outcome loss': 0.12346450977000224, 'Total loss': 0.12346450977000224}
2022-12-31 04:09:05,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:05,636 INFO:     Epoch: 71
2022-12-31 04:09:07,242 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4720048745473226, 'Total loss': 0.4720048745473226} | train loss {'Reaction outcome loss': 0.12391430827156796, 'Total loss': 0.12391430827156796}
2022-12-31 04:09:07,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:07,243 INFO:     Epoch: 72
2022-12-31 04:09:08,896 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44435196816921235, 'Total loss': 0.44435196816921235} | train loss {'Reaction outcome loss': 0.12347081050881777, 'Total loss': 0.12347081050881777}
2022-12-31 04:09:08,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:08,896 INFO:     Epoch: 73
2022-12-31 04:09:10,550 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42771878639856975, 'Total loss': 0.42771878639856975} | train loss {'Reaction outcome loss': 0.12230635597880413, 'Total loss': 0.12230635597880413}
2022-12-31 04:09:10,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:10,551 INFO:     Epoch: 74
2022-12-31 04:09:12,203 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42773503561814624, 'Total loss': 0.42773503561814624} | train loss {'Reaction outcome loss': 0.11631382294390079, 'Total loss': 0.11631382294390079}
2022-12-31 04:09:12,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:12,204 INFO:     Epoch: 75
2022-12-31 04:09:13,858 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44731969237327573, 'Total loss': 0.44731969237327573} | train loss {'Reaction outcome loss': 0.12144917320888353, 'Total loss': 0.12144917320888353}
2022-12-31 04:09:13,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:13,858 INFO:     Epoch: 76
2022-12-31 04:09:15,459 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41133185625076296, 'Total loss': 0.41133185625076296} | train loss {'Reaction outcome loss': 0.11973446101310534, 'Total loss': 0.11973446101310534}
2022-12-31 04:09:15,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:15,460 INFO:     Epoch: 77
2022-12-31 04:09:17,073 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4198255404829979, 'Total loss': 0.4198255404829979} | train loss {'Reaction outcome loss': 0.11817803857321205, 'Total loss': 0.11817803857321205}
2022-12-31 04:09:17,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:17,073 INFO:     Epoch: 78
2022-12-31 04:09:18,688 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41442064742247264, 'Total loss': 0.41442064742247264} | train loss {'Reaction outcome loss': 0.12071078674983315, 'Total loss': 0.12071078674983315}
2022-12-31 04:09:18,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:18,689 INFO:     Epoch: 79
2022-12-31 04:09:20,309 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44404571255048114, 'Total loss': 0.44404571255048114} | train loss {'Reaction outcome loss': 0.12113597939797018, 'Total loss': 0.12113597939797018}
2022-12-31 04:09:20,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:20,310 INFO:     Epoch: 80
2022-12-31 04:09:21,931 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4361013484109814, 'Total loss': 0.4361013484109814} | train loss {'Reaction outcome loss': 0.11702423713367133, 'Total loss': 0.11702423713367133}
2022-12-31 04:09:21,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:21,931 INFO:     Epoch: 81
2022-12-31 04:09:23,547 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45142626464366914, 'Total loss': 0.45142626464366914} | train loss {'Reaction outcome loss': 0.1162260512245248, 'Total loss': 0.1162260512245248}
2022-12-31 04:09:23,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:23,548 INFO:     Epoch: 82
2022-12-31 04:09:25,174 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42998709877332053, 'Total loss': 0.42998709877332053} | train loss {'Reaction outcome loss': 0.11633172105610316, 'Total loss': 0.11633172105610316}
2022-12-31 04:09:25,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:25,174 INFO:     Epoch: 83
2022-12-31 04:09:26,788 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4319018011291822, 'Total loss': 0.4319018011291822} | train loss {'Reaction outcome loss': 0.11403400236043916, 'Total loss': 0.11403400236043916}
2022-12-31 04:09:26,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:26,789 INFO:     Epoch: 84
2022-12-31 04:09:28,401 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4615292410055796, 'Total loss': 0.4615292410055796} | train loss {'Reaction outcome loss': 0.1145873219998431, 'Total loss': 0.1145873219998431}
2022-12-31 04:09:28,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:28,401 INFO:     Epoch: 85
2022-12-31 04:09:30,054 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43661002616087596, 'Total loss': 0.43661002616087596} | train loss {'Reaction outcome loss': 0.11807692582450507, 'Total loss': 0.11807692582450507}
2022-12-31 04:09:30,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:30,054 INFO:     Epoch: 86
2022-12-31 04:09:31,707 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45399445096651714, 'Total loss': 0.45399445096651714} | train loss {'Reaction outcome loss': 0.12782365753804845, 'Total loss': 0.12782365753804845}
2022-12-31 04:09:31,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:31,708 INFO:     Epoch: 87
2022-12-31 04:09:33,318 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44946558972199757, 'Total loss': 0.44946558972199757} | train loss {'Reaction outcome loss': 0.12181023306750359, 'Total loss': 0.12181023306750359}
2022-12-31 04:09:33,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:33,319 INFO:     Epoch: 88
2022-12-31 04:09:34,931 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45860821108023325, 'Total loss': 0.45860821108023325} | train loss {'Reaction outcome loss': 0.11560163538848614, 'Total loss': 0.11560163538848614}
2022-12-31 04:09:34,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:34,932 INFO:     Epoch: 89
2022-12-31 04:09:36,554 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4279498130083084, 'Total loss': 0.4279498130083084} | train loss {'Reaction outcome loss': 0.11153015343516548, 'Total loss': 0.11153015343516548}
2022-12-31 04:09:36,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:36,554 INFO:     Epoch: 90
2022-12-31 04:09:38,173 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45529144058624904, 'Total loss': 0.45529144058624904} | train loss {'Reaction outcome loss': 0.11003774657750326, 'Total loss': 0.11003774657750326}
2022-12-31 04:09:38,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:38,174 INFO:     Epoch: 91
2022-12-31 04:09:39,790 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45492494602998096, 'Total loss': 0.45492494602998096} | train loss {'Reaction outcome loss': 0.11582263539388885, 'Total loss': 0.11582263539388885}
2022-12-31 04:09:39,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:39,790 INFO:     Epoch: 92
2022-12-31 04:09:41,398 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42711006303628285, 'Total loss': 0.42711006303628285} | train loss {'Reaction outcome loss': 0.11245691533757876, 'Total loss': 0.11245691533757876}
2022-12-31 04:09:41,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:41,398 INFO:     Epoch: 93
2022-12-31 04:09:43,025 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45697938998540244, 'Total loss': 0.45697938998540244} | train loss {'Reaction outcome loss': 0.1099335748479654, 'Total loss': 0.1099335748479654}
2022-12-31 04:09:43,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:43,025 INFO:     Epoch: 94
2022-12-31 04:09:44,677 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4320721536874771, 'Total loss': 0.4320721536874771} | train loss {'Reaction outcome loss': 0.11656171121858876, 'Total loss': 0.11656171121858876}
2022-12-31 04:09:44,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:44,677 INFO:     Epoch: 95
2022-12-31 04:09:46,330 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4641682839021087, 'Total loss': 0.4641682839021087} | train loss {'Reaction outcome loss': 0.11376928797086877, 'Total loss': 0.11376928797086877}
2022-12-31 04:09:46,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:46,331 INFO:     Epoch: 96
2022-12-31 04:09:47,935 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40603323727846147, 'Total loss': 0.40603323727846147} | train loss {'Reaction outcome loss': 0.11552403052422443, 'Total loss': 0.11552403052422443}
2022-12-31 04:09:47,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:47,935 INFO:     Epoch: 97
2022-12-31 04:09:49,588 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4490004527072112, 'Total loss': 0.4490004527072112} | train loss {'Reaction outcome loss': 0.11505356873895456, 'Total loss': 0.11505356873895456}
2022-12-31 04:09:49,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:49,588 INFO:     Epoch: 98
2022-12-31 04:09:51,226 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4028799260656039, 'Total loss': 0.4028799260656039} | train loss {'Reaction outcome loss': 0.1121506193418219, 'Total loss': 0.1121506193418219}
2022-12-31 04:09:51,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:51,226 INFO:     Epoch: 99
2022-12-31 04:09:52,857 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4246878087520599, 'Total loss': 0.4246878087520599} | train loss {'Reaction outcome loss': 0.11318327441733385, 'Total loss': 0.11318327441733385}
2022-12-31 04:09:52,857 INFO:     Best model found after epoch 33 of 100.
2022-12-31 04:09:52,857 INFO:   Done with stage: TRAINING
2022-12-31 04:09:52,857 INFO:   Starting stage: EVALUATION
2022-12-31 04:09:52,993 INFO:   Done with stage: EVALUATION
2022-12-31 04:09:52,993 INFO:   Leaving out SEQ value Fold_2
2022-12-31 04:09:53,006 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 04:09:53,006 INFO:   Starting stage: FEATURE SCALING
2022-12-31 04:09:53,656 INFO:   Done with stage: FEATURE SCALING
2022-12-31 04:09:53,656 INFO:   Starting stage: SCALING TARGETS
2022-12-31 04:09:53,728 INFO:   Done with stage: SCALING TARGETS
2022-12-31 04:09:53,728 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:09:53,728 INFO:     No hyperparam tuning for this model
2022-12-31 04:09:53,728 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:09:53,728 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 04:09:53,729 INFO:     None feature selector for col prot
2022-12-31 04:09:53,729 INFO:     None feature selector for col prot
2022-12-31 04:09:53,729 INFO:     None feature selector for col prot
2022-12-31 04:09:53,730 INFO:     None feature selector for col chem
2022-12-31 04:09:53,730 INFO:     None feature selector for col chem
2022-12-31 04:09:53,730 INFO:     None feature selector for col chem
2022-12-31 04:09:53,730 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 04:09:53,730 INFO:   Starting stage: BUILD MODEL
2022-12-31 04:09:53,732 INFO:     Number of params in model 224011
2022-12-31 04:09:53,735 INFO:   Done with stage: BUILD MODEL
2022-12-31 04:09:53,735 INFO:   Starting stage: TRAINING
2022-12-31 04:09:53,779 INFO:     Val loss before train {'Reaction outcome loss': 0.9595138867696126, 'Total loss': 0.9595138867696126}
2022-12-31 04:09:53,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:53,779 INFO:     Epoch: 0
2022-12-31 04:09:55,391 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5894472380479177, 'Total loss': 0.5894472380479177} | train loss {'Reaction outcome loss': 0.7690727654574574, 'Total loss': 0.7690727654574574}
2022-12-31 04:09:55,392 INFO:     Found new best model at epoch 0
2022-12-31 04:09:55,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:55,393 INFO:     Epoch: 1
2022-12-31 04:09:57,002 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49498817523320515, 'Total loss': 0.49498817523320515} | train loss {'Reaction outcome loss': 0.5185731158539504, 'Total loss': 0.5185731158539504}
2022-12-31 04:09:57,003 INFO:     Found new best model at epoch 1
2022-12-31 04:09:57,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:57,004 INFO:     Epoch: 2
2022-12-31 04:09:58,668 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4716501633326213, 'Total loss': 0.4716501633326213} | train loss {'Reaction outcome loss': 0.44787495689208456, 'Total loss': 0.44787495689208456}
2022-12-31 04:09:58,668 INFO:     Found new best model at epoch 2
2022-12-31 04:09:58,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:09:58,669 INFO:     Epoch: 3
2022-12-31 04:10:00,277 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4741461992263794, 'Total loss': 0.4741461992263794} | train loss {'Reaction outcome loss': 0.4128848029759483, 'Total loss': 0.4128848029759483}
2022-12-31 04:10:00,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:00,278 INFO:     Epoch: 4
2022-12-31 04:10:01,937 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45603214104970297, 'Total loss': 0.45603214104970297} | train loss {'Reaction outcome loss': 0.39531311496714316, 'Total loss': 0.39531311496714316}
2022-12-31 04:10:01,937 INFO:     Found new best model at epoch 4
2022-12-31 04:10:01,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:01,938 INFO:     Epoch: 5
2022-12-31 04:10:03,549 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.42416625618934634, 'Total loss': 0.42416625618934634} | train loss {'Reaction outcome loss': 0.36251048781517625, 'Total loss': 0.36251048781517625}
2022-12-31 04:10:03,550 INFO:     Found new best model at epoch 5
2022-12-31 04:10:03,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:03,551 INFO:     Epoch: 6
2022-12-31 04:10:05,216 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47136500279108684, 'Total loss': 0.47136500279108684} | train loss {'Reaction outcome loss': 0.3439108159682423, 'Total loss': 0.3439108159682423}
2022-12-31 04:10:05,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:05,217 INFO:     Epoch: 7
2022-12-31 04:10:06,881 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47420274615287783, 'Total loss': 0.47420274615287783} | train loss {'Reaction outcome loss': 0.32789273125429946, 'Total loss': 0.32789273125429946}
2022-12-31 04:10:06,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:06,881 INFO:     Epoch: 8
2022-12-31 04:10:08,497 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4298763503630956, 'Total loss': 0.4298763503630956} | train loss {'Reaction outcome loss': 0.31126722399631696, 'Total loss': 0.31126722399631696}
2022-12-31 04:10:08,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:08,497 INFO:     Epoch: 9
2022-12-31 04:10:10,114 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4246283533672492, 'Total loss': 0.4246283533672492} | train loss {'Reaction outcome loss': 0.29392817527506215, 'Total loss': 0.29392817527506215}
2022-12-31 04:10:10,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:10,114 INFO:     Epoch: 10
2022-12-31 04:10:11,745 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.427558571100235, 'Total loss': 0.427558571100235} | train loss {'Reaction outcome loss': 0.28435962071660836, 'Total loss': 0.28435962071660836}
2022-12-31 04:10:11,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:11,746 INFO:     Epoch: 11
2022-12-31 04:10:13,379 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45569759955008826, 'Total loss': 0.45569759955008826} | train loss {'Reaction outcome loss': 0.2681729529604522, 'Total loss': 0.2681729529604522}
2022-12-31 04:10:13,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:13,379 INFO:     Epoch: 12
2022-12-31 04:10:15,012 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43352295756340026, 'Total loss': 0.43352295756340026} | train loss {'Reaction outcome loss': 0.2599751737248827, 'Total loss': 0.2599751737248827}
2022-12-31 04:10:15,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:15,013 INFO:     Epoch: 13
2022-12-31 04:10:16,646 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.461090745528539, 'Total loss': 0.461090745528539} | train loss {'Reaction outcome loss': 0.2514302094831415, 'Total loss': 0.2514302094831415}
2022-12-31 04:10:16,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:16,646 INFO:     Epoch: 14
2022-12-31 04:10:18,272 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44819557170073193, 'Total loss': 0.44819557170073193} | train loss {'Reaction outcome loss': 0.24101022840319353, 'Total loss': 0.24101022840319353}
2022-12-31 04:10:18,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:18,272 INFO:     Epoch: 15
2022-12-31 04:10:19,896 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4692690551280975, 'Total loss': 0.4692690551280975} | train loss {'Reaction outcome loss': 0.2347556958050953, 'Total loss': 0.2347556958050953}
2022-12-31 04:10:19,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:19,896 INFO:     Epoch: 16
2022-12-31 04:10:21,528 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49089097579320273, 'Total loss': 0.49089097579320273} | train loss {'Reaction outcome loss': 0.22638700505721962, 'Total loss': 0.22638700505721962}
2022-12-31 04:10:21,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:21,529 INFO:     Epoch: 17
2022-12-31 04:10:23,163 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4769687165816625, 'Total loss': 0.4769687165816625} | train loss {'Reaction outcome loss': 0.21991307477878433, 'Total loss': 0.21991307477878433}
2022-12-31 04:10:23,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:23,164 INFO:     Epoch: 18
2022-12-31 04:10:24,798 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4663411669433117, 'Total loss': 0.4663411669433117} | train loss {'Reaction outcome loss': 0.2172931627740753, 'Total loss': 0.2172931627740753}
2022-12-31 04:10:24,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:24,798 INFO:     Epoch: 19
2022-12-31 04:10:26,429 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44725355108579, 'Total loss': 0.44725355108579} | train loss {'Reaction outcome loss': 0.21405550603336398, 'Total loss': 0.21405550603336398}
2022-12-31 04:10:26,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:26,429 INFO:     Epoch: 20
2022-12-31 04:10:28,043 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4657829523086548, 'Total loss': 0.4657829523086548} | train loss {'Reaction outcome loss': 0.21578128507784297, 'Total loss': 0.21578128507784297}
2022-12-31 04:10:28,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:28,045 INFO:     Epoch: 21
2022-12-31 04:10:29,679 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4806543548901876, 'Total loss': 0.4806543548901876} | train loss {'Reaction outcome loss': 0.20220923509180505, 'Total loss': 0.20220923509180505}
2022-12-31 04:10:29,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:29,679 INFO:     Epoch: 22
2022-12-31 04:10:31,313 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4896166662375132, 'Total loss': 0.4896166662375132} | train loss {'Reaction outcome loss': 0.19746055546473118, 'Total loss': 0.19746055546473118}
2022-12-31 04:10:31,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:31,313 INFO:     Epoch: 23
2022-12-31 04:10:32,946 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4957066188255946, 'Total loss': 0.4957066188255946} | train loss {'Reaction outcome loss': 0.19323336548887937, 'Total loss': 0.19323336548887937}
2022-12-31 04:10:32,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:32,946 INFO:     Epoch: 24
2022-12-31 04:10:34,579 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.502102987964948, 'Total loss': 0.502102987964948} | train loss {'Reaction outcome loss': 0.18671101815509272, 'Total loss': 0.18671101815509272}
2022-12-31 04:10:34,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:34,580 INFO:     Epoch: 25
2022-12-31 04:10:36,203 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5047794818878174, 'Total loss': 0.5047794818878174} | train loss {'Reaction outcome loss': 0.18325699306455057, 'Total loss': 0.18325699306455057}
2022-12-31 04:10:36,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:36,203 INFO:     Epoch: 26
2022-12-31 04:10:37,828 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5040056476990382, 'Total loss': 0.5040056476990382} | train loss {'Reaction outcome loss': 0.17676798376065772, 'Total loss': 0.17676798376065772}
2022-12-31 04:10:37,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:37,828 INFO:     Epoch: 27
2022-12-31 04:10:39,461 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4757608100771904, 'Total loss': 0.4757608100771904} | train loss {'Reaction outcome loss': 0.1742259626077704, 'Total loss': 0.1742259626077704}
2022-12-31 04:10:39,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:39,461 INFO:     Epoch: 28
2022-12-31 04:10:41,094 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4756321628888448, 'Total loss': 0.4756321628888448} | train loss {'Reaction outcome loss': 0.1730735829522651, 'Total loss': 0.1730735829522651}
2022-12-31 04:10:41,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:41,094 INFO:     Epoch: 29
2022-12-31 04:10:42,723 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4783598303794861, 'Total loss': 0.4783598303794861} | train loss {'Reaction outcome loss': 0.17141767636454408, 'Total loss': 0.17141767636454408}
2022-12-31 04:10:42,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:42,723 INFO:     Epoch: 30
2022-12-31 04:10:44,354 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4603304125368595, 'Total loss': 0.4603304125368595} | train loss {'Reaction outcome loss': 0.17035218553138437, 'Total loss': 0.17035218553138437}
2022-12-31 04:10:44,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:44,354 INFO:     Epoch: 31
2022-12-31 04:10:45,967 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49957904815673826, 'Total loss': 0.49957904815673826} | train loss {'Reaction outcome loss': 0.16291963384129052, 'Total loss': 0.16291963384129052}
2022-12-31 04:10:45,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:45,968 INFO:     Epoch: 32
2022-12-31 04:10:47,580 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47514594793319703, 'Total loss': 0.47514594793319703} | train loss {'Reaction outcome loss': 0.16486750080830592, 'Total loss': 0.16486750080830592}
2022-12-31 04:10:47,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:47,581 INFO:     Epoch: 33
2022-12-31 04:10:49,198 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5010061532258987, 'Total loss': 0.5010061532258987} | train loss {'Reaction outcome loss': 0.15824539756969266, 'Total loss': 0.15824539756969266}
2022-12-31 04:10:49,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:49,198 INFO:     Epoch: 34
2022-12-31 04:10:50,863 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.442447097102801, 'Total loss': 0.442447097102801} | train loss {'Reaction outcome loss': 0.16208309058500137, 'Total loss': 0.16208309058500137}
2022-12-31 04:10:50,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:50,864 INFO:     Epoch: 35
2022-12-31 04:10:52,530 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49795332153638205, 'Total loss': 0.49795332153638205} | train loss {'Reaction outcome loss': 0.16195343531823406, 'Total loss': 0.16195343531823406}
2022-12-31 04:10:52,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:52,530 INFO:     Epoch: 36
2022-12-31 04:10:54,155 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47335169514020287, 'Total loss': 0.47335169514020287} | train loss {'Reaction outcome loss': 0.1755189479369184, 'Total loss': 0.1755189479369184}
2022-12-31 04:10:54,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:54,155 INFO:     Epoch: 37
2022-12-31 04:10:55,791 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49423982898394264, 'Total loss': 0.49423982898394264} | train loss {'Reaction outcome loss': 0.1775732336640088, 'Total loss': 0.1775732336640088}
2022-12-31 04:10:55,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:55,791 INFO:     Epoch: 38
2022-12-31 04:10:57,456 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4946622669696808, 'Total loss': 0.4946622669696808} | train loss {'Reaction outcome loss': 0.17400165502753542, 'Total loss': 0.17400165502753542}
2022-12-31 04:10:57,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:57,457 INFO:     Epoch: 39
2022-12-31 04:10:59,121 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.492159765958786, 'Total loss': 0.492159765958786} | train loss {'Reaction outcome loss': 0.14921835652750445, 'Total loss': 0.14921835652750445}
2022-12-31 04:10:59,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:10:59,123 INFO:     Epoch: 40
2022-12-31 04:11:00,740 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47042137483755747, 'Total loss': 0.47042137483755747} | train loss {'Reaction outcome loss': 0.14704794863026083, 'Total loss': 0.14704794863026083}
2022-12-31 04:11:00,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:00,740 INFO:     Epoch: 41
2022-12-31 04:11:02,405 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4749613583087921, 'Total loss': 0.4749613583087921} | train loss {'Reaction outcome loss': 0.14267611269758124, 'Total loss': 0.14267611269758124}
2022-12-31 04:11:02,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:02,405 INFO:     Epoch: 42
2022-12-31 04:11:04,037 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4692966043949127, 'Total loss': 0.4692966043949127} | train loss {'Reaction outcome loss': 0.1441294237282937, 'Total loss': 0.1441294237282937}
2022-12-31 04:11:04,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:04,037 INFO:     Epoch: 43
2022-12-31 04:11:05,652 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5115631957848866, 'Total loss': 0.5115631957848866} | train loss {'Reaction outcome loss': 0.1400632781466508, 'Total loss': 0.1400632781466508}
2022-12-31 04:11:05,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:05,653 INFO:     Epoch: 44
2022-12-31 04:11:07,277 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47183186014493306, 'Total loss': 0.47183186014493306} | train loss {'Reaction outcome loss': 0.13949186823573773, 'Total loss': 0.13949186823573773}
2022-12-31 04:11:07,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:07,278 INFO:     Epoch: 45
2022-12-31 04:11:08,901 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4734914501508077, 'Total loss': 0.4734914501508077} | train loss {'Reaction outcome loss': 0.14067976159181536, 'Total loss': 0.14067976159181536}
2022-12-31 04:11:08,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:08,902 INFO:     Epoch: 46
2022-12-31 04:11:10,527 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4924023648103078, 'Total loss': 0.4924023648103078} | train loss {'Reaction outcome loss': 0.13724839915911338, 'Total loss': 0.13724839915911338}
2022-12-31 04:11:10,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:10,527 INFO:     Epoch: 47
2022-12-31 04:11:12,152 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48626586894194285, 'Total loss': 0.48626586894194285} | train loss {'Reaction outcome loss': 0.13759374551944717, 'Total loss': 0.13759374551944717}
2022-12-31 04:11:12,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:12,153 INFO:     Epoch: 48
2022-12-31 04:11:13,762 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46385556558767954, 'Total loss': 0.46385556558767954} | train loss {'Reaction outcome loss': 0.13703093909493147, 'Total loss': 0.13703093909493147}
2022-12-31 04:11:13,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:13,762 INFO:     Epoch: 49
2022-12-31 04:11:15,427 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48489882151285807, 'Total loss': 0.48489882151285807} | train loss {'Reaction outcome loss': 0.133476279803504, 'Total loss': 0.133476279803504}
2022-12-31 04:11:15,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:15,427 INFO:     Epoch: 50
2022-12-31 04:11:17,041 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.493698858221372, 'Total loss': 0.493698858221372} | train loss {'Reaction outcome loss': 0.1359680269750348, 'Total loss': 0.1359680269750348}
2022-12-31 04:11:17,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:17,041 INFO:     Epoch: 51
2022-12-31 04:11:18,706 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47415232956409453, 'Total loss': 0.47415232956409453} | train loss {'Reaction outcome loss': 0.14365498110473182, 'Total loss': 0.14365498110473182}
2022-12-31 04:11:18,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:18,707 INFO:     Epoch: 52
2022-12-31 04:11:20,325 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4925418198108673, 'Total loss': 0.4925418198108673} | train loss {'Reaction outcome loss': 0.12912538611166435, 'Total loss': 0.12912538611166435}
2022-12-31 04:11:20,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:20,325 INFO:     Epoch: 53
2022-12-31 04:11:21,974 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4665575395027796, 'Total loss': 0.4665575395027796} | train loss {'Reaction outcome loss': 0.1293958096751906, 'Total loss': 0.1293958096751906}
2022-12-31 04:11:21,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:21,975 INFO:     Epoch: 54
2022-12-31 04:11:23,584 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45974868535995483, 'Total loss': 0.45974868535995483} | train loss {'Reaction outcome loss': 0.13018821329740973, 'Total loss': 0.13018821329740973}
2022-12-31 04:11:23,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:23,585 INFO:     Epoch: 55
2022-12-31 04:11:25,249 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5124949057896931, 'Total loss': 0.5124949057896931} | train loss {'Reaction outcome loss': 0.12741885353703317, 'Total loss': 0.12741885353703317}
2022-12-31 04:11:25,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:25,249 INFO:     Epoch: 56
2022-12-31 04:11:26,871 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4736166998744011, 'Total loss': 0.4736166998744011} | train loss {'Reaction outcome loss': 0.12820565199945122, 'Total loss': 0.12820565199945122}
2022-12-31 04:11:26,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:26,871 INFO:     Epoch: 57
2022-12-31 04:11:28,534 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4844969093799591, 'Total loss': 0.4844969093799591} | train loss {'Reaction outcome loss': 0.1297807348400702, 'Total loss': 0.1297807348400702}
2022-12-31 04:11:28,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:28,534 INFO:     Epoch: 58
2022-12-31 04:11:30,194 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4927101155122121, 'Total loss': 0.4927101155122121} | train loss {'Reaction outcome loss': 0.12788370930636542, 'Total loss': 0.12788370930636542}
2022-12-31 04:11:30,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:30,195 INFO:     Epoch: 59
2022-12-31 04:11:31,810 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4851026306549708, 'Total loss': 0.4851026306549708} | train loss {'Reaction outcome loss': 0.12620733406889695, 'Total loss': 0.12620733406889695}
2022-12-31 04:11:31,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:31,811 INFO:     Epoch: 60
2022-12-31 04:11:33,425 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49548078974088033, 'Total loss': 0.49548078974088033} | train loss {'Reaction outcome loss': 0.12774468181347745, 'Total loss': 0.12774468181347745}
2022-12-31 04:11:33,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:33,426 INFO:     Epoch: 61
2022-12-31 04:11:35,047 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5244281113147735, 'Total loss': 0.5244281113147735} | train loss {'Reaction outcome loss': 0.13114869295943365, 'Total loss': 0.13114869295943365}
2022-12-31 04:11:35,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:35,047 INFO:     Epoch: 62
2022-12-31 04:11:36,668 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48542458812395733, 'Total loss': 0.48542458812395733} | train loss {'Reaction outcome loss': 0.1479284573910975, 'Total loss': 0.1479284573910975}
2022-12-31 04:11:36,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:36,669 INFO:     Epoch: 63
2022-12-31 04:11:38,291 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48018090923627216, 'Total loss': 0.48018090923627216} | train loss {'Reaction outcome loss': 0.12431708319185207, 'Total loss': 0.12431708319185207}
2022-12-31 04:11:38,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:38,291 INFO:     Epoch: 64
2022-12-31 04:11:39,908 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47225720683733624, 'Total loss': 0.47225720683733624} | train loss {'Reaction outcome loss': 0.12394532781141554, 'Total loss': 0.12394532781141554}
2022-12-31 04:11:39,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:39,908 INFO:     Epoch: 65
2022-12-31 04:11:41,525 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4862096031506856, 'Total loss': 0.4862096031506856} | train loss {'Reaction outcome loss': 0.11928482130673913, 'Total loss': 0.11928482130673913}
2022-12-31 04:11:41,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:41,525 INFO:     Epoch: 66
2022-12-31 04:11:43,152 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4776531229416529, 'Total loss': 0.4776531229416529} | train loss {'Reaction outcome loss': 0.12176579372464692, 'Total loss': 0.12176579372464692}
2022-12-31 04:11:43,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:43,152 INFO:     Epoch: 67
2022-12-31 04:11:44,777 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4911142150561015, 'Total loss': 0.4911142150561015} | train loss {'Reaction outcome loss': 0.12144566660790868, 'Total loss': 0.12144566660790868}
2022-12-31 04:11:44,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:44,777 INFO:     Epoch: 68
2022-12-31 04:11:46,402 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4958125253518422, 'Total loss': 0.4958125253518422} | train loss {'Reaction outcome loss': 0.1226188624741685, 'Total loss': 0.1226188624741685}
2022-12-31 04:11:46,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:46,403 INFO:     Epoch: 69
2022-12-31 04:11:48,031 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4777147680521011, 'Total loss': 0.4777147680521011} | train loss {'Reaction outcome loss': 0.12163869321069586, 'Total loss': 0.12163869321069586}
2022-12-31 04:11:48,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:48,031 INFO:     Epoch: 70
2022-12-31 04:11:49,647 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4995998660723368, 'Total loss': 0.4995998660723368} | train loss {'Reaction outcome loss': 0.11603911684157894, 'Total loss': 0.11603911684157894}
2022-12-31 04:11:49,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:49,648 INFO:     Epoch: 71
2022-12-31 04:11:51,263 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4725824773311615, 'Total loss': 0.4725824773311615} | train loss {'Reaction outcome loss': 0.12164955059457841, 'Total loss': 0.12164955059457841}
2022-12-31 04:11:51,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:51,263 INFO:     Epoch: 72
2022-12-31 04:11:52,889 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5125904659430186, 'Total loss': 0.5125904659430186} | train loss {'Reaction outcome loss': 0.12418939984079612, 'Total loss': 0.12418939984079612}
2022-12-31 04:11:52,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:52,889 INFO:     Epoch: 73
2022-12-31 04:11:54,514 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5260209520657857, 'Total loss': 0.5260209520657857} | train loss {'Reaction outcome loss': 0.1236603110077788, 'Total loss': 0.1236603110077788}
2022-12-31 04:11:54,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:54,515 INFO:     Epoch: 74
2022-12-31 04:11:56,139 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4890774339437485, 'Total loss': 0.4890774339437485} | train loss {'Reaction outcome loss': 0.13143933976770958, 'Total loss': 0.13143933976770958}
2022-12-31 04:11:56,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:56,140 INFO:     Epoch: 75
2022-12-31 04:11:57,758 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48807196219762167, 'Total loss': 0.48807196219762167} | train loss {'Reaction outcome loss': 0.12847745610691863, 'Total loss': 0.12847745610691863}
2022-12-31 04:11:57,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:57,759 INFO:     Epoch: 76
2022-12-31 04:11:59,371 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4814489305019379, 'Total loss': 0.4814489305019379} | train loss {'Reaction outcome loss': 0.11598419302543439, 'Total loss': 0.11598419302543439}
2022-12-31 04:11:59,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:11:59,371 INFO:     Epoch: 77
2022-12-31 04:12:00,996 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5096502939860026, 'Total loss': 0.5096502939860026} | train loss {'Reaction outcome loss': 0.11611077914088694, 'Total loss': 0.11611077914088694}
2022-12-31 04:12:00,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:00,996 INFO:     Epoch: 78
2022-12-31 04:12:02,619 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5273598710695903, 'Total loss': 0.5273598710695903} | train loss {'Reaction outcome loss': 0.12053212554694281, 'Total loss': 0.12053212554694281}
2022-12-31 04:12:02,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:02,619 INFO:     Epoch: 79
2022-12-31 04:12:04,241 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5342467198769252, 'Total loss': 0.5342467198769252} | train loss {'Reaction outcome loss': 0.11714451258223457, 'Total loss': 0.11714451258223457}
2022-12-31 04:12:04,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:04,241 INFO:     Epoch: 80
2022-12-31 04:12:05,862 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.491902764638265, 'Total loss': 0.491902764638265} | train loss {'Reaction outcome loss': 0.11609133995269709, 'Total loss': 0.11609133995269709}
2022-12-31 04:12:05,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:05,864 INFO:     Epoch: 81
2022-12-31 04:12:07,488 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4936553478240967, 'Total loss': 0.4936553478240967} | train loss {'Reaction outcome loss': 0.11889465209062927, 'Total loss': 0.11889465209062927}
2022-12-31 04:12:07,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:07,488 INFO:     Epoch: 82
2022-12-31 04:12:09,110 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4818477292855581, 'Total loss': 0.4818477292855581} | train loss {'Reaction outcome loss': 0.11807706985693611, 'Total loss': 0.11807706985693611}
2022-12-31 04:12:09,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:09,111 INFO:     Epoch: 83
2022-12-31 04:12:10,771 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.525990613301595, 'Total loss': 0.525990613301595} | train loss {'Reaction outcome loss': 0.1175281464567651, 'Total loss': 0.1175281464567651}
2022-12-31 04:12:10,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:10,771 INFO:     Epoch: 84
2022-12-31 04:12:12,430 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47880849639574685, 'Total loss': 0.47880849639574685} | train loss {'Reaction outcome loss': 0.12128693312389668, 'Total loss': 0.12128693312389668}
2022-12-31 04:12:12,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:12,431 INFO:     Epoch: 85
2022-12-31 04:12:14,046 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4802316923936208, 'Total loss': 0.4802316923936208} | train loss {'Reaction outcome loss': 0.11741678056178911, 'Total loss': 0.11741678056178911}
2022-12-31 04:12:14,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:14,046 INFO:     Epoch: 86
2022-12-31 04:12:15,706 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5088798751433691, 'Total loss': 0.5088798751433691} | train loss {'Reaction outcome loss': 0.11491384781033233, 'Total loss': 0.11491384781033233}
2022-12-31 04:12:15,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:15,706 INFO:     Epoch: 87
2022-12-31 04:12:17,349 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4943070183197657, 'Total loss': 0.4943070183197657} | train loss {'Reaction outcome loss': 0.11182557716898188, 'Total loss': 0.11182557716898188}
2022-12-31 04:12:17,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:17,349 INFO:     Epoch: 88
2022-12-31 04:12:18,990 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5377258221308391, 'Total loss': 0.5377258221308391} | train loss {'Reaction outcome loss': 0.1124650566784692, 'Total loss': 0.1124650566784692}
2022-12-31 04:12:18,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:18,990 INFO:     Epoch: 89
2022-12-31 04:12:20,605 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4906992793083191, 'Total loss': 0.4906992793083191} | train loss {'Reaction outcome loss': 0.1125503044889268, 'Total loss': 0.1125503044889268}
2022-12-31 04:12:20,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:20,606 INFO:     Epoch: 90
2022-12-31 04:12:22,221 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47834455768267314, 'Total loss': 0.47834455768267314} | train loss {'Reaction outcome loss': 0.11440154277754144, 'Total loss': 0.11440154277754144}
2022-12-31 04:12:22,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:22,221 INFO:     Epoch: 91
2022-12-31 04:12:23,836 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4868962486584981, 'Total loss': 0.4868962486584981} | train loss {'Reaction outcome loss': 0.11596052804093958, 'Total loss': 0.11596052804093958}
2022-12-31 04:12:23,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:23,836 INFO:     Epoch: 92
2022-12-31 04:12:25,446 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48129939536253613, 'Total loss': 0.48129939536253613} | train loss {'Reaction outcome loss': 0.11449429168488756, 'Total loss': 0.11449429168488756}
2022-12-31 04:12:25,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:25,447 INFO:     Epoch: 93
2022-12-31 04:12:27,064 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4648043046394984, 'Total loss': 0.4648043046394984} | train loss {'Reaction outcome loss': 0.11921606442964454, 'Total loss': 0.11921606442964454}
2022-12-31 04:12:27,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:27,064 INFO:     Epoch: 94
2022-12-31 04:12:28,679 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4857614318529765, 'Total loss': 0.4857614318529765} | train loss {'Reaction outcome loss': 0.11406385188024286, 'Total loss': 0.11406385188024286}
2022-12-31 04:12:28,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:28,679 INFO:     Epoch: 95
2022-12-31 04:12:30,292 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5059629052877426, 'Total loss': 0.5059629052877426} | train loss {'Reaction outcome loss': 0.112333069083895, 'Total loss': 0.112333069083895}
2022-12-31 04:12:30,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:30,292 INFO:     Epoch: 96
2022-12-31 04:12:31,904 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4867530703544617, 'Total loss': 0.4867530703544617} | train loss {'Reaction outcome loss': 0.12482459027123169, 'Total loss': 0.12482459027123169}
2022-12-31 04:12:31,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:31,904 INFO:     Epoch: 97
2022-12-31 04:12:33,517 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4854158749183019, 'Total loss': 0.4854158749183019} | train loss {'Reaction outcome loss': 0.1127981012531023, 'Total loss': 0.1127981012531023}
2022-12-31 04:12:33,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:33,517 INFO:     Epoch: 98
2022-12-31 04:12:35,127 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.494078129529953, 'Total loss': 0.494078129529953} | train loss {'Reaction outcome loss': 0.11155342648339354, 'Total loss': 0.11155342648339354}
2022-12-31 04:12:35,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:35,127 INFO:     Epoch: 99
2022-12-31 04:12:36,742 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.512221763531367, 'Total loss': 0.512221763531367} | train loss {'Reaction outcome loss': 0.10897595082586622, 'Total loss': 0.10897595082586622}
2022-12-31 04:12:36,742 INFO:     Best model found after epoch 6 of 100.
2022-12-31 04:12:36,742 INFO:   Done with stage: TRAINING
2022-12-31 04:12:36,742 INFO:   Starting stage: EVALUATION
2022-12-31 04:12:36,874 INFO:   Done with stage: EVALUATION
2022-12-31 04:12:36,875 INFO:   Leaving out SEQ value Fold_3
2022-12-31 04:12:36,887 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 04:12:36,888 INFO:   Starting stage: FEATURE SCALING
2022-12-31 04:12:37,536 INFO:   Done with stage: FEATURE SCALING
2022-12-31 04:12:37,544 INFO:   Starting stage: SCALING TARGETS
2022-12-31 04:12:37,616 INFO:   Done with stage: SCALING TARGETS
2022-12-31 04:12:37,616 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:12:37,616 INFO:     No hyperparam tuning for this model
2022-12-31 04:12:37,616 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:12:37,616 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 04:12:37,617 INFO:     None feature selector for col prot
2022-12-31 04:12:37,617 INFO:     None feature selector for col prot
2022-12-31 04:12:37,617 INFO:     None feature selector for col prot
2022-12-31 04:12:37,618 INFO:     None feature selector for col chem
2022-12-31 04:12:37,618 INFO:     None feature selector for col chem
2022-12-31 04:12:37,618 INFO:     None feature selector for col chem
2022-12-31 04:12:37,618 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 04:12:37,618 INFO:   Starting stage: BUILD MODEL
2022-12-31 04:12:37,620 INFO:     Number of params in model 224011
2022-12-31 04:12:37,624 INFO:   Done with stage: BUILD MODEL
2022-12-31 04:12:37,624 INFO:   Starting stage: TRAINING
2022-12-31 04:12:37,670 INFO:     Val loss before train {'Reaction outcome loss': 1.029009997844696, 'Total loss': 1.029009997844696}
2022-12-31 04:12:37,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:37,670 INFO:     Epoch: 0
2022-12-31 04:12:39,283 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6260259727636973, 'Total loss': 0.6260259727636973} | train loss {'Reaction outcome loss': 0.7707476835616314, 'Total loss': 0.7707476835616314}
2022-12-31 04:12:39,283 INFO:     Found new best model at epoch 0
2022-12-31 04:12:39,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:39,284 INFO:     Epoch: 1
2022-12-31 04:12:40,917 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5505993982156118, 'Total loss': 0.5505993982156118} | train loss {'Reaction outcome loss': 0.5155095051239876, 'Total loss': 0.5155095051239876}
2022-12-31 04:12:40,918 INFO:     Found new best model at epoch 1
2022-12-31 04:12:40,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:40,919 INFO:     Epoch: 2
2022-12-31 04:12:42,571 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49409439265727995, 'Total loss': 0.49409439265727995} | train loss {'Reaction outcome loss': 0.4462948293037658, 'Total loss': 0.4462948293037658}
2022-12-31 04:12:42,571 INFO:     Found new best model at epoch 2
2022-12-31 04:12:42,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:42,572 INFO:     Epoch: 3
2022-12-31 04:12:44,184 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46935507555802664, 'Total loss': 0.46935507555802664} | train loss {'Reaction outcome loss': 0.40588446287778174, 'Total loss': 0.40588446287778174}
2022-12-31 04:12:44,184 INFO:     Found new best model at epoch 3
2022-12-31 04:12:44,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:44,185 INFO:     Epoch: 4
2022-12-31 04:12:45,787 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46025293668111167, 'Total loss': 0.46025293668111167} | train loss {'Reaction outcome loss': 0.37687431025679097, 'Total loss': 0.37687431025679097}
2022-12-31 04:12:45,788 INFO:     Found new best model at epoch 4
2022-12-31 04:12:45,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:45,789 INFO:     Epoch: 5
2022-12-31 04:12:47,401 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4606622924407323, 'Total loss': 0.4606622924407323} | train loss {'Reaction outcome loss': 0.35192727728536094, 'Total loss': 0.35192727728536094}
2022-12-31 04:12:47,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:47,402 INFO:     Epoch: 6
2022-12-31 04:12:49,012 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4341036081314087, 'Total loss': 0.4341036081314087} | train loss {'Reaction outcome loss': 0.3316254387915569, 'Total loss': 0.3316254387915569}
2022-12-31 04:12:49,012 INFO:     Found new best model at epoch 6
2022-12-31 04:12:49,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:49,014 INFO:     Epoch: 7
2022-12-31 04:12:50,625 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45697940488656363, 'Total loss': 0.45697940488656363} | train loss {'Reaction outcome loss': 0.3165670640114015, 'Total loss': 0.3165670640114015}
2022-12-31 04:12:50,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:50,626 INFO:     Epoch: 8
2022-12-31 04:12:52,263 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4245006660620371, 'Total loss': 0.4245006660620371} | train loss {'Reaction outcome loss': 0.302900687274761, 'Total loss': 0.302900687274761}
2022-12-31 04:12:52,263 INFO:     Found new best model at epoch 8
2022-12-31 04:12:52,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:52,264 INFO:     Epoch: 9
2022-12-31 04:12:53,867 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4349895611405373, 'Total loss': 0.4349895611405373} | train loss {'Reaction outcome loss': 0.2861921744026842, 'Total loss': 0.2861921744026842}
2022-12-31 04:12:53,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:53,868 INFO:     Epoch: 10
2022-12-31 04:12:55,480 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41995169321695963, 'Total loss': 0.41995169321695963} | train loss {'Reaction outcome loss': 0.2778318813818432, 'Total loss': 0.2778318813818432}
2022-12-31 04:12:55,480 INFO:     Found new best model at epoch 10
2022-12-31 04:12:55,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:55,481 INFO:     Epoch: 11
2022-12-31 04:12:57,091 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4246873398621877, 'Total loss': 0.4246873398621877} | train loss {'Reaction outcome loss': 0.26555093434931587, 'Total loss': 0.26555093434931587}
2022-12-31 04:12:57,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:57,092 INFO:     Epoch: 12
2022-12-31 04:12:58,700 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4041984389225642, 'Total loss': 0.4041984389225642} | train loss {'Reaction outcome loss': 0.25706400571350196, 'Total loss': 0.25706400571350196}
2022-12-31 04:12:58,700 INFO:     Found new best model at epoch 12
2022-12-31 04:12:58,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:12:58,702 INFO:     Epoch: 13
2022-12-31 04:13:00,311 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4050592223803202, 'Total loss': 0.4050592223803202} | train loss {'Reaction outcome loss': 0.24930825659556546, 'Total loss': 0.24930825659556546}
2022-12-31 04:13:00,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:00,312 INFO:     Epoch: 14
2022-12-31 04:13:01,930 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4219595342874527, 'Total loss': 0.4219595342874527} | train loss {'Reaction outcome loss': 0.24226339120608176, 'Total loss': 0.24226339120608176}
2022-12-31 04:13:01,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:01,930 INFO:     Epoch: 15
2022-12-31 04:13:03,535 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4374313036600749, 'Total loss': 0.4374313036600749} | train loss {'Reaction outcome loss': 0.23413923015668445, 'Total loss': 0.23413923015668445}
2022-12-31 04:13:03,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:03,536 INFO:     Epoch: 16
2022-12-31 04:13:05,188 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41919313271840414, 'Total loss': 0.41919313271840414} | train loss {'Reaction outcome loss': 0.22386140184626527, 'Total loss': 0.22386140184626527}
2022-12-31 04:13:05,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:05,188 INFO:     Epoch: 17
2022-12-31 04:13:06,840 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44196919600168866, 'Total loss': 0.44196919600168866} | train loss {'Reaction outcome loss': 0.21871305588143367, 'Total loss': 0.21871305588143367}
2022-12-31 04:13:06,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:06,841 INFO:     Epoch: 18
2022-12-31 04:13:08,455 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4212342361609141, 'Total loss': 0.4212342361609141} | train loss {'Reaction outcome loss': 0.2091529915095681, 'Total loss': 0.2091529915095681}
2022-12-31 04:13:08,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:08,455 INFO:     Epoch: 19
2022-12-31 04:13:10,067 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40579854547977445, 'Total loss': 0.40579854547977445} | train loss {'Reaction outcome loss': 0.20518779263824877, 'Total loss': 0.20518779263824877}
2022-12-31 04:13:10,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:10,068 INFO:     Epoch: 20
2022-12-31 04:13:11,670 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38771734535694125, 'Total loss': 0.38771734535694125} | train loss {'Reaction outcome loss': 0.20136368918796851, 'Total loss': 0.20136368918796851}
2022-12-31 04:13:11,671 INFO:     Found new best model at epoch 20
2022-12-31 04:13:11,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:11,672 INFO:     Epoch: 21
2022-12-31 04:13:13,280 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41172344783941905, 'Total loss': 0.41172344783941905} | train loss {'Reaction outcome loss': 0.1937521352521042, 'Total loss': 0.1937521352521042}
2022-12-31 04:13:13,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:13,280 INFO:     Epoch: 22
2022-12-31 04:13:14,933 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44386038382848103, 'Total loss': 0.44386038382848103} | train loss {'Reaction outcome loss': 0.18986652353370603, 'Total loss': 0.18986652353370603}
2022-12-31 04:13:14,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:14,933 INFO:     Epoch: 23
2022-12-31 04:13:16,546 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4351697613795598, 'Total loss': 0.4351697613795598} | train loss {'Reaction outcome loss': 0.18666727052335322, 'Total loss': 0.18666727052335322}
2022-12-31 04:13:16,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:16,546 INFO:     Epoch: 24
2022-12-31 04:13:18,199 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40349273482958475, 'Total loss': 0.40349273482958475} | train loss {'Reaction outcome loss': 0.18161211331395338, 'Total loss': 0.18161211331395338}
2022-12-31 04:13:18,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:18,200 INFO:     Epoch: 25
2022-12-31 04:13:19,812 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4280768434206645, 'Total loss': 0.4280768434206645} | train loss {'Reaction outcome loss': 0.18004420666146453, 'Total loss': 0.18004420666146453}
2022-12-31 04:13:19,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:19,812 INFO:     Epoch: 26
2022-12-31 04:13:21,441 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42556815445423124, 'Total loss': 0.42556815445423124} | train loss {'Reaction outcome loss': 0.17361390898615991, 'Total loss': 0.17361390898615991}
2022-12-31 04:13:21,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:21,441 INFO:     Epoch: 27
2022-12-31 04:13:23,094 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42699436148007713, 'Total loss': 0.42699436148007713} | train loss {'Reaction outcome loss': 0.16951119677116075, 'Total loss': 0.16951119677116075}
2022-12-31 04:13:23,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:23,094 INFO:     Epoch: 28
2022-12-31 04:13:24,707 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4335101842880249, 'Total loss': 0.4335101842880249} | train loss {'Reaction outcome loss': 0.1677628348302776, 'Total loss': 0.1677628348302776}
2022-12-31 04:13:24,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:24,707 INFO:     Epoch: 29
2022-12-31 04:13:26,360 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44070161978403727, 'Total loss': 0.44070161978403727} | train loss {'Reaction outcome loss': 0.16443952436756043, 'Total loss': 0.16443952436756043}
2022-12-31 04:13:26,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:26,360 INFO:     Epoch: 30
2022-12-31 04:13:27,974 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4455982635418574, 'Total loss': 0.4455982635418574} | train loss {'Reaction outcome loss': 0.16136343452236512, 'Total loss': 0.16136343452236512}
2022-12-31 04:13:27,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:27,975 INFO:     Epoch: 31
2022-12-31 04:13:29,582 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4291449710726738, 'Total loss': 0.4291449710726738} | train loss {'Reaction outcome loss': 0.15664088504429716, 'Total loss': 0.15664088504429716}
2022-12-31 04:13:29,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:29,583 INFO:     Epoch: 32
2022-12-31 04:13:31,194 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43571993013223015, 'Total loss': 0.43571993013223015} | train loss {'Reaction outcome loss': 0.15619168436005168, 'Total loss': 0.15619168436005168}
2022-12-31 04:13:31,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:31,195 INFO:     Epoch: 33
2022-12-31 04:13:32,798 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4534153133630753, 'Total loss': 0.4534153133630753} | train loss {'Reaction outcome loss': 0.1519777983032765, 'Total loss': 0.1519777983032765}
2022-12-31 04:13:32,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:32,798 INFO:     Epoch: 34
2022-12-31 04:13:34,401 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44291082620620725, 'Total loss': 0.44291082620620725} | train loss {'Reaction outcome loss': 0.15300642420626143, 'Total loss': 0.15300642420626143}
2022-12-31 04:13:34,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:34,401 INFO:     Epoch: 35
2022-12-31 04:13:36,005 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41618810494740804, 'Total loss': 0.41618810494740804} | train loss {'Reaction outcome loss': 0.1523752711427799, 'Total loss': 0.1523752711427799}
2022-12-31 04:13:36,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:36,005 INFO:     Epoch: 36
2022-12-31 04:13:37,658 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46893521348635353, 'Total loss': 0.46893521348635353} | train loss {'Reaction outcome loss': 0.1506244087707333, 'Total loss': 0.1506244087707333}
2022-12-31 04:13:37,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:37,658 INFO:     Epoch: 37
2022-12-31 04:13:39,266 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43522864480813345, 'Total loss': 0.43522864480813345} | train loss {'Reaction outcome loss': 0.14534323198217763, 'Total loss': 0.14534323198217763}
2022-12-31 04:13:39,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:39,266 INFO:     Epoch: 38
2022-12-31 04:13:40,886 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45518351991971334, 'Total loss': 0.45518351991971334} | train loss {'Reaction outcome loss': 0.14366937321984638, 'Total loss': 0.14366937321984638}
2022-12-31 04:13:40,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:40,886 INFO:     Epoch: 39
2022-12-31 04:13:42,507 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43435900608698524, 'Total loss': 0.43435900608698524} | train loss {'Reaction outcome loss': 0.1437604771926999, 'Total loss': 0.1437604771926999}
2022-12-31 04:13:42,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:42,508 INFO:     Epoch: 40
2022-12-31 04:13:44,127 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45519779920578, 'Total loss': 0.45519779920578} | train loss {'Reaction outcome loss': 0.1386216408352157, 'Total loss': 0.1386216408352157}
2022-12-31 04:13:44,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:44,127 INFO:     Epoch: 41
2022-12-31 04:13:45,745 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4351471453905106, 'Total loss': 0.4351471453905106} | train loss {'Reaction outcome loss': 0.13769000383386265, 'Total loss': 0.13769000383386265}
2022-12-31 04:13:45,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:45,745 INFO:     Epoch: 42
2022-12-31 04:13:47,360 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.406841445962588, 'Total loss': 0.406841445962588} | train loss {'Reaction outcome loss': 0.13621242001251638, 'Total loss': 0.13621242001251638}
2022-12-31 04:13:47,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:47,360 INFO:     Epoch: 43
2022-12-31 04:13:48,971 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4207398772239685, 'Total loss': 0.4207398772239685} | train loss {'Reaction outcome loss': 0.13615039459354902, 'Total loss': 0.13615039459354902}
2022-12-31 04:13:48,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:48,972 INFO:     Epoch: 44
2022-12-31 04:13:50,591 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42355769673983257, 'Total loss': 0.42355769673983257} | train loss {'Reaction outcome loss': 0.13222881277044216, 'Total loss': 0.13222881277044216}
2022-12-31 04:13:50,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:50,592 INFO:     Epoch: 45
2022-12-31 04:13:52,209 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4560214797655741, 'Total loss': 0.4560214797655741} | train loss {'Reaction outcome loss': 0.13305802263972097, 'Total loss': 0.13305802263972097}
2022-12-31 04:13:52,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:52,210 INFO:     Epoch: 46
2022-12-31 04:13:53,828 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4338130444288254, 'Total loss': 0.4338130444288254} | train loss {'Reaction outcome loss': 0.1334213910345668, 'Total loss': 0.1334213910345668}
2022-12-31 04:13:53,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:53,828 INFO:     Epoch: 47
2022-12-31 04:13:55,446 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42830663124720253, 'Total loss': 0.42830663124720253} | train loss {'Reaction outcome loss': 0.13048525106664882, 'Total loss': 0.13048525106664882}
2022-12-31 04:13:55,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:55,446 INFO:     Epoch: 48
2022-12-31 04:13:57,053 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.418055023252964, 'Total loss': 0.418055023252964} | train loss {'Reaction outcome loss': 0.12596458830381232, 'Total loss': 0.12596458830381232}
2022-12-31 04:13:57,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:57,053 INFO:     Epoch: 49
2022-12-31 04:13:58,664 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42527914643287656, 'Total loss': 0.42527914643287656} | train loss {'Reaction outcome loss': 0.13253165917712378, 'Total loss': 0.13253165917712378}
2022-12-31 04:13:58,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:13:58,664 INFO:     Epoch: 50
2022-12-31 04:14:00,281 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4299282054106394, 'Total loss': 0.4299282054106394} | train loss {'Reaction outcome loss': 0.1329163721640234, 'Total loss': 0.1329163721640234}
2022-12-31 04:14:00,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:00,281 INFO:     Epoch: 51
2022-12-31 04:14:01,898 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45312716166178385, 'Total loss': 0.45312716166178385} | train loss {'Reaction outcome loss': 0.13067126854146102, 'Total loss': 0.13067126854146102}
2022-12-31 04:14:01,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:01,899 INFO:     Epoch: 52
2022-12-31 04:14:03,514 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4272073805332184, 'Total loss': 0.4272073805332184} | train loss {'Reaction outcome loss': 0.12536600059625713, 'Total loss': 0.12536600059625713}
2022-12-31 04:14:03,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:03,514 INFO:     Epoch: 53
2022-12-31 04:14:05,118 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4186238671342532, 'Total loss': 0.4186238671342532} | train loss {'Reaction outcome loss': 0.12405256291402735, 'Total loss': 0.12405256291402735}
2022-12-31 04:14:05,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:05,118 INFO:     Epoch: 54
2022-12-31 04:14:06,754 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47350552479426067, 'Total loss': 0.47350552479426067} | train loss {'Reaction outcome loss': 0.12708086650614647, 'Total loss': 0.12708086650614647}
2022-12-31 04:14:06,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:06,755 INFO:     Epoch: 55
2022-12-31 04:14:08,406 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4220486303170522, 'Total loss': 0.4220486303170522} | train loss {'Reaction outcome loss': 0.12388174952157385, 'Total loss': 0.12388174952157385}
2022-12-31 04:14:08,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:08,407 INFO:     Epoch: 56
2022-12-31 04:14:10,060 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43095285395781197, 'Total loss': 0.43095285395781197} | train loss {'Reaction outcome loss': 0.11868794628310214, 'Total loss': 0.11868794628310214}
2022-12-31 04:14:10,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:10,060 INFO:     Epoch: 57
2022-12-31 04:14:11,668 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4728724151849747, 'Total loss': 0.4728724151849747} | train loss {'Reaction outcome loss': 0.12239672468608095, 'Total loss': 0.12239672468608095}
2022-12-31 04:14:11,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:11,669 INFO:     Epoch: 58
2022-12-31 04:14:13,322 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4394763747851054, 'Total loss': 0.4394763747851054} | train loss {'Reaction outcome loss': 0.12238135518689715, 'Total loss': 0.12238135518689715}
2022-12-31 04:14:13,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:13,323 INFO:     Epoch: 59
2022-12-31 04:14:14,939 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41990984479586285, 'Total loss': 0.41990984479586285} | train loss {'Reaction outcome loss': 0.1200560725457205, 'Total loss': 0.1200560725457205}
2022-12-31 04:14:14,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:14,939 INFO:     Epoch: 60
2022-12-31 04:14:16,546 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4598694021503131, 'Total loss': 0.4598694021503131} | train loss {'Reaction outcome loss': 0.12408767733128102, 'Total loss': 0.12408767733128102}
2022-12-31 04:14:16,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:16,546 INFO:     Epoch: 61
2022-12-31 04:14:18,160 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43985346853733065, 'Total loss': 0.43985346853733065} | train loss {'Reaction outcome loss': 0.12393899781316736, 'Total loss': 0.12393899781316736}
2022-12-31 04:14:18,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:18,161 INFO:     Epoch: 62
2022-12-31 04:14:19,775 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4525167226791382, 'Total loss': 0.4525167226791382} | train loss {'Reaction outcome loss': 0.11924818506206039, 'Total loss': 0.11924818506206039}
2022-12-31 04:14:19,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:19,776 INFO:     Epoch: 63
2022-12-31 04:14:21,391 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4383618394533793, 'Total loss': 0.4383618394533793} | train loss {'Reaction outcome loss': 0.12019016193633858, 'Total loss': 0.12019016193633858}
2022-12-31 04:14:21,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:21,391 INFO:     Epoch: 64
2022-12-31 04:14:23,005 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47783791621526084, 'Total loss': 0.47783791621526084} | train loss {'Reaction outcome loss': 0.11988508519138732, 'Total loss': 0.11988508519138732}
2022-12-31 04:14:23,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:23,005 INFO:     Epoch: 65
2022-12-31 04:14:24,611 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4844579224785169, 'Total loss': 0.4844579224785169} | train loss {'Reaction outcome loss': 0.11548459088008334, 'Total loss': 0.11548459088008334}
2022-12-31 04:14:24,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:24,612 INFO:     Epoch: 66
2022-12-31 04:14:26,210 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43174068530400594, 'Total loss': 0.43174068530400594} | train loss {'Reaction outcome loss': 0.11814601195085603, 'Total loss': 0.11814601195085603}
2022-12-31 04:14:26,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:26,210 INFO:     Epoch: 67
2022-12-31 04:14:27,843 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4391684204339981, 'Total loss': 0.4391684204339981} | train loss {'Reaction outcome loss': 0.11426465222646014, 'Total loss': 0.11426465222646014}
2022-12-31 04:14:27,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:27,844 INFO:     Epoch: 68
2022-12-31 04:14:29,446 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4102296104033788, 'Total loss': 0.4102296104033788} | train loss {'Reaction outcome loss': 0.11846324854469212, 'Total loss': 0.11846324854469212}
2022-12-31 04:14:29,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:29,446 INFO:     Epoch: 69
2022-12-31 04:14:31,047 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4576246698697408, 'Total loss': 0.4576246698697408} | train loss {'Reaction outcome loss': 0.11991140904435277, 'Total loss': 0.11991140904435277}
2022-12-31 04:14:31,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:31,047 INFO:     Epoch: 70
2022-12-31 04:14:32,644 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40882757703463235, 'Total loss': 0.40882757703463235} | train loss {'Reaction outcome loss': 0.11318534306236917, 'Total loss': 0.11318534306236917}
2022-12-31 04:14:32,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:32,645 INFO:     Epoch: 71
2022-12-31 04:14:34,245 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47554632027943927, 'Total loss': 0.47554632027943927} | train loss {'Reaction outcome loss': 0.11374858759656331, 'Total loss': 0.11374858759656331}
2022-12-31 04:14:34,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:34,245 INFO:     Epoch: 72
2022-12-31 04:14:35,866 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43442581097284955, 'Total loss': 0.43442581097284955} | train loss {'Reaction outcome loss': 0.11552038286510094, 'Total loss': 0.11552038286510094}
2022-12-31 04:14:35,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:35,867 INFO:     Epoch: 73
2022-12-31 04:14:37,489 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3976712206999461, 'Total loss': 0.3976712206999461} | train loss {'Reaction outcome loss': 0.11512994723578059, 'Total loss': 0.11512994723578059}
2022-12-31 04:14:37,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:37,490 INFO:     Epoch: 74
2022-12-31 04:14:39,113 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40252039233843484, 'Total loss': 0.40252039233843484} | train loss {'Reaction outcome loss': 0.11704217302392027, 'Total loss': 0.11704217302392027}
2022-12-31 04:14:39,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:39,113 INFO:     Epoch: 75
2022-12-31 04:14:40,733 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4230932439366976, 'Total loss': 0.4230932439366976} | train loss {'Reaction outcome loss': 0.11645212827631048, 'Total loss': 0.11645212827631048}
2022-12-31 04:14:40,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:40,733 INFO:     Epoch: 76
2022-12-31 04:14:42,348 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4536701331535975, 'Total loss': 0.4536701331535975} | train loss {'Reaction outcome loss': 0.11277592421703068, 'Total loss': 0.11277592421703068}
2022-12-31 04:14:42,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:42,348 INFO:     Epoch: 77
2022-12-31 04:14:43,962 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4305226037899653, 'Total loss': 0.4305226037899653} | train loss {'Reaction outcome loss': 0.11021953850413543, 'Total loss': 0.11021953850413543}
2022-12-31 04:14:43,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:43,964 INFO:     Epoch: 78
2022-12-31 04:14:45,584 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4536724294225375, 'Total loss': 0.4536724294225375} | train loss {'Reaction outcome loss': 0.11110703379466423, 'Total loss': 0.11110703379466423}
2022-12-31 04:14:45,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:45,584 INFO:     Epoch: 79
2022-12-31 04:14:47,203 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4506215512752533, 'Total loss': 0.4506215512752533} | train loss {'Reaction outcome loss': 0.11319683928188806, 'Total loss': 0.11319683928188806}
2022-12-31 04:14:47,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:47,204 INFO:     Epoch: 80
2022-12-31 04:14:48,820 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45964373350143434, 'Total loss': 0.45964373350143434} | train loss {'Reaction outcome loss': 0.11156460209018856, 'Total loss': 0.11156460209018856}
2022-12-31 04:14:48,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:48,820 INFO:     Epoch: 81
2022-12-31 04:14:50,436 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.480725105603536, 'Total loss': 0.480725105603536} | train loss {'Reaction outcome loss': 0.11091785272923264, 'Total loss': 0.11091785272923264}
2022-12-31 04:14:50,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:50,436 INFO:     Epoch: 82
2022-12-31 04:14:52,047 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4363104889790217, 'Total loss': 0.4363104889790217} | train loss {'Reaction outcome loss': 0.11021805103837655, 'Total loss': 0.11021805103837655}
2022-12-31 04:14:52,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:52,047 INFO:     Epoch: 83
2022-12-31 04:14:53,660 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4256361941496531, 'Total loss': 0.4256361941496531} | train loss {'Reaction outcome loss': 0.10866072107646886, 'Total loss': 0.10866072107646886}
2022-12-31 04:14:53,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:53,660 INFO:     Epoch: 84
2022-12-31 04:14:55,283 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4414595643679301, 'Total loss': 0.4414595643679301} | train loss {'Reaction outcome loss': 0.10819483653771399, 'Total loss': 0.10819483653771399}
2022-12-31 04:14:55,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:55,283 INFO:     Epoch: 85
2022-12-31 04:14:56,903 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4150920728842417, 'Total loss': 0.4150920728842417} | train loss {'Reaction outcome loss': 0.11353686469161788, 'Total loss': 0.11353686469161788}
2022-12-31 04:14:56,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:56,904 INFO:     Epoch: 86
2022-12-31 04:14:58,524 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4220541814963023, 'Total loss': 0.4220541814963023} | train loss {'Reaction outcome loss': 0.10911352816717632, 'Total loss': 0.10911352816717632}
2022-12-31 04:14:58,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:14:58,525 INFO:     Epoch: 87
2022-12-31 04:15:00,139 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44409756859143573, 'Total loss': 0.44409756859143573} | train loss {'Reaction outcome loss': 0.11281539743297128, 'Total loss': 0.11281539743297128}
2022-12-31 04:15:00,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:00,139 INFO:     Epoch: 88
2022-12-31 04:15:01,612 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45769188820074, 'Total loss': 0.45769188820074} | train loss {'Reaction outcome loss': 0.10982905973401601, 'Total loss': 0.10982905973401601}
2022-12-31 04:15:01,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:01,612 INFO:     Epoch: 89
2022-12-31 04:15:02,724 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4298196529348691, 'Total loss': 0.4298196529348691} | train loss {'Reaction outcome loss': 0.10845948459859257, 'Total loss': 0.10845948459859257}
2022-12-31 04:15:02,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:02,725 INFO:     Epoch: 90
2022-12-31 04:15:03,825 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46275104880332946, 'Total loss': 0.46275104880332946} | train loss {'Reaction outcome loss': 0.11185703687216869, 'Total loss': 0.11185703687216869}
2022-12-31 04:15:03,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:03,826 INFO:     Epoch: 91
2022-12-31 04:15:04,925 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4454475253820419, 'Total loss': 0.4454475253820419} | train loss {'Reaction outcome loss': 0.11287473228821246, 'Total loss': 0.11287473228821246}
2022-12-31 04:15:04,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:04,926 INFO:     Epoch: 92
2022-12-31 04:15:06,119 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41519812047481536, 'Total loss': 0.41519812047481536} | train loss {'Reaction outcome loss': 0.10750543229268307, 'Total loss': 0.10750543229268307}
2022-12-31 04:15:06,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:06,119 INFO:     Epoch: 93
2022-12-31 04:15:07,731 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42379008531570433, 'Total loss': 0.42379008531570433} | train loss {'Reaction outcome loss': 0.10944604789702235, 'Total loss': 0.10944604789702235}
2022-12-31 04:15:07,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:07,731 INFO:     Epoch: 94
2022-12-31 04:15:09,353 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44607519805431367, 'Total loss': 0.44607519805431367} | train loss {'Reaction outcome loss': 0.10773036338518081, 'Total loss': 0.10773036338518081}
2022-12-31 04:15:09,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:09,354 INFO:     Epoch: 95
2022-12-31 04:15:10,977 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44022200504938763, 'Total loss': 0.44022200504938763} | train loss {'Reaction outcome loss': 0.10694033815610447, 'Total loss': 0.10694033815610447}
2022-12-31 04:15:10,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:10,977 INFO:     Epoch: 96
2022-12-31 04:15:12,598 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4219391415516535, 'Total loss': 0.4219391415516535} | train loss {'Reaction outcome loss': 0.1054902048288661, 'Total loss': 0.1054902048288661}
2022-12-31 04:15:12,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:12,598 INFO:     Epoch: 97
2022-12-31 04:15:14,221 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4431399901707967, 'Total loss': 0.4431399901707967} | train loss {'Reaction outcome loss': 0.11244782255656582, 'Total loss': 0.11244782255656582}
2022-12-31 04:15:14,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:14,223 INFO:     Epoch: 98
2022-12-31 04:15:15,828 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41339126725991565, 'Total loss': 0.41339126725991565} | train loss {'Reaction outcome loss': 0.1039279376744653, 'Total loss': 0.1039279376744653}
2022-12-31 04:15:15,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:15,829 INFO:     Epoch: 99
2022-12-31 04:15:17,457 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4539825995763143, 'Total loss': 0.4539825995763143} | train loss {'Reaction outcome loss': 0.11122139243079336, 'Total loss': 0.11122139243079336}
2022-12-31 04:15:17,458 INFO:     Best model found after epoch 21 of 100.
2022-12-31 04:15:17,458 INFO:   Done with stage: TRAINING
2022-12-31 04:15:17,458 INFO:   Starting stage: EVALUATION
2022-12-31 04:15:17,596 INFO:   Done with stage: EVALUATION
2022-12-31 04:15:17,596 INFO:   Leaving out SEQ value Fold_4
2022-12-31 04:15:17,608 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 04:15:17,608 INFO:   Starting stage: FEATURE SCALING
2022-12-31 04:15:18,249 INFO:   Done with stage: FEATURE SCALING
2022-12-31 04:15:18,250 INFO:   Starting stage: SCALING TARGETS
2022-12-31 04:15:18,323 INFO:   Done with stage: SCALING TARGETS
2022-12-31 04:15:18,323 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:15:18,323 INFO:     No hyperparam tuning for this model
2022-12-31 04:15:18,323 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:15:18,323 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 04:15:18,324 INFO:     None feature selector for col prot
2022-12-31 04:15:18,324 INFO:     None feature selector for col prot
2022-12-31 04:15:18,324 INFO:     None feature selector for col prot
2022-12-31 04:15:18,325 INFO:     None feature selector for col chem
2022-12-31 04:15:18,325 INFO:     None feature selector for col chem
2022-12-31 04:15:18,325 INFO:     None feature selector for col chem
2022-12-31 04:15:18,325 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 04:15:18,325 INFO:   Starting stage: BUILD MODEL
2022-12-31 04:15:18,327 INFO:     Number of params in model 224011
2022-12-31 04:15:18,330 INFO:   Done with stage: BUILD MODEL
2022-12-31 04:15:18,330 INFO:   Starting stage: TRAINING
2022-12-31 04:15:18,376 INFO:     Val loss before train {'Reaction outcome loss': 0.8574545462926229, 'Total loss': 0.8574545462926229}
2022-12-31 04:15:18,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:18,376 INFO:     Epoch: 0
2022-12-31 04:15:20,004 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5213440457979838, 'Total loss': 0.5213440457979838} | train loss {'Reaction outcome loss': 0.7842141650617123, 'Total loss': 0.7842141650617123}
2022-12-31 04:15:20,005 INFO:     Found new best model at epoch 0
2022-12-31 04:15:20,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:20,006 INFO:     Epoch: 1
2022-12-31 04:15:21,636 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.44886405070622765, 'Total loss': 0.44886405070622765} | train loss {'Reaction outcome loss': 0.5167084659139315, 'Total loss': 0.5167084659139315}
2022-12-31 04:15:21,637 INFO:     Found new best model at epoch 1
2022-12-31 04:15:21,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:21,638 INFO:     Epoch: 2
2022-12-31 04:15:23,268 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.43753663102785745, 'Total loss': 0.43753663102785745} | train loss {'Reaction outcome loss': 0.4555569730051186, 'Total loss': 0.4555569730051186}
2022-12-31 04:15:23,268 INFO:     Found new best model at epoch 2
2022-12-31 04:15:23,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:23,269 INFO:     Epoch: 3
2022-12-31 04:15:24,887 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45020942787329354, 'Total loss': 0.45020942787329354} | train loss {'Reaction outcome loss': 0.4191868043963568, 'Total loss': 0.4191868043963568}
2022-12-31 04:15:24,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:24,887 INFO:     Epoch: 4
2022-12-31 04:15:26,522 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.40137799580891925, 'Total loss': 0.40137799580891925} | train loss {'Reaction outcome loss': 0.39429602443147893, 'Total loss': 0.39429602443147893}
2022-12-31 04:15:26,522 INFO:     Found new best model at epoch 4
2022-12-31 04:15:26,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:26,523 INFO:     Epoch: 5
2022-12-31 04:15:28,145 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3810739641388257, 'Total loss': 0.3810739641388257} | train loss {'Reaction outcome loss': 0.36875827939829964, 'Total loss': 0.36875827939829964}
2022-12-31 04:15:28,146 INFO:     Found new best model at epoch 5
2022-12-31 04:15:28,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:28,147 INFO:     Epoch: 6
2022-12-31 04:15:29,767 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.39494966765244804, 'Total loss': 0.39494966765244804} | train loss {'Reaction outcome loss': 0.35095069749766716, 'Total loss': 0.35095069749766716}
2022-12-31 04:15:29,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:29,768 INFO:     Epoch: 7
2022-12-31 04:15:31,432 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.38049061546723045, 'Total loss': 0.38049061546723045} | train loss {'Reaction outcome loss': 0.33420769608515466, 'Total loss': 0.33420769608515466}
2022-12-31 04:15:31,433 INFO:     Found new best model at epoch 7
2022-12-31 04:15:31,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:31,434 INFO:     Epoch: 8
2022-12-31 04:15:33,056 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3733071525891622, 'Total loss': 0.3733071525891622} | train loss {'Reaction outcome loss': 0.320619228946811, 'Total loss': 0.320619228946811}
2022-12-31 04:15:33,056 INFO:     Found new best model at epoch 8
2022-12-31 04:15:33,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:33,057 INFO:     Epoch: 9
2022-12-31 04:15:34,667 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3714320202668508, 'Total loss': 0.3714320202668508} | train loss {'Reaction outcome loss': 0.30481416408619605, 'Total loss': 0.30481416408619605}
2022-12-31 04:15:34,668 INFO:     Found new best model at epoch 9
2022-12-31 04:15:34,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:34,669 INFO:     Epoch: 10
2022-12-31 04:15:36,289 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.368844103316466, 'Total loss': 0.368844103316466} | train loss {'Reaction outcome loss': 0.289491767026619, 'Total loss': 0.289491767026619}
2022-12-31 04:15:36,289 INFO:     Found new best model at epoch 10
2022-12-31 04:15:36,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:36,291 INFO:     Epoch: 11
2022-12-31 04:15:37,911 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.37841034928957623, 'Total loss': 0.37841034928957623} | train loss {'Reaction outcome loss': 0.2804684364169404, 'Total loss': 0.2804684364169404}
2022-12-31 04:15:37,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:37,912 INFO:     Epoch: 12
2022-12-31 04:15:39,576 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3517201443513234, 'Total loss': 0.3517201443513234} | train loss {'Reaction outcome loss': 0.27388023198970285, 'Total loss': 0.27388023198970285}
2022-12-31 04:15:39,576 INFO:     Found new best model at epoch 12
2022-12-31 04:15:39,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:39,577 INFO:     Epoch: 13
2022-12-31 04:15:41,191 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3879139135281245, 'Total loss': 0.3879139135281245} | train loss {'Reaction outcome loss': 0.2550729507971825, 'Total loss': 0.2550729507971825}
2022-12-31 04:15:41,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:41,191 INFO:     Epoch: 14
2022-12-31 04:15:42,830 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3863100598255793, 'Total loss': 0.3863100598255793} | train loss {'Reaction outcome loss': 0.25040626719735726, 'Total loss': 0.25040626719735726}
2022-12-31 04:15:42,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:42,830 INFO:     Epoch: 15
2022-12-31 04:15:44,452 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3761591653029124, 'Total loss': 0.3761591653029124} | train loss {'Reaction outcome loss': 0.24270029210036728, 'Total loss': 0.24270029210036728}
2022-12-31 04:15:44,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:44,452 INFO:     Epoch: 16
2022-12-31 04:15:46,081 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3959514369567235, 'Total loss': 0.3959514369567235} | train loss {'Reaction outcome loss': 0.23816459094687953, 'Total loss': 0.23816459094687953}
2022-12-31 04:15:46,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:46,081 INFO:     Epoch: 17
2022-12-31 04:15:47,711 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3767791857322057, 'Total loss': 0.3767791857322057} | train loss {'Reaction outcome loss': 0.22926929920736322, 'Total loss': 0.22926929920736322}
2022-12-31 04:15:47,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:47,711 INFO:     Epoch: 18
2022-12-31 04:15:49,341 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.36998633841673534, 'Total loss': 0.36998633841673534} | train loss {'Reaction outcome loss': 0.2243676265719367, 'Total loss': 0.2243676265719367}
2022-12-31 04:15:49,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:49,342 INFO:     Epoch: 19
2022-12-31 04:15:50,971 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.37627852062384287, 'Total loss': 0.37627852062384287} | train loss {'Reaction outcome loss': 0.21585168785995978, 'Total loss': 0.21585168785995978}
2022-12-31 04:15:50,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:50,972 INFO:     Epoch: 20
2022-12-31 04:15:52,582 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38678779105345407, 'Total loss': 0.38678779105345407} | train loss {'Reaction outcome loss': 0.2152444393697964, 'Total loss': 0.2152444393697964}
2022-12-31 04:15:52,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:52,582 INFO:     Epoch: 21
2022-12-31 04:15:54,212 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40699660529692966, 'Total loss': 0.40699660529692966} | train loss {'Reaction outcome loss': 0.20987369930219796, 'Total loss': 0.20987369930219796}
2022-12-31 04:15:54,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:54,212 INFO:     Epoch: 22
2022-12-31 04:15:55,843 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3894134054581324, 'Total loss': 0.3894134054581324} | train loss {'Reaction outcome loss': 0.20697179534406884, 'Total loss': 0.20697179534406884}
2022-12-31 04:15:55,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:55,843 INFO:     Epoch: 23
2022-12-31 04:15:57,475 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3845723172028859, 'Total loss': 0.3845723172028859} | train loss {'Reaction outcome loss': 0.195333029731494, 'Total loss': 0.195333029731494}
2022-12-31 04:15:57,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:57,476 INFO:     Epoch: 24
2022-12-31 04:15:59,105 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40420705676078794, 'Total loss': 0.40420705676078794} | train loss {'Reaction outcome loss': 0.1956596085928259, 'Total loss': 0.1956596085928259}
2022-12-31 04:15:59,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:15:59,106 INFO:     Epoch: 25
2022-12-31 04:16:00,731 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.401217449704806, 'Total loss': 0.401217449704806} | train loss {'Reaction outcome loss': 0.19263191456677992, 'Total loss': 0.19263191456677992}
2022-12-31 04:16:00,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:00,732 INFO:     Epoch: 26
2022-12-31 04:16:02,374 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39594240076839926, 'Total loss': 0.39594240076839926} | train loss {'Reaction outcome loss': 0.18375249441469085, 'Total loss': 0.18375249441469085}
2022-12-31 04:16:02,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:02,375 INFO:     Epoch: 27
2022-12-31 04:16:04,039 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3842703382174174, 'Total loss': 0.3842703382174174} | train loss {'Reaction outcome loss': 0.1830509990839619, 'Total loss': 0.1830509990839619}
2022-12-31 04:16:04,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:04,039 INFO:     Epoch: 28
2022-12-31 04:16:05,701 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3805940955877304, 'Total loss': 0.3805940955877304} | train loss {'Reaction outcome loss': 0.17930516510218233, 'Total loss': 0.17930516510218233}
2022-12-31 04:16:05,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:05,702 INFO:     Epoch: 29
2022-12-31 04:16:07,318 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.37776918758948647, 'Total loss': 0.37776918758948647} | train loss {'Reaction outcome loss': 0.17687161875875207, 'Total loss': 0.17687161875875207}
2022-12-31 04:16:07,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:07,319 INFO:     Epoch: 30
2022-12-31 04:16:08,978 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41035011609395344, 'Total loss': 0.41035011609395344} | train loss {'Reaction outcome loss': 0.17614649039814653, 'Total loss': 0.17614649039814653}
2022-12-31 04:16:08,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:08,978 INFO:     Epoch: 31
2022-12-31 04:16:10,596 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.385930028061072, 'Total loss': 0.385930028061072} | train loss {'Reaction outcome loss': 0.1731537562302327, 'Total loss': 0.1731537562302327}
2022-12-31 04:16:10,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:10,597 INFO:     Epoch: 32
2022-12-31 04:16:12,215 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3868115782737732, 'Total loss': 0.3868115782737732} | train loss {'Reaction outcome loss': 0.16827809945612715, 'Total loss': 0.16827809945612715}
2022-12-31 04:16:12,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:12,216 INFO:     Epoch: 33
2022-12-31 04:16:13,840 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3952720522880554, 'Total loss': 0.3952720522880554} | train loss {'Reaction outcome loss': 0.18282412934195894, 'Total loss': 0.18282412934195894}
2022-12-31 04:16:13,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:13,841 INFO:     Epoch: 34
2022-12-31 04:16:15,460 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40139738519986473, 'Total loss': 0.40139738519986473} | train loss {'Reaction outcome loss': 0.16793672102031068, 'Total loss': 0.16793672102031068}
2022-12-31 04:16:15,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:15,460 INFO:     Epoch: 35
2022-12-31 04:16:17,080 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39011749376853305, 'Total loss': 0.39011749376853305} | train loss {'Reaction outcome loss': 0.16343238214072744, 'Total loss': 0.16343238214072744}
2022-12-31 04:16:17,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:17,080 INFO:     Epoch: 36
2022-12-31 04:16:18,696 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43011712829271953, 'Total loss': 0.43011712829271953} | train loss {'Reaction outcome loss': 0.16230006061453858, 'Total loss': 0.16230006061453858}
2022-12-31 04:16:18,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:18,696 INFO:     Epoch: 37
2022-12-31 04:16:20,304 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39324228664239247, 'Total loss': 0.39324228664239247} | train loss {'Reaction outcome loss': 0.1624171725757744, 'Total loss': 0.1624171725757744}
2022-12-31 04:16:20,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:20,304 INFO:     Epoch: 38
2022-12-31 04:16:21,921 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4071270947655042, 'Total loss': 0.4071270947655042} | train loss {'Reaction outcome loss': 0.15637892027376255, 'Total loss': 0.15637892027376255}
2022-12-31 04:16:21,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:21,921 INFO:     Epoch: 39
2022-12-31 04:16:23,540 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4001548250516256, 'Total loss': 0.4001548250516256} | train loss {'Reaction outcome loss': 0.15883083731772046, 'Total loss': 0.15883083731772046}
2022-12-31 04:16:23,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:23,540 INFO:     Epoch: 40
2022-12-31 04:16:25,157 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.36532035445173583, 'Total loss': 0.36532035445173583} | train loss {'Reaction outcome loss': 0.15818725137269476, 'Total loss': 0.15818725137269476}
2022-12-31 04:16:25,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:25,158 INFO:     Epoch: 41
2022-12-31 04:16:26,775 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38958167533079785, 'Total loss': 0.38958167533079785} | train loss {'Reaction outcome loss': 0.1690361468134907, 'Total loss': 0.1690361468134907}
2022-12-31 04:16:26,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:26,777 INFO:     Epoch: 42
2022-12-31 04:16:28,385 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38132527271906536, 'Total loss': 0.38132527271906536} | train loss {'Reaction outcome loss': 0.15390708469962905, 'Total loss': 0.15390708469962905}
2022-12-31 04:16:28,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:28,386 INFO:     Epoch: 43
2022-12-31 04:16:29,996 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3817437117298444, 'Total loss': 0.3817437117298444} | train loss {'Reaction outcome loss': 0.1514929402720831, 'Total loss': 0.1514929402720831}
2022-12-31 04:16:29,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:29,996 INFO:     Epoch: 44
2022-12-31 04:16:31,614 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3612071226583794, 'Total loss': 0.3612071226583794} | train loss {'Reaction outcome loss': 0.1488845078628915, 'Total loss': 0.1488845078628915}
2022-12-31 04:16:31,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:31,614 INFO:     Epoch: 45
2022-12-31 04:16:33,228 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3585289642214775, 'Total loss': 0.3585289642214775} | train loss {'Reaction outcome loss': 0.15092066974730056, 'Total loss': 0.15092066974730056}
2022-12-31 04:16:33,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:33,229 INFO:     Epoch: 46
2022-12-31 04:16:34,842 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4001271848877271, 'Total loss': 0.4001271848877271} | train loss {'Reaction outcome loss': 0.17224530880238212, 'Total loss': 0.17224530880238212}
2022-12-31 04:16:34,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:34,842 INFO:     Epoch: 47
2022-12-31 04:16:36,502 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39320028722286227, 'Total loss': 0.39320028722286227} | train loss {'Reaction outcome loss': 0.1547087440047872, 'Total loss': 0.1547087440047872}
2022-12-31 04:16:36,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:36,503 INFO:     Epoch: 48
2022-12-31 04:16:38,107 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41224344074726105, 'Total loss': 0.41224344074726105} | train loss {'Reaction outcome loss': 0.14615123120703452, 'Total loss': 0.14615123120703452}
2022-12-31 04:16:38,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:38,107 INFO:     Epoch: 49
2022-12-31 04:16:39,737 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3787097819149494, 'Total loss': 0.3787097819149494} | train loss {'Reaction outcome loss': 0.14609186167059385, 'Total loss': 0.14609186167059385}
2022-12-31 04:16:39,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:39,738 INFO:     Epoch: 50
2022-12-31 04:16:41,364 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39858242372671765, 'Total loss': 0.39858242372671765} | train loss {'Reaction outcome loss': 0.14668855588485277, 'Total loss': 0.14668855588485277}
2022-12-31 04:16:41,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:41,365 INFO:     Epoch: 51
2022-12-31 04:16:42,987 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4111371524631977, 'Total loss': 0.4111371524631977} | train loss {'Reaction outcome loss': 0.14173266941350818, 'Total loss': 0.14173266941350818}
2022-12-31 04:16:42,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:42,987 INFO:     Epoch: 52
2022-12-31 04:16:44,611 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36633805731932323, 'Total loss': 0.36633805731932323} | train loss {'Reaction outcome loss': 0.14249795444975197, 'Total loss': 0.14249795444975197}
2022-12-31 04:16:44,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:44,612 INFO:     Epoch: 53
2022-12-31 04:16:46,228 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3838719966510932, 'Total loss': 0.3838719966510932} | train loss {'Reaction outcome loss': 0.14075861086446134, 'Total loss': 0.14075861086446134}
2022-12-31 04:16:46,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:46,229 INFO:     Epoch: 54
2022-12-31 04:16:47,842 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39635117451349894, 'Total loss': 0.39635117451349894} | train loss {'Reaction outcome loss': 0.1381317413183422, 'Total loss': 0.1381317413183422}
2022-12-31 04:16:47,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:47,842 INFO:     Epoch: 55
2022-12-31 04:16:49,466 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37503079523642857, 'Total loss': 0.37503079523642857} | train loss {'Reaction outcome loss': 0.13716610613229693, 'Total loss': 0.13716610613229693}
2022-12-31 04:16:49,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:49,467 INFO:     Epoch: 56
2022-12-31 04:16:51,089 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39278547167778016, 'Total loss': 0.39278547167778016} | train loss {'Reaction outcome loss': 0.13911309063914287, 'Total loss': 0.13911309063914287}
2022-12-31 04:16:51,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:51,090 INFO:     Epoch: 57
2022-12-31 04:16:52,715 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38362952719132104, 'Total loss': 0.38362952719132104} | train loss {'Reaction outcome loss': 0.13567575686961325, 'Total loss': 0.13567575686961325}
2022-12-31 04:16:52,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:52,715 INFO:     Epoch: 58
2022-12-31 04:16:54,339 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38157233198483786, 'Total loss': 0.38157233198483786} | train loss {'Reaction outcome loss': 0.14196603728392485, 'Total loss': 0.14196603728392485}
2022-12-31 04:16:54,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:54,339 INFO:     Epoch: 59
2022-12-31 04:16:55,947 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.36805321673552194, 'Total loss': 0.36805321673552194} | train loss {'Reaction outcome loss': 0.13793893430409007, 'Total loss': 0.13793893430409007}
2022-12-31 04:16:55,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:55,947 INFO:     Epoch: 60
2022-12-31 04:16:57,566 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43957566122214, 'Total loss': 0.43957566122214} | train loss {'Reaction outcome loss': 0.13246992738424815, 'Total loss': 0.13246992738424815}
2022-12-31 04:16:57,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:57,566 INFO:     Epoch: 61
2022-12-31 04:16:59,188 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3769715875387192, 'Total loss': 0.3769715875387192} | train loss {'Reaction outcome loss': 0.13554528671143024, 'Total loss': 0.13554528671143024}
2022-12-31 04:16:59,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:16:59,188 INFO:     Epoch: 62
2022-12-31 04:17:00,808 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3998363008101781, 'Total loss': 0.3998363008101781} | train loss {'Reaction outcome loss': 0.1310476940428919, 'Total loss': 0.1310476940428919}
2022-12-31 04:17:00,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:00,808 INFO:     Epoch: 63
2022-12-31 04:17:02,428 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4006151507298152, 'Total loss': 0.4006151507298152} | train loss {'Reaction outcome loss': 0.1335196646058635, 'Total loss': 0.1335196646058635}
2022-12-31 04:17:02,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:02,429 INFO:     Epoch: 64
2022-12-31 04:17:04,038 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3764277795950572, 'Total loss': 0.3764277795950572} | train loss {'Reaction outcome loss': 0.12668041705805133, 'Total loss': 0.12668041705805133}
2022-12-31 04:17:04,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:04,039 INFO:     Epoch: 65
2022-12-31 04:17:05,663 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39579681952794393, 'Total loss': 0.39579681952794393} | train loss {'Reaction outcome loss': 0.13144914883562614, 'Total loss': 0.13144914883562614}
2022-12-31 04:17:05,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:05,663 INFO:     Epoch: 66
2022-12-31 04:17:07,323 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3835581958293915, 'Total loss': 0.3835581958293915} | train loss {'Reaction outcome loss': 0.13419432705099546, 'Total loss': 0.13419432705099546}
2022-12-31 04:17:07,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:07,323 INFO:     Epoch: 67
2022-12-31 04:17:08,946 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4148879607518514, 'Total loss': 0.4148879607518514} | train loss {'Reaction outcome loss': 0.1290885381589549, 'Total loss': 0.1290885381589549}
2022-12-31 04:17:08,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:08,947 INFO:     Epoch: 68
2022-12-31 04:17:10,569 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3869859958688418, 'Total loss': 0.3869859958688418} | train loss {'Reaction outcome loss': 0.1291074472496605, 'Total loss': 0.1291074472496605}
2022-12-31 04:17:10,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:10,569 INFO:     Epoch: 69
2022-12-31 04:17:12,227 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4066902240117391, 'Total loss': 0.4066902240117391} | train loss {'Reaction outcome loss': 0.12412373946373945, 'Total loss': 0.12412373946373945}
2022-12-31 04:17:12,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:12,227 INFO:     Epoch: 70
2022-12-31 04:17:13,863 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38797350972890854, 'Total loss': 0.38797350972890854} | train loss {'Reaction outcome loss': 0.12754472776525316, 'Total loss': 0.12754472776525316}
2022-12-31 04:17:13,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:13,863 INFO:     Epoch: 71
2022-12-31 04:17:15,470 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39845915188392006, 'Total loss': 0.39845915188392006} | train loss {'Reaction outcome loss': 0.12773740706978826, 'Total loss': 0.12773740706978826}
2022-12-31 04:17:15,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:15,470 INFO:     Epoch: 72
2022-12-31 04:17:17,082 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37420664305488266, 'Total loss': 0.37420664305488266} | train loss {'Reaction outcome loss': 0.12591512332251048, 'Total loss': 0.12591512332251048}
2022-12-31 04:17:17,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:17,082 INFO:     Epoch: 73
2022-12-31 04:17:18,695 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3989740242560705, 'Total loss': 0.3989740242560705} | train loss {'Reaction outcome loss': 0.12745985773938667, 'Total loss': 0.12745985773938667}
2022-12-31 04:17:18,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:18,695 INFO:     Epoch: 74
2022-12-31 04:17:20,306 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4040872265895208, 'Total loss': 0.4040872265895208} | train loss {'Reaction outcome loss': 0.12202558834088859, 'Total loss': 0.12202558834088859}
2022-12-31 04:17:20,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:20,306 INFO:     Epoch: 75
2022-12-31 04:17:21,919 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3813593596220016, 'Total loss': 0.3813593596220016} | train loss {'Reaction outcome loss': 0.12909374810228852, 'Total loss': 0.12909374810228852}
2022-12-31 04:17:21,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:21,920 INFO:     Epoch: 76
2022-12-31 04:17:23,524 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38963087896505993, 'Total loss': 0.38963087896505993} | train loss {'Reaction outcome loss': 0.12704679409743866, 'Total loss': 0.12704679409743866}
2022-12-31 04:17:23,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:23,524 INFO:     Epoch: 77
2022-12-31 04:17:25,134 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3729753059955935, 'Total loss': 0.3729753059955935} | train loss {'Reaction outcome loss': 0.12137796112970597, 'Total loss': 0.12137796112970597}
2022-12-31 04:17:25,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:25,134 INFO:     Epoch: 78
2022-12-31 04:17:26,797 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4408242752154668, 'Total loss': 0.4408242752154668} | train loss {'Reaction outcome loss': 0.12270067224618168, 'Total loss': 0.12270067224618168}
2022-12-31 04:17:26,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:26,798 INFO:     Epoch: 79
2022-12-31 04:17:28,462 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39501704374949137, 'Total loss': 0.39501704374949137} | train loss {'Reaction outcome loss': 0.12643867029481148, 'Total loss': 0.12643867029481148}
2022-12-31 04:17:28,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:28,462 INFO:     Epoch: 80
2022-12-31 04:17:30,073 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.39204731782277424, 'Total loss': 0.39204731782277424} | train loss {'Reaction outcome loss': 0.1253612605117572, 'Total loss': 0.1253612605117572}
2022-12-31 04:17:30,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:30,073 INFO:     Epoch: 81
2022-12-31 04:17:31,685 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3805014505982399, 'Total loss': 0.3805014505982399} | train loss {'Reaction outcome loss': 0.12028387858760217, 'Total loss': 0.12028387858760217}
2022-12-31 04:17:31,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:31,686 INFO:     Epoch: 82
2022-12-31 04:17:33,308 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3968143870433172, 'Total loss': 0.3968143870433172} | train loss {'Reaction outcome loss': 0.11740855405788761, 'Total loss': 0.11740855405788761}
2022-12-31 04:17:33,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:33,309 INFO:     Epoch: 83
2022-12-31 04:17:34,939 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.35897944768269857, 'Total loss': 0.35897944768269857} | train loss {'Reaction outcome loss': 0.11909131984452541, 'Total loss': 0.11909131984452541}
2022-12-31 04:17:34,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:34,939 INFO:     Epoch: 84
2022-12-31 04:17:36,565 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40415931145350137, 'Total loss': 0.40415931145350137} | train loss {'Reaction outcome loss': 0.1242043407474884, 'Total loss': 0.1242043407474884}
2022-12-31 04:17:36,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:36,565 INFO:     Epoch: 85
2022-12-31 04:17:38,227 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3784712304671605, 'Total loss': 0.3784712304671605} | train loss {'Reaction outcome loss': 0.12077167290292404, 'Total loss': 0.12077167290292404}
2022-12-31 04:17:38,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:38,228 INFO:     Epoch: 86
2022-12-31 04:17:39,890 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4257141952713331, 'Total loss': 0.4257141952713331} | train loss {'Reaction outcome loss': 0.12216665072575805, 'Total loss': 0.12216665072575805}
2022-12-31 04:17:39,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:39,891 INFO:     Epoch: 87
2022-12-31 04:17:41,506 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3923692693312963, 'Total loss': 0.3923692693312963} | train loss {'Reaction outcome loss': 0.11623929052080527, 'Total loss': 0.11623929052080527}
2022-12-31 04:17:41,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:41,506 INFO:     Epoch: 88
2022-12-31 04:17:43,169 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.36259230971336365, 'Total loss': 0.36259230971336365} | train loss {'Reaction outcome loss': 0.11460989229448572, 'Total loss': 0.11460989229448572}
2022-12-31 04:17:43,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:43,170 INFO:     Epoch: 89
2022-12-31 04:17:44,832 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4266030738751094, 'Total loss': 0.4266030738751094} | train loss {'Reaction outcome loss': 0.11658246815288979, 'Total loss': 0.11658246815288979}
2022-12-31 04:17:44,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:44,833 INFO:     Epoch: 90
2022-12-31 04:17:46,495 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3977422595024109, 'Total loss': 0.3977422595024109} | train loss {'Reaction outcome loss': 0.1172383281763346, 'Total loss': 0.1172383281763346}
2022-12-31 04:17:46,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:46,496 INFO:     Epoch: 91
2022-12-31 04:17:48,159 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.37419984297206005, 'Total loss': 0.37419984297206005} | train loss {'Reaction outcome loss': 0.12068352037696994, 'Total loss': 0.12068352037696994}
2022-12-31 04:17:48,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:48,159 INFO:     Epoch: 92
2022-12-31 04:17:49,819 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3794100580116113, 'Total loss': 0.3794100580116113} | train loss {'Reaction outcome loss': 0.12281251682535461, 'Total loss': 0.12281251682535461}
2022-12-31 04:17:49,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:49,820 INFO:     Epoch: 93
2022-12-31 04:17:51,420 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4232581575711568, 'Total loss': 0.4232581575711568} | train loss {'Reaction outcome loss': 0.1406021217985983, 'Total loss': 0.1406021217985983}
2022-12-31 04:17:51,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:51,421 INFO:     Epoch: 94
2022-12-31 04:17:53,047 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38688090940316516, 'Total loss': 0.38688090940316516} | train loss {'Reaction outcome loss': 0.1418947999939163, 'Total loss': 0.1418947999939163}
2022-12-31 04:17:53,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:53,048 INFO:     Epoch: 95
2022-12-31 04:17:54,661 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40640525966882707, 'Total loss': 0.40640525966882707} | train loss {'Reaction outcome loss': 0.11699596724128755, 'Total loss': 0.11699596724128755}
2022-12-31 04:17:54,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:54,661 INFO:     Epoch: 96
2022-12-31 04:17:56,375 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40612332075834273, 'Total loss': 0.40612332075834273} | train loss {'Reaction outcome loss': 0.11282126107202518, 'Total loss': 0.11282126107202518}
2022-12-31 04:17:56,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:56,375 INFO:     Epoch: 97
2022-12-31 04:17:58,033 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41523922234773636, 'Total loss': 0.41523922234773636} | train loss {'Reaction outcome loss': 0.11168507422806452, 'Total loss': 0.11168507422806452}
2022-12-31 04:17:58,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:58,033 INFO:     Epoch: 98
2022-12-31 04:17:59,641 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4206811835368474, 'Total loss': 0.4206811835368474} | train loss {'Reaction outcome loss': 0.11050367275290056, 'Total loss': 0.11050367275290056}
2022-12-31 04:17:59,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:17:59,642 INFO:     Epoch: 99
2022-12-31 04:18:01,300 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3856291498988867, 'Total loss': 0.3856291498988867} | train loss {'Reaction outcome loss': 0.11284150140299049, 'Total loss': 0.11284150140299049}
2022-12-31 04:18:01,300 INFO:     Best model found after epoch 13 of 100.
2022-12-31 04:18:01,300 INFO:   Done with stage: TRAINING
2022-12-31 04:18:01,300 INFO:   Starting stage: EVALUATION
2022-12-31 04:18:01,430 INFO:   Done with stage: EVALUATION
2022-12-31 04:18:01,431 INFO:   Leaving out SEQ value Fold_5
2022-12-31 04:18:01,443 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 04:18:01,443 INFO:   Starting stage: FEATURE SCALING
2022-12-31 04:18:02,085 INFO:   Done with stage: FEATURE SCALING
2022-12-31 04:18:02,085 INFO:   Starting stage: SCALING TARGETS
2022-12-31 04:18:02,158 INFO:   Done with stage: SCALING TARGETS
2022-12-31 04:18:02,158 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:18:02,158 INFO:     No hyperparam tuning for this model
2022-12-31 04:18:02,158 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:18:02,158 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 04:18:02,159 INFO:     None feature selector for col prot
2022-12-31 04:18:02,159 INFO:     None feature selector for col prot
2022-12-31 04:18:02,159 INFO:     None feature selector for col prot
2022-12-31 04:18:02,160 INFO:     None feature selector for col chem
2022-12-31 04:18:02,160 INFO:     None feature selector for col chem
2022-12-31 04:18:02,160 INFO:     None feature selector for col chem
2022-12-31 04:18:02,160 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 04:18:02,160 INFO:   Starting stage: BUILD MODEL
2022-12-31 04:18:02,162 INFO:     Number of params in model 224011
2022-12-31 04:18:02,165 INFO:   Done with stage: BUILD MODEL
2022-12-31 04:18:02,165 INFO:   Starting stage: TRAINING
2022-12-31 04:18:02,209 INFO:     Val loss before train {'Reaction outcome loss': 1.0051240801811219, 'Total loss': 1.0051240801811219}
2022-12-31 04:18:02,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:02,209 INFO:     Epoch: 0
2022-12-31 04:18:03,821 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5919516623020172, 'Total loss': 0.5919516623020172} | train loss {'Reaction outcome loss': 0.7824220541151853, 'Total loss': 0.7824220541151853}
2022-12-31 04:18:03,822 INFO:     Found new best model at epoch 0
2022-12-31 04:18:03,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:03,823 INFO:     Epoch: 1
2022-12-31 04:18:05,436 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48005857268969215, 'Total loss': 0.48005857268969215} | train loss {'Reaction outcome loss': 0.5139614648659737, 'Total loss': 0.5139614648659737}
2022-12-31 04:18:05,436 INFO:     Found new best model at epoch 1
2022-12-31 04:18:05,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:05,437 INFO:     Epoch: 2
2022-12-31 04:18:07,048 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4752366036176682, 'Total loss': 0.4752366036176682} | train loss {'Reaction outcome loss': 0.44249586701823485, 'Total loss': 0.44249586701823485}
2022-12-31 04:18:07,049 INFO:     Found new best model at epoch 2
2022-12-31 04:18:07,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:07,050 INFO:     Epoch: 3
2022-12-31 04:18:08,658 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45625474750995637, 'Total loss': 0.45625474750995637} | train loss {'Reaction outcome loss': 0.403598699436291, 'Total loss': 0.403598699436291}
2022-12-31 04:18:08,658 INFO:     Found new best model at epoch 3
2022-12-31 04:18:08,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:08,659 INFO:     Epoch: 4
2022-12-31 04:18:10,289 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4076506038506826, 'Total loss': 0.4076506038506826} | train loss {'Reaction outcome loss': 0.3693313025449157, 'Total loss': 0.3693313025449157}
2022-12-31 04:18:10,290 INFO:     Found new best model at epoch 4
2022-12-31 04:18:10,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:10,291 INFO:     Epoch: 5
2022-12-31 04:18:11,920 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4193900833527247, 'Total loss': 0.4193900833527247} | train loss {'Reaction outcome loss': 0.34793236717205184, 'Total loss': 0.34793236717205184}
2022-12-31 04:18:11,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:11,920 INFO:     Epoch: 6
2022-12-31 04:18:13,549 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42214262584845225, 'Total loss': 0.42214262584845225} | train loss {'Reaction outcome loss': 0.32729248718664533, 'Total loss': 0.32729248718664533}
2022-12-31 04:18:13,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:13,550 INFO:     Epoch: 7
2022-12-31 04:18:15,181 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4142689570784569, 'Total loss': 0.4142689570784569} | train loss {'Reaction outcome loss': 0.30983158039594816, 'Total loss': 0.30983158039594816}
2022-12-31 04:18:15,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:15,181 INFO:     Epoch: 8
2022-12-31 04:18:16,805 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.423183266321818, 'Total loss': 0.423183266321818} | train loss {'Reaction outcome loss': 0.2904805260364114, 'Total loss': 0.2904805260364114}
2022-12-31 04:18:16,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:16,805 INFO:     Epoch: 9
2022-12-31 04:18:18,423 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4004622687896093, 'Total loss': 0.4004622687896093} | train loss {'Reaction outcome loss': 0.2777730979644004, 'Total loss': 0.2777730979644004}
2022-12-31 04:18:18,423 INFO:     Found new best model at epoch 9
2022-12-31 04:18:18,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:18,424 INFO:     Epoch: 10
2022-12-31 04:18:20,041 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4027921050786972, 'Total loss': 0.4027921050786972} | train loss {'Reaction outcome loss': 0.2672639788810957, 'Total loss': 0.2672639788810957}
2022-12-31 04:18:20,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:20,041 INFO:     Epoch: 11
2022-12-31 04:18:21,706 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4141634685297807, 'Total loss': 0.4141634685297807} | train loss {'Reaction outcome loss': 0.254499981536224, 'Total loss': 0.254499981536224}
2022-12-31 04:18:21,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:21,706 INFO:     Epoch: 12
2022-12-31 04:18:23,369 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4137749046087265, 'Total loss': 0.4137749046087265} | train loss {'Reaction outcome loss': 0.24683627638199268, 'Total loss': 0.24683627638199268}
2022-12-31 04:18:23,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:23,370 INFO:     Epoch: 13
2022-12-31 04:18:24,986 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42610575755437213, 'Total loss': 0.42610575755437213} | train loss {'Reaction outcome loss': 0.23814281575812113, 'Total loss': 0.23814281575812113}
2022-12-31 04:18:24,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:24,986 INFO:     Epoch: 14
2022-12-31 04:18:26,629 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39839298874139784, 'Total loss': 0.39839298874139784} | train loss {'Reaction outcome loss': 0.22986815276720463, 'Total loss': 0.22986815276720463}
2022-12-31 04:18:26,629 INFO:     Found new best model at epoch 14
2022-12-31 04:18:26,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:26,630 INFO:     Epoch: 15
2022-12-31 04:18:28,263 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.399808269739151, 'Total loss': 0.399808269739151} | train loss {'Reaction outcome loss': 0.22302179531419536, 'Total loss': 0.22302179531419536}
2022-12-31 04:18:28,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:28,263 INFO:     Epoch: 16
2022-12-31 04:18:29,893 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41900007327397665, 'Total loss': 0.41900007327397665} | train loss {'Reaction outcome loss': 0.21870549319863372, 'Total loss': 0.21870549319863372}
2022-12-31 04:18:29,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:29,894 INFO:     Epoch: 17
2022-12-31 04:18:31,525 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39319638709227245, 'Total loss': 0.39319638709227245} | train loss {'Reaction outcome loss': 0.21079132892863844, 'Total loss': 0.21079132892863844}
2022-12-31 04:18:31,525 INFO:     Found new best model at epoch 17
2022-12-31 04:18:31,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:31,526 INFO:     Epoch: 18
2022-12-31 04:18:33,156 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40638892302910484, 'Total loss': 0.40638892302910484} | train loss {'Reaction outcome loss': 0.20299147593953548, 'Total loss': 0.20299147593953548}
2022-12-31 04:18:33,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:33,156 INFO:     Epoch: 19
2022-12-31 04:18:34,786 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4444633493820826, 'Total loss': 0.4444633493820826} | train loss {'Reaction outcome loss': 0.2012465361451952, 'Total loss': 0.2012465361451952}
2022-12-31 04:18:34,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:34,787 INFO:     Epoch: 20
2022-12-31 04:18:36,423 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40687729517618815, 'Total loss': 0.40687729517618815} | train loss {'Reaction outcome loss': 0.19648054897085854, 'Total loss': 0.19648054897085854}
2022-12-31 04:18:36,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:36,423 INFO:     Epoch: 21
2022-12-31 04:18:38,038 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42351790964603425, 'Total loss': 0.42351790964603425} | train loss {'Reaction outcome loss': 0.19261218785620984, 'Total loss': 0.19261218785620984}
2022-12-31 04:18:38,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:38,038 INFO:     Epoch: 22
2022-12-31 04:18:39,703 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41440808872381846, 'Total loss': 0.41440808872381846} | train loss {'Reaction outcome loss': 0.1895934624079655, 'Total loss': 0.1895934624079655}
2022-12-31 04:18:39,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:39,704 INFO:     Epoch: 23
2022-12-31 04:18:41,317 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43933318853378295, 'Total loss': 0.43933318853378295} | train loss {'Reaction outcome loss': 0.18584983507406624, 'Total loss': 0.18584983507406624}
2022-12-31 04:18:41,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:41,317 INFO:     Epoch: 24
2022-12-31 04:18:42,936 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4128128424286842, 'Total loss': 0.4128128424286842} | train loss {'Reaction outcome loss': 0.18239234188833822, 'Total loss': 0.18239234188833822}
2022-12-31 04:18:42,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:42,937 INFO:     Epoch: 25
2022-12-31 04:18:44,547 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4170389225085576, 'Total loss': 0.4170389225085576} | train loss {'Reaction outcome loss': 0.17757146874113203, 'Total loss': 0.17757146874113203}
2022-12-31 04:18:44,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:44,547 INFO:     Epoch: 26
2022-12-31 04:18:46,181 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41044981392721336, 'Total loss': 0.41044981392721336} | train loss {'Reaction outcome loss': 0.17469068663026666, 'Total loss': 0.17469068663026666}
2022-12-31 04:18:46,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:46,182 INFO:     Epoch: 27
2022-12-31 04:18:47,805 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4014910946289698, 'Total loss': 0.4014910946289698} | train loss {'Reaction outcome loss': 0.17051282625927822, 'Total loss': 0.17051282625927822}
2022-12-31 04:18:47,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:47,805 INFO:     Epoch: 28
2022-12-31 04:18:49,474 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41921861469745636, 'Total loss': 0.41921861469745636} | train loss {'Reaction outcome loss': 0.16947815534305702, 'Total loss': 0.16947815534305702}
2022-12-31 04:18:49,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:49,474 INFO:     Epoch: 29
2022-12-31 04:18:51,101 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4128653590877851, 'Total loss': 0.4128653590877851} | train loss {'Reaction outcome loss': 0.1691629866891228, 'Total loss': 0.1691629866891228}
2022-12-31 04:18:51,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:51,102 INFO:     Epoch: 30
2022-12-31 04:18:52,770 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4052762269973755, 'Total loss': 0.4052762269973755} | train loss {'Reaction outcome loss': 0.1646208251575983, 'Total loss': 0.1646208251575983}
2022-12-31 04:18:52,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:52,770 INFO:     Epoch: 31
2022-12-31 04:18:54,391 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41723765631516774, 'Total loss': 0.41723765631516774} | train loss {'Reaction outcome loss': 0.1632288045011165, 'Total loss': 0.1632288045011165}
2022-12-31 04:18:54,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:54,392 INFO:     Epoch: 32
2022-12-31 04:18:56,060 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4194095224142075, 'Total loss': 0.4194095224142075} | train loss {'Reaction outcome loss': 0.15481262518570418, 'Total loss': 0.15481262518570418}
2022-12-31 04:18:56,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:56,060 INFO:     Epoch: 33
2022-12-31 04:18:57,729 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4070964073141416, 'Total loss': 0.4070964073141416} | train loss {'Reaction outcome loss': 0.15522483626501601, 'Total loss': 0.15522483626501601}
2022-12-31 04:18:57,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:57,729 INFO:     Epoch: 34
2022-12-31 04:18:59,397 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43514539698759713, 'Total loss': 0.43514539698759713} | train loss {'Reaction outcome loss': 0.15417298277678634, 'Total loss': 0.15417298277678634}
2022-12-31 04:18:59,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:18:59,398 INFO:     Epoch: 35
2022-12-31 04:19:01,023 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4219767679770788, 'Total loss': 0.4219767679770788} | train loss {'Reaction outcome loss': 0.15459249511071976, 'Total loss': 0.15459249511071976}
2022-12-31 04:19:01,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:01,024 INFO:     Epoch: 36
2022-12-31 04:19:02,677 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38392421305179597, 'Total loss': 0.38392421305179597} | train loss {'Reaction outcome loss': 0.1525384692596238, 'Total loss': 0.1525384692596238}
2022-12-31 04:19:02,677 INFO:     Found new best model at epoch 36
2022-12-31 04:19:02,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:02,679 INFO:     Epoch: 37
2022-12-31 04:19:04,310 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40753059486548104, 'Total loss': 0.40753059486548104} | train loss {'Reaction outcome loss': 0.14921077401024233, 'Total loss': 0.14921077401024233}
2022-12-31 04:19:04,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:04,310 INFO:     Epoch: 38
2022-12-31 04:19:05,951 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41608141859372455, 'Total loss': 0.41608141859372455} | train loss {'Reaction outcome loss': 0.14934433796627966, 'Total loss': 0.14934433796627966}
2022-12-31 04:19:05,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:05,952 INFO:     Epoch: 39
2022-12-31 04:19:07,594 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4347110867500305, 'Total loss': 0.4347110867500305} | train loss {'Reaction outcome loss': 0.14598086443040453, 'Total loss': 0.14598086443040453}
2022-12-31 04:19:07,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:07,594 INFO:     Epoch: 40
2022-12-31 04:19:09,214 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40676318407058715, 'Total loss': 0.40676318407058715} | train loss {'Reaction outcome loss': 0.14370123131220844, 'Total loss': 0.14370123131220844}
2022-12-31 04:19:09,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:09,214 INFO:     Epoch: 41
2022-12-31 04:19:10,836 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40793118079503377, 'Total loss': 0.40793118079503377} | train loss {'Reaction outcome loss': 0.1413504894039449, 'Total loss': 0.1413504894039449}
2022-12-31 04:19:10,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:10,837 INFO:     Epoch: 42
2022-12-31 04:19:12,454 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40849532832702, 'Total loss': 0.40849532832702} | train loss {'Reaction outcome loss': 0.14388204419091075, 'Total loss': 0.14388204419091075}
2022-12-31 04:19:12,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:12,455 INFO:     Epoch: 43
2022-12-31 04:19:14,124 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42533961633841194, 'Total loss': 0.42533961633841194} | train loss {'Reaction outcome loss': 0.14213906197105988, 'Total loss': 0.14213906197105988}
2022-12-31 04:19:14,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:14,124 INFO:     Epoch: 44
2022-12-31 04:19:15,752 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40741268545389175, 'Total loss': 0.40741268545389175} | train loss {'Reaction outcome loss': 0.14259330233364007, 'Total loss': 0.14259330233364007}
2022-12-31 04:19:15,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:15,752 INFO:     Epoch: 45
2022-12-31 04:19:17,422 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3905856321255366, 'Total loss': 0.3905856321255366} | train loss {'Reaction outcome loss': 0.1385163451151566, 'Total loss': 0.1385163451151566}
2022-12-31 04:19:17,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:17,423 INFO:     Epoch: 46
2022-12-31 04:19:19,047 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4079775979121526, 'Total loss': 0.4079775979121526} | train loss {'Reaction outcome loss': 0.1388937242510678, 'Total loss': 0.1388937242510678}
2022-12-31 04:19:19,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:19,047 INFO:     Epoch: 47
2022-12-31 04:19:20,713 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.377275188267231, 'Total loss': 0.377275188267231} | train loss {'Reaction outcome loss': 0.14252347009935643, 'Total loss': 0.14252347009935643}
2022-12-31 04:19:20,713 INFO:     Found new best model at epoch 47
2022-12-31 04:19:20,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:20,714 INFO:     Epoch: 48
2022-12-31 04:19:22,348 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4292197744051615, 'Total loss': 0.4292197744051615} | train loss {'Reaction outcome loss': 0.13435045337566723, 'Total loss': 0.13435045337566723}
2022-12-31 04:19:22,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:22,348 INFO:     Epoch: 49
2022-12-31 04:19:23,981 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4017792115608851, 'Total loss': 0.4017792115608851} | train loss {'Reaction outcome loss': 0.135047244642683, 'Total loss': 0.135047244642683}
2022-12-31 04:19:23,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:23,982 INFO:     Epoch: 50
2022-12-31 04:19:25,612 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4225419133901596, 'Total loss': 0.4225419133901596} | train loss {'Reaction outcome loss': 0.1358093934735478, 'Total loss': 0.1358093934735478}
2022-12-31 04:19:25,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:25,612 INFO:     Epoch: 51
2022-12-31 04:19:27,244 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4227682054042816, 'Total loss': 0.4227682054042816} | train loss {'Reaction outcome loss': 0.13278413817138557, 'Total loss': 0.13278413817138557}
2022-12-31 04:19:27,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:27,245 INFO:     Epoch: 52
2022-12-31 04:19:28,878 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41307577590147654, 'Total loss': 0.41307577590147654} | train loss {'Reaction outcome loss': 0.1319001136509036, 'Total loss': 0.1319001136509036}
2022-12-31 04:19:28,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:28,879 INFO:     Epoch: 53
2022-12-31 04:19:30,501 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4275319933891296, 'Total loss': 0.4275319933891296} | train loss {'Reaction outcome loss': 0.13124727369000336, 'Total loss': 0.13124727369000336}
2022-12-31 04:19:30,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:30,501 INFO:     Epoch: 54
2022-12-31 04:19:32,145 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42359657188256583, 'Total loss': 0.42359657188256583} | train loss {'Reaction outcome loss': 0.1339438250590963, 'Total loss': 0.1339438250590963}
2022-12-31 04:19:32,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:32,145 INFO:     Epoch: 55
2022-12-31 04:19:33,779 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.405781552195549, 'Total loss': 0.405781552195549} | train loss {'Reaction outcome loss': 0.1325243477111124, 'Total loss': 0.1325243477111124}
2022-12-31 04:19:33,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:33,779 INFO:     Epoch: 56
2022-12-31 04:19:35,411 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4126774882276853, 'Total loss': 0.4126774882276853} | train loss {'Reaction outcome loss': 0.12981014756909454, 'Total loss': 0.12981014756909454}
2022-12-31 04:19:35,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:35,411 INFO:     Epoch: 57
2022-12-31 04:19:37,044 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43285067081451417, 'Total loss': 0.43285067081451417} | train loss {'Reaction outcome loss': 0.1301705065672538, 'Total loss': 0.1301705065672538}
2022-12-31 04:19:37,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:37,045 INFO:     Epoch: 58
2022-12-31 04:19:38,674 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4422661249836286, 'Total loss': 0.4422661249836286} | train loss {'Reaction outcome loss': 0.1322995903313375, 'Total loss': 0.1322995903313375}
2022-12-31 04:19:38,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:38,674 INFO:     Epoch: 59
2022-12-31 04:19:40,293 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3986894678324461, 'Total loss': 0.3986894678324461} | train loss {'Reaction outcome loss': 0.12970743478958358, 'Total loss': 0.12970743478958358}
2022-12-31 04:19:40,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:40,294 INFO:     Epoch: 60
2022-12-31 04:19:41,925 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42126548091570537, 'Total loss': 0.42126548091570537} | train loss {'Reaction outcome loss': 0.12522137443793918, 'Total loss': 0.12522137443793918}
2022-12-31 04:19:41,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:41,925 INFO:     Epoch: 61
2022-12-31 04:19:43,559 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43313557704289757, 'Total loss': 0.43313557704289757} | train loss {'Reaction outcome loss': 0.1306609704465158, 'Total loss': 0.1306609704465158}
2022-12-31 04:19:43,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:43,559 INFO:     Epoch: 62
2022-12-31 04:19:45,190 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40768857051928836, 'Total loss': 0.40768857051928836} | train loss {'Reaction outcome loss': 0.12958942764415154, 'Total loss': 0.12958942764415154}
2022-12-31 04:19:45,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:45,190 INFO:     Epoch: 63
2022-12-31 04:19:46,831 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4248107453187307, 'Total loss': 0.4248107453187307} | train loss {'Reaction outcome loss': 0.12374037294732643, 'Total loss': 0.12374037294732643}
2022-12-31 04:19:46,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:46,832 INFO:     Epoch: 64
2022-12-31 04:19:48,450 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4047891051818927, 'Total loss': 0.4047891051818927} | train loss {'Reaction outcome loss': 0.1225166037419831, 'Total loss': 0.1225166037419831}
2022-12-31 04:19:48,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:48,451 INFO:     Epoch: 65
2022-12-31 04:19:50,175 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4206858158111572, 'Total loss': 0.4206858158111572} | train loss {'Reaction outcome loss': 0.12740781307657542, 'Total loss': 0.12740781307657542}
2022-12-31 04:19:50,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:50,175 INFO:     Epoch: 66
2022-12-31 04:19:51,796 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4249346166849136, 'Total loss': 0.4249346166849136} | train loss {'Reaction outcome loss': 0.12283277303982351, 'Total loss': 0.12283277303982351}
2022-12-31 04:19:51,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:51,796 INFO:     Epoch: 67
2022-12-31 04:19:53,511 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4061679402987162, 'Total loss': 0.4061679402987162} | train loss {'Reaction outcome loss': 0.12286232869369432, 'Total loss': 0.12286232869369432}
2022-12-31 04:19:53,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:53,512 INFO:     Epoch: 68
2022-12-31 04:19:55,135 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4150380184253057, 'Total loss': 0.4150380184253057} | train loss {'Reaction outcome loss': 0.12174952726320293, 'Total loss': 0.12174952726320293}
2022-12-31 04:19:55,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:55,135 INFO:     Epoch: 69
2022-12-31 04:19:56,805 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.425773561000824, 'Total loss': 0.425773561000824} | train loss {'Reaction outcome loss': 0.12277433690732674, 'Total loss': 0.12277433690732674}
2022-12-31 04:19:56,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:56,805 INFO:     Epoch: 70
2022-12-31 04:19:58,429 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4248737871646881, 'Total loss': 0.4248737871646881} | train loss {'Reaction outcome loss': 0.12027152456235585, 'Total loss': 0.12027152456235585}
2022-12-31 04:19:58,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:19:58,429 INFO:     Epoch: 71
2022-12-31 04:20:00,064 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4127474159002304, 'Total loss': 0.4127474159002304} | train loss {'Reaction outcome loss': 0.12328143896440898, 'Total loss': 0.12328143896440898}
2022-12-31 04:20:00,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:00,064 INFO:     Epoch: 72
2022-12-31 04:20:01,700 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4264084190130234, 'Total loss': 0.4264084190130234} | train loss {'Reaction outcome loss': 0.12382314801602776, 'Total loss': 0.12382314801602776}
2022-12-31 04:20:01,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:01,700 INFO:     Epoch: 73
2022-12-31 04:20:03,336 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4317272394895554, 'Total loss': 0.4317272394895554} | train loss {'Reaction outcome loss': 0.12288900384753404, 'Total loss': 0.12288900384753404}
2022-12-31 04:20:03,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:03,336 INFO:     Epoch: 74
2022-12-31 04:20:04,974 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40934591690699257, 'Total loss': 0.40934591690699257} | train loss {'Reaction outcome loss': 0.12381941574333162, 'Total loss': 0.12381941574333162}
2022-12-31 04:20:04,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:04,974 INFO:     Epoch: 75
2022-12-31 04:20:06,599 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4394887790083885, 'Total loss': 0.4394887790083885} | train loss {'Reaction outcome loss': 0.1259202078431979, 'Total loss': 0.1259202078431979}
2022-12-31 04:20:06,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:06,600 INFO:     Epoch: 76
2022-12-31 04:20:08,231 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4193037341038386, 'Total loss': 0.4193037341038386} | train loss {'Reaction outcome loss': 0.11947709675508447, 'Total loss': 0.11947709675508447}
2022-12-31 04:20:08,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:08,232 INFO:     Epoch: 77
2022-12-31 04:20:09,869 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.445350477596124, 'Total loss': 0.445350477596124} | train loss {'Reaction outcome loss': 0.12300920116779014, 'Total loss': 0.12300920116779014}
2022-12-31 04:20:09,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:09,869 INFO:     Epoch: 78
2022-12-31 04:20:11,506 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42282915314038594, 'Total loss': 0.42282915314038594} | train loss {'Reaction outcome loss': 0.1226108522080423, 'Total loss': 0.1226108522080423}
2022-12-31 04:20:11,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:11,507 INFO:     Epoch: 79
2022-12-31 04:20:13,143 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41387850046157837, 'Total loss': 0.41387850046157837} | train loss {'Reaction outcome loss': 0.12082411269304286, 'Total loss': 0.12082411269304286}
2022-12-31 04:20:13,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:13,143 INFO:     Epoch: 80
2022-12-31 04:20:14,782 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40811634610096614, 'Total loss': 0.40811634610096614} | train loss {'Reaction outcome loss': 0.11565192802288042, 'Total loss': 0.11565192802288042}
2022-12-31 04:20:14,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:14,782 INFO:     Epoch: 81
2022-12-31 04:20:16,237 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40523907852669555, 'Total loss': 0.40523907852669555} | train loss {'Reaction outcome loss': 0.11787083686080624, 'Total loss': 0.11787083686080624}
2022-12-31 04:20:16,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:16,237 INFO:     Epoch: 82
2022-12-31 04:20:17,358 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4054609020551046, 'Total loss': 0.4054609020551046} | train loss {'Reaction outcome loss': 0.11491149857922689, 'Total loss': 0.11491149857922689}
2022-12-31 04:20:17,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:17,358 INFO:     Epoch: 83
2022-12-31 04:20:18,472 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4316619684298833, 'Total loss': 0.4316619684298833} | train loss {'Reaction outcome loss': 0.1156344323735079, 'Total loss': 0.1156344323735079}
2022-12-31 04:20:18,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:18,473 INFO:     Epoch: 84
2022-12-31 04:20:19,588 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4551386654376984, 'Total loss': 0.4551386654376984} | train loss {'Reaction outcome loss': 0.11603012852142111, 'Total loss': 0.11603012852142111}
2022-12-31 04:20:19,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:19,588 INFO:     Epoch: 85
2022-12-31 04:20:20,848 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40965832968552907, 'Total loss': 0.40965832968552907} | train loss {'Reaction outcome loss': 0.11502281487633605, 'Total loss': 0.11502281487633605}
2022-12-31 04:20:20,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:20,848 INFO:     Epoch: 86
2022-12-31 04:20:22,482 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43913345237572987, 'Total loss': 0.43913345237572987} | train loss {'Reaction outcome loss': 0.12148346936343649, 'Total loss': 0.12148346936343649}
2022-12-31 04:20:22,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:22,483 INFO:     Epoch: 87
2022-12-31 04:20:24,136 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39516214032967883, 'Total loss': 0.39516214032967883} | train loss {'Reaction outcome loss': 0.12429081718689537, 'Total loss': 0.12429081718689537}
2022-12-31 04:20:24,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:24,136 INFO:     Epoch: 88
2022-12-31 04:20:25,801 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44590349197387696, 'Total loss': 0.44590349197387696} | train loss {'Reaction outcome loss': 0.11835446642772278, 'Total loss': 0.11835446642772278}
2022-12-31 04:20:25,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:25,801 INFO:     Epoch: 89
2022-12-31 04:20:27,467 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4223238448301951, 'Total loss': 0.4223238448301951} | train loss {'Reaction outcome loss': 0.11280500580597037, 'Total loss': 0.11280500580597037}
2022-12-31 04:20:27,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:27,467 INFO:     Epoch: 90
2022-12-31 04:20:29,133 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39691722989082334, 'Total loss': 0.39691722989082334} | train loss {'Reaction outcome loss': 0.11097463407883226, 'Total loss': 0.11097463407883226}
2022-12-31 04:20:29,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:29,134 INFO:     Epoch: 91
2022-12-31 04:20:30,781 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4140533010164897, 'Total loss': 0.4140533010164897} | train loss {'Reaction outcome loss': 0.1144304052810605, 'Total loss': 0.1144304052810605}
2022-12-31 04:20:30,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:30,781 INFO:     Epoch: 92
2022-12-31 04:20:32,394 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3952886998653412, 'Total loss': 0.3952886998653412} | train loss {'Reaction outcome loss': 0.1155029729744991, 'Total loss': 0.1155029729744991}
2022-12-31 04:20:32,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:32,394 INFO:     Epoch: 93
2022-12-31 04:20:34,061 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4057678004105886, 'Total loss': 0.4057678004105886} | train loss {'Reaction outcome loss': 0.11761221988630961, 'Total loss': 0.11761221988630961}
2022-12-31 04:20:34,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:34,061 INFO:     Epoch: 94
2022-12-31 04:20:35,687 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43733041485150653, 'Total loss': 0.43733041485150653} | train loss {'Reaction outcome loss': 0.1168677434014217, 'Total loss': 0.1168677434014217}
2022-12-31 04:20:35,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:35,687 INFO:     Epoch: 95
2022-12-31 04:20:37,353 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.421226610429585, 'Total loss': 0.421226610429585} | train loss {'Reaction outcome loss': 0.11780001474914245, 'Total loss': 0.11780001474914245}
2022-12-31 04:20:37,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:37,354 INFO:     Epoch: 96
2022-12-31 04:20:39,008 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40939531326293943, 'Total loss': 0.40939531326293943} | train loss {'Reaction outcome loss': 0.11682831615693733, 'Total loss': 0.11682831615693733}
2022-12-31 04:20:39,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:39,008 INFO:     Epoch: 97
2022-12-31 04:20:40,676 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4126645565032959, 'Total loss': 0.4126645565032959} | train loss {'Reaction outcome loss': 0.12183766404296262, 'Total loss': 0.12183766404296262}
2022-12-31 04:20:40,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:40,676 INFO:     Epoch: 98
2022-12-31 04:20:42,327 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3938635220130285, 'Total loss': 0.3938635220130285} | train loss {'Reaction outcome loss': 0.11326841615259796, 'Total loss': 0.11326841615259796}
2022-12-31 04:20:42,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:42,328 INFO:     Epoch: 99
2022-12-31 04:20:43,943 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4148958255226413, 'Total loss': 0.4148958255226413} | train loss {'Reaction outcome loss': 0.11329177836971593, 'Total loss': 0.11329177836971593}
2022-12-31 04:20:43,944 INFO:     Best model found after epoch 48 of 100.
2022-12-31 04:20:43,944 INFO:   Done with stage: TRAINING
2022-12-31 04:20:43,944 INFO:   Starting stage: EVALUATION
2022-12-31 04:20:44,068 INFO:   Done with stage: EVALUATION
2022-12-31 04:20:44,068 INFO:   Leaving out SEQ value Fold_6
2022-12-31 04:20:44,080 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 04:20:44,080 INFO:   Starting stage: FEATURE SCALING
2022-12-31 04:20:44,721 INFO:   Done with stage: FEATURE SCALING
2022-12-31 04:20:44,721 INFO:   Starting stage: SCALING TARGETS
2022-12-31 04:20:44,793 INFO:   Done with stage: SCALING TARGETS
2022-12-31 04:20:44,793 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:20:44,793 INFO:     No hyperparam tuning for this model
2022-12-31 04:20:44,793 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:20:44,793 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 04:20:44,794 INFO:     None feature selector for col prot
2022-12-31 04:20:44,794 INFO:     None feature selector for col prot
2022-12-31 04:20:44,794 INFO:     None feature selector for col prot
2022-12-31 04:20:44,794 INFO:     None feature selector for col chem
2022-12-31 04:20:44,795 INFO:     None feature selector for col chem
2022-12-31 04:20:44,795 INFO:     None feature selector for col chem
2022-12-31 04:20:44,795 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 04:20:44,795 INFO:   Starting stage: BUILD MODEL
2022-12-31 04:20:44,797 INFO:     Number of params in model 224011
2022-12-31 04:20:44,800 INFO:   Done with stage: BUILD MODEL
2022-12-31 04:20:44,800 INFO:   Starting stage: TRAINING
2022-12-31 04:20:44,846 INFO:     Val loss before train {'Reaction outcome loss': 0.9816672166188558, 'Total loss': 0.9816672166188558}
2022-12-31 04:20:44,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:44,846 INFO:     Epoch: 0
2022-12-31 04:20:46,458 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5876709322134653, 'Total loss': 0.5876709322134653} | train loss {'Reaction outcome loss': 0.7943885483636869, 'Total loss': 0.7943885483636869}
2022-12-31 04:20:46,458 INFO:     Found new best model at epoch 0
2022-12-31 04:20:46,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:46,459 INFO:     Epoch: 1
2022-12-31 04:20:48,075 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5086621542771658, 'Total loss': 0.5086621542771658} | train loss {'Reaction outcome loss': 0.5190727052116848, 'Total loss': 0.5190727052116848}
2022-12-31 04:20:48,075 INFO:     Found new best model at epoch 1
2022-12-31 04:20:48,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:48,076 INFO:     Epoch: 2
2022-12-31 04:20:49,679 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4860999345779419, 'Total loss': 0.4860999345779419} | train loss {'Reaction outcome loss': 0.444275382046581, 'Total loss': 0.444275382046581}
2022-12-31 04:20:49,679 INFO:     Found new best model at epoch 2
2022-12-31 04:20:49,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:49,680 INFO:     Epoch: 3
2022-12-31 04:20:51,292 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45533166627089183, 'Total loss': 0.45533166627089183} | train loss {'Reaction outcome loss': 0.4005995382356797, 'Total loss': 0.4005995382356797}
2022-12-31 04:20:51,292 INFO:     Found new best model at epoch 3
2022-12-31 04:20:51,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:51,293 INFO:     Epoch: 4
2022-12-31 04:20:52,906 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4337153236071269, 'Total loss': 0.4337153236071269} | train loss {'Reaction outcome loss': 0.3700452110092358, 'Total loss': 0.3700452110092358}
2022-12-31 04:20:52,907 INFO:     Found new best model at epoch 4
2022-12-31 04:20:52,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:52,908 INFO:     Epoch: 5
2022-12-31 04:20:54,570 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4502642750740051, 'Total loss': 0.4502642750740051} | train loss {'Reaction outcome loss': 0.3468165355146717, 'Total loss': 0.3468165355146717}
2022-12-31 04:20:54,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:54,571 INFO:     Epoch: 6
2022-12-31 04:20:56,186 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43589790860811867, 'Total loss': 0.43589790860811867} | train loss {'Reaction outcome loss': 0.3249456893544698, 'Total loss': 0.3249456893544698}
2022-12-31 04:20:56,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:56,187 INFO:     Epoch: 7
2022-12-31 04:20:57,820 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4275835454463959, 'Total loss': 0.4275835454463959} | train loss {'Reaction outcome loss': 0.31023525866339036, 'Total loss': 0.31023525866339036}
2022-12-31 04:20:57,820 INFO:     Found new best model at epoch 7
2022-12-31 04:20:57,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:57,821 INFO:     Epoch: 8
2022-12-31 04:20:59,440 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42635935147603354, 'Total loss': 0.42635935147603354} | train loss {'Reaction outcome loss': 0.2918902675492986, 'Total loss': 0.2918902675492986}
2022-12-31 04:20:59,441 INFO:     Found new best model at epoch 8
2022-12-31 04:20:59,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:20:59,442 INFO:     Epoch: 9
2022-12-31 04:21:01,066 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42198062837123873, 'Total loss': 0.42198062837123873} | train loss {'Reaction outcome loss': 0.2775324083243807, 'Total loss': 0.2775324083243807}
2022-12-31 04:21:01,066 INFO:     Found new best model at epoch 9
2022-12-31 04:21:01,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:01,067 INFO:     Epoch: 10
2022-12-31 04:21:02,692 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4257499317328135, 'Total loss': 0.4257499317328135} | train loss {'Reaction outcome loss': 0.27612473568676604, 'Total loss': 0.27612473568676604}
2022-12-31 04:21:02,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:02,692 INFO:     Epoch: 11
2022-12-31 04:21:04,318 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40438934763272605, 'Total loss': 0.40438934763272605} | train loss {'Reaction outcome loss': 0.2728800057598823, 'Total loss': 0.2728800057598823}
2022-12-31 04:21:04,318 INFO:     Found new best model at epoch 11
2022-12-31 04:21:04,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:04,319 INFO:     Epoch: 12
2022-12-31 04:21:05,936 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3995336939891179, 'Total loss': 0.3995336939891179} | train loss {'Reaction outcome loss': 0.24576099386415107, 'Total loss': 0.24576099386415107}
2022-12-31 04:21:05,936 INFO:     Found new best model at epoch 12
2022-12-31 04:21:05,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:05,937 INFO:     Epoch: 13
2022-12-31 04:21:07,564 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4312239130338033, 'Total loss': 0.4312239130338033} | train loss {'Reaction outcome loss': 0.23381526317899587, 'Total loss': 0.23381526317899587}
2022-12-31 04:21:07,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:07,564 INFO:     Epoch: 14
2022-12-31 04:21:09,182 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.402345664302508, 'Total loss': 0.402345664302508} | train loss {'Reaction outcome loss': 0.22681524754042967, 'Total loss': 0.22681524754042967}
2022-12-31 04:21:09,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:09,182 INFO:     Epoch: 15
2022-12-31 04:21:10,806 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4168169329563777, 'Total loss': 0.4168169329563777} | train loss {'Reaction outcome loss': 0.22612583558952462, 'Total loss': 0.22612583558952462}
2022-12-31 04:21:10,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:10,806 INFO:     Epoch: 16
2022-12-31 04:21:12,431 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4054180254538854, 'Total loss': 0.4054180254538854} | train loss {'Reaction outcome loss': 0.22134292367991293, 'Total loss': 0.22134292367991293}
2022-12-31 04:21:12,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:12,432 INFO:     Epoch: 17
2022-12-31 04:21:14,059 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41396632194519045, 'Total loss': 0.41396632194519045} | train loss {'Reaction outcome loss': 0.20916049756097904, 'Total loss': 0.20916049756097904}
2022-12-31 04:21:14,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:14,059 INFO:     Epoch: 18
2022-12-31 04:21:15,676 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4135460873444875, 'Total loss': 0.4135460873444875} | train loss {'Reaction outcome loss': 0.20443965728834196, 'Total loss': 0.20443965728834196}
2022-12-31 04:21:15,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:15,676 INFO:     Epoch: 19
2022-12-31 04:21:17,291 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42405103941758476, 'Total loss': 0.42405103941758476} | train loss {'Reaction outcome loss': 0.20799215297228185, 'Total loss': 0.20799215297228185}
2022-12-31 04:21:17,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:17,292 INFO:     Epoch: 20
2022-12-31 04:21:18,915 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39965992122888566, 'Total loss': 0.39965992122888566} | train loss {'Reaction outcome loss': 0.2293527532137755, 'Total loss': 0.2293527532137755}
2022-12-31 04:21:18,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:18,915 INFO:     Epoch: 21
2022-12-31 04:21:20,538 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4199339916308721, 'Total loss': 0.4199339916308721} | train loss {'Reaction outcome loss': 0.194516405754257, 'Total loss': 0.194516405754257}
2022-12-31 04:21:20,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:20,538 INFO:     Epoch: 22
2022-12-31 04:21:22,165 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42059479852517445, 'Total loss': 0.42059479852517445} | train loss {'Reaction outcome loss': 0.18777317533417576, 'Total loss': 0.18777317533417576}
2022-12-31 04:21:22,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:22,165 INFO:     Epoch: 23
2022-12-31 04:21:23,787 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3995582739512126, 'Total loss': 0.3995582739512126} | train loss {'Reaction outcome loss': 0.18208324044362467, 'Total loss': 0.18208324044362467}
2022-12-31 04:21:23,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:23,789 INFO:     Epoch: 24
2022-12-31 04:21:25,414 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42912827531496683, 'Total loss': 0.42912827531496683} | train loss {'Reaction outcome loss': 0.1744151687870054, 'Total loss': 0.1744151687870054}
2022-12-31 04:21:25,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:25,414 INFO:     Epoch: 25
2022-12-31 04:21:27,034 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4173300633827845, 'Total loss': 0.4173300633827845} | train loss {'Reaction outcome loss': 0.173568916986224, 'Total loss': 0.173568916986224}
2022-12-31 04:21:27,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:27,035 INFO:     Epoch: 26
2022-12-31 04:21:28,656 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4222489207983017, 'Total loss': 0.4222489207983017} | train loss {'Reaction outcome loss': 0.1678359130304987, 'Total loss': 0.1678359130304987}
2022-12-31 04:21:28,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:28,657 INFO:     Epoch: 27
2022-12-31 04:21:30,287 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4188283110658328, 'Total loss': 0.4188283110658328} | train loss {'Reaction outcome loss': 0.16610517767499458, 'Total loss': 0.16610517767499458}
2022-12-31 04:21:30,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:30,288 INFO:     Epoch: 28
2022-12-31 04:21:31,915 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43300074338912964, 'Total loss': 0.43300074338912964} | train loss {'Reaction outcome loss': 0.16203090313621837, 'Total loss': 0.16203090313621837}
2022-12-31 04:21:31,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:31,915 INFO:     Epoch: 29
2022-12-31 04:21:33,538 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.435086727142334, 'Total loss': 0.435086727142334} | train loss {'Reaction outcome loss': 0.16209328149283386, 'Total loss': 0.16209328149283386}
2022-12-31 04:21:33,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:33,538 INFO:     Epoch: 30
2022-12-31 04:21:35,163 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4195670669277509, 'Total loss': 0.4195670669277509} | train loss {'Reaction outcome loss': 0.15550373396600017, 'Total loss': 0.15550373396600017}
2022-12-31 04:21:35,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:35,163 INFO:     Epoch: 31
2022-12-31 04:21:36,771 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4252030447125435, 'Total loss': 0.4252030447125435} | train loss {'Reaction outcome loss': 0.16019852849506383, 'Total loss': 0.16019852849506383}
2022-12-31 04:21:36,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:36,771 INFO:     Epoch: 32
2022-12-31 04:21:38,431 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4372020085652669, 'Total loss': 0.4372020085652669} | train loss {'Reaction outcome loss': 0.15949240606953052, 'Total loss': 0.15949240606953052}
2022-12-31 04:21:38,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:38,431 INFO:     Epoch: 33
2022-12-31 04:21:40,091 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4307457615931829, 'Total loss': 0.4307457615931829} | train loss {'Reaction outcome loss': 0.18461462950770088, 'Total loss': 0.18461462950770088}
2022-12-31 04:21:40,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:40,092 INFO:     Epoch: 34
2022-12-31 04:21:41,752 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4494219571352005, 'Total loss': 0.4494219571352005} | train loss {'Reaction outcome loss': 0.15326034110752307, 'Total loss': 0.15326034110752307}
2022-12-31 04:21:41,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:41,753 INFO:     Epoch: 35
2022-12-31 04:21:43,362 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4277110616366068, 'Total loss': 0.4277110616366068} | train loss {'Reaction outcome loss': 0.1454572333984644, 'Total loss': 0.1454572333984644}
2022-12-31 04:21:43,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:43,363 INFO:     Epoch: 36
2022-12-31 04:21:44,970 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44003567496935525, 'Total loss': 0.44003567496935525} | train loss {'Reaction outcome loss': 0.14305140929137333, 'Total loss': 0.14305140929137333}
2022-12-31 04:21:44,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:44,970 INFO:     Epoch: 37
2022-12-31 04:21:46,597 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41344815244277316, 'Total loss': 0.41344815244277316} | train loss {'Reaction outcome loss': 0.14112686397561777, 'Total loss': 0.14112686397561777}
2022-12-31 04:21:46,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:46,598 INFO:     Epoch: 38
2022-12-31 04:21:48,225 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42930963039398196, 'Total loss': 0.42930963039398196} | train loss {'Reaction outcome loss': 0.14371160772440117, 'Total loss': 0.14371160772440117}
2022-12-31 04:21:48,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:48,226 INFO:     Epoch: 39
2022-12-31 04:21:49,854 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40712207506100334, 'Total loss': 0.40712207506100334} | train loss {'Reaction outcome loss': 0.14179623994699586, 'Total loss': 0.14179623994699586}
2022-12-31 04:21:49,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:49,854 INFO:     Epoch: 40
2022-12-31 04:21:51,472 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44480876276890435, 'Total loss': 0.44480876276890435} | train loss {'Reaction outcome loss': 0.14190444950203318, 'Total loss': 0.14190444950203318}
2022-12-31 04:21:51,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:51,472 INFO:     Epoch: 41
2022-12-31 04:21:53,134 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4354389319817225, 'Total loss': 0.4354389319817225} | train loss {'Reaction outcome loss': 0.1416036522258883, 'Total loss': 0.1416036522258883}
2022-12-31 04:21:53,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:53,134 INFO:     Epoch: 42
2022-12-31 04:21:54,745 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44957496523857116, 'Total loss': 0.44957496523857116} | train loss {'Reaction outcome loss': 0.13929234628088033, 'Total loss': 0.13929234628088033}
2022-12-31 04:21:54,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:54,746 INFO:     Epoch: 43
2022-12-31 04:21:56,358 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4428623100121816, 'Total loss': 0.4428623100121816} | train loss {'Reaction outcome loss': 0.13834228855135944, 'Total loss': 0.13834228855135944}
2022-12-31 04:21:56,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:56,358 INFO:     Epoch: 44
2022-12-31 04:21:58,018 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4204323391119639, 'Total loss': 0.4204323391119639} | train loss {'Reaction outcome loss': 0.13855683444779826, 'Total loss': 0.13855683444779826}
2022-12-31 04:21:58,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:58,018 INFO:     Epoch: 45
2022-12-31 04:21:59,678 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4234115382035573, 'Total loss': 0.4234115382035573} | train loss {'Reaction outcome loss': 0.13450015468212465, 'Total loss': 0.13450015468212465}
2022-12-31 04:21:59,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:21:59,679 INFO:     Epoch: 46
2022-12-31 04:22:01,301 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4091540882984797, 'Total loss': 0.4091540882984797} | train loss {'Reaction outcome loss': 0.1369896694595809, 'Total loss': 0.1369896694595809}
2022-12-31 04:22:01,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:01,301 INFO:     Epoch: 47
2022-12-31 04:22:02,914 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4368192195892334, 'Total loss': 0.4368192195892334} | train loss {'Reaction outcome loss': 0.13561374574319285, 'Total loss': 0.13561374574319285}
2022-12-31 04:22:02,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:02,914 INFO:     Epoch: 48
2022-12-31 04:22:04,527 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4471140613158544, 'Total loss': 0.4471140613158544} | train loss {'Reaction outcome loss': 0.13043124963418898, 'Total loss': 0.13043124963418898}
2022-12-31 04:22:04,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:04,527 INFO:     Epoch: 49
2022-12-31 04:22:06,138 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44162694215774534, 'Total loss': 0.44162694215774534} | train loss {'Reaction outcome loss': 0.1296549880237011, 'Total loss': 0.1296549880237011}
2022-12-31 04:22:06,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:06,138 INFO:     Epoch: 50
2022-12-31 04:22:07,749 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43499372055133184, 'Total loss': 0.43499372055133184} | train loss {'Reaction outcome loss': 0.13029548566429067, 'Total loss': 0.13029548566429067}
2022-12-31 04:22:07,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:07,749 INFO:     Epoch: 51
2022-12-31 04:22:09,360 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43530758122603097, 'Total loss': 0.43530758122603097} | train loss {'Reaction outcome loss': 0.12977023629903578, 'Total loss': 0.12977023629903578}
2022-12-31 04:22:09,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:09,360 INFO:     Epoch: 52
2022-12-31 04:22:10,991 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4408683399359385, 'Total loss': 0.4408683399359385} | train loss {'Reaction outcome loss': 0.1301872345122873, 'Total loss': 0.1301872345122873}
2022-12-31 04:22:10,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:10,991 INFO:     Epoch: 53
2022-12-31 04:22:12,625 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4008525848388672, 'Total loss': 0.4008525848388672} | train loss {'Reaction outcome loss': 0.13057056890026972, 'Total loss': 0.13057056890026972}
2022-12-31 04:22:12,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:12,626 INFO:     Epoch: 54
2022-12-31 04:22:14,291 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4233400121331215, 'Total loss': 0.4233400121331215} | train loss {'Reaction outcome loss': 0.1282904251917068, 'Total loss': 0.1282904251917068}
2022-12-31 04:22:14,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:14,292 INFO:     Epoch: 55
2022-12-31 04:22:15,912 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4318761428197225, 'Total loss': 0.4318761428197225} | train loss {'Reaction outcome loss': 0.13007775239521582, 'Total loss': 0.13007775239521582}
2022-12-31 04:22:15,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:15,912 INFO:     Epoch: 56
2022-12-31 04:22:17,576 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4268631706635157, 'Total loss': 0.4268631706635157} | train loss {'Reaction outcome loss': 0.12838519054254732, 'Total loss': 0.12838519054254732}
2022-12-31 04:22:17,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:17,576 INFO:     Epoch: 57
2022-12-31 04:22:19,226 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4724773089090983, 'Total loss': 0.4724773089090983} | train loss {'Reaction outcome loss': 0.12302020079780208, 'Total loss': 0.12302020079780208}
2022-12-31 04:22:19,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:19,227 INFO:     Epoch: 58
2022-12-31 04:22:20,844 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46480841835339864, 'Total loss': 0.46480841835339864} | train loss {'Reaction outcome loss': 0.12566493478231638, 'Total loss': 0.12566493478231638}
2022-12-31 04:22:20,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:20,845 INFO:     Epoch: 59
2022-12-31 04:22:22,467 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45721679329872134, 'Total loss': 0.45721679329872134} | train loss {'Reaction outcome loss': 0.12296980913211171, 'Total loss': 0.12296980913211171}
2022-12-31 04:22:22,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:22,467 INFO:     Epoch: 60
2022-12-31 04:22:24,099 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4392214328050613, 'Total loss': 0.4392214328050613} | train loss {'Reaction outcome loss': 0.12349705544698551, 'Total loss': 0.12349705544698551}
2022-12-31 04:22:24,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:24,100 INFO:     Epoch: 61
2022-12-31 04:22:25,731 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44618420700232186, 'Total loss': 0.44618420700232186} | train loss {'Reaction outcome loss': 0.12335622912602655, 'Total loss': 0.12335622912602655}
2022-12-31 04:22:25,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:25,733 INFO:     Epoch: 62
2022-12-31 04:22:27,365 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43049427469571433, 'Total loss': 0.43049427469571433} | train loss {'Reaction outcome loss': 0.12458865299645433, 'Total loss': 0.12458865299645433}
2022-12-31 04:22:27,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:27,365 INFO:     Epoch: 63
2022-12-31 04:22:28,986 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4234631528457006, 'Total loss': 0.4234631528457006} | train loss {'Reaction outcome loss': 0.11862489041379666, 'Total loss': 0.11862489041379666}
2022-12-31 04:22:28,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:28,986 INFO:     Epoch: 64
2022-12-31 04:22:30,608 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43650609254837036, 'Total loss': 0.43650609254837036} | train loss {'Reaction outcome loss': 0.12470787816994783, 'Total loss': 0.12470787816994783}
2022-12-31 04:22:30,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:30,608 INFO:     Epoch: 65
2022-12-31 04:22:32,239 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4486886143684387, 'Total loss': 0.4486886143684387} | train loss {'Reaction outcome loss': 0.12472199669027627, 'Total loss': 0.12472199669027627}
2022-12-31 04:22:32,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:32,240 INFO:     Epoch: 66
2022-12-31 04:22:33,867 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4449474940697352, 'Total loss': 0.4449474940697352} | train loss {'Reaction outcome loss': 0.1230278963811925, 'Total loss': 0.1230278963811925}
2022-12-31 04:22:33,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:33,867 INFO:     Epoch: 67
2022-12-31 04:22:35,496 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43744069735209146, 'Total loss': 0.43744069735209146} | train loss {'Reaction outcome loss': 0.11878935879795408, 'Total loss': 0.11878935879795408}
2022-12-31 04:22:35,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:35,496 INFO:     Epoch: 68
2022-12-31 04:22:37,120 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4663465787967046, 'Total loss': 0.4663465787967046} | train loss {'Reaction outcome loss': 0.11751607810004108, 'Total loss': 0.11751607810004108}
2022-12-31 04:22:37,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:37,121 INFO:     Epoch: 69
2022-12-31 04:22:38,786 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45688674102226895, 'Total loss': 0.45688674102226895} | train loss {'Reaction outcome loss': 0.1180947943104674, 'Total loss': 0.1180947943104674}
2022-12-31 04:22:38,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:38,786 INFO:     Epoch: 70
2022-12-31 04:22:40,432 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.438237343976895, 'Total loss': 0.438237343976895} | train loss {'Reaction outcome loss': 0.11940238994176743, 'Total loss': 0.11940238994176743}
2022-12-31 04:22:40,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:40,432 INFO:     Epoch: 71
2022-12-31 04:22:42,098 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43149951721231145, 'Total loss': 0.43149951721231145} | train loss {'Reaction outcome loss': 0.11724554492326021, 'Total loss': 0.11724554492326021}
2022-12-31 04:22:42,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:42,098 INFO:     Epoch: 72
2022-12-31 04:22:43,716 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4509456555048625, 'Total loss': 0.4509456555048625} | train loss {'Reaction outcome loss': 0.11682533232522184, 'Total loss': 0.11682533232522184}
2022-12-31 04:22:43,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:43,716 INFO:     Epoch: 73
2022-12-31 04:22:45,332 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4685187141100566, 'Total loss': 0.4685187141100566} | train loss {'Reaction outcome loss': 0.12053756431959155, 'Total loss': 0.12053756431959155}
2022-12-31 04:22:45,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:45,333 INFO:     Epoch: 74
2022-12-31 04:22:46,972 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4486712177594503, 'Total loss': 0.4486712177594503} | train loss {'Reaction outcome loss': 0.11815577945874436, 'Total loss': 0.11815577945874436}
2022-12-31 04:22:46,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:46,972 INFO:     Epoch: 75
2022-12-31 04:22:48,627 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45817545652389524, 'Total loss': 0.45817545652389524} | train loss {'Reaction outcome loss': 0.11506066966778261, 'Total loss': 0.11506066966778261}
2022-12-31 04:22:48,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:48,628 INFO:     Epoch: 76
2022-12-31 04:22:50,262 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4832659989595413, 'Total loss': 0.4832659989595413} | train loss {'Reaction outcome loss': 0.11850144054053248, 'Total loss': 0.11850144054053248}
2022-12-31 04:22:50,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:50,263 INFO:     Epoch: 77
2022-12-31 04:22:51,888 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4107488671628137, 'Total loss': 0.4107488671628137} | train loss {'Reaction outcome loss': 0.12182388529417686, 'Total loss': 0.12182388529417686}
2022-12-31 04:22:51,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:51,888 INFO:     Epoch: 78
2022-12-31 04:22:53,515 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45532322824001314, 'Total loss': 0.45532322824001314} | train loss {'Reaction outcome loss': 0.11429926280676306, 'Total loss': 0.11429926280676306}
2022-12-31 04:22:53,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:53,515 INFO:     Epoch: 79
2022-12-31 04:22:55,136 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43764926741520566, 'Total loss': 0.43764926741520566} | train loss {'Reaction outcome loss': 0.10805176562902541, 'Total loss': 0.10805176562902541}
2022-12-31 04:22:55,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:55,136 INFO:     Epoch: 80
2022-12-31 04:22:56,759 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4446965932846069, 'Total loss': 0.4446965932846069} | train loss {'Reaction outcome loss': 0.11825218678374465, 'Total loss': 0.11825218678374465}
2022-12-31 04:22:56,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:56,760 INFO:     Epoch: 81
2022-12-31 04:22:58,379 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42113609351217746, 'Total loss': 0.42113609351217746} | train loss {'Reaction outcome loss': 0.13049561477421684, 'Total loss': 0.13049561477421684}
2022-12-31 04:22:58,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:22:58,379 INFO:     Epoch: 82
2022-12-31 04:23:00,007 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4559901088476181, 'Total loss': 0.4559901088476181} | train loss {'Reaction outcome loss': 0.11709068939144608, 'Total loss': 0.11709068939144608}
2022-12-31 04:23:00,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:00,007 INFO:     Epoch: 83
2022-12-31 04:23:01,632 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4366332749525706, 'Total loss': 0.4366332749525706} | train loss {'Reaction outcome loss': 0.11243638406375649, 'Total loss': 0.11243638406375649}
2022-12-31 04:23:01,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:01,634 INFO:     Epoch: 84
2022-12-31 04:23:03,258 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42988090415795643, 'Total loss': 0.42988090415795643} | train loss {'Reaction outcome loss': 0.10899324466953512, 'Total loss': 0.10899324466953512}
2022-12-31 04:23:03,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:03,258 INFO:     Epoch: 85
2022-12-31 04:23:04,891 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4252563536167145, 'Total loss': 0.4252563536167145} | train loss {'Reaction outcome loss': 0.10790288540791126, 'Total loss': 0.10790288540791126}
2022-12-31 04:23:04,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:04,891 INFO:     Epoch: 86
2022-12-31 04:23:06,510 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4664519121249517, 'Total loss': 0.4664519121249517} | train loss {'Reaction outcome loss': 0.11485002324680217, 'Total loss': 0.11485002324680217}
2022-12-31 04:23:06,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:06,510 INFO:     Epoch: 87
2022-12-31 04:23:08,131 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4598716855049133, 'Total loss': 0.4598716855049133} | train loss {'Reaction outcome loss': 0.11348867494129133, 'Total loss': 0.11348867494129133}
2022-12-31 04:23:08,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:08,131 INFO:     Epoch: 88
2022-12-31 04:23:09,758 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47236357231934867, 'Total loss': 0.47236357231934867} | train loss {'Reaction outcome loss': 0.11182979152020552, 'Total loss': 0.11182979152020552}
2022-12-31 04:23:09,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:09,758 INFO:     Epoch: 89
2022-12-31 04:23:11,388 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46586275299390156, 'Total loss': 0.46586275299390156} | train loss {'Reaction outcome loss': 0.11298038310285294, 'Total loss': 0.11298038310285294}
2022-12-31 04:23:11,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:11,388 INFO:     Epoch: 90
2022-12-31 04:23:13,016 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4464632352193197, 'Total loss': 0.4464632352193197} | train loss {'Reaction outcome loss': 0.11144260965036243, 'Total loss': 0.11144260965036243}
2022-12-31 04:23:13,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:13,016 INFO:     Epoch: 91
2022-12-31 04:23:14,666 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4521154930194219, 'Total loss': 0.4521154930194219} | train loss {'Reaction outcome loss': 0.11058619935605404, 'Total loss': 0.11058619935605404}
2022-12-31 04:23:14,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:14,666 INFO:     Epoch: 92
2022-12-31 04:23:16,278 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4449289580186208, 'Total loss': 0.4449289580186208} | train loss {'Reaction outcome loss': 0.11357856401836203, 'Total loss': 0.11357856401836203}
2022-12-31 04:23:16,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:16,278 INFO:     Epoch: 93
2022-12-31 04:23:17,943 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4831269611914953, 'Total loss': 0.4831269611914953} | train loss {'Reaction outcome loss': 0.10672159939249336, 'Total loss': 0.10672159939249336}
2022-12-31 04:23:17,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:17,944 INFO:     Epoch: 94
2022-12-31 04:23:19,562 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42922788535555206, 'Total loss': 0.42922788535555206} | train loss {'Reaction outcome loss': 0.10803449543706939, 'Total loss': 0.10803449543706939}
2022-12-31 04:23:19,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:19,562 INFO:     Epoch: 95
2022-12-31 04:23:21,178 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.419992051521937, 'Total loss': 0.419992051521937} | train loss {'Reaction outcome loss': 0.10723147954980748, 'Total loss': 0.10723147954980748}
2022-12-31 04:23:21,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:21,179 INFO:     Epoch: 96
2022-12-31 04:23:22,799 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4251264313856761, 'Total loss': 0.4251264313856761} | train loss {'Reaction outcome loss': 0.10713081420913838, 'Total loss': 0.10713081420913838}
2022-12-31 04:23:22,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:22,799 INFO:     Epoch: 97
2022-12-31 04:23:24,463 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4508215179045995, 'Total loss': 0.4508215179045995} | train loss {'Reaction outcome loss': 0.1158742469845532, 'Total loss': 0.1158742469845532}
2022-12-31 04:23:24,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:24,464 INFO:     Epoch: 98
2022-12-31 04:23:26,074 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48022918005784354, 'Total loss': 0.48022918005784354} | train loss {'Reaction outcome loss': 0.11578960252412851, 'Total loss': 0.11578960252412851}
2022-12-31 04:23:26,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:26,074 INFO:     Epoch: 99
2022-12-31 04:23:27,692 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4729832430680593, 'Total loss': 0.4729832430680593} | train loss {'Reaction outcome loss': 0.10840448751822925, 'Total loss': 0.10840448751822925}
2022-12-31 04:23:27,692 INFO:     Best model found after epoch 13 of 100.
2022-12-31 04:23:27,692 INFO:   Done with stage: TRAINING
2022-12-31 04:23:27,692 INFO:   Starting stage: EVALUATION
2022-12-31 04:23:27,825 INFO:   Done with stage: EVALUATION
2022-12-31 04:23:27,825 INFO:   Leaving out SEQ value Fold_7
2022-12-31 04:23:27,837 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 04:23:27,837 INFO:   Starting stage: FEATURE SCALING
2022-12-31 04:23:28,484 INFO:   Done with stage: FEATURE SCALING
2022-12-31 04:23:28,484 INFO:   Starting stage: SCALING TARGETS
2022-12-31 04:23:28,557 INFO:   Done with stage: SCALING TARGETS
2022-12-31 04:23:28,557 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:23:28,557 INFO:     No hyperparam tuning for this model
2022-12-31 04:23:28,557 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:23:28,557 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 04:23:28,558 INFO:     None feature selector for col prot
2022-12-31 04:23:28,558 INFO:     None feature selector for col prot
2022-12-31 04:23:28,558 INFO:     None feature selector for col prot
2022-12-31 04:23:28,559 INFO:     None feature selector for col chem
2022-12-31 04:23:28,559 INFO:     None feature selector for col chem
2022-12-31 04:23:28,559 INFO:     None feature selector for col chem
2022-12-31 04:23:28,559 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 04:23:28,559 INFO:   Starting stage: BUILD MODEL
2022-12-31 04:23:28,561 INFO:     Number of params in model 224011
2022-12-31 04:23:28,564 INFO:   Done with stage: BUILD MODEL
2022-12-31 04:23:28,564 INFO:   Starting stage: TRAINING
2022-12-31 04:23:28,609 INFO:     Val loss before train {'Reaction outcome loss': 1.0371111551920573, 'Total loss': 1.0371111551920573}
2022-12-31 04:23:28,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:28,609 INFO:     Epoch: 0
2022-12-31 04:23:30,229 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.593969343105952, 'Total loss': 0.593969343105952} | train loss {'Reaction outcome loss': 0.7686115231675407, 'Total loss': 0.7686115231675407}
2022-12-31 04:23:30,229 INFO:     Found new best model at epoch 0
2022-12-31 04:23:30,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:30,230 INFO:     Epoch: 1
2022-12-31 04:23:31,849 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5066348830858867, 'Total loss': 0.5066348830858867} | train loss {'Reaction outcome loss': 0.5381936340228372, 'Total loss': 0.5381936340228372}
2022-12-31 04:23:31,849 INFO:     Found new best model at epoch 1
2022-12-31 04:23:31,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:31,850 INFO:     Epoch: 2
2022-12-31 04:23:33,464 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48979422251383464, 'Total loss': 0.48979422251383464} | train loss {'Reaction outcome loss': 0.4483160413126799, 'Total loss': 0.4483160413126799}
2022-12-31 04:23:33,464 INFO:     Found new best model at epoch 2
2022-12-31 04:23:33,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:33,466 INFO:     Epoch: 3
2022-12-31 04:23:35,080 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4668642560640971, 'Total loss': 0.4668642560640971} | train loss {'Reaction outcome loss': 0.41116700236402126, 'Total loss': 0.41116700236402126}
2022-12-31 04:23:35,080 INFO:     Found new best model at epoch 3
2022-12-31 04:23:35,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:35,081 INFO:     Epoch: 4
2022-12-31 04:23:36,698 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.449766884247462, 'Total loss': 0.449766884247462} | train loss {'Reaction outcome loss': 0.39236579916399456, 'Total loss': 0.39236579916399456}
2022-12-31 04:23:36,699 INFO:     Found new best model at epoch 4
2022-12-31 04:23:36,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:36,700 INFO:     Epoch: 5
2022-12-31 04:23:38,366 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4345195601383845, 'Total loss': 0.4345195601383845} | train loss {'Reaction outcome loss': 0.3805345625117205, 'Total loss': 0.3805345625117205}
2022-12-31 04:23:38,366 INFO:     Found new best model at epoch 5
2022-12-31 04:23:38,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:38,367 INFO:     Epoch: 6
2022-12-31 04:23:39,978 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44605158964792885, 'Total loss': 0.44605158964792885} | train loss {'Reaction outcome loss': 0.3473650685045868, 'Total loss': 0.3473650685045868}
2022-12-31 04:23:39,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:39,979 INFO:     Epoch: 7
2022-12-31 04:23:41,605 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4440503309170405, 'Total loss': 0.4440503309170405} | train loss {'Reaction outcome loss': 0.3210213969974522, 'Total loss': 0.3210213969974522}
2022-12-31 04:23:41,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:41,605 INFO:     Epoch: 8
2022-12-31 04:23:43,242 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43483755389849343, 'Total loss': 0.43483755389849343} | train loss {'Reaction outcome loss': 0.3055702829497286, 'Total loss': 0.3055702829497286}
2022-12-31 04:23:43,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:43,243 INFO:     Epoch: 9
2022-12-31 04:23:44,860 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42626272241274515, 'Total loss': 0.42626272241274515} | train loss {'Reaction outcome loss': 0.29535889950180927, 'Total loss': 0.29535889950180927}
2022-12-31 04:23:44,861 INFO:     Found new best model at epoch 9
2022-12-31 04:23:44,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:44,862 INFO:     Epoch: 10
2022-12-31 04:23:46,477 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4103701909383138, 'Total loss': 0.4103701909383138} | train loss {'Reaction outcome loss': 0.28207263442606706, 'Total loss': 0.28207263442606706}
2022-12-31 04:23:46,477 INFO:     Found new best model at epoch 10
2022-12-31 04:23:46,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:46,478 INFO:     Epoch: 11
2022-12-31 04:23:48,094 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42189901967843374, 'Total loss': 0.42189901967843374} | train loss {'Reaction outcome loss': 0.2873641383172809, 'Total loss': 0.2873641383172809}
2022-12-31 04:23:48,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:48,094 INFO:     Epoch: 12
2022-12-31 04:23:49,714 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4282174289226532, 'Total loss': 0.4282174289226532} | train loss {'Reaction outcome loss': 0.2876271511245843, 'Total loss': 0.2876271511245843}
2022-12-31 04:23:49,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:49,715 INFO:     Epoch: 13
2022-12-31 04:23:51,379 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43970709343751274, 'Total loss': 0.43970709343751274} | train loss {'Reaction outcome loss': 0.2577868773866836, 'Total loss': 0.2577868773866836}
2022-12-31 04:23:51,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:51,379 INFO:     Epoch: 14
2022-12-31 04:23:52,995 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.422783495982488, 'Total loss': 0.422783495982488} | train loss {'Reaction outcome loss': 0.24548514958511025, 'Total loss': 0.24548514958511025}
2022-12-31 04:23:52,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:52,995 INFO:     Epoch: 15
2022-12-31 04:23:54,659 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4265285392602285, 'Total loss': 0.4265285392602285} | train loss {'Reaction outcome loss': 0.23981381800916532, 'Total loss': 0.23981381800916532}
2022-12-31 04:23:54,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:54,659 INFO:     Epoch: 16
2022-12-31 04:23:56,323 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39375265936056775, 'Total loss': 0.39375265936056775} | train loss {'Reaction outcome loss': 0.2329017101026156, 'Total loss': 0.2329017101026156}
2022-12-31 04:23:56,323 INFO:     Found new best model at epoch 16
2022-12-31 04:23:56,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:56,324 INFO:     Epoch: 17
2022-12-31 04:23:57,946 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4276147266228994, 'Total loss': 0.4276147266228994} | train loss {'Reaction outcome loss': 0.23331680418788522, 'Total loss': 0.23331680418788522}
2022-12-31 04:23:57,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:57,946 INFO:     Epoch: 18
2022-12-31 04:23:59,559 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4142644802729289, 'Total loss': 0.4142644802729289} | train loss {'Reaction outcome loss': 0.24005656184601612, 'Total loss': 0.24005656184601612}
2022-12-31 04:23:59,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:23:59,560 INFO:     Epoch: 19
2022-12-31 04:24:01,171 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41618796686331433, 'Total loss': 0.41618796686331433} | train loss {'Reaction outcome loss': 0.22595508743509435, 'Total loss': 0.22595508743509435}
2022-12-31 04:24:01,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:01,171 INFO:     Epoch: 20
2022-12-31 04:24:02,804 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4194670875867208, 'Total loss': 0.4194670875867208} | train loss {'Reaction outcome loss': 0.2278545826025631, 'Total loss': 0.2278545826025631}
2022-12-31 04:24:02,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:02,804 INFO:     Epoch: 21
2022-12-31 04:24:04,437 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4162234390775363, 'Total loss': 0.4162234390775363} | train loss {'Reaction outcome loss': 0.2083340249972526, 'Total loss': 0.2083340249972526}
2022-12-31 04:24:04,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:04,437 INFO:     Epoch: 22
2022-12-31 04:24:06,071 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4405761649211248, 'Total loss': 0.4405761649211248} | train loss {'Reaction outcome loss': 0.20304772167372098, 'Total loss': 0.20304772167372098}
2022-12-31 04:24:06,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:06,071 INFO:     Epoch: 23
2022-12-31 04:24:07,696 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4147277961174647, 'Total loss': 0.4147277961174647} | train loss {'Reaction outcome loss': 0.2079668183683627, 'Total loss': 0.2079668183683627}
2022-12-31 04:24:07,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:07,697 INFO:     Epoch: 24
2022-12-31 04:24:09,326 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41157777309417726, 'Total loss': 0.41157777309417726} | train loss {'Reaction outcome loss': 0.1945827650673944, 'Total loss': 0.1945827650673944}
2022-12-31 04:24:09,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:09,326 INFO:     Epoch: 25
2022-12-31 04:24:10,958 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.418806204199791, 'Total loss': 0.418806204199791} | train loss {'Reaction outcome loss': 0.18898858433670324, 'Total loss': 0.18898858433670324}
2022-12-31 04:24:10,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:10,959 INFO:     Epoch: 26
2022-12-31 04:24:12,624 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4001591742038727, 'Total loss': 0.4001591742038727} | train loss {'Reaction outcome loss': 0.18762933678142185, 'Total loss': 0.18762933678142185}
2022-12-31 04:24:12,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:12,624 INFO:     Epoch: 27
2022-12-31 04:24:14,289 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44042400221029915, 'Total loss': 0.44042400221029915} | train loss {'Reaction outcome loss': 0.18444263498447294, 'Total loss': 0.18444263498447294}
2022-12-31 04:24:14,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:14,290 INFO:     Epoch: 28
2022-12-31 04:24:15,919 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4245357781648636, 'Total loss': 0.4245357781648636} | train loss {'Reaction outcome loss': 0.18275447734024766, 'Total loss': 0.18275447734024766}
2022-12-31 04:24:15,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:15,920 INFO:     Epoch: 29
2022-12-31 04:24:17,564 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4461020330588023, 'Total loss': 0.4461020330588023} | train loss {'Reaction outcome loss': 0.18159265499697, 'Total loss': 0.18159265499697}
2022-12-31 04:24:17,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:17,564 INFO:     Epoch: 30
2022-12-31 04:24:19,194 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42856438656648, 'Total loss': 0.42856438656648} | train loss {'Reaction outcome loss': 0.17817849643693806, 'Total loss': 0.17817849643693806}
2022-12-31 04:24:19,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:19,194 INFO:     Epoch: 31
2022-12-31 04:24:20,857 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41726532379786174, 'Total loss': 0.41726532379786174} | train loss {'Reaction outcome loss': 0.17377037321663616, 'Total loss': 0.17377037321663616}
2022-12-31 04:24:20,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:20,857 INFO:     Epoch: 32
2022-12-31 04:24:22,473 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41978452503681185, 'Total loss': 0.41978452503681185} | train loss {'Reaction outcome loss': 0.17073593336238485, 'Total loss': 0.17073593336238485}
2022-12-31 04:24:22,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:22,473 INFO:     Epoch: 33
2022-12-31 04:24:24,088 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41956825951735177, 'Total loss': 0.41956825951735177} | train loss {'Reaction outcome loss': 0.19656323166429132, 'Total loss': 0.19656323166429132}
2022-12-31 04:24:24,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:24,089 INFO:     Epoch: 34
2022-12-31 04:24:25,695 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4166982412338257, 'Total loss': 0.4166982412338257} | train loss {'Reaction outcome loss': 0.16955169676161924, 'Total loss': 0.16955169676161924}
2022-12-31 04:24:25,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:25,695 INFO:     Epoch: 35
2022-12-31 04:24:27,324 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4505671133597692, 'Total loss': 0.4505671133597692} | train loss {'Reaction outcome loss': 0.16417737269638683, 'Total loss': 0.16417737269638683}
2022-12-31 04:24:27,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:27,325 INFO:     Epoch: 36
2022-12-31 04:24:28,964 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42201305826505026, 'Total loss': 0.42201305826505026} | train loss {'Reaction outcome loss': 0.16535710168924803, 'Total loss': 0.16535710168924803}
2022-12-31 04:24:28,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:28,964 INFO:     Epoch: 37
2022-12-31 04:24:30,577 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.429361159602801, 'Total loss': 0.429361159602801} | train loss {'Reaction outcome loss': 0.16322397472475236, 'Total loss': 0.16322397472475236}
2022-12-31 04:24:30,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:30,577 INFO:     Epoch: 38
2022-12-31 04:24:32,242 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.455981570482254, 'Total loss': 0.455981570482254} | train loss {'Reaction outcome loss': 0.15937484869989904, 'Total loss': 0.15937484869989904}
2022-12-31 04:24:32,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:32,243 INFO:     Epoch: 39
2022-12-31 04:24:33,887 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41313956181208294, 'Total loss': 0.41313956181208294} | train loss {'Reaction outcome loss': 0.16105241525044708, 'Total loss': 0.16105241525044708}
2022-12-31 04:24:33,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:33,888 INFO:     Epoch: 40
2022-12-31 04:24:35,563 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39680424133936565, 'Total loss': 0.39680424133936565} | train loss {'Reaction outcome loss': 0.16020517141652713, 'Total loss': 0.16020517141652713}
2022-12-31 04:24:35,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:35,563 INFO:     Epoch: 41
2022-12-31 04:24:37,198 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4176102578639984, 'Total loss': 0.4176102578639984} | train loss {'Reaction outcome loss': 0.15462252292828466, 'Total loss': 0.15462252292828466}
2022-12-31 04:24:37,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:37,198 INFO:     Epoch: 42
2022-12-31 04:24:38,818 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40606755316257476, 'Total loss': 0.40606755316257476} | train loss {'Reaction outcome loss': 0.1628760533420828, 'Total loss': 0.1628760533420828}
2022-12-31 04:24:38,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:38,819 INFO:     Epoch: 43
2022-12-31 04:24:40,445 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4284684181213379, 'Total loss': 0.4284684181213379} | train loss {'Reaction outcome loss': 0.18171287030186184, 'Total loss': 0.18171287030186184}
2022-12-31 04:24:40,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:40,445 INFO:     Epoch: 44
2022-12-31 04:24:42,075 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4003967344760895, 'Total loss': 0.4003967344760895} | train loss {'Reaction outcome loss': 0.15850905101515178, 'Total loss': 0.15850905101515178}
2022-12-31 04:24:42,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:42,076 INFO:     Epoch: 45
2022-12-31 04:24:43,705 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40505323906739554, 'Total loss': 0.40505323906739554} | train loss {'Reaction outcome loss': 0.16256230922780282, 'Total loss': 0.16256230922780282}
2022-12-31 04:24:43,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:43,705 INFO:     Epoch: 46
2022-12-31 04:24:45,354 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41123668029904364, 'Total loss': 0.41123668029904364} | train loss {'Reaction outcome loss': 0.1738818390328653, 'Total loss': 0.1738818390328653}
2022-12-31 04:24:45,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:45,355 INFO:     Epoch: 47
2022-12-31 04:24:46,968 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4119966119527817, 'Total loss': 0.4119966119527817} | train loss {'Reaction outcome loss': 0.17021554550054765, 'Total loss': 0.17021554550054765}
2022-12-31 04:24:46,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:46,969 INFO:     Epoch: 48
2022-12-31 04:24:48,633 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4409757018089294, 'Total loss': 0.4409757018089294} | train loss {'Reaction outcome loss': 0.14952002430515637, 'Total loss': 0.14952002430515637}
2022-12-31 04:24:48,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:48,633 INFO:     Epoch: 49
2022-12-31 04:24:50,255 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4257695893446604, 'Total loss': 0.4257695893446604} | train loss {'Reaction outcome loss': 0.1463697617603601, 'Total loss': 0.1463697617603601}
2022-12-31 04:24:50,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:50,255 INFO:     Epoch: 50
2022-12-31 04:24:51,920 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4303538074096044, 'Total loss': 0.4303538074096044} | train loss {'Reaction outcome loss': 0.15022882661442977, 'Total loss': 0.15022882661442977}
2022-12-31 04:24:51,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:51,920 INFO:     Epoch: 51
2022-12-31 04:24:53,541 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44518764317035675, 'Total loss': 0.44518764317035675} | train loss {'Reaction outcome loss': 0.13940341047861654, 'Total loss': 0.13940341047861654}
2022-12-31 04:24:53,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:53,542 INFO:     Epoch: 52
2022-12-31 04:24:55,206 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4231366316477458, 'Total loss': 0.4231366316477458} | train loss {'Reaction outcome loss': 0.15075902978255265, 'Total loss': 0.15075902978255265}
2022-12-31 04:24:55,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:55,206 INFO:     Epoch: 53
2022-12-31 04:24:56,831 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4220659414927165, 'Total loss': 0.4220659414927165} | train loss {'Reaction outcome loss': 0.15519947994945812, 'Total loss': 0.15519947994945812}
2022-12-31 04:24:56,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:56,832 INFO:     Epoch: 54
2022-12-31 04:24:58,496 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42428200542926786, 'Total loss': 0.42428200542926786} | train loss {'Reaction outcome loss': 0.14417825070436727, 'Total loss': 0.14417825070436727}
2022-12-31 04:24:58,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:24:58,497 INFO:     Epoch: 55
2022-12-31 04:25:00,116 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43435951868693035, 'Total loss': 0.43435951868693035} | train loss {'Reaction outcome loss': 0.13616994088869946, 'Total loss': 0.13616994088869946}
2022-12-31 04:25:00,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:00,116 INFO:     Epoch: 56
2022-12-31 04:25:01,780 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4423794329166412, 'Total loss': 0.4423794329166412} | train loss {'Reaction outcome loss': 0.13810602399061664, 'Total loss': 0.13810602399061664}
2022-12-31 04:25:01,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:01,780 INFO:     Epoch: 57
2022-12-31 04:25:03,415 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4473699708779653, 'Total loss': 0.4473699708779653} | train loss {'Reaction outcome loss': 0.13897941578044623, 'Total loss': 0.13897941578044623}
2022-12-31 04:25:03,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:03,415 INFO:     Epoch: 58
2022-12-31 04:25:05,041 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4324207782745361, 'Total loss': 0.4324207782745361} | train loss {'Reaction outcome loss': 0.1396242342079463, 'Total loss': 0.1396242342079463}
2022-12-31 04:25:05,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:05,041 INFO:     Epoch: 59
2022-12-31 04:25:06,663 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4650410979986191, 'Total loss': 0.4650410979986191} | train loss {'Reaction outcome loss': 0.13827730810094246, 'Total loss': 0.13827730810094246}
2022-12-31 04:25:06,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:06,663 INFO:     Epoch: 60
2022-12-31 04:25:08,327 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4080927481253942, 'Total loss': 0.4080927481253942} | train loss {'Reaction outcome loss': 0.1339831926300146, 'Total loss': 0.1339831926300146}
2022-12-31 04:25:08,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:08,327 INFO:     Epoch: 61
2022-12-31 04:25:09,992 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5081378976504008, 'Total loss': 0.5081378976504008} | train loss {'Reaction outcome loss': 0.13530204916774444, 'Total loss': 0.13530204916774444}
2022-12-31 04:25:09,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:09,993 INFO:     Epoch: 62
2022-12-31 04:25:11,609 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43234304785728456, 'Total loss': 0.43234304785728456} | train loss {'Reaction outcome loss': 0.1359407308644723, 'Total loss': 0.1359407308644723}
2022-12-31 04:25:11,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:11,609 INFO:     Epoch: 63
2022-12-31 04:25:13,269 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44055502315362294, 'Total loss': 0.44055502315362294} | train loss {'Reaction outcome loss': 0.13459429848918933, 'Total loss': 0.13459429848918933}
2022-12-31 04:25:13,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:13,269 INFO:     Epoch: 64
2022-12-31 04:25:14,901 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4215414295593897, 'Total loss': 0.4215414295593897} | train loss {'Reaction outcome loss': 0.14135583166194998, 'Total loss': 0.14135583166194998}
2022-12-31 04:25:14,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:14,902 INFO:     Epoch: 65
2022-12-31 04:25:16,566 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4389085213343302, 'Total loss': 0.4389085213343302} | train loss {'Reaction outcome loss': 0.14956024257749642, 'Total loss': 0.14956024257749642}
2022-12-31 04:25:16,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:16,567 INFO:     Epoch: 66
2022-12-31 04:25:18,187 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43072451700766884, 'Total loss': 0.43072451700766884} | train loss {'Reaction outcome loss': 0.13267449359072075, 'Total loss': 0.13267449359072075}
2022-12-31 04:25:18,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:18,188 INFO:     Epoch: 67
2022-12-31 04:25:19,852 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.451214687153697, 'Total loss': 0.451214687153697} | train loss {'Reaction outcome loss': 0.13158662200515645, 'Total loss': 0.13158662200515645}
2022-12-31 04:25:19,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:19,852 INFO:     Epoch: 68
2022-12-31 04:25:21,466 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4260232627391815, 'Total loss': 0.4260232627391815} | train loss {'Reaction outcome loss': 0.129050143053723, 'Total loss': 0.129050143053723}
2022-12-31 04:25:21,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:21,466 INFO:     Epoch: 69
2022-12-31 04:25:23,081 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4412199825048447, 'Total loss': 0.4412199825048447} | train loss {'Reaction outcome loss': 0.1290287133074278, 'Total loss': 0.1290287133074278}
2022-12-31 04:25:23,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:23,081 INFO:     Epoch: 70
2022-12-31 04:25:24,705 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44492846727371216, 'Total loss': 0.44492846727371216} | train loss {'Reaction outcome loss': 0.129601256678502, 'Total loss': 0.129601256678502}
2022-12-31 04:25:24,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:24,706 INFO:     Epoch: 71
2022-12-31 04:25:26,339 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4286014253894488, 'Total loss': 0.4286014253894488} | train loss {'Reaction outcome loss': 0.1272830532853613, 'Total loss': 0.1272830532853613}
2022-12-31 04:25:26,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:26,339 INFO:     Epoch: 72
2022-12-31 04:25:27,974 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4214643200238546, 'Total loss': 0.4214643200238546} | train loss {'Reaction outcome loss': 0.1247723498482905, 'Total loss': 0.1247723498482905}
2022-12-31 04:25:27,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:27,974 INFO:     Epoch: 73
2022-12-31 04:25:29,608 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4451090574264526, 'Total loss': 0.4451090574264526} | train loss {'Reaction outcome loss': 0.1249881318554153, 'Total loss': 0.1249881318554153}
2022-12-31 04:25:29,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:29,609 INFO:     Epoch: 74
2022-12-31 04:25:31,233 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45388516783714294, 'Total loss': 0.45388516783714294} | train loss {'Reaction outcome loss': 0.12500389385209215, 'Total loss': 0.12500389385209215}
2022-12-31 04:25:31,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:31,234 INFO:     Epoch: 75
2022-12-31 04:25:32,858 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45025082528591154, 'Total loss': 0.45025082528591154} | train loss {'Reaction outcome loss': 0.12459340539467319, 'Total loss': 0.12459340539467319}
2022-12-31 04:25:32,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:32,858 INFO:     Epoch: 76
2022-12-31 04:25:34,487 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4012137499948343, 'Total loss': 0.4012137499948343} | train loss {'Reaction outcome loss': 0.12474192046046602, 'Total loss': 0.12474192046046602}
2022-12-31 04:25:34,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:34,487 INFO:     Epoch: 77
2022-12-31 04:25:36,111 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.451333819826444, 'Total loss': 0.451333819826444} | train loss {'Reaction outcome loss': 0.12432530002822033, 'Total loss': 0.12432530002822033}
2022-12-31 04:25:36,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:36,112 INFO:     Epoch: 78
2022-12-31 04:25:37,744 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40407476872205733, 'Total loss': 0.40407476872205733} | train loss {'Reaction outcome loss': 0.12391440295373352, 'Total loss': 0.12391440295373352}
2022-12-31 04:25:37,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:37,744 INFO:     Epoch: 79
2022-12-31 04:25:39,359 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4468129346768061, 'Total loss': 0.4468129346768061} | train loss {'Reaction outcome loss': 0.12119725805925977, 'Total loss': 0.12119725805925977}
2022-12-31 04:25:39,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:39,359 INFO:     Epoch: 80
2022-12-31 04:25:40,973 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.448776571949323, 'Total loss': 0.448776571949323} | train loss {'Reaction outcome loss': 0.12507656917079948, 'Total loss': 0.12507656917079948}
2022-12-31 04:25:40,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:40,973 INFO:     Epoch: 81
2022-12-31 04:25:42,592 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45434105495611826, 'Total loss': 0.45434105495611826} | train loss {'Reaction outcome loss': 0.13320408525633748, 'Total loss': 0.13320408525633748}
2022-12-31 04:25:42,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:42,592 INFO:     Epoch: 82
2022-12-31 04:25:44,227 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40754678572217623, 'Total loss': 0.40754678572217623} | train loss {'Reaction outcome loss': 0.17684587053625603, 'Total loss': 0.17684587053625603}
2022-12-31 04:25:44,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:44,227 INFO:     Epoch: 83
2022-12-31 04:25:45,852 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43363107840220133, 'Total loss': 0.43363107840220133} | train loss {'Reaction outcome loss': 0.13265547283926804, 'Total loss': 0.13265547283926804}
2022-12-31 04:25:45,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:45,854 INFO:     Epoch: 84
2022-12-31 04:25:47,491 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40093038147315385, 'Total loss': 0.40093038147315385} | train loss {'Reaction outcome loss': 0.1210102692581342, 'Total loss': 0.1210102692581342}
2022-12-31 04:25:47,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:47,491 INFO:     Epoch: 85
2022-12-31 04:25:49,110 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4420295794804891, 'Total loss': 0.4420295794804891} | train loss {'Reaction outcome loss': 0.11683804515490445, 'Total loss': 0.11683804515490445}
2022-12-31 04:25:49,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:49,110 INFO:     Epoch: 86
2022-12-31 04:25:50,731 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41308410167694093, 'Total loss': 0.41308410167694093} | train loss {'Reaction outcome loss': 0.11488322000872543, 'Total loss': 0.11488322000872543}
2022-12-31 04:25:50,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:50,731 INFO:     Epoch: 87
2022-12-31 04:25:52,344 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3992798775434494, 'Total loss': 0.3992798775434494} | train loss {'Reaction outcome loss': 0.11688474531659439, 'Total loss': 0.11688474531659439}
2022-12-31 04:25:52,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:52,345 INFO:     Epoch: 88
2022-12-31 04:25:53,956 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41301174461841583, 'Total loss': 0.41301174461841583} | train loss {'Reaction outcome loss': 0.11715434834384697, 'Total loss': 0.11715434834384697}
2022-12-31 04:25:53,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:53,956 INFO:     Epoch: 89
2022-12-31 04:25:55,569 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4058214664459229, 'Total loss': 0.4058214664459229} | train loss {'Reaction outcome loss': 0.11620946785065674, 'Total loss': 0.11620946785065674}
2022-12-31 04:25:55,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:55,569 INFO:     Epoch: 90
2022-12-31 04:25:57,175 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41294992665449776, 'Total loss': 0.41294992665449776} | train loss {'Reaction outcome loss': 0.11507607497902506, 'Total loss': 0.11507607497902506}
2022-12-31 04:25:57,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:57,175 INFO:     Epoch: 91
2022-12-31 04:25:58,818 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40574075529972714, 'Total loss': 0.40574075529972714} | train loss {'Reaction outcome loss': 0.1187685894037598, 'Total loss': 0.1187685894037598}
2022-12-31 04:25:58,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:25:58,818 INFO:     Epoch: 92
2022-12-31 04:26:00,454 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3985558067758878, 'Total loss': 0.3985558067758878} | train loss {'Reaction outcome loss': 0.1181484961916399, 'Total loss': 0.1181484961916399}
2022-12-31 04:26:00,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:00,454 INFO:     Epoch: 93
2022-12-31 04:26:02,073 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42834898034731544, 'Total loss': 0.42834898034731544} | train loss {'Reaction outcome loss': 0.11517220357814369, 'Total loss': 0.11517220357814369}
2022-12-31 04:26:02,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:02,073 INFO:     Epoch: 94
2022-12-31 04:26:03,686 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4063364605108897, 'Total loss': 0.4063364605108897} | train loss {'Reaction outcome loss': 0.11891100363799774, 'Total loss': 0.11891100363799774}
2022-12-31 04:26:03,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:03,687 INFO:     Epoch: 95
2022-12-31 04:26:05,351 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4109125209351381, 'Total loss': 0.4109125209351381} | train loss {'Reaction outcome loss': 0.11964232876630705, 'Total loss': 0.11964232876630705}
2022-12-31 04:26:05,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:05,352 INFO:     Epoch: 96
2022-12-31 04:26:06,972 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42270700136820477, 'Total loss': 0.42270700136820477} | train loss {'Reaction outcome loss': 0.11625234470488648, 'Total loss': 0.11625234470488648}
2022-12-31 04:26:06,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:06,972 INFO:     Epoch: 97
2022-12-31 04:26:08,636 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41129196286201475, 'Total loss': 0.41129196286201475} | train loss {'Reaction outcome loss': 0.11495751251662285, 'Total loss': 0.11495751251662285}
2022-12-31 04:26:08,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:08,636 INFO:     Epoch: 98
2022-12-31 04:26:10,254 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4083892156680425, 'Total loss': 0.4083892156680425} | train loss {'Reaction outcome loss': 0.11393399758726709, 'Total loss': 0.11393399758726709}
2022-12-31 04:26:10,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:10,255 INFO:     Epoch: 99
2022-12-31 04:26:11,882 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43303798933823906, 'Total loss': 0.43303798933823906} | train loss {'Reaction outcome loss': 0.11034411027524756, 'Total loss': 0.11034411027524756}
2022-12-31 04:26:11,882 INFO:     Best model found after epoch 17 of 100.
2022-12-31 04:26:11,882 INFO:   Done with stage: TRAINING
2022-12-31 04:26:11,882 INFO:   Starting stage: EVALUATION
2022-12-31 04:26:12,015 INFO:   Done with stage: EVALUATION
2022-12-31 04:26:12,015 INFO:   Leaving out SEQ value Fold_8
2022-12-31 04:26:12,028 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 04:26:12,028 INFO:   Starting stage: FEATURE SCALING
2022-12-31 04:26:12,677 INFO:   Done with stage: FEATURE SCALING
2022-12-31 04:26:12,677 INFO:   Starting stage: SCALING TARGETS
2022-12-31 04:26:12,749 INFO:   Done with stage: SCALING TARGETS
2022-12-31 04:26:12,750 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:26:12,750 INFO:     No hyperparam tuning for this model
2022-12-31 04:26:12,750 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:26:12,750 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 04:26:12,750 INFO:     None feature selector for col prot
2022-12-31 04:26:12,751 INFO:     None feature selector for col prot
2022-12-31 04:26:12,751 INFO:     None feature selector for col prot
2022-12-31 04:26:12,751 INFO:     None feature selector for col chem
2022-12-31 04:26:12,751 INFO:     None feature selector for col chem
2022-12-31 04:26:12,751 INFO:     None feature selector for col chem
2022-12-31 04:26:12,751 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 04:26:12,752 INFO:   Starting stage: BUILD MODEL
2022-12-31 04:26:12,753 INFO:     Number of params in model 224011
2022-12-31 04:26:12,757 INFO:   Done with stage: BUILD MODEL
2022-12-31 04:26:12,757 INFO:   Starting stage: TRAINING
2022-12-31 04:26:12,802 INFO:     Val loss before train {'Reaction outcome loss': 0.9753735820452373, 'Total loss': 0.9753735820452373}
2022-12-31 04:26:12,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:12,802 INFO:     Epoch: 0
2022-12-31 04:26:14,403 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5738904694716136, 'Total loss': 0.5738904694716136} | train loss {'Reaction outcome loss': 0.7612877335303869, 'Total loss': 0.7612877335303869}
2022-12-31 04:26:14,403 INFO:     Found new best model at epoch 0
2022-12-31 04:26:14,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:14,404 INFO:     Epoch: 1
2022-12-31 04:26:15,994 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5121075093746186, 'Total loss': 0.5121075093746186} | train loss {'Reaction outcome loss': 0.503207552127349, 'Total loss': 0.503207552127349}
2022-12-31 04:26:15,994 INFO:     Found new best model at epoch 1
2022-12-31 04:26:15,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:15,995 INFO:     Epoch: 2
2022-12-31 04:26:17,591 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4642112116018931, 'Total loss': 0.4642112116018931} | train loss {'Reaction outcome loss': 0.43884791417436286, 'Total loss': 0.43884791417436286}
2022-12-31 04:26:17,591 INFO:     Found new best model at epoch 2
2022-12-31 04:26:17,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:17,592 INFO:     Epoch: 3
2022-12-31 04:26:19,188 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47876366078853605, 'Total loss': 0.47876366078853605} | train loss {'Reaction outcome loss': 0.3978675357697211, 'Total loss': 0.3978675357697211}
2022-12-31 04:26:19,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:19,188 INFO:     Epoch: 4
2022-12-31 04:26:20,836 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46743603348731994, 'Total loss': 0.46743603348731994} | train loss {'Reaction outcome loss': 0.36545625514599867, 'Total loss': 0.36545625514599867}
2022-12-31 04:26:20,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:20,837 INFO:     Epoch: 5
2022-12-31 04:26:22,439 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46325838565826416, 'Total loss': 0.46325838565826416} | train loss {'Reaction outcome loss': 0.3419674977714762, 'Total loss': 0.3419674977714762}
2022-12-31 04:26:22,439 INFO:     Found new best model at epoch 5
2022-12-31 04:26:22,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:22,440 INFO:     Epoch: 6
2022-12-31 04:26:24,037 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4501807560523351, 'Total loss': 0.4501807560523351} | train loss {'Reaction outcome loss': 0.3257860623764031, 'Total loss': 0.3257860623764031}
2022-12-31 04:26:24,037 INFO:     Found new best model at epoch 6
2022-12-31 04:26:24,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:24,038 INFO:     Epoch: 7
2022-12-31 04:26:25,630 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4570699135462443, 'Total loss': 0.4570699135462443} | train loss {'Reaction outcome loss': 0.3045261712214353, 'Total loss': 0.3045261712214353}
2022-12-31 04:26:25,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:25,630 INFO:     Epoch: 8
2022-12-31 04:26:27,257 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4723564843336741, 'Total loss': 0.4723564843336741} | train loss {'Reaction outcome loss': 0.28780833365661757, 'Total loss': 0.28780833365661757}
2022-12-31 04:26:27,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:27,258 INFO:     Epoch: 9
2022-12-31 04:26:28,871 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4564391295115153, 'Total loss': 0.4564391295115153} | train loss {'Reaction outcome loss': 0.2765909717469425, 'Total loss': 0.2765909717469425}
2022-12-31 04:26:28,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:28,871 INFO:     Epoch: 10
2022-12-31 04:26:30,485 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4433620244264603, 'Total loss': 0.4433620244264603} | train loss {'Reaction outcome loss': 0.2648520082944915, 'Total loss': 0.2648520082944915}
2022-12-31 04:26:30,485 INFO:     Found new best model at epoch 10
2022-12-31 04:26:30,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:30,486 INFO:     Epoch: 11
2022-12-31 04:26:32,103 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49487778544425964, 'Total loss': 0.49487778544425964} | train loss {'Reaction outcome loss': 0.25859761759365874, 'Total loss': 0.25859761759365874}
2022-12-31 04:26:32,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:32,103 INFO:     Epoch: 12
2022-12-31 04:26:33,717 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4691848168770472, 'Total loss': 0.4691848168770472} | train loss {'Reaction outcome loss': 0.24611235588734404, 'Total loss': 0.24611235588734404}
2022-12-31 04:26:33,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:33,717 INFO:     Epoch: 13
2022-12-31 04:26:35,339 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4651224931081136, 'Total loss': 0.4651224931081136} | train loss {'Reaction outcome loss': 0.23230110619203512, 'Total loss': 0.23230110619203512}
2022-12-31 04:26:35,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:35,339 INFO:     Epoch: 14
2022-12-31 04:26:36,949 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4167096346616745, 'Total loss': 0.4167096346616745} | train loss {'Reaction outcome loss': 0.2281193780702549, 'Total loss': 0.2281193780702549}
2022-12-31 04:26:36,949 INFO:     Found new best model at epoch 14
2022-12-31 04:26:36,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:36,950 INFO:     Epoch: 15
2022-12-31 04:26:38,571 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45150243043899535, 'Total loss': 0.45150243043899535} | train loss {'Reaction outcome loss': 0.21984636535247168, 'Total loss': 0.21984636535247168}
2022-12-31 04:26:38,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:38,571 INFO:     Epoch: 16
2022-12-31 04:26:40,205 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4304611571133137, 'Total loss': 0.4304611571133137} | train loss {'Reaction outcome loss': 0.2179776596471722, 'Total loss': 0.2179776596471722}
2022-12-31 04:26:40,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:40,206 INFO:     Epoch: 17
2022-12-31 04:26:41,811 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4403179526329041, 'Total loss': 0.4403179526329041} | train loss {'Reaction outcome loss': 0.20416798783745957, 'Total loss': 0.20416798783745957}
2022-12-31 04:26:41,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:41,812 INFO:     Epoch: 18
2022-12-31 04:26:43,426 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45353686312834424, 'Total loss': 0.45353686312834424} | train loss {'Reaction outcome loss': 0.2013655686034606, 'Total loss': 0.2013655686034606}
2022-12-31 04:26:43,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:43,426 INFO:     Epoch: 19
2022-12-31 04:26:45,037 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49862721649309, 'Total loss': 0.49862721649309} | train loss {'Reaction outcome loss': 0.19555817697292718, 'Total loss': 0.19555817697292718}
2022-12-31 04:26:45,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:45,038 INFO:     Epoch: 20
2022-12-31 04:26:46,643 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49462413092454277, 'Total loss': 0.49462413092454277} | train loss {'Reaction outcome loss': 0.189097497429726, 'Total loss': 0.189097497429726}
2022-12-31 04:26:46,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:46,643 INFO:     Epoch: 21
2022-12-31 04:26:48,319 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47050720353921255, 'Total loss': 0.47050720353921255} | train loss {'Reaction outcome loss': 0.1851376184081529, 'Total loss': 0.1851376184081529}
2022-12-31 04:26:48,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:48,319 INFO:     Epoch: 22
2022-12-31 04:26:49,968 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44080372899770737, 'Total loss': 0.44080372899770737} | train loss {'Reaction outcome loss': 0.18415159188661273, 'Total loss': 0.18415159188661273}
2022-12-31 04:26:49,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:49,968 INFO:     Epoch: 23
2022-12-31 04:26:51,611 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43644925380746524, 'Total loss': 0.43644925380746524} | train loss {'Reaction outcome loss': 0.18081279566013442, 'Total loss': 0.18081279566013442}
2022-12-31 04:26:51,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:51,612 INFO:     Epoch: 24
2022-12-31 04:26:53,208 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45551426013310753, 'Total loss': 0.45551426013310753} | train loss {'Reaction outcome loss': 0.17917597801475735, 'Total loss': 0.17917597801475735}
2022-12-31 04:26:53,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:53,209 INFO:     Epoch: 25
2022-12-31 04:26:54,844 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45668259014685947, 'Total loss': 0.45668259014685947} | train loss {'Reaction outcome loss': 0.17074484924270666, 'Total loss': 0.17074484924270666}
2022-12-31 04:26:54,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:54,844 INFO:     Epoch: 26
2022-12-31 04:26:56,445 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48087839086850487, 'Total loss': 0.48087839086850487} | train loss {'Reaction outcome loss': 0.16546029920584007, 'Total loss': 0.16546029920584007}
2022-12-31 04:26:56,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:56,445 INFO:     Epoch: 27
2022-12-31 04:26:58,050 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5015331516663234, 'Total loss': 0.5015331516663234} | train loss {'Reaction outcome loss': 0.16584844392939255, 'Total loss': 0.16584844392939255}
2022-12-31 04:26:58,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:58,051 INFO:     Epoch: 28
2022-12-31 04:26:59,647 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47672749956448873, 'Total loss': 0.47672749956448873} | train loss {'Reaction outcome loss': 0.16402330520416136, 'Total loss': 0.16402330520416136}
2022-12-31 04:26:59,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:26:59,647 INFO:     Epoch: 29
2022-12-31 04:27:01,279 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4905464688936869, 'Total loss': 0.4905464688936869} | train loss {'Reaction outcome loss': 0.16173813648985855, 'Total loss': 0.16173813648985855}
2022-12-31 04:27:01,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:01,279 INFO:     Epoch: 30
2022-12-31 04:27:02,897 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5196344494819641, 'Total loss': 0.5196344494819641} | train loss {'Reaction outcome loss': 0.15626485234351603, 'Total loss': 0.15626485234351603}
2022-12-31 04:27:02,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:02,897 INFO:     Epoch: 31
2022-12-31 04:27:04,508 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45562782138586044, 'Total loss': 0.45562782138586044} | train loss {'Reaction outcome loss': 0.15610063812548752, 'Total loss': 0.15610063812548752}
2022-12-31 04:27:04,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:04,509 INFO:     Epoch: 32
2022-12-31 04:27:06,124 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4472230871518453, 'Total loss': 0.4472230871518453} | train loss {'Reaction outcome loss': 0.14993696044379975, 'Total loss': 0.14993696044379975}
2022-12-31 04:27:06,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:06,125 INFO:     Epoch: 33
2022-12-31 04:27:07,740 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4507718821366628, 'Total loss': 0.4507718821366628} | train loss {'Reaction outcome loss': 0.15035759231532778, 'Total loss': 0.15035759231532778}
2022-12-31 04:27:07,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:07,740 INFO:     Epoch: 34
2022-12-31 04:27:09,354 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5297353953123093, 'Total loss': 0.5297353953123093} | train loss {'Reaction outcome loss': 0.1470202242114646, 'Total loss': 0.1470202242114646}
2022-12-31 04:27:09,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:09,354 INFO:     Epoch: 35
2022-12-31 04:27:10,961 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45948020884146296, 'Total loss': 0.45948020884146296} | train loss {'Reaction outcome loss': 0.14181322296364948, 'Total loss': 0.14181322296364948}
2022-12-31 04:27:10,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:10,962 INFO:     Epoch: 36
2022-12-31 04:27:12,573 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4677794526020686, 'Total loss': 0.4677794526020686} | train loss {'Reaction outcome loss': 0.14366925707523584, 'Total loss': 0.14366925707523584}
2022-12-31 04:27:12,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:12,573 INFO:     Epoch: 37
2022-12-31 04:27:14,168 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49153354366620383, 'Total loss': 0.49153354366620383} | train loss {'Reaction outcome loss': 0.13912316053617924, 'Total loss': 0.13912316053617924}
2022-12-31 04:27:14,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:14,168 INFO:     Epoch: 38
2022-12-31 04:27:15,815 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47313892245292666, 'Total loss': 0.47313892245292666} | train loss {'Reaction outcome loss': 0.1426347008438938, 'Total loss': 0.1426347008438938}
2022-12-31 04:27:15,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:15,815 INFO:     Epoch: 39
2022-12-31 04:27:17,438 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47278655469417574, 'Total loss': 0.47278655469417574} | train loss {'Reaction outcome loss': 0.14179949547699738, 'Total loss': 0.14179949547699738}
2022-12-31 04:27:17,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:17,438 INFO:     Epoch: 40
2022-12-31 04:27:19,048 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4847983737786611, 'Total loss': 0.4847983737786611} | train loss {'Reaction outcome loss': 0.1358679981881773, 'Total loss': 0.1358679981881773}
2022-12-31 04:27:19,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:19,048 INFO:     Epoch: 41
2022-12-31 04:27:20,690 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4557203009724617, 'Total loss': 0.4557203009724617} | train loss {'Reaction outcome loss': 0.13683213651071102, 'Total loss': 0.13683213651071102}
2022-12-31 04:27:20,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:20,690 INFO:     Epoch: 42
2022-12-31 04:27:22,310 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4825245887041092, 'Total loss': 0.4825245887041092} | train loss {'Reaction outcome loss': 0.1314596507336685, 'Total loss': 0.1314596507336685}
2022-12-31 04:27:22,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:22,311 INFO:     Epoch: 43
2022-12-31 04:27:23,912 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4696649879217148, 'Total loss': 0.4696649879217148} | train loss {'Reaction outcome loss': 0.13143339545479651, 'Total loss': 0.13143339545479651}
2022-12-31 04:27:23,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:23,912 INFO:     Epoch: 44
2022-12-31 04:27:25,560 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4985853244860967, 'Total loss': 0.4985853244860967} | train loss {'Reaction outcome loss': 0.12629224204257022, 'Total loss': 0.12629224204257022}
2022-12-31 04:27:25,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:25,560 INFO:     Epoch: 45
2022-12-31 04:27:27,196 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.518052805463473, 'Total loss': 0.518052805463473} | train loss {'Reaction outcome loss': 0.12598513360322885, 'Total loss': 0.12598513360322885}
2022-12-31 04:27:27,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:27,196 INFO:     Epoch: 46
2022-12-31 04:27:28,818 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48560320933659873, 'Total loss': 0.48560320933659873} | train loss {'Reaction outcome loss': 0.12693911935833893, 'Total loss': 0.12693911935833893}
2022-12-31 04:27:28,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:28,819 INFO:     Epoch: 47
2022-12-31 04:27:30,436 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48700138330459597, 'Total loss': 0.48700138330459597} | train loss {'Reaction outcome loss': 0.1271856938703702, 'Total loss': 0.1271856938703702}
2022-12-31 04:27:30,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:30,436 INFO:     Epoch: 48
2022-12-31 04:27:32,062 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45932967563470206, 'Total loss': 0.45932967563470206} | train loss {'Reaction outcome loss': 0.1251278367778798, 'Total loss': 0.1251278367778798}
2022-12-31 04:27:32,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:32,062 INFO:     Epoch: 49
2022-12-31 04:27:33,660 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46229101220766705, 'Total loss': 0.46229101220766705} | train loss {'Reaction outcome loss': 0.12761222064706595, 'Total loss': 0.12761222064706595}
2022-12-31 04:27:33,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:33,660 INFO:     Epoch: 50
2022-12-31 04:27:35,260 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.438303554058075, 'Total loss': 0.438303554058075} | train loss {'Reaction outcome loss': 0.12337478722066997, 'Total loss': 0.12337478722066997}
2022-12-31 04:27:35,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:35,260 INFO:     Epoch: 51
2022-12-31 04:27:36,902 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4633550226688385, 'Total loss': 0.4633550226688385} | train loss {'Reaction outcome loss': 0.12537149573853684, 'Total loss': 0.12537149573853684}
2022-12-31 04:27:36,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:36,903 INFO:     Epoch: 52
2022-12-31 04:27:38,514 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5035530130068461, 'Total loss': 0.5035530130068461} | train loss {'Reaction outcome loss': 0.12079069688029233, 'Total loss': 0.12079069688029233}
2022-12-31 04:27:38,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:38,514 INFO:     Epoch: 53
2022-12-31 04:27:40,119 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45456916093826294, 'Total loss': 0.45456916093826294} | train loss {'Reaction outcome loss': 0.12061011465650134, 'Total loss': 0.12061011465650134}
2022-12-31 04:27:40,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:40,119 INFO:     Epoch: 54
2022-12-31 04:27:41,711 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46828788916269937, 'Total loss': 0.46828788916269937} | train loss {'Reaction outcome loss': 0.11951339922865832, 'Total loss': 0.11951339922865832}
2022-12-31 04:27:41,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:41,712 INFO:     Epoch: 55
2022-12-31 04:27:43,306 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4653824230035146, 'Total loss': 0.4653824230035146} | train loss {'Reaction outcome loss': 0.11866628484384263, 'Total loss': 0.11866628484384263}
2022-12-31 04:27:43,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:43,306 INFO:     Epoch: 56
2022-12-31 04:27:44,948 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48678499857584634, 'Total loss': 0.48678499857584634} | train loss {'Reaction outcome loss': 0.11586708946225162, 'Total loss': 0.11586708946225162}
2022-12-31 04:27:44,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:44,948 INFO:     Epoch: 57
2022-12-31 04:27:46,554 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4233815074898303, 'Total loss': 0.4233815074898303} | train loss {'Reaction outcome loss': 0.11780435135485706, 'Total loss': 0.11780435135485706}
2022-12-31 04:27:46,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:46,555 INFO:     Epoch: 58
2022-12-31 04:27:48,201 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.461835781733195, 'Total loss': 0.461835781733195} | train loss {'Reaction outcome loss': 0.11695319926963212, 'Total loss': 0.11695319926963212}
2022-12-31 04:27:48,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:48,201 INFO:     Epoch: 59
2022-12-31 04:27:49,820 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44495406150817873, 'Total loss': 0.44495406150817873} | train loss {'Reaction outcome loss': 0.11484045519462817, 'Total loss': 0.11484045519462817}
2022-12-31 04:27:49,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:49,821 INFO:     Epoch: 60
2022-12-31 04:27:51,427 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47673267126083374, 'Total loss': 0.47673267126083374} | train loss {'Reaction outcome loss': 0.11293397780726135, 'Total loss': 0.11293397780726135}
2022-12-31 04:27:51,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:51,427 INFO:     Epoch: 61
2022-12-31 04:27:53,035 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46505242586135864, 'Total loss': 0.46505242586135864} | train loss {'Reaction outcome loss': 0.1194071435291088, 'Total loss': 0.1194071435291088}
2022-12-31 04:27:53,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:53,036 INFO:     Epoch: 62
2022-12-31 04:27:54,640 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47786861956119536, 'Total loss': 0.47786861956119536} | train loss {'Reaction outcome loss': 0.1173503842898184, 'Total loss': 0.1173503842898184}
2022-12-31 04:27:54,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:54,640 INFO:     Epoch: 63
2022-12-31 04:27:56,258 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4425395905971527, 'Total loss': 0.4425395905971527} | train loss {'Reaction outcome loss': 0.11707185686398776, 'Total loss': 0.11707185686398776}
2022-12-31 04:27:56,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:56,258 INFO:     Epoch: 64
2022-12-31 04:27:57,872 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.426619915291667, 'Total loss': 0.426619915291667} | train loss {'Reaction outcome loss': 0.1142505891450541, 'Total loss': 0.1142505891450541}
2022-12-31 04:27:57,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:57,872 INFO:     Epoch: 65
2022-12-31 04:27:59,504 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47724169691403706, 'Total loss': 0.47724169691403706} | train loss {'Reaction outcome loss': 0.115759433823682, 'Total loss': 0.115759433823682}
2022-12-31 04:27:59,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:27:59,505 INFO:     Epoch: 66
2022-12-31 04:28:01,163 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44718646903832754, 'Total loss': 0.44718646903832754} | train loss {'Reaction outcome loss': 0.11812803284827988, 'Total loss': 0.11812803284827988}
2022-12-31 04:28:01,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:01,163 INFO:     Epoch: 67
2022-12-31 04:28:02,807 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4731388280789057, 'Total loss': 0.4731388280789057} | train loss {'Reaction outcome loss': 0.12100619888496023, 'Total loss': 0.12100619888496023}
2022-12-31 04:28:02,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:02,807 INFO:     Epoch: 68
2022-12-31 04:28:04,452 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4331885260840257, 'Total loss': 0.4331885260840257} | train loss {'Reaction outcome loss': 0.10932641999195619, 'Total loss': 0.10932641999195619}
2022-12-31 04:28:04,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:04,452 INFO:     Epoch: 69
2022-12-31 04:28:06,083 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5044571568568548, 'Total loss': 0.5044571568568548} | train loss {'Reaction outcome loss': 0.10563367328200585, 'Total loss': 0.10563367328200585}
2022-12-31 04:28:06,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:06,084 INFO:     Epoch: 70
2022-12-31 04:28:07,696 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4480192869901657, 'Total loss': 0.4480192869901657} | train loss {'Reaction outcome loss': 0.1060901338534324, 'Total loss': 0.1060901338534324}
2022-12-31 04:28:07,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:07,696 INFO:     Epoch: 71
2022-12-31 04:28:09,313 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4474760894974073, 'Total loss': 0.4474760894974073} | train loss {'Reaction outcome loss': 0.10718437094811091, 'Total loss': 0.10718437094811091}
2022-12-31 04:28:09,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:09,313 INFO:     Epoch: 72
2022-12-31 04:28:10,928 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4675447762012482, 'Total loss': 0.4675447762012482} | train loss {'Reaction outcome loss': 0.11162247678142163, 'Total loss': 0.11162247678142163}
2022-12-31 04:28:10,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:10,928 INFO:     Epoch: 73
2022-12-31 04:28:12,544 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43752796451250714, 'Total loss': 0.43752796451250714} | train loss {'Reaction outcome loss': 0.11069337058140327, 'Total loss': 0.11069337058140327}
2022-12-31 04:28:12,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:12,545 INFO:     Epoch: 74
2022-12-31 04:28:14,150 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43907900837560493, 'Total loss': 0.43907900837560493} | train loss {'Reaction outcome loss': 0.11156283857321346, 'Total loss': 0.11156283857321346}
2022-12-31 04:28:14,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:14,150 INFO:     Epoch: 75
2022-12-31 04:28:15,789 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46155053153634074, 'Total loss': 0.46155053153634074} | train loss {'Reaction outcome loss': 0.1105215065262277, 'Total loss': 0.1105215065262277}
2022-12-31 04:28:15,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:15,789 INFO:     Epoch: 76
2022-12-31 04:28:17,390 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48373694717884064, 'Total loss': 0.48373694717884064} | train loss {'Reaction outcome loss': 0.10785290841251993, 'Total loss': 0.10785290841251993}
2022-12-31 04:28:17,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:17,390 INFO:     Epoch: 77
2022-12-31 04:28:19,003 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4855784296989441, 'Total loss': 0.4855784296989441} | train loss {'Reaction outcome loss': 0.10612716721865474, 'Total loss': 0.10612716721865474}
2022-12-31 04:28:19,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:19,003 INFO:     Epoch: 78
2022-12-31 04:28:20,615 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.446353871623675, 'Total loss': 0.446353871623675} | train loss {'Reaction outcome loss': 0.11051491433123448, 'Total loss': 0.11051491433123448}
2022-12-31 04:28:20,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:20,616 INFO:     Epoch: 79
2022-12-31 04:28:22,223 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4512853682041168, 'Total loss': 0.4512853682041168} | train loss {'Reaction outcome loss': 0.10888857982247631, 'Total loss': 0.10888857982247631}
2022-12-31 04:28:22,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:22,223 INFO:     Epoch: 80
2022-12-31 04:28:23,836 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47563564976056416, 'Total loss': 0.47563564976056416} | train loss {'Reaction outcome loss': 0.10691716949175702, 'Total loss': 0.10691716949175702}
2022-12-31 04:28:23,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:23,838 INFO:     Epoch: 81
2022-12-31 04:28:25,433 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49970861673355105, 'Total loss': 0.49970861673355105} | train loss {'Reaction outcome loss': 0.1076660229681203, 'Total loss': 0.1076660229681203}
2022-12-31 04:28:25,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:25,433 INFO:     Epoch: 82
2022-12-31 04:28:27,029 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4772150953610738, 'Total loss': 0.4772150953610738} | train loss {'Reaction outcome loss': 0.1051760865281585, 'Total loss': 0.1051760865281585}
2022-12-31 04:28:27,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:27,029 INFO:     Epoch: 83
2022-12-31 04:28:28,625 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4817860623200734, 'Total loss': 0.4817860623200734} | train loss {'Reaction outcome loss': 0.10485987211389965, 'Total loss': 0.10485987211389965}
2022-12-31 04:28:28,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:28,625 INFO:     Epoch: 84
2022-12-31 04:28:30,266 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4824687202771505, 'Total loss': 0.4824687202771505} | train loss {'Reaction outcome loss': 0.10800344649797831, 'Total loss': 0.10800344649797831}
2022-12-31 04:28:30,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:30,267 INFO:     Epoch: 85
2022-12-31 04:28:31,867 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46297751665115355, 'Total loss': 0.46297751665115355} | train loss {'Reaction outcome loss': 0.10586292339546859, 'Total loss': 0.10586292339546859}
2022-12-31 04:28:31,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:31,867 INFO:     Epoch: 86
2022-12-31 04:28:33,471 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4532025992870331, 'Total loss': 0.4532025992870331} | train loss {'Reaction outcome loss': 0.11437545117244957, 'Total loss': 0.11437545117244957}
2022-12-31 04:28:33,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:33,471 INFO:     Epoch: 87
2022-12-31 04:28:35,099 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4705680747826894, 'Total loss': 0.4705680747826894} | train loss {'Reaction outcome loss': 0.10604327268925778, 'Total loss': 0.10604327268925778}
2022-12-31 04:28:35,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:35,099 INFO:     Epoch: 88
2022-12-31 04:28:36,742 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45266775687535604, 'Total loss': 0.45266775687535604} | train loss {'Reaction outcome loss': 0.10427477884092692, 'Total loss': 0.10427477884092692}
2022-12-31 04:28:36,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:36,742 INFO:     Epoch: 89
2022-12-31 04:28:38,385 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5025112176934878, 'Total loss': 0.5025112176934878} | train loss {'Reaction outcome loss': 0.10581529604513266, 'Total loss': 0.10581529604513266}
2022-12-31 04:28:38,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:38,385 INFO:     Epoch: 90
2022-12-31 04:28:40,029 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4693281531333923, 'Total loss': 0.4693281531333923} | train loss {'Reaction outcome loss': 0.10519945563751891, 'Total loss': 0.10519945563751891}
2022-12-31 04:28:40,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:40,029 INFO:     Epoch: 91
2022-12-31 04:28:41,626 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4743630637725194, 'Total loss': 0.4743630637725194} | train loss {'Reaction outcome loss': 0.10623493256139477, 'Total loss': 0.10623493256139477}
2022-12-31 04:28:41,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:41,626 INFO:     Epoch: 92
2022-12-31 04:28:43,229 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5578593889872233, 'Total loss': 0.5578593889872233} | train loss {'Reaction outcome loss': 0.10842930701656793, 'Total loss': 0.10842930701656793}
2022-12-31 04:28:43,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:43,230 INFO:     Epoch: 93
2022-12-31 04:28:44,823 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48188791299859685, 'Total loss': 0.48188791299859685} | train loss {'Reaction outcome loss': 0.1066089414423434, 'Total loss': 0.1066089414423434}
2022-12-31 04:28:44,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:44,824 INFO:     Epoch: 94
2022-12-31 04:28:46,470 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.49612632195154827, 'Total loss': 0.49612632195154827} | train loss {'Reaction outcome loss': 0.1035428185245336, 'Total loss': 0.1035428185245336}
2022-12-31 04:28:46,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:46,471 INFO:     Epoch: 95
2022-12-31 04:28:48,117 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48088624676068625, 'Total loss': 0.48088624676068625} | train loss {'Reaction outcome loss': 0.1042661089294474, 'Total loss': 0.1042661089294474}
2022-12-31 04:28:48,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:48,117 INFO:     Epoch: 96
2022-12-31 04:28:49,716 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5019514198104541, 'Total loss': 0.5019514198104541} | train loss {'Reaction outcome loss': 0.10067383055114648, 'Total loss': 0.10067383055114648}
2022-12-31 04:28:49,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:49,717 INFO:     Epoch: 97
2022-12-31 04:28:51,330 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4425160062499344, 'Total loss': 0.4425160062499344} | train loss {'Reaction outcome loss': 0.10132910109989877, 'Total loss': 0.10132910109989877}
2022-12-31 04:28:51,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:51,330 INFO:     Epoch: 98
2022-12-31 04:28:52,988 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.50396901567777, 'Total loss': 0.50396901567777} | train loss {'Reaction outcome loss': 0.10131269359863926, 'Total loss': 0.10131269359863926}
2022-12-31 04:28:52,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:52,988 INFO:     Epoch: 99
2022-12-31 04:28:54,598 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46483536760012306, 'Total loss': 0.46483536760012306} | train loss {'Reaction outcome loss': 0.11339025806563978, 'Total loss': 0.11339025806563978}
2022-12-31 04:28:54,599 INFO:     Best model found after epoch 15 of 100.
2022-12-31 04:28:54,600 INFO:   Done with stage: TRAINING
2022-12-31 04:28:54,600 INFO:   Starting stage: EVALUATION
2022-12-31 04:28:54,743 INFO:   Done with stage: EVALUATION
2022-12-31 04:28:54,743 INFO:   Leaving out SEQ value Fold_9
2022-12-31 04:28:54,756 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 04:28:54,756 INFO:   Starting stage: FEATURE SCALING
2022-12-31 04:28:55,394 INFO:   Done with stage: FEATURE SCALING
2022-12-31 04:28:55,394 INFO:   Starting stage: SCALING TARGETS
2022-12-31 04:28:55,466 INFO:   Done with stage: SCALING TARGETS
2022-12-31 04:28:55,466 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:28:55,466 INFO:     No hyperparam tuning for this model
2022-12-31 04:28:55,466 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:28:55,466 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 04:28:55,467 INFO:     None feature selector for col prot
2022-12-31 04:28:55,467 INFO:     None feature selector for col prot
2022-12-31 04:28:55,467 INFO:     None feature selector for col prot
2022-12-31 04:28:55,467 INFO:     None feature selector for col chem
2022-12-31 04:28:55,468 INFO:     None feature selector for col chem
2022-12-31 04:28:55,468 INFO:     None feature selector for col chem
2022-12-31 04:28:55,468 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 04:28:55,468 INFO:   Starting stage: BUILD MODEL
2022-12-31 04:28:55,469 INFO:     Number of params in model 224011
2022-12-31 04:28:55,473 INFO:   Done with stage: BUILD MODEL
2022-12-31 04:28:55,473 INFO:   Starting stage: TRAINING
2022-12-31 04:28:55,518 INFO:     Val loss before train {'Reaction outcome loss': 0.9909351150194804, 'Total loss': 0.9909351150194804}
2022-12-31 04:28:55,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:55,518 INFO:     Epoch: 0
2022-12-31 04:28:57,134 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5074573397636414, 'Total loss': 0.5074573397636414} | train loss {'Reaction outcome loss': 0.769749946244385, 'Total loss': 0.769749946244385}
2022-12-31 04:28:57,134 INFO:     Found new best model at epoch 0
2022-12-31 04:28:57,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:57,135 INFO:     Epoch: 1
2022-12-31 04:28:58,750 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.42473357915878296, 'Total loss': 0.42473357915878296} | train loss {'Reaction outcome loss': 0.5069960656329531, 'Total loss': 0.5069960656329531}
2022-12-31 04:28:58,750 INFO:     Found new best model at epoch 1
2022-12-31 04:28:58,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:28:58,751 INFO:     Epoch: 2
2022-12-31 04:29:00,404 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.3920515954494476, 'Total loss': 0.3920515954494476} | train loss {'Reaction outcome loss': 0.4382019891088113, 'Total loss': 0.4382019891088113}
2022-12-31 04:29:00,404 INFO:     Found new best model at epoch 2
2022-12-31 04:29:00,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:00,405 INFO:     Epoch: 3
2022-12-31 04:29:02,032 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4086549470822016, 'Total loss': 0.4086549470822016} | train loss {'Reaction outcome loss': 0.39890772589495865, 'Total loss': 0.39890772589495865}
2022-12-31 04:29:02,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:02,033 INFO:     Epoch: 4
2022-12-31 04:29:03,660 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.3884730686744054, 'Total loss': 0.3884730686744054} | train loss {'Reaction outcome loss': 0.37239452813198604, 'Total loss': 0.37239452813198604}
2022-12-31 04:29:03,661 INFO:     Found new best model at epoch 4
2022-12-31 04:29:03,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:03,662 INFO:     Epoch: 5
2022-12-31 04:29:05,288 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.36869795620441437, 'Total loss': 0.36869795620441437} | train loss {'Reaction outcome loss': 0.3481769536257438, 'Total loss': 0.3481769536257438}
2022-12-31 04:29:05,288 INFO:     Found new best model at epoch 5
2022-12-31 04:29:05,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:05,289 INFO:     Epoch: 6
2022-12-31 04:29:06,921 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.37926614383856455, 'Total loss': 0.37926614383856455} | train loss {'Reaction outcome loss': 0.32813235949985636, 'Total loss': 0.32813235949985636}
2022-12-31 04:29:06,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:06,922 INFO:     Epoch: 7
2022-12-31 04:29:08,546 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3955359439055125, 'Total loss': 0.3955359439055125} | train loss {'Reaction outcome loss': 0.31087566640369757, 'Total loss': 0.31087566640369757}
2022-12-31 04:29:08,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:08,546 INFO:     Epoch: 8
2022-12-31 04:29:10,164 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.37833389031390346, 'Total loss': 0.37833389031390346} | train loss {'Reaction outcome loss': 0.2973462977865036, 'Total loss': 0.2973462977865036}
2022-12-31 04:29:10,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:10,164 INFO:     Epoch: 9
2022-12-31 04:29:11,784 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.38622283240159355, 'Total loss': 0.38622283240159355} | train loss {'Reaction outcome loss': 0.2840374066650324, 'Total loss': 0.2840374066650324}
2022-12-31 04:29:11,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:11,785 INFO:     Epoch: 10
2022-12-31 04:29:13,411 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40248156785964967, 'Total loss': 0.40248156785964967} | train loss {'Reaction outcome loss': 0.2691187913296744, 'Total loss': 0.2691187913296744}
2022-12-31 04:29:13,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:13,412 INFO:     Epoch: 11
2022-12-31 04:29:15,036 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3941550354162852, 'Total loss': 0.3941550354162852} | train loss {'Reaction outcome loss': 0.26063778903335333, 'Total loss': 0.26063778903335333}
2022-12-31 04:29:15,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:15,037 INFO:     Epoch: 12
2022-12-31 04:29:16,658 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3815336674451828, 'Total loss': 0.3815336674451828} | train loss {'Reaction outcome loss': 0.2503892301203872, 'Total loss': 0.2503892301203872}
2022-12-31 04:29:16,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:16,659 INFO:     Epoch: 13
2022-12-31 04:29:18,275 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3879256973663966, 'Total loss': 0.3879256973663966} | train loss {'Reaction outcome loss': 0.2393186954828654, 'Total loss': 0.2393186954828654}
2022-12-31 04:29:18,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:18,275 INFO:     Epoch: 14
2022-12-31 04:29:19,900 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.382736082871755, 'Total loss': 0.382736082871755} | train loss {'Reaction outcome loss': 0.2311436230590081, 'Total loss': 0.2311436230590081}
2022-12-31 04:29:19,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:19,900 INFO:     Epoch: 15
2022-12-31 04:29:21,518 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3919244388739268, 'Total loss': 0.3919244388739268} | train loss {'Reaction outcome loss': 0.22011822548866158, 'Total loss': 0.22011822548866158}
2022-12-31 04:29:21,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:21,518 INFO:     Epoch: 16
2022-12-31 04:29:23,143 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40607939660549164, 'Total loss': 0.40607939660549164} | train loss {'Reaction outcome loss': 0.2130155775079059, 'Total loss': 0.2130155775079059}
2022-12-31 04:29:23,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:23,143 INFO:     Epoch: 17
2022-12-31 04:29:24,774 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3930304487546285, 'Total loss': 0.3930304487546285} | train loss {'Reaction outcome loss': 0.2075595878215635, 'Total loss': 0.2075595878215635}
2022-12-31 04:29:24,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:24,775 INFO:     Epoch: 18
2022-12-31 04:29:26,401 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42278916339079536, 'Total loss': 0.42278916339079536} | train loss {'Reaction outcome loss': 0.20265159629615073, 'Total loss': 0.20265159629615073}
2022-12-31 04:29:26,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:26,401 INFO:     Epoch: 19
2022-12-31 04:29:28,018 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3943929980198542, 'Total loss': 0.3943929980198542} | train loss {'Reaction outcome loss': 0.22124876575611963, 'Total loss': 0.22124876575611963}
2022-12-31 04:29:28,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:28,019 INFO:     Epoch: 20
2022-12-31 04:29:29,641 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4153133869171143, 'Total loss': 0.4153133869171143} | train loss {'Reaction outcome loss': 0.20030720831625554, 'Total loss': 0.20030720831625554}
2022-12-31 04:29:29,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:29,641 INFO:     Epoch: 21
2022-12-31 04:29:31,266 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3993076682090759, 'Total loss': 0.3993076682090759} | train loss {'Reaction outcome loss': 0.19012384203328428, 'Total loss': 0.19012384203328428}
2022-12-31 04:29:31,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:31,267 INFO:     Epoch: 22
2022-12-31 04:29:32,891 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38565379778544107, 'Total loss': 0.38565379778544107} | train loss {'Reaction outcome loss': 0.18353776395509858, 'Total loss': 0.18353776395509858}
2022-12-31 04:29:32,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:32,892 INFO:     Epoch: 23
2022-12-31 04:29:34,514 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3459605264166991, 'Total loss': 0.3459605264166991} | train loss {'Reaction outcome loss': 0.1830765901287795, 'Total loss': 0.1830765901287795}
2022-12-31 04:29:34,515 INFO:     Found new best model at epoch 23
2022-12-31 04:29:34,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:34,516 INFO:     Epoch: 24
2022-12-31 04:29:36,131 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40863746603329976, 'Total loss': 0.40863746603329976} | train loss {'Reaction outcome loss': 0.18067928302532865, 'Total loss': 0.18067928302532865}
2022-12-31 04:29:36,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:36,131 INFO:     Epoch: 25
2022-12-31 04:29:37,754 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.38774227499961855, 'Total loss': 0.38774227499961855} | train loss {'Reaction outcome loss': 0.17797844218886524, 'Total loss': 0.17797844218886524}
2022-12-31 04:29:37,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:37,754 INFO:     Epoch: 26
2022-12-31 04:29:39,366 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4176495830217997, 'Total loss': 0.4176495830217997} | train loss {'Reaction outcome loss': 0.20185826236611584, 'Total loss': 0.20185826236611584}
2022-12-31 04:29:39,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:39,366 INFO:     Epoch: 27
2022-12-31 04:29:40,990 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3881040088832378, 'Total loss': 0.3881040088832378} | train loss {'Reaction outcome loss': 0.17793135601812907, 'Total loss': 0.17793135601812907}
2022-12-31 04:29:40,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:40,990 INFO:     Epoch: 28
2022-12-31 04:29:42,612 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40213151449958484, 'Total loss': 0.40213151449958484} | train loss {'Reaction outcome loss': 0.16773962610370843, 'Total loss': 0.16773962610370843}
2022-12-31 04:29:42,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:42,612 INFO:     Epoch: 29
2022-12-31 04:29:44,230 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4036651194095612, 'Total loss': 0.4036651194095612} | train loss {'Reaction outcome loss': 0.16604202791495482, 'Total loss': 0.16604202791495482}
2022-12-31 04:29:44,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:44,231 INFO:     Epoch: 30
2022-12-31 04:29:45,842 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40214235832293826, 'Total loss': 0.40214235832293826} | train loss {'Reaction outcome loss': 0.15978332565915163, 'Total loss': 0.15978332565915163}
2022-12-31 04:29:45,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:45,843 INFO:     Epoch: 31
2022-12-31 04:29:47,461 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40205853879451753, 'Total loss': 0.40205853879451753} | train loss {'Reaction outcome loss': 0.1597521932176871, 'Total loss': 0.1597521932176871}
2022-12-31 04:29:47,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:47,461 INFO:     Epoch: 32
2022-12-31 04:29:49,069 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39038949509461723, 'Total loss': 0.39038949509461723} | train loss {'Reaction outcome loss': 0.15665443428873044, 'Total loss': 0.15665443428873044}
2022-12-31 04:29:49,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:49,070 INFO:     Epoch: 33
2022-12-31 04:29:50,729 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3992174526055654, 'Total loss': 0.3992174526055654} | train loss {'Reaction outcome loss': 0.15840600923220863, 'Total loss': 0.15840600923220863}
2022-12-31 04:29:50,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:50,729 INFO:     Epoch: 34
2022-12-31 04:29:52,388 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3896846186990539, 'Total loss': 0.3896846186990539} | train loss {'Reaction outcome loss': 0.1526959906559964, 'Total loss': 0.1526959906559964}
2022-12-31 04:29:52,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:52,388 INFO:     Epoch: 35
2022-12-31 04:29:54,013 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4224599818388621, 'Total loss': 0.4224599818388621} | train loss {'Reaction outcome loss': 0.15161772501449086, 'Total loss': 0.15161772501449086}
2022-12-31 04:29:54,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:54,014 INFO:     Epoch: 36
2022-12-31 04:29:55,673 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39166912039120994, 'Total loss': 0.39166912039120994} | train loss {'Reaction outcome loss': 0.15307468662196197, 'Total loss': 0.15307468662196197}
2022-12-31 04:29:55,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:55,673 INFO:     Epoch: 37
2022-12-31 04:29:57,285 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3786772474646568, 'Total loss': 0.3786772474646568} | train loss {'Reaction outcome loss': 0.14860999486172924, 'Total loss': 0.14860999486172924}
2022-12-31 04:29:57,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:57,286 INFO:     Epoch: 38
2022-12-31 04:29:58,945 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43255794743696846, 'Total loss': 0.43255794743696846} | train loss {'Reaction outcome loss': 0.14938959480006841, 'Total loss': 0.14938959480006841}
2022-12-31 04:29:58,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:29:58,945 INFO:     Epoch: 39
2022-12-31 04:30:00,557 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4116693317890167, 'Total loss': 0.4116693317890167} | train loss {'Reaction outcome loss': 0.14699470567285206, 'Total loss': 0.14699470567285206}
2022-12-31 04:30:00,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:00,559 INFO:     Epoch: 40
2022-12-31 04:30:02,175 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44919566412766776, 'Total loss': 0.44919566412766776} | train loss {'Reaction outcome loss': 0.14495753623929847, 'Total loss': 0.14495753623929847}
2022-12-31 04:30:02,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:02,175 INFO:     Epoch: 41
2022-12-31 04:30:03,819 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3925935347874959, 'Total loss': 0.3925935347874959} | train loss {'Reaction outcome loss': 0.1425724475309413, 'Total loss': 0.1425724475309413}
2022-12-31 04:30:03,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:03,820 INFO:     Epoch: 42
2022-12-31 04:30:05,465 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41131622989972433, 'Total loss': 0.41131622989972433} | train loss {'Reaction outcome loss': 0.14341050068901826, 'Total loss': 0.14341050068901826}
2022-12-31 04:30:05,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:05,465 INFO:     Epoch: 43
2022-12-31 04:30:07,070 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4519840881228447, 'Total loss': 0.4519840881228447} | train loss {'Reaction outcome loss': 0.14236453728770596, 'Total loss': 0.14236453728770596}
2022-12-31 04:30:07,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:07,071 INFO:     Epoch: 44
2022-12-31 04:30:08,681 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41779758234818776, 'Total loss': 0.41779758234818776} | train loss {'Reaction outcome loss': 0.13993072671745313, 'Total loss': 0.13993072671745313}
2022-12-31 04:30:08,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:08,681 INFO:     Epoch: 45
2022-12-31 04:30:10,297 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4063967893520991, 'Total loss': 0.4063967893520991} | train loss {'Reaction outcome loss': 0.14333890415628706, 'Total loss': 0.14333890415628706}
2022-12-31 04:30:10,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:10,297 INFO:     Epoch: 46
2022-12-31 04:30:11,911 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4047918111085892, 'Total loss': 0.4047918111085892} | train loss {'Reaction outcome loss': 0.13790644099261018, 'Total loss': 0.13790644099261018}
2022-12-31 04:30:11,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:11,911 INFO:     Epoch: 47
2022-12-31 04:30:13,531 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43805634379386904, 'Total loss': 0.43805634379386904} | train loss {'Reaction outcome loss': 0.13746293270199111, 'Total loss': 0.13746293270199111}
2022-12-31 04:30:13,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:13,531 INFO:     Epoch: 48
2022-12-31 04:30:15,076 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43780367374420165, 'Total loss': 0.43780367374420165} | train loss {'Reaction outcome loss': 0.13845089090434645, 'Total loss': 0.13845089090434645}
2022-12-31 04:30:15,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:15,077 INFO:     Epoch: 49
2022-12-31 04:30:16,195 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4186179652810097, 'Total loss': 0.4186179652810097} | train loss {'Reaction outcome loss': 0.13425925225359, 'Total loss': 0.13425925225359}
2022-12-31 04:30:16,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:16,195 INFO:     Epoch: 50
2022-12-31 04:30:17,308 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45335169235865275, 'Total loss': 0.45335169235865275} | train loss {'Reaction outcome loss': 0.13197665725686197, 'Total loss': 0.13197665725686197}
2022-12-31 04:30:17,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:17,309 INFO:     Epoch: 51
2022-12-31 04:30:18,421 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4314354509115219, 'Total loss': 0.4314354509115219} | train loss {'Reaction outcome loss': 0.1379681102040669, 'Total loss': 0.1379681102040669}
2022-12-31 04:30:18,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:18,421 INFO:     Epoch: 52
2022-12-31 04:30:19,679 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4341699327031771, 'Total loss': 0.4341699327031771} | train loss {'Reaction outcome loss': 0.14436003246774434, 'Total loss': 0.14436003246774434}
2022-12-31 04:30:19,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:19,680 INFO:     Epoch: 53
2022-12-31 04:30:21,292 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4366195340951284, 'Total loss': 0.4366195340951284} | train loss {'Reaction outcome loss': 0.1322325999389632, 'Total loss': 0.1322325999389632}
2022-12-31 04:30:21,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:21,292 INFO:     Epoch: 54
2022-12-31 04:30:22,904 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4234197407960892, 'Total loss': 0.4234197407960892} | train loss {'Reaction outcome loss': 0.12976199162675175, 'Total loss': 0.12976199162675175}
2022-12-31 04:30:22,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:22,905 INFO:     Epoch: 55
2022-12-31 04:30:24,550 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4301048109928767, 'Total loss': 0.4301048109928767} | train loss {'Reaction outcome loss': 0.1260950462542562, 'Total loss': 0.1260950462542562}
2022-12-31 04:30:24,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:24,550 INFO:     Epoch: 56
2022-12-31 04:30:26,165 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4368141045173009, 'Total loss': 0.4368141045173009} | train loss {'Reaction outcome loss': 0.13109635154588445, 'Total loss': 0.13109635154588445}
2022-12-31 04:30:26,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:26,165 INFO:     Epoch: 57
2022-12-31 04:30:27,778 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4230737538387378, 'Total loss': 0.4230737538387378} | train loss {'Reaction outcome loss': 0.13357836820722552, 'Total loss': 0.13357836820722552}
2022-12-31 04:30:27,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:27,778 INFO:     Epoch: 58
2022-12-31 04:30:29,411 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4309082238624493, 'Total loss': 0.4309082238624493} | train loss {'Reaction outcome loss': 0.12664434672468275, 'Total loss': 0.12664434672468275}
2022-12-31 04:30:29,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:29,411 INFO:     Epoch: 59
2022-12-31 04:30:31,023 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4278585399190585, 'Total loss': 0.4278585399190585} | train loss {'Reaction outcome loss': 0.12957292591306832, 'Total loss': 0.12957292591306832}
2022-12-31 04:30:31,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:31,023 INFO:     Epoch: 60
2022-12-31 04:30:32,687 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4290010472138723, 'Total loss': 0.4290010472138723} | train loss {'Reaction outcome loss': 0.1265324476694661, 'Total loss': 0.1265324476694661}
2022-12-31 04:30:32,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:32,687 INFO:     Epoch: 61
2022-12-31 04:30:34,304 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41563889185587566, 'Total loss': 0.41563889185587566} | train loss {'Reaction outcome loss': 0.12573473393519857, 'Total loss': 0.12573473393519857}
2022-12-31 04:30:34,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:34,304 INFO:     Epoch: 62
2022-12-31 04:30:35,970 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4314157783985138, 'Total loss': 0.4314157783985138} | train loss {'Reaction outcome loss': 0.12330170123385724, 'Total loss': 0.12330170123385724}
2022-12-31 04:30:35,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:35,971 INFO:     Epoch: 63
2022-12-31 04:30:37,586 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4263605535030365, 'Total loss': 0.4263605535030365} | train loss {'Reaction outcome loss': 0.12342264839073482, 'Total loss': 0.12342264839073482}
2022-12-31 04:30:37,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:37,588 INFO:     Epoch: 64
2022-12-31 04:30:39,243 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42458523412545524, 'Total loss': 0.42458523412545524} | train loss {'Reaction outcome loss': 0.12179839187234208, 'Total loss': 0.12179839187234208}
2022-12-31 04:30:39,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:39,243 INFO:     Epoch: 65
2022-12-31 04:30:40,863 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4132265031337738, 'Total loss': 0.4132265031337738} | train loss {'Reaction outcome loss': 0.12249779544694372, 'Total loss': 0.12249779544694372}
2022-12-31 04:30:40,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:40,863 INFO:     Epoch: 66
2022-12-31 04:30:42,527 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4364911139011383, 'Total loss': 0.4364911139011383} | train loss {'Reaction outcome loss': 0.12759698548799622, 'Total loss': 0.12759698548799622}
2022-12-31 04:30:42,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:42,528 INFO:     Epoch: 67
2022-12-31 04:30:44,166 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4368400514125824, 'Total loss': 0.4368400514125824} | train loss {'Reaction outcome loss': 0.12725628987470333, 'Total loss': 0.12725628987470333}
2022-12-31 04:30:44,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:44,167 INFO:     Epoch: 68
2022-12-31 04:30:45,780 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43891529043515526, 'Total loss': 0.43891529043515526} | train loss {'Reaction outcome loss': 0.12285352764731702, 'Total loss': 0.12285352764731702}
2022-12-31 04:30:45,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:45,780 INFO:     Epoch: 69
2022-12-31 04:30:47,399 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4395816067854563, 'Total loss': 0.4395816067854563} | train loss {'Reaction outcome loss': 0.12243940388240541, 'Total loss': 0.12243940388240541}
2022-12-31 04:30:47,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:47,399 INFO:     Epoch: 70
2022-12-31 04:30:49,015 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4591094712416331, 'Total loss': 0.4591094712416331} | train loss {'Reaction outcome loss': 0.12102824092110404, 'Total loss': 0.12102824092110404}
2022-12-31 04:30:49,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:49,016 INFO:     Epoch: 71
2022-12-31 04:30:50,636 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44667967905600864, 'Total loss': 0.44667967905600864} | train loss {'Reaction outcome loss': 0.12430378798402987, 'Total loss': 0.12430378798402987}
2022-12-31 04:30:50,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:50,636 INFO:     Epoch: 72
2022-12-31 04:30:52,253 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44619856278101605, 'Total loss': 0.44619856278101605} | train loss {'Reaction outcome loss': 0.11991375937973119, 'Total loss': 0.11991375937973119}
2022-12-31 04:30:52,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:52,253 INFO:     Epoch: 73
2022-12-31 04:30:53,868 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4558142552773158, 'Total loss': 0.4558142552773158} | train loss {'Reaction outcome loss': 0.12006795526974821, 'Total loss': 0.12006795526974821}
2022-12-31 04:30:53,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:53,868 INFO:     Epoch: 74
2022-12-31 04:30:55,481 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44167017738024394, 'Total loss': 0.44167017738024394} | train loss {'Reaction outcome loss': 0.11515836859083113, 'Total loss': 0.11515836859083113}
2022-12-31 04:30:55,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:55,481 INFO:     Epoch: 75
2022-12-31 04:30:57,095 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42829313278198244, 'Total loss': 0.42829313278198244} | train loss {'Reaction outcome loss': 0.11909414174948799, 'Total loss': 0.11909414174948799}
2022-12-31 04:30:57,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:57,096 INFO:     Epoch: 76
2022-12-31 04:30:58,727 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4387852162122726, 'Total loss': 0.4387852162122726} | train loss {'Reaction outcome loss': 0.1382266358519648, 'Total loss': 0.1382266358519648}
2022-12-31 04:30:58,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:30:58,727 INFO:     Epoch: 77
2022-12-31 04:31:00,360 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4313225671648979, 'Total loss': 0.4313225671648979} | train loss {'Reaction outcome loss': 0.12147641333290991, 'Total loss': 0.12147641333290991}
2022-12-31 04:31:00,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:00,360 INFO:     Epoch: 78
2022-12-31 04:31:01,994 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44840926229953765, 'Total loss': 0.44840926229953765} | train loss {'Reaction outcome loss': 0.11743120245122607, 'Total loss': 0.11743120245122607}
2022-12-31 04:31:01,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:01,994 INFO:     Epoch: 79
2022-12-31 04:31:03,627 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4034808337688446, 'Total loss': 0.4034808337688446} | train loss {'Reaction outcome loss': 0.11938978780744947, 'Total loss': 0.11938978780744947}
2022-12-31 04:31:03,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:03,627 INFO:     Epoch: 80
2022-12-31 04:31:05,237 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4628759096066157, 'Total loss': 0.4628759096066157} | train loss {'Reaction outcome loss': 0.11833469347899703, 'Total loss': 0.11833469347899703}
2022-12-31 04:31:05,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:05,238 INFO:     Epoch: 81
2022-12-31 04:31:06,901 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47512983083724974, 'Total loss': 0.47512983083724974} | train loss {'Reaction outcome loss': 0.1175131804589857, 'Total loss': 0.1175131804589857}
2022-12-31 04:31:06,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:06,901 INFO:     Epoch: 82
2022-12-31 04:31:08,520 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45261536485825976, 'Total loss': 0.45261536485825976} | train loss {'Reaction outcome loss': 0.1297366067453328, 'Total loss': 0.1297366067453328}
2022-12-31 04:31:08,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:08,520 INFO:     Epoch: 83
2022-12-31 04:31:10,138 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47667996982733407, 'Total loss': 0.47667996982733407} | train loss {'Reaction outcome loss': 0.12680283399885925, 'Total loss': 0.12680283399885925}
2022-12-31 04:31:10,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:10,138 INFO:     Epoch: 84
2022-12-31 04:31:11,803 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4343653211990992, 'Total loss': 0.4343653211990992} | train loss {'Reaction outcome loss': 0.12767785706513468, 'Total loss': 0.12767785706513468}
2022-12-31 04:31:11,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:11,803 INFO:     Epoch: 85
2022-12-31 04:31:13,421 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4521209488312403, 'Total loss': 0.4521209488312403} | train loss {'Reaction outcome loss': 0.11167872204279537, 'Total loss': 0.11167872204279537}
2022-12-31 04:31:13,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:13,422 INFO:     Epoch: 86
2022-12-31 04:31:15,052 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4349538264175256, 'Total loss': 0.4349538264175256} | train loss {'Reaction outcome loss': 0.11312545849131825, 'Total loss': 0.11312545849131825}
2022-12-31 04:31:15,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:15,052 INFO:     Epoch: 87
2022-12-31 04:31:16,687 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4410973856846491, 'Total loss': 0.4410973856846491} | train loss {'Reaction outcome loss': 0.11509044589373567, 'Total loss': 0.11509044589373567}
2022-12-31 04:31:16,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:16,687 INFO:     Epoch: 88
2022-12-31 04:31:18,316 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46318103075027467, 'Total loss': 0.46318103075027467} | train loss {'Reaction outcome loss': 0.11169345051672755, 'Total loss': 0.11169345051672755}
2022-12-31 04:31:18,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:18,316 INFO:     Epoch: 89
2022-12-31 04:31:19,949 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43590987225373584, 'Total loss': 0.43590987225373584} | train loss {'Reaction outcome loss': 0.11536976095015669, 'Total loss': 0.11536976095015669}
2022-12-31 04:31:19,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:19,950 INFO:     Epoch: 90
2022-12-31 04:31:21,582 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44019891768693925, 'Total loss': 0.44019891768693925} | train loss {'Reaction outcome loss': 0.11002390013596015, 'Total loss': 0.11002390013596015}
2022-12-31 04:31:21,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:21,582 INFO:     Epoch: 91
2022-12-31 04:31:23,204 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44770456751187643, 'Total loss': 0.44770456751187643} | train loss {'Reaction outcome loss': 0.11360254873887282, 'Total loss': 0.11360254873887282}
2022-12-31 04:31:23,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:23,204 INFO:     Epoch: 92
2022-12-31 04:31:24,812 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43624360660711925, 'Total loss': 0.43624360660711925} | train loss {'Reaction outcome loss': 0.11585816008754182, 'Total loss': 0.11585816008754182}
2022-12-31 04:31:24,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:24,812 INFO:     Epoch: 93
2022-12-31 04:31:26,473 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4614974558353424, 'Total loss': 0.4614974558353424} | train loss {'Reaction outcome loss': 0.11618863809828485, 'Total loss': 0.11618863809828485}
2022-12-31 04:31:26,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:26,473 INFO:     Epoch: 94
2022-12-31 04:31:28,089 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4476897728939851, 'Total loss': 0.4476897728939851} | train loss {'Reaction outcome loss': 0.11293964971538525, 'Total loss': 0.11293964971538525}
2022-12-31 04:31:28,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:28,089 INFO:     Epoch: 95
2022-12-31 04:31:29,749 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4482395023107529, 'Total loss': 0.4482395023107529} | train loss {'Reaction outcome loss': 0.12241614279607176, 'Total loss': 0.12241614279607176}
2022-12-31 04:31:29,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:29,749 INFO:     Epoch: 96
2022-12-31 04:31:31,372 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4397503465414047, 'Total loss': 0.4397503465414047} | train loss {'Reaction outcome loss': 0.11931562799166558, 'Total loss': 0.11931562799166558}
2022-12-31 04:31:31,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:31,372 INFO:     Epoch: 97
2022-12-31 04:31:32,990 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42910517007112503, 'Total loss': 0.42910517007112503} | train loss {'Reaction outcome loss': 0.11416318031885, 'Total loss': 0.11416318031885}
2022-12-31 04:31:32,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:32,991 INFO:     Epoch: 98
2022-12-31 04:31:34,631 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4206799546877543, 'Total loss': 0.4206799546877543} | train loss {'Reaction outcome loss': 0.11435481762020862, 'Total loss': 0.11435481762020862}
2022-12-31 04:31:34,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:34,631 INFO:     Epoch: 99
2022-12-31 04:31:36,253 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44148374696572623, 'Total loss': 0.44148374696572623} | train loss {'Reaction outcome loss': 0.11329396306731117, 'Total loss': 0.11329396306731117}
2022-12-31 04:31:36,253 INFO:     Best model found after epoch 24 of 100.
2022-12-31 04:31:36,253 INFO:   Done with stage: TRAINING
2022-12-31 04:31:36,254 INFO:   Starting stage: EVALUATION
2022-12-31 04:31:36,383 INFO:   Done with stage: EVALUATION
2022-12-31 04:31:36,392 INFO:   Leaving out SEQ value Fold_0
2022-12-31 04:31:36,405 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 04:31:36,405 INFO:   Starting stage: FEATURE SCALING
2022-12-31 04:31:37,047 INFO:   Done with stage: FEATURE SCALING
2022-12-31 04:31:37,047 INFO:   Starting stage: SCALING TARGETS
2022-12-31 04:31:37,119 INFO:   Done with stage: SCALING TARGETS
2022-12-31 04:31:37,119 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:31:37,120 INFO:     No hyperparam tuning for this model
2022-12-31 04:31:37,120 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:31:37,120 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 04:31:37,120 INFO:     None feature selector for col prot
2022-12-31 04:31:37,120 INFO:     None feature selector for col prot
2022-12-31 04:31:37,121 INFO:     None feature selector for col prot
2022-12-31 04:31:37,121 INFO:     None feature selector for col chem
2022-12-31 04:31:37,121 INFO:     None feature selector for col chem
2022-12-31 04:31:37,121 INFO:     None feature selector for col chem
2022-12-31 04:31:37,121 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 04:31:37,121 INFO:   Starting stage: BUILD MODEL
2022-12-31 04:31:37,123 INFO:     Number of params in model 224011
2022-12-31 04:31:37,126 INFO:   Done with stage: BUILD MODEL
2022-12-31 04:31:37,126 INFO:   Starting stage: TRAINING
2022-12-31 04:31:37,172 INFO:     Val loss before train {'Reaction outcome loss': 1.0465144236882529, 'Total loss': 1.0465144236882529}
2022-12-31 04:31:37,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:37,172 INFO:     Epoch: 0
2022-12-31 04:31:38,779 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6236227333545685, 'Total loss': 0.6236227333545685} | train loss {'Reaction outcome loss': 0.7948488119278487, 'Total loss': 0.7948488119278487}
2022-12-31 04:31:38,779 INFO:     Found new best model at epoch 0
2022-12-31 04:31:38,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:38,780 INFO:     Epoch: 1
2022-12-31 04:31:40,389 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5071237812439601, 'Total loss': 0.5071237812439601} | train loss {'Reaction outcome loss': 0.519778980239146, 'Total loss': 0.519778980239146}
2022-12-31 04:31:40,389 INFO:     Found new best model at epoch 1
2022-12-31 04:31:40,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:40,390 INFO:     Epoch: 2
2022-12-31 04:31:41,999 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4760233958562215, 'Total loss': 0.4760233958562215} | train loss {'Reaction outcome loss': 0.4451806585209957, 'Total loss': 0.4451806585209957}
2022-12-31 04:31:41,999 INFO:     Found new best model at epoch 2
2022-12-31 04:31:42,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:42,000 INFO:     Epoch: 3
2022-12-31 04:31:43,616 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46859486897786456, 'Total loss': 0.46859486897786456} | train loss {'Reaction outcome loss': 0.4039074493018721, 'Total loss': 0.4039074493018721}
2022-12-31 04:31:43,616 INFO:     Found new best model at epoch 3
2022-12-31 04:31:43,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:43,617 INFO:     Epoch: 4
2022-12-31 04:31:45,230 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4554428865512212, 'Total loss': 0.4554428865512212} | train loss {'Reaction outcome loss': 0.3758129496768495, 'Total loss': 0.3758129496768495}
2022-12-31 04:31:45,230 INFO:     Found new best model at epoch 4
2022-12-31 04:31:45,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:45,231 INFO:     Epoch: 5
2022-12-31 04:31:46,850 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4198139697313309, 'Total loss': 0.4198139697313309} | train loss {'Reaction outcome loss': 0.35066337767394556, 'Total loss': 0.35066337767394556}
2022-12-31 04:31:46,850 INFO:     Found new best model at epoch 5
2022-12-31 04:31:46,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:46,851 INFO:     Epoch: 6
2022-12-31 04:31:48,471 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3964255526661873, 'Total loss': 0.3964255526661873} | train loss {'Reaction outcome loss': 0.3305383130791597, 'Total loss': 0.3305383130791597}
2022-12-31 04:31:48,472 INFO:     Found new best model at epoch 6
2022-12-31 04:31:48,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:48,473 INFO:     Epoch: 7
2022-12-31 04:31:50,114 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45874313910802206, 'Total loss': 0.45874313910802206} | train loss {'Reaction outcome loss': 0.31663375690687395, 'Total loss': 0.31663375690687395}
2022-12-31 04:31:50,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:50,114 INFO:     Epoch: 8
2022-12-31 04:31:51,731 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4303374022245407, 'Total loss': 0.4303374022245407} | train loss {'Reaction outcome loss': 0.31355010040053877, 'Total loss': 0.31355010040053877}
2022-12-31 04:31:51,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:51,732 INFO:     Epoch: 9
2022-12-31 04:31:53,392 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43106546302636467, 'Total loss': 0.43106546302636467} | train loss {'Reaction outcome loss': 0.28022113134848303, 'Total loss': 0.28022113134848303}
2022-12-31 04:31:53,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:53,392 INFO:     Epoch: 10
2022-12-31 04:31:55,054 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.431473804016908, 'Total loss': 0.431473804016908} | train loss {'Reaction outcome loss': 0.26949578530384577, 'Total loss': 0.26949578530384577}
2022-12-31 04:31:55,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:55,055 INFO:     Epoch: 11
2022-12-31 04:31:56,674 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4333159257968267, 'Total loss': 0.4333159257968267} | train loss {'Reaction outcome loss': 0.281511336085859, 'Total loss': 0.281511336085859}
2022-12-31 04:31:56,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:56,674 INFO:     Epoch: 12
2022-12-31 04:31:58,335 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4195373257001241, 'Total loss': 0.4195373257001241} | train loss {'Reaction outcome loss': 0.25435092306292645, 'Total loss': 0.25435092306292645}
2022-12-31 04:31:58,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:58,335 INFO:     Epoch: 13
2022-12-31 04:31:59,972 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4276803692181905, 'Total loss': 0.4276803692181905} | train loss {'Reaction outcome loss': 0.24061924923697245, 'Total loss': 0.24061924923697245}
2022-12-31 04:31:59,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:31:59,972 INFO:     Epoch: 14
2022-12-31 04:32:01,636 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4511602133512497, 'Total loss': 0.4511602133512497} | train loss {'Reaction outcome loss': 0.2743948360743082, 'Total loss': 0.2743948360743082}
2022-12-31 04:32:01,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:01,636 INFO:     Epoch: 15
2022-12-31 04:32:03,259 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4288911739985148, 'Total loss': 0.4288911739985148} | train loss {'Reaction outcome loss': 0.25588686032004765, 'Total loss': 0.25588686032004765}
2022-12-31 04:32:03,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:03,259 INFO:     Epoch: 16
2022-12-31 04:32:04,883 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.422511367003123, 'Total loss': 0.422511367003123} | train loss {'Reaction outcome loss': 0.2243980414274594, 'Total loss': 0.2243980414274594}
2022-12-31 04:32:04,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:04,883 INFO:     Epoch: 17
2022-12-31 04:32:06,548 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41384476820627847, 'Total loss': 0.41384476820627847} | train loss {'Reaction outcome loss': 0.21670071188144494, 'Total loss': 0.21670071188144494}
2022-12-31 04:32:06,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:06,548 INFO:     Epoch: 18
2022-12-31 04:32:08,202 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4108229170242945, 'Total loss': 0.4108229170242945} | train loss {'Reaction outcome loss': 0.21277251212829826, 'Total loss': 0.21277251212829826}
2022-12-31 04:32:08,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:08,202 INFO:     Epoch: 19
2022-12-31 04:32:09,828 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42635197242101036, 'Total loss': 0.42635197242101036} | train loss {'Reaction outcome loss': 0.20820606249195617, 'Total loss': 0.20820606249195617}
2022-12-31 04:32:09,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:09,828 INFO:     Epoch: 20
2022-12-31 04:32:11,452 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4544832249482473, 'Total loss': 0.4544832249482473} | train loss {'Reaction outcome loss': 0.2015889406727671, 'Total loss': 0.2015889406727671}
2022-12-31 04:32:11,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:11,452 INFO:     Epoch: 21
2022-12-31 04:32:13,114 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4179113005598386, 'Total loss': 0.4179113005598386} | train loss {'Reaction outcome loss': 0.19772543240838603, 'Total loss': 0.19772543240838603}
2022-12-31 04:32:13,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:13,114 INFO:     Epoch: 22
2022-12-31 04:32:14,733 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41275963286558787, 'Total loss': 0.41275963286558787} | train loss {'Reaction outcome loss': 0.19320478538672128, 'Total loss': 0.19320478538672128}
2022-12-31 04:32:14,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:14,733 INFO:     Epoch: 23
2022-12-31 04:32:16,395 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4443233211835225, 'Total loss': 0.4443233211835225} | train loss {'Reaction outcome loss': 0.18934707481083393, 'Total loss': 0.18934707481083393}
2022-12-31 04:32:16,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:16,395 INFO:     Epoch: 24
2022-12-31 04:32:18,018 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4492201934258143, 'Total loss': 0.4492201934258143} | train loss {'Reaction outcome loss': 0.18424801155081208, 'Total loss': 0.18424801155081208}
2022-12-31 04:32:18,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:18,018 INFO:     Epoch: 25
2022-12-31 04:32:19,652 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4312660127878189, 'Total loss': 0.4312660127878189} | train loss {'Reaction outcome loss': 0.1862275660496907, 'Total loss': 0.1862275660496907}
2022-12-31 04:32:19,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:19,653 INFO:     Epoch: 26
2022-12-31 04:32:21,288 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42877773741881053, 'Total loss': 0.42877773741881053} | train loss {'Reaction outcome loss': 0.1912535035955733, 'Total loss': 0.1912535035955733}
2022-12-31 04:32:21,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:21,289 INFO:     Epoch: 27
2022-12-31 04:32:22,923 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45411550601323447, 'Total loss': 0.45411550601323447} | train loss {'Reaction outcome loss': 0.19116223885414554, 'Total loss': 0.19116223885414554}
2022-12-31 04:32:22,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:22,923 INFO:     Epoch: 28
2022-12-31 04:32:24,558 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44165550072987875, 'Total loss': 0.44165550072987875} | train loss {'Reaction outcome loss': 0.17719524372301565, 'Total loss': 0.17719524372301565}
2022-12-31 04:32:24,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:24,559 INFO:     Epoch: 29
2022-12-31 04:32:26,192 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43517351349194844, 'Total loss': 0.43517351349194844} | train loss {'Reaction outcome loss': 0.16897323355078697, 'Total loss': 0.16897323355078697}
2022-12-31 04:32:26,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:26,193 INFO:     Epoch: 30
2022-12-31 04:32:27,804 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43054690957069397, 'Total loss': 0.43054690957069397} | train loss {'Reaction outcome loss': 0.16859078420806117, 'Total loss': 0.16859078420806117}
2022-12-31 04:32:27,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:27,805 INFO:     Epoch: 31
2022-12-31 04:32:29,428 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4347332383195559, 'Total loss': 0.4347332383195559} | train loss {'Reaction outcome loss': 0.16083051526304876, 'Total loss': 0.16083051526304876}
2022-12-31 04:32:29,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:29,428 INFO:     Epoch: 32
2022-12-31 04:32:31,053 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4252877990404765, 'Total loss': 0.4252877990404765} | train loss {'Reaction outcome loss': 0.16235709196105058, 'Total loss': 0.16235709196105058}
2022-12-31 04:32:31,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:31,053 INFO:     Epoch: 33
2022-12-31 04:32:32,675 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.453520334760348, 'Total loss': 0.453520334760348} | train loss {'Reaction outcome loss': 0.15807339444459564, 'Total loss': 0.15807339444459564}
2022-12-31 04:32:32,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:32,675 INFO:     Epoch: 34
2022-12-31 04:32:34,298 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41030319084723793, 'Total loss': 0.41030319084723793} | train loss {'Reaction outcome loss': 0.1584650830136261, 'Total loss': 0.1584650830136261}
2022-12-31 04:32:34,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:34,299 INFO:     Epoch: 35
2022-12-31 04:32:35,913 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44872606694698336, 'Total loss': 0.44872606694698336} | train loss {'Reaction outcome loss': 0.15475370826375118, 'Total loss': 0.15475370826375118}
2022-12-31 04:32:35,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:35,913 INFO:     Epoch: 36
2022-12-31 04:32:37,527 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41401185022356607, 'Total loss': 0.41401185022356607} | train loss {'Reaction outcome loss': 0.15712915160532948, 'Total loss': 0.15712915160532948}
2022-12-31 04:32:37,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:37,527 INFO:     Epoch: 37
2022-12-31 04:32:39,188 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4356470654408137, 'Total loss': 0.4356470654408137} | train loss {'Reaction outcome loss': 0.15566439640700253, 'Total loss': 0.15566439640700253}
2022-12-31 04:32:39,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:39,188 INFO:     Epoch: 38
2022-12-31 04:32:40,808 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4338507731755575, 'Total loss': 0.4338507731755575} | train loss {'Reaction outcome loss': 0.14829898419544485, 'Total loss': 0.14829898419544485}
2022-12-31 04:32:40,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:40,808 INFO:     Epoch: 39
2022-12-31 04:32:42,468 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4606482336918513, 'Total loss': 0.4606482336918513} | train loss {'Reaction outcome loss': 0.14693207812218834, 'Total loss': 0.14693207812218834}
2022-12-31 04:32:42,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:42,469 INFO:     Epoch: 40
2022-12-31 04:32:44,129 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4374680668115616, 'Total loss': 0.4374680668115616} | train loss {'Reaction outcome loss': 0.1460205091573606, 'Total loss': 0.1460205091573606}
2022-12-31 04:32:44,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:44,129 INFO:     Epoch: 41
2022-12-31 04:32:45,751 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44868489106496173, 'Total loss': 0.44868489106496173} | train loss {'Reaction outcome loss': 0.14456230039713377, 'Total loss': 0.14456230039713377}
2022-12-31 04:32:45,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:45,752 INFO:     Epoch: 42
2022-12-31 04:32:47,412 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4451291481653849, 'Total loss': 0.4451291481653849} | train loss {'Reaction outcome loss': 0.1431972027213846, 'Total loss': 0.1431972027213846}
2022-12-31 04:32:47,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:47,412 INFO:     Epoch: 43
2022-12-31 04:32:49,073 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43186052987972895, 'Total loss': 0.43186052987972895} | train loss {'Reaction outcome loss': 0.1415386417145361, 'Total loss': 0.1415386417145361}
2022-12-31 04:32:49,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:49,073 INFO:     Epoch: 44
2022-12-31 04:32:50,734 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4222189386685689, 'Total loss': 0.4222189386685689} | train loss {'Reaction outcome loss': 0.14277072905763594, 'Total loss': 0.14277072905763594}
2022-12-31 04:32:50,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:50,735 INFO:     Epoch: 45
2022-12-31 04:32:52,352 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44826531906922656, 'Total loss': 0.44826531906922656} | train loss {'Reaction outcome loss': 0.14192411389446033, 'Total loss': 0.14192411389446033}
2022-12-31 04:32:52,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:52,352 INFO:     Epoch: 46
2022-12-31 04:32:53,995 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42631238301595054, 'Total loss': 0.42631238301595054} | train loss {'Reaction outcome loss': 0.13997891748953986, 'Total loss': 0.13997891748953986}
2022-12-31 04:32:53,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:53,995 INFO:     Epoch: 47
2022-12-31 04:32:55,638 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4575549602508545, 'Total loss': 0.4575549602508545} | train loss {'Reaction outcome loss': 0.1369090003515695, 'Total loss': 0.1369090003515695}
2022-12-31 04:32:55,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:55,640 INFO:     Epoch: 48
2022-12-31 04:32:57,248 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4043749796847502, 'Total loss': 0.4043749796847502} | train loss {'Reaction outcome loss': 0.1315088706560082, 'Total loss': 0.1315088706560082}
2022-12-31 04:32:57,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:57,248 INFO:     Epoch: 49
2022-12-31 04:32:58,908 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44857978224754336, 'Total loss': 0.44857978224754336} | train loss {'Reaction outcome loss': 0.13649876926860272, 'Total loss': 0.13649876926860272}
2022-12-31 04:32:58,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:32:58,908 INFO:     Epoch: 50
2022-12-31 04:33:00,525 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40303939282894136, 'Total loss': 0.40303939282894136} | train loss {'Reaction outcome loss': 0.13500974268633095, 'Total loss': 0.13500974268633095}
2022-12-31 04:33:00,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:00,525 INFO:     Epoch: 51
2022-12-31 04:33:02,186 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47142200569311776, 'Total loss': 0.47142200569311776} | train loss {'Reaction outcome loss': 0.13101345469434475, 'Total loss': 0.13101345469434475}
2022-12-31 04:33:02,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:02,186 INFO:     Epoch: 52
2022-12-31 04:33:03,802 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4120660021901131, 'Total loss': 0.4120660021901131} | train loss {'Reaction outcome loss': 0.13131388210593656, 'Total loss': 0.13131388210593656}
2022-12-31 04:33:03,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:03,802 INFO:     Epoch: 53
2022-12-31 04:33:05,437 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4576855351527532, 'Total loss': 0.4576855351527532} | train loss {'Reaction outcome loss': 0.13022411997477268, 'Total loss': 0.13022411997477268}
2022-12-31 04:33:05,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:05,437 INFO:     Epoch: 54
2022-12-31 04:33:07,070 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4394221305847168, 'Total loss': 0.4394221305847168} | train loss {'Reaction outcome loss': 0.13329368527722207, 'Total loss': 0.13329368527722207}
2022-12-31 04:33:07,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:07,071 INFO:     Epoch: 55
2022-12-31 04:33:08,702 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43160521102448307, 'Total loss': 0.43160521102448307} | train loss {'Reaction outcome loss': 0.18728823799292382, 'Total loss': 0.18728823799292382}
2022-12-31 04:33:08,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:08,702 INFO:     Epoch: 56
2022-12-31 04:33:10,312 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4498585979143778, 'Total loss': 0.4498585979143778} | train loss {'Reaction outcome loss': 0.13083533615544055, 'Total loss': 0.13083533615544055}
2022-12-31 04:33:10,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:10,312 INFO:     Epoch: 57
2022-12-31 04:33:11,969 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4501870761315028, 'Total loss': 0.4501870761315028} | train loss {'Reaction outcome loss': 0.13326003298372624, 'Total loss': 0.13326003298372624}
2022-12-31 04:33:11,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:11,969 INFO:     Epoch: 58
2022-12-31 04:33:13,576 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4083997334043185, 'Total loss': 0.4083997334043185} | train loss {'Reaction outcome loss': 0.167196637699448, 'Total loss': 0.167196637699448}
2022-12-31 04:33:13,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:13,577 INFO:     Epoch: 59
2022-12-31 04:33:15,239 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40652341196934383, 'Total loss': 0.40652341196934383} | train loss {'Reaction outcome loss': 0.1716531544709757, 'Total loss': 0.1716531544709757}
2022-12-31 04:33:15,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:15,239 INFO:     Epoch: 60
2022-12-31 04:33:16,894 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43730911513169607, 'Total loss': 0.43730911513169607} | train loss {'Reaction outcome loss': 0.1317907992870196, 'Total loss': 0.1317907992870196}
2022-12-31 04:33:16,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:16,894 INFO:     Epoch: 61
2022-12-31 04:33:18,554 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40750720743089913, 'Total loss': 0.40750720743089913} | train loss {'Reaction outcome loss': 0.12342984820091826, 'Total loss': 0.12342984820091826}
2022-12-31 04:33:18,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:18,555 INFO:     Epoch: 62
2022-12-31 04:33:20,203 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42668064385652543, 'Total loss': 0.42668064385652543} | train loss {'Reaction outcome loss': 0.1223173103922897, 'Total loss': 0.1223173103922897}
2022-12-31 04:33:20,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:20,203 INFO:     Epoch: 63
2022-12-31 04:33:21,829 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4383965700864792, 'Total loss': 0.4383965700864792} | train loss {'Reaction outcome loss': 0.11991588796144756, 'Total loss': 0.11991588796144756}
2022-12-31 04:33:21,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:21,829 INFO:     Epoch: 64
2022-12-31 04:33:23,460 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42385207215944926, 'Total loss': 0.42385207215944926} | train loss {'Reaction outcome loss': 0.11875215137927402, 'Total loss': 0.11875215137927402}
2022-12-31 04:33:23,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:23,461 INFO:     Epoch: 65
2022-12-31 04:33:25,122 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4280328889687856, 'Total loss': 0.4280328889687856} | train loss {'Reaction outcome loss': 0.11791424365994475, 'Total loss': 0.11791424365994475}
2022-12-31 04:33:25,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:25,122 INFO:     Epoch: 66
2022-12-31 04:33:26,775 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40465579529603324, 'Total loss': 0.40465579529603324} | train loss {'Reaction outcome loss': 0.12088178675517354, 'Total loss': 0.12088178675517354}
2022-12-31 04:33:26,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:26,776 INFO:     Epoch: 67
2022-12-31 04:33:28,437 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4061358895657274, 'Total loss': 0.4061358895657274} | train loss {'Reaction outcome loss': 0.11931088650341563, 'Total loss': 0.11931088650341563}
2022-12-31 04:33:28,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:28,438 INFO:     Epoch: 68
2022-12-31 04:33:30,098 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4264882852633794, 'Total loss': 0.4264882852633794} | train loss {'Reaction outcome loss': 0.12706480971406642, 'Total loss': 0.12706480971406642}
2022-12-31 04:33:30,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:30,098 INFO:     Epoch: 69
2022-12-31 04:33:31,725 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4227564742167791, 'Total loss': 0.4227564742167791} | train loss {'Reaction outcome loss': 0.12243108203266814, 'Total loss': 0.12243108203266814}
2022-12-31 04:33:31,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:31,726 INFO:     Epoch: 70
2022-12-31 04:33:33,334 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3928996548677484, 'Total loss': 0.3928996548677484} | train loss {'Reaction outcome loss': 0.11730963647520791, 'Total loss': 0.11730963647520791}
2022-12-31 04:33:33,334 INFO:     Found new best model at epoch 70
2022-12-31 04:33:33,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:33,335 INFO:     Epoch: 71
2022-12-31 04:33:34,945 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44491334160168966, 'Total loss': 0.44491334160168966} | train loss {'Reaction outcome loss': 0.12039049420137957, 'Total loss': 0.12039049420137957}
2022-12-31 04:33:34,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:34,945 INFO:     Epoch: 72
2022-12-31 04:33:36,606 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47277524272600807, 'Total loss': 0.47277524272600807} | train loss {'Reaction outcome loss': 0.11799862084782048, 'Total loss': 0.11799862084782048}
2022-12-31 04:33:36,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:36,606 INFO:     Epoch: 73
2022-12-31 04:33:38,246 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44842580407857896, 'Total loss': 0.44842580407857896} | train loss {'Reaction outcome loss': 0.1161023480907307, 'Total loss': 0.1161023480907307}
2022-12-31 04:33:38,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:38,247 INFO:     Epoch: 74
2022-12-31 04:33:39,857 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4357953766981761, 'Total loss': 0.4357953766981761} | train loss {'Reaction outcome loss': 0.12208277473352307, 'Total loss': 0.12208277473352307}
2022-12-31 04:33:39,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:39,857 INFO:     Epoch: 75
2022-12-31 04:33:41,502 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44654520352681476, 'Total loss': 0.44654520352681476} | train loss {'Reaction outcome loss': 0.11857772195635269, 'Total loss': 0.11857772195635269}
2022-12-31 04:33:41,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:41,502 INFO:     Epoch: 76
2022-12-31 04:33:43,162 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44477263689041135, 'Total loss': 0.44477263689041135} | train loss {'Reaction outcome loss': 0.11842428318113493, 'Total loss': 0.11842428318113493}
2022-12-31 04:33:43,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:43,162 INFO:     Epoch: 77
2022-12-31 04:33:44,772 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4315013438463211, 'Total loss': 0.4315013438463211} | train loss {'Reaction outcome loss': 0.11979631835972701, 'Total loss': 0.11979631835972701}
2022-12-31 04:33:44,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:44,772 INFO:     Epoch: 78
2022-12-31 04:33:46,381 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42784102459748585, 'Total loss': 0.42784102459748585} | train loss {'Reaction outcome loss': 0.1186402527087341, 'Total loss': 0.1186402527087341}
2022-12-31 04:33:46,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:46,381 INFO:     Epoch: 79
2022-12-31 04:33:48,009 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4336737245321274, 'Total loss': 0.4336737245321274} | train loss {'Reaction outcome loss': 0.11817224550168907, 'Total loss': 0.11817224550168907}
2022-12-31 04:33:48,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:48,009 INFO:     Epoch: 80
2022-12-31 04:33:49,639 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44246894816557564, 'Total loss': 0.44246894816557564} | train loss {'Reaction outcome loss': 0.1157767254088063, 'Total loss': 0.1157767254088063}
2022-12-31 04:33:49,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:49,639 INFO:     Epoch: 81
2022-12-31 04:33:51,300 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43527692556381226, 'Total loss': 0.43527692556381226} | train loss {'Reaction outcome loss': 0.11986092628905905, 'Total loss': 0.11986092628905905}
2022-12-31 04:33:51,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:51,301 INFO:     Epoch: 82
2022-12-31 04:33:52,914 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4539568811655045, 'Total loss': 0.4539568811655045} | train loss {'Reaction outcome loss': 0.12017721336746616, 'Total loss': 0.12017721336746616}
2022-12-31 04:33:52,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:52,914 INFO:     Epoch: 83
2022-12-31 04:33:54,575 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4074977308511734, 'Total loss': 0.4074977308511734} | train loss {'Reaction outcome loss': 0.12258478557771962, 'Total loss': 0.12258478557771962}
2022-12-31 04:33:54,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:54,576 INFO:     Epoch: 84
2022-12-31 04:33:56,236 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41551848128437996, 'Total loss': 0.41551848128437996} | train loss {'Reaction outcome loss': 0.11392442193607787, 'Total loss': 0.11392442193607787}
2022-12-31 04:33:56,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:56,236 INFO:     Epoch: 85
2022-12-31 04:33:57,848 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4289066016674042, 'Total loss': 0.4289066016674042} | train loss {'Reaction outcome loss': 0.1200275996386114, 'Total loss': 0.1200275996386114}
2022-12-31 04:33:57,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:57,848 INFO:     Epoch: 86
2022-12-31 04:33:59,452 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42476309835910797, 'Total loss': 0.42476309835910797} | train loss {'Reaction outcome loss': 0.11362660523298183, 'Total loss': 0.11362660523298183}
2022-12-31 04:33:59,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:33:59,452 INFO:     Epoch: 87
2022-12-31 04:34:01,074 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.434045414129893, 'Total loss': 0.434045414129893} | train loss {'Reaction outcome loss': 0.11215625353245254, 'Total loss': 0.11215625353245254}
2022-12-31 04:34:01,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:01,074 INFO:     Epoch: 88
2022-12-31 04:34:02,702 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4412859857082367, 'Total loss': 0.4412859857082367} | train loss {'Reaction outcome loss': 0.11291295860090927, 'Total loss': 0.11291295860090927}
2022-12-31 04:34:02,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:02,702 INFO:     Epoch: 89
2022-12-31 04:34:04,329 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4289985477924347, 'Total loss': 0.4289985477924347} | train loss {'Reaction outcome loss': 0.1181188507357349, 'Total loss': 0.1181188507357349}
2022-12-31 04:34:04,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:04,329 INFO:     Epoch: 90
2022-12-31 04:34:05,957 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4313994829853376, 'Total loss': 0.4313994829853376} | train loss {'Reaction outcome loss': 0.11627768131523002, 'Total loss': 0.11627768131523002}
2022-12-31 04:34:05,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:05,958 INFO:     Epoch: 91
2022-12-31 04:34:07,568 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4676474119226138, 'Total loss': 0.4676474119226138} | train loss {'Reaction outcome loss': 0.12124726895548309, 'Total loss': 0.12124726895548309}
2022-12-31 04:34:07,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:07,569 INFO:     Epoch: 92
2022-12-31 04:34:09,179 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4528121665120125, 'Total loss': 0.4528121665120125} | train loss {'Reaction outcome loss': 0.11206958727247632, 'Total loss': 0.11206958727247632}
2022-12-31 04:34:09,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:09,179 INFO:     Epoch: 93
2022-12-31 04:34:10,838 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4232475126783053, 'Total loss': 0.4232475126783053} | train loss {'Reaction outcome loss': 0.11236092749902088, 'Total loss': 0.11236092749902088}
2022-12-31 04:34:10,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:10,839 INFO:     Epoch: 94
2022-12-31 04:34:12,454 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4407783687114716, 'Total loss': 0.4407783687114716} | train loss {'Reaction outcome loss': 0.11009135633745852, 'Total loss': 0.11009135633745852}
2022-12-31 04:34:12,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:12,454 INFO:     Epoch: 95
2022-12-31 04:34:14,116 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40537019520998, 'Total loss': 0.40537019520998} | train loss {'Reaction outcome loss': 0.10829652697303453, 'Total loss': 0.10829652697303453}
2022-12-31 04:34:14,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:14,117 INFO:     Epoch: 96
2022-12-31 04:34:15,732 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4735419531663259, 'Total loss': 0.4735419531663259} | train loss {'Reaction outcome loss': 0.10955509385245893, 'Total loss': 0.10955509385245893}
2022-12-31 04:34:15,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:15,732 INFO:     Epoch: 97
2022-12-31 04:34:17,345 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44557775010665257, 'Total loss': 0.44557775010665257} | train loss {'Reaction outcome loss': 0.11374100075407614, 'Total loss': 0.11374100075407614}
2022-12-31 04:34:17,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:17,345 INFO:     Epoch: 98
2022-12-31 04:34:18,978 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4353667438030243, 'Total loss': 0.4353667438030243} | train loss {'Reaction outcome loss': 0.11642484106730831, 'Total loss': 0.11642484106730831}
2022-12-31 04:34:18,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:18,978 INFO:     Epoch: 99
2022-12-31 04:34:20,611 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46448656568924584, 'Total loss': 0.46448656568924584} | train loss {'Reaction outcome loss': 0.12413176750777748, 'Total loss': 0.12413176750777748}
2022-12-31 04:34:20,612 INFO:     Best model found after epoch 71 of 100.
2022-12-31 04:34:20,612 INFO:   Done with stage: TRAINING
2022-12-31 04:34:20,612 INFO:   Starting stage: EVALUATION
2022-12-31 04:34:20,741 INFO:   Done with stage: EVALUATION
2022-12-31 04:34:20,741 INFO:   Leaving out SEQ value Fold_1
2022-12-31 04:34:20,754 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 04:34:20,754 INFO:   Starting stage: FEATURE SCALING
2022-12-31 04:34:21,394 INFO:   Done with stage: FEATURE SCALING
2022-12-31 04:34:21,394 INFO:   Starting stage: SCALING TARGETS
2022-12-31 04:34:21,465 INFO:   Done with stage: SCALING TARGETS
2022-12-31 04:34:21,465 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:34:21,465 INFO:     No hyperparam tuning for this model
2022-12-31 04:34:21,465 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:34:21,465 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 04:34:21,466 INFO:     None feature selector for col prot
2022-12-31 04:34:21,466 INFO:     None feature selector for col prot
2022-12-31 04:34:21,466 INFO:     None feature selector for col prot
2022-12-31 04:34:21,467 INFO:     None feature selector for col chem
2022-12-31 04:34:21,467 INFO:     None feature selector for col chem
2022-12-31 04:34:21,467 INFO:     None feature selector for col chem
2022-12-31 04:34:21,467 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 04:34:21,467 INFO:   Starting stage: BUILD MODEL
2022-12-31 04:34:21,469 INFO:     Number of params in model 224011
2022-12-31 04:34:21,472 INFO:   Done with stage: BUILD MODEL
2022-12-31 04:34:21,472 INFO:   Starting stage: TRAINING
2022-12-31 04:34:21,517 INFO:     Val loss before train {'Reaction outcome loss': 0.9772284865379334, 'Total loss': 0.9772284865379334}
2022-12-31 04:34:21,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:21,517 INFO:     Epoch: 0
2022-12-31 04:34:23,148 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.589653201897939, 'Total loss': 0.589653201897939} | train loss {'Reaction outcome loss': 0.7749099241218705, 'Total loss': 0.7749099241218705}
2022-12-31 04:34:23,149 INFO:     Found new best model at epoch 0
2022-12-31 04:34:23,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:23,150 INFO:     Epoch: 1
2022-12-31 04:34:24,779 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5089080184698105, 'Total loss': 0.5089080184698105} | train loss {'Reaction outcome loss': 0.5111769657528055, 'Total loss': 0.5111769657528055}
2022-12-31 04:34:24,779 INFO:     Found new best model at epoch 1
2022-12-31 04:34:24,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:24,780 INFO:     Epoch: 2
2022-12-31 04:34:26,420 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4976867437362671, 'Total loss': 0.4976867437362671} | train loss {'Reaction outcome loss': 0.44699695116529864, 'Total loss': 0.44699695116529864}
2022-12-31 04:34:26,421 INFO:     Found new best model at epoch 2
2022-12-31 04:34:26,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:26,422 INFO:     Epoch: 3
2022-12-31 04:34:28,030 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4721232036749522, 'Total loss': 0.4721232036749522} | train loss {'Reaction outcome loss': 0.4057730555034958, 'Total loss': 0.4057730555034958}
2022-12-31 04:34:28,030 INFO:     Found new best model at epoch 3
2022-12-31 04:34:28,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:28,031 INFO:     Epoch: 4
2022-12-31 04:34:29,643 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44704778095086417, 'Total loss': 0.44704778095086417} | train loss {'Reaction outcome loss': 0.37931141744627606, 'Total loss': 0.37931141744627606}
2022-12-31 04:34:29,643 INFO:     Found new best model at epoch 4
2022-12-31 04:34:29,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:29,644 INFO:     Epoch: 5
2022-12-31 04:34:31,262 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4721757173538208, 'Total loss': 0.4721757173538208} | train loss {'Reaction outcome loss': 0.356441993414394, 'Total loss': 0.356441993414394}
2022-12-31 04:34:31,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:31,262 INFO:     Epoch: 6
2022-12-31 04:34:32,925 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4480172832806905, 'Total loss': 0.4480172832806905} | train loss {'Reaction outcome loss': 0.3370799843991256, 'Total loss': 0.3370799843991256}
2022-12-31 04:34:32,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:32,926 INFO:     Epoch: 7
2022-12-31 04:34:34,546 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4532039741675059, 'Total loss': 0.4532039741675059} | train loss {'Reaction outcome loss': 0.3214558523040319, 'Total loss': 0.3214558523040319}
2022-12-31 04:34:34,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:34,546 INFO:     Epoch: 8
2022-12-31 04:34:36,196 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4699230978886286, 'Total loss': 0.4699230978886286} | train loss {'Reaction outcome loss': 0.30459756050528825, 'Total loss': 0.30459756050528825}
2022-12-31 04:34:36,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:36,196 INFO:     Epoch: 9
2022-12-31 04:34:37,808 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45253859361012777, 'Total loss': 0.45253859361012777} | train loss {'Reaction outcome loss': 0.2903740884919872, 'Total loss': 0.2903740884919872}
2022-12-31 04:34:37,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:37,808 INFO:     Epoch: 10
2022-12-31 04:34:39,421 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4853693425655365, 'Total loss': 0.4853693425655365} | train loss {'Reaction outcome loss': 0.27556539735414315, 'Total loss': 0.27556539735414315}
2022-12-31 04:34:39,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:39,421 INFO:     Epoch: 11
2022-12-31 04:34:41,034 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.455377663175265, 'Total loss': 0.455377663175265} | train loss {'Reaction outcome loss': 0.26758924508138315, 'Total loss': 0.26758924508138315}
2022-12-31 04:34:41,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:41,035 INFO:     Epoch: 12
2022-12-31 04:34:42,697 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47730116347471874, 'Total loss': 0.47730116347471874} | train loss {'Reaction outcome loss': 0.25638547174647736, 'Total loss': 0.25638547174647736}
2022-12-31 04:34:42,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:42,699 INFO:     Epoch: 13
2022-12-31 04:34:44,300 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44955368240674337, 'Total loss': 0.44955368240674337} | train loss {'Reaction outcome loss': 0.24235644870165834, 'Total loss': 0.24235644870165834}
2022-12-31 04:34:44,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:44,300 INFO:     Epoch: 14
2022-12-31 04:34:45,932 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47093997001647947, 'Total loss': 0.47093997001647947} | train loss {'Reaction outcome loss': 0.23815887169228622, 'Total loss': 0.23815887169228622}
2022-12-31 04:34:45,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:45,932 INFO:     Epoch: 15
2022-12-31 04:34:47,566 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.474128786722819, 'Total loss': 0.474128786722819} | train loss {'Reaction outcome loss': 0.22961801333703857, 'Total loss': 0.22961801333703857}
2022-12-31 04:34:47,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:47,566 INFO:     Epoch: 16
2022-12-31 04:34:49,201 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4618029216925303, 'Total loss': 0.4618029216925303} | train loss {'Reaction outcome loss': 0.23000878125321175, 'Total loss': 0.23000878125321175}
2022-12-31 04:34:49,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:49,202 INFO:     Epoch: 17
2022-12-31 04:34:50,832 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46474800805250804, 'Total loss': 0.46474800805250804} | train loss {'Reaction outcome loss': 0.2192194622235231, 'Total loss': 0.2192194622235231}
2022-12-31 04:34:50,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:50,832 INFO:     Epoch: 18
2022-12-31 04:34:52,451 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4875018229087194, 'Total loss': 0.4875018229087194} | train loss {'Reaction outcome loss': 0.21446367910644715, 'Total loss': 0.21446367910644715}
2022-12-31 04:34:52,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:52,452 INFO:     Epoch: 19
2022-12-31 04:34:54,094 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48393937448660534, 'Total loss': 0.48393937448660534} | train loss {'Reaction outcome loss': 0.20288866507760667, 'Total loss': 0.20288866507760667}
2022-12-31 04:34:54,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:54,094 INFO:     Epoch: 20
2022-12-31 04:34:55,705 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44680345356464385, 'Total loss': 0.44680345356464385} | train loss {'Reaction outcome loss': 0.20266271042350706, 'Total loss': 0.20266271042350706}
2022-12-31 04:34:55,705 INFO:     Found new best model at epoch 20
2022-12-31 04:34:55,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:55,706 INFO:     Epoch: 21
2022-12-31 04:34:57,313 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47855969071388244, 'Total loss': 0.47855969071388244} | train loss {'Reaction outcome loss': 0.19628080252226462, 'Total loss': 0.19628080252226462}
2022-12-31 04:34:57,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:57,313 INFO:     Epoch: 22
2022-12-31 04:34:58,975 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4688779999812444, 'Total loss': 0.4688779999812444} | train loss {'Reaction outcome loss': 0.19413210280027418, 'Total loss': 0.19413210280027418}
2022-12-31 04:34:58,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:34:58,976 INFO:     Epoch: 23
2022-12-31 04:35:00,588 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4966883142789205, 'Total loss': 0.4966883142789205} | train loss {'Reaction outcome loss': 0.18719627791458904, 'Total loss': 0.18719627791458904}
2022-12-31 04:35:00,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:00,588 INFO:     Epoch: 24
2022-12-31 04:35:02,216 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4780858019987742, 'Total loss': 0.4780858019987742} | train loss {'Reaction outcome loss': 0.18954986578150504, 'Total loss': 0.18954986578150504}
2022-12-31 04:35:02,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:02,217 INFO:     Epoch: 25
2022-12-31 04:35:03,846 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44951417048772174, 'Total loss': 0.44951417048772174} | train loss {'Reaction outcome loss': 0.20138139700166124, 'Total loss': 0.20138139700166124}
2022-12-31 04:35:03,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:03,846 INFO:     Epoch: 26
2022-12-31 04:35:05,476 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4480483144521713, 'Total loss': 0.4480483144521713} | train loss {'Reaction outcome loss': 0.1901996545229981, 'Total loss': 0.1901996545229981}
2022-12-31 04:35:05,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:05,477 INFO:     Epoch: 27
2022-12-31 04:35:07,107 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47862226019303006, 'Total loss': 0.47862226019303006} | train loss {'Reaction outcome loss': 0.18450497831487894, 'Total loss': 0.18450497831487894}
2022-12-31 04:35:07,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:07,107 INFO:     Epoch: 28
2022-12-31 04:35:08,737 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47111427088578545, 'Total loss': 0.47111427088578545} | train loss {'Reaction outcome loss': 0.18898981630353365, 'Total loss': 0.18898981630353365}
2022-12-31 04:35:08,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:08,737 INFO:     Epoch: 29
2022-12-31 04:35:10,364 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5128414591153463, 'Total loss': 0.5128414591153463} | train loss {'Reaction outcome loss': 0.1738544282616467, 'Total loss': 0.1738544282616467}
2022-12-31 04:35:10,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:10,364 INFO:     Epoch: 30
2022-12-31 04:35:11,973 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4667755444844564, 'Total loss': 0.4667755444844564} | train loss {'Reaction outcome loss': 0.16855554574547146, 'Total loss': 0.16855554574547146}
2022-12-31 04:35:11,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:11,973 INFO:     Epoch: 31
2022-12-31 04:35:13,583 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5113638480504353, 'Total loss': 0.5113638480504353} | train loss {'Reaction outcome loss': 0.16613861462742469, 'Total loss': 0.16613861462742469}
2022-12-31 04:35:13,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:13,584 INFO:     Epoch: 32
2022-12-31 04:35:15,190 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5225931415955226, 'Total loss': 0.5225931415955226} | train loss {'Reaction outcome loss': 0.1614848562732231, 'Total loss': 0.1614848562732231}
2022-12-31 04:35:15,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:15,190 INFO:     Epoch: 33
2022-12-31 04:35:16,853 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4784796416759491, 'Total loss': 0.4784796416759491} | train loss {'Reaction outcome loss': 0.1615723464308995, 'Total loss': 0.1615723464308995}
2022-12-31 04:35:16,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:16,853 INFO:     Epoch: 34
2022-12-31 04:35:18,517 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5053484718004863, 'Total loss': 0.5053484718004863} | train loss {'Reaction outcome loss': 0.15876699835855002, 'Total loss': 0.15876699835855002}
2022-12-31 04:35:18,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:18,517 INFO:     Epoch: 35
2022-12-31 04:35:20,125 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49646297891934715, 'Total loss': 0.49646297891934715} | train loss {'Reaction outcome loss': 0.15769168724511765, 'Total loss': 0.15769168724511765}
2022-12-31 04:35:20,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:20,126 INFO:     Epoch: 36
2022-12-31 04:35:21,776 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4868906001249949, 'Total loss': 0.4868906001249949} | train loss {'Reaction outcome loss': 0.15744242247150186, 'Total loss': 0.15744242247150186}
2022-12-31 04:35:21,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:21,776 INFO:     Epoch: 37
2022-12-31 04:35:23,391 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5255137105782827, 'Total loss': 0.5255137105782827} | train loss {'Reaction outcome loss': 0.15344696048397463, 'Total loss': 0.15344696048397463}
2022-12-31 04:35:23,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:23,391 INFO:     Epoch: 38
2022-12-31 04:35:25,052 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.50840624148647, 'Total loss': 0.50840624148647} | train loss {'Reaction outcome loss': 0.15249126242554706, 'Total loss': 0.15249126242554706}
2022-12-31 04:35:25,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:25,052 INFO:     Epoch: 39
2022-12-31 04:35:26,702 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5444194575150808, 'Total loss': 0.5444194575150808} | train loss {'Reaction outcome loss': 0.15079008771589134, 'Total loss': 0.15079008771589134}
2022-12-31 04:35:26,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:26,703 INFO:     Epoch: 40
2022-12-31 04:35:28,365 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5088402430216471, 'Total loss': 0.5088402430216471} | train loss {'Reaction outcome loss': 0.1522563917197935, 'Total loss': 0.1522563917197935}
2022-12-31 04:35:28,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:28,365 INFO:     Epoch: 41
2022-12-31 04:35:29,641 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5066836873690287, 'Total loss': 0.5066836873690287} | train loss {'Reaction outcome loss': 0.15888733088871485, 'Total loss': 0.15888733088871485}
2022-12-31 04:35:29,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:29,641 INFO:     Epoch: 42
2022-12-31 04:35:30,773 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5123169422149658, 'Total loss': 0.5123169422149658} | train loss {'Reaction outcome loss': 0.15159169772633121, 'Total loss': 0.15159169772633121}
2022-12-31 04:35:30,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:30,773 INFO:     Epoch: 43
2022-12-31 04:35:31,901 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.49767476667960486, 'Total loss': 0.49767476667960486} | train loss {'Reaction outcome loss': 0.15309066384224276, 'Total loss': 0.15309066384224276}
2022-12-31 04:35:31,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:31,901 INFO:     Epoch: 44
2022-12-31 04:35:33,029 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5118845403194427, 'Total loss': 0.5118845403194427} | train loss {'Reaction outcome loss': 0.14412836755113, 'Total loss': 0.14412836755113}
2022-12-31 04:35:33,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:33,030 INFO:     Epoch: 45
2022-12-31 04:35:34,542 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5041753242413203, 'Total loss': 0.5041753242413203} | train loss {'Reaction outcome loss': 0.1431214626898746, 'Total loss': 0.1431214626898746}
2022-12-31 04:35:34,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:34,542 INFO:     Epoch: 46
2022-12-31 04:35:36,170 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5066393613815308, 'Total loss': 0.5066393613815308} | train loss {'Reaction outcome loss': 0.13989701294601706, 'Total loss': 0.13989701294601706}
2022-12-31 04:35:36,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:36,170 INFO:     Epoch: 47
2022-12-31 04:35:37,787 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5150811483462652, 'Total loss': 0.5150811483462652} | train loss {'Reaction outcome loss': 0.13759645175161786, 'Total loss': 0.13759645175161786}
2022-12-31 04:35:37,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:37,787 INFO:     Epoch: 48
2022-12-31 04:35:39,415 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5210696498552958, 'Total loss': 0.5210696498552958} | train loss {'Reaction outcome loss': 0.14910692221694288, 'Total loss': 0.14910692221694288}
2022-12-31 04:35:39,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:39,415 INFO:     Epoch: 49
2022-12-31 04:35:41,043 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5249027614792188, 'Total loss': 0.5249027614792188} | train loss {'Reaction outcome loss': 0.1423957784771356, 'Total loss': 0.1423957784771356}
2022-12-31 04:35:41,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:41,043 INFO:     Epoch: 50
2022-12-31 04:35:42,664 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49278197089831033, 'Total loss': 0.49278197089831033} | train loss {'Reaction outcome loss': 0.1345253493377311, 'Total loss': 0.1345253493377311}
2022-12-31 04:35:42,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:42,665 INFO:     Epoch: 51
2022-12-31 04:35:44,280 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4881987690925598, 'Total loss': 0.4881987690925598} | train loss {'Reaction outcome loss': 0.13062071738879266, 'Total loss': 0.13062071738879266}
2022-12-31 04:35:44,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:44,281 INFO:     Epoch: 52
2022-12-31 04:35:45,889 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4988385279973348, 'Total loss': 0.4988385279973348} | train loss {'Reaction outcome loss': 0.13521572226233294, 'Total loss': 0.13521572226233294}
2022-12-31 04:35:45,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:45,889 INFO:     Epoch: 53
2022-12-31 04:35:47,549 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.52220439016819, 'Total loss': 0.52220439016819} | train loss {'Reaction outcome loss': 0.1296781872473387, 'Total loss': 0.1296781872473387}
2022-12-31 04:35:47,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:47,550 INFO:     Epoch: 54
2022-12-31 04:35:49,210 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49081151088078817, 'Total loss': 0.49081151088078817} | train loss {'Reaction outcome loss': 0.13649893244281344, 'Total loss': 0.13649893244281344}
2022-12-31 04:35:49,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:49,210 INFO:     Epoch: 55
2022-12-31 04:35:50,871 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5163985321919123, 'Total loss': 0.5163985321919123} | train loss {'Reaction outcome loss': 0.13046807996537266, 'Total loss': 0.13046807996537266}
2022-12-31 04:35:50,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:50,872 INFO:     Epoch: 56
2022-12-31 04:35:52,493 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5248582601547241, 'Total loss': 0.5248582601547241} | train loss {'Reaction outcome loss': 0.13216858845286575, 'Total loss': 0.13216858845286575}
2022-12-31 04:35:52,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:52,493 INFO:     Epoch: 57
2022-12-31 04:35:54,153 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4882401704788208, 'Total loss': 0.4882401704788208} | train loss {'Reaction outcome loss': 0.13726977659456863, 'Total loss': 0.13726977659456863}
2022-12-31 04:35:54,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:54,153 INFO:     Epoch: 58
2022-12-31 04:35:55,784 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.504917660355568, 'Total loss': 0.504917660355568} | train loss {'Reaction outcome loss': 0.14748071935500248, 'Total loss': 0.14748071935500248}
2022-12-31 04:35:55,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:55,785 INFO:     Epoch: 59
2022-12-31 04:35:57,445 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5264151016871135, 'Total loss': 0.5264151016871135} | train loss {'Reaction outcome loss': 0.1297373501111524, 'Total loss': 0.1297373501111524}
2022-12-31 04:35:57,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:57,445 INFO:     Epoch: 60
2022-12-31 04:35:59,067 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5053181529045105, 'Total loss': 0.5053181529045105} | train loss {'Reaction outcome loss': 0.12991592307346012, 'Total loss': 0.12991592307346012}
2022-12-31 04:35:59,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:35:59,067 INFO:     Epoch: 61
2022-12-31 04:36:00,728 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5078727106253306, 'Total loss': 0.5078727106253306} | train loss {'Reaction outcome loss': 0.12129260487921968, 'Total loss': 0.12129260487921968}
2022-12-31 04:36:00,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:00,728 INFO:     Epoch: 62
2022-12-31 04:36:02,380 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4866449683904648, 'Total loss': 0.4866449683904648} | train loss {'Reaction outcome loss': 0.12831409741277416, 'Total loss': 0.12831409741277416}
2022-12-31 04:36:02,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:02,380 INFO:     Epoch: 63
2022-12-31 04:36:03,993 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5176164448261261, 'Total loss': 0.5176164448261261} | train loss {'Reaction outcome loss': 0.12639828091757238, 'Total loss': 0.12639828091757238}
2022-12-31 04:36:03,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:03,994 INFO:     Epoch: 64
2022-12-31 04:36:05,603 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49633293350537616, 'Total loss': 0.49633293350537616} | train loss {'Reaction outcome loss': 0.12482264082991869, 'Total loss': 0.12482264082991869}
2022-12-31 04:36:05,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:05,604 INFO:     Epoch: 65
2022-12-31 04:36:07,264 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5002302194635073, 'Total loss': 0.5002302194635073} | train loss {'Reaction outcome loss': 0.12363719763676351, 'Total loss': 0.12363719763676351}
2022-12-31 04:36:07,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:07,264 INFO:     Epoch: 66
2022-12-31 04:36:08,924 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5183943092823029, 'Total loss': 0.5183943092823029} | train loss {'Reaction outcome loss': 0.12263470419903583, 'Total loss': 0.12263470419903583}
2022-12-31 04:36:08,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:08,924 INFO:     Epoch: 67
2022-12-31 04:36:10,556 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5351314882437388, 'Total loss': 0.5351314882437388} | train loss {'Reaction outcome loss': 0.12518951992936217, 'Total loss': 0.12518951992936217}
2022-12-31 04:36:10,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:10,556 INFO:     Epoch: 68
2022-12-31 04:36:12,171 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5273173848787943, 'Total loss': 0.5273173848787943} | train loss {'Reaction outcome loss': 0.12237076029861413, 'Total loss': 0.12237076029861413}
2022-12-31 04:36:12,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:12,171 INFO:     Epoch: 69
2022-12-31 04:36:13,803 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4824352035919825, 'Total loss': 0.4824352035919825} | train loss {'Reaction outcome loss': 0.12463801309101089, 'Total loss': 0.12463801309101089}
2022-12-31 04:36:13,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:13,803 INFO:     Epoch: 70
2022-12-31 04:36:15,464 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5078358401854833, 'Total loss': 0.5078358401854833} | train loss {'Reaction outcome loss': 0.12006197086968999, 'Total loss': 0.12006197086968999}
2022-12-31 04:36:15,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:15,465 INFO:     Epoch: 71
2022-12-31 04:36:17,081 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.520566334327062, 'Total loss': 0.520566334327062} | train loss {'Reaction outcome loss': 0.11883306615103113, 'Total loss': 0.11883306615103113}
2022-12-31 04:36:17,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:17,081 INFO:     Epoch: 72
2022-12-31 04:36:18,742 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5387330869833629, 'Total loss': 0.5387330869833629} | train loss {'Reaction outcome loss': 0.11764331054818931, 'Total loss': 0.11764331054818931}
2022-12-31 04:36:18,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:18,742 INFO:     Epoch: 73
2022-12-31 04:36:20,365 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5442699978748957, 'Total loss': 0.5442699978748957} | train loss {'Reaction outcome loss': 0.12038744050449537, 'Total loss': 0.12038744050449537}
2022-12-31 04:36:20,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:20,365 INFO:     Epoch: 74
2022-12-31 04:36:21,992 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5490208844343821, 'Total loss': 0.5490208844343821} | train loss {'Reaction outcome loss': 0.12133134092141847, 'Total loss': 0.12133134092141847}
2022-12-31 04:36:21,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:21,993 INFO:     Epoch: 75
2022-12-31 04:36:23,610 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5458443681399028, 'Total loss': 0.5458443681399028} | train loss {'Reaction outcome loss': 0.11634645991908749, 'Total loss': 0.11634645991908749}
2022-12-31 04:36:23,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:23,610 INFO:     Epoch: 76
2022-12-31 04:36:25,236 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5013738666971524, 'Total loss': 0.5013738666971524} | train loss {'Reaction outcome loss': 0.11945304017601724, 'Total loss': 0.11945304017601724}
2022-12-31 04:36:25,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:25,236 INFO:     Epoch: 77
2022-12-31 04:36:26,864 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5259898831446965, 'Total loss': 0.5259898831446965} | train loss {'Reaction outcome loss': 0.11834775284101404, 'Total loss': 0.11834775284101404}
2022-12-31 04:36:26,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:26,864 INFO:     Epoch: 78
2022-12-31 04:36:28,481 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5573169112205505, 'Total loss': 0.5573169112205505} | train loss {'Reaction outcome loss': 0.12475519251661288, 'Total loss': 0.12475519251661288}
2022-12-31 04:36:28,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:28,482 INFO:     Epoch: 79
2022-12-31 04:36:30,106 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5307168443997701, 'Total loss': 0.5307168443997701} | train loss {'Reaction outcome loss': 0.11649422625002141, 'Total loss': 0.11649422625002141}
2022-12-31 04:36:30,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:30,106 INFO:     Epoch: 80
2022-12-31 04:36:31,718 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5448321362336477, 'Total loss': 0.5448321362336477} | train loss {'Reaction outcome loss': 0.11351618079124423, 'Total loss': 0.11351618079124423}
2022-12-31 04:36:31,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:31,718 INFO:     Epoch: 81
2022-12-31 04:36:33,378 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4873794953028361, 'Total loss': 0.4873794953028361} | train loss {'Reaction outcome loss': 0.11336094441324257, 'Total loss': 0.11336094441324257}
2022-12-31 04:36:33,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:33,378 INFO:     Epoch: 82
2022-12-31 04:36:34,994 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5265584550797939, 'Total loss': 0.5265584550797939} | train loss {'Reaction outcome loss': 0.11387801037051469, 'Total loss': 0.11387801037051469}
2022-12-31 04:36:34,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:34,995 INFO:     Epoch: 83
2022-12-31 04:36:36,609 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.531179960568746, 'Total loss': 0.531179960568746} | train loss {'Reaction outcome loss': 0.11853796881505464, 'Total loss': 0.11853796881505464}
2022-12-31 04:36:36,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:36,610 INFO:     Epoch: 84
2022-12-31 04:36:38,227 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4848241925239563, 'Total loss': 0.4848241925239563} | train loss {'Reaction outcome loss': 0.11836961356069271, 'Total loss': 0.11836961356069271}
2022-12-31 04:36:38,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:38,227 INFO:     Epoch: 85
2022-12-31 04:36:39,888 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5490089237689972, 'Total loss': 0.5490089237689972} | train loss {'Reaction outcome loss': 0.11696100606584456, 'Total loss': 0.11696100606584456}
2022-12-31 04:36:39,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:39,888 INFO:     Epoch: 86
2022-12-31 04:36:41,501 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5262840569019318, 'Total loss': 0.5262840569019318} | train loss {'Reaction outcome loss': 0.11683338428923415, 'Total loss': 0.11683338428923415}
2022-12-31 04:36:41,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:41,502 INFO:     Epoch: 87
2022-12-31 04:36:43,126 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5429619918266932, 'Total loss': 0.5429619918266932} | train loss {'Reaction outcome loss': 0.1124001448666123, 'Total loss': 0.1124001448666123}
2022-12-31 04:36:43,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:43,127 INFO:     Epoch: 88
2022-12-31 04:36:44,752 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5322811598579089, 'Total loss': 0.5322811598579089} | train loss {'Reaction outcome loss': 0.1262633714561715, 'Total loss': 0.1262633714561715}
2022-12-31 04:36:44,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:44,752 INFO:     Epoch: 89
2022-12-31 04:36:46,372 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5234224001566569, 'Total loss': 0.5234224001566569} | train loss {'Reaction outcome loss': 0.12256722327130273, 'Total loss': 0.12256722327130273}
2022-12-31 04:36:46,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:46,372 INFO:     Epoch: 90
2022-12-31 04:36:48,005 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5095128893852234, 'Total loss': 0.5095128893852234} | train loss {'Reaction outcome loss': 0.10910688812267229, 'Total loss': 0.10910688812267229}
2022-12-31 04:36:48,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:48,005 INFO:     Epoch: 91
2022-12-31 04:36:49,634 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5467225223779678, 'Total loss': 0.5467225223779678} | train loss {'Reaction outcome loss': 0.11005580640409354, 'Total loss': 0.11005580640409354}
2022-12-31 04:36:49,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:49,634 INFO:     Epoch: 92
2022-12-31 04:36:51,286 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5427527273694674, 'Total loss': 0.5427527273694674} | train loss {'Reaction outcome loss': 0.11236117817377922, 'Total loss': 0.11236117817377922}
2022-12-31 04:36:51,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:51,287 INFO:     Epoch: 93
2022-12-31 04:36:52,924 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.511891433596611, 'Total loss': 0.511891433596611} | train loss {'Reaction outcome loss': 0.1129174342995216, 'Total loss': 0.1129174342995216}
2022-12-31 04:36:52,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:52,924 INFO:     Epoch: 94
2022-12-31 04:36:54,558 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.540345178047816, 'Total loss': 0.540345178047816} | train loss {'Reaction outcome loss': 0.11222242953722278, 'Total loss': 0.11222242953722278}
2022-12-31 04:36:54,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:54,559 INFO:     Epoch: 95
2022-12-31 04:36:56,181 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5387304365634918, 'Total loss': 0.5387304365634918} | train loss {'Reaction outcome loss': 0.11140789632918313, 'Total loss': 0.11140789632918313}
2022-12-31 04:36:56,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:56,181 INFO:     Epoch: 96
2022-12-31 04:36:57,816 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5311118602752686, 'Total loss': 0.5311118602752686} | train loss {'Reaction outcome loss': 0.1081275962414625, 'Total loss': 0.1081275962414625}
2022-12-31 04:36:57,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:57,817 INFO:     Epoch: 97
2022-12-31 04:36:59,441 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5332751482725143, 'Total loss': 0.5332751482725143} | train loss {'Reaction outcome loss': 0.10856442346477602, 'Total loss': 0.10856442346477602}
2022-12-31 04:36:59,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:36:59,441 INFO:     Epoch: 98
2022-12-31 04:37:01,083 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4943341791629791, 'Total loss': 0.4943341791629791} | train loss {'Reaction outcome loss': 0.10960494689670272, 'Total loss': 0.10960494689670272}
2022-12-31 04:37:01,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:01,083 INFO:     Epoch: 99
2022-12-31 04:37:02,720 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5697736660639445, 'Total loss': 0.5697736660639445} | train loss {'Reaction outcome loss': 0.10965004517145091, 'Total loss': 0.10965004517145091}
2022-12-31 04:37:02,721 INFO:     Best model found after epoch 21 of 100.
2022-12-31 04:37:02,721 INFO:   Done with stage: TRAINING
2022-12-31 04:37:02,721 INFO:   Starting stage: EVALUATION
2022-12-31 04:37:02,854 INFO:   Done with stage: EVALUATION
2022-12-31 04:37:02,854 INFO:   Leaving out SEQ value Fold_2
2022-12-31 04:37:02,866 INFO:   examples: 20,544| examples in train: 17,236 | examples in val: 908| examples in test: 2,400
2022-12-31 04:37:02,867 INFO:   Starting stage: FEATURE SCALING
2022-12-31 04:37:03,510 INFO:   Done with stage: FEATURE SCALING
2022-12-31 04:37:03,510 INFO:   Starting stage: SCALING TARGETS
2022-12-31 04:37:03,582 INFO:   Done with stage: SCALING TARGETS
2022-12-31 04:37:03,582 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:37:03,582 INFO:     No hyperparam tuning for this model
2022-12-31 04:37:03,582 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:37:03,582 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 04:37:03,583 INFO:     None feature selector for col prot
2022-12-31 04:37:03,583 INFO:     None feature selector for col prot
2022-12-31 04:37:03,583 INFO:     None feature selector for col prot
2022-12-31 04:37:03,584 INFO:     None feature selector for col chem
2022-12-31 04:37:03,584 INFO:     None feature selector for col chem
2022-12-31 04:37:03,584 INFO:     None feature selector for col chem
2022-12-31 04:37:03,584 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 04:37:03,584 INFO:   Starting stage: BUILD MODEL
2022-12-31 04:37:03,586 INFO:     Number of params in model 224011
2022-12-31 04:37:03,589 INFO:   Done with stage: BUILD MODEL
2022-12-31 04:37:03,589 INFO:   Starting stage: TRAINING
2022-12-31 04:37:03,634 INFO:     Val loss before train {'Reaction outcome loss': 1.031955615679423, 'Total loss': 1.031955615679423}
2022-12-31 04:37:03,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:03,634 INFO:     Epoch: 0
2022-12-31 04:37:05,231 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5274467766284943, 'Total loss': 0.5274467766284943} | train loss {'Reaction outcome loss': 0.7662192855168272, 'Total loss': 0.7662192855168272}
2022-12-31 04:37:05,231 INFO:     Found new best model at epoch 0
2022-12-31 04:37:05,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:05,233 INFO:     Epoch: 1
2022-12-31 04:37:06,837 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4264488329490026, 'Total loss': 0.4264488329490026} | train loss {'Reaction outcome loss': 0.4857936492672673, 'Total loss': 0.4857936492672673}
2022-12-31 04:37:06,838 INFO:     Found new best model at epoch 1
2022-12-31 04:37:06,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:06,839 INFO:     Epoch: 2
2022-12-31 04:37:08,434 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4158702572186788, 'Total loss': 0.4158702572186788} | train loss {'Reaction outcome loss': 0.42475061985077683, 'Total loss': 0.42475061985077683}
2022-12-31 04:37:08,434 INFO:     Found new best model at epoch 2
2022-12-31 04:37:08,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:08,435 INFO:     Epoch: 3
2022-12-31 04:37:10,037 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.3906721184651057, 'Total loss': 0.3906721184651057} | train loss {'Reaction outcome loss': 0.39095280890663464, 'Total loss': 0.39095280890663464}
2022-12-31 04:37:10,038 INFO:     Found new best model at epoch 3
2022-12-31 04:37:10,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:10,039 INFO:     Epoch: 4
2022-12-31 04:37:11,641 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.37075380980968475, 'Total loss': 0.37075380980968475} | train loss {'Reaction outcome loss': 0.3647738286190563, 'Total loss': 0.3647738286190563}
2022-12-31 04:37:11,641 INFO:     Found new best model at epoch 4
2022-12-31 04:37:11,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:11,642 INFO:     Epoch: 5
2022-12-31 04:37:13,243 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.380573903520902, 'Total loss': 0.380573903520902} | train loss {'Reaction outcome loss': 0.3422545895808273, 'Total loss': 0.3422545895808273}
2022-12-31 04:37:13,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:13,243 INFO:     Epoch: 6
2022-12-31 04:37:14,833 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.417030930519104, 'Total loss': 0.417030930519104} | train loss {'Reaction outcome loss': 0.32531216682659253, 'Total loss': 0.32531216682659253}
2022-12-31 04:37:14,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:14,833 INFO:     Epoch: 7
2022-12-31 04:37:16,428 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.37235787212848664, 'Total loss': 0.37235787212848664} | train loss {'Reaction outcome loss': 0.30969932302832603, 'Total loss': 0.30969932302832603}
2022-12-31 04:37:16,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:16,428 INFO:     Epoch: 8
2022-12-31 04:37:18,019 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3636587927738825, 'Total loss': 0.3636587927738825} | train loss {'Reaction outcome loss': 0.294880260195997, 'Total loss': 0.294880260195997}
2022-12-31 04:37:18,019 INFO:     Found new best model at epoch 8
2022-12-31 04:37:18,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:18,020 INFO:     Epoch: 9
2022-12-31 04:37:19,613 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43726827800273893, 'Total loss': 0.43726827800273893} | train loss {'Reaction outcome loss': 0.2805909664818534, 'Total loss': 0.2805909664818534}
2022-12-31 04:37:19,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:19,613 INFO:     Epoch: 10
2022-12-31 04:37:21,209 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3866657495498657, 'Total loss': 0.3866657495498657} | train loss {'Reaction outcome loss': 0.2749612118083018, 'Total loss': 0.2749612118083018}
2022-12-31 04:37:21,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:21,209 INFO:     Epoch: 11
2022-12-31 04:37:22,805 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3542981545130412, 'Total loss': 0.3542981545130412} | train loss {'Reaction outcome loss': 0.25890217444135083, 'Total loss': 0.25890217444135083}
2022-12-31 04:37:22,805 INFO:     Found new best model at epoch 11
2022-12-31 04:37:22,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:22,806 INFO:     Epoch: 12
2022-12-31 04:37:24,401 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3976498772700628, 'Total loss': 0.3976498772700628} | train loss {'Reaction outcome loss': 0.24894997763137022, 'Total loss': 0.24894997763137022}
2022-12-31 04:37:24,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:24,401 INFO:     Epoch: 13
2022-12-31 04:37:25,998 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39544102946917215, 'Total loss': 0.39544102946917215} | train loss {'Reaction outcome loss': 0.2432690339093959, 'Total loss': 0.2432690339093959}
2022-12-31 04:37:25,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:25,999 INFO:     Epoch: 14
2022-12-31 04:37:27,592 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3802683353424072, 'Total loss': 0.3802683353424072} | train loss {'Reaction outcome loss': 0.23499321257350622, 'Total loss': 0.23499321257350622}
2022-12-31 04:37:27,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:27,592 INFO:     Epoch: 15
2022-12-31 04:37:29,187 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.38222942451635994, 'Total loss': 0.38222942451635994} | train loss {'Reaction outcome loss': 0.22926312691221634, 'Total loss': 0.22926312691221634}
2022-12-31 04:37:29,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:29,187 INFO:     Epoch: 16
2022-12-31 04:37:30,786 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3581905702749888, 'Total loss': 0.3581905702749888} | train loss {'Reaction outcome loss': 0.2211414465818692, 'Total loss': 0.2211414465818692}
2022-12-31 04:37:30,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:30,786 INFO:     Epoch: 17
2022-12-31 04:37:32,377 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43501193821430206, 'Total loss': 0.43501193821430206} | train loss {'Reaction outcome loss': 0.21550523231012952, 'Total loss': 0.21550523231012952}
2022-12-31 04:37:32,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:32,378 INFO:     Epoch: 18
2022-12-31 04:37:33,972 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.38476876517136893, 'Total loss': 0.38476876517136893} | train loss {'Reaction outcome loss': 0.21291189940163383, 'Total loss': 0.21291189940163383}
2022-12-31 04:37:33,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:33,972 INFO:     Epoch: 19
2022-12-31 04:37:35,558 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38975951572259265, 'Total loss': 0.38975951572259265} | train loss {'Reaction outcome loss': 0.20363750348764437, 'Total loss': 0.20363750348764437}
2022-12-31 04:37:35,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:35,558 INFO:     Epoch: 20
2022-12-31 04:37:37,149 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.369846078256766, 'Total loss': 0.369846078256766} | train loss {'Reaction outcome loss': 0.201310350732119, 'Total loss': 0.201310350732119}
2022-12-31 04:37:37,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:37,149 INFO:     Epoch: 21
2022-12-31 04:37:38,741 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3785790652036667, 'Total loss': 0.3785790652036667} | train loss {'Reaction outcome loss': 0.19842656200958622, 'Total loss': 0.19842656200958622}
2022-12-31 04:37:38,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:38,741 INFO:     Epoch: 22
2022-12-31 04:37:40,332 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3681248476107915, 'Total loss': 0.3681248476107915} | train loss {'Reaction outcome loss': 0.19079607936933085, 'Total loss': 0.19079607936933085}
2022-12-31 04:37:40,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:40,333 INFO:     Epoch: 23
2022-12-31 04:37:41,916 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4607816199461619, 'Total loss': 0.4607816199461619} | train loss {'Reaction outcome loss': 0.1871755614531813, 'Total loss': 0.1871755614531813}
2022-12-31 04:37:41,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:41,916 INFO:     Epoch: 24
2022-12-31 04:37:43,510 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38420289556185405, 'Total loss': 0.38420289556185405} | train loss {'Reaction outcome loss': 0.18363688046595564, 'Total loss': 0.18363688046595564}
2022-12-31 04:37:43,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:43,510 INFO:     Epoch: 25
2022-12-31 04:37:45,103 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.37799867590268454, 'Total loss': 0.37799867590268454} | train loss {'Reaction outcome loss': 0.17938878246479564, 'Total loss': 0.17938878246479564}
2022-12-31 04:37:45,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:45,104 INFO:     Epoch: 26
2022-12-31 04:37:46,698 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40696765581766764, 'Total loss': 0.40696765581766764} | train loss {'Reaction outcome loss': 0.17834191935619823, 'Total loss': 0.17834191935619823}
2022-12-31 04:37:46,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:46,699 INFO:     Epoch: 27
2022-12-31 04:37:48,293 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42254436016082764, 'Total loss': 0.42254436016082764} | train loss {'Reaction outcome loss': 0.17496532996495565, 'Total loss': 0.17496532996495565}
2022-12-31 04:37:48,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:48,294 INFO:     Epoch: 28
2022-12-31 04:37:49,888 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43396657953659695, 'Total loss': 0.43396657953659695} | train loss {'Reaction outcome loss': 0.16944178965770537, 'Total loss': 0.16944178965770537}
2022-12-31 04:37:49,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:49,888 INFO:     Epoch: 29
2022-12-31 04:37:51,532 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42889036337534586, 'Total loss': 0.42889036337534586} | train loss {'Reaction outcome loss': 0.16497626194592427, 'Total loss': 0.16497626194592427}
2022-12-31 04:37:51,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:51,533 INFO:     Epoch: 30
2022-12-31 04:37:53,124 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41797539393107097, 'Total loss': 0.41797539393107097} | train loss {'Reaction outcome loss': 0.1643059641916167, 'Total loss': 0.1643059641916167}
2022-12-31 04:37:53,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:53,125 INFO:     Epoch: 31
2022-12-31 04:37:54,712 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4262274861335754, 'Total loss': 0.4262274861335754} | train loss {'Reaction outcome loss': 0.16341661087202805, 'Total loss': 0.16341661087202805}
2022-12-31 04:37:54,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:54,712 INFO:     Epoch: 32
2022-12-31 04:37:56,292 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46610833903153737, 'Total loss': 0.46610833903153737} | train loss {'Reaction outcome loss': 0.16303450873604527, 'Total loss': 0.16303450873604527}
2022-12-31 04:37:56,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:56,292 INFO:     Epoch: 33
2022-12-31 04:37:57,871 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4154319897294044, 'Total loss': 0.4154319897294044} | train loss {'Reaction outcome loss': 0.15597299719574276, 'Total loss': 0.15597299719574276}
2022-12-31 04:37:57,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:57,872 INFO:     Epoch: 34
2022-12-31 04:37:59,488 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40113299489021303, 'Total loss': 0.40113299489021303} | train loss {'Reaction outcome loss': 0.15300844432441174, 'Total loss': 0.15300844432441174}
2022-12-31 04:37:59,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:37:59,489 INFO:     Epoch: 35
2022-12-31 04:38:01,116 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40415677689015866, 'Total loss': 0.40415677689015866} | train loss {'Reaction outcome loss': 0.15532395082905337, 'Total loss': 0.15532395082905337}
2022-12-31 04:38:01,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:01,116 INFO:     Epoch: 36
2022-12-31 04:38:02,696 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4084346065918604, 'Total loss': 0.4084346065918604} | train loss {'Reaction outcome loss': 0.15286172571833487, 'Total loss': 0.15286172571833487}
2022-12-31 04:38:02,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:02,697 INFO:     Epoch: 37
2022-12-31 04:38:04,322 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3779166499773661, 'Total loss': 0.3779166499773661} | train loss {'Reaction outcome loss': 0.1487870913223122, 'Total loss': 0.1487870913223122}
2022-12-31 04:38:04,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:04,322 INFO:     Epoch: 38
2022-12-31 04:38:05,927 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4036217687961956, 'Total loss': 0.4036217687961956} | train loss {'Reaction outcome loss': 0.14628704456457248, 'Total loss': 0.14628704456457248}
2022-12-31 04:38:05,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:05,927 INFO:     Epoch: 39
2022-12-31 04:38:07,554 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44128532807032267, 'Total loss': 0.44128532807032267} | train loss {'Reaction outcome loss': 0.1426899356595068, 'Total loss': 0.1426899356595068}
2022-12-31 04:38:07,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:07,554 INFO:     Epoch: 40
2022-12-31 04:38:09,128 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41760461727778114, 'Total loss': 0.41760461727778114} | train loss {'Reaction outcome loss': 0.1432114469197889, 'Total loss': 0.1432114469197889}
2022-12-31 04:38:09,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:09,129 INFO:     Epoch: 41
2022-12-31 04:38:10,706 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43456318775812786, 'Total loss': 0.43456318775812786} | train loss {'Reaction outcome loss': 0.14384109450124757, 'Total loss': 0.14384109450124757}
2022-12-31 04:38:10,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:10,707 INFO:     Epoch: 42
2022-12-31 04:38:12,287 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42083055476347603, 'Total loss': 0.42083055476347603} | train loss {'Reaction outcome loss': 0.1390107862720335, 'Total loss': 0.1390107862720335}
2022-12-31 04:38:12,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:12,287 INFO:     Epoch: 43
2022-12-31 04:38:13,895 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3842346156636874, 'Total loss': 0.3842346156636874} | train loss {'Reaction outcome loss': 0.1459055335467888, 'Total loss': 0.1459055335467888}
2022-12-31 04:38:13,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:13,895 INFO:     Epoch: 44
2022-12-31 04:38:15,477 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3955832189026599, 'Total loss': 0.3955832189026599} | train loss {'Reaction outcome loss': 0.14138904061616847, 'Total loss': 0.14138904061616847}
2022-12-31 04:38:15,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:15,477 INFO:     Epoch: 45
2022-12-31 04:38:17,104 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41532383461793265, 'Total loss': 0.41532383461793265} | train loss {'Reaction outcome loss': 0.1351865090119342, 'Total loss': 0.1351865090119342}
2022-12-31 04:38:17,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:17,104 INFO:     Epoch: 46
2022-12-31 04:38:18,740 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42030464907487236, 'Total loss': 0.42030464907487236} | train loss {'Reaction outcome loss': 0.13486700297712728, 'Total loss': 0.13486700297712728}
2022-12-31 04:38:18,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:18,740 INFO:     Epoch: 47
2022-12-31 04:38:20,396 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42508435050646465, 'Total loss': 0.42508435050646465} | train loss {'Reaction outcome loss': 0.1310980277463656, 'Total loss': 0.1310980277463656}
2022-12-31 04:38:20,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:20,396 INFO:     Epoch: 48
2022-12-31 04:38:22,031 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4332252452770869, 'Total loss': 0.4332252452770869} | train loss {'Reaction outcome loss': 0.13522876980542034, 'Total loss': 0.13522876980542034}
2022-12-31 04:38:22,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:22,032 INFO:     Epoch: 49
2022-12-31 04:38:23,682 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4305342460672061, 'Total loss': 0.4305342460672061} | train loss {'Reaction outcome loss': 0.13711768534655372, 'Total loss': 0.13711768534655372}
2022-12-31 04:38:23,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:23,683 INFO:     Epoch: 50
2022-12-31 04:38:25,335 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39442648912469547, 'Total loss': 0.39442648912469547} | train loss {'Reaction outcome loss': 0.1323215026943082, 'Total loss': 0.1323215026943082}
2022-12-31 04:38:25,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:25,336 INFO:     Epoch: 51
2022-12-31 04:38:26,989 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41416851480801903, 'Total loss': 0.41416851480801903} | train loss {'Reaction outcome loss': 0.1332586584560987, 'Total loss': 0.1332586584560987}
2022-12-31 04:38:26,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:26,989 INFO:     Epoch: 52
2022-12-31 04:38:28,564 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39825032353401185, 'Total loss': 0.39825032353401185} | train loss {'Reaction outcome loss': 0.1332150166578315, 'Total loss': 0.1332150166578315}
2022-12-31 04:38:28,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:28,564 INFO:     Epoch: 53
2022-12-31 04:38:30,190 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.387460162738959, 'Total loss': 0.387460162738959} | train loss {'Reaction outcome loss': 0.12805708016924283, 'Total loss': 0.12805708016924283}
2022-12-31 04:38:30,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:30,190 INFO:     Epoch: 54
2022-12-31 04:38:31,822 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5292231346170108, 'Total loss': 0.5292231346170108} | train loss {'Reaction outcome loss': 0.13140390773165833, 'Total loss': 0.13140390773165833}
2022-12-31 04:38:31,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:31,822 INFO:     Epoch: 55
2022-12-31 04:38:33,481 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4753298074007034, 'Total loss': 0.4753298074007034} | train loss {'Reaction outcome loss': 0.12784552114705244, 'Total loss': 0.12784552114705244}
2022-12-31 04:38:33,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:33,481 INFO:     Epoch: 56
2022-12-31 04:38:35,138 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4021881053845088, 'Total loss': 0.4021881053845088} | train loss {'Reaction outcome loss': 0.1247367150115746, 'Total loss': 0.1247367150115746}
2022-12-31 04:38:35,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:35,138 INFO:     Epoch: 57
2022-12-31 04:38:36,782 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4029083312178651, 'Total loss': 0.4029083312178651} | train loss {'Reaction outcome loss': 0.12490561701943753, 'Total loss': 0.12490561701943753}
2022-12-31 04:38:36,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:36,783 INFO:     Epoch: 58
2022-12-31 04:38:38,447 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4948349416255951, 'Total loss': 0.4948349416255951} | train loss {'Reaction outcome loss': 0.12822074535716738, 'Total loss': 0.12822074535716738}
2022-12-31 04:38:38,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:38,448 INFO:     Epoch: 59
2022-12-31 04:38:40,087 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43347148795922597, 'Total loss': 0.43347148795922597} | train loss {'Reaction outcome loss': 0.12673896784652713, 'Total loss': 0.12673896784652713}
2022-12-31 04:38:40,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:40,087 INFO:     Epoch: 60
2022-12-31 04:38:41,747 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47252764453490576, 'Total loss': 0.47252764453490576} | train loss {'Reaction outcome loss': 0.12707228446206836, 'Total loss': 0.12707228446206836}
2022-12-31 04:38:41,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:41,747 INFO:     Epoch: 61
2022-12-31 04:38:43,400 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40094663202762604, 'Total loss': 0.40094663202762604} | train loss {'Reaction outcome loss': 0.12340806708498686, 'Total loss': 0.12340806708498686}
2022-12-31 04:38:43,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:43,400 INFO:     Epoch: 62
2022-12-31 04:38:45,064 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41827372430513304, 'Total loss': 0.41827372430513304} | train loss {'Reaction outcome loss': 0.12350615893697572, 'Total loss': 0.12350615893697572}
2022-12-31 04:38:45,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:45,065 INFO:     Epoch: 63
2022-12-31 04:38:46,691 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4064107415576776, 'Total loss': 0.4064107415576776} | train loss {'Reaction outcome loss': 0.12143563684765939, 'Total loss': 0.12143563684765939}
2022-12-31 04:38:46,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:46,691 INFO:     Epoch: 64
2022-12-31 04:38:48,281 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.449917297065258, 'Total loss': 0.449917297065258} | train loss {'Reaction outcome loss': 0.11948397712937246, 'Total loss': 0.11948397712937246}
2022-12-31 04:38:48,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:48,281 INFO:     Epoch: 65
2022-12-31 04:38:49,882 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4473352074623108, 'Total loss': 0.4473352074623108} | train loss {'Reaction outcome loss': 0.11807196462630398, 'Total loss': 0.11807196462630398}
2022-12-31 04:38:49,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:49,882 INFO:     Epoch: 66
2022-12-31 04:38:51,509 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40024847493041305, 'Total loss': 0.40024847493041305} | train loss {'Reaction outcome loss': 0.1230493453219188, 'Total loss': 0.1230493453219188}
2022-12-31 04:38:51,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:51,509 INFO:     Epoch: 67
2022-12-31 04:38:53,137 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4155484641281267, 'Total loss': 0.4155484641281267} | train loss {'Reaction outcome loss': 0.11891527888451324, 'Total loss': 0.11891527888451324}
2022-12-31 04:38:53,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:53,137 INFO:     Epoch: 68
2022-12-31 04:38:54,728 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40381794574980934, 'Total loss': 0.40381794574980934} | train loss {'Reaction outcome loss': 0.12107270327051757, 'Total loss': 0.12107270327051757}
2022-12-31 04:38:54,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:54,729 INFO:     Epoch: 69
2022-12-31 04:38:56,343 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.38352946266531945, 'Total loss': 0.38352946266531945} | train loss {'Reaction outcome loss': 0.1217567424600323, 'Total loss': 0.1217567424600323}
2022-12-31 04:38:56,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:56,343 INFO:     Epoch: 70
2022-12-31 04:38:57,933 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.377428508301576, 'Total loss': 0.377428508301576} | train loss {'Reaction outcome loss': 0.12008766556779543, 'Total loss': 0.12008766556779543}
2022-12-31 04:38:57,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:57,934 INFO:     Epoch: 71
2022-12-31 04:38:59,540 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4260883281628291, 'Total loss': 0.4260883281628291} | train loss {'Reaction outcome loss': 0.12391269833832565, 'Total loss': 0.12391269833832565}
2022-12-31 04:38:59,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:38:59,540 INFO:     Epoch: 72
2022-12-31 04:39:01,126 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.410046179095904, 'Total loss': 0.410046179095904} | train loss {'Reaction outcome loss': 0.12229033528861624, 'Total loss': 0.12229033528861624}
2022-12-31 04:39:01,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:01,126 INFO:     Epoch: 73
2022-12-31 04:39:02,753 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4062022333343824, 'Total loss': 0.4062022333343824} | train loss {'Reaction outcome loss': 0.11653551008138392, 'Total loss': 0.11653551008138392}
2022-12-31 04:39:02,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:02,753 INFO:     Epoch: 74
2022-12-31 04:39:04,367 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38654166609048846, 'Total loss': 0.38654166609048846} | train loss {'Reaction outcome loss': 0.11544802443262328, 'Total loss': 0.11544802443262328}
2022-12-31 04:39:04,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:04,368 INFO:     Epoch: 75
2022-12-31 04:39:05,995 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.38019107553797465, 'Total loss': 0.38019107553797465} | train loss {'Reaction outcome loss': 0.11754297647901156, 'Total loss': 0.11754297647901156}
2022-12-31 04:39:05,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:05,995 INFO:     Epoch: 76
2022-12-31 04:39:07,613 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38541840348237505, 'Total loss': 0.38541840348237505} | train loss {'Reaction outcome loss': 0.11388522952415601, 'Total loss': 0.11388522952415601}
2022-12-31 04:39:07,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:07,614 INFO:     Epoch: 77
2022-12-31 04:39:09,197 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4219676872715354, 'Total loss': 0.4219676872715354} | train loss {'Reaction outcome loss': 0.1171129074016655, 'Total loss': 0.1171129074016655}
2022-12-31 04:39:09,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:09,198 INFO:     Epoch: 78
2022-12-31 04:39:10,776 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44327291411658126, 'Total loss': 0.44327291411658126} | train loss {'Reaction outcome loss': 0.11740435394975875, 'Total loss': 0.11740435394975875}
2022-12-31 04:39:10,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:10,776 INFO:     Epoch: 79
2022-12-31 04:39:12,402 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4492097745339076, 'Total loss': 0.4492097745339076} | train loss {'Reaction outcome loss': 0.11817748141819956, 'Total loss': 0.11817748141819956}
2022-12-31 04:39:12,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:12,402 INFO:     Epoch: 80
2022-12-31 04:39:13,995 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4516883432865143, 'Total loss': 0.4516883432865143} | train loss {'Reaction outcome loss': 0.11587216485015772, 'Total loss': 0.11587216485015772}
2022-12-31 04:39:13,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:13,995 INFO:     Epoch: 81
2022-12-31 04:39:15,591 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40730110704898836, 'Total loss': 0.40730110704898836} | train loss {'Reaction outcome loss': 0.11488028062697224, 'Total loss': 0.11488028062697224}
2022-12-31 04:39:15,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:15,592 INFO:     Epoch: 82
2022-12-31 04:39:17,172 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.412943605085214, 'Total loss': 0.412943605085214} | train loss {'Reaction outcome loss': 0.10976339570005182, 'Total loss': 0.10976339570005182}
2022-12-31 04:39:17,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:17,172 INFO:     Epoch: 83
2022-12-31 04:39:18,764 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4210124731063843, 'Total loss': 0.4210124731063843} | train loss {'Reaction outcome loss': 0.11383038432233863, 'Total loss': 0.11383038432233863}
2022-12-31 04:39:18,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:18,765 INFO:     Epoch: 84
2022-12-31 04:39:20,351 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.437579204638799, 'Total loss': 0.437579204638799} | train loss {'Reaction outcome loss': 0.11484457590418902, 'Total loss': 0.11484457590418902}
2022-12-31 04:39:20,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:20,352 INFO:     Epoch: 85
2022-12-31 04:39:21,937 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40664595799365394, 'Total loss': 0.40664595799365394} | train loss {'Reaction outcome loss': 0.11998176511842758, 'Total loss': 0.11998176511842758}
2022-12-31 04:39:21,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:21,937 INFO:     Epoch: 86
2022-12-31 04:39:23,517 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42907664279143015, 'Total loss': 0.42907664279143015} | train loss {'Reaction outcome loss': 0.11486917184838266, 'Total loss': 0.11486917184838266}
2022-12-31 04:39:23,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:23,518 INFO:     Epoch: 87
2022-12-31 04:39:25,110 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40219164490699766, 'Total loss': 0.40219164490699766} | train loss {'Reaction outcome loss': 0.11320356315312287, 'Total loss': 0.11320356315312287}
2022-12-31 04:39:25,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:25,110 INFO:     Epoch: 88
2022-12-31 04:39:26,695 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4069266110658646, 'Total loss': 0.4069266110658646} | train loss {'Reaction outcome loss': 0.10771744818495656, 'Total loss': 0.10771744818495656}
2022-12-31 04:39:26,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:26,695 INFO:     Epoch: 89
2022-12-31 04:39:28,288 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40156316161155703, 'Total loss': 0.40156316161155703} | train loss {'Reaction outcome loss': 0.11016204201064451, 'Total loss': 0.11016204201064451}
2022-12-31 04:39:28,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:28,289 INFO:     Epoch: 90
2022-12-31 04:39:29,880 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4620567490657171, 'Total loss': 0.4620567490657171} | train loss {'Reaction outcome loss': 0.10945833831749581, 'Total loss': 0.10945833831749581}
2022-12-31 04:39:29,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:29,881 INFO:     Epoch: 91
2022-12-31 04:39:31,465 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4573090593020121, 'Total loss': 0.4573090593020121} | train loss {'Reaction outcome loss': 0.10865263657696131, 'Total loss': 0.10865263657696131}
2022-12-31 04:39:31,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:31,465 INFO:     Epoch: 92
2022-12-31 04:39:33,092 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5163533608118693, 'Total loss': 0.5163533608118693} | train loss {'Reaction outcome loss': 0.10883813938643369, 'Total loss': 0.10883813938643369}
2022-12-31 04:39:33,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:33,092 INFO:     Epoch: 93
2022-12-31 04:39:34,719 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38728156466192254, 'Total loss': 0.38728156466192254} | train loss {'Reaction outcome loss': 0.1127255307338028, 'Total loss': 0.1127255307338028}
2022-12-31 04:39:34,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:34,719 INFO:     Epoch: 94
2022-12-31 04:39:36,330 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44444718062877653, 'Total loss': 0.44444718062877653} | train loss {'Reaction outcome loss': 0.11282726048267688, 'Total loss': 0.11282726048267688}
2022-12-31 04:39:36,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:36,330 INFO:     Epoch: 95
2022-12-31 04:39:37,955 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40457966725031536, 'Total loss': 0.40457966725031536} | train loss {'Reaction outcome loss': 0.1134515134298622, 'Total loss': 0.1134515134298622}
2022-12-31 04:39:37,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:37,956 INFO:     Epoch: 96
2022-12-31 04:39:39,538 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4775147537390391, 'Total loss': 0.4775147537390391} | train loss {'Reaction outcome loss': 0.11216149512091997, 'Total loss': 0.11216149512091997}
2022-12-31 04:39:39,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:39,539 INFO:     Epoch: 97
2022-12-31 04:39:41,146 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40884695649147035, 'Total loss': 0.40884695649147035} | train loss {'Reaction outcome loss': 0.1090744621741275, 'Total loss': 0.1090744621741275}
2022-12-31 04:39:41,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:41,146 INFO:     Epoch: 98
2022-12-31 04:39:42,728 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42038144121567406, 'Total loss': 0.42038144121567406} | train loss {'Reaction outcome loss': 0.1071407328195939, 'Total loss': 0.1071407328195939}
2022-12-31 04:39:42,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:42,728 INFO:     Epoch: 99
2022-12-31 04:39:44,339 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4110853289797281, 'Total loss': 0.4110853289797281} | train loss {'Reaction outcome loss': 0.10720806313437169, 'Total loss': 0.10720806313437169}
2022-12-31 04:39:44,340 INFO:     Best model found after epoch 12 of 100.
2022-12-31 04:39:44,340 INFO:   Done with stage: TRAINING
2022-12-31 04:39:44,340 INFO:   Starting stage: EVALUATION
2022-12-31 04:39:44,497 INFO:   Done with stage: EVALUATION
2022-12-31 04:39:44,497 INFO:   Leaving out SEQ value Fold_3
2022-12-31 04:39:44,510 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 04:39:44,510 INFO:   Starting stage: FEATURE SCALING
2022-12-31 04:39:45,146 INFO:   Done with stage: FEATURE SCALING
2022-12-31 04:39:45,146 INFO:   Starting stage: SCALING TARGETS
2022-12-31 04:39:45,217 INFO:   Done with stage: SCALING TARGETS
2022-12-31 04:39:45,217 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:39:45,217 INFO:     No hyperparam tuning for this model
2022-12-31 04:39:45,217 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:39:45,218 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 04:39:45,218 INFO:     None feature selector for col prot
2022-12-31 04:39:45,218 INFO:     None feature selector for col prot
2022-12-31 04:39:45,218 INFO:     None feature selector for col prot
2022-12-31 04:39:45,219 INFO:     None feature selector for col chem
2022-12-31 04:39:45,219 INFO:     None feature selector for col chem
2022-12-31 04:39:45,219 INFO:     None feature selector for col chem
2022-12-31 04:39:45,219 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 04:39:45,219 INFO:   Starting stage: BUILD MODEL
2022-12-31 04:39:45,221 INFO:     Number of params in model 224011
2022-12-31 04:39:45,224 INFO:   Done with stage: BUILD MODEL
2022-12-31 04:39:45,224 INFO:   Starting stage: TRAINING
2022-12-31 04:39:45,271 INFO:     Val loss before train {'Reaction outcome loss': 0.9831068813800812, 'Total loss': 0.9831068813800812}
2022-12-31 04:39:45,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:45,271 INFO:     Epoch: 0
2022-12-31 04:39:46,876 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6225863734881083, 'Total loss': 0.6225863734881083} | train loss {'Reaction outcome loss': 0.7780610594229821, 'Total loss': 0.7780610594229821}
2022-12-31 04:39:46,877 INFO:     Found new best model at epoch 0
2022-12-31 04:39:46,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:46,878 INFO:     Epoch: 1
2022-12-31 04:39:48,481 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5116563538710276, 'Total loss': 0.5116563538710276} | train loss {'Reaction outcome loss': 0.5271213966193217, 'Total loss': 0.5271213966193217}
2022-12-31 04:39:48,481 INFO:     Found new best model at epoch 1
2022-12-31 04:39:48,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:48,482 INFO:     Epoch: 2
2022-12-31 04:39:50,085 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4991942842801412, 'Total loss': 0.4991942842801412} | train loss {'Reaction outcome loss': 0.4612500358905111, 'Total loss': 0.4612500358905111}
2022-12-31 04:39:50,085 INFO:     Found new best model at epoch 2
2022-12-31 04:39:50,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:50,086 INFO:     Epoch: 3
2022-12-31 04:39:51,720 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.521729834874471, 'Total loss': 0.521729834874471} | train loss {'Reaction outcome loss': 0.41690987073594615, 'Total loss': 0.41690987073594615}
2022-12-31 04:39:51,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:51,721 INFO:     Epoch: 4
2022-12-31 04:39:53,325 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4862561623255412, 'Total loss': 0.4862561623255412} | train loss {'Reaction outcome loss': 0.3923917654014769, 'Total loss': 0.3923917654014769}
2022-12-31 04:39:53,325 INFO:     Found new best model at epoch 4
2022-12-31 04:39:53,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:53,327 INFO:     Epoch: 5
2022-12-31 04:39:54,966 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5053668220837911, 'Total loss': 0.5053668220837911} | train loss {'Reaction outcome loss': 0.3623273593984244, 'Total loss': 0.3623273593984244}
2022-12-31 04:39:54,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:54,966 INFO:     Epoch: 6
2022-12-31 04:39:56,611 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4903069833914439, 'Total loss': 0.4903069833914439} | train loss {'Reaction outcome loss': 0.3386956190369723, 'Total loss': 0.3386956190369723}
2022-12-31 04:39:56,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:56,611 INFO:     Epoch: 7
2022-12-31 04:39:58,253 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47020278573036195, 'Total loss': 0.47020278573036195} | train loss {'Reaction outcome loss': 0.32239544015009325, 'Total loss': 0.32239544015009325}
2022-12-31 04:39:58,254 INFO:     Found new best model at epoch 7
2022-12-31 04:39:58,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:58,255 INFO:     Epoch: 8
2022-12-31 04:39:59,867 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44199145833651227, 'Total loss': 0.44199145833651227} | train loss {'Reaction outcome loss': 0.30479797216016297, 'Total loss': 0.30479797216016297}
2022-12-31 04:39:59,867 INFO:     Found new best model at epoch 8
2022-12-31 04:39:59,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:39:59,869 INFO:     Epoch: 9
2022-12-31 04:40:01,475 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4604859749476115, 'Total loss': 0.4604859749476115} | train loss {'Reaction outcome loss': 0.29382162713087523, 'Total loss': 0.29382162713087523}
2022-12-31 04:40:01,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:01,475 INFO:     Epoch: 10
2022-12-31 04:40:03,076 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4384515242030223, 'Total loss': 0.4384515242030223} | train loss {'Reaction outcome loss': 0.2824959236234699, 'Total loss': 0.2824959236234699}
2022-12-31 04:40:03,076 INFO:     Found new best model at epoch 10
2022-12-31 04:40:03,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:03,077 INFO:     Epoch: 11
2022-12-31 04:40:04,686 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49861703515052797, 'Total loss': 0.49861703515052797} | train loss {'Reaction outcome loss': 0.2727562484873848, 'Total loss': 0.2727562484873848}
2022-12-31 04:40:04,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:04,687 INFO:     Epoch: 12
2022-12-31 04:40:06,296 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43553924510876335, 'Total loss': 0.43553924510876335} | train loss {'Reaction outcome loss': 0.26467886114076816, 'Total loss': 0.26467886114076816}
2022-12-31 04:40:06,296 INFO:     Found new best model at epoch 12
2022-12-31 04:40:06,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:06,297 INFO:     Epoch: 13
2022-12-31 04:40:07,901 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45410282611846925, 'Total loss': 0.45410282611846925} | train loss {'Reaction outcome loss': 0.25385883282665367, 'Total loss': 0.25385883282665367}
2022-12-31 04:40:07,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:07,901 INFO:     Epoch: 14
2022-12-31 04:40:09,490 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.475821511944135, 'Total loss': 0.475821511944135} | train loss {'Reaction outcome loss': 0.24297614680814655, 'Total loss': 0.24297614680814655}
2022-12-31 04:40:09,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:09,490 INFO:     Epoch: 15
2022-12-31 04:40:11,132 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.455232971906662, 'Total loss': 0.455232971906662} | train loss {'Reaction outcome loss': 0.23887996905015937, 'Total loss': 0.23887996905015937}
2022-12-31 04:40:11,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:11,132 INFO:     Epoch: 16
2022-12-31 04:40:12,762 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43891829525431, 'Total loss': 0.43891829525431} | train loss {'Reaction outcome loss': 0.23110145964956547, 'Total loss': 0.23110145964956547}
2022-12-31 04:40:12,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:12,763 INFO:     Epoch: 17
2022-12-31 04:40:14,405 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4795737812916438, 'Total loss': 0.4795737812916438} | train loss {'Reaction outcome loss': 0.2240909143954843, 'Total loss': 0.2240909143954843}
2022-12-31 04:40:14,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:14,405 INFO:     Epoch: 18
2022-12-31 04:40:16,034 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4805052638053894, 'Total loss': 0.4805052638053894} | train loss {'Reaction outcome loss': 0.21590546182878725, 'Total loss': 0.21590546182878725}
2022-12-31 04:40:16,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:16,035 INFO:     Epoch: 19
2022-12-31 04:40:17,625 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45909810488422714, 'Total loss': 0.45909810488422714} | train loss {'Reaction outcome loss': 0.21106734458398033, 'Total loss': 0.21106734458398033}
2022-12-31 04:40:17,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:17,626 INFO:     Epoch: 20
2022-12-31 04:40:19,268 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47587942679723105, 'Total loss': 0.47587942679723105} | train loss {'Reaction outcome loss': 0.21044318952457808, 'Total loss': 0.21044318952457808}
2022-12-31 04:40:19,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:19,268 INFO:     Epoch: 21
2022-12-31 04:40:20,894 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4719976082444191, 'Total loss': 0.4719976082444191} | train loss {'Reaction outcome loss': 0.2035277508362964, 'Total loss': 0.2035277508362964}
2022-12-31 04:40:20,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:20,894 INFO:     Epoch: 22
2022-12-31 04:40:22,497 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4716058204571406, 'Total loss': 0.4716058204571406} | train loss {'Reaction outcome loss': 0.1997617358348636, 'Total loss': 0.1997617358348636}
2022-12-31 04:40:22,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:22,498 INFO:     Epoch: 23
2022-12-31 04:40:24,106 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4614247406522433, 'Total loss': 0.4614247406522433} | train loss {'Reaction outcome loss': 0.19467659766748274, 'Total loss': 0.19467659766748274}
2022-12-31 04:40:24,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:24,107 INFO:     Epoch: 24
2022-12-31 04:40:25,715 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4737743844588598, 'Total loss': 0.4737743844588598} | train loss {'Reaction outcome loss': 0.19288434104605034, 'Total loss': 0.19288434104605034}
2022-12-31 04:40:25,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:25,716 INFO:     Epoch: 25
2022-12-31 04:40:27,316 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49150856733322146, 'Total loss': 0.49150856733322146} | train loss {'Reaction outcome loss': 0.18568075262010098, 'Total loss': 0.18568075262010098}
2022-12-31 04:40:27,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:27,316 INFO:     Epoch: 26
2022-12-31 04:40:28,958 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4517437886757155, 'Total loss': 0.4517437886757155} | train loss {'Reaction outcome loss': 0.18394835075643254, 'Total loss': 0.18394835075643254}
2022-12-31 04:40:28,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:28,959 INFO:     Epoch: 27
2022-12-31 04:40:30,588 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4491836359103521, 'Total loss': 0.4491836359103521} | train loss {'Reaction outcome loss': 0.17917574338287443, 'Total loss': 0.17917574338287443}
2022-12-31 04:40:30,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:30,588 INFO:     Epoch: 28
2022-12-31 04:40:32,210 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47521931628386177, 'Total loss': 0.47521931628386177} | train loss {'Reaction outcome loss': 0.17560473576634986, 'Total loss': 0.17560473576634986}
2022-12-31 04:40:32,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:32,210 INFO:     Epoch: 29
2022-12-31 04:40:33,853 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46805011481046677, 'Total loss': 0.46805011481046677} | train loss {'Reaction outcome loss': 0.17939471302301566, 'Total loss': 0.17939471302301566}
2022-12-31 04:40:33,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:33,854 INFO:     Epoch: 30
2022-12-31 04:40:35,488 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45171452735861145, 'Total loss': 0.45171452735861145} | train loss {'Reaction outcome loss': 0.1730566440839252, 'Total loss': 0.1730566440839252}
2022-12-31 04:40:35,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:35,489 INFO:     Epoch: 31
2022-12-31 04:40:37,083 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4845551590124766, 'Total loss': 0.4845551590124766} | train loss {'Reaction outcome loss': 0.16676248552025238, 'Total loss': 0.16676248552025238}
2022-12-31 04:40:37,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:37,083 INFO:     Epoch: 32
2022-12-31 04:40:38,726 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4715805371602376, 'Total loss': 0.4715805371602376} | train loss {'Reaction outcome loss': 0.1659620591122043, 'Total loss': 0.1659620591122043}
2022-12-31 04:40:38,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:38,726 INFO:     Epoch: 33
2022-12-31 04:40:40,318 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.459130859375, 'Total loss': 0.459130859375} | train loss {'Reaction outcome loss': 0.16294007746489111, 'Total loss': 0.16294007746489111}
2022-12-31 04:40:40,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:40,319 INFO:     Epoch: 34
2022-12-31 04:40:41,950 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4638422484199206, 'Total loss': 0.4638422484199206} | train loss {'Reaction outcome loss': 0.16024673777895096, 'Total loss': 0.16024673777895096}
2022-12-31 04:40:41,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:41,950 INFO:     Epoch: 35
2022-12-31 04:40:43,557 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48469533324241637, 'Total loss': 0.48469533324241637} | train loss {'Reaction outcome loss': 0.16319358473705067, 'Total loss': 0.16319358473705067}
2022-12-31 04:40:43,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:43,558 INFO:     Epoch: 36
2022-12-31 04:40:45,152 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4775008698304494, 'Total loss': 0.4775008698304494} | train loss {'Reaction outcome loss': 0.1596663794377921, 'Total loss': 0.1596663794377921}
2022-12-31 04:40:45,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:45,152 INFO:     Epoch: 37
2022-12-31 04:40:46,760 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4590961247682571, 'Total loss': 0.4590961247682571} | train loss {'Reaction outcome loss': 0.1544130399973292, 'Total loss': 0.1544130399973292}
2022-12-31 04:40:46,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:46,761 INFO:     Epoch: 38
2022-12-31 04:40:48,360 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49178500175476075, 'Total loss': 0.49178500175476075} | train loss {'Reaction outcome loss': 0.15530733752572712, 'Total loss': 0.15530733752572712}
2022-12-31 04:40:48,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:48,360 INFO:     Epoch: 39
2022-12-31 04:40:50,004 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4624545102318128, 'Total loss': 0.4624545102318128} | train loss {'Reaction outcome loss': 0.15113066435678973, 'Total loss': 0.15113066435678973}
2022-12-31 04:40:50,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:50,004 INFO:     Epoch: 40
2022-12-31 04:40:51,648 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4637414216995239, 'Total loss': 0.4637414216995239} | train loss {'Reaction outcome loss': 0.15140943889993996, 'Total loss': 0.15140943889993996}
2022-12-31 04:40:51,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:51,649 INFO:     Epoch: 41
2022-12-31 04:40:53,249 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4900572662552198, 'Total loss': 0.4900572662552198} | train loss {'Reaction outcome loss': 0.1479613557389695, 'Total loss': 0.1479613557389695}
2022-12-31 04:40:53,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:53,250 INFO:     Epoch: 42
2022-12-31 04:40:54,882 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46581416539847853, 'Total loss': 0.46581416539847853} | train loss {'Reaction outcome loss': 0.1439864280405062, 'Total loss': 0.1439864280405062}
2022-12-31 04:40:54,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:54,882 INFO:     Epoch: 43
2022-12-31 04:40:56,525 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47486123541990916, 'Total loss': 0.47486123541990916} | train loss {'Reaction outcome loss': 0.142309307432887, 'Total loss': 0.142309307432887}
2022-12-31 04:40:56,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:56,526 INFO:     Epoch: 44
2022-12-31 04:40:58,137 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4591983874638875, 'Total loss': 0.4591983874638875} | train loss {'Reaction outcome loss': 0.1476681658668928, 'Total loss': 0.1476681658668928}
2022-12-31 04:40:58,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:58,138 INFO:     Epoch: 45
2022-12-31 04:40:59,744 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47499087850252786, 'Total loss': 0.47499087850252786} | train loss {'Reaction outcome loss': 0.14122847489323534, 'Total loss': 0.14122847489323534}
2022-12-31 04:40:59,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:40:59,744 INFO:     Epoch: 46
2022-12-31 04:41:01,352 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4969645063082377, 'Total loss': 0.4969645063082377} | train loss {'Reaction outcome loss': 0.13951837998770533, 'Total loss': 0.13951837998770533}
2022-12-31 04:41:01,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:01,352 INFO:     Epoch: 47
2022-12-31 04:41:02,951 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4612757503986359, 'Total loss': 0.4612757503986359} | train loss {'Reaction outcome loss': 0.14092327751246564, 'Total loss': 0.14092327751246564}
2022-12-31 04:41:02,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:02,951 INFO:     Epoch: 48
2022-12-31 04:41:04,595 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4853515605131785, 'Total loss': 0.4853515605131785} | train loss {'Reaction outcome loss': 0.13961543029876966, 'Total loss': 0.13961543029876966}
2022-12-31 04:41:04,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:04,595 INFO:     Epoch: 49
2022-12-31 04:41:06,236 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4614958941936493, 'Total loss': 0.4614958941936493} | train loss {'Reaction outcome loss': 0.13657407664895166, 'Total loss': 0.13657407664895166}
2022-12-31 04:41:06,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:06,237 INFO:     Epoch: 50
2022-12-31 04:41:07,868 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4907933841149012, 'Total loss': 0.4907933841149012} | train loss {'Reaction outcome loss': 0.13589704944496298, 'Total loss': 0.13589704944496298}
2022-12-31 04:41:07,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:07,868 INFO:     Epoch: 51
2022-12-31 04:41:09,511 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5473054250081381, 'Total loss': 0.5473054250081381} | train loss {'Reaction outcome loss': 0.13580480265523215, 'Total loss': 0.13580480265523215}
2022-12-31 04:41:09,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:09,511 INFO:     Epoch: 52
2022-12-31 04:41:11,154 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4367668164273103, 'Total loss': 0.4367668164273103} | train loss {'Reaction outcome loss': 0.1406012427329594, 'Total loss': 0.1406012427329594}
2022-12-31 04:41:11,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:11,155 INFO:     Epoch: 53
2022-12-31 04:41:12,759 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4765217403570811, 'Total loss': 0.4765217403570811} | train loss {'Reaction outcome loss': 0.1306954194986067, 'Total loss': 0.1306954194986067}
2022-12-31 04:41:12,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:12,759 INFO:     Epoch: 54
2022-12-31 04:41:14,402 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5368206828832627, 'Total loss': 0.5368206828832627} | train loss {'Reaction outcome loss': 0.13099543806233685, 'Total loss': 0.13099543806233685}
2022-12-31 04:41:14,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:14,402 INFO:     Epoch: 55
2022-12-31 04:41:16,009 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4593314747015635, 'Total loss': 0.4593314747015635} | train loss {'Reaction outcome loss': 0.13094459917061987, 'Total loss': 0.13094459917061987}
2022-12-31 04:41:16,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:16,009 INFO:     Epoch: 56
2022-12-31 04:41:17,652 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.494872643550237, 'Total loss': 0.494872643550237} | train loss {'Reaction outcome loss': 0.12756359054546654, 'Total loss': 0.12756359054546654}
2022-12-31 04:41:17,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:17,652 INFO:     Epoch: 57
2022-12-31 04:41:19,294 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48328600625197093, 'Total loss': 0.48328600625197093} | train loss {'Reaction outcome loss': 0.1304453555221632, 'Total loss': 0.1304453555221632}
2022-12-31 04:41:19,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:19,294 INFO:     Epoch: 58
2022-12-31 04:41:20,938 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47404354612032573, 'Total loss': 0.47404354612032573} | train loss {'Reaction outcome loss': 0.1273527918110564, 'Total loss': 0.1273527918110564}
2022-12-31 04:41:20,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:20,938 INFO:     Epoch: 59
2022-12-31 04:41:22,529 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4946909209092458, 'Total loss': 0.4946909209092458} | train loss {'Reaction outcome loss': 0.1274402616647901, 'Total loss': 0.1274402616647901}
2022-12-31 04:41:22,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:22,530 INFO:     Epoch: 60
2022-12-31 04:41:24,124 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4773595849672953, 'Total loss': 0.4773595849672953} | train loss {'Reaction outcome loss': 0.12443017684504895, 'Total loss': 0.12443017684504895}
2022-12-31 04:41:24,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:24,124 INFO:     Epoch: 61
2022-12-31 04:41:25,735 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45201277136802676, 'Total loss': 0.45201277136802676} | train loss {'Reaction outcome loss': 0.12801612399334272, 'Total loss': 0.12801612399334272}
2022-12-31 04:41:25,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:25,736 INFO:     Epoch: 62
2022-12-31 04:41:27,349 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46936528086662294, 'Total loss': 0.46936528086662294} | train loss {'Reaction outcome loss': 0.1309718730255634, 'Total loss': 0.1309718730255634}
2022-12-31 04:41:27,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:27,350 INFO:     Epoch: 63
2022-12-31 04:41:28,954 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44903644323349, 'Total loss': 0.44903644323349} | train loss {'Reaction outcome loss': 0.12621295776886818, 'Total loss': 0.12621295776886818}
2022-12-31 04:41:28,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:28,955 INFO:     Epoch: 64
2022-12-31 04:41:30,587 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4552135236561298, 'Total loss': 0.4552135236561298} | train loss {'Reaction outcome loss': 0.12472155038437946, 'Total loss': 0.12472155038437946}
2022-12-31 04:41:30,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:30,587 INFO:     Epoch: 65
2022-12-31 04:41:32,189 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4968711977203687, 'Total loss': 0.4968711977203687} | train loss {'Reaction outcome loss': 0.12272040846317515, 'Total loss': 0.12272040846317515}
2022-12-31 04:41:32,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:32,189 INFO:     Epoch: 66
2022-12-31 04:41:33,795 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45693870534499487, 'Total loss': 0.45693870534499487} | train loss {'Reaction outcome loss': 0.12677678202991902, 'Total loss': 0.12677678202991902}
2022-12-31 04:41:33,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:33,795 INFO:     Epoch: 67
2022-12-31 04:41:35,436 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49393223524093627, 'Total loss': 0.49393223524093627} | train loss {'Reaction outcome loss': 0.1237909971350879, 'Total loss': 0.1237909971350879}
2022-12-31 04:41:35,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:35,436 INFO:     Epoch: 68
2022-12-31 04:41:37,079 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46869017581144967, 'Total loss': 0.46869017581144967} | train loss {'Reaction outcome loss': 0.12027860701343407, 'Total loss': 0.12027860701343407}
2022-12-31 04:41:37,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:37,079 INFO:     Epoch: 69
2022-12-31 04:41:38,673 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.483271058400472, 'Total loss': 0.483271058400472} | train loss {'Reaction outcome loss': 0.12118608133539885, 'Total loss': 0.12118608133539885}
2022-12-31 04:41:38,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:38,673 INFO:     Epoch: 70
2022-12-31 04:41:40,270 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.527056090037028, 'Total loss': 0.527056090037028} | train loss {'Reaction outcome loss': 0.1239389120004116, 'Total loss': 0.1239389120004116}
2022-12-31 04:41:40,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:40,270 INFO:     Epoch: 71
2022-12-31 04:41:41,882 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4748900756239891, 'Total loss': 0.4748900756239891} | train loss {'Reaction outcome loss': 0.1179997934516342, 'Total loss': 0.1179997934516342}
2022-12-31 04:41:41,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:41,882 INFO:     Epoch: 72
2022-12-31 04:41:43,491 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46172931815187135, 'Total loss': 0.46172931815187135} | train loss {'Reaction outcome loss': 0.11866921407465683, 'Total loss': 0.11866921407465683}
2022-12-31 04:41:43,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:43,491 INFO:     Epoch: 73
2022-12-31 04:41:45,091 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.530612517396609, 'Total loss': 0.530612517396609} | train loss {'Reaction outcome loss': 0.11590824588696598, 'Total loss': 0.11590824588696598}
2022-12-31 04:41:45,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:45,091 INFO:     Epoch: 74
2022-12-31 04:41:46,735 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4849460393190384, 'Total loss': 0.4849460393190384} | train loss {'Reaction outcome loss': 0.11855355205420309, 'Total loss': 0.11855355205420309}
2022-12-31 04:41:46,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:46,735 INFO:     Epoch: 75
2022-12-31 04:41:48,333 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5053117076555887, 'Total loss': 0.5053117076555887} | train loss {'Reaction outcome loss': 0.11934611565627895, 'Total loss': 0.11934611565627895}
2022-12-31 04:41:48,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:48,333 INFO:     Epoch: 76
2022-12-31 04:41:49,934 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49630014101664227, 'Total loss': 0.49630014101664227} | train loss {'Reaction outcome loss': 0.11588668124920828, 'Total loss': 0.11588668124920828}
2022-12-31 04:41:49,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:49,934 INFO:     Epoch: 77
2022-12-31 04:41:51,549 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4575749781137953, 'Total loss': 0.4575749781137953} | train loss {'Reaction outcome loss': 0.11597068028715558, 'Total loss': 0.11597068028715558}
2022-12-31 04:41:51,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:51,549 INFO:     Epoch: 78
2022-12-31 04:41:53,147 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49023799697558085, 'Total loss': 0.49023799697558085} | train loss {'Reaction outcome loss': 0.11716458798495323, 'Total loss': 0.11716458798495323}
2022-12-31 04:41:53,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:53,147 INFO:     Epoch: 79
2022-12-31 04:41:54,755 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46714124232530596, 'Total loss': 0.46714124232530596} | train loss {'Reaction outcome loss': 0.12369854309708699, 'Total loss': 0.12369854309708699}
2022-12-31 04:41:54,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:54,755 INFO:     Epoch: 80
2022-12-31 04:41:56,367 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4424457927544912, 'Total loss': 0.4424457927544912} | train loss {'Reaction outcome loss': 0.11886673183146278, 'Total loss': 0.11886673183146278}
2022-12-31 04:41:56,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:56,367 INFO:     Epoch: 81
2022-12-31 04:41:57,972 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47986602584520976, 'Total loss': 0.47986602584520976} | train loss {'Reaction outcome loss': 0.11642050883441059, 'Total loss': 0.11642050883441059}
2022-12-31 04:41:57,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:57,973 INFO:     Epoch: 82
2022-12-31 04:41:59,585 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45119724832475183, 'Total loss': 0.45119724832475183} | train loss {'Reaction outcome loss': 0.11288822609283057, 'Total loss': 0.11288822609283057}
2022-12-31 04:41:59,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:41:59,585 INFO:     Epoch: 83
2022-12-31 04:42:01,190 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4870628962914149, 'Total loss': 0.4870628962914149} | train loss {'Reaction outcome loss': 0.11732372753799726, 'Total loss': 0.11732372753799726}
2022-12-31 04:42:01,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:01,190 INFO:     Epoch: 84
2022-12-31 04:42:02,831 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5124704877535502, 'Total loss': 0.5124704877535502} | train loss {'Reaction outcome loss': 0.11322362677641076, 'Total loss': 0.11322362677641076}
2022-12-31 04:42:02,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:02,831 INFO:     Epoch: 85
2022-12-31 04:42:04,476 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47345243965586026, 'Total loss': 0.47345243965586026} | train loss {'Reaction outcome loss': 0.11337534132483501, 'Total loss': 0.11337534132483501}
2022-12-31 04:42:04,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:04,476 INFO:     Epoch: 86
2022-12-31 04:42:06,067 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46954437494277956, 'Total loss': 0.46954437494277956} | train loss {'Reaction outcome loss': 0.11315650639598404, 'Total loss': 0.11315650639598404}
2022-12-31 04:42:06,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:06,068 INFO:     Epoch: 87
2022-12-31 04:42:07,674 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4529881993308663, 'Total loss': 0.4529881993308663} | train loss {'Reaction outcome loss': 0.11147961781049769, 'Total loss': 0.11147961781049769}
2022-12-31 04:42:07,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:07,674 INFO:     Epoch: 88
2022-12-31 04:42:09,318 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44867701406280197, 'Total loss': 0.44867701406280197} | train loss {'Reaction outcome loss': 0.11087613298400772, 'Total loss': 0.11087613298400772}
2022-12-31 04:42:09,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:09,318 INFO:     Epoch: 89
2022-12-31 04:42:10,915 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48446322083473203, 'Total loss': 0.48446322083473203} | train loss {'Reaction outcome loss': 0.11629306199540804, 'Total loss': 0.11629306199540804}
2022-12-31 04:42:10,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:10,915 INFO:     Epoch: 90
2022-12-31 04:42:12,559 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4955506853759289, 'Total loss': 0.4955506853759289} | train loss {'Reaction outcome loss': 0.1122203138008741, 'Total loss': 0.1122203138008741}
2022-12-31 04:42:12,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:12,559 INFO:     Epoch: 91
2022-12-31 04:42:14,205 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4580316652854284, 'Total loss': 0.4580316652854284} | train loss {'Reaction outcome loss': 0.12052762546429868, 'Total loss': 0.12052762546429868}
2022-12-31 04:42:14,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:14,205 INFO:     Epoch: 92
2022-12-31 04:42:15,797 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46153539617856343, 'Total loss': 0.46153539617856343} | train loss {'Reaction outcome loss': 0.11071942859387278, 'Total loss': 0.11071942859387278}
2022-12-31 04:42:15,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:15,797 INFO:     Epoch: 93
2022-12-31 04:42:17,428 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44580104351043703, 'Total loss': 0.44580104351043703} | train loss {'Reaction outcome loss': 0.11252626142082497, 'Total loss': 0.11252626142082497}
2022-12-31 04:42:17,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:17,429 INFO:     Epoch: 94
2022-12-31 04:42:19,034 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4682944983864824, 'Total loss': 0.4682944983864824} | train loss {'Reaction outcome loss': 0.10875273853772398, 'Total loss': 0.10875273853772398}
2022-12-31 04:42:19,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:19,034 INFO:     Epoch: 95
2022-12-31 04:42:20,638 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47345346013704936, 'Total loss': 0.47345346013704936} | train loss {'Reaction outcome loss': 0.1099070238833053, 'Total loss': 0.1099070238833053}
2022-12-31 04:42:20,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:20,638 INFO:     Epoch: 96
2022-12-31 04:42:22,281 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47561826308568317, 'Total loss': 0.47561826308568317} | train loss {'Reaction outcome loss': 0.11062016200629018, 'Total loss': 0.11062016200629018}
2022-12-31 04:42:22,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:22,281 INFO:     Epoch: 97
2022-12-31 04:42:23,924 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46579664250214897, 'Total loss': 0.46579664250214897} | train loss {'Reaction outcome loss': 0.10899705288849854, 'Total loss': 0.10899705288849854}
2022-12-31 04:42:23,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:23,924 INFO:     Epoch: 98
2022-12-31 04:42:25,557 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48136672178904216, 'Total loss': 0.48136672178904216} | train loss {'Reaction outcome loss': 0.10797460234532945, 'Total loss': 0.10797460234532945}
2022-12-31 04:42:25,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:25,557 INFO:     Epoch: 99
2022-12-31 04:42:27,161 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4623980700969696, 'Total loss': 0.4623980700969696} | train loss {'Reaction outcome loss': 0.11280093164074033, 'Total loss': 0.11280093164074033}
2022-12-31 04:42:27,161 INFO:     Best model found after epoch 13 of 100.
2022-12-31 04:42:27,162 INFO:   Done with stage: TRAINING
2022-12-31 04:42:27,162 INFO:   Starting stage: EVALUATION
2022-12-31 04:42:27,305 INFO:   Done with stage: EVALUATION
2022-12-31 04:42:27,306 INFO:   Leaving out SEQ value Fold_4
2022-12-31 04:42:27,318 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 04:42:27,318 INFO:   Starting stage: FEATURE SCALING
2022-12-31 04:42:27,963 INFO:   Done with stage: FEATURE SCALING
2022-12-31 04:42:27,964 INFO:   Starting stage: SCALING TARGETS
2022-12-31 04:42:28,036 INFO:   Done with stage: SCALING TARGETS
2022-12-31 04:42:28,036 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:42:28,036 INFO:     No hyperparam tuning for this model
2022-12-31 04:42:28,036 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:42:28,036 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 04:42:28,037 INFO:     None feature selector for col prot
2022-12-31 04:42:28,037 INFO:     None feature selector for col prot
2022-12-31 04:42:28,037 INFO:     None feature selector for col prot
2022-12-31 04:42:28,037 INFO:     None feature selector for col chem
2022-12-31 04:42:28,037 INFO:     None feature selector for col chem
2022-12-31 04:42:28,038 INFO:     None feature selector for col chem
2022-12-31 04:42:28,038 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 04:42:28,038 INFO:   Starting stage: BUILD MODEL
2022-12-31 04:42:28,039 INFO:     Number of params in model 224011
2022-12-31 04:42:28,043 INFO:   Done with stage: BUILD MODEL
2022-12-31 04:42:28,043 INFO:   Starting stage: TRAINING
2022-12-31 04:42:28,087 INFO:     Val loss before train {'Reaction outcome loss': 0.9383630474408468, 'Total loss': 0.9383630474408468}
2022-12-31 04:42:28,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:28,087 INFO:     Epoch: 0
2022-12-31 04:42:29,696 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.56188911596934, 'Total loss': 0.56188911596934} | train loss {'Reaction outcome loss': 0.7580970107916021, 'Total loss': 0.7580970107916021}
2022-12-31 04:42:29,696 INFO:     Found new best model at epoch 0
2022-12-31 04:42:29,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:29,697 INFO:     Epoch: 1
2022-12-31 04:42:31,314 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4847717106342316, 'Total loss': 0.4847717106342316} | train loss {'Reaction outcome loss': 0.4964119862778571, 'Total loss': 0.4964119862778571}
2022-12-31 04:42:31,314 INFO:     Found new best model at epoch 1
2022-12-31 04:42:31,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:31,315 INFO:     Epoch: 2
2022-12-31 04:42:32,926 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.471845797697703, 'Total loss': 0.471845797697703} | train loss {'Reaction outcome loss': 0.4350416988026405, 'Total loss': 0.4350416988026405}
2022-12-31 04:42:32,926 INFO:     Found new best model at epoch 2
2022-12-31 04:42:32,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:32,927 INFO:     Epoch: 3
2022-12-31 04:42:34,544 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.42187620997428893, 'Total loss': 0.42187620997428893} | train loss {'Reaction outcome loss': 0.3991855992463188, 'Total loss': 0.3991855992463188}
2022-12-31 04:42:34,545 INFO:     Found new best model at epoch 3
2022-12-31 04:42:34,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:34,546 INFO:     Epoch: 4
2022-12-31 04:42:36,164 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.40918412506580354, 'Total loss': 0.40918412506580354} | train loss {'Reaction outcome loss': 0.370717811566926, 'Total loss': 0.370717811566926}
2022-12-31 04:42:36,164 INFO:     Found new best model at epoch 4
2022-12-31 04:42:36,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:36,165 INFO:     Epoch: 5
2022-12-31 04:42:37,772 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3998333752155304, 'Total loss': 0.3998333752155304} | train loss {'Reaction outcome loss': 0.35944454949619115, 'Total loss': 0.35944454949619115}
2022-12-31 04:42:37,772 INFO:     Found new best model at epoch 5
2022-12-31 04:42:37,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:37,773 INFO:     Epoch: 6
2022-12-31 04:42:39,393 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42267306248346964, 'Total loss': 0.42267306248346964} | train loss {'Reaction outcome loss': 0.35024780604610406, 'Total loss': 0.35024780604610406}
2022-12-31 04:42:39,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:39,393 INFO:     Epoch: 7
2022-12-31 04:42:41,030 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.39338351686795553, 'Total loss': 0.39338351686795553} | train loss {'Reaction outcome loss': 0.31969442307983653, 'Total loss': 0.31969442307983653}
2022-12-31 04:42:41,030 INFO:     Found new best model at epoch 7
2022-12-31 04:42:41,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:41,031 INFO:     Epoch: 8
2022-12-31 04:42:42,644 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.39129273196061454, 'Total loss': 0.39129273196061454} | train loss {'Reaction outcome loss': 0.29499306484285626, 'Total loss': 0.29499306484285626}
2022-12-31 04:42:42,644 INFO:     Found new best model at epoch 8
2022-12-31 04:42:42,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:42,645 INFO:     Epoch: 9
2022-12-31 04:42:44,256 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.37804916004339856, 'Total loss': 0.37804916004339856} | train loss {'Reaction outcome loss': 0.2816627834819382, 'Total loss': 0.2816627834819382}
2022-12-31 04:42:44,256 INFO:     Found new best model at epoch 9
2022-12-31 04:42:44,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:44,257 INFO:     Epoch: 10
2022-12-31 04:42:45,873 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.38069212436676025, 'Total loss': 0.38069212436676025} | train loss {'Reaction outcome loss': 0.274713805080324, 'Total loss': 0.274713805080324}
2022-12-31 04:42:45,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:45,873 INFO:     Epoch: 11
2022-12-31 04:42:47,482 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44157561759154, 'Total loss': 0.44157561759154} | train loss {'Reaction outcome loss': 0.27408124594660255, 'Total loss': 0.27408124594660255}
2022-12-31 04:42:47,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:47,483 INFO:     Epoch: 12
2022-12-31 04:42:49,095 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39952351450920104, 'Total loss': 0.39952351450920104} | train loss {'Reaction outcome loss': 0.2516681937824773, 'Total loss': 0.2516681937824773}
2022-12-31 04:42:49,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:49,095 INFO:     Epoch: 13
2022-12-31 04:42:50,708 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3863148053487142, 'Total loss': 0.3863148053487142} | train loss {'Reaction outcome loss': 0.24198849972816644, 'Total loss': 0.24198849972816644}
2022-12-31 04:42:50,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:50,709 INFO:     Epoch: 14
2022-12-31 04:42:52,316 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.37727343042691547, 'Total loss': 0.37727343042691547} | train loss {'Reaction outcome loss': 0.2285167863322557, 'Total loss': 0.2285167863322557}
2022-12-31 04:42:52,317 INFO:     Found new best model at epoch 14
2022-12-31 04:42:52,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:52,318 INFO:     Epoch: 15
2022-12-31 04:42:53,936 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3756833329796791, 'Total loss': 0.3756833329796791} | train loss {'Reaction outcome loss': 0.22812466435573078, 'Total loss': 0.22812466435573078}
2022-12-31 04:42:53,936 INFO:     Found new best model at epoch 15
2022-12-31 04:42:53,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:53,937 INFO:     Epoch: 16
2022-12-31 04:42:55,552 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3662768224875132, 'Total loss': 0.3662768224875132} | train loss {'Reaction outcome loss': 0.22173411366057352, 'Total loss': 0.22173411366057352}
2022-12-31 04:42:55,552 INFO:     Found new best model at epoch 16
2022-12-31 04:42:55,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:55,553 INFO:     Epoch: 17
2022-12-31 04:42:57,177 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3745366563399633, 'Total loss': 0.3745366563399633} | train loss {'Reaction outcome loss': 0.21529328589584085, 'Total loss': 0.21529328589584085}
2022-12-31 04:42:57,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:57,177 INFO:     Epoch: 18
2022-12-31 04:42:58,800 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4024412274360657, 'Total loss': 0.4024412274360657} | train loss {'Reaction outcome loss': 0.21672001096645754, 'Total loss': 0.21672001096645754}
2022-12-31 04:42:58,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:42:58,801 INFO:     Epoch: 19
2022-12-31 04:43:00,422 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38172226349512733, 'Total loss': 0.38172226349512733} | train loss {'Reaction outcome loss': 0.19853495353838324, 'Total loss': 0.19853495353838324}
2022-12-31 04:43:00,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:00,422 INFO:     Epoch: 20
2022-12-31 04:43:02,065 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3727341562509537, 'Total loss': 0.3727341562509537} | train loss {'Reaction outcome loss': 0.19592834459984695, 'Total loss': 0.19592834459984695}
2022-12-31 04:43:02,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:02,065 INFO:     Epoch: 21
2022-12-31 04:43:03,781 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.36540381113688153, 'Total loss': 0.36540381113688153} | train loss {'Reaction outcome loss': 0.19042870760777209, 'Total loss': 0.19042870760777209}
2022-12-31 04:43:03,781 INFO:     Found new best model at epoch 21
2022-12-31 04:43:03,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:03,782 INFO:     Epoch: 22
2022-12-31 04:43:05,397 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.37093738118807473, 'Total loss': 0.37093738118807473} | train loss {'Reaction outcome loss': 0.18417936688427394, 'Total loss': 0.18417936688427394}
2022-12-31 04:43:05,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:05,398 INFO:     Epoch: 23
2022-12-31 04:43:07,022 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3345956395069758, 'Total loss': 0.3345956395069758} | train loss {'Reaction outcome loss': 0.18076200459379016, 'Total loss': 0.18076200459379016}
2022-12-31 04:43:07,023 INFO:     Found new best model at epoch 23
2022-12-31 04:43:07,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:07,024 INFO:     Epoch: 24
2022-12-31 04:43:08,645 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.36976069112618765, 'Total loss': 0.36976069112618765} | train loss {'Reaction outcome loss': 0.17811475694854406, 'Total loss': 0.17811475694854406}
2022-12-31 04:43:08,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:08,646 INFO:     Epoch: 25
2022-12-31 04:43:10,321 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3659307440121969, 'Total loss': 0.3659307440121969} | train loss {'Reaction outcome loss': 0.17281183763391353, 'Total loss': 0.17281183763391353}
2022-12-31 04:43:10,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:10,321 INFO:     Epoch: 26
2022-12-31 04:43:11,938 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.37968337337176006, 'Total loss': 0.37968337337176006} | train loss {'Reaction outcome loss': 0.1701628830101665, 'Total loss': 0.1701628830101665}
2022-12-31 04:43:11,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:11,939 INFO:     Epoch: 27
2022-12-31 04:43:13,555 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4195392966270447, 'Total loss': 0.4195392966270447} | train loss {'Reaction outcome loss': 0.165249396593013, 'Total loss': 0.165249396593013}
2022-12-31 04:43:13,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:13,555 INFO:     Epoch: 28
2022-12-31 04:43:15,240 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4015989422798157, 'Total loss': 0.4015989422798157} | train loss {'Reaction outcome loss': 0.16590172015771648, 'Total loss': 0.16590172015771648}
2022-12-31 04:43:15,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:15,241 INFO:     Epoch: 29
2022-12-31 04:43:16,859 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3813171217838923, 'Total loss': 0.3813171217838923} | train loss {'Reaction outcome loss': 0.19109777595334942, 'Total loss': 0.19109777595334942}
2022-12-31 04:43:16,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:16,859 INFO:     Epoch: 30
2022-12-31 04:43:18,518 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.37988539536794025, 'Total loss': 0.37988539536794025} | train loss {'Reaction outcome loss': 0.16200276778334333, 'Total loss': 0.16200276778334333}
2022-12-31 04:43:18,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:18,519 INFO:     Epoch: 31
2022-12-31 04:43:20,140 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39772385557492573, 'Total loss': 0.39772385557492573} | train loss {'Reaction outcome loss': 0.16136203653728654, 'Total loss': 0.16136203653728654}
2022-12-31 04:43:20,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:20,140 INFO:     Epoch: 32
2022-12-31 04:43:21,798 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3556774144371351, 'Total loss': 0.3556774144371351} | train loss {'Reaction outcome loss': 0.15419853791135593, 'Total loss': 0.15419853791135593}
2022-12-31 04:43:21,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:21,798 INFO:     Epoch: 33
2022-12-31 04:43:23,443 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39531390368938446, 'Total loss': 0.39531390368938446} | train loss {'Reaction outcome loss': 0.15717737253694591, 'Total loss': 0.15717737253694591}
2022-12-31 04:43:23,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:23,444 INFO:     Epoch: 34
2022-12-31 04:43:25,064 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40916838496923447, 'Total loss': 0.40916838496923447} | train loss {'Reaction outcome loss': 0.15037870484714708, 'Total loss': 0.15037870484714708}
2022-12-31 04:43:25,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:25,065 INFO:     Epoch: 35
2022-12-31 04:43:26,724 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38475084404150645, 'Total loss': 0.38475084404150645} | train loss {'Reaction outcome loss': 0.14501861367740354, 'Total loss': 0.14501861367740354}
2022-12-31 04:43:26,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:26,725 INFO:     Epoch: 36
2022-12-31 04:43:28,381 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38802933792273203, 'Total loss': 0.38802933792273203} | train loss {'Reaction outcome loss': 0.14198975199900998, 'Total loss': 0.14198975199900998}
2022-12-31 04:43:28,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:28,381 INFO:     Epoch: 37
2022-12-31 04:43:29,985 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4284023722012838, 'Total loss': 0.4284023722012838} | train loss {'Reaction outcome loss': 0.1433111601256077, 'Total loss': 0.1433111601256077}
2022-12-31 04:43:29,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:29,985 INFO:     Epoch: 38
2022-12-31 04:43:31,601 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.38396627008914946, 'Total loss': 0.38396627008914946} | train loss {'Reaction outcome loss': 0.14170675856260367, 'Total loss': 0.14170675856260367}
2022-12-31 04:43:31,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:31,601 INFO:     Epoch: 39
2022-12-31 04:43:33,216 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3945279002189636, 'Total loss': 0.3945279002189636} | train loss {'Reaction outcome loss': 0.14183999714908208, 'Total loss': 0.14183999714908208}
2022-12-31 04:43:33,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:33,216 INFO:     Epoch: 40
2022-12-31 04:43:34,837 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37667524615923564, 'Total loss': 0.37667524615923564} | train loss {'Reaction outcome loss': 0.14158686846048626, 'Total loss': 0.14158686846048626}
2022-12-31 04:43:34,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:34,839 INFO:     Epoch: 41
2022-12-31 04:43:36,464 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39536377365390457, 'Total loss': 0.39536377365390457} | train loss {'Reaction outcome loss': 0.13953614889201624, 'Total loss': 0.13953614889201624}
2022-12-31 04:43:36,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:36,465 INFO:     Epoch: 42
2022-12-31 04:43:38,088 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3902109831571579, 'Total loss': 0.3902109831571579} | train loss {'Reaction outcome loss': 0.13419090405807146, 'Total loss': 0.13419090405807146}
2022-12-31 04:43:38,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:38,089 INFO:     Epoch: 43
2022-12-31 04:43:39,748 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44104749858379366, 'Total loss': 0.44104749858379366} | train loss {'Reaction outcome loss': 0.13379587919073369, 'Total loss': 0.13379587919073369}
2022-12-31 04:43:39,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:39,748 INFO:     Epoch: 44
2022-12-31 04:43:41,365 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.393189729253451, 'Total loss': 0.393189729253451} | train loss {'Reaction outcome loss': 0.13310830446378374, 'Total loss': 0.13310830446378374}
2022-12-31 04:43:41,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:41,366 INFO:     Epoch: 45
2022-12-31 04:43:42,996 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3808233412603537, 'Total loss': 0.3808233412603537} | train loss {'Reaction outcome loss': 0.13380646937108343, 'Total loss': 0.13380646937108343}
2022-12-31 04:43:42,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:42,996 INFO:     Epoch: 46
2022-12-31 04:43:44,626 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41166126827398936, 'Total loss': 0.41166126827398936} | train loss {'Reaction outcome loss': 0.13244638383143273, 'Total loss': 0.13244638383143273}
2022-12-31 04:43:44,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:44,626 INFO:     Epoch: 47
2022-12-31 04:43:46,257 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3811695039272308, 'Total loss': 0.3811695039272308} | train loss {'Reaction outcome loss': 0.13270391363260822, 'Total loss': 0.13270391363260822}
2022-12-31 04:43:46,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:46,257 INFO:     Epoch: 48
2022-12-31 04:43:47,877 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39795501381158827, 'Total loss': 0.39795501381158827} | train loss {'Reaction outcome loss': 0.12749565826038303, 'Total loss': 0.12749565826038303}
2022-12-31 04:43:47,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:47,878 INFO:     Epoch: 49
2022-12-31 04:43:49,507 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4292895396550496, 'Total loss': 0.4292895396550496} | train loss {'Reaction outcome loss': 0.1248991120863112, 'Total loss': 0.1248991120863112}
2022-12-31 04:43:49,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:49,507 INFO:     Epoch: 50
2022-12-31 04:43:51,126 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4213286531468233, 'Total loss': 0.4213286531468233} | train loss {'Reaction outcome loss': 0.12262499701701281, 'Total loss': 0.12262499701701281}
2022-12-31 04:43:51,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:51,126 INFO:     Epoch: 51
2022-12-31 04:43:52,750 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3868665128946304, 'Total loss': 0.3868665128946304} | train loss {'Reaction outcome loss': 0.1286403192842018, 'Total loss': 0.1286403192842018}
2022-12-31 04:43:52,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:52,751 INFO:     Epoch: 52
2022-12-31 04:43:54,372 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41392508099476494, 'Total loss': 0.41392508099476494} | train loss {'Reaction outcome loss': 0.12737735127692745, 'Total loss': 0.12737735127692745}
2022-12-31 04:43:54,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:54,373 INFO:     Epoch: 53
2022-12-31 04:43:55,984 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42832190990448, 'Total loss': 0.42832190990448} | train loss {'Reaction outcome loss': 0.12450422585412077, 'Total loss': 0.12450422585412077}
2022-12-31 04:43:55,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:55,984 INFO:     Epoch: 54
2022-12-31 04:43:57,611 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4126985584696134, 'Total loss': 0.4126985584696134} | train loss {'Reaction outcome loss': 0.1249295814885282, 'Total loss': 0.1249295814885282}
2022-12-31 04:43:57,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:57,612 INFO:     Epoch: 55
2022-12-31 04:43:59,239 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38815406189921003, 'Total loss': 0.38815406189921003} | train loss {'Reaction outcome loss': 0.12544764896544316, 'Total loss': 0.12544764896544316}
2022-12-31 04:43:59,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:43:59,239 INFO:     Epoch: 56
2022-12-31 04:44:00,854 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.418949160973231, 'Total loss': 0.418949160973231} | train loss {'Reaction outcome loss': 0.12861294246676666, 'Total loss': 0.12861294246676666}
2022-12-31 04:44:00,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:00,854 INFO:     Epoch: 57
2022-12-31 04:44:02,477 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4275981843471527, 'Total loss': 0.4275981843471527} | train loss {'Reaction outcome loss': 0.12347342813281222, 'Total loss': 0.12347342813281222}
2022-12-31 04:44:02,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:02,477 INFO:     Epoch: 58
2022-12-31 04:44:04,104 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4187559872865677, 'Total loss': 0.4187559872865677} | train loss {'Reaction outcome loss': 0.12247358467183127, 'Total loss': 0.12247358467183127}
2022-12-31 04:44:04,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:04,104 INFO:     Epoch: 59
2022-12-31 04:44:05,723 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4161294102668762, 'Total loss': 0.4161294102668762} | train loss {'Reaction outcome loss': 0.11944055137818382, 'Total loss': 0.11944055137818382}
2022-12-31 04:44:05,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:05,724 INFO:     Epoch: 60
2022-12-31 04:44:07,350 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41084616581598915, 'Total loss': 0.41084616581598915} | train loss {'Reaction outcome loss': 0.11642510361211927, 'Total loss': 0.11642510361211927}
2022-12-31 04:44:07,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:07,350 INFO:     Epoch: 61
2022-12-31 04:44:08,977 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4068163201212883, 'Total loss': 0.4068163201212883} | train loss {'Reaction outcome loss': 0.12083216637045657, 'Total loss': 0.12083216637045657}
2022-12-31 04:44:08,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:08,977 INFO:     Epoch: 62
2022-12-31 04:44:10,637 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4172789106766383, 'Total loss': 0.4172789106766383} | train loss {'Reaction outcome loss': 0.12018088844775195, 'Total loss': 0.12018088844775195}
2022-12-31 04:44:10,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:10,637 INFO:     Epoch: 63
2022-12-31 04:44:12,298 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4353012988964717, 'Total loss': 0.4353012988964717} | train loss {'Reaction outcome loss': 0.1183373576377694, 'Total loss': 0.1183373576377694}
2022-12-31 04:44:12,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:12,298 INFO:     Epoch: 64
2022-12-31 04:44:13,919 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40682161748409273, 'Total loss': 0.40682161748409273} | train loss {'Reaction outcome loss': 0.11652324143075758, 'Total loss': 0.11652324143075758}
2022-12-31 04:44:13,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:13,919 INFO:     Epoch: 65
2022-12-31 04:44:15,570 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46901792138814924, 'Total loss': 0.46901792138814924} | train loss {'Reaction outcome loss': 0.11948917928806412, 'Total loss': 0.11948917928806412}
2022-12-31 04:44:15,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:15,570 INFO:     Epoch: 66
2022-12-31 04:44:17,201 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4183157746990522, 'Total loss': 0.4183157746990522} | train loss {'Reaction outcome loss': 0.11696648044660148, 'Total loss': 0.11696648044660148}
2022-12-31 04:44:17,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:17,201 INFO:     Epoch: 67
2022-12-31 04:44:18,818 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3815150551497936, 'Total loss': 0.3815150551497936} | train loss {'Reaction outcome loss': 0.14296176510148487, 'Total loss': 0.14296176510148487}
2022-12-31 04:44:18,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:18,818 INFO:     Epoch: 68
2022-12-31 04:44:20,450 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4003529022137324, 'Total loss': 0.4003529022137324} | train loss {'Reaction outcome loss': 0.11808741997584297, 'Total loss': 0.11808741997584297}
2022-12-31 04:44:20,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:20,450 INFO:     Epoch: 69
2022-12-31 04:44:22,080 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4299374217788378, 'Total loss': 0.4299374217788378} | train loss {'Reaction outcome loss': 0.11560671595667583, 'Total loss': 0.11560671595667583}
2022-12-31 04:44:22,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:22,081 INFO:     Epoch: 70
2022-12-31 04:44:23,709 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4226768255233765, 'Total loss': 0.4226768255233765} | train loss {'Reaction outcome loss': 0.11287540136312389, 'Total loss': 0.11287540136312389}
2022-12-31 04:44:23,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:23,709 INFO:     Epoch: 71
2022-12-31 04:44:25,330 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4276690443356832, 'Total loss': 0.4276690443356832} | train loss {'Reaction outcome loss': 0.11359524202924913, 'Total loss': 0.11359524202924913}
2022-12-31 04:44:25,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:25,331 INFO:     Epoch: 72
2022-12-31 04:44:26,943 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4066895514726639, 'Total loss': 0.4066895514726639} | train loss {'Reaction outcome loss': 0.11303550375133994, 'Total loss': 0.11303550375133994}
2022-12-31 04:44:26,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:26,944 INFO:     Epoch: 73
2022-12-31 04:44:28,560 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4467359552780787, 'Total loss': 0.4467359552780787} | train loss {'Reaction outcome loss': 0.11351188714784718, 'Total loss': 0.11351188714784718}
2022-12-31 04:44:28,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:28,561 INFO:     Epoch: 74
2022-12-31 04:44:30,177 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4331079736351967, 'Total loss': 0.4331079736351967} | train loss {'Reaction outcome loss': 0.11386360150114026, 'Total loss': 0.11386360150114026}
2022-12-31 04:44:30,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:30,178 INFO:     Epoch: 75
2022-12-31 04:44:31,838 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4352919568618139, 'Total loss': 0.4352919568618139} | train loss {'Reaction outcome loss': 0.10804540674739721, 'Total loss': 0.10804540674739721}
2022-12-31 04:44:31,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:31,838 INFO:     Epoch: 76
2022-12-31 04:44:33,456 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4306065703431765, 'Total loss': 0.4306065703431765} | train loss {'Reaction outcome loss': 0.11181590293407667, 'Total loss': 0.11181590293407667}
2022-12-31 04:44:33,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:33,456 INFO:     Epoch: 77
2022-12-31 04:44:35,081 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4363858034213384, 'Total loss': 0.4363858034213384} | train loss {'Reaction outcome loss': 0.10967768468106152, 'Total loss': 0.10967768468106152}
2022-12-31 04:44:35,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:35,081 INFO:     Epoch: 78
2022-12-31 04:44:36,690 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.427249043683211, 'Total loss': 0.427249043683211} | train loss {'Reaction outcome loss': 0.11562073415911257, 'Total loss': 0.11562073415911257}
2022-12-31 04:44:36,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:36,692 INFO:     Epoch: 79
2022-12-31 04:44:38,307 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44291237493356067, 'Total loss': 0.44291237493356067} | train loss {'Reaction outcome loss': 0.11092344561568124, 'Total loss': 0.11092344561568124}
2022-12-31 04:44:38,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:38,307 INFO:     Epoch: 80
2022-12-31 04:44:39,967 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46098341047763824, 'Total loss': 0.46098341047763824} | train loss {'Reaction outcome loss': 0.1074721718007071, 'Total loss': 0.1074721718007071}
2022-12-31 04:44:39,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:39,967 INFO:     Epoch: 81
2022-12-31 04:44:41,594 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45557603041330974, 'Total loss': 0.45557603041330974} | train loss {'Reaction outcome loss': 0.11056467702323773, 'Total loss': 0.11056467702323773}
2022-12-31 04:44:41,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:41,594 INFO:     Epoch: 82
2022-12-31 04:44:43,254 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44097468852996824, 'Total loss': 0.44097468852996824} | train loss {'Reaction outcome loss': 0.11098843576749368, 'Total loss': 0.11098843576749368}
2022-12-31 04:44:43,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:43,255 INFO:     Epoch: 83
2022-12-31 04:44:44,868 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43545631965001425, 'Total loss': 0.43545631965001425} | train loss {'Reaction outcome loss': 0.11097315062894611, 'Total loss': 0.11097315062894611}
2022-12-31 04:44:44,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:44,868 INFO:     Epoch: 84
2022-12-31 04:44:46,487 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42047846019268037, 'Total loss': 0.42047846019268037} | train loss {'Reaction outcome loss': 0.10841278865724313, 'Total loss': 0.10841278865724313}
2022-12-31 04:44:46,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:46,487 INFO:     Epoch: 85
2022-12-31 04:44:48,127 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4280998607476552, 'Total loss': 0.4280998607476552} | train loss {'Reaction outcome loss': 0.11816687083236226, 'Total loss': 0.11816687083236226}
2022-12-31 04:44:48,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:48,127 INFO:     Epoch: 86
2022-12-31 04:44:49,746 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44739331205685934, 'Total loss': 0.44739331205685934} | train loss {'Reaction outcome loss': 0.1225232752554618, 'Total loss': 0.1225232752554618}
2022-12-31 04:44:49,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:49,746 INFO:     Epoch: 87
2022-12-31 04:44:51,373 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4158279329538345, 'Total loss': 0.4158279329538345} | train loss {'Reaction outcome loss': 0.11151169664715754, 'Total loss': 0.11151169664715754}
2022-12-31 04:44:51,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:51,373 INFO:     Epoch: 88
2022-12-31 04:44:53,001 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39603783388932545, 'Total loss': 0.39603783388932545} | train loss {'Reaction outcome loss': 0.10832017775153846, 'Total loss': 0.10832017775153846}
2022-12-31 04:44:53,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:53,001 INFO:     Epoch: 89
2022-12-31 04:44:54,621 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42018373012542726, 'Total loss': 0.42018373012542726} | train loss {'Reaction outcome loss': 0.10575041695773361, 'Total loss': 0.10575041695773361}
2022-12-31 04:44:54,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:54,621 INFO:     Epoch: 90
2022-12-31 04:44:56,248 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4053556481997172, 'Total loss': 0.4053556481997172} | train loss {'Reaction outcome loss': 0.10849813789093826, 'Total loss': 0.10849813789093826}
2022-12-31 04:44:56,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:56,249 INFO:     Epoch: 91
2022-12-31 04:44:57,878 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4381504168113073, 'Total loss': 0.4381504168113073} | train loss {'Reaction outcome loss': 0.11081500034155053, 'Total loss': 0.11081500034155053}
2022-12-31 04:44:57,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:57,878 INFO:     Epoch: 92
2022-12-31 04:44:59,496 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41938297847906747, 'Total loss': 0.41938297847906747} | train loss {'Reaction outcome loss': 0.12273655036599097, 'Total loss': 0.12273655036599097}
2022-12-31 04:44:59,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:44:59,496 INFO:     Epoch: 93
2022-12-31 04:45:01,124 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41960914731025695, 'Total loss': 0.41960914731025695} | train loss {'Reaction outcome loss': 0.10701598629835184, 'Total loss': 0.10701598629835184}
2022-12-31 04:45:01,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:01,124 INFO:     Epoch: 94
2022-12-31 04:45:02,751 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44516584773858386, 'Total loss': 0.44516584773858386} | train loss {'Reaction outcome loss': 0.10518748528978693, 'Total loss': 0.10518748528978693}
2022-12-31 04:45:02,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:02,751 INFO:     Epoch: 95
2022-12-31 04:45:04,369 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4464829092224439, 'Total loss': 0.4464829092224439} | train loss {'Reaction outcome loss': 0.12397847323006937, 'Total loss': 0.12397847323006937}
2022-12-31 04:45:04,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:04,370 INFO:     Epoch: 96
2022-12-31 04:45:05,999 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4236952858666579, 'Total loss': 0.4236952858666579} | train loss {'Reaction outcome loss': 0.10447772910592376, 'Total loss': 0.10447772910592376}
2022-12-31 04:45:05,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:05,999 INFO:     Epoch: 97
2022-12-31 04:45:07,626 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43694425572951634, 'Total loss': 0.43694425572951634} | train loss {'Reaction outcome loss': 0.10180965735955819, 'Total loss': 0.10180965735955819}
2022-12-31 04:45:07,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:07,628 INFO:     Epoch: 98
2022-12-31 04:45:09,246 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40842627982298535, 'Total loss': 0.40842627982298535} | train loss {'Reaction outcome loss': 0.10414835723855978, 'Total loss': 0.10414835723855978}
2022-12-31 04:45:09,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:09,247 INFO:     Epoch: 99
2022-12-31 04:45:10,875 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4205207169055939, 'Total loss': 0.4205207169055939} | train loss {'Reaction outcome loss': 0.10427214865542381, 'Total loss': 0.10427214865542381}
2022-12-31 04:45:10,875 INFO:     Best model found after epoch 24 of 100.
2022-12-31 04:45:10,875 INFO:   Done with stage: TRAINING
2022-12-31 04:45:10,876 INFO:   Starting stage: EVALUATION
2022-12-31 04:45:11,008 INFO:   Done with stage: EVALUATION
2022-12-31 04:45:11,008 INFO:   Leaving out SEQ value Fold_5
2022-12-31 04:45:11,020 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 04:45:11,020 INFO:   Starting stage: FEATURE SCALING
2022-12-31 04:45:11,660 INFO:   Done with stage: FEATURE SCALING
2022-12-31 04:45:11,660 INFO:   Starting stage: SCALING TARGETS
2022-12-31 04:45:11,733 INFO:   Done with stage: SCALING TARGETS
2022-12-31 04:45:11,733 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:45:11,733 INFO:     No hyperparam tuning for this model
2022-12-31 04:45:11,733 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:45:11,733 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 04:45:11,734 INFO:     None feature selector for col prot
2022-12-31 04:45:11,734 INFO:     None feature selector for col prot
2022-12-31 04:45:11,734 INFO:     None feature selector for col prot
2022-12-31 04:45:11,734 INFO:     None feature selector for col chem
2022-12-31 04:45:11,735 INFO:     None feature selector for col chem
2022-12-31 04:45:11,735 INFO:     None feature selector for col chem
2022-12-31 04:45:11,735 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 04:45:11,735 INFO:   Starting stage: BUILD MODEL
2022-12-31 04:45:11,736 INFO:     Number of params in model 224011
2022-12-31 04:45:11,740 INFO:   Done with stage: BUILD MODEL
2022-12-31 04:45:11,740 INFO:   Starting stage: TRAINING
2022-12-31 04:45:11,783 INFO:     Val loss before train {'Reaction outcome loss': 0.9614084482192993, 'Total loss': 0.9614084482192993}
2022-12-31 04:45:11,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:11,784 INFO:     Epoch: 0
2022-12-31 04:45:13,394 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6051595369974773, 'Total loss': 0.6051595369974773} | train loss {'Reaction outcome loss': 0.7759640535231733, 'Total loss': 0.7759640535231733}
2022-12-31 04:45:13,395 INFO:     Found new best model at epoch 0
2022-12-31 04:45:13,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:13,396 INFO:     Epoch: 1
2022-12-31 04:45:14,997 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5140066107114156, 'Total loss': 0.5140066107114156} | train loss {'Reaction outcome loss': 0.5132445486775343, 'Total loss': 0.5132445486775343}
2022-12-31 04:45:14,998 INFO:     Found new best model at epoch 1
2022-12-31 04:45:14,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:14,999 INFO:     Epoch: 2
2022-12-31 04:45:16,610 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4893108328183492, 'Total loss': 0.4893108328183492} | train loss {'Reaction outcome loss': 0.447442978335396, 'Total loss': 0.447442978335396}
2022-12-31 04:45:16,610 INFO:     Found new best model at epoch 2
2022-12-31 04:45:16,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:16,611 INFO:     Epoch: 3
2022-12-31 04:45:18,228 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4725872357686361, 'Total loss': 0.4725872357686361} | train loss {'Reaction outcome loss': 0.4089496592743039, 'Total loss': 0.4089496592743039}
2022-12-31 04:45:18,228 INFO:     Found new best model at epoch 3
2022-12-31 04:45:18,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:18,229 INFO:     Epoch: 4
2022-12-31 04:45:19,857 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4299072682857513, 'Total loss': 0.4299072682857513} | train loss {'Reaction outcome loss': 0.38508622869984177, 'Total loss': 0.38508622869984177}
2022-12-31 04:45:19,857 INFO:     Found new best model at epoch 4
2022-12-31 04:45:19,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:19,858 INFO:     Epoch: 5
2022-12-31 04:45:21,484 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4474181224902471, 'Total loss': 0.4474181224902471} | train loss {'Reaction outcome loss': 0.36287358993380936, 'Total loss': 0.36287358993380936}
2022-12-31 04:45:21,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:21,484 INFO:     Epoch: 6
2022-12-31 04:45:23,144 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43513158957163495, 'Total loss': 0.43513158957163495} | train loss {'Reaction outcome loss': 0.34321319131582195, 'Total loss': 0.34321319131582195}
2022-12-31 04:45:23,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:23,145 INFO:     Epoch: 7
2022-12-31 04:45:24,805 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43687356611092887, 'Total loss': 0.43687356611092887} | train loss {'Reaction outcome loss': 0.3235954863417462, 'Total loss': 0.3235954863417462}
2022-12-31 04:45:24,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:24,805 INFO:     Epoch: 8
2022-12-31 04:45:26,425 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.423470006386439, 'Total loss': 0.423470006386439} | train loss {'Reaction outcome loss': 0.30948940076463705, 'Total loss': 0.30948940076463705}
2022-12-31 04:45:26,425 INFO:     Found new best model at epoch 8
2022-12-31 04:45:26,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:26,427 INFO:     Epoch: 9
2022-12-31 04:45:28,044 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40375876824061074, 'Total loss': 0.40375876824061074} | train loss {'Reaction outcome loss': 0.29438254755644966, 'Total loss': 0.29438254755644966}
2022-12-31 04:45:28,045 INFO:     Found new best model at epoch 9
2022-12-31 04:45:28,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:28,046 INFO:     Epoch: 10
2022-12-31 04:45:29,664 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4150229682524999, 'Total loss': 0.4150229682524999} | train loss {'Reaction outcome loss': 0.28924355302275956, 'Total loss': 0.28924355302275956}
2022-12-31 04:45:29,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:29,664 INFO:     Epoch: 11
2022-12-31 04:45:30,935 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4276999314626058, 'Total loss': 0.4276999314626058} | train loss {'Reaction outcome loss': 0.27550616456141724, 'Total loss': 0.27550616456141724}
2022-12-31 04:45:30,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:30,935 INFO:     Epoch: 12
2022-12-31 04:45:32,049 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4104050904512405, 'Total loss': 0.4104050904512405} | train loss {'Reaction outcome loss': 0.26233632331345474, 'Total loss': 0.26233632331345474}
2022-12-31 04:45:32,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:32,050 INFO:     Epoch: 13
2022-12-31 04:45:33,166 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40386944587032, 'Total loss': 0.40386944587032} | train loss {'Reaction outcome loss': 0.25196355606928683, 'Total loss': 0.25196355606928683}
2022-12-31 04:45:33,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:33,166 INFO:     Epoch: 14
2022-12-31 04:45:34,317 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4244906087716421, 'Total loss': 0.4244906087716421} | train loss {'Reaction outcome loss': 0.24424030553495538, 'Total loss': 0.24424030553495538}
2022-12-31 04:45:34,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:34,317 INFO:     Epoch: 15
2022-12-31 04:45:35,782 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3971132661526402, 'Total loss': 0.3971132661526402} | train loss {'Reaction outcome loss': 0.23559735132300336, 'Total loss': 0.23559735132300336}
2022-12-31 04:45:35,783 INFO:     Found new best model at epoch 15
2022-12-31 04:45:35,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:35,784 INFO:     Epoch: 16
2022-12-31 04:45:37,395 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4361299554506938, 'Total loss': 0.4361299554506938} | train loss {'Reaction outcome loss': 0.22841670495788846, 'Total loss': 0.22841670495788846}
2022-12-31 04:45:37,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:37,396 INFO:     Epoch: 17
2022-12-31 04:45:39,011 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4334757626056671, 'Total loss': 0.4334757626056671} | train loss {'Reaction outcome loss': 0.22206027605136405, 'Total loss': 0.22206027605136405}
2022-12-31 04:45:39,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:39,011 INFO:     Epoch: 18
2022-12-31 04:45:40,671 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4000607730820775, 'Total loss': 0.4000607730820775} | train loss {'Reaction outcome loss': 0.2182660443561516, 'Total loss': 0.2182660443561516}
2022-12-31 04:45:40,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:40,671 INFO:     Epoch: 19
2022-12-31 04:45:42,286 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.393302828570207, 'Total loss': 0.393302828570207} | train loss {'Reaction outcome loss': 0.2094189240867137, 'Total loss': 0.2094189240867137}
2022-12-31 04:45:42,287 INFO:     Found new best model at epoch 19
2022-12-31 04:45:42,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:42,288 INFO:     Epoch: 20
2022-12-31 04:45:43,882 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4024739305178324, 'Total loss': 0.4024739305178324} | train loss {'Reaction outcome loss': 0.20479879894064387, 'Total loss': 0.20479879894064387}
2022-12-31 04:45:43,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:43,883 INFO:     Epoch: 21
2022-12-31 04:45:45,497 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4352968064447244, 'Total loss': 0.4352968064447244} | train loss {'Reaction outcome loss': 0.20572851506480272, 'Total loss': 0.20572851506480272}
2022-12-31 04:45:45,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:45,498 INFO:     Epoch: 22
2022-12-31 04:45:47,158 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41248201827208203, 'Total loss': 0.41248201827208203} | train loss {'Reaction outcome loss': 0.19810208333723678, 'Total loss': 0.19810208333723678}
2022-12-31 04:45:47,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:47,158 INFO:     Epoch: 23
2022-12-31 04:45:48,774 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43692999680836997, 'Total loss': 0.43692999680836997} | train loss {'Reaction outcome loss': 0.2029413288000269, 'Total loss': 0.2029413288000269}
2022-12-31 04:45:48,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:48,774 INFO:     Epoch: 24
2022-12-31 04:45:50,435 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40885701129833857, 'Total loss': 0.40885701129833857} | train loss {'Reaction outcome loss': 0.20052741770442759, 'Total loss': 0.20052741770442759}
2022-12-31 04:45:50,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:50,435 INFO:     Epoch: 25
2022-12-31 04:45:52,075 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43315627574920657, 'Total loss': 0.43315627574920657} | train loss {'Reaction outcome loss': 0.18528992509801764, 'Total loss': 0.18528992509801764}
2022-12-31 04:45:52,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:52,075 INFO:     Epoch: 26
2022-12-31 04:45:53,686 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44358939230442046, 'Total loss': 0.44358939230442046} | train loss {'Reaction outcome loss': 0.18158364385675194, 'Total loss': 0.18158364385675194}
2022-12-31 04:45:53,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:53,686 INFO:     Epoch: 27
2022-12-31 04:45:55,339 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4055171320835749, 'Total loss': 0.4055171320835749} | train loss {'Reaction outcome loss': 0.17429257344026378, 'Total loss': 0.17429257344026378}
2022-12-31 04:45:55,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:55,339 INFO:     Epoch: 28
2022-12-31 04:45:56,958 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4260734309752782, 'Total loss': 0.4260734309752782} | train loss {'Reaction outcome loss': 0.17427529146189571, 'Total loss': 0.17427529146189571}
2022-12-31 04:45:56,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:56,959 INFO:     Epoch: 29
2022-12-31 04:45:58,577 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4318532317876816, 'Total loss': 0.4318532317876816} | train loss {'Reaction outcome loss': 0.16999893822619502, 'Total loss': 0.16999893822619502}
2022-12-31 04:45:58,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:45:58,577 INFO:     Epoch: 30
2022-12-31 04:46:00,238 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40462118685245513, 'Total loss': 0.40462118685245513} | train loss {'Reaction outcome loss': 0.1670903812122086, 'Total loss': 0.1670903812122086}
2022-12-31 04:46:00,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:00,238 INFO:     Epoch: 31
2022-12-31 04:46:01,869 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44329892893632256, 'Total loss': 0.44329892893632256} | train loss {'Reaction outcome loss': 0.16873479653251075, 'Total loss': 0.16873479653251075}
2022-12-31 04:46:01,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:01,870 INFO:     Epoch: 32
2022-12-31 04:46:03,494 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43538578748703005, 'Total loss': 0.43538578748703005} | train loss {'Reaction outcome loss': 0.164783655591579, 'Total loss': 0.164783655591579}
2022-12-31 04:46:03,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:03,495 INFO:     Epoch: 33
2022-12-31 04:46:05,121 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4056848873694738, 'Total loss': 0.4056848873694738} | train loss {'Reaction outcome loss': 0.16685855223297857, 'Total loss': 0.16685855223297857}
2022-12-31 04:46:05,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:05,121 INFO:     Epoch: 34
2022-12-31 04:46:06,744 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4425002555052439, 'Total loss': 0.4425002555052439} | train loss {'Reaction outcome loss': 0.1629775499366561, 'Total loss': 0.1629775499366561}
2022-12-31 04:46:06,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:06,744 INFO:     Epoch: 35
2022-12-31 04:46:08,365 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.418507331609726, 'Total loss': 0.418507331609726} | train loss {'Reaction outcome loss': 0.15782204420184312, 'Total loss': 0.15782204420184312}
2022-12-31 04:46:08,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:08,366 INFO:     Epoch: 36
2022-12-31 04:46:09,985 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.419394692281882, 'Total loss': 0.419394692281882} | train loss {'Reaction outcome loss': 0.1557375282677673, 'Total loss': 0.1557375282677673}
2022-12-31 04:46:09,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:09,985 INFO:     Epoch: 37
2022-12-31 04:46:11,596 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4235515624284744, 'Total loss': 0.4235515624284744} | train loss {'Reaction outcome loss': 0.15438295652469, 'Total loss': 0.15438295652469}
2022-12-31 04:46:11,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:11,596 INFO:     Epoch: 38
2022-12-31 04:46:13,229 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4076060285170873, 'Total loss': 0.4076060285170873} | train loss {'Reaction outcome loss': 0.15618758888888187, 'Total loss': 0.15618758888888187}
2022-12-31 04:46:13,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:13,230 INFO:     Epoch: 39
2022-12-31 04:46:14,851 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.451378188530604, 'Total loss': 0.451378188530604} | train loss {'Reaction outcome loss': 0.15292617923958038, 'Total loss': 0.15292617923958038}
2022-12-31 04:46:14,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:14,851 INFO:     Epoch: 40
2022-12-31 04:46:16,529 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4308234969774882, 'Total loss': 0.4308234969774882} | train loss {'Reaction outcome loss': 0.15063317724760028, 'Total loss': 0.15063317724760028}
2022-12-31 04:46:16,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:16,529 INFO:     Epoch: 41
2022-12-31 04:46:18,162 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41585976084073384, 'Total loss': 0.41585976084073384} | train loss {'Reaction outcome loss': 0.14858577513149468, 'Total loss': 0.14858577513149468}
2022-12-31 04:46:18,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:18,163 INFO:     Epoch: 42
2022-12-31 04:46:19,810 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40243448813756305, 'Total loss': 0.40243448813756305} | train loss {'Reaction outcome loss': 0.15121358539149893, 'Total loss': 0.15121358539149893}
2022-12-31 04:46:19,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:19,811 INFO:     Epoch: 43
2022-12-31 04:46:21,413 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4435080260038376, 'Total loss': 0.4435080260038376} | train loss {'Reaction outcome loss': 0.14369328542059098, 'Total loss': 0.14369328542059098}
2022-12-31 04:46:21,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:21,413 INFO:     Epoch: 44
2022-12-31 04:46:23,067 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43235992391904193, 'Total loss': 0.43235992391904193} | train loss {'Reaction outcome loss': 0.14534922494161603, 'Total loss': 0.14534922494161603}
2022-12-31 04:46:23,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:23,067 INFO:     Epoch: 45
2022-12-31 04:46:24,729 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43062558869520823, 'Total loss': 0.43062558869520823} | train loss {'Reaction outcome loss': 0.14147992534226037, 'Total loss': 0.14147992534226037}
2022-12-31 04:46:24,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:24,729 INFO:     Epoch: 46
2022-12-31 04:46:26,457 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43865111072858176, 'Total loss': 0.43865111072858176} | train loss {'Reaction outcome loss': 0.14279353714791004, 'Total loss': 0.14279353714791004}
2022-12-31 04:46:26,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:26,457 INFO:     Epoch: 47
2022-12-31 04:46:28,177 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43509242633978523, 'Total loss': 0.43509242633978523} | train loss {'Reaction outcome loss': 0.14207401817290793, 'Total loss': 0.14207401817290793}
2022-12-31 04:46:28,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:28,178 INFO:     Epoch: 48
2022-12-31 04:46:29,816 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40640786588191985, 'Total loss': 0.40640786588191985} | train loss {'Reaction outcome loss': 0.1388418391510825, 'Total loss': 0.1388418391510825}
2022-12-31 04:46:29,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:29,817 INFO:     Epoch: 49
2022-12-31 04:46:31,454 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41010079234838487, 'Total loss': 0.41010079234838487} | train loss {'Reaction outcome loss': 0.1371711795370135, 'Total loss': 0.1371711795370135}
2022-12-31 04:46:31,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:31,454 INFO:     Epoch: 50
2022-12-31 04:46:33,064 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41078066527843476, 'Total loss': 0.41078066527843476} | train loss {'Reaction outcome loss': 0.13595205234604943, 'Total loss': 0.13595205234604943}
2022-12-31 04:46:33,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:33,065 INFO:     Epoch: 51
2022-12-31 04:46:34,675 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4162748803695043, 'Total loss': 0.4162748803695043} | train loss {'Reaction outcome loss': 0.14284721204160672, 'Total loss': 0.14284721204160672}
2022-12-31 04:46:34,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:34,675 INFO:     Epoch: 52
2022-12-31 04:46:36,311 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4007275482018789, 'Total loss': 0.4007275482018789} | train loss {'Reaction outcome loss': 0.14658141844304645, 'Total loss': 0.14658141844304645}
2022-12-31 04:46:36,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:36,311 INFO:     Epoch: 53
2022-12-31 04:46:37,952 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4207168956597646, 'Total loss': 0.4207168956597646} | train loss {'Reaction outcome loss': 0.137568237884362, 'Total loss': 0.137568237884362}
2022-12-31 04:46:37,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:37,953 INFO:     Epoch: 54
2022-12-31 04:46:39,571 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39191886881987253, 'Total loss': 0.39191886881987253} | train loss {'Reaction outcome loss': 0.12968262595350624, 'Total loss': 0.12968262595350624}
2022-12-31 04:46:39,571 INFO:     Found new best model at epoch 54
2022-12-31 04:46:39,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:39,572 INFO:     Epoch: 55
2022-12-31 04:46:41,192 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4430708428223928, 'Total loss': 0.4430708428223928} | train loss {'Reaction outcome loss': 0.13279282337095102, 'Total loss': 0.13279282337095102}
2022-12-31 04:46:41,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:41,192 INFO:     Epoch: 56
2022-12-31 04:46:42,817 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42228796407580377, 'Total loss': 0.42228796407580377} | train loss {'Reaction outcome loss': 0.14493316154339878, 'Total loss': 0.14493316154339878}
2022-12-31 04:46:42,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:42,818 INFO:     Epoch: 57
2022-12-31 04:46:44,442 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38007735162973405, 'Total loss': 0.38007735162973405} | train loss {'Reaction outcome loss': 0.13476295138610547, 'Total loss': 0.13476295138610547}
2022-12-31 04:46:44,442 INFO:     Found new best model at epoch 57
2022-12-31 04:46:44,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:44,443 INFO:     Epoch: 58
2022-12-31 04:46:46,066 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43078184326489766, 'Total loss': 0.43078184326489766} | train loss {'Reaction outcome loss': 0.12801732138420144, 'Total loss': 0.12801732138420144}
2022-12-31 04:46:46,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:46,066 INFO:     Epoch: 59
2022-12-31 04:46:47,707 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3920917461315791, 'Total loss': 0.3920917461315791} | train loss {'Reaction outcome loss': 0.13158823473993148, 'Total loss': 0.13158823473993148}
2022-12-31 04:46:47,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:47,707 INFO:     Epoch: 60
2022-12-31 04:46:49,327 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4034647007783254, 'Total loss': 0.4034647007783254} | train loss {'Reaction outcome loss': 0.12636515976139007, 'Total loss': 0.12636515976139007}
2022-12-31 04:46:49,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:49,329 INFO:     Epoch: 61
2022-12-31 04:46:50,949 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4162304868300756, 'Total loss': 0.4162304868300756} | train loss {'Reaction outcome loss': 0.12891719359195913, 'Total loss': 0.12891719359195913}
2022-12-31 04:46:50,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:50,949 INFO:     Epoch: 62
2022-12-31 04:46:52,575 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40593486030896503, 'Total loss': 0.40593486030896503} | train loss {'Reaction outcome loss': 0.12862769370722293, 'Total loss': 0.12862769370722293}
2022-12-31 04:46:52,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:52,575 INFO:     Epoch: 63
2022-12-31 04:46:54,202 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4379483610391617, 'Total loss': 0.4379483610391617} | train loss {'Reaction outcome loss': 0.13956279070892683, 'Total loss': 0.13956279070892683}
2022-12-31 04:46:54,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:54,203 INFO:     Epoch: 64
2022-12-31 04:46:55,830 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.425487414537929, 'Total loss': 0.425487414537929} | train loss {'Reaction outcome loss': 0.17806095197000474, 'Total loss': 0.17806095197000474}
2022-12-31 04:46:55,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:55,831 INFO:     Epoch: 65
2022-12-31 04:46:57,447 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42805443505446117, 'Total loss': 0.42805443505446117} | train loss {'Reaction outcome loss': 0.13689147778938565, 'Total loss': 0.13689147778938565}
2022-12-31 04:46:57,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:57,448 INFO:     Epoch: 66
2022-12-31 04:46:59,069 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41365658640861513, 'Total loss': 0.41365658640861513} | train loss {'Reaction outcome loss': 0.12501065059895272, 'Total loss': 0.12501065059895272}
2022-12-31 04:46:59,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:46:59,069 INFO:     Epoch: 67
2022-12-31 04:47:00,731 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42288699448108674, 'Total loss': 0.42288699448108674} | train loss {'Reaction outcome loss': 0.12367910033419216, 'Total loss': 0.12367910033419216}
2022-12-31 04:47:00,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:00,731 INFO:     Epoch: 68
2022-12-31 04:47:02,349 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39665701786677043, 'Total loss': 0.39665701786677043} | train loss {'Reaction outcome loss': 0.12202263383917761, 'Total loss': 0.12202263383917761}
2022-12-31 04:47:02,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:02,349 INFO:     Epoch: 69
2022-12-31 04:47:04,010 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40858053267002103, 'Total loss': 0.40858053267002103} | train loss {'Reaction outcome loss': 0.11958690654159415, 'Total loss': 0.11958690654159415}
2022-12-31 04:47:04,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:04,010 INFO:     Epoch: 70
2022-12-31 04:47:05,635 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4522999942302704, 'Total loss': 0.4522999942302704} | train loss {'Reaction outcome loss': 0.11692720849954429, 'Total loss': 0.11692720849954429}
2022-12-31 04:47:05,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:05,635 INFO:     Epoch: 71
2022-12-31 04:47:07,244 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4371054574847221, 'Total loss': 0.4371054574847221} | train loss {'Reaction outcome loss': 0.12348806371936508, 'Total loss': 0.12348806371936508}
2022-12-31 04:47:07,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:07,244 INFO:     Epoch: 72
2022-12-31 04:47:08,905 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3989081343015035, 'Total loss': 0.3989081343015035} | train loss {'Reaction outcome loss': 0.12158226326181502, 'Total loss': 0.12158226326181502}
2022-12-31 04:47:08,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:08,906 INFO:     Epoch: 73
2022-12-31 04:47:10,521 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4391261195143064, 'Total loss': 0.4391261195143064} | train loss {'Reaction outcome loss': 0.12316516384590363, 'Total loss': 0.12316516384590363}
2022-12-31 04:47:10,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:10,521 INFO:     Epoch: 74
2022-12-31 04:47:12,182 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40427976548671724, 'Total loss': 0.40427976548671724} | train loss {'Reaction outcome loss': 0.12296388786880003, 'Total loss': 0.12296388786880003}
2022-12-31 04:47:12,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:12,182 INFO:     Epoch: 75
2022-12-31 04:47:13,801 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43249248564243314, 'Total loss': 0.43249248564243314} | train loss {'Reaction outcome loss': 0.12722069794184843, 'Total loss': 0.12722069794184843}
2022-12-31 04:47:13,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:13,802 INFO:     Epoch: 76
2022-12-31 04:47:15,447 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39562150835990906, 'Total loss': 0.39562150835990906} | train loss {'Reaction outcome loss': 0.1239819751732495, 'Total loss': 0.1239819751732495}
2022-12-31 04:47:15,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:15,448 INFO:     Epoch: 77
2022-12-31 04:47:17,108 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4038046638170878, 'Total loss': 0.4038046638170878} | train loss {'Reaction outcome loss': 0.13166818630955843, 'Total loss': 0.13166818630955843}
2022-12-31 04:47:17,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:17,108 INFO:     Epoch: 78
2022-12-31 04:47:18,726 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4411554048458735, 'Total loss': 0.4411554048458735} | train loss {'Reaction outcome loss': 0.12855696405851, 'Total loss': 0.12855696405851}
2022-12-31 04:47:18,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:18,727 INFO:     Epoch: 79
2022-12-31 04:47:20,344 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4043204148610433, 'Total loss': 0.4043204148610433} | train loss {'Reaction outcome loss': 0.11554432310937124, 'Total loss': 0.11554432310937124}
2022-12-31 04:47:20,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:20,345 INFO:     Epoch: 80
2022-12-31 04:47:21,962 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4423724576830864, 'Total loss': 0.4423724576830864} | train loss {'Reaction outcome loss': 0.11374720177053055, 'Total loss': 0.11374720177053055}
2022-12-31 04:47:21,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:21,962 INFO:     Epoch: 81
2022-12-31 04:47:23,594 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43055723756551745, 'Total loss': 0.43055723756551745} | train loss {'Reaction outcome loss': 0.12009349730742279, 'Total loss': 0.12009349730742279}
2022-12-31 04:47:23,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:23,594 INFO:     Epoch: 82
2022-12-31 04:47:25,213 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4048858980337779, 'Total loss': 0.4048858980337779} | train loss {'Reaction outcome loss': 0.11794758145781774, 'Total loss': 0.11794758145781774}
2022-12-31 04:47:25,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:25,213 INFO:     Epoch: 83
2022-12-31 04:47:26,842 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41246945460637413, 'Total loss': 0.41246945460637413} | train loss {'Reaction outcome loss': 0.11392799262830522, 'Total loss': 0.11392799262830522}
2022-12-31 04:47:26,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:26,843 INFO:     Epoch: 84
2022-12-31 04:47:28,471 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40501226087411246, 'Total loss': 0.40501226087411246} | train loss {'Reaction outcome loss': 0.11918797361492606, 'Total loss': 0.11918797361492606}
2022-12-31 04:47:28,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:28,472 INFO:     Epoch: 85
2022-12-31 04:47:30,101 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4385680596033732, 'Total loss': 0.4385680596033732} | train loss {'Reaction outcome loss': 0.11766667602637755, 'Total loss': 0.11766667602637755}
2022-12-31 04:47:30,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:30,101 INFO:     Epoch: 86
2022-12-31 04:47:31,727 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4515500545501709, 'Total loss': 0.4515500545501709} | train loss {'Reaction outcome loss': 0.11500851119057769, 'Total loss': 0.11500851119057769}
2022-12-31 04:47:31,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:31,727 INFO:     Epoch: 87
2022-12-31 04:47:33,344 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4475862125555674, 'Total loss': 0.4475862125555674} | train loss {'Reaction outcome loss': 0.11425662892060759, 'Total loss': 0.11425662892060759}
2022-12-31 04:47:33,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:33,345 INFO:     Epoch: 88
2022-12-31 04:47:34,952 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4195570568243662, 'Total loss': 0.4195570568243662} | train loss {'Reaction outcome loss': 0.12448685234744188, 'Total loss': 0.12448685234744188}
2022-12-31 04:47:34,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:34,952 INFO:     Epoch: 89
2022-12-31 04:47:36,612 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.442474623521169, 'Total loss': 0.442474623521169} | train loss {'Reaction outcome loss': 0.11605288249615958, 'Total loss': 0.11605288249615958}
2022-12-31 04:47:36,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:36,612 INFO:     Epoch: 90
2022-12-31 04:47:38,226 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40919592678546907, 'Total loss': 0.40919592678546907} | train loss {'Reaction outcome loss': 0.11703484003236804, 'Total loss': 0.11703484003236804}
2022-12-31 04:47:38,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:38,226 INFO:     Epoch: 91
2022-12-31 04:47:39,885 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4412725269794464, 'Total loss': 0.4412725269794464} | train loss {'Reaction outcome loss': 0.1162069007160439, 'Total loss': 0.1162069007160439}
2022-12-31 04:47:39,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:39,886 INFO:     Epoch: 92
2022-12-31 04:47:41,504 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4588702589273453, 'Total loss': 0.4588702589273453} | train loss {'Reaction outcome loss': 0.11129291808870419, 'Total loss': 0.11129291808870419}
2022-12-31 04:47:41,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:41,504 INFO:     Epoch: 93
2022-12-31 04:47:43,140 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39858264128367105, 'Total loss': 0.39858264128367105} | train loss {'Reaction outcome loss': 0.11143143873190295, 'Total loss': 0.11143143873190295}
2022-12-31 04:47:43,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:43,140 INFO:     Epoch: 94
2022-12-31 04:47:44,799 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44491905768712364, 'Total loss': 0.44491905768712364} | train loss {'Reaction outcome loss': 0.11075402290764717, 'Total loss': 0.11075402290764717}
2022-12-31 04:47:44,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:44,799 INFO:     Epoch: 95
2022-12-31 04:47:46,458 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41679877291123074, 'Total loss': 0.41679877291123074} | train loss {'Reaction outcome loss': 0.1116479867369112, 'Total loss': 0.1116479867369112}
2022-12-31 04:47:46,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:46,458 INFO:     Epoch: 96
2022-12-31 04:47:48,117 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4441927815477053, 'Total loss': 0.4441927815477053} | train loss {'Reaction outcome loss': 0.10883387739338196, 'Total loss': 0.10883387739338196}
2022-12-31 04:47:48,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:48,117 INFO:     Epoch: 97
2022-12-31 04:47:49,777 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4271109730005264, 'Total loss': 0.4271109730005264} | train loss {'Reaction outcome loss': 0.10908942585587468, 'Total loss': 0.10908942585587468}
2022-12-31 04:47:49,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:49,777 INFO:     Epoch: 98
2022-12-31 04:47:51,396 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4250797212123871, 'Total loss': 0.4250797212123871} | train loss {'Reaction outcome loss': 0.11515037955351821, 'Total loss': 0.11515037955351821}
2022-12-31 04:47:51,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:51,397 INFO:     Epoch: 99
2022-12-31 04:47:53,015 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42081064780553185, 'Total loss': 0.42081064780553185} | train loss {'Reaction outcome loss': 0.11447472088342614, 'Total loss': 0.11447472088342614}
2022-12-31 04:47:53,015 INFO:     Best model found after epoch 58 of 100.
2022-12-31 04:47:53,016 INFO:   Done with stage: TRAINING
2022-12-31 04:47:53,016 INFO:   Starting stage: EVALUATION
2022-12-31 04:47:53,146 INFO:   Done with stage: EVALUATION
2022-12-31 04:47:53,146 INFO:   Leaving out SEQ value Fold_6
2022-12-31 04:47:53,158 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 04:47:53,159 INFO:   Starting stage: FEATURE SCALING
2022-12-31 04:47:53,798 INFO:   Done with stage: FEATURE SCALING
2022-12-31 04:47:53,798 INFO:   Starting stage: SCALING TARGETS
2022-12-31 04:47:53,871 INFO:   Done with stage: SCALING TARGETS
2022-12-31 04:47:53,871 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:47:53,871 INFO:     No hyperparam tuning for this model
2022-12-31 04:47:53,871 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:47:53,872 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 04:47:53,872 INFO:     None feature selector for col prot
2022-12-31 04:47:53,872 INFO:     None feature selector for col prot
2022-12-31 04:47:53,872 INFO:     None feature selector for col prot
2022-12-31 04:47:53,873 INFO:     None feature selector for col chem
2022-12-31 04:47:53,873 INFO:     None feature selector for col chem
2022-12-31 04:47:53,873 INFO:     None feature selector for col chem
2022-12-31 04:47:53,873 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 04:47:53,873 INFO:   Starting stage: BUILD MODEL
2022-12-31 04:47:53,875 INFO:     Number of params in model 224011
2022-12-31 04:47:53,878 INFO:   Done with stage: BUILD MODEL
2022-12-31 04:47:53,878 INFO:   Starting stage: TRAINING
2022-12-31 04:47:53,923 INFO:     Val loss before train {'Reaction outcome loss': 1.0050116578737895, 'Total loss': 1.0050116578737895}
2022-12-31 04:47:53,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:53,923 INFO:     Epoch: 0
2022-12-31 04:47:55,536 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5497550169626871, 'Total loss': 0.5497550169626871} | train loss {'Reaction outcome loss': 0.7595357673944555, 'Total loss': 0.7595357673944555}
2022-12-31 04:47:55,536 INFO:     Found new best model at epoch 0
2022-12-31 04:47:55,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:55,537 INFO:     Epoch: 1
2022-12-31 04:47:57,145 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4597175121307373, 'Total loss': 0.4597175121307373} | train loss {'Reaction outcome loss': 0.5044303362028323, 'Total loss': 0.5044303362028323}
2022-12-31 04:47:57,145 INFO:     Found new best model at epoch 1
2022-12-31 04:47:57,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:57,146 INFO:     Epoch: 2
2022-12-31 04:47:58,761 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.43243975937366486, 'Total loss': 0.43243975937366486} | train loss {'Reaction outcome loss': 0.440005040579084, 'Total loss': 0.440005040579084}
2022-12-31 04:47:58,762 INFO:     Found new best model at epoch 2
2022-12-31 04:47:58,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:47:58,763 INFO:     Epoch: 3
2022-12-31 04:48:00,421 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.44367913007736204, 'Total loss': 0.44367913007736204} | train loss {'Reaction outcome loss': 0.40145036716864485, 'Total loss': 0.40145036716864485}
2022-12-31 04:48:00,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:00,422 INFO:     Epoch: 4
2022-12-31 04:48:02,038 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4159578263759613, 'Total loss': 0.4159578263759613} | train loss {'Reaction outcome loss': 0.37626661559435254, 'Total loss': 0.37626661559435254}
2022-12-31 04:48:02,038 INFO:     Found new best model at epoch 4
2022-12-31 04:48:02,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:02,040 INFO:     Epoch: 5
2022-12-31 04:48:03,648 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4091008643309275, 'Total loss': 0.4091008643309275} | train loss {'Reaction outcome loss': 0.35332551926336053, 'Total loss': 0.35332551926336053}
2022-12-31 04:48:03,648 INFO:     Found new best model at epoch 5
2022-12-31 04:48:03,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:03,649 INFO:     Epoch: 6
2022-12-31 04:48:05,264 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4026653160651525, 'Total loss': 0.4026653160651525} | train loss {'Reaction outcome loss': 0.338966524893202, 'Total loss': 0.338966524893202}
2022-12-31 04:48:05,264 INFO:     Found new best model at epoch 6
2022-12-31 04:48:05,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:05,265 INFO:     Epoch: 7
2022-12-31 04:48:06,884 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4116353472073873, 'Total loss': 0.4116353472073873} | train loss {'Reaction outcome loss': 0.3180871812080074, 'Total loss': 0.3180871812080074}
2022-12-31 04:48:06,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:06,884 INFO:     Epoch: 8
2022-12-31 04:48:08,532 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.38903946479161583, 'Total loss': 0.38903946479161583} | train loss {'Reaction outcome loss': 0.3037151497370307, 'Total loss': 0.3037151497370307}
2022-12-31 04:48:08,532 INFO:     Found new best model at epoch 8
2022-12-31 04:48:08,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:08,533 INFO:     Epoch: 9
2022-12-31 04:48:10,144 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41594952046871186, 'Total loss': 0.41594952046871186} | train loss {'Reaction outcome loss': 0.290159168051711, 'Total loss': 0.290159168051711}
2022-12-31 04:48:10,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:10,145 INFO:     Epoch: 10
2022-12-31 04:48:11,758 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.37746962706247966, 'Total loss': 0.37746962706247966} | train loss {'Reaction outcome loss': 0.2787604842434529, 'Total loss': 0.2787604842434529}
2022-12-31 04:48:11,759 INFO:     Found new best model at epoch 10
2022-12-31 04:48:11,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:11,760 INFO:     Epoch: 11
2022-12-31 04:48:13,373 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.37935137152671816, 'Total loss': 0.37935137152671816} | train loss {'Reaction outcome loss': 0.26531751050640817, 'Total loss': 0.26531751050640817}
2022-12-31 04:48:13,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:13,373 INFO:     Epoch: 12
2022-12-31 04:48:15,034 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40948580304781595, 'Total loss': 0.40948580304781595} | train loss {'Reaction outcome loss': 0.25589918762916175, 'Total loss': 0.25589918762916175}
2022-12-31 04:48:15,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:15,034 INFO:     Epoch: 13
2022-12-31 04:48:16,649 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.38826912542184194, 'Total loss': 0.38826912542184194} | train loss {'Reaction outcome loss': 0.24594539389068235, 'Total loss': 0.24594539389068235}
2022-12-31 04:48:16,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:16,649 INFO:     Epoch: 14
2022-12-31 04:48:18,294 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3692113478978475, 'Total loss': 0.3692113478978475} | train loss {'Reaction outcome loss': 0.24001183249798697, 'Total loss': 0.24001183249798697}
2022-12-31 04:48:18,294 INFO:     Found new best model at epoch 14
2022-12-31 04:48:18,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:18,295 INFO:     Epoch: 15
2022-12-31 04:48:19,907 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3990603228410085, 'Total loss': 0.3990603228410085} | train loss {'Reaction outcome loss': 0.23301660971027677, 'Total loss': 0.23301660971027677}
2022-12-31 04:48:19,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:19,907 INFO:     Epoch: 16
2022-12-31 04:48:21,531 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4153715600570043, 'Total loss': 0.4153715600570043} | train loss {'Reaction outcome loss': 0.2252943016372729, 'Total loss': 0.2252943016372729}
2022-12-31 04:48:21,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:21,532 INFO:     Epoch: 17
2022-12-31 04:48:23,155 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3910442570845286, 'Total loss': 0.3910442570845286} | train loss {'Reaction outcome loss': 0.21805992353356618, 'Total loss': 0.21805992353356618}
2022-12-31 04:48:23,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:23,155 INFO:     Epoch: 18
2022-12-31 04:48:24,776 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3838093226154645, 'Total loss': 0.3838093226154645} | train loss {'Reaction outcome loss': 0.21132071283510953, 'Total loss': 0.21132071283510953}
2022-12-31 04:48:24,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:24,776 INFO:     Epoch: 19
2022-12-31 04:48:26,391 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4152510086695353, 'Total loss': 0.4152510086695353} | train loss {'Reaction outcome loss': 0.21037137512778997, 'Total loss': 0.21037137512778997}
2022-12-31 04:48:26,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:26,392 INFO:     Epoch: 20
2022-12-31 04:48:28,044 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39718509117762246, 'Total loss': 0.39718509117762246} | train loss {'Reaction outcome loss': 0.20373763704834424, 'Total loss': 0.20373763704834424}
2022-12-31 04:48:28,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:28,044 INFO:     Epoch: 21
2022-12-31 04:48:29,655 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4198560893535614, 'Total loss': 0.4198560893535614} | train loss {'Reaction outcome loss': 0.2083697521973037, 'Total loss': 0.2083697521973037}
2022-12-31 04:48:29,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:29,656 INFO:     Epoch: 22
2022-12-31 04:48:31,269 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42539985875288644, 'Total loss': 0.42539985875288644} | train loss {'Reaction outcome loss': 0.19659277666326397, 'Total loss': 0.19659277666326397}
2022-12-31 04:48:31,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:31,269 INFO:     Epoch: 23
2022-12-31 04:48:32,931 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.38513621389865876, 'Total loss': 0.38513621389865876} | train loss {'Reaction outcome loss': 0.19342301818339722, 'Total loss': 0.19342301818339722}
2022-12-31 04:48:32,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:32,931 INFO:     Epoch: 24
2022-12-31 04:48:34,548 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38942894836266834, 'Total loss': 0.38942894836266834} | train loss {'Reaction outcome loss': 0.186542560550995, 'Total loss': 0.186542560550995}
2022-12-31 04:48:34,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:34,548 INFO:     Epoch: 25
2022-12-31 04:48:36,156 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43559022545814513, 'Total loss': 0.43559022545814513} | train loss {'Reaction outcome loss': 0.19708840824677137, 'Total loss': 0.19708840824677137}
2022-12-31 04:48:36,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:36,157 INFO:     Epoch: 26
2022-12-31 04:48:37,769 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4498653203248978, 'Total loss': 0.4498653203248978} | train loss {'Reaction outcome loss': 0.21777086168784054, 'Total loss': 0.21777086168784054}
2022-12-31 04:48:37,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:37,770 INFO:     Epoch: 27
2022-12-31 04:48:39,377 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3986014852921168, 'Total loss': 0.3986014852921168} | train loss {'Reaction outcome loss': 0.18584215239810664, 'Total loss': 0.18584215239810664}
2022-12-31 04:48:39,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:39,377 INFO:     Epoch: 28
2022-12-31 04:48:41,038 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.417398805419604, 'Total loss': 0.417398805419604} | train loss {'Reaction outcome loss': 0.1807167590730756, 'Total loss': 0.1807167590730756}
2022-12-31 04:48:41,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:41,039 INFO:     Epoch: 29
2022-12-31 04:48:42,645 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44894774357477824, 'Total loss': 0.44894774357477824} | train loss {'Reaction outcome loss': 0.17860617192775902, 'Total loss': 0.17860617192775902}
2022-12-31 04:48:42,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:42,645 INFO:     Epoch: 30
2022-12-31 04:48:44,306 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40126380026340486, 'Total loss': 0.40126380026340486} | train loss {'Reaction outcome loss': 0.1724398036764098, 'Total loss': 0.1724398036764098}
2022-12-31 04:48:44,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:44,306 INFO:     Epoch: 31
2022-12-31 04:48:45,955 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4546982303261757, 'Total loss': 0.4546982303261757} | train loss {'Reaction outcome loss': 0.1691880620766323, 'Total loss': 0.1691880620766323}
2022-12-31 04:48:45,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:45,956 INFO:     Epoch: 32
2022-12-31 04:48:47,569 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4399681200583776, 'Total loss': 0.4399681200583776} | train loss {'Reaction outcome loss': 0.18053538337235164, 'Total loss': 0.18053538337235164}
2022-12-31 04:48:47,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:47,569 INFO:     Epoch: 33
2022-12-31 04:48:49,178 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4199909041325251, 'Total loss': 0.4199909041325251} | train loss {'Reaction outcome loss': 0.1637332617010691, 'Total loss': 0.1637332617010691}
2022-12-31 04:48:49,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:49,178 INFO:     Epoch: 34
2022-12-31 04:48:50,840 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.418335618575414, 'Total loss': 0.418335618575414} | train loss {'Reaction outcome loss': 0.16603786112281724, 'Total loss': 0.16603786112281724}
2022-12-31 04:48:50,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:50,840 INFO:     Epoch: 35
2022-12-31 04:48:52,502 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4129928966363271, 'Total loss': 0.4129928966363271} | train loss {'Reaction outcome loss': 0.16685241537735515, 'Total loss': 0.16685241537735515}
2022-12-31 04:48:52,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:52,503 INFO:     Epoch: 36
2022-12-31 04:48:54,118 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4258432482679685, 'Total loss': 0.4258432482679685} | train loss {'Reaction outcome loss': 0.20631421392149144, 'Total loss': 0.20631421392149144}
2022-12-31 04:48:54,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:54,118 INFO:     Epoch: 37
2022-12-31 04:48:55,763 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3949564293026924, 'Total loss': 0.3949564293026924} | train loss {'Reaction outcome loss': 0.18144302457010886, 'Total loss': 0.18144302457010886}
2022-12-31 04:48:55,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:55,763 INFO:     Epoch: 38
2022-12-31 04:48:57,388 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40448870360851286, 'Total loss': 0.40448870360851286} | train loss {'Reaction outcome loss': 0.16879692018636083, 'Total loss': 0.16879692018636083}
2022-12-31 04:48:57,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:57,388 INFO:     Epoch: 39
2022-12-31 04:48:59,014 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40973520080248516, 'Total loss': 0.40973520080248516} | train loss {'Reaction outcome loss': 0.15645348452760474, 'Total loss': 0.15645348452760474}
2022-12-31 04:48:59,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:48:59,015 INFO:     Epoch: 40
2022-12-31 04:49:00,641 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43234580258528393, 'Total loss': 0.43234580258528393} | train loss {'Reaction outcome loss': 0.15374210962614018, 'Total loss': 0.15374210962614018}
2022-12-31 04:49:00,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:00,641 INFO:     Epoch: 41
2022-12-31 04:49:02,267 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39289516359567644, 'Total loss': 0.39289516359567644} | train loss {'Reaction outcome loss': 0.1527168439045098, 'Total loss': 0.1527168439045098}
2022-12-31 04:49:02,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:02,267 INFO:     Epoch: 42
2022-12-31 04:49:03,887 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39488127939403056, 'Total loss': 0.39488127939403056} | train loss {'Reaction outcome loss': 0.15104265652505844, 'Total loss': 0.15104265652505844}
2022-12-31 04:49:03,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:03,887 INFO:     Epoch: 43
2022-12-31 04:49:05,504 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42945379614830015, 'Total loss': 0.42945379614830015} | train loss {'Reaction outcome loss': 0.1515148052198313, 'Total loss': 0.1515148052198313}
2022-12-31 04:49:05,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:05,504 INFO:     Epoch: 44
2022-12-31 04:49:07,114 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.447062619527181, 'Total loss': 0.447062619527181} | train loss {'Reaction outcome loss': 0.15021504625252893, 'Total loss': 0.15021504625252893}
2022-12-31 04:49:07,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:07,114 INFO:     Epoch: 45
2022-12-31 04:49:08,733 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4216732422510783, 'Total loss': 0.4216732422510783} | train loss {'Reaction outcome loss': 0.1465116867987925, 'Total loss': 0.1465116867987925}
2022-12-31 04:49:08,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:08,733 INFO:     Epoch: 46
2022-12-31 04:49:10,349 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46033347845077516, 'Total loss': 0.46033347845077516} | train loss {'Reaction outcome loss': 0.14533791588821812, 'Total loss': 0.14533791588821812}
2022-12-31 04:49:10,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:10,349 INFO:     Epoch: 47
2022-12-31 04:49:11,992 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43571748634179436, 'Total loss': 0.43571748634179436} | train loss {'Reaction outcome loss': 0.14495855417993406, 'Total loss': 0.14495855417993406}
2022-12-31 04:49:11,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:11,993 INFO:     Epoch: 48
2022-12-31 04:49:13,597 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41651818056901296, 'Total loss': 0.41651818056901296} | train loss {'Reaction outcome loss': 0.145209182822755, 'Total loss': 0.145209182822755}
2022-12-31 04:49:13,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:13,598 INFO:     Epoch: 49
2022-12-31 04:49:15,249 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4114790598551432, 'Total loss': 0.4114790598551432} | train loss {'Reaction outcome loss': 0.1417099377427223, 'Total loss': 0.1417099377427223}
2022-12-31 04:49:15,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:15,249 INFO:     Epoch: 50
2022-12-31 04:49:16,864 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42165667166312537, 'Total loss': 0.42165667166312537} | train loss {'Reaction outcome loss': 0.14424755124112024, 'Total loss': 0.14424755124112024}
2022-12-31 04:49:16,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:16,864 INFO:     Epoch: 51
2022-12-31 04:49:18,500 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43529728750387825, 'Total loss': 0.43529728750387825} | train loss {'Reaction outcome loss': 0.14959326538297793, 'Total loss': 0.14959326538297793}
2022-12-31 04:49:18,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:18,501 INFO:     Epoch: 52
2022-12-31 04:49:20,108 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4437260150909424, 'Total loss': 0.4437260150909424} | train loss {'Reaction outcome loss': 0.15919168902885006, 'Total loss': 0.15919168902885006}
2022-12-31 04:49:20,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:20,109 INFO:     Epoch: 53
2022-12-31 04:49:21,752 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47226676940917967, 'Total loss': 0.47226676940917967} | train loss {'Reaction outcome loss': 0.1476174636328073, 'Total loss': 0.1476174636328073}
2022-12-31 04:49:21,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:21,753 INFO:     Epoch: 54
2022-12-31 04:49:23,360 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45174014767011006, 'Total loss': 0.45174014767011006} | train loss {'Reaction outcome loss': 0.15087904276805458, 'Total loss': 0.15087904276805458}
2022-12-31 04:49:23,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:23,361 INFO:     Epoch: 55
2022-12-31 04:49:25,022 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43581198851267494, 'Total loss': 0.43581198851267494} | train loss {'Reaction outcome loss': 0.16970490949651043, 'Total loss': 0.16970490949651043}
2022-12-31 04:49:25,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:25,022 INFO:     Epoch: 56
2022-12-31 04:49:26,651 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41580124100049337, 'Total loss': 0.41580124100049337} | train loss {'Reaction outcome loss': 0.14669140514851084, 'Total loss': 0.14669140514851084}
2022-12-31 04:49:26,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:26,652 INFO:     Epoch: 57
2022-12-31 04:49:28,268 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45463246206442515, 'Total loss': 0.45463246206442515} | train loss {'Reaction outcome loss': 0.1479357318257562, 'Total loss': 0.1479357318257562}
2022-12-31 04:49:28,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:28,268 INFO:     Epoch: 58
2022-12-31 04:49:29,929 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42073083321253457, 'Total loss': 0.42073083321253457} | train loss {'Reaction outcome loss': 0.1614204717102373, 'Total loss': 0.1614204717102373}
2022-12-31 04:49:29,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:29,930 INFO:     Epoch: 59
2022-12-31 04:49:31,581 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4388867259025574, 'Total loss': 0.4388867259025574} | train loss {'Reaction outcome loss': 0.13801973657446334, 'Total loss': 0.13801973657446334}
2022-12-31 04:49:31,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:31,582 INFO:     Epoch: 60
2022-12-31 04:49:33,193 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4327349970738093, 'Total loss': 0.4327349970738093} | train loss {'Reaction outcome loss': 0.1385926788403278, 'Total loss': 0.1385926788403278}
2022-12-31 04:49:33,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:33,194 INFO:     Epoch: 61
2022-12-31 04:49:34,828 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4102760136127472, 'Total loss': 0.4102760136127472} | train loss {'Reaction outcome loss': 0.1334360750618583, 'Total loss': 0.1334360750618583}
2022-12-31 04:49:34,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:34,828 INFO:     Epoch: 62
2022-12-31 04:49:36,456 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44164635638395944, 'Total loss': 0.44164635638395944} | train loss {'Reaction outcome loss': 0.13009711219279596, 'Total loss': 0.13009711219279596}
2022-12-31 04:49:36,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:36,456 INFO:     Epoch: 63
2022-12-31 04:49:38,083 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4213897198438644, 'Total loss': 0.4213897198438644} | train loss {'Reaction outcome loss': 0.12793050348588714, 'Total loss': 0.12793050348588714}
2022-12-31 04:49:38,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:38,084 INFO:     Epoch: 64
2022-12-31 04:49:39,693 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41810723741849265, 'Total loss': 0.41810723741849265} | train loss {'Reaction outcome loss': 0.13036776102573008, 'Total loss': 0.13036776102573008}
2022-12-31 04:49:39,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:39,693 INFO:     Epoch: 65
2022-12-31 04:49:41,313 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.396519202987353, 'Total loss': 0.396519202987353} | train loss {'Reaction outcome loss': 0.1270989949335421, 'Total loss': 0.1270989949335421}
2022-12-31 04:49:41,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:41,313 INFO:     Epoch: 66
2022-12-31 04:49:42,938 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4096250454584757, 'Total loss': 0.4096250454584757} | train loss {'Reaction outcome loss': 0.12979993469459747, 'Total loss': 0.12979993469459747}
2022-12-31 04:49:42,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:42,938 INFO:     Epoch: 67
2022-12-31 04:49:44,566 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4272996157407761, 'Total loss': 0.4272996157407761} | train loss {'Reaction outcome loss': 0.13085408264052364, 'Total loss': 0.13085408264052364}
2022-12-31 04:49:44,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:44,566 INFO:     Epoch: 68
2022-12-31 04:49:46,192 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3988472739855448, 'Total loss': 0.3988472739855448} | train loss {'Reaction outcome loss': 0.13000681990730378, 'Total loss': 0.13000681990730378}
2022-12-31 04:49:46,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:46,193 INFO:     Epoch: 69
2022-12-31 04:49:47,814 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4349796921014786, 'Total loss': 0.4349796921014786} | train loss {'Reaction outcome loss': 0.1273862520883204, 'Total loss': 0.1273862520883204}
2022-12-31 04:49:47,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:47,814 INFO:     Epoch: 70
2022-12-31 04:49:49,428 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3997924707519511, 'Total loss': 0.3997924707519511} | train loss {'Reaction outcome loss': 0.13136868691071868, 'Total loss': 0.13136868691071868}
2022-12-31 04:49:49,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:49,428 INFO:     Epoch: 71
2022-12-31 04:49:51,047 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45195688903331754, 'Total loss': 0.45195688903331754} | train loss {'Reaction outcome loss': 0.12555697173503585, 'Total loss': 0.12555697173503585}
2022-12-31 04:49:51,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:51,048 INFO:     Epoch: 72
2022-12-31 04:49:52,673 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41759347518285117, 'Total loss': 0.41759347518285117} | train loss {'Reaction outcome loss': 0.1320837679846538, 'Total loss': 0.1320837679846538}
2022-12-31 04:49:52,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:52,674 INFO:     Epoch: 73
2022-12-31 04:49:54,299 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4209892849127452, 'Total loss': 0.4209892849127452} | train loss {'Reaction outcome loss': 0.1271074624437724, 'Total loss': 0.1271074624437724}
2022-12-31 04:49:54,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:54,300 INFO:     Epoch: 74
2022-12-31 04:49:55,924 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4011113484700521, 'Total loss': 0.4011113484700521} | train loss {'Reaction outcome loss': 0.12893801867038998, 'Total loss': 0.12893801867038998}
2022-12-31 04:49:55,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:55,924 INFO:     Epoch: 75
2022-12-31 04:49:57,539 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43528521557648975, 'Total loss': 0.43528521557648975} | train loss {'Reaction outcome loss': 0.12547626540248713, 'Total loss': 0.12547626540248713}
2022-12-31 04:49:57,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:57,539 INFO:     Epoch: 76
2022-12-31 04:49:59,155 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4408220946788788, 'Total loss': 0.4408220946788788} | train loss {'Reaction outcome loss': 0.12166258739175712, 'Total loss': 0.12166258739175712}
2022-12-31 04:49:59,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:49:59,155 INFO:     Epoch: 77
2022-12-31 04:50:00,768 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44638195832570393, 'Total loss': 0.44638195832570393} | train loss {'Reaction outcome loss': 0.1221271565574579, 'Total loss': 0.1221271565574579}
2022-12-31 04:50:00,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:00,769 INFO:     Epoch: 78
2022-12-31 04:50:02,452 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4445226540168126, 'Total loss': 0.4445226540168126} | train loss {'Reaction outcome loss': 0.12326877647622798, 'Total loss': 0.12326877647622798}
2022-12-31 04:50:02,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:02,453 INFO:     Epoch: 79
2022-12-31 04:50:04,075 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3838044544061025, 'Total loss': 0.3838044544061025} | train loss {'Reaction outcome loss': 0.127005008060065, 'Total loss': 0.127005008060065}
2022-12-31 04:50:04,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:04,075 INFO:     Epoch: 80
2022-12-31 04:50:05,693 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4355448782444, 'Total loss': 0.4355448782444} | train loss {'Reaction outcome loss': 0.1266299540133121, 'Total loss': 0.1266299540133121}
2022-12-31 04:50:05,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:05,694 INFO:     Epoch: 81
2022-12-31 04:50:07,303 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4192949790507555, 'Total loss': 0.4192949790507555} | train loss {'Reaction outcome loss': 0.12515620255304594, 'Total loss': 0.12515620255304594}
2022-12-31 04:50:07,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:07,304 INFO:     Epoch: 82
2022-12-31 04:50:08,924 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4054107695817947, 'Total loss': 0.4054107695817947} | train loss {'Reaction outcome loss': 0.11882132909178433, 'Total loss': 0.11882132909178433}
2022-12-31 04:50:08,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:08,924 INFO:     Epoch: 83
2022-12-31 04:50:10,542 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4182348767916361, 'Total loss': 0.4182348767916361} | train loss {'Reaction outcome loss': 0.11719406960174387, 'Total loss': 0.11719406960174387}
2022-12-31 04:50:10,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:10,542 INFO:     Epoch: 84
2022-12-31 04:50:12,161 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43362231651941935, 'Total loss': 0.43362231651941935} | train loss {'Reaction outcome loss': 0.1187031542307839, 'Total loss': 0.1187031542307839}
2022-12-31 04:50:12,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:12,162 INFO:     Epoch: 85
2022-12-31 04:50:13,780 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45545721650123594, 'Total loss': 0.45545721650123594} | train loss {'Reaction outcome loss': 0.11844137154959912, 'Total loss': 0.11844137154959912}
2022-12-31 04:50:13,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:13,781 INFO:     Epoch: 86
2022-12-31 04:50:15,400 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4252049009005229, 'Total loss': 0.4252049009005229} | train loss {'Reaction outcome loss': 0.11799391169449297, 'Total loss': 0.11799391169449297}
2022-12-31 04:50:15,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:15,400 INFO:     Epoch: 87
2022-12-31 04:50:17,016 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44162022372086845, 'Total loss': 0.44162022372086845} | train loss {'Reaction outcome loss': 0.11857552871958393, 'Total loss': 0.11857552871958393}
2022-12-31 04:50:17,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:17,016 INFO:     Epoch: 88
2022-12-31 04:50:18,633 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4591043432553609, 'Total loss': 0.4591043432553609} | train loss {'Reaction outcome loss': 0.11560564296213789, 'Total loss': 0.11560564296213789}
2022-12-31 04:50:18,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:18,634 INFO:     Epoch: 89
2022-12-31 04:50:20,259 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4205658286809921, 'Total loss': 0.4205658286809921} | train loss {'Reaction outcome loss': 0.11722990279027411, 'Total loss': 0.11722990279027411}
2022-12-31 04:50:20,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:20,259 INFO:     Epoch: 90
2022-12-31 04:50:21,887 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43017855038245517, 'Total loss': 0.43017855038245517} | train loss {'Reaction outcome loss': 0.11714295163462826, 'Total loss': 0.11714295163462826}
2022-12-31 04:50:21,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:21,887 INFO:     Epoch: 91
2022-12-31 04:50:23,513 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42200624346733095, 'Total loss': 0.42200624346733095} | train loss {'Reaction outcome loss': 0.11539207481687101, 'Total loss': 0.11539207481687101}
2022-12-31 04:50:23,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:23,514 INFO:     Epoch: 92
2022-12-31 04:50:25,131 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46431880195935565, 'Total loss': 0.46431880195935565} | train loss {'Reaction outcome loss': 0.11425127825856654, 'Total loss': 0.11425127825856654}
2022-12-31 04:50:25,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:25,132 INFO:     Epoch: 93
2022-12-31 04:50:26,751 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4117516999443372, 'Total loss': 0.4117516999443372} | train loss {'Reaction outcome loss': 0.11582294046209005, 'Total loss': 0.11582294046209005}
2022-12-31 04:50:26,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:26,751 INFO:     Epoch: 94
2022-12-31 04:50:28,378 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42671427528063455, 'Total loss': 0.42671427528063455} | train loss {'Reaction outcome loss': 0.11324859733359398, 'Total loss': 0.11324859733359398}
2022-12-31 04:50:28,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:28,378 INFO:     Epoch: 95
2022-12-31 04:50:30,006 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44814881881078084, 'Total loss': 0.44814881881078084} | train loss {'Reaction outcome loss': 0.11162105761130975, 'Total loss': 0.11162105761130975}
2022-12-31 04:50:30,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:30,006 INFO:     Epoch: 96
2022-12-31 04:50:31,634 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4255558907985687, 'Total loss': 0.4255558907985687} | train loss {'Reaction outcome loss': 0.12323070104584853, 'Total loss': 0.12323070104584853}
2022-12-31 04:50:31,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:31,635 INFO:     Epoch: 97
2022-12-31 04:50:33,263 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4461553027232488, 'Total loss': 0.4461553027232488} | train loss {'Reaction outcome loss': 0.12908649029534147, 'Total loss': 0.12908649029534147}
2022-12-31 04:50:33,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:33,263 INFO:     Epoch: 98
2022-12-31 04:50:34,908 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42999104696015517, 'Total loss': 0.42999104696015517} | train loss {'Reaction outcome loss': 0.11963086963320772, 'Total loss': 0.11963086963320772}
2022-12-31 04:50:34,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:34,908 INFO:     Epoch: 99
2022-12-31 04:50:36,535 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40523975193500517, 'Total loss': 0.40523975193500517} | train loss {'Reaction outcome loss': 0.10854713252677133, 'Total loss': 0.10854713252677133}
2022-12-31 04:50:36,535 INFO:     Best model found after epoch 15 of 100.
2022-12-31 04:50:36,535 INFO:   Done with stage: TRAINING
2022-12-31 04:50:36,535 INFO:   Starting stage: EVALUATION
2022-12-31 04:50:36,665 INFO:   Done with stage: EVALUATION
2022-12-31 04:50:36,666 INFO:   Leaving out SEQ value Fold_7
2022-12-31 04:50:36,678 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 04:50:36,678 INFO:   Starting stage: FEATURE SCALING
2022-12-31 04:50:37,323 INFO:   Done with stage: FEATURE SCALING
2022-12-31 04:50:37,323 INFO:   Starting stage: SCALING TARGETS
2022-12-31 04:50:37,396 INFO:   Done with stage: SCALING TARGETS
2022-12-31 04:50:37,396 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:50:37,396 INFO:     No hyperparam tuning for this model
2022-12-31 04:50:37,396 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:50:37,396 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 04:50:37,397 INFO:     None feature selector for col prot
2022-12-31 04:50:37,397 INFO:     None feature selector for col prot
2022-12-31 04:50:37,397 INFO:     None feature selector for col prot
2022-12-31 04:50:37,397 INFO:     None feature selector for col chem
2022-12-31 04:50:37,397 INFO:     None feature selector for col chem
2022-12-31 04:50:37,398 INFO:     None feature selector for col chem
2022-12-31 04:50:37,398 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 04:50:37,398 INFO:   Starting stage: BUILD MODEL
2022-12-31 04:50:37,399 INFO:     Number of params in model 224011
2022-12-31 04:50:37,403 INFO:   Done with stage: BUILD MODEL
2022-12-31 04:50:37,403 INFO:   Starting stage: TRAINING
2022-12-31 04:50:37,447 INFO:     Val loss before train {'Reaction outcome loss': 0.952853262424469, 'Total loss': 0.952853262424469}
2022-12-31 04:50:37,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:37,447 INFO:     Epoch: 0
2022-12-31 04:50:39,073 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5615209519863129, 'Total loss': 0.5615209519863129} | train loss {'Reaction outcome loss': 0.7784074683697215, 'Total loss': 0.7784074683697215}
2022-12-31 04:50:39,073 INFO:     Found new best model at epoch 0
2022-12-31 04:50:39,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:39,074 INFO:     Epoch: 1
2022-12-31 04:50:40,697 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.47928314208984374, 'Total loss': 0.47928314208984374} | train loss {'Reaction outcome loss': 0.5080503795551479, 'Total loss': 0.5080503795551479}
2022-12-31 04:50:40,697 INFO:     Found new best model at epoch 1
2022-12-31 04:50:40,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:40,698 INFO:     Epoch: 2
2022-12-31 04:50:42,321 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46560769776503247, 'Total loss': 0.46560769776503247} | train loss {'Reaction outcome loss': 0.4354441005346577, 'Total loss': 0.4354441005346577}
2022-12-31 04:50:42,321 INFO:     Found new best model at epoch 2
2022-12-31 04:50:42,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:42,322 INFO:     Epoch: 3
2022-12-31 04:50:43,446 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49111500978469846, 'Total loss': 0.49111500978469846} | train loss {'Reaction outcome loss': 0.3949515497856622, 'Total loss': 0.3949515497856622}
2022-12-31 04:50:43,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:43,446 INFO:     Epoch: 4
2022-12-31 04:50:44,572 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45719393293062843, 'Total loss': 0.45719393293062843} | train loss {'Reaction outcome loss': 0.36825874111605034, 'Total loss': 0.36825874111605034}
2022-12-31 04:50:44,573 INFO:     Found new best model at epoch 4
2022-12-31 04:50:44,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:44,574 INFO:     Epoch: 5
2022-12-31 04:50:45,685 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4684607187906901, 'Total loss': 0.4684607187906901} | train loss {'Reaction outcome loss': 0.3474749095926216, 'Total loss': 0.3474749095926216}
2022-12-31 04:50:45,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:45,685 INFO:     Epoch: 6
2022-12-31 04:50:46,790 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4454840362071991, 'Total loss': 0.4454840362071991} | train loss {'Reaction outcome loss': 0.3276691380014058, 'Total loss': 0.3276691380014058}
2022-12-31 04:50:46,790 INFO:     Found new best model at epoch 6
2022-12-31 04:50:46,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:46,791 INFO:     Epoch: 7
2022-12-31 04:50:48,426 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4597213993469874, 'Total loss': 0.4597213993469874} | train loss {'Reaction outcome loss': 0.3086181714700448, 'Total loss': 0.3086181714700448}
2022-12-31 04:50:48,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:48,427 INFO:     Epoch: 8
2022-12-31 04:50:50,042 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.461380635201931, 'Total loss': 0.461380635201931} | train loss {'Reaction outcome loss': 0.2936223726786861, 'Total loss': 0.2936223726786861}
2022-12-31 04:50:50,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:50,043 INFO:     Epoch: 9
2022-12-31 04:50:51,671 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46204044024149576, 'Total loss': 0.46204044024149576} | train loss {'Reaction outcome loss': 0.27476705200566715, 'Total loss': 0.27476705200566715}
2022-12-31 04:50:51,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:51,671 INFO:     Epoch: 10
2022-12-31 04:50:53,283 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.436896883447965, 'Total loss': 0.436896883447965} | train loss {'Reaction outcome loss': 0.2644605039474336, 'Total loss': 0.2644605039474336}
2022-12-31 04:50:53,284 INFO:     Found new best model at epoch 10
2022-12-31 04:50:53,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:53,285 INFO:     Epoch: 11
2022-12-31 04:50:54,896 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46548134585221607, 'Total loss': 0.46548134585221607} | train loss {'Reaction outcome loss': 0.255230770711972, 'Total loss': 0.255230770711972}
2022-12-31 04:50:54,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:54,897 INFO:     Epoch: 12
2022-12-31 04:50:56,514 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45443023641904196, 'Total loss': 0.45443023641904196} | train loss {'Reaction outcome loss': 0.24042317337131242, 'Total loss': 0.24042317337131242}
2022-12-31 04:50:56,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:56,515 INFO:     Epoch: 13
2022-12-31 04:50:58,130 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4682411770025889, 'Total loss': 0.4682411770025889} | train loss {'Reaction outcome loss': 0.23618185804107827, 'Total loss': 0.23618185804107827}
2022-12-31 04:50:58,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:58,130 INFO:     Epoch: 14
2022-12-31 04:50:59,742 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4497762163480123, 'Total loss': 0.4497762163480123} | train loss {'Reaction outcome loss': 0.22562958366012315, 'Total loss': 0.22562958366012315}
2022-12-31 04:50:59,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:50:59,742 INFO:     Epoch: 15
2022-12-31 04:51:01,359 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43933778802553813, 'Total loss': 0.43933778802553813} | train loss {'Reaction outcome loss': 0.21598915350942835, 'Total loss': 0.21598915350942835}
2022-12-31 04:51:01,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:01,361 INFO:     Epoch: 16
2022-12-31 04:51:02,974 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43208026786645254, 'Total loss': 0.43208026786645254} | train loss {'Reaction outcome loss': 0.20931269953343412, 'Total loss': 0.20931269953343412}
2022-12-31 04:51:02,974 INFO:     Found new best model at epoch 16
2022-12-31 04:51:02,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:02,975 INFO:     Epoch: 17
2022-12-31 04:51:04,586 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48232590556144717, 'Total loss': 0.48232590556144717} | train loss {'Reaction outcome loss': 0.19872192273904915, 'Total loss': 0.19872192273904915}
2022-12-31 04:51:04,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:04,586 INFO:     Epoch: 18
2022-12-31 04:51:06,204 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45619218846162163, 'Total loss': 0.45619218846162163} | train loss {'Reaction outcome loss': 0.1960226427024022, 'Total loss': 0.1960226427024022}
2022-12-31 04:51:06,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:06,204 INFO:     Epoch: 19
2022-12-31 04:51:07,833 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4913339535395304, 'Total loss': 0.4913339535395304} | train loss {'Reaction outcome loss': 0.1909619627406128, 'Total loss': 0.1909619627406128}
2022-12-31 04:51:07,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:07,834 INFO:     Epoch: 20
2022-12-31 04:51:09,452 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44377613961696627, 'Total loss': 0.44377613961696627} | train loss {'Reaction outcome loss': 0.18990314523235555, 'Total loss': 0.18990314523235555}
2022-12-31 04:51:09,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:09,452 INFO:     Epoch: 21
2022-12-31 04:51:11,082 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45091900130112966, 'Total loss': 0.45091900130112966} | train loss {'Reaction outcome loss': 0.18190933413642194, 'Total loss': 0.18190933413642194}
2022-12-31 04:51:11,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:11,082 INFO:     Epoch: 22
2022-12-31 04:51:12,748 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4461385349432627, 'Total loss': 0.4461385349432627} | train loss {'Reaction outcome loss': 0.17680614149796403, 'Total loss': 0.17680614149796403}
2022-12-31 04:51:12,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:12,748 INFO:     Epoch: 23
2022-12-31 04:51:14,401 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4302845676740011, 'Total loss': 0.4302845676740011} | train loss {'Reaction outcome loss': 0.1749483957711863, 'Total loss': 0.1749483957711863}
2022-12-31 04:51:14,401 INFO:     Found new best model at epoch 23
2022-12-31 04:51:14,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:14,402 INFO:     Epoch: 24
2022-12-31 04:51:16,027 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4203602264324824, 'Total loss': 0.4203602264324824} | train loss {'Reaction outcome loss': 0.17297706305509977, 'Total loss': 0.17297706305509977}
2022-12-31 04:51:16,027 INFO:     Found new best model at epoch 24
2022-12-31 04:51:16,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:16,028 INFO:     Epoch: 25
2022-12-31 04:51:17,650 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49788560569286344, 'Total loss': 0.49788560569286344} | train loss {'Reaction outcome loss': 0.16715953173620177, 'Total loss': 0.16715953173620177}
2022-12-31 04:51:17,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:17,651 INFO:     Epoch: 26
2022-12-31 04:51:19,280 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4376135538021723, 'Total loss': 0.4376135538021723} | train loss {'Reaction outcome loss': 0.16495650991905036, 'Total loss': 0.16495650991905036}
2022-12-31 04:51:19,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:19,280 INFO:     Epoch: 27
2022-12-31 04:51:20,946 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4552735318740209, 'Total loss': 0.4552735318740209} | train loss {'Reaction outcome loss': 0.16328589547600342, 'Total loss': 0.16328589547600342}
2022-12-31 04:51:20,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:20,947 INFO:     Epoch: 28
2022-12-31 04:51:22,572 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46675011118253074, 'Total loss': 0.46675011118253074} | train loss {'Reaction outcome loss': 0.16108523987717793, 'Total loss': 0.16108523987717793}
2022-12-31 04:51:22,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:22,572 INFO:     Epoch: 29
2022-12-31 04:51:24,225 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4343364049990972, 'Total loss': 0.4343364049990972} | train loss {'Reaction outcome loss': 0.1567493290052033, 'Total loss': 0.1567493290052033}
2022-12-31 04:51:24,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:24,225 INFO:     Epoch: 30
2022-12-31 04:51:25,851 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4707607448101044, 'Total loss': 0.4707607448101044} | train loss {'Reaction outcome loss': 0.1501967502852048, 'Total loss': 0.1501967502852048}
2022-12-31 04:51:25,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:25,852 INFO:     Epoch: 31
2022-12-31 04:51:27,515 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4992413282394409, 'Total loss': 0.4992413282394409} | train loss {'Reaction outcome loss': 0.15388768909848716, 'Total loss': 0.15388768909848716}
2022-12-31 04:51:27,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:27,515 INFO:     Epoch: 32
2022-12-31 04:51:29,136 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45993197908004124, 'Total loss': 0.45993197908004124} | train loss {'Reaction outcome loss': 0.148070764469003, 'Total loss': 0.148070764469003}
2022-12-31 04:51:29,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:29,136 INFO:     Epoch: 33
2022-12-31 04:51:30,802 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49319418470064796, 'Total loss': 0.49319418470064796} | train loss {'Reaction outcome loss': 0.14671213566140684, 'Total loss': 0.14671213566140684}
2022-12-31 04:51:30,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:30,803 INFO:     Epoch: 34
2022-12-31 04:51:32,459 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4506661117076874, 'Total loss': 0.4506661117076874} | train loss {'Reaction outcome loss': 0.14642172442944149, 'Total loss': 0.14642172442944149}
2022-12-31 04:51:32,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:32,459 INFO:     Epoch: 35
2022-12-31 04:51:34,087 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4688449800014496, 'Total loss': 0.4688449800014496} | train loss {'Reaction outcome loss': 0.1457060736836025, 'Total loss': 0.1457060736836025}
2022-12-31 04:51:34,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:34,087 INFO:     Epoch: 36
2022-12-31 04:51:35,718 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46766106188297274, 'Total loss': 0.46766106188297274} | train loss {'Reaction outcome loss': 0.1402177914022216, 'Total loss': 0.1402177914022216}
2022-12-31 04:51:35,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:35,718 INFO:     Epoch: 37
2022-12-31 04:51:37,342 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46699771185715994, 'Total loss': 0.46699771185715994} | train loss {'Reaction outcome loss': 0.13925273762007215, 'Total loss': 0.13925273762007215}
2022-12-31 04:51:37,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:37,343 INFO:     Epoch: 38
2022-12-31 04:51:38,976 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4591608663400014, 'Total loss': 0.4591608663400014} | train loss {'Reaction outcome loss': 0.13819764341002444, 'Total loss': 0.13819764341002444}
2022-12-31 04:51:38,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:38,976 INFO:     Epoch: 39
2022-12-31 04:51:40,607 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4718027045329412, 'Total loss': 0.4718027045329412} | train loss {'Reaction outcome loss': 0.1366047716669281, 'Total loss': 0.1366047716669281}
2022-12-31 04:51:40,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:40,607 INFO:     Epoch: 40
2022-12-31 04:51:42,246 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47032064000765483, 'Total loss': 0.47032064000765483} | train loss {'Reaction outcome loss': 0.13492081657603436, 'Total loss': 0.13492081657603436}
2022-12-31 04:51:42,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:42,246 INFO:     Epoch: 41
2022-12-31 04:51:43,912 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4278233855962753, 'Total loss': 0.4278233855962753} | train loss {'Reaction outcome loss': 0.1362659222234565, 'Total loss': 0.1362659222234565}
2022-12-31 04:51:43,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:43,912 INFO:     Epoch: 42
2022-12-31 04:51:45,532 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4745406637589137, 'Total loss': 0.4745406637589137} | train loss {'Reaction outcome loss': 0.1337181225869576, 'Total loss': 0.1337181225869576}
2022-12-31 04:51:45,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:45,532 INFO:     Epoch: 43
2022-12-31 04:51:47,162 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4763570139805476, 'Total loss': 0.4763570139805476} | train loss {'Reaction outcome loss': 0.13159100774890786, 'Total loss': 0.13159100774890786}
2022-12-31 04:51:47,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:47,162 INFO:     Epoch: 44
2022-12-31 04:51:48,795 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.450002325574557, 'Total loss': 0.450002325574557} | train loss {'Reaction outcome loss': 0.12814339710607964, 'Total loss': 0.12814339710607964}
2022-12-31 04:51:48,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:48,796 INFO:     Epoch: 45
2022-12-31 04:51:50,429 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45038716718554495, 'Total loss': 0.45038716718554495} | train loss {'Reaction outcome loss': 0.12881761715354043, 'Total loss': 0.12881761715354043}
2022-12-31 04:51:50,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:50,429 INFO:     Epoch: 46
2022-12-31 04:51:52,081 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44651011923948924, 'Total loss': 0.44651011923948924} | train loss {'Reaction outcome loss': 0.13058227437652567, 'Total loss': 0.13058227437652567}
2022-12-31 04:51:52,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:52,081 INFO:     Epoch: 47
2022-12-31 04:51:53,747 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4256020387013753, 'Total loss': 0.4256020387013753} | train loss {'Reaction outcome loss': 0.12637587463220964, 'Total loss': 0.12637587463220964}
2022-12-31 04:51:53,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:53,747 INFO:     Epoch: 48
2022-12-31 04:51:55,362 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4613513257354498, 'Total loss': 0.4613513257354498} | train loss {'Reaction outcome loss': 0.1283035618959109, 'Total loss': 0.1283035618959109}
2022-12-31 04:51:55,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:55,362 INFO:     Epoch: 49
2022-12-31 04:51:57,027 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43401031419634817, 'Total loss': 0.43401031419634817} | train loss {'Reaction outcome loss': 0.1247271513398266, 'Total loss': 0.1247271513398266}
2022-12-31 04:51:57,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:57,028 INFO:     Epoch: 50
2022-12-31 04:51:58,647 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44263391296068827, 'Total loss': 0.44263391296068827} | train loss {'Reaction outcome loss': 0.12442811245320613, 'Total loss': 0.12442811245320613}
2022-12-31 04:51:58,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:51:58,647 INFO:     Epoch: 51
2022-12-31 04:52:00,291 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47915809949239097, 'Total loss': 0.47915809949239097} | train loss {'Reaction outcome loss': 0.12408335363351158, 'Total loss': 0.12408335363351158}
2022-12-31 04:52:00,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:00,292 INFO:     Epoch: 52
2022-12-31 04:52:01,924 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4530031448851029, 'Total loss': 0.4530031448851029} | train loss {'Reaction outcome loss': 0.12667696033049683, 'Total loss': 0.12667696033049683}
2022-12-31 04:52:01,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:01,925 INFO:     Epoch: 53
2022-12-31 04:52:03,558 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4518230710799495, 'Total loss': 0.4518230710799495} | train loss {'Reaction outcome loss': 0.1232609061275471, 'Total loss': 0.1232609061275471}
2022-12-31 04:52:03,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:03,558 INFO:     Epoch: 54
2022-12-31 04:52:05,180 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45277190605799356, 'Total loss': 0.45277190605799356} | train loss {'Reaction outcome loss': 0.12332745629113961, 'Total loss': 0.12332745629113961}
2022-12-31 04:52:05,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:05,180 INFO:     Epoch: 55
2022-12-31 04:52:06,814 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4661784658829371, 'Total loss': 0.4661784658829371} | train loss {'Reaction outcome loss': 0.12171126911265352, 'Total loss': 0.12171126911265352}
2022-12-31 04:52:06,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:06,814 INFO:     Epoch: 56
2022-12-31 04:52:08,446 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4581632117430369, 'Total loss': 0.4581632117430369} | train loss {'Reaction outcome loss': 0.12029299044490721, 'Total loss': 0.12029299044490721}
2022-12-31 04:52:08,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:08,446 INFO:     Epoch: 57
2022-12-31 04:52:10,094 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5322153806686402, 'Total loss': 0.5322153806686402} | train loss {'Reaction outcome loss': 0.12161442052593138, 'Total loss': 0.12161442052593138}
2022-12-31 04:52:10,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:10,095 INFO:     Epoch: 58
2022-12-31 04:52:11,709 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.450225882177862, 'Total loss': 0.450225882177862} | train loss {'Reaction outcome loss': 0.11967668531375134, 'Total loss': 0.11967668531375134}
2022-12-31 04:52:11,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:11,711 INFO:     Epoch: 59
2022-12-31 04:52:13,325 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48330950140953066, 'Total loss': 0.48330950140953066} | train loss {'Reaction outcome loss': 0.12384749778179915, 'Total loss': 0.12384749778179915}
2022-12-31 04:52:13,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:13,325 INFO:     Epoch: 60
2022-12-31 04:52:14,990 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4744859461983045, 'Total loss': 0.4744859461983045} | train loss {'Reaction outcome loss': 0.12001062903405312, 'Total loss': 0.12001062903405312}
2022-12-31 04:52:14,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:14,990 INFO:     Epoch: 61
2022-12-31 04:52:16,656 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4607641279697418, 'Total loss': 0.4607641279697418} | train loss {'Reaction outcome loss': 0.1204943213685809, 'Total loss': 0.1204943213685809}
2022-12-31 04:52:16,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:16,657 INFO:     Epoch: 62
2022-12-31 04:52:18,310 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4960769454638163, 'Total loss': 0.4960769454638163} | train loss {'Reaction outcome loss': 0.11853985564904254, 'Total loss': 0.11853985564904254}
2022-12-31 04:52:18,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:18,311 INFO:     Epoch: 63
2022-12-31 04:52:19,928 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4254416346549988, 'Total loss': 0.4254416346549988} | train loss {'Reaction outcome loss': 0.1180283223171231, 'Total loss': 0.1180283223171231}
2022-12-31 04:52:19,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:19,929 INFO:     Epoch: 64
2022-12-31 04:52:21,594 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47521919906139376, 'Total loss': 0.47521919906139376} | train loss {'Reaction outcome loss': 0.11481182830280452, 'Total loss': 0.11481182830280452}
2022-12-31 04:52:21,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:21,594 INFO:     Epoch: 65
2022-12-31 04:52:23,228 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46929391026496886, 'Total loss': 0.46929391026496886} | train loss {'Reaction outcome loss': 0.11548323571994659, 'Total loss': 0.11548323571994659}
2022-12-31 04:52:23,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:23,228 INFO:     Epoch: 66
2022-12-31 04:52:24,894 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46493087311585746, 'Total loss': 0.46493087311585746} | train loss {'Reaction outcome loss': 0.11409217360957327, 'Total loss': 0.11409217360957327}
2022-12-31 04:52:24,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:24,894 INFO:     Epoch: 67
2022-12-31 04:52:26,514 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4561488300561905, 'Total loss': 0.4561488300561905} | train loss {'Reaction outcome loss': 0.11816679272676284, 'Total loss': 0.11816679272676284}
2022-12-31 04:52:26,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:26,515 INFO:     Epoch: 68
2022-12-31 04:52:28,168 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46338477432727815, 'Total loss': 0.46338477432727815} | train loss {'Reaction outcome loss': 0.11328507218987341, 'Total loss': 0.11328507218987341}
2022-12-31 04:52:28,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:28,168 INFO:     Epoch: 69
2022-12-31 04:52:29,835 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4955874850352605, 'Total loss': 0.4955874850352605} | train loss {'Reaction outcome loss': 0.11696973986526958, 'Total loss': 0.11696973986526958}
2022-12-31 04:52:29,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:29,835 INFO:     Epoch: 70
2022-12-31 04:52:31,460 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46531144380569456, 'Total loss': 0.46531144380569456} | train loss {'Reaction outcome loss': 0.11738511410437605, 'Total loss': 0.11738511410437605}
2022-12-31 04:52:31,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:31,461 INFO:     Epoch: 71
2022-12-31 04:52:33,135 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.461805135011673, 'Total loss': 0.461805135011673} | train loss {'Reaction outcome loss': 0.115100419728778, 'Total loss': 0.115100419728778}
2022-12-31 04:52:33,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:33,135 INFO:     Epoch: 72
2022-12-31 04:52:34,802 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4945163091023763, 'Total loss': 0.4945163091023763} | train loss {'Reaction outcome loss': 0.11385352969411694, 'Total loss': 0.11385352969411694}
2022-12-31 04:52:34,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:34,802 INFO:     Epoch: 73
2022-12-31 04:52:36,457 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4702671438455582, 'Total loss': 0.4702671438455582} | train loss {'Reaction outcome loss': 0.11712397165623382, 'Total loss': 0.11712397165623382}
2022-12-31 04:52:36,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:36,458 INFO:     Epoch: 74
2022-12-31 04:52:38,126 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4687280684709549, 'Total loss': 0.4687280684709549} | train loss {'Reaction outcome loss': 0.1145349346178614, 'Total loss': 0.1145349346178614}
2022-12-31 04:52:38,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:38,126 INFO:     Epoch: 75
2022-12-31 04:52:39,740 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4877493033806483, 'Total loss': 0.4877493033806483} | train loss {'Reaction outcome loss': 0.11373197472745061, 'Total loss': 0.11373197472745061}
2022-12-31 04:52:39,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:39,740 INFO:     Epoch: 76
2022-12-31 04:52:41,383 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48140812913576764, 'Total loss': 0.48140812913576764} | train loss {'Reaction outcome loss': 0.11271322985929487, 'Total loss': 0.11271322985929487}
2022-12-31 04:52:41,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:41,383 INFO:     Epoch: 77
2022-12-31 04:52:43,011 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47675512234369916, 'Total loss': 0.47675512234369916} | train loss {'Reaction outcome loss': 0.10953800920615585, 'Total loss': 0.10953800920615585}
2022-12-31 04:52:43,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:43,011 INFO:     Epoch: 78
2022-12-31 04:52:44,638 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4548108369112015, 'Total loss': 0.4548108369112015} | train loss {'Reaction outcome loss': 0.11193882865118475, 'Total loss': 0.11193882865118475}
2022-12-31 04:52:44,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:44,639 INFO:     Epoch: 79
2022-12-31 04:52:46,261 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4642265260219574, 'Total loss': 0.4642265260219574} | train loss {'Reaction outcome loss': 0.10918158237126384, 'Total loss': 0.10918158237126384}
2022-12-31 04:52:46,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:46,261 INFO:     Epoch: 80
2022-12-31 04:52:47,893 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5185074746608734, 'Total loss': 0.5185074746608734} | train loss {'Reaction outcome loss': 0.10969704855737757, 'Total loss': 0.10969704855737757}
2022-12-31 04:52:47,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:47,894 INFO:     Epoch: 81
2022-12-31 04:52:49,525 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47240126033624014, 'Total loss': 0.47240126033624014} | train loss {'Reaction outcome loss': 0.11768052111201607, 'Total loss': 0.11768052111201607}
2022-12-31 04:52:49,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:49,526 INFO:     Epoch: 82
2022-12-31 04:52:51,149 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5089775289098422, 'Total loss': 0.5089775289098422} | train loss {'Reaction outcome loss': 0.11771646906900815, 'Total loss': 0.11771646906900815}
2022-12-31 04:52:51,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:51,149 INFO:     Epoch: 83
2022-12-31 04:52:52,780 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4756556371847788, 'Total loss': 0.4756556371847788} | train loss {'Reaction outcome loss': 0.11071836181818794, 'Total loss': 0.11071836181818794}
2022-12-31 04:52:52,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:52,781 INFO:     Epoch: 84
2022-12-31 04:52:54,410 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5013117479781309, 'Total loss': 0.5013117479781309} | train loss {'Reaction outcome loss': 0.10896253316168966, 'Total loss': 0.10896253316168966}
2022-12-31 04:52:54,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:54,411 INFO:     Epoch: 85
2022-12-31 04:52:56,068 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.451515265305837, 'Total loss': 0.451515265305837} | train loss {'Reaction outcome loss': 0.1065210787518898, 'Total loss': 0.1065210787518898}
2022-12-31 04:52:56,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:56,069 INFO:     Epoch: 86
2022-12-31 04:52:57,735 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4665639599164327, 'Total loss': 0.4665639599164327} | train loss {'Reaction outcome loss': 0.10774456120570214, 'Total loss': 0.10774456120570214}
2022-12-31 04:52:57,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:57,736 INFO:     Epoch: 87
2022-12-31 04:52:59,384 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4667996724446615, 'Total loss': 0.4667996724446615} | train loss {'Reaction outcome loss': 0.10972945831231908, 'Total loss': 0.10972945831231908}
2022-12-31 04:52:59,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:52:59,385 INFO:     Epoch: 88
2022-12-31 04:53:01,051 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44192049900690716, 'Total loss': 0.44192049900690716} | train loss {'Reaction outcome loss': 0.11201769364190822, 'Total loss': 0.11201769364190822}
2022-12-31 04:53:01,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:01,052 INFO:     Epoch: 89
2022-12-31 04:53:02,677 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46657585104306537, 'Total loss': 0.46657585104306537} | train loss {'Reaction outcome loss': 0.11166909467496167, 'Total loss': 0.11166909467496167}
2022-12-31 04:53:02,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:02,677 INFO:     Epoch: 90
2022-12-31 04:53:04,331 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45757764875888823, 'Total loss': 0.45757764875888823} | train loss {'Reaction outcome loss': 0.10887957355747208, 'Total loss': 0.10887957355747208}
2022-12-31 04:53:04,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:04,331 INFO:     Epoch: 91
2022-12-31 04:53:05,999 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4537014891703924, 'Total loss': 0.4537014891703924} | train loss {'Reaction outcome loss': 0.10496944324062996, 'Total loss': 0.10496944324062996}
2022-12-31 04:53:05,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:05,999 INFO:     Epoch: 92
2022-12-31 04:53:07,668 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46050289968649544, 'Total loss': 0.46050289968649544} | train loss {'Reaction outcome loss': 0.10475345335846989, 'Total loss': 0.10475345335846989}
2022-12-31 04:53:07,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:07,669 INFO:     Epoch: 93
2022-12-31 04:53:09,291 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45012057622273766, 'Total loss': 0.45012057622273766} | train loss {'Reaction outcome loss': 0.10721107774215753, 'Total loss': 0.10721107774215753}
2022-12-31 04:53:09,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:09,291 INFO:     Epoch: 94
2022-12-31 04:53:10,917 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4692657619714737, 'Total loss': 0.4692657619714737} | train loss {'Reaction outcome loss': 0.11277410143142438, 'Total loss': 0.11277410143142438}
2022-12-31 04:53:10,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:10,917 INFO:     Epoch: 95
2022-12-31 04:53:12,543 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45249509314695996, 'Total loss': 0.45249509314695996} | train loss {'Reaction outcome loss': 0.11086903146252924, 'Total loss': 0.11086903146252924}
2022-12-31 04:53:12,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:12,543 INFO:     Epoch: 96
2022-12-31 04:53:14,169 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48246207684278486, 'Total loss': 0.48246207684278486} | train loss {'Reaction outcome loss': 0.10895478825962393, 'Total loss': 0.10895478825962393}
2022-12-31 04:53:14,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:14,169 INFO:     Epoch: 97
2022-12-31 04:53:15,792 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45126482446988425, 'Total loss': 0.45126482446988425} | train loss {'Reaction outcome loss': 0.10776902905527488, 'Total loss': 0.10776902905527488}
2022-12-31 04:53:15,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:15,793 INFO:     Epoch: 98
2022-12-31 04:53:17,449 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4897192617257436, 'Total loss': 0.4897192617257436} | train loss {'Reaction outcome loss': 0.1066292932388181, 'Total loss': 0.1066292932388181}
2022-12-31 04:53:17,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:17,450 INFO:     Epoch: 99
2022-12-31 04:53:19,078 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4487664485350251, 'Total loss': 0.4487664485350251} | train loss {'Reaction outcome loss': 0.10634240886912638, 'Total loss': 0.10634240886912638}
2022-12-31 04:53:19,079 INFO:     Best model found after epoch 25 of 100.
2022-12-31 04:53:19,080 INFO:   Done with stage: TRAINING
2022-12-31 04:53:19,080 INFO:   Starting stage: EVALUATION
2022-12-31 04:53:19,207 INFO:   Done with stage: EVALUATION
2022-12-31 04:53:19,207 INFO:   Leaving out SEQ value Fold_8
2022-12-31 04:53:19,220 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 04:53:19,220 INFO:   Starting stage: FEATURE SCALING
2022-12-31 04:53:19,873 INFO:   Done with stage: FEATURE SCALING
2022-12-31 04:53:19,874 INFO:   Starting stage: SCALING TARGETS
2022-12-31 04:53:19,947 INFO:   Done with stage: SCALING TARGETS
2022-12-31 04:53:19,947 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:53:19,947 INFO:     No hyperparam tuning for this model
2022-12-31 04:53:19,947 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:53:19,947 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 04:53:19,948 INFO:     None feature selector for col prot
2022-12-31 04:53:19,948 INFO:     None feature selector for col prot
2022-12-31 04:53:19,948 INFO:     None feature selector for col prot
2022-12-31 04:53:19,949 INFO:     None feature selector for col chem
2022-12-31 04:53:19,949 INFO:     None feature selector for col chem
2022-12-31 04:53:19,949 INFO:     None feature selector for col chem
2022-12-31 04:53:19,949 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 04:53:19,949 INFO:   Starting stage: BUILD MODEL
2022-12-31 04:53:19,951 INFO:     Number of params in model 224011
2022-12-31 04:53:19,954 INFO:   Done with stage: BUILD MODEL
2022-12-31 04:53:19,954 INFO:   Starting stage: TRAINING
2022-12-31 04:53:20,001 INFO:     Val loss before train {'Reaction outcome loss': 0.9445023099581401, 'Total loss': 0.9445023099581401}
2022-12-31 04:53:20,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:20,001 INFO:     Epoch: 0
2022-12-31 04:53:21,631 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5230566442012787, 'Total loss': 0.5230566442012787} | train loss {'Reaction outcome loss': 0.792759498749399, 'Total loss': 0.792759498749399}
2022-12-31 04:53:21,631 INFO:     Found new best model at epoch 0
2022-12-31 04:53:21,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:21,632 INFO:     Epoch: 1
2022-12-31 04:53:23,275 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4735034426053365, 'Total loss': 0.4735034426053365} | train loss {'Reaction outcome loss': 0.5224239493212545, 'Total loss': 0.5224239493212545}
2022-12-31 04:53:23,275 INFO:     Found new best model at epoch 1
2022-12-31 04:53:23,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:23,276 INFO:     Epoch: 2
2022-12-31 04:53:24,900 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.43354570865631104, 'Total loss': 0.43354570865631104} | train loss {'Reaction outcome loss': 0.44834833845012023, 'Total loss': 0.44834833845012023}
2022-12-31 04:53:24,900 INFO:     Found new best model at epoch 2
2022-12-31 04:53:24,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:24,901 INFO:     Epoch: 3
2022-12-31 04:53:26,518 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.42227696180343627, 'Total loss': 0.42227696180343627} | train loss {'Reaction outcome loss': 0.40570586500185063, 'Total loss': 0.40570586500185063}
2022-12-31 04:53:26,518 INFO:     Found new best model at epoch 3
2022-12-31 04:53:26,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:26,519 INFO:     Epoch: 4
2022-12-31 04:53:28,143 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43666244149208067, 'Total loss': 0.43666244149208067} | train loss {'Reaction outcome loss': 0.36988332617476527, 'Total loss': 0.36988332617476527}
2022-12-31 04:53:28,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:28,143 INFO:     Epoch: 5
2022-12-31 04:53:29,769 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4063224752744039, 'Total loss': 0.4063224752744039} | train loss {'Reaction outcome loss': 0.3452071951238257, 'Total loss': 0.3452071951238257}
2022-12-31 04:53:29,769 INFO:     Found new best model at epoch 5
2022-12-31 04:53:29,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:29,770 INFO:     Epoch: 6
2022-12-31 04:53:31,408 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3764063725868861, 'Total loss': 0.3764063725868861} | train loss {'Reaction outcome loss': 0.32385211338420206, 'Total loss': 0.32385211338420206}
2022-12-31 04:53:31,408 INFO:     Found new best model at epoch 6
2022-12-31 04:53:31,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:31,409 INFO:     Epoch: 7
2022-12-31 04:53:33,030 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3960123141606649, 'Total loss': 0.3960123141606649} | train loss {'Reaction outcome loss': 0.3052979181739182, 'Total loss': 0.3052979181739182}
2022-12-31 04:53:33,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:33,031 INFO:     Epoch: 8
2022-12-31 04:53:34,654 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.393187952041626, 'Total loss': 0.393187952041626} | train loss {'Reaction outcome loss': 0.2903287167583562, 'Total loss': 0.2903287167583562}
2022-12-31 04:53:34,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:34,655 INFO:     Epoch: 9
2022-12-31 04:53:36,282 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3821841577688853, 'Total loss': 0.3821841577688853} | train loss {'Reaction outcome loss': 0.27889076690273595, 'Total loss': 0.27889076690273595}
2022-12-31 04:53:36,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:36,282 INFO:     Epoch: 10
2022-12-31 04:53:37,906 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.38449209729830425, 'Total loss': 0.38449209729830425} | train loss {'Reaction outcome loss': 0.26193084524749416, 'Total loss': 0.26193084524749416}
2022-12-31 04:53:37,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:37,907 INFO:     Epoch: 11
2022-12-31 04:53:39,574 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.37136794328689576, 'Total loss': 0.37136794328689576} | train loss {'Reaction outcome loss': 0.25305666462501464, 'Total loss': 0.25305666462501464}
2022-12-31 04:53:39,575 INFO:     Found new best model at epoch 11
2022-12-31 04:53:39,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:39,576 INFO:     Epoch: 12
2022-12-31 04:53:41,205 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39105627238750457, 'Total loss': 0.39105627238750457} | train loss {'Reaction outcome loss': 0.24291789527673152, 'Total loss': 0.24291789527673152}
2022-12-31 04:53:41,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:41,205 INFO:     Epoch: 13
2022-12-31 04:53:42,827 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3757960746685664, 'Total loss': 0.3757960746685664} | train loss {'Reaction outcome loss': 0.2301042687268894, 'Total loss': 0.2301042687268894}
2022-12-31 04:53:42,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:42,827 INFO:     Epoch: 14
2022-12-31 04:53:44,446 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3848419388135274, 'Total loss': 0.3848419388135274} | train loss {'Reaction outcome loss': 0.22459490716941521, 'Total loss': 0.22459490716941521}
2022-12-31 04:53:44,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:44,446 INFO:     Epoch: 15
2022-12-31 04:53:46,066 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3580669124921163, 'Total loss': 0.3580669124921163} | train loss {'Reaction outcome loss': 0.21412580783078816, 'Total loss': 0.21412580783078816}
2022-12-31 04:53:46,067 INFO:     Found new best model at epoch 15
2022-12-31 04:53:46,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:46,068 INFO:     Epoch: 16
2022-12-31 04:53:47,686 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.37543396751085917, 'Total loss': 0.37543396751085917} | train loss {'Reaction outcome loss': 0.20976868236861074, 'Total loss': 0.20976868236861074}
2022-12-31 04:53:47,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:47,687 INFO:     Epoch: 17
2022-12-31 04:53:49,338 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3792281617720922, 'Total loss': 0.3792281617720922} | train loss {'Reaction outcome loss': 0.20209673179199225, 'Total loss': 0.20209673179199225}
2022-12-31 04:53:49,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:49,339 INFO:     Epoch: 18
2022-12-31 04:53:50,956 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3507496876021226, 'Total loss': 0.3507496876021226} | train loss {'Reaction outcome loss': 0.19636435544165357, 'Total loss': 0.19636435544165357}
2022-12-31 04:53:50,957 INFO:     Found new best model at epoch 18
2022-12-31 04:53:50,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:50,958 INFO:     Epoch: 19
2022-12-31 04:53:52,575 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3657299006978671, 'Total loss': 0.3657299006978671} | train loss {'Reaction outcome loss': 0.19087107584472168, 'Total loss': 0.19087107584472168}
2022-12-31 04:53:52,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:52,576 INFO:     Epoch: 20
2022-12-31 04:53:54,192 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3832058310508728, 'Total loss': 0.3832058310508728} | train loss {'Reaction outcome loss': 0.18804124630449695, 'Total loss': 0.18804124630449695}
2022-12-31 04:53:54,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:54,192 INFO:     Epoch: 21
2022-12-31 04:53:55,819 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3727208157380422, 'Total loss': 0.3727208157380422} | train loss {'Reaction outcome loss': 0.1867319032186743, 'Total loss': 0.1867319032186743}
2022-12-31 04:53:55,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:55,820 INFO:     Epoch: 22
2022-12-31 04:53:57,449 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3680194020271301, 'Total loss': 0.3680194020271301} | train loss {'Reaction outcome loss': 0.17997476428962356, 'Total loss': 0.17997476428962356}
2022-12-31 04:53:57,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:57,449 INFO:     Epoch: 23
2022-12-31 04:53:59,070 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3732607265313466, 'Total loss': 0.3732607265313466} | train loss {'Reaction outcome loss': 0.1719954505576231, 'Total loss': 0.1719954505576231}
2022-12-31 04:53:59,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:53:59,070 INFO:     Epoch: 24
2022-12-31 04:54:00,701 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3797352880239487, 'Total loss': 0.3797352880239487} | train loss {'Reaction outcome loss': 0.1719329152189007, 'Total loss': 0.1719329152189007}
2022-12-31 04:54:00,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:00,701 INFO:     Epoch: 25
2022-12-31 04:54:02,334 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3662605081995328, 'Total loss': 0.3662605081995328} | train loss {'Reaction outcome loss': 0.16762690699998867, 'Total loss': 0.16762690699998867}
2022-12-31 04:54:02,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:02,334 INFO:     Epoch: 26
2022-12-31 04:54:03,961 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39666282137235004, 'Total loss': 0.39666282137235004} | train loss {'Reaction outcome loss': 0.1651531545485669, 'Total loss': 0.1651531545485669}
2022-12-31 04:54:03,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:03,961 INFO:     Epoch: 27
2022-12-31 04:54:05,595 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3633100171883901, 'Total loss': 0.3633100171883901} | train loss {'Reaction outcome loss': 0.1621984916803047, 'Total loss': 0.1621984916803047}
2022-12-31 04:54:05,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:05,595 INFO:     Epoch: 28
2022-12-31 04:54:07,219 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39677804211775464, 'Total loss': 0.39677804211775464} | train loss {'Reaction outcome loss': 0.15921413531990902, 'Total loss': 0.15921413531990902}
2022-12-31 04:54:07,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:07,220 INFO:     Epoch: 29
2022-12-31 04:54:08,845 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3527253657579422, 'Total loss': 0.3527253657579422} | train loss {'Reaction outcome loss': 0.15907091509201143, 'Total loss': 0.15907091509201143}
2022-12-31 04:54:08,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:08,846 INFO:     Epoch: 30
2022-12-31 04:54:10,466 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3988731324672699, 'Total loss': 0.3988731324672699} | train loss {'Reaction outcome loss': 0.15447651690026806, 'Total loss': 0.15447651690026806}
2022-12-31 04:54:10,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:10,466 INFO:     Epoch: 31
2022-12-31 04:54:12,117 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3750797520081202, 'Total loss': 0.3750797520081202} | train loss {'Reaction outcome loss': 0.1546135918869358, 'Total loss': 0.1546135918869358}
2022-12-31 04:54:12,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:12,118 INFO:     Epoch: 32
2022-12-31 04:54:13,785 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3713094264268875, 'Total loss': 0.3713094264268875} | train loss {'Reaction outcome loss': 0.1493634937939634, 'Total loss': 0.1493634937939634}
2022-12-31 04:54:13,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:13,786 INFO:     Epoch: 33
2022-12-31 04:54:15,405 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3634484072526296, 'Total loss': 0.3634484072526296} | train loss {'Reaction outcome loss': 0.14579506976435816, 'Total loss': 0.14579506976435816}
2022-12-31 04:54:15,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:15,405 INFO:     Epoch: 34
2022-12-31 04:54:17,056 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3851795643568039, 'Total loss': 0.3851795643568039} | train loss {'Reaction outcome loss': 0.14528125471062286, 'Total loss': 0.14528125471062286}
2022-12-31 04:54:17,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:17,056 INFO:     Epoch: 35
2022-12-31 04:54:18,679 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3875212808450063, 'Total loss': 0.3875212808450063} | train loss {'Reaction outcome loss': 0.14470079679727985, 'Total loss': 0.14470079679727985}
2022-12-31 04:54:18,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:18,680 INFO:     Epoch: 36
2022-12-31 04:54:20,303 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37577176094055176, 'Total loss': 0.37577176094055176} | train loss {'Reaction outcome loss': 0.14391476525975533, 'Total loss': 0.14391476525975533}
2022-12-31 04:54:20,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:20,305 INFO:     Epoch: 37
2022-12-31 04:54:21,918 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39095760583877565, 'Total loss': 0.39095760583877565} | train loss {'Reaction outcome loss': 0.1414417192198686, 'Total loss': 0.1414417192198686}
2022-12-31 04:54:21,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:21,919 INFO:     Epoch: 38
2022-12-31 04:54:23,545 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3887606754899025, 'Total loss': 0.3887606754899025} | train loss {'Reaction outcome loss': 0.13805817204799892, 'Total loss': 0.13805817204799892}
2022-12-31 04:54:23,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:23,545 INFO:     Epoch: 39
2022-12-31 04:54:25,211 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3870701839526494, 'Total loss': 0.3870701839526494} | train loss {'Reaction outcome loss': 0.13862964050972074, 'Total loss': 0.13862964050972074}
2022-12-31 04:54:25,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:25,211 INFO:     Epoch: 40
2022-12-31 04:54:26,861 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3926627713876466, 'Total loss': 0.3926627713876466} | train loss {'Reaction outcome loss': 0.1364312294470516, 'Total loss': 0.1364312294470516}
2022-12-31 04:54:26,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:26,862 INFO:     Epoch: 41
2022-12-31 04:54:28,483 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4038199504216512, 'Total loss': 0.4038199504216512} | train loss {'Reaction outcome loss': 0.1381684878356889, 'Total loss': 0.1381684878356889}
2022-12-31 04:54:28,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:28,483 INFO:     Epoch: 42
2022-12-31 04:54:30,133 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3816655114293098, 'Total loss': 0.3816655114293098} | train loss {'Reaction outcome loss': 0.136250065350468, 'Total loss': 0.136250065350468}
2022-12-31 04:54:30,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:30,134 INFO:     Epoch: 43
2022-12-31 04:54:31,752 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.36680556237697604, 'Total loss': 0.36680556237697604} | train loss {'Reaction outcome loss': 0.13279417522641618, 'Total loss': 0.13279417522641618}
2022-12-31 04:54:31,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:31,752 INFO:     Epoch: 44
2022-12-31 04:54:33,372 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3784288654724757, 'Total loss': 0.3784288654724757} | train loss {'Reaction outcome loss': 0.13176661355602504, 'Total loss': 0.13176661355602504}
2022-12-31 04:54:33,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:33,372 INFO:     Epoch: 45
2022-12-31 04:54:35,024 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38199339757363, 'Total loss': 0.38199339757363} | train loss {'Reaction outcome loss': 0.13277060645111308, 'Total loss': 0.13277060645111308}
2022-12-31 04:54:35,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:35,024 INFO:     Epoch: 46
2022-12-31 04:54:36,643 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.37738630374272664, 'Total loss': 0.37738630374272664} | train loss {'Reaction outcome loss': 0.12780441759517316, 'Total loss': 0.12780441759517316}
2022-12-31 04:54:36,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:36,643 INFO:     Epoch: 47
2022-12-31 04:54:38,311 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40735116600990295, 'Total loss': 0.40735116600990295} | train loss {'Reaction outcome loss': 0.13016659530242805, 'Total loss': 0.13016659530242805}
2022-12-31 04:54:38,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:38,311 INFO:     Epoch: 48
2022-12-31 04:54:39,921 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38118331333001454, 'Total loss': 0.38118331333001454} | train loss {'Reaction outcome loss': 0.1354649825835271, 'Total loss': 0.1354649825835271}
2022-12-31 04:54:39,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:39,922 INFO:     Epoch: 49
2022-12-31 04:54:41,541 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3691689545909564, 'Total loss': 0.3691689545909564} | train loss {'Reaction outcome loss': 0.13121093061856845, 'Total loss': 0.13121093061856845}
2022-12-31 04:54:41,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:41,542 INFO:     Epoch: 50
2022-12-31 04:54:43,208 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37323432192206385, 'Total loss': 0.37323432192206385} | train loss {'Reaction outcome loss': 0.12866785259755995, 'Total loss': 0.12866785259755995}
2022-12-31 04:54:43,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:43,209 INFO:     Epoch: 51
2022-12-31 04:54:44,835 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.37746534844239554, 'Total loss': 0.37746534844239554} | train loss {'Reaction outcome loss': 0.12582585675430077, 'Total loss': 0.12582585675430077}
2022-12-31 04:54:44,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:44,835 INFO:     Epoch: 52
2022-12-31 04:54:46,466 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3875588566064835, 'Total loss': 0.3875588566064835} | train loss {'Reaction outcome loss': 0.12358186895444666, 'Total loss': 0.12358186895444666}
2022-12-31 04:54:46,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:46,467 INFO:     Epoch: 53
2022-12-31 04:54:48,095 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38009879489739734, 'Total loss': 0.38009879489739734} | train loss {'Reaction outcome loss': 0.12424842147526435, 'Total loss': 0.12424842147526435}
2022-12-31 04:54:48,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:48,095 INFO:     Epoch: 54
2022-12-31 04:54:49,752 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3622772837678591, 'Total loss': 0.3622772837678591} | train loss {'Reaction outcome loss': 0.12270159195496663, 'Total loss': 0.12270159195496663}
2022-12-31 04:54:49,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:49,752 INFO:     Epoch: 55
2022-12-31 04:54:51,371 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40337913334369657, 'Total loss': 0.40337913334369657} | train loss {'Reaction outcome loss': 0.1256091192445385, 'Total loss': 0.1256091192445385}
2022-12-31 04:54:51,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:51,372 INFO:     Epoch: 56
2022-12-31 04:54:52,990 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4138017475605011, 'Total loss': 0.4138017475605011} | train loss {'Reaction outcome loss': 0.12279664979245689, 'Total loss': 0.12279664979245689}
2022-12-31 04:54:52,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:52,990 INFO:     Epoch: 57
2022-12-31 04:54:54,657 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39784730871518453, 'Total loss': 0.39784730871518453} | train loss {'Reaction outcome loss': 0.12463993048093648, 'Total loss': 0.12463993048093648}
2022-12-31 04:54:54,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:54,657 INFO:     Epoch: 58
2022-12-31 04:54:56,269 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3809943323334058, 'Total loss': 0.3809943323334058} | train loss {'Reaction outcome loss': 0.1215602964304038, 'Total loss': 0.1215602964304038}
2022-12-31 04:54:56,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:56,269 INFO:     Epoch: 59
2022-12-31 04:54:57,906 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3746212124824524, 'Total loss': 0.3746212124824524} | train loss {'Reaction outcome loss': 0.12106488429897529, 'Total loss': 0.12106488429897529}
2022-12-31 04:54:57,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:57,907 INFO:     Epoch: 60
2022-12-31 04:54:59,523 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3722427010536194, 'Total loss': 0.3722427010536194} | train loss {'Reaction outcome loss': 0.12221789705173687, 'Total loss': 0.12221789705173687}
2022-12-31 04:54:59,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:54:59,524 INFO:     Epoch: 61
2022-12-31 04:55:01,190 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3564655090371768, 'Total loss': 0.3564655090371768} | train loss {'Reaction outcome loss': 0.12152349092705102, 'Total loss': 0.12152349092705102}
2022-12-31 04:55:01,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:01,190 INFO:     Epoch: 62
2022-12-31 04:55:02,841 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3869527707497279, 'Total loss': 0.3869527707497279} | train loss {'Reaction outcome loss': 0.1215829863179381, 'Total loss': 0.1215829863179381}
2022-12-31 04:55:02,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:02,842 INFO:     Epoch: 63
2022-12-31 04:55:04,463 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3887471762796243, 'Total loss': 0.3887471762796243} | train loss {'Reaction outcome loss': 0.11818762891169382, 'Total loss': 0.11818762891169382}
2022-12-31 04:55:04,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:04,464 INFO:     Epoch: 64
2022-12-31 04:55:06,130 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3962844908237457, 'Total loss': 0.3962844908237457} | train loss {'Reaction outcome loss': 0.11689742885207226, 'Total loss': 0.11689742885207226}
2022-12-31 04:55:06,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:06,130 INFO:     Epoch: 65
2022-12-31 04:55:07,740 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4001348992188772, 'Total loss': 0.4001348992188772} | train loss {'Reaction outcome loss': 0.12007740102304879, 'Total loss': 0.12007740102304879}
2022-12-31 04:55:07,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:07,740 INFO:     Epoch: 66
2022-12-31 04:55:09,406 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40368520418802895, 'Total loss': 0.40368520418802895} | train loss {'Reaction outcome loss': 0.11421995811561116, 'Total loss': 0.11421995811561116}
2022-12-31 04:55:09,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:09,406 INFO:     Epoch: 67
2022-12-31 04:55:11,025 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4116563086708387, 'Total loss': 0.4116563086708387} | train loss {'Reaction outcome loss': 0.11617604240485961, 'Total loss': 0.11617604240485961}
2022-12-31 04:55:11,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:11,026 INFO:     Epoch: 68
2022-12-31 04:55:12,643 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3826877882083257, 'Total loss': 0.3826877882083257} | train loss {'Reaction outcome loss': 0.1166975497493406, 'Total loss': 0.1166975497493406}
2022-12-31 04:55:12,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:12,643 INFO:     Epoch: 69
2022-12-31 04:55:14,260 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3863360156615575, 'Total loss': 0.3863360156615575} | train loss {'Reaction outcome loss': 0.11353367370207011, 'Total loss': 0.11353367370207011}
2022-12-31 04:55:14,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:14,260 INFO:     Epoch: 70
2022-12-31 04:55:15,874 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.415458312133948, 'Total loss': 0.415458312133948} | train loss {'Reaction outcome loss': 0.11585708481464736, 'Total loss': 0.11585708481464736}
2022-12-31 04:55:15,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:15,874 INFO:     Epoch: 71
2022-12-31 04:55:17,495 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38102391362190247, 'Total loss': 0.38102391362190247} | train loss {'Reaction outcome loss': 0.11532642684930713, 'Total loss': 0.11532642684930713}
2022-12-31 04:55:17,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:17,495 INFO:     Epoch: 72
2022-12-31 04:55:19,118 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3586779708663623, 'Total loss': 0.3586779708663623} | train loss {'Reaction outcome loss': 0.11058329071577248, 'Total loss': 0.11058329071577248}
2022-12-31 04:55:19,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:19,118 INFO:     Epoch: 73
2022-12-31 04:55:20,732 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37880182365576426, 'Total loss': 0.37880182365576426} | train loss {'Reaction outcome loss': 0.11467707336170847, 'Total loss': 0.11467707336170847}
2022-12-31 04:55:20,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:20,732 INFO:     Epoch: 74
2022-12-31 04:55:22,353 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40437113245328266, 'Total loss': 0.40437113245328266} | train loss {'Reaction outcome loss': 0.11934217157192017, 'Total loss': 0.11934217157192017}
2022-12-31 04:55:22,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:22,353 INFO:     Epoch: 75
2022-12-31 04:55:23,972 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40618788450956345, 'Total loss': 0.40618788450956345} | train loss {'Reaction outcome loss': 0.1158192772082043, 'Total loss': 0.1158192772082043}
2022-12-31 04:55:23,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:23,972 INFO:     Epoch: 76
2022-12-31 04:55:25,617 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3557032456000646, 'Total loss': 0.3557032456000646} | train loss {'Reaction outcome loss': 0.11039239209185654, 'Total loss': 0.11039239209185654}
2022-12-31 04:55:25,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:25,618 INFO:     Epoch: 77
2022-12-31 04:55:27,238 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38776792933543525, 'Total loss': 0.38776792933543525} | train loss {'Reaction outcome loss': 0.11017495638351309, 'Total loss': 0.11017495638351309}
2022-12-31 04:55:27,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:27,239 INFO:     Epoch: 78
2022-12-31 04:55:28,856 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.34352176189422606, 'Total loss': 0.34352176189422606} | train loss {'Reaction outcome loss': 0.111548741332958, 'Total loss': 0.111548741332958}
2022-12-31 04:55:28,856 INFO:     Found new best model at epoch 78
2022-12-31 04:55:28,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:28,857 INFO:     Epoch: 79
2022-12-31 04:55:30,473 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3614609658718109, 'Total loss': 0.3614609658718109} | train loss {'Reaction outcome loss': 0.10915797806701318, 'Total loss': 0.10915797806701318}
2022-12-31 04:55:30,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:30,473 INFO:     Epoch: 80
2022-12-31 04:55:32,098 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40961431463559467, 'Total loss': 0.40961431463559467} | train loss {'Reaction outcome loss': 0.1093914969336739, 'Total loss': 0.1093914969336739}
2022-12-31 04:55:32,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:32,099 INFO:     Epoch: 81
2022-12-31 04:55:33,715 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3383620657026768, 'Total loss': 0.3383620657026768} | train loss {'Reaction outcome loss': 0.10743395301819332, 'Total loss': 0.10743395301819332}
2022-12-31 04:55:33,716 INFO:     Found new best model at epoch 81
2022-12-31 04:55:33,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:33,717 INFO:     Epoch: 82
2022-12-31 04:55:35,333 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3510161221027374, 'Total loss': 0.3510161221027374} | train loss {'Reaction outcome loss': 0.11138042266605025, 'Total loss': 0.11138042266605025}
2022-12-31 04:55:35,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:35,333 INFO:     Epoch: 83
2022-12-31 04:55:36,951 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3638763964176178, 'Total loss': 0.3638763964176178} | train loss {'Reaction outcome loss': 0.11326938900686397, 'Total loss': 0.11326938900686397}
2022-12-31 04:55:36,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:36,951 INFO:     Epoch: 84
2022-12-31 04:55:38,566 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3715692420800527, 'Total loss': 0.3715692420800527} | train loss {'Reaction outcome loss': 0.10784900185167924, 'Total loss': 0.10784900185167924}
2022-12-31 04:55:38,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:38,566 INFO:     Epoch: 85
2022-12-31 04:55:40,191 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.374466380973657, 'Total loss': 0.374466380973657} | train loss {'Reaction outcome loss': 0.10983969886292996, 'Total loss': 0.10983969886292996}
2022-12-31 04:55:40,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:40,192 INFO:     Epoch: 86
2022-12-31 04:55:41,806 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.36802463233470917, 'Total loss': 0.36802463233470917} | train loss {'Reaction outcome loss': 0.10510330936881555, 'Total loss': 0.10510330936881555}
2022-12-31 04:55:41,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:41,807 INFO:     Epoch: 87
2022-12-31 04:55:43,454 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3647647718588511, 'Total loss': 0.3647647718588511} | train loss {'Reaction outcome loss': 0.10772234516130888, 'Total loss': 0.10772234516130888}
2022-12-31 04:55:43,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:43,454 INFO:     Epoch: 88
2022-12-31 04:55:45,121 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.36654529770215355, 'Total loss': 0.36654529770215355} | train loss {'Reaction outcome loss': 0.11016049418457202, 'Total loss': 0.11016049418457202}
2022-12-31 04:55:45,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:45,121 INFO:     Epoch: 89
2022-12-31 04:55:46,754 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3921160727739334, 'Total loss': 0.3921160727739334} | train loss {'Reaction outcome loss': 0.10763588533921685, 'Total loss': 0.10763588533921685}
2022-12-31 04:55:46,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:46,755 INFO:     Epoch: 90
2022-12-31 04:55:48,384 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3734673003355662, 'Total loss': 0.3734673003355662} | train loss {'Reaction outcome loss': 0.10866844919863214, 'Total loss': 0.10866844919863214}
2022-12-31 04:55:48,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:48,385 INFO:     Epoch: 91
2022-12-31 04:55:50,050 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38190154631932577, 'Total loss': 0.38190154631932577} | train loss {'Reaction outcome loss': 0.10782731258031317, 'Total loss': 0.10782731258031317}
2022-12-31 04:55:50,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:50,050 INFO:     Epoch: 92
2022-12-31 04:55:51,715 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3593577841917674, 'Total loss': 0.3593577841917674} | train loss {'Reaction outcome loss': 0.11028666327293922, 'Total loss': 0.11028666327293922}
2022-12-31 04:55:51,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:51,715 INFO:     Epoch: 93
2022-12-31 04:55:53,373 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3602101974189281, 'Total loss': 0.3602101974189281} | train loss {'Reaction outcome loss': 0.10994501460750422, 'Total loss': 0.10994501460750422}
2022-12-31 04:55:53,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:53,373 INFO:     Epoch: 94
2022-12-31 04:55:54,991 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3882327377796173, 'Total loss': 0.3882327377796173} | train loss {'Reaction outcome loss': 0.10816007089172405, 'Total loss': 0.10816007089172405}
2022-12-31 04:55:54,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:54,991 INFO:     Epoch: 95
2022-12-31 04:55:56,608 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3795441875855128, 'Total loss': 0.3795441875855128} | train loss {'Reaction outcome loss': 0.10362899699290401, 'Total loss': 0.10362899699290401}
2022-12-31 04:55:56,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:56,609 INFO:     Epoch: 96
2022-12-31 04:55:58,225 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3417173683643341, 'Total loss': 0.3417173683643341} | train loss {'Reaction outcome loss': 0.10579530046647583, 'Total loss': 0.10579530046647583}
2022-12-31 04:55:58,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:58,226 INFO:     Epoch: 97
2022-12-31 04:55:59,836 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3889543841282527, 'Total loss': 0.3889543841282527} | train loss {'Reaction outcome loss': 0.10630176048843519, 'Total loss': 0.10630176048843519}
2022-12-31 04:55:59,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:55:59,837 INFO:     Epoch: 98
2022-12-31 04:56:01,480 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37868813077608743, 'Total loss': 0.37868813077608743} | train loss {'Reaction outcome loss': 0.10055714281484324, 'Total loss': 0.10055714281484324}
2022-12-31 04:56:01,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:01,480 INFO:     Epoch: 99
2022-12-31 04:56:03,111 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3463209261496862, 'Total loss': 0.3463209261496862} | train loss {'Reaction outcome loss': 0.10177964453134915, 'Total loss': 0.10177964453134915}
2022-12-31 04:56:03,112 INFO:     Best model found after epoch 82 of 100.
2022-12-31 04:56:03,113 INFO:   Done with stage: TRAINING
2022-12-31 04:56:03,113 INFO:   Starting stage: EVALUATION
2022-12-31 04:56:03,237 INFO:   Done with stage: EVALUATION
2022-12-31 04:56:03,237 INFO:   Leaving out SEQ value Fold_9
2022-12-31 04:56:03,250 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 04:56:03,250 INFO:   Starting stage: FEATURE SCALING
2022-12-31 04:56:03,890 INFO:   Done with stage: FEATURE SCALING
2022-12-31 04:56:03,891 INFO:   Starting stage: SCALING TARGETS
2022-12-31 04:56:03,963 INFO:   Done with stage: SCALING TARGETS
2022-12-31 04:56:03,963 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:56:03,963 INFO:     No hyperparam tuning for this model
2022-12-31 04:56:03,963 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 04:56:03,963 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 04:56:03,964 INFO:     None feature selector for col prot
2022-12-31 04:56:03,964 INFO:     None feature selector for col prot
2022-12-31 04:56:03,964 INFO:     None feature selector for col prot
2022-12-31 04:56:03,964 INFO:     None feature selector for col chem
2022-12-31 04:56:03,965 INFO:     None feature selector for col chem
2022-12-31 04:56:03,965 INFO:     None feature selector for col chem
2022-12-31 04:56:03,965 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 04:56:03,965 INFO:   Starting stage: BUILD MODEL
2022-12-31 04:56:03,967 INFO:     Number of params in model 224011
2022-12-31 04:56:03,970 INFO:   Done with stage: BUILD MODEL
2022-12-31 04:56:03,970 INFO:   Starting stage: TRAINING
2022-12-31 04:56:04,015 INFO:     Val loss before train {'Reaction outcome loss': 0.9877291679382324, 'Total loss': 0.9877291679382324}
2022-12-31 04:56:04,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:04,015 INFO:     Epoch: 0
2022-12-31 04:56:05,629 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.4953001280625661, 'Total loss': 0.4953001280625661} | train loss {'Reaction outcome loss': 0.7937141154020472, 'Total loss': 0.7937141154020472}
2022-12-31 04:56:05,629 INFO:     Found new best model at epoch 0
2022-12-31 04:56:05,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:05,630 INFO:     Epoch: 1
2022-12-31 04:56:07,239 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4412636538346609, 'Total loss': 0.4412636538346609} | train loss {'Reaction outcome loss': 0.5316525667551921, 'Total loss': 0.5316525667551921}
2022-12-31 04:56:07,240 INFO:     Found new best model at epoch 1
2022-12-31 04:56:07,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:07,241 INFO:     Epoch: 2
2022-12-31 04:56:08,851 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.38881856203079224, 'Total loss': 0.38881856203079224} | train loss {'Reaction outcome loss': 0.4608363791544368, 'Total loss': 0.4608363791544368}
2022-12-31 04:56:08,851 INFO:     Found new best model at epoch 2
2022-12-31 04:56:08,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:08,852 INFO:     Epoch: 3
2022-12-31 04:56:10,465 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.36112190087636314, 'Total loss': 0.36112190087636314} | train loss {'Reaction outcome loss': 0.4203404756667821, 'Total loss': 0.4203404756667821}
2022-12-31 04:56:10,466 INFO:     Found new best model at epoch 3
2022-12-31 04:56:10,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:10,467 INFO:     Epoch: 4
2022-12-31 04:56:12,127 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.3594025661547979, 'Total loss': 0.3594025661547979} | train loss {'Reaction outcome loss': 0.3904852005787003, 'Total loss': 0.3904852005787003}
2022-12-31 04:56:12,128 INFO:     Found new best model at epoch 4
2022-12-31 04:56:12,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:12,129 INFO:     Epoch: 5
2022-12-31 04:56:13,762 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.35909774005413053, 'Total loss': 0.35909774005413053} | train loss {'Reaction outcome loss': 0.3824838394218165, 'Total loss': 0.3824838394218165}
2022-12-31 04:56:13,762 INFO:     Found new best model at epoch 5
2022-12-31 04:56:13,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:13,764 INFO:     Epoch: 6
2022-12-31 04:56:15,416 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3301426033178965, 'Total loss': 0.3301426033178965} | train loss {'Reaction outcome loss': 0.3932304307278516, 'Total loss': 0.3932304307278516}
2022-12-31 04:56:15,416 INFO:     Found new best model at epoch 6
2022-12-31 04:56:15,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:15,417 INFO:     Epoch: 7
2022-12-31 04:56:17,034 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3267787014444669, 'Total loss': 0.3267787014444669} | train loss {'Reaction outcome loss': 0.3386836187488845, 'Total loss': 0.3386836187488845}
2022-12-31 04:56:17,034 INFO:     Found new best model at epoch 7
2022-12-31 04:56:17,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:17,036 INFO:     Epoch: 8
2022-12-31 04:56:18,659 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3178875813881556, 'Total loss': 0.3178875813881556} | train loss {'Reaction outcome loss': 0.31863284162397537, 'Total loss': 0.31863284162397537}
2022-12-31 04:56:18,659 INFO:     Found new best model at epoch 8
2022-12-31 04:56:18,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:18,660 INFO:     Epoch: 9
2022-12-31 04:56:20,278 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3267693128436804, 'Total loss': 0.3267693128436804} | train loss {'Reaction outcome loss': 0.30393165891207213, 'Total loss': 0.30393165891207213}
2022-12-31 04:56:20,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:20,278 INFO:     Epoch: 10
2022-12-31 04:56:21,939 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.33295122981071473, 'Total loss': 0.33295122981071473} | train loss {'Reaction outcome loss': 0.2940041672343901, 'Total loss': 0.2940041672343901}
2022-12-31 04:56:21,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:21,939 INFO:     Epoch: 11
2022-12-31 04:56:23,549 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3259976123770078, 'Total loss': 0.3259976123770078} | train loss {'Reaction outcome loss': 0.2804032131638108, 'Total loss': 0.2804032131638108}
2022-12-31 04:56:23,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:23,550 INFO:     Epoch: 12
2022-12-31 04:56:25,166 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3387984792391459, 'Total loss': 0.3387984792391459} | train loss {'Reaction outcome loss': 0.27289307422419684, 'Total loss': 0.27289307422419684}
2022-12-31 04:56:25,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:25,166 INFO:     Epoch: 13
2022-12-31 04:56:26,827 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.33810381442308424, 'Total loss': 0.33810381442308424} | train loss {'Reaction outcome loss': 0.26139385381709185, 'Total loss': 0.26139385381709185}
2022-12-31 04:56:26,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:26,827 INFO:     Epoch: 14
2022-12-31 04:56:28,473 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.34100324908892315, 'Total loss': 0.34100324908892315} | train loss {'Reaction outcome loss': 0.2540444636960392, 'Total loss': 0.2540444636960392}
2022-12-31 04:56:28,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:28,473 INFO:     Epoch: 15
2022-12-31 04:56:30,135 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.327497939268748, 'Total loss': 0.327497939268748} | train loss {'Reaction outcome loss': 0.25901085039789695, 'Total loss': 0.25901085039789695}
2022-12-31 04:56:30,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:30,135 INFO:     Epoch: 16
2022-12-31 04:56:31,752 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.33622369517882666, 'Total loss': 0.33622369517882666} | train loss {'Reaction outcome loss': 0.25073887439161213, 'Total loss': 0.25073887439161213}
2022-12-31 04:56:31,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:31,752 INFO:     Epoch: 17
2022-12-31 04:56:33,402 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3486500268181165, 'Total loss': 0.3486500268181165} | train loss {'Reaction outcome loss': 0.22943160545749022, 'Total loss': 0.22943160545749022}
2022-12-31 04:56:33,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:33,402 INFO:     Epoch: 18
2022-12-31 04:56:35,066 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3679570605357488, 'Total loss': 0.3679570605357488} | train loss {'Reaction outcome loss': 0.2222574092650219, 'Total loss': 0.2222574092650219}
2022-12-31 04:56:35,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:35,066 INFO:     Epoch: 19
2022-12-31 04:56:36,729 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3127508044242859, 'Total loss': 0.3127508044242859} | train loss {'Reaction outcome loss': 0.21738840177325378, 'Total loss': 0.21738840177325378}
2022-12-31 04:56:36,729 INFO:     Found new best model at epoch 19
2022-12-31 04:56:36,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:36,730 INFO:     Epoch: 20
2022-12-31 04:56:38,348 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.35781515861550967, 'Total loss': 0.35781515861550967} | train loss {'Reaction outcome loss': 0.21708163192522698, 'Total loss': 0.21708163192522698}
2022-12-31 04:56:38,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:38,349 INFO:     Epoch: 21
2022-12-31 04:56:39,964 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.32776291941603025, 'Total loss': 0.32776291941603025} | train loss {'Reaction outcome loss': 0.23770286370932625, 'Total loss': 0.23770286370932625}
2022-12-31 04:56:39,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:39,965 INFO:     Epoch: 22
2022-12-31 04:56:41,627 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.319979701936245, 'Total loss': 0.319979701936245} | train loss {'Reaction outcome loss': 0.2057648344977903, 'Total loss': 0.2057648344977903}
2022-12-31 04:56:41,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:41,627 INFO:     Epoch: 23
2022-12-31 04:56:43,241 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.32299587031205496, 'Total loss': 0.32299587031205496} | train loss {'Reaction outcome loss': 0.19883952145397232, 'Total loss': 0.19883952145397232}
2022-12-31 04:56:43,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:43,241 INFO:     Epoch: 24
2022-12-31 04:56:44,904 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.34190224756797155, 'Total loss': 0.34190224756797155} | train loss {'Reaction outcome loss': 0.19661498250301837, 'Total loss': 0.19661498250301837}
2022-12-31 04:56:44,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:44,904 INFO:     Epoch: 25
2022-12-31 04:56:46,512 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.35292639111479124, 'Total loss': 0.35292639111479124} | train loss {'Reaction outcome loss': 0.189768659523722, 'Total loss': 0.189768659523722}
2022-12-31 04:56:46,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:46,512 INFO:     Epoch: 26
2022-12-31 04:56:48,173 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3365173935890198, 'Total loss': 0.3365173935890198} | train loss {'Reaction outcome loss': 0.1890678280134402, 'Total loss': 0.1890678280134402}
2022-12-31 04:56:48,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:48,173 INFO:     Epoch: 27
2022-12-31 04:56:49,789 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.35863586564858757, 'Total loss': 0.35863586564858757} | train loss {'Reaction outcome loss': 0.19414009565514498, 'Total loss': 0.19414009565514498}
2022-12-31 04:56:49,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:49,789 INFO:     Epoch: 28
2022-12-31 04:56:51,412 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.34270050302147864, 'Total loss': 0.34270050302147864} | train loss {'Reaction outcome loss': 0.21461293694522718, 'Total loss': 0.21461293694522718}
2022-12-31 04:56:51,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:51,412 INFO:     Epoch: 29
2022-12-31 04:56:53,075 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.343989360332489, 'Total loss': 0.343989360332489} | train loss {'Reaction outcome loss': 0.18340644370798237, 'Total loss': 0.18340644370798237}
2022-12-31 04:56:53,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:53,076 INFO:     Epoch: 30
2022-12-31 04:56:54,738 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.36479833722114563, 'Total loss': 0.36479833722114563} | train loss {'Reaction outcome loss': 0.1768706364078832, 'Total loss': 0.1768706364078832}
2022-12-31 04:56:54,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:54,738 INFO:     Epoch: 31
2022-12-31 04:56:56,357 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.33748614639043806, 'Total loss': 0.33748614639043806} | train loss {'Reaction outcome loss': 0.17165916375950843, 'Total loss': 0.17165916375950843}
2022-12-31 04:56:56,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:56,358 INFO:     Epoch: 32
2022-12-31 04:56:57,972 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.356220384935538, 'Total loss': 0.356220384935538} | train loss {'Reaction outcome loss': 0.17261541017375048, 'Total loss': 0.17261541017375048}
2022-12-31 04:56:57,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:57,973 INFO:     Epoch: 33
2022-12-31 04:56:59,588 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3326766401529312, 'Total loss': 0.3326766401529312} | train loss {'Reaction outcome loss': 0.1653415141916122, 'Total loss': 0.1653415141916122}
2022-12-31 04:56:59,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:56:59,588 INFO:     Epoch: 34
2022-12-31 04:57:01,208 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3636145596702894, 'Total loss': 0.3636145596702894} | train loss {'Reaction outcome loss': 0.16880804336751284, 'Total loss': 0.16880804336751284}
2022-12-31 04:57:01,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:01,208 INFO:     Epoch: 35
2022-12-31 04:57:02,868 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.33223199024796485, 'Total loss': 0.33223199024796485} | train loss {'Reaction outcome loss': 0.17793705378552777, 'Total loss': 0.17793705378552777}
2022-12-31 04:57:02,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:02,868 INFO:     Epoch: 36
2022-12-31 04:57:04,528 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3617969145377477, 'Total loss': 0.3617969145377477} | train loss {'Reaction outcome loss': 0.18284695485498811, 'Total loss': 0.18284695485498811}
2022-12-31 04:57:04,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:04,528 INFO:     Epoch: 37
2022-12-31 04:57:06,136 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3716150221725305, 'Total loss': 0.3716150221725305} | train loss {'Reaction outcome loss': 0.1820090076476133, 'Total loss': 0.1820090076476133}
2022-12-31 04:57:06,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:06,136 INFO:     Epoch: 38
2022-12-31 04:57:07,795 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3496690998474757, 'Total loss': 0.3496690998474757} | train loss {'Reaction outcome loss': 0.15861331066285408, 'Total loss': 0.15861331066285408}
2022-12-31 04:57:07,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:07,795 INFO:     Epoch: 39
2022-12-31 04:57:09,441 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.33827391465504963, 'Total loss': 0.33827391465504963} | train loss {'Reaction outcome loss': 0.15636318071451766, 'Total loss': 0.15636318071451766}
2022-12-31 04:57:09,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:09,443 INFO:     Epoch: 40
2022-12-31 04:57:11,065 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.36482772550856074, 'Total loss': 0.36482772550856074} | train loss {'Reaction outcome loss': 0.15337820899119411, 'Total loss': 0.15337820899119411}
2022-12-31 04:57:11,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:11,065 INFO:     Epoch: 41
2022-12-31 04:57:12,683 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.36609509624540804, 'Total loss': 0.36609509624540804} | train loss {'Reaction outcome loss': 0.14968645914822168, 'Total loss': 0.14968645914822168}
2022-12-31 04:57:12,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:12,683 INFO:     Epoch: 42
2022-12-31 04:57:14,297 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3463718036810557, 'Total loss': 0.3463718036810557} | train loss {'Reaction outcome loss': 0.1519421072756866, 'Total loss': 0.1519421072756866}
2022-12-31 04:57:14,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:14,297 INFO:     Epoch: 43
2022-12-31 04:57:15,923 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3771336406469345, 'Total loss': 0.3771336406469345} | train loss {'Reaction outcome loss': 0.14498039052494383, 'Total loss': 0.14498039052494383}
2022-12-31 04:57:15,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:15,924 INFO:     Epoch: 44
2022-12-31 04:57:17,552 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.37618111769358314, 'Total loss': 0.37618111769358314} | train loss {'Reaction outcome loss': 0.14894972950727597, 'Total loss': 0.14894972950727597}
2022-12-31 04:57:17,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:17,552 INFO:     Epoch: 45
2022-12-31 04:57:19,170 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.34740006749828656, 'Total loss': 0.34740006749828656} | train loss {'Reaction outcome loss': 0.14743243320830568, 'Total loss': 0.14743243320830568}
2022-12-31 04:57:19,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:19,170 INFO:     Epoch: 46
2022-12-31 04:57:20,796 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.35616234242916106, 'Total loss': 0.35616234242916106} | train loss {'Reaction outcome loss': 0.17115219091773842, 'Total loss': 0.17115219091773842}
2022-12-31 04:57:20,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:20,797 INFO:     Epoch: 47
2022-12-31 04:57:22,425 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3954946239789327, 'Total loss': 0.3954946239789327} | train loss {'Reaction outcome loss': 0.1440339769985218, 'Total loss': 0.1440339769985218}
2022-12-31 04:57:22,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:22,425 INFO:     Epoch: 48
2022-12-31 04:57:24,044 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39316426316897074, 'Total loss': 0.39316426316897074} | train loss {'Reaction outcome loss': 0.14505157362926158, 'Total loss': 0.14505157362926158}
2022-12-31 04:57:24,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:24,044 INFO:     Epoch: 49
2022-12-31 04:57:25,673 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3456218103567759, 'Total loss': 0.3456218103567759} | train loss {'Reaction outcome loss': 0.147559808686956, 'Total loss': 0.147559808686956}
2022-12-31 04:57:25,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:25,673 INFO:     Epoch: 50
2022-12-31 04:57:27,298 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38597305174916985, 'Total loss': 0.38597305174916985} | train loss {'Reaction outcome loss': 0.14506482875288423, 'Total loss': 0.14506482875288423}
2022-12-31 04:57:27,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:27,298 INFO:     Epoch: 51
2022-12-31 04:57:28,917 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3826916148265203, 'Total loss': 0.3826916148265203} | train loss {'Reaction outcome loss': 0.13930782628384134, 'Total loss': 0.13930782628384134}
2022-12-31 04:57:28,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:28,918 INFO:     Epoch: 52
2022-12-31 04:57:30,543 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.381458713610967, 'Total loss': 0.381458713610967} | train loss {'Reaction outcome loss': 0.13692717528497073, 'Total loss': 0.13692717528497073}
2022-12-31 04:57:30,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:30,543 INFO:     Epoch: 53
2022-12-31 04:57:32,157 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39663830598195393, 'Total loss': 0.39663830598195393} | train loss {'Reaction outcome loss': 0.1343260446581922, 'Total loss': 0.1343260446581922}
2022-12-31 04:57:32,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:32,158 INFO:     Epoch: 54
2022-12-31 04:57:33,785 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3711466044187546, 'Total loss': 0.3711466044187546} | train loss {'Reaction outcome loss': 0.13795002949384227, 'Total loss': 0.13795002949384227}
2022-12-31 04:57:33,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:33,785 INFO:     Epoch: 55
2022-12-31 04:57:35,449 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3711159214377403, 'Total loss': 0.3711159214377403} | train loss {'Reaction outcome loss': 0.1376896394282032, 'Total loss': 0.1376896394282032}
2022-12-31 04:57:35,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:35,449 INFO:     Epoch: 56
2022-12-31 04:57:37,071 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37949593166510265, 'Total loss': 0.37949593166510265} | train loss {'Reaction outcome loss': 0.13759435975731796, 'Total loss': 0.13759435975731796}
2022-12-31 04:57:37,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:37,071 INFO:     Epoch: 57
2022-12-31 04:57:38,735 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.35223140915234885, 'Total loss': 0.35223140915234885} | train loss {'Reaction outcome loss': 0.13448684290989954, 'Total loss': 0.13448684290989954}
2022-12-31 04:57:38,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:38,736 INFO:     Epoch: 58
2022-12-31 04:57:40,400 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3792094113926093, 'Total loss': 0.3792094113926093} | train loss {'Reaction outcome loss': 0.1348136471519248, 'Total loss': 0.1348136471519248}
2022-12-31 04:57:40,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:40,402 INFO:     Epoch: 59
2022-12-31 04:57:42,033 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37921326955159507, 'Total loss': 0.37921326955159507} | train loss {'Reaction outcome loss': 0.13457585146702974, 'Total loss': 0.13457585146702974}
2022-12-31 04:57:42,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:42,033 INFO:     Epoch: 60
2022-12-31 04:57:43,657 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3891534149646759, 'Total loss': 0.3891534149646759} | train loss {'Reaction outcome loss': 0.1317693668517176, 'Total loss': 0.1317693668517176}
2022-12-31 04:57:43,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:43,657 INFO:     Epoch: 61
2022-12-31 04:57:45,321 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3599199598034223, 'Total loss': 0.3599199598034223} | train loss {'Reaction outcome loss': 0.13928387549273885, 'Total loss': 0.13928387549273885}
2022-12-31 04:57:45,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:45,321 INFO:     Epoch: 62
2022-12-31 04:57:46,948 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37503176331520083, 'Total loss': 0.37503176331520083} | train loss {'Reaction outcome loss': 0.13539957550381296, 'Total loss': 0.13539957550381296}
2022-12-31 04:57:46,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:46,949 INFO:     Epoch: 63
2022-12-31 04:57:48,570 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3830018763740857, 'Total loss': 0.3830018763740857} | train loss {'Reaction outcome loss': 0.13416994462950507, 'Total loss': 0.13416994462950507}
2022-12-31 04:57:48,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:48,570 INFO:     Epoch: 64
2022-12-31 04:57:50,234 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38803198585907617, 'Total loss': 0.38803198585907617} | train loss {'Reaction outcome loss': 0.1255478812406933, 'Total loss': 0.1255478812406933}
2022-12-31 04:57:50,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:50,234 INFO:     Epoch: 65
2022-12-31 04:57:51,855 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40459644695123037, 'Total loss': 0.40459644695123037} | train loss {'Reaction outcome loss': 0.12565936422580978, 'Total loss': 0.12565936422580978}
2022-12-31 04:57:51,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:51,855 INFO:     Epoch: 66
2022-12-31 04:57:53,486 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3831327239672343, 'Total loss': 0.3831327239672343} | train loss {'Reaction outcome loss': 0.12877876204489122, 'Total loss': 0.12877876204489122}
2022-12-31 04:57:53,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:53,487 INFO:     Epoch: 67
2022-12-31 04:57:55,106 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.388409224152565, 'Total loss': 0.388409224152565} | train loss {'Reaction outcome loss': 0.12393660521875195, 'Total loss': 0.12393660521875195}
2022-12-31 04:57:55,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:55,106 INFO:     Epoch: 68
2022-12-31 04:57:56,720 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38008013317982353, 'Total loss': 0.38008013317982353} | train loss {'Reaction outcome loss': 0.12510955582679278, 'Total loss': 0.12510955582679278}
2022-12-31 04:57:56,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:56,720 INFO:     Epoch: 69
2022-12-31 04:57:58,333 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3871404061714808, 'Total loss': 0.3871404061714808} | train loss {'Reaction outcome loss': 0.12261414065550776, 'Total loss': 0.12261414065550776}
2022-12-31 04:57:58,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:58,334 INFO:     Epoch: 70
2022-12-31 04:57:59,976 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39631659587224327, 'Total loss': 0.39631659587224327} | train loss {'Reaction outcome loss': 0.12486485841657048, 'Total loss': 0.12486485841657048}
2022-12-31 04:57:59,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:57:59,977 INFO:     Epoch: 71
2022-12-31 04:58:01,606 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40059501628081, 'Total loss': 0.40059501628081} | train loss {'Reaction outcome loss': 0.13426749195955842, 'Total loss': 0.13426749195955842}
2022-12-31 04:58:01,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:01,606 INFO:     Epoch: 72
2022-12-31 04:58:03,233 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3807790085673332, 'Total loss': 0.3807790085673332} | train loss {'Reaction outcome loss': 0.121475788763812, 'Total loss': 0.121475788763812}
2022-12-31 04:58:03,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:03,234 INFO:     Epoch: 73
2022-12-31 04:58:04,852 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3883309764166673, 'Total loss': 0.3883309764166673} | train loss {'Reaction outcome loss': 0.11873581546778028, 'Total loss': 0.11873581546778028}
2022-12-31 04:58:04,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:04,852 INFO:     Epoch: 74
2022-12-31 04:58:06,482 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3838934342066447, 'Total loss': 0.3838934342066447} | train loss {'Reaction outcome loss': 0.1250428246305513, 'Total loss': 0.1250428246305513}
2022-12-31 04:58:06,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:06,482 INFO:     Epoch: 75
2022-12-31 04:58:08,112 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41345999265710515, 'Total loss': 0.41345999265710515} | train loss {'Reaction outcome loss': 0.12419861412406359, 'Total loss': 0.12419861412406359}
2022-12-31 04:58:08,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:08,112 INFO:     Epoch: 76
2022-12-31 04:58:09,758 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3920957903067271, 'Total loss': 0.3920957903067271} | train loss {'Reaction outcome loss': 0.12052071578627742, 'Total loss': 0.12052071578627742}
2022-12-31 04:58:09,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:09,759 INFO:     Epoch: 77
2022-12-31 04:58:11,383 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38139772806316613, 'Total loss': 0.38139772806316613} | train loss {'Reaction outcome loss': 0.11977558463577159, 'Total loss': 0.11977558463577159}
2022-12-31 04:58:11,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:11,383 INFO:     Epoch: 78
2022-12-31 04:58:13,044 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3778453866640727, 'Total loss': 0.3778453866640727} | train loss {'Reaction outcome loss': 0.12141065183981403, 'Total loss': 0.12141065183981403}
2022-12-31 04:58:13,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:13,044 INFO:     Epoch: 79
2022-12-31 04:58:14,668 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3791584928830465, 'Total loss': 0.3791584928830465} | train loss {'Reaction outcome loss': 0.12320215193629838, 'Total loss': 0.12320215193629838}
2022-12-31 04:58:14,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:14,669 INFO:     Epoch: 80
2022-12-31 04:58:16,298 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38326018353303276, 'Total loss': 0.38326018353303276} | train loss {'Reaction outcome loss': 0.12026878023196173, 'Total loss': 0.12026878023196173}
2022-12-31 04:58:16,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:16,299 INFO:     Epoch: 81
2022-12-31 04:58:17,915 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41652258634567263, 'Total loss': 0.41652258634567263} | train loss {'Reaction outcome loss': 0.12077840078669344, 'Total loss': 0.12077840078669344}
2022-12-31 04:58:17,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:17,915 INFO:     Epoch: 82
2022-12-31 04:58:19,578 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40488146940867104, 'Total loss': 0.40488146940867104} | train loss {'Reaction outcome loss': 0.11800729175793358, 'Total loss': 0.11800729175793358}
2022-12-31 04:58:19,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:19,579 INFO:     Epoch: 83
2022-12-31 04:58:21,243 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.37582877054810526, 'Total loss': 0.37582877054810526} | train loss {'Reaction outcome loss': 0.11619887695264154, 'Total loss': 0.11619887695264154}
2022-12-31 04:58:21,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:21,243 INFO:     Epoch: 84
2022-12-31 04:58:22,878 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4202835902571678, 'Total loss': 0.4202835902571678} | train loss {'Reaction outcome loss': 0.12306995097558525, 'Total loss': 0.12306995097558525}
2022-12-31 04:58:22,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:22,879 INFO:     Epoch: 85
2022-12-31 04:58:24,499 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38447338889042537, 'Total loss': 0.38447338889042537} | train loss {'Reaction outcome loss': 0.11628191622684676, 'Total loss': 0.11628191622684676}
2022-12-31 04:58:24,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:24,499 INFO:     Epoch: 86
2022-12-31 04:58:26,162 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3635479842623075, 'Total loss': 0.3635479842623075} | train loss {'Reaction outcome loss': 0.1146702133057946, 'Total loss': 0.1146702133057946}
2022-12-31 04:58:26,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:26,162 INFO:     Epoch: 87
2022-12-31 04:58:27,799 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.34550033311049144, 'Total loss': 0.34550033311049144} | train loss {'Reaction outcome loss': 0.112369880291964, 'Total loss': 0.112369880291964}
2022-12-31 04:58:27,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:27,799 INFO:     Epoch: 88
2022-12-31 04:58:29,462 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3745340069445471, 'Total loss': 0.3745340069445471} | train loss {'Reaction outcome loss': 0.11625414660691445, 'Total loss': 0.11625414660691445}
2022-12-31 04:58:29,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:29,462 INFO:     Epoch: 89
2022-12-31 04:58:31,127 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3867709477742513, 'Total loss': 0.3867709477742513} | train loss {'Reaction outcome loss': 0.12008250963041671, 'Total loss': 0.12008250963041671}
2022-12-31 04:58:31,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:31,127 INFO:     Epoch: 90
2022-12-31 04:58:32,753 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.365473511070013, 'Total loss': 0.365473511070013} | train loss {'Reaction outcome loss': 0.116756519144131, 'Total loss': 0.116756519144131}
2022-12-31 04:58:32,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:32,753 INFO:     Epoch: 91
2022-12-31 04:58:34,384 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.387276221315066, 'Total loss': 0.387276221315066} | train loss {'Reaction outcome loss': 0.11778103320634944, 'Total loss': 0.11778103320634944}
2022-12-31 04:58:34,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:34,384 INFO:     Epoch: 92
2022-12-31 04:58:36,015 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3826826674242814, 'Total loss': 0.3826826674242814} | train loss {'Reaction outcome loss': 0.11433455785099532, 'Total loss': 0.11433455785099532}
2022-12-31 04:58:36,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:36,016 INFO:     Epoch: 93
2022-12-31 04:58:37,638 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4070838734507561, 'Total loss': 0.4070838734507561} | train loss {'Reaction outcome loss': 0.12693138296489834, 'Total loss': 0.12693138296489834}
2022-12-31 04:58:37,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:37,639 INFO:     Epoch: 94
2022-12-31 04:58:39,273 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.35303744971752166, 'Total loss': 0.35303744971752166} | train loss {'Reaction outcome loss': 0.12451410507813873, 'Total loss': 0.12451410507813873}
2022-12-31 04:58:39,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:39,273 INFO:     Epoch: 95
2022-12-31 04:58:40,900 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39785358409086863, 'Total loss': 0.39785358409086863} | train loss {'Reaction outcome loss': 0.11366406461593874, 'Total loss': 0.11366406461593874}
2022-12-31 04:58:40,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:40,900 INFO:     Epoch: 96
2022-12-31 04:58:42,529 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38036806707580884, 'Total loss': 0.38036806707580884} | train loss {'Reaction outcome loss': 0.11368095172962268, 'Total loss': 0.11368095172962268}
2022-12-31 04:58:42,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:42,530 INFO:     Epoch: 97
2022-12-31 04:58:44,160 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.37499969055255256, 'Total loss': 0.37499969055255256} | train loss {'Reaction outcome loss': 0.10902083958785953, 'Total loss': 0.10902083958785953}
2022-12-31 04:58:44,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:44,160 INFO:     Epoch: 98
2022-12-31 04:58:45,783 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3933226784070333, 'Total loss': 0.3933226784070333} | train loss {'Reaction outcome loss': 0.1127077554423443, 'Total loss': 0.1127077554423443}
2022-12-31 04:58:45,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 04:58:45,783 INFO:     Epoch: 99
2022-12-31 04:58:47,414 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39015880425771077, 'Total loss': 0.39015880425771077} | train loss {'Reaction outcome loss': 0.11298320805012801, 'Total loss': 0.11298320805012801}
2022-12-31 04:58:47,414 INFO:     Best model found after epoch 20 of 100.
2022-12-31 04:58:47,414 INFO:   Done with stage: TRAINING
2022-12-31 04:58:47,414 INFO:   Starting stage: EVALUATION
2022-12-31 04:58:47,545 INFO:   Done with stage: EVALUATION
2022-12-31 04:58:47,545 INFO: Done with stage: RUNNING SPLITS
2022-12-31 04:58:47,545 INFO: Starting stage: COMPUTE METRICS
2022-12-31 04:58:48,717 INFO: Done with stage: COMPUTE METRICS
2022-12-31 04:58:48,717 INFO: Starting stage: EXPORT RESULTS
2022-12-31 04:58:48,735 INFO:   Final results averaged over 50 folds: 
2022-12-31 04:58:48,739 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.162136           NaN  0.314462       NaN
2022-12-31 04:58:50,344 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-12-31 04:58:50,350 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-12-31 04:58:50,352 DEBUG:   interactive is False
2022-12-31 04:58:50,352 DEBUG:   platform is linux
2022-12-31 04:58:50,352 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.naming', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-12-31 04:58:50,526 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-12-31 04:58:50,528 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-12-31 04:58:50,962 DEBUG:   Loaded backend agg version unknown.
2022-12-31 04:58:50,964 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-12-31 04:58:50,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:50,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:50,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:50,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 04:58:50,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 04:58:50,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 04:58:50,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:50,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:50,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:50,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:50,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 04:58:50,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 04:58:50,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:50,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:50,965 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:50,966 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 04:58:50,966 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:50,966 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 04:58:50,966 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:50,966 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:50,966 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-31 04:58:50,966 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 04:58:50,966 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 04:58:50,966 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:50,967 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:50,967 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:50,967 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:50,967 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:50,967 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:50,967 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:50,967 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:50,967 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:50,967 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-31 04:58:50,967 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:50,967 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:50,967 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:50,967 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:50,967 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 04:58:50,967 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 04:58:50,967 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:50,968 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:50,968 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:50,968 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 04:58:50,968 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:50,968 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-31 04:58:51,004 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-12-31 04:58:51,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:51,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 04:58:51,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 04:58:51,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 04:58:51,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:51,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:51,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 04:58:51,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 04:58:51,005 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 04:58:51,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 04:58:51,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-31 04:58:51,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 04:58:51,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 04:58:51,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:51,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:51,006 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:51,007 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,007 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:51,007 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-31 04:58:51,007 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,007 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,007 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:51,007 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,007 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 04:58:51,007 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 04:58:51,007 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,007 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:51,007 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,007 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 04:58:51,007 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:51,007 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-31 04:58:51,016 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-12-31 04:58:51,016 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:51,016 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,016 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,016 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 04:58:51,016 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 04:58:51,016 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 04:58:51,016 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:51,016 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:51,017 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,017 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,017 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 04:58:51,017 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 04:58:51,017 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,017 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,017 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,017 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 04:58:51,017 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,017 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 04:58:51,017 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,017 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,017 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-31 04:58:51,017 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 04:58:51,017 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 04:58:51,017 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,017 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,018 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,018 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:51,018 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,018 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:51,018 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:51,018 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,018 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:51,018 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-31 04:58:51,018 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,018 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,018 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:51,018 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,018 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 04:58:51,018 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 04:58:51,018 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,018 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:51,018 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 04:58:51,019 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 04:58:51,019 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 04:58:51,019 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-31 04:58:51,295 INFO: Done with stage: EXPORT RESULTS
2022-12-31 04:58:51,295 INFO: Starting stage: SAVE MODEL
2022-12-31 04:58:51,354 INFO: Done with stage: SAVE MODEL
2022-12-31 04:58:51,354 INFO: Wall time for program:  8155.34 seconds
