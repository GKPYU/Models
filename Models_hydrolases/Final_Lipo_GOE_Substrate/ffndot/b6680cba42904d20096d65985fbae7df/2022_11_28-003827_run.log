2022-11-28 00:38:43,620 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffndot/b6680cba42904d20096d65985fbae7df/2022_11_28-003827",
  "seed": 1,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "jtvae",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffndot",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.85,
  "val_size": 0.15,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.0015553873022161448,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 90,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-11-28 00:38:43,628 INFO: Starting stage: BUILD FEATURIZERS
2022-11-28 00:38:43,639 INFO:   Creating esm representation model
2022-11-28 00:38:43,639 INFO:   Done esm representation model
2022-11-28 00:38:43,639 INFO: Done with stage: BUILD FEATURIZERS
2022-11-28 00:38:43,639 INFO: Starting stage: BUILDING DATASET
2022-11-28 00:38:43,692 INFO: Done with stage: BUILDING DATASET
2022-11-28 00:38:43,692 INFO: Starting stage: FEATURIZING DATA
2022-11-28 00:38:43,693 INFO:   Featurizing proteins
2022-11-28 00:38:43,694 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-11-28 00:38:43,713 INFO:   Loaded feature cache of size 204
2022-11-28 00:38:43,714 INFO:   Starting to pool ESM Embeddings
2022-11-28 00:38:43,815 INFO:   Featurizing molecules
2022-11-28 00:38:43,837 INFO: Done with stage: FEATURIZING DATA
2022-11-28 00:38:43,837 INFO: Starting stage: RUNNING SPLITS
2022-11-28 00:38:43,846 INFO:   Leaving out SEQ value Fold_0
2022-11-28 00:38:43,859 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 00:38:43,859 INFO:   Starting stage: FEATURE SCALING
2022-11-28 00:38:44,517 INFO:   Done with stage: FEATURE SCALING
2022-11-28 00:38:44,517 INFO:   Starting stage: SCALING TARGETS
2022-11-28 00:38:44,585 INFO:   Done with stage: SCALING TARGETS
2022-11-28 00:38:44,586 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:38:44,586 INFO:     No hyperparam tuning for this model
2022-11-28 00:38:44,586 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:38:44,586 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 00:38:44,586 INFO:     None feature selector for col prot
2022-11-28 00:38:44,587 INFO:     None feature selector for col prot
2022-11-28 00:38:44,587 INFO:     None feature selector for col prot
2022-11-28 00:38:44,587 INFO:     None feature selector for col chem
2022-11-28 00:38:44,587 INFO:     None feature selector for col chem
2022-11-28 00:38:44,587 INFO:     None feature selector for col chem
2022-11-28 00:38:44,587 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 00:38:44,588 INFO:   Starting stage: BUILD MODEL
2022-11-28 00:38:44,589 INFO:     Number of params in model 169741
2022-11-28 00:38:44,589 INFO:   Done with stage: BUILD MODEL
2022-11-28 00:38:44,589 INFO:   Starting stage: TRAINING
2022-11-28 00:38:46,621 INFO:     Val loss before train {'Reaction outcome loss': 1.0205451568891837, 'Total loss': 1.0205451568891837}
2022-11-28 00:38:46,622 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:38:46,622 INFO:     Epoch: 0
2022-11-28 00:38:47,366 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5658169783825098, 'Total loss': 0.5658169783825098} | train loss {'Reaction outcome loss': 0.6294395954149669, 'Total loss': 0.6294395954149669}
2022-11-28 00:38:47,366 INFO:     Found new best model at epoch 0
2022-11-28 00:38:47,367 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:38:47,367 INFO:     Epoch: 1
2022-11-28 00:38:48,106 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5114372705304345, 'Total loss': 0.5114372705304345} | train loss {'Reaction outcome loss': 0.49082574385722155, 'Total loss': 0.49082574385722155}
2022-11-28 00:38:48,106 INFO:     Found new best model at epoch 1
2022-11-28 00:38:48,107 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:38:48,107 INFO:     Epoch: 2
2022-11-28 00:38:48,843 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5102906816227492, 'Total loss': 0.5102906816227492} | train loss {'Reaction outcome loss': 0.4535551231171264, 'Total loss': 0.4535551231171264}
2022-11-28 00:38:48,844 INFO:     Found new best model at epoch 2
2022-11-28 00:38:48,844 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:38:48,845 INFO:     Epoch: 3
2022-11-28 00:38:49,579 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4869272556415824, 'Total loss': 0.4869272556415824} | train loss {'Reaction outcome loss': 0.44280255298878324, 'Total loss': 0.44280255298878324}
2022-11-28 00:38:49,579 INFO:     Found new best model at epoch 3
2022-11-28 00:38:49,580 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:38:49,580 INFO:     Epoch: 4
2022-11-28 00:38:50,317 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5320187800152357, 'Total loss': 0.5320187800152357} | train loss {'Reaction outcome loss': 0.42474774368962304, 'Total loss': 0.42474774368962304}
2022-11-28 00:38:50,318 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:38:50,318 INFO:     Epoch: 5
2022-11-28 00:38:51,053 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4878061486538066, 'Total loss': 0.4878061486538066} | train loss {'Reaction outcome loss': 0.41659816269014704, 'Total loss': 0.41659816269014704}
2022-11-28 00:38:51,053 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:38:51,053 INFO:     Epoch: 6
2022-11-28 00:38:51,786 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4641149054433024, 'Total loss': 0.4641149054433024} | train loss {'Reaction outcome loss': 0.4081246901120319, 'Total loss': 0.4081246901120319}
2022-11-28 00:38:51,787 INFO:     Found new best model at epoch 6
2022-11-28 00:38:51,787 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:38:51,787 INFO:     Epoch: 7
2022-11-28 00:38:52,524 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49884843687678493, 'Total loss': 0.49884843687678493} | train loss {'Reaction outcome loss': 0.4022880153516766, 'Total loss': 0.4022880153516766}
2022-11-28 00:38:52,524 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:38:52,524 INFO:     Epoch: 8
2022-11-28 00:38:53,260 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4880043885042501, 'Total loss': 0.4880043885042501} | train loss {'Reaction outcome loss': 0.3966921263481261, 'Total loss': 0.3966921263481261}
2022-11-28 00:38:53,261 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:38:53,261 INFO:     Epoch: 9
2022-11-28 00:38:53,994 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5076976505129837, 'Total loss': 0.5076976505129837} | train loss {'Reaction outcome loss': 0.3845368047534931, 'Total loss': 0.3845368047534931}
2022-11-28 00:38:53,994 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:38:53,994 INFO:     Epoch: 10
2022-11-28 00:38:54,731 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47369153693664906, 'Total loss': 0.47369153693664906} | train loss {'Reaction outcome loss': 0.37549637340497777, 'Total loss': 0.37549637340497777}
2022-11-28 00:38:54,732 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:38:54,732 INFO:     Epoch: 11
2022-11-28 00:38:55,465 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4647007924179698, 'Total loss': 0.4647007924179698} | train loss {'Reaction outcome loss': 0.3785626822624539, 'Total loss': 0.3785626822624539}
2022-11-28 00:38:55,465 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:38:55,465 INFO:     Epoch: 12
2022-11-28 00:38:56,202 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47373136254244075, 'Total loss': 0.47373136254244075} | train loss {'Reaction outcome loss': 0.37135553982902747, 'Total loss': 0.37135553982902747}
2022-11-28 00:38:56,202 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:38:56,202 INFO:     Epoch: 13
2022-11-28 00:38:56,939 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4906011954989544, 'Total loss': 0.4906011954989544} | train loss {'Reaction outcome loss': 0.36398307692076337, 'Total loss': 0.36398307692076337}
2022-11-28 00:38:56,940 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:38:56,940 INFO:     Epoch: 14
2022-11-28 00:38:57,673 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4435013267536496, 'Total loss': 0.4435013267536496} | train loss {'Reaction outcome loss': 0.36480264735148576, 'Total loss': 0.36480264735148576}
2022-11-28 00:38:57,673 INFO:     Found new best model at epoch 14
2022-11-28 00:38:57,674 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:38:57,674 INFO:     Epoch: 15
2022-11-28 00:38:58,407 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.469466095400411, 'Total loss': 0.469466095400411} | train loss {'Reaction outcome loss': 0.3620219550660399, 'Total loss': 0.3620219550660399}
2022-11-28 00:38:58,407 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:38:58,407 INFO:     Epoch: 16
2022-11-28 00:38:59,141 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4534729843915895, 'Total loss': 0.4534729843915895} | train loss {'Reaction outcome loss': 0.34866301776444325, 'Total loss': 0.34866301776444325}
2022-11-28 00:38:59,141 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:38:59,141 INFO:     Epoch: 17
2022-11-28 00:38:59,877 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.487417908255444, 'Total loss': 0.487417908255444} | train loss {'Reaction outcome loss': 0.35873794561771094, 'Total loss': 0.35873794561771094}
2022-11-28 00:38:59,877 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:38:59,877 INFO:     Epoch: 18
2022-11-28 00:39:00,610 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4858176850302275, 'Total loss': 0.4858176850302275} | train loss {'Reaction outcome loss': 0.34728151920144673, 'Total loss': 0.34728151920144673}
2022-11-28 00:39:00,610 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:00,610 INFO:     Epoch: 19
2022-11-28 00:39:01,345 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4748107025096583, 'Total loss': 0.4748107025096583} | train loss {'Reaction outcome loss': 0.344652348915573, 'Total loss': 0.344652348915573}
2022-11-28 00:39:01,345 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:01,345 INFO:     Epoch: 20
2022-11-28 00:39:02,078 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.484103521635366, 'Total loss': 0.484103521635366} | train loss {'Reaction outcome loss': 0.34995675355684563, 'Total loss': 0.34995675355684563}
2022-11-28 00:39:02,078 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:02,079 INFO:     Epoch: 21
2022-11-28 00:39:02,817 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4719184207361798, 'Total loss': 0.4719184207361798} | train loss {'Reaction outcome loss': 0.3502585515990609, 'Total loss': 0.3502585515990609}
2022-11-28 00:39:02,818 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:02,818 INFO:     Epoch: 22
2022-11-28 00:39:03,551 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.459113325490508, 'Total loss': 0.459113325490508} | train loss {'Reaction outcome loss': 0.3448459601151894, 'Total loss': 0.3448459601151894}
2022-11-28 00:39:03,551 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:03,551 INFO:     Epoch: 23
2022-11-28 00:39:04,285 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4527717118346414, 'Total loss': 0.4527717118346414} | train loss {'Reaction outcome loss': 0.33666435525309846, 'Total loss': 0.33666435525309846}
2022-11-28 00:39:04,285 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:04,285 INFO:     Epoch: 24
2022-11-28 00:39:05,016 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4439000799212345, 'Total loss': 0.4439000799212345} | train loss {'Reaction outcome loss': 0.3410376772345578, 'Total loss': 0.3410376772345578}
2022-11-28 00:39:05,017 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:05,017 INFO:     Epoch: 25
2022-11-28 00:39:05,745 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4504149684379267, 'Total loss': 0.4504149684379267} | train loss {'Reaction outcome loss': 0.340874493519058, 'Total loss': 0.340874493519058}
2022-11-28 00:39:05,746 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:05,746 INFO:     Epoch: 26
2022-11-28 00:39:06,480 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46687971644623333, 'Total loss': 0.46687971644623333} | train loss {'Reaction outcome loss': 0.32980765719882776, 'Total loss': 0.32980765719882776}
2022-11-28 00:39:06,480 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:06,481 INFO:     Epoch: 27
2022-11-28 00:39:07,210 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4688590990249501, 'Total loss': 0.4688590990249501} | train loss {'Reaction outcome loss': 0.3370387774327251, 'Total loss': 0.3370387774327251}
2022-11-28 00:39:07,211 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:07,211 INFO:     Epoch: 28
2022-11-28 00:39:07,941 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4715963543154473, 'Total loss': 0.4715963543154473} | train loss {'Reaction outcome loss': 0.3311635799950264, 'Total loss': 0.3311635799950264}
2022-11-28 00:39:07,941 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:07,941 INFO:     Epoch: 29
2022-11-28 00:39:08,672 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47284685803014176, 'Total loss': 0.47284685803014176} | train loss {'Reaction outcome loss': 0.3321210306259941, 'Total loss': 0.3321210306259941}
2022-11-28 00:39:08,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:08,673 INFO:     Epoch: 30
2022-11-28 00:39:09,405 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4604516174904136, 'Total loss': 0.4604516174904136} | train loss {'Reaction outcome loss': 0.3219542358467569, 'Total loss': 0.3219542358467569}
2022-11-28 00:39:09,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:09,405 INFO:     Epoch: 31
2022-11-28 00:39:10,134 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4644661237334096, 'Total loss': 0.4644661237334096} | train loss {'Reaction outcome loss': 0.324067641141229, 'Total loss': 0.324067641141229}
2022-11-28 00:39:10,135 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:10,135 INFO:     Epoch: 32
2022-11-28 00:39:10,872 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45383491037889967, 'Total loss': 0.45383491037889967} | train loss {'Reaction outcome loss': 0.32607825888229197, 'Total loss': 0.32607825888229197}
2022-11-28 00:39:10,872 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:10,872 INFO:     Epoch: 33
2022-11-28 00:39:11,616 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45519062980662944, 'Total loss': 0.45519062980662944} | train loss {'Reaction outcome loss': 0.32560450568428784, 'Total loss': 0.32560450568428784}
2022-11-28 00:39:11,616 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:11,616 INFO:     Epoch: 34
2022-11-28 00:39:12,358 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46340463085230005, 'Total loss': 0.46340463085230005} | train loss {'Reaction outcome loss': 0.3246908626198524, 'Total loss': 0.3246908626198524}
2022-11-28 00:39:12,358 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:12,358 INFO:     Epoch: 35
2022-11-28 00:39:13,098 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48388570824334787, 'Total loss': 0.48388570824334787} | train loss {'Reaction outcome loss': 0.32941560093008104, 'Total loss': 0.32941560093008104}
2022-11-28 00:39:13,098 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:13,098 INFO:     Epoch: 36
2022-11-28 00:39:13,835 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4460408230160558, 'Total loss': 0.4460408230160558} | train loss {'Reaction outcome loss': 0.32613426874407003, 'Total loss': 0.32613426874407003}
2022-11-28 00:39:13,835 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:13,836 INFO:     Epoch: 37
2022-11-28 00:39:14,575 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43731672819270645, 'Total loss': 0.43731672819270645} | train loss {'Reaction outcome loss': 0.31635820908380335, 'Total loss': 0.31635820908380335}
2022-11-28 00:39:14,575 INFO:     Found new best model at epoch 37
2022-11-28 00:39:14,576 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:14,576 INFO:     Epoch: 38
2022-11-28 00:39:15,315 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43502786582292513, 'Total loss': 0.43502786582292513} | train loss {'Reaction outcome loss': 0.3193540154788338, 'Total loss': 0.3193540154788338}
2022-11-28 00:39:15,315 INFO:     Found new best model at epoch 38
2022-11-28 00:39:15,316 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:15,316 INFO:     Epoch: 39
2022-11-28 00:39:16,053 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45119066120580187, 'Total loss': 0.45119066120580187} | train loss {'Reaction outcome loss': 0.31752220623683736, 'Total loss': 0.31752220623683736}
2022-11-28 00:39:16,054 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:16,054 INFO:     Epoch: 40
2022-11-28 00:39:16,792 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44925441367681634, 'Total loss': 0.44925441367681634} | train loss {'Reaction outcome loss': 0.3187194290326633, 'Total loss': 0.3187194290326633}
2022-11-28 00:39:16,792 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:16,792 INFO:     Epoch: 41
2022-11-28 00:39:17,530 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41992216089437173, 'Total loss': 0.41992216089437173} | train loss {'Reaction outcome loss': 0.31558697682912235, 'Total loss': 0.31558697682912235}
2022-11-28 00:39:17,530 INFO:     Found new best model at epoch 41
2022-11-28 00:39:17,531 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:17,531 INFO:     Epoch: 42
2022-11-28 00:39:18,272 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45150410124035767, 'Total loss': 0.45150410124035767} | train loss {'Reaction outcome loss': 0.3180997872755664, 'Total loss': 0.3180997872755664}
2022-11-28 00:39:18,272 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:18,273 INFO:     Epoch: 43
2022-11-28 00:39:19,008 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4601354605929796, 'Total loss': 0.4601354605929796} | train loss {'Reaction outcome loss': 0.31769473939279064, 'Total loss': 0.31769473939279064}
2022-11-28 00:39:19,009 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:19,009 INFO:     Epoch: 44
2022-11-28 00:39:19,748 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44746332528979277, 'Total loss': 0.44746332528979277} | train loss {'Reaction outcome loss': 0.3210719551158244, 'Total loss': 0.3210719551158244}
2022-11-28 00:39:19,748 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:19,748 INFO:     Epoch: 45
2022-11-28 00:39:20,486 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47065835082253743, 'Total loss': 0.47065835082253743} | train loss {'Reaction outcome loss': 0.31667770512524196, 'Total loss': 0.31667770512524196}
2022-11-28 00:39:20,486 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:20,486 INFO:     Epoch: 46
2022-11-28 00:39:21,233 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.450311528388844, 'Total loss': 0.450311528388844} | train loss {'Reaction outcome loss': 0.3153629251450422, 'Total loss': 0.3153629251450422}
2022-11-28 00:39:21,233 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:21,233 INFO:     Epoch: 47
2022-11-28 00:39:21,970 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5393470844557119, 'Total loss': 0.5393470844557119} | train loss {'Reaction outcome loss': 0.31558985525711636, 'Total loss': 0.31558985525711636}
2022-11-28 00:39:21,971 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:21,971 INFO:     Epoch: 48
2022-11-28 00:39:22,707 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4414305680019911, 'Total loss': 0.4414305680019911} | train loss {'Reaction outcome loss': 0.3233093994776489, 'Total loss': 0.3233093994776489}
2022-11-28 00:39:22,707 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:22,707 INFO:     Epoch: 49
2022-11-28 00:39:23,440 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46082673966884613, 'Total loss': 0.46082673966884613} | train loss {'Reaction outcome loss': 0.3145056017598168, 'Total loss': 0.3145056017598168}
2022-11-28 00:39:23,441 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:23,441 INFO:     Epoch: 50
2022-11-28 00:39:24,175 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46535522612028346, 'Total loss': 0.46535522612028346} | train loss {'Reaction outcome loss': 0.3135393080835948, 'Total loss': 0.3135393080835948}
2022-11-28 00:39:24,175 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:24,175 INFO:     Epoch: 51
2022-11-28 00:39:24,920 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4320105872181959, 'Total loss': 0.4320105872181959} | train loss {'Reaction outcome loss': 0.3137556403325718, 'Total loss': 0.3137556403325718}
2022-11-28 00:39:24,920 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:24,921 INFO:     Epoch: 52
2022-11-28 00:39:25,662 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4411525102548821, 'Total loss': 0.4411525102548821} | train loss {'Reaction outcome loss': 0.3201203677406321, 'Total loss': 0.3201203677406321}
2022-11-28 00:39:25,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:25,662 INFO:     Epoch: 53
2022-11-28 00:39:26,395 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4319967610198398, 'Total loss': 0.4319967610198398} | train loss {'Reaction outcome loss': 0.31245401367300846, 'Total loss': 0.31245401367300846}
2022-11-28 00:39:26,395 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:26,395 INFO:     Epoch: 54
2022-11-28 00:39:27,131 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45804013103939767, 'Total loss': 0.45804013103939767} | train loss {'Reaction outcome loss': 0.3078775622988822, 'Total loss': 0.3078775622988822}
2022-11-28 00:39:27,131 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:27,132 INFO:     Epoch: 55
2022-11-28 00:39:27,867 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4539073688346286, 'Total loss': 0.4539073688346286} | train loss {'Reaction outcome loss': 0.3133611136467242, 'Total loss': 0.3133611136467242}
2022-11-28 00:39:27,867 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:27,867 INFO:     Epoch: 56
2022-11-28 00:39:28,603 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48398338431535765, 'Total loss': 0.48398338431535765} | train loss {'Reaction outcome loss': 0.30385066481826245, 'Total loss': 0.30385066481826245}
2022-11-28 00:39:28,603 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:28,604 INFO:     Epoch: 57
2022-11-28 00:39:29,344 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4649930783482485, 'Total loss': 0.4649930783482485} | train loss {'Reaction outcome loss': 0.3061014591090259, 'Total loss': 0.3061014591090259}
2022-11-28 00:39:29,344 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:29,344 INFO:     Epoch: 58
2022-11-28 00:39:30,087 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42877935184988863, 'Total loss': 0.42877935184988863} | train loss {'Reaction outcome loss': 0.3120856409678694, 'Total loss': 0.3120856409678694}
2022-11-28 00:39:30,088 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:30,088 INFO:     Epoch: 59
2022-11-28 00:39:30,826 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42669310368770774, 'Total loss': 0.42669310368770774} | train loss {'Reaction outcome loss': 0.3111818573880391, 'Total loss': 0.3111818573880391}
2022-11-28 00:39:30,826 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:30,826 INFO:     Epoch: 60
2022-11-28 00:39:31,561 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48101504978745485, 'Total loss': 0.48101504978745485} | train loss {'Reaction outcome loss': 0.30562578019548636, 'Total loss': 0.30562578019548636}
2022-11-28 00:39:31,561 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:31,562 INFO:     Epoch: 61
2022-11-28 00:39:32,305 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4588745156692904, 'Total loss': 0.4588745156692904} | train loss {'Reaction outcome loss': 0.31467356416778486, 'Total loss': 0.31467356416778486}
2022-11-28 00:39:32,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:32,305 INFO:     Epoch: 62
2022-11-28 00:39:33,048 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4688190128221068, 'Total loss': 0.4688190128221068} | train loss {'Reaction outcome loss': 0.3136030621673973, 'Total loss': 0.3136030621673973}
2022-11-28 00:39:33,048 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:33,048 INFO:     Epoch: 63
2022-11-28 00:39:33,786 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47755880653858185, 'Total loss': 0.47755880653858185} | train loss {'Reaction outcome loss': 0.31598575263604767, 'Total loss': 0.31598575263604767}
2022-11-28 00:39:33,786 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:33,787 INFO:     Epoch: 64
2022-11-28 00:39:34,526 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4421892994365027, 'Total loss': 0.4421892994365027} | train loss {'Reaction outcome loss': 0.3097507547831438, 'Total loss': 0.3097507547831438}
2022-11-28 00:39:34,526 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:34,526 INFO:     Epoch: 65
2022-11-28 00:39:35,263 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4404164318775022, 'Total loss': 0.4404164318775022} | train loss {'Reaction outcome loss': 0.300348799385619, 'Total loss': 0.300348799385619}
2022-11-28 00:39:35,263 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:35,264 INFO:     Epoch: 66
2022-11-28 00:39:36,000 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45867903184059056, 'Total loss': 0.45867903184059056} | train loss {'Reaction outcome loss': 0.31132579909362756, 'Total loss': 0.31132579909362756}
2022-11-28 00:39:36,000 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:36,000 INFO:     Epoch: 67
2022-11-28 00:39:36,746 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4534561072671136, 'Total loss': 0.4534561072671136} | train loss {'Reaction outcome loss': 0.30773991050168137, 'Total loss': 0.30773991050168137}
2022-11-28 00:39:36,746 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:36,746 INFO:     Epoch: 68
2022-11-28 00:39:37,482 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.462160509512868, 'Total loss': 0.462160509512868} | train loss {'Reaction outcome loss': 0.30467394253880276, 'Total loss': 0.30467394253880276}
2022-11-28 00:39:37,482 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:37,482 INFO:     Epoch: 69
2022-11-28 00:39:38,221 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4619070059338281, 'Total loss': 0.4619070059338281} | train loss {'Reaction outcome loss': 0.30578373583247426, 'Total loss': 0.30578373583247426}
2022-11-28 00:39:38,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:38,221 INFO:     Epoch: 70
2022-11-28 00:39:38,962 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43378516685130986, 'Total loss': 0.43378516685130986} | train loss {'Reaction outcome loss': 0.3094941300538475, 'Total loss': 0.3094941300538475}
2022-11-28 00:39:38,962 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:38,962 INFO:     Epoch: 71
2022-11-28 00:39:39,704 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45970709743194804, 'Total loss': 0.45970709743194804} | train loss {'Reaction outcome loss': 0.3079445957526809, 'Total loss': 0.3079445957526809}
2022-11-28 00:39:39,704 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:39,704 INFO:     Epoch: 72
2022-11-28 00:39:40,440 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45697633540907573, 'Total loss': 0.45697633540907573} | train loss {'Reaction outcome loss': 0.31615005447300243, 'Total loss': 0.31615005447300243}
2022-11-28 00:39:40,441 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:40,441 INFO:     Epoch: 73
2022-11-28 00:39:41,178 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4623167175193166, 'Total loss': 0.4623167175193166} | train loss {'Reaction outcome loss': 0.3133179563265599, 'Total loss': 0.3133179563265599}
2022-11-28 00:39:41,179 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:41,179 INFO:     Epoch: 74
2022-11-28 00:39:41,914 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42909428269364114, 'Total loss': 0.42909428269364114} | train loss {'Reaction outcome loss': 0.3015889943287265, 'Total loss': 0.3015889943287265}
2022-11-28 00:39:41,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:41,915 INFO:     Epoch: 75
2022-11-28 00:39:42,650 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44609722079232683, 'Total loss': 0.44609722079232683} | train loss {'Reaction outcome loss': 0.2994396935415561, 'Total loss': 0.2994396935415561}
2022-11-28 00:39:42,650 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:42,650 INFO:     Epoch: 76
2022-11-28 00:39:43,385 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4420824180855307, 'Total loss': 0.4420824180855307} | train loss {'Reaction outcome loss': 0.31074514648434326, 'Total loss': 0.31074514648434326}
2022-11-28 00:39:43,385 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:43,385 INFO:     Epoch: 77
2022-11-28 00:39:44,116 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45289011507533317, 'Total loss': 0.45289011507533317} | train loss {'Reaction outcome loss': 0.30154422340823, 'Total loss': 0.30154422340823}
2022-11-28 00:39:44,116 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:44,116 INFO:     Epoch: 78
2022-11-28 00:39:44,852 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4505766581657321, 'Total loss': 0.4505766581657321} | train loss {'Reaction outcome loss': 0.30928518548302475, 'Total loss': 0.30928518548302475}
2022-11-28 00:39:44,852 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:44,852 INFO:     Epoch: 79
2022-11-28 00:39:45,595 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4670387170342512, 'Total loss': 0.4670387170342512} | train loss {'Reaction outcome loss': 0.30638290367654114, 'Total loss': 0.30638290367654114}
2022-11-28 00:39:45,596 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:45,596 INFO:     Epoch: 80
2022-11-28 00:39:46,333 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43807651726312413, 'Total loss': 0.43807651726312413} | train loss {'Reaction outcome loss': 0.3060038768548946, 'Total loss': 0.3060038768548946}
2022-11-28 00:39:46,333 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:46,333 INFO:     Epoch: 81
2022-11-28 00:39:47,070 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.444024255802465, 'Total loss': 0.444024255802465} | train loss {'Reaction outcome loss': 0.30227181254351726, 'Total loss': 0.30227181254351726}
2022-11-28 00:39:47,070 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:47,070 INFO:     Epoch: 82
2022-11-28 00:39:47,806 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46145767008149347, 'Total loss': 0.46145767008149347} | train loss {'Reaction outcome loss': 0.3100254099632873, 'Total loss': 0.3100254099632873}
2022-11-28 00:39:47,807 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:47,807 INFO:     Epoch: 83
2022-11-28 00:39:48,547 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4242806805427684, 'Total loss': 0.4242806805427684} | train loss {'Reaction outcome loss': 0.30308556507845397, 'Total loss': 0.30308556507845397}
2022-11-28 00:39:48,547 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:48,547 INFO:     Epoch: 84
2022-11-28 00:39:49,285 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4342718495185985, 'Total loss': 0.4342718495185985} | train loss {'Reaction outcome loss': 0.30315295063325615, 'Total loss': 0.30315295063325615}
2022-11-28 00:39:49,285 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:49,285 INFO:     Epoch: 85
2022-11-28 00:39:50,021 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45028177908686706, 'Total loss': 0.45028177908686706} | train loss {'Reaction outcome loss': 0.3068364805801482, 'Total loss': 0.3068364805801482}
2022-11-28 00:39:50,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:50,021 INFO:     Epoch: 86
2022-11-28 00:39:50,756 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47259860329849773, 'Total loss': 0.47259860329849773} | train loss {'Reaction outcome loss': 0.3095487459089424, 'Total loss': 0.3095487459089424}
2022-11-28 00:39:50,756 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:50,756 INFO:     Epoch: 87
2022-11-28 00:39:51,493 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.469426958366882, 'Total loss': 0.469426958366882} | train loss {'Reaction outcome loss': 0.3035790031073523, 'Total loss': 0.3035790031073523}
2022-11-28 00:39:51,493 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:51,494 INFO:     Epoch: 88
2022-11-28 00:39:52,231 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47151014797909313, 'Total loss': 0.47151014797909313} | train loss {'Reaction outcome loss': 0.3066326598713144, 'Total loss': 0.3066326598713144}
2022-11-28 00:39:52,231 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:52,231 INFO:     Epoch: 89
2022-11-28 00:39:52,969 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.421994945337606, 'Total loss': 0.421994945337606} | train loss {'Reaction outcome loss': 0.3039316693778898, 'Total loss': 0.3039316693778898}
2022-11-28 00:39:52,970 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:52,970 INFO:     Epoch: 90
2022-11-28 00:39:53,711 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4466512414605118, 'Total loss': 0.4466512414605118} | train loss {'Reaction outcome loss': 0.31080588833505257, 'Total loss': 0.31080588833505257}
2022-11-28 00:39:53,711 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:53,711 INFO:     Epoch: 91
2022-11-28 00:39:54,443 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4474091051622879, 'Total loss': 0.4474091051622879} | train loss {'Reaction outcome loss': 0.30096994862571114, 'Total loss': 0.30096994862571114}
2022-11-28 00:39:54,443 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:54,443 INFO:     Epoch: 92
2022-11-28 00:39:55,171 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49108468160726304, 'Total loss': 0.49108468160726304} | train loss {'Reaction outcome loss': 0.3057951110980061, 'Total loss': 0.3057951110980061}
2022-11-28 00:39:55,171 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:55,171 INFO:     Epoch: 93
2022-11-28 00:39:55,896 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4486622110355732, 'Total loss': 0.4486622110355732} | train loss {'Reaction outcome loss': 0.30247973632372793, 'Total loss': 0.30247973632372793}
2022-11-28 00:39:55,896 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:55,897 INFO:     Epoch: 94
2022-11-28 00:39:56,625 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4498957301988158, 'Total loss': 0.4498957301988158} | train loss {'Reaction outcome loss': 0.3103936369546124, 'Total loss': 0.3103936369546124}
2022-11-28 00:39:56,626 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:56,626 INFO:     Epoch: 95
2022-11-28 00:39:57,361 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49936375195203825, 'Total loss': 0.49936375195203825} | train loss {'Reaction outcome loss': 0.3011534387764872, 'Total loss': 0.3011534387764872}
2022-11-28 00:39:57,361 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:57,361 INFO:     Epoch: 96
2022-11-28 00:39:58,094 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4434255354626234, 'Total loss': 0.4434255354626234} | train loss {'Reaction outcome loss': 0.3106626107769667, 'Total loss': 0.3106626107769667}
2022-11-28 00:39:58,094 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:58,094 INFO:     Epoch: 97
2022-11-28 00:39:58,824 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44898714575656623, 'Total loss': 0.44898714575656623} | train loss {'Reaction outcome loss': 0.3011649761226822, 'Total loss': 0.3011649761226822}
2022-11-28 00:39:58,824 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:58,824 INFO:     Epoch: 98
2022-11-28 00:39:59,559 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4609257443699726, 'Total loss': 0.4609257443699726} | train loss {'Reaction outcome loss': 0.2985942162664943, 'Total loss': 0.2985942162664943}
2022-11-28 00:39:59,560 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:39:59,560 INFO:     Epoch: 99
2022-11-28 00:40:00,290 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4402228791353314, 'Total loss': 0.4402228791353314} | train loss {'Reaction outcome loss': 0.30070635537448964, 'Total loss': 0.30070635537448964}
2022-11-28 00:40:00,290 INFO:     Best model found after epoch 42 of 100.
2022-11-28 00:40:00,290 INFO:   Done with stage: TRAINING
2022-11-28 00:40:00,290 INFO:   Starting stage: EVALUATION
2022-11-28 00:40:00,423 INFO:   Done with stage: EVALUATION
2022-11-28 00:40:00,423 INFO:   Leaving out SEQ value Fold_1
2022-11-28 00:40:00,435 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 00:40:00,435 INFO:   Starting stage: FEATURE SCALING
2022-11-28 00:40:01,087 INFO:   Done with stage: FEATURE SCALING
2022-11-28 00:40:01,088 INFO:   Starting stage: SCALING TARGETS
2022-11-28 00:40:01,158 INFO:   Done with stage: SCALING TARGETS
2022-11-28 00:40:01,158 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:40:01,158 INFO:     No hyperparam tuning for this model
2022-11-28 00:40:01,158 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:40:01,158 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 00:40:01,159 INFO:     None feature selector for col prot
2022-11-28 00:40:01,159 INFO:     None feature selector for col prot
2022-11-28 00:40:01,159 INFO:     None feature selector for col prot
2022-11-28 00:40:01,160 INFO:     None feature selector for col chem
2022-11-28 00:40:01,160 INFO:     None feature selector for col chem
2022-11-28 00:40:01,160 INFO:     None feature selector for col chem
2022-11-28 00:40:01,160 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 00:40:01,160 INFO:   Starting stage: BUILD MODEL
2022-11-28 00:40:01,161 INFO:     Number of params in model 169741
2022-11-28 00:40:01,164 INFO:   Done with stage: BUILD MODEL
2022-11-28 00:40:01,164 INFO:   Starting stage: TRAINING
2022-11-28 00:40:01,217 INFO:     Val loss before train {'Reaction outcome loss': 1.0302079956639896, 'Total loss': 1.0302079956639896}
2022-11-28 00:40:01,218 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:01,218 INFO:     Epoch: 0
2022-11-28 00:40:01,959 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6074926074255597, 'Total loss': 0.6074926074255597} | train loss {'Reaction outcome loss': 0.6279302136633198, 'Total loss': 0.6279302136633198}
2022-11-28 00:40:01,959 INFO:     Found new best model at epoch 0
2022-11-28 00:40:01,960 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:01,960 INFO:     Epoch: 1
2022-11-28 00:40:02,701 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5221438624642112, 'Total loss': 0.5221438624642112} | train loss {'Reaction outcome loss': 0.4859681953544076, 'Total loss': 0.4859681953544076}
2022-11-28 00:40:02,701 INFO:     Found new best model at epoch 1
2022-11-28 00:40:02,701 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:02,702 INFO:     Epoch: 2
2022-11-28 00:40:03,439 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5251401385123079, 'Total loss': 0.5251401385123079} | train loss {'Reaction outcome loss': 0.45328377482862126, 'Total loss': 0.45328377482862126}
2022-11-28 00:40:03,439 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:03,440 INFO:     Epoch: 3
2022-11-28 00:40:04,182 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5038305317813699, 'Total loss': 0.5038305317813699} | train loss {'Reaction outcome loss': 0.43589819663087365, 'Total loss': 0.43589819663087365}
2022-11-28 00:40:04,182 INFO:     Found new best model at epoch 3
2022-11-28 00:40:04,183 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:04,183 INFO:     Epoch: 4
2022-11-28 00:40:04,926 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49377523667433043, 'Total loss': 0.49377523667433043} | train loss {'Reaction outcome loss': 0.4176365883100914, 'Total loss': 0.4176365883100914}
2022-11-28 00:40:04,926 INFO:     Found new best model at epoch 4
2022-11-28 00:40:04,927 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:04,927 INFO:     Epoch: 5
2022-11-28 00:40:05,670 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48821465230800887, 'Total loss': 0.48821465230800887} | train loss {'Reaction outcome loss': 0.40225228223844095, 'Total loss': 0.40225228223844095}
2022-11-28 00:40:05,670 INFO:     Found new best model at epoch 5
2022-11-28 00:40:05,671 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:05,671 INFO:     Epoch: 6
2022-11-28 00:40:06,410 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4793356237086383, 'Total loss': 0.4793356237086383} | train loss {'Reaction outcome loss': 0.3946708730659504, 'Total loss': 0.3946708730659504}
2022-11-28 00:40:06,410 INFO:     Found new best model at epoch 6
2022-11-28 00:40:06,411 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:06,411 INFO:     Epoch: 7
2022-11-28 00:40:07,151 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4583577804944732, 'Total loss': 0.4583577804944732} | train loss {'Reaction outcome loss': 0.39400599785299917, 'Total loss': 0.39400599785299917}
2022-11-28 00:40:07,151 INFO:     Found new best model at epoch 7
2022-11-28 00:40:07,152 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:07,152 INFO:     Epoch: 8
2022-11-28 00:40:07,889 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49895086139440536, 'Total loss': 0.49895086139440536} | train loss {'Reaction outcome loss': 0.3829162001368488, 'Total loss': 0.3829162001368488}
2022-11-28 00:40:07,890 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:07,890 INFO:     Epoch: 9
2022-11-28 00:40:08,630 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.502294637601484, 'Total loss': 0.502294637601484} | train loss {'Reaction outcome loss': 0.37170534922179543, 'Total loss': 0.37170534922179543}
2022-11-28 00:40:08,630 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:08,630 INFO:     Epoch: 10
2022-11-28 00:40:09,369 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49244140257889574, 'Total loss': 0.49244140257889574} | train loss {'Reaction outcome loss': 0.36713779443188715, 'Total loss': 0.36713779443188715}
2022-11-28 00:40:09,369 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:09,369 INFO:     Epoch: 11
2022-11-28 00:40:10,109 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44769647040150384, 'Total loss': 0.44769647040150384} | train loss {'Reaction outcome loss': 0.371117167778102, 'Total loss': 0.371117167778102}
2022-11-28 00:40:10,110 INFO:     Found new best model at epoch 11
2022-11-28 00:40:10,110 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:10,110 INFO:     Epoch: 12
2022-11-28 00:40:10,856 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4581592279401692, 'Total loss': 0.4581592279401692} | train loss {'Reaction outcome loss': 0.36726976529910016, 'Total loss': 0.36726976529910016}
2022-11-28 00:40:10,856 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:10,856 INFO:     Epoch: 13
2022-11-28 00:40:11,605 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4713919945061207, 'Total loss': 0.4713919945061207} | train loss {'Reaction outcome loss': 0.3576781862313569, 'Total loss': 0.3576781862313569}
2022-11-28 00:40:11,605 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:11,605 INFO:     Epoch: 14
2022-11-28 00:40:12,347 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46864723244851286, 'Total loss': 0.46864723244851286} | train loss {'Reaction outcome loss': 0.34827894261974074, 'Total loss': 0.34827894261974074}
2022-11-28 00:40:12,347 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:12,347 INFO:     Epoch: 15
2022-11-28 00:40:13,091 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4823773527009921, 'Total loss': 0.4823773527009921} | train loss {'Reaction outcome loss': 0.3469832616175717, 'Total loss': 0.3469832616175717}
2022-11-28 00:40:13,091 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:13,091 INFO:     Epoch: 16
2022-11-28 00:40:13,836 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45010700686411426, 'Total loss': 0.45010700686411426} | train loss {'Reaction outcome loss': 0.3453849444499518, 'Total loss': 0.3453849444499518}
2022-11-28 00:40:13,836 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:13,837 INFO:     Epoch: 17
2022-11-28 00:40:14,580 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48073170367967, 'Total loss': 0.48073170367967} | train loss {'Reaction outcome loss': 0.3450053904888028, 'Total loss': 0.3450053904888028}
2022-11-28 00:40:14,580 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:14,580 INFO:     Epoch: 18
2022-11-28 00:40:15,327 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4775901992212642, 'Total loss': 0.4775901992212642} | train loss {'Reaction outcome loss': 0.3412525511765287, 'Total loss': 0.3412525511765287}
2022-11-28 00:40:15,327 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:15,327 INFO:     Epoch: 19
2022-11-28 00:40:16,073 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4702171812003309, 'Total loss': 0.4702171812003309} | train loss {'Reaction outcome loss': 0.3520752682014998, 'Total loss': 0.3520752682014998}
2022-11-28 00:40:16,074 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:16,074 INFO:     Epoch: 20
2022-11-28 00:40:16,820 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4941685274243355, 'Total loss': 0.4941685274243355} | train loss {'Reaction outcome loss': 0.33563525407661793, 'Total loss': 0.33563525407661793}
2022-11-28 00:40:16,821 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:16,821 INFO:     Epoch: 21
2022-11-28 00:40:17,564 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47822160172191536, 'Total loss': 0.47822160172191536} | train loss {'Reaction outcome loss': 0.3380489599125588, 'Total loss': 0.3380489599125588}
2022-11-28 00:40:17,564 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:17,564 INFO:     Epoch: 22
2022-11-28 00:40:18,308 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4474923878230832, 'Total loss': 0.4474923878230832} | train loss {'Reaction outcome loss': 0.3423263580511939, 'Total loss': 0.3423263580511939}
2022-11-28 00:40:18,308 INFO:     Found new best model at epoch 22
2022-11-28 00:40:18,309 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:18,309 INFO:     Epoch: 23
2022-11-28 00:40:19,054 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4470898112790151, 'Total loss': 0.4470898112790151} | train loss {'Reaction outcome loss': 0.3373050011321148, 'Total loss': 0.3373050011321148}
2022-11-28 00:40:19,054 INFO:     Found new best model at epoch 23
2022-11-28 00:40:19,055 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:19,055 INFO:     Epoch: 24
2022-11-28 00:40:19,800 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4591559611938216, 'Total loss': 0.4591559611938216} | train loss {'Reaction outcome loss': 0.3260934023348698, 'Total loss': 0.3260934023348698}
2022-11-28 00:40:19,800 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:19,800 INFO:     Epoch: 25
2022-11-28 00:40:20,545 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46482409502972255, 'Total loss': 0.46482409502972255} | train loss {'Reaction outcome loss': 0.33020438278010983, 'Total loss': 0.33020438278010983}
2022-11-28 00:40:20,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:20,546 INFO:     Epoch: 26
2022-11-28 00:40:21,291 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4493847767060453, 'Total loss': 0.4493847767060453} | train loss {'Reaction outcome loss': 0.34779325580631615, 'Total loss': 0.34779325580631615}
2022-11-28 00:40:21,291 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:21,291 INFO:     Epoch: 27
2022-11-28 00:40:22,036 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47079999711025844, 'Total loss': 0.47079999711025844} | train loss {'Reaction outcome loss': 0.3224206120379058, 'Total loss': 0.3224206120379058}
2022-11-28 00:40:22,036 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:22,037 INFO:     Epoch: 28
2022-11-28 00:40:22,779 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48145597157153214, 'Total loss': 0.48145597157153214} | train loss {'Reaction outcome loss': 0.3216727169259802, 'Total loss': 0.3216727169259802}
2022-11-28 00:40:22,779 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:22,779 INFO:     Epoch: 29
2022-11-28 00:40:23,522 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4792292236604474, 'Total loss': 0.4792292236604474} | train loss {'Reaction outcome loss': 0.3329670376140579, 'Total loss': 0.3329670376140579}
2022-11-28 00:40:23,523 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:23,523 INFO:     Epoch: 30
2022-11-28 00:40:24,268 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4639525633643974, 'Total loss': 0.4639525633643974} | train loss {'Reaction outcome loss': 0.3417400302636901, 'Total loss': 0.3417400302636901}
2022-11-28 00:40:24,269 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:24,269 INFO:     Epoch: 31
2022-11-28 00:40:25,017 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49119856648824434, 'Total loss': 0.49119856648824434} | train loss {'Reaction outcome loss': 0.3223157978733541, 'Total loss': 0.3223157978733541}
2022-11-28 00:40:25,017 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:25,017 INFO:     Epoch: 32
2022-11-28 00:40:25,762 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46426424011588097, 'Total loss': 0.46426424011588097} | train loss {'Reaction outcome loss': 0.33945954803694117, 'Total loss': 0.33945954803694117}
2022-11-28 00:40:25,762 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:25,762 INFO:     Epoch: 33
2022-11-28 00:40:26,507 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44542598080906, 'Total loss': 0.44542598080906} | train loss {'Reaction outcome loss': 0.38866401502960607, 'Total loss': 0.38866401502960607}
2022-11-28 00:40:26,507 INFO:     Found new best model at epoch 33
2022-11-28 00:40:26,508 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:26,508 INFO:     Epoch: 34
2022-11-28 00:40:27,252 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4683038196103139, 'Total loss': 0.4683038196103139} | train loss {'Reaction outcome loss': 0.3187657553204882, 'Total loss': 0.3187657553204882}
2022-11-28 00:40:27,252 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:27,252 INFO:     Epoch: 35
2022-11-28 00:40:27,998 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4470068666745316, 'Total loss': 0.4470068666745316} | train loss {'Reaction outcome loss': 0.3157880121035132, 'Total loss': 0.3157880121035132}
2022-11-28 00:40:27,998 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:27,998 INFO:     Epoch: 36
2022-11-28 00:40:28,745 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4703185541385954, 'Total loss': 0.4703185541385954} | train loss {'Reaction outcome loss': 0.3186036071585499, 'Total loss': 0.3186036071585499}
2022-11-28 00:40:28,745 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:28,745 INFO:     Epoch: 37
2022-11-28 00:40:29,489 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4671201285990802, 'Total loss': 0.4671201285990802} | train loss {'Reaction outcome loss': 0.3413302158929317, 'Total loss': 0.3413302158929317}
2022-11-28 00:40:29,489 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:29,489 INFO:     Epoch: 38
2022-11-28 00:40:30,235 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46156936477531085, 'Total loss': 0.46156936477531085} | train loss {'Reaction outcome loss': 0.3161504201983151, 'Total loss': 0.3161504201983151}
2022-11-28 00:40:30,235 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:30,236 INFO:     Epoch: 39
2022-11-28 00:40:30,981 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46306750076738273, 'Total loss': 0.46306750076738273} | train loss {'Reaction outcome loss': 0.31374322787409853, 'Total loss': 0.31374322787409853}
2022-11-28 00:40:30,982 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:30,982 INFO:     Epoch: 40
2022-11-28 00:40:31,725 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4407606107944792, 'Total loss': 0.4407606107944792} | train loss {'Reaction outcome loss': 0.32000056114274, 'Total loss': 0.32000056114274}
2022-11-28 00:40:31,725 INFO:     Found new best model at epoch 40
2022-11-28 00:40:31,726 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:31,726 INFO:     Epoch: 41
2022-11-28 00:40:32,473 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4514612392945723, 'Total loss': 0.4514612392945723} | train loss {'Reaction outcome loss': 0.31637085159780526, 'Total loss': 0.31637085159780526}
2022-11-28 00:40:32,473 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:32,473 INFO:     Epoch: 42
2022-11-28 00:40:33,220 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42527015320956707, 'Total loss': 0.42527015320956707} | train loss {'Reaction outcome loss': 0.3169026188854023, 'Total loss': 0.3169026188854023}
2022-11-28 00:40:33,220 INFO:     Found new best model at epoch 42
2022-11-28 00:40:33,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:33,221 INFO:     Epoch: 43
2022-11-28 00:40:33,965 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4465602179142562, 'Total loss': 0.4465602179142562} | train loss {'Reaction outcome loss': 0.3177078407604685, 'Total loss': 0.3177078407604685}
2022-11-28 00:40:33,965 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:33,966 INFO:     Epoch: 44
2022-11-28 00:40:34,709 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42842209339141846, 'Total loss': 0.42842209339141846} | train loss {'Reaction outcome loss': 0.3126884019567899, 'Total loss': 0.3126884019567899}
2022-11-28 00:40:34,710 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:34,710 INFO:     Epoch: 45
2022-11-28 00:40:35,456 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.469255636700175, 'Total loss': 0.469255636700175} | train loss {'Reaction outcome loss': 0.3195714277539568, 'Total loss': 0.3195714277539568}
2022-11-28 00:40:35,456 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:35,457 INFO:     Epoch: 46
2022-11-28 00:40:36,204 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4489835084161975, 'Total loss': 0.4489835084161975} | train loss {'Reaction outcome loss': 0.3118921399544472, 'Total loss': 0.3118921399544472}
2022-11-28 00:40:36,204 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:36,204 INFO:     Epoch: 47
2022-11-28 00:40:36,952 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4634703008288687, 'Total loss': 0.4634703008288687} | train loss {'Reaction outcome loss': 0.3093171936670989, 'Total loss': 0.3093171936670989}
2022-11-28 00:40:36,953 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:36,953 INFO:     Epoch: 48
2022-11-28 00:40:37,697 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4633417532525279, 'Total loss': 0.4633417532525279} | train loss {'Reaction outcome loss': 0.3136800688310613, 'Total loss': 0.3136800688310613}
2022-11-28 00:40:37,697 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:37,697 INFO:     Epoch: 49
2022-11-28 00:40:38,439 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.458930402147499, 'Total loss': 0.458930402147499} | train loss {'Reaction outcome loss': 0.3070754285766046, 'Total loss': 0.3070754285766046}
2022-11-28 00:40:38,439 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:38,439 INFO:     Epoch: 50
2022-11-28 00:40:39,182 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4434226971458305, 'Total loss': 0.4434226971458305} | train loss {'Reaction outcome loss': 0.31304153244987676, 'Total loss': 0.31304153244987676}
2022-11-28 00:40:39,182 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:39,182 INFO:     Epoch: 51
2022-11-28 00:40:39,928 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45125985043970024, 'Total loss': 0.45125985043970024} | train loss {'Reaction outcome loss': 0.30776764458490286, 'Total loss': 0.30776764458490286}
2022-11-28 00:40:39,928 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:39,928 INFO:     Epoch: 52
2022-11-28 00:40:40,673 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.454130443321033, 'Total loss': 0.454130443321033} | train loss {'Reaction outcome loss': 0.3216125401046112, 'Total loss': 0.3216125401046112}
2022-11-28 00:40:40,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:40,673 INFO:     Epoch: 53
2022-11-28 00:40:41,420 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4587761322883042, 'Total loss': 0.4587761322883042} | train loss {'Reaction outcome loss': 0.33738763591176585, 'Total loss': 0.33738763591176585}
2022-11-28 00:40:41,420 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:41,420 INFO:     Epoch: 54
2022-11-28 00:40:42,161 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4739382260225036, 'Total loss': 0.4739382260225036} | train loss {'Reaction outcome loss': 0.3353345659278665, 'Total loss': 0.3353345659278665}
2022-11-28 00:40:42,161 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:42,161 INFO:     Epoch: 55
2022-11-28 00:40:42,904 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45279511606151407, 'Total loss': 0.45279511606151407} | train loss {'Reaction outcome loss': 0.34109327605612544, 'Total loss': 0.34109327605612544}
2022-11-28 00:40:42,904 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:42,905 INFO:     Epoch: 56
2022-11-28 00:40:43,649 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4344247071580453, 'Total loss': 0.4344247071580453} | train loss {'Reaction outcome loss': 0.31693521697028926, 'Total loss': 0.31693521697028926}
2022-11-28 00:40:43,650 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:43,650 INFO:     Epoch: 57
2022-11-28 00:40:44,394 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4412631160494956, 'Total loss': 0.4412631160494956} | train loss {'Reaction outcome loss': 0.3110073597023362, 'Total loss': 0.3110073597023362}
2022-11-28 00:40:44,394 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:44,394 INFO:     Epoch: 58
2022-11-28 00:40:45,135 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43487346138466487, 'Total loss': 0.43487346138466487} | train loss {'Reaction outcome loss': 0.311982468626017, 'Total loss': 0.311982468626017}
2022-11-28 00:40:45,135 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:45,135 INFO:     Epoch: 59
2022-11-28 00:40:45,882 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4331435791470788, 'Total loss': 0.4331435791470788} | train loss {'Reaction outcome loss': 0.30459922349960866, 'Total loss': 0.30459922349960866}
2022-11-28 00:40:45,883 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:45,883 INFO:     Epoch: 60
2022-11-28 00:40:46,632 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45909572731364856, 'Total loss': 0.45909572731364856} | train loss {'Reaction outcome loss': 0.31535757809636084, 'Total loss': 0.31535757809636084}
2022-11-28 00:40:46,632 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:46,632 INFO:     Epoch: 61
2022-11-28 00:40:47,379 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4231178496371616, 'Total loss': 0.4231178496371616} | train loss {'Reaction outcome loss': 0.3162798296645103, 'Total loss': 0.3162798296645103}
2022-11-28 00:40:47,379 INFO:     Found new best model at epoch 61
2022-11-28 00:40:47,380 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:47,380 INFO:     Epoch: 62
2022-11-28 00:40:48,129 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46305054968053644, 'Total loss': 0.46305054968053644} | train loss {'Reaction outcome loss': 0.31595056163154633, 'Total loss': 0.31595056163154633}
2022-11-28 00:40:48,129 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:48,129 INFO:     Epoch: 63
2022-11-28 00:40:48,878 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46315969628366555, 'Total loss': 0.46315969628366555} | train loss {'Reaction outcome loss': 0.3180086098400205, 'Total loss': 0.3180086098400205}
2022-11-28 00:40:48,878 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:48,878 INFO:     Epoch: 64
2022-11-28 00:40:49,625 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4716842018745162, 'Total loss': 0.4716842018745162} | train loss {'Reaction outcome loss': 0.32532078710333767, 'Total loss': 0.32532078710333767}
2022-11-28 00:40:49,625 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:49,625 INFO:     Epoch: 65
2022-11-28 00:40:50,379 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4797055304727771, 'Total loss': 0.4797055304727771} | train loss {'Reaction outcome loss': 0.31460383097049194, 'Total loss': 0.31460383097049194}
2022-11-28 00:40:50,379 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:50,379 INFO:     Epoch: 66
2022-11-28 00:40:51,126 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4494656138122082, 'Total loss': 0.4494656138122082} | train loss {'Reaction outcome loss': 0.32551029240071533, 'Total loss': 0.32551029240071533}
2022-11-28 00:40:51,126 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:51,126 INFO:     Epoch: 67
2022-11-28 00:40:51,872 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47745750709013507, 'Total loss': 0.47745750709013507} | train loss {'Reaction outcome loss': 0.31516034068607607, 'Total loss': 0.31516034068607607}
2022-11-28 00:40:51,872 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:51,872 INFO:     Epoch: 68
2022-11-28 00:40:52,622 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46297852898185904, 'Total loss': 0.46297852898185904} | train loss {'Reaction outcome loss': 0.3099941707815719, 'Total loss': 0.3099941707815719}
2022-11-28 00:40:52,622 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:52,622 INFO:     Epoch: 69
2022-11-28 00:40:53,369 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43428650159727444, 'Total loss': 0.43428650159727444} | train loss {'Reaction outcome loss': 0.31429873186687707, 'Total loss': 0.31429873186687707}
2022-11-28 00:40:53,369 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:53,369 INFO:     Epoch: 70
2022-11-28 00:40:54,126 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4455322955142368, 'Total loss': 0.4455322955142368} | train loss {'Reaction outcome loss': 0.30896103019196436, 'Total loss': 0.30896103019196436}
2022-11-28 00:40:54,126 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:54,126 INFO:     Epoch: 71
2022-11-28 00:40:54,875 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4421313283541663, 'Total loss': 0.4421313283541663} | train loss {'Reaction outcome loss': 0.30951294695076187, 'Total loss': 0.30951294695076187}
2022-11-28 00:40:54,875 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:54,876 INFO:     Epoch: 72
2022-11-28 00:40:55,623 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45331298864700575, 'Total loss': 0.45331298864700575} | train loss {'Reaction outcome loss': 0.31561021274521284, 'Total loss': 0.31561021274521284}
2022-11-28 00:40:55,624 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:55,624 INFO:     Epoch: 73
2022-11-28 00:40:56,373 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44346254522150214, 'Total loss': 0.44346254522150214} | train loss {'Reaction outcome loss': 0.30899075521175046, 'Total loss': 0.30899075521175046}
2022-11-28 00:40:56,374 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:56,374 INFO:     Epoch: 74
2022-11-28 00:40:57,125 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.455088676715439, 'Total loss': 0.455088676715439} | train loss {'Reaction outcome loss': 0.30989970870104877, 'Total loss': 0.30989970870104877}
2022-11-28 00:40:57,125 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:57,125 INFO:     Epoch: 75
2022-11-28 00:40:57,878 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4367582770064473, 'Total loss': 0.4367582770064473} | train loss {'Reaction outcome loss': 0.31793592764660417, 'Total loss': 0.31793592764660417}
2022-11-28 00:40:57,878 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:57,878 INFO:     Epoch: 76
2022-11-28 00:40:58,624 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41336649791760877, 'Total loss': 0.41336649791760877} | train loss {'Reaction outcome loss': 0.3243972707977179, 'Total loss': 0.3243972707977179}
2022-11-28 00:40:58,624 INFO:     Found new best model at epoch 76
2022-11-28 00:40:58,624 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:58,625 INFO:     Epoch: 77
2022-11-28 00:40:59,371 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44375870072028856, 'Total loss': 0.44375870072028856} | train loss {'Reaction outcome loss': 0.31925328217657956, 'Total loss': 0.31925328217657956}
2022-11-28 00:40:59,371 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:40:59,371 INFO:     Epoch: 78
2022-11-28 00:41:00,117 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45110788162459026, 'Total loss': 0.45110788162459026} | train loss {'Reaction outcome loss': 0.3046064115287774, 'Total loss': 0.3046064115287774}
2022-11-28 00:41:00,117 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:00,117 INFO:     Epoch: 79
2022-11-28 00:41:00,870 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44001660495996475, 'Total loss': 0.44001660495996475} | train loss {'Reaction outcome loss': 0.3120857891947152, 'Total loss': 0.3120857891947152}
2022-11-28 00:41:00,870 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:00,870 INFO:     Epoch: 80
2022-11-28 00:41:01,625 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4744964790615169, 'Total loss': 0.4744964790615169} | train loss {'Reaction outcome loss': 0.3167072258861867, 'Total loss': 0.3167072258861867}
2022-11-28 00:41:01,626 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:01,626 INFO:     Epoch: 81
2022-11-28 00:41:02,376 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45179479399865324, 'Total loss': 0.45179479399865324} | train loss {'Reaction outcome loss': 0.3084084733958669, 'Total loss': 0.3084084733958669}
2022-11-28 00:41:02,377 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:02,377 INFO:     Epoch: 82
2022-11-28 00:41:03,127 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45135799930854276, 'Total loss': 0.45135799930854276} | train loss {'Reaction outcome loss': 0.31474446741767936, 'Total loss': 0.31474446741767936}
2022-11-28 00:41:03,127 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:03,127 INFO:     Epoch: 83
2022-11-28 00:41:03,875 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4527462605725635, 'Total loss': 0.4527462605725635} | train loss {'Reaction outcome loss': 0.3074012506406317, 'Total loss': 0.3074012506406317}
2022-11-28 00:41:03,875 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:03,875 INFO:     Epoch: 84
2022-11-28 00:41:04,622 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46833060681819916, 'Total loss': 0.46833060681819916} | train loss {'Reaction outcome loss': 0.3176717208886919, 'Total loss': 0.3176717208886919}
2022-11-28 00:41:04,622 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:04,622 INFO:     Epoch: 85
2022-11-28 00:41:05,367 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42985513095151295, 'Total loss': 0.42985513095151295} | train loss {'Reaction outcome loss': 0.30730247968121577, 'Total loss': 0.30730247968121577}
2022-11-28 00:41:05,367 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:05,367 INFO:     Epoch: 86
2022-11-28 00:41:06,117 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4823847257278182, 'Total loss': 0.4823847257278182} | train loss {'Reaction outcome loss': 0.3149703728102962, 'Total loss': 0.3149703728102962}
2022-11-28 00:41:06,117 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:06,117 INFO:     Epoch: 87
2022-11-28 00:41:06,869 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.466472865505652, 'Total loss': 0.466472865505652} | train loss {'Reaction outcome loss': 0.3160366660157437, 'Total loss': 0.3160366660157437}
2022-11-28 00:41:06,869 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:06,869 INFO:     Epoch: 88
2022-11-28 00:41:07,617 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4695399964058941, 'Total loss': 0.4695399964058941} | train loss {'Reaction outcome loss': 0.3023946344369819, 'Total loss': 0.3023946344369819}
2022-11-28 00:41:07,618 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:07,618 INFO:     Epoch: 89
2022-11-28 00:41:08,370 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4807680496437983, 'Total loss': 0.4807680496437983} | train loss {'Reaction outcome loss': 0.3078601747027293, 'Total loss': 0.3078601747027293}
2022-11-28 00:41:08,370 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:08,370 INFO:     Epoch: 90
2022-11-28 00:41:09,118 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45864847200838005, 'Total loss': 0.45864847200838005} | train loss {'Reaction outcome loss': 0.30694396472592583, 'Total loss': 0.30694396472592583}
2022-11-28 00:41:09,118 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:09,118 INFO:     Epoch: 91
2022-11-28 00:41:09,860 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49123408882455394, 'Total loss': 0.49123408882455394} | train loss {'Reaction outcome loss': 0.3234370558895925, 'Total loss': 0.3234370558895925}
2022-11-28 00:41:09,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:09,860 INFO:     Epoch: 92
2022-11-28 00:41:10,603 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4619400731541894, 'Total loss': 0.4619400731541894} | train loss {'Reaction outcome loss': 0.30766992252847924, 'Total loss': 0.30766992252847924}
2022-11-28 00:41:10,603 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:10,603 INFO:     Epoch: 93
2022-11-28 00:41:11,347 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4758255664597858, 'Total loss': 0.4758255664597858} | train loss {'Reaction outcome loss': 0.3070723263599612, 'Total loss': 0.3070723263599612}
2022-11-28 00:41:11,347 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:11,347 INFO:     Epoch: 94
2022-11-28 00:41:12,090 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48197790641676297, 'Total loss': 0.48197790641676297} | train loss {'Reaction outcome loss': 0.3033967814766444, 'Total loss': 0.3033967814766444}
2022-11-28 00:41:12,091 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:12,091 INFO:     Epoch: 95
2022-11-28 00:41:12,837 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4536450542509556, 'Total loss': 0.4536450542509556} | train loss {'Reaction outcome loss': 0.3012998901941033, 'Total loss': 0.3012998901941033}
2022-11-28 00:41:12,837 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:12,837 INFO:     Epoch: 96
2022-11-28 00:41:13,579 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4570030746134845, 'Total loss': 0.4570030746134845} | train loss {'Reaction outcome loss': 0.3192223377143097, 'Total loss': 0.3192223377143097}
2022-11-28 00:41:13,580 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:13,580 INFO:     Epoch: 97
2022-11-28 00:41:14,322 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4332418135282668, 'Total loss': 0.4332418135282668} | train loss {'Reaction outcome loss': 0.3044447510213137, 'Total loss': 0.3044447510213137}
2022-11-28 00:41:14,323 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:14,323 INFO:     Epoch: 98
2022-11-28 00:41:15,070 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45991815118627116, 'Total loss': 0.45991815118627116} | train loss {'Reaction outcome loss': 0.2957761669870813, 'Total loss': 0.2957761669870813}
2022-11-28 00:41:15,070 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:15,070 INFO:     Epoch: 99
2022-11-28 00:41:15,811 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4576331932436336, 'Total loss': 0.4576331932436336} | train loss {'Reaction outcome loss': 0.31936383328064977, 'Total loss': 0.31936383328064977}
2022-11-28 00:41:15,811 INFO:     Best model found after epoch 77 of 100.
2022-11-28 00:41:15,812 INFO:   Done with stage: TRAINING
2022-11-28 00:41:15,812 INFO:   Starting stage: EVALUATION
2022-11-28 00:41:15,931 INFO:   Done with stage: EVALUATION
2022-11-28 00:41:15,931 INFO:   Leaving out SEQ value Fold_2
2022-11-28 00:41:15,943 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 00:41:15,944 INFO:   Starting stage: FEATURE SCALING
2022-11-28 00:41:16,582 INFO:   Done with stage: FEATURE SCALING
2022-11-28 00:41:16,582 INFO:   Starting stage: SCALING TARGETS
2022-11-28 00:41:16,653 INFO:   Done with stage: SCALING TARGETS
2022-11-28 00:41:16,653 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:41:16,653 INFO:     No hyperparam tuning for this model
2022-11-28 00:41:16,653 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:41:16,653 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 00:41:16,654 INFO:     None feature selector for col prot
2022-11-28 00:41:16,654 INFO:     None feature selector for col prot
2022-11-28 00:41:16,654 INFO:     None feature selector for col prot
2022-11-28 00:41:16,654 INFO:     None feature selector for col chem
2022-11-28 00:41:16,655 INFO:     None feature selector for col chem
2022-11-28 00:41:16,655 INFO:     None feature selector for col chem
2022-11-28 00:41:16,655 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 00:41:16,655 INFO:   Starting stage: BUILD MODEL
2022-11-28 00:41:16,656 INFO:     Number of params in model 169741
2022-11-28 00:41:16,659 INFO:   Done with stage: BUILD MODEL
2022-11-28 00:41:16,659 INFO:   Starting stage: TRAINING
2022-11-28 00:41:16,712 INFO:     Val loss before train {'Reaction outcome loss': 0.9266484190117229, 'Total loss': 0.9266484190117229}
2022-11-28 00:41:16,712 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:16,712 INFO:     Epoch: 0
2022-11-28 00:41:17,450 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.48978581381115044, 'Total loss': 0.48978581381115044} | train loss {'Reaction outcome loss': 0.6375029455642311, 'Total loss': 0.6375029455642311}
2022-11-28 00:41:17,450 INFO:     Found new best model at epoch 0
2022-11-28 00:41:17,451 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:17,451 INFO:     Epoch: 1
2022-11-28 00:41:18,187 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4545017206533389, 'Total loss': 0.4545017206533389} | train loss {'Reaction outcome loss': 0.5040148329369876, 'Total loss': 0.5040148329369876}
2022-11-28 00:41:18,188 INFO:     Found new best model at epoch 1
2022-11-28 00:41:18,188 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:18,188 INFO:     Epoch: 2
2022-11-28 00:41:18,927 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.41835965698754246, 'Total loss': 0.41835965698754246} | train loss {'Reaction outcome loss': 0.4510908572649469, 'Total loss': 0.4510908572649469}
2022-11-28 00:41:18,927 INFO:     Found new best model at epoch 2
2022-11-28 00:41:18,928 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:18,928 INFO:     Epoch: 3
2022-11-28 00:41:19,666 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4120525824414058, 'Total loss': 0.4120525824414058} | train loss {'Reaction outcome loss': 0.4329215597741458, 'Total loss': 0.4329215597741458}
2022-11-28 00:41:19,666 INFO:     Found new best model at epoch 3
2022-11-28 00:41:19,667 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:19,667 INFO:     Epoch: 4
2022-11-28 00:41:20,405 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4338678077540614, 'Total loss': 0.4338678077540614} | train loss {'Reaction outcome loss': 0.4203325408453844, 'Total loss': 0.4203325408453844}
2022-11-28 00:41:20,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:20,405 INFO:     Epoch: 5
2022-11-28 00:41:21,144 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4245804470371116, 'Total loss': 0.4245804470371116} | train loss {'Reaction outcome loss': 0.4097222199245375, 'Total loss': 0.4097222199245375}
2022-11-28 00:41:21,144 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:21,144 INFO:     Epoch: 6
2022-11-28 00:41:21,879 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49034148488532414, 'Total loss': 0.49034148488532414} | train loss {'Reaction outcome loss': 0.4038702561843152, 'Total loss': 0.4038702561843152}
2022-11-28 00:41:21,879 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:21,879 INFO:     Epoch: 7
2022-11-28 00:41:22,622 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4095346067439426, 'Total loss': 0.4095346067439426} | train loss {'Reaction outcome loss': 0.39380561572556594, 'Total loss': 0.39380561572556594}
2022-11-28 00:41:22,622 INFO:     Found new best model at epoch 7
2022-11-28 00:41:22,622 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:22,623 INFO:     Epoch: 8
2022-11-28 00:41:23,358 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.37655870751901105, 'Total loss': 0.37655870751901105} | train loss {'Reaction outcome loss': 0.3799573162684635, 'Total loss': 0.3799573162684635}
2022-11-28 00:41:23,358 INFO:     Found new best model at epoch 8
2022-11-28 00:41:23,359 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:23,359 INFO:     Epoch: 9
2022-11-28 00:41:24,097 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41351814060048625, 'Total loss': 0.41351814060048625} | train loss {'Reaction outcome loss': 0.37345505980204563, 'Total loss': 0.37345505980204563}
2022-11-28 00:41:24,097 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:24,097 INFO:     Epoch: 10
2022-11-28 00:41:24,833 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4255102261562239, 'Total loss': 0.4255102261562239} | train loss {'Reaction outcome loss': 0.370922504182981, 'Total loss': 0.370922504182981}
2022-11-28 00:41:24,833 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:24,833 INFO:     Epoch: 11
2022-11-28 00:41:25,568 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40656667067246005, 'Total loss': 0.40656667067246005} | train loss {'Reaction outcome loss': 0.37341198538030895, 'Total loss': 0.37341198538030895}
2022-11-28 00:41:25,569 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:25,569 INFO:     Epoch: 12
2022-11-28 00:41:26,301 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.37283936447717925, 'Total loss': 0.37283936447717925} | train loss {'Reaction outcome loss': 0.3672581853915234, 'Total loss': 0.3672581853915234}
2022-11-28 00:41:26,302 INFO:     Found new best model at epoch 12
2022-11-28 00:41:26,303 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:26,303 INFO:     Epoch: 13
2022-11-28 00:41:27,034 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3941121353259818, 'Total loss': 0.3941121353259818} | train loss {'Reaction outcome loss': 0.35719360295607117, 'Total loss': 0.35719360295607117}
2022-11-28 00:41:27,034 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:27,034 INFO:     Epoch: 14
2022-11-28 00:41:27,763 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.35640675760805607, 'Total loss': 0.35640675760805607} | train loss {'Reaction outcome loss': 0.3610678857382463, 'Total loss': 0.3610678857382463}
2022-11-28 00:41:27,764 INFO:     Found new best model at epoch 14
2022-11-28 00:41:27,764 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:27,764 INFO:     Epoch: 15
2022-11-28 00:41:28,500 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3793056553060358, 'Total loss': 0.3793056553060358} | train loss {'Reaction outcome loss': 0.35503778767829036, 'Total loss': 0.35503778767829036}
2022-11-28 00:41:28,500 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:28,500 INFO:     Epoch: 16
2022-11-28 00:41:29,238 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4127272765194489, 'Total loss': 0.4127272765194489} | train loss {'Reaction outcome loss': 0.35203346795573526, 'Total loss': 0.35203346795573526}
2022-11-28 00:41:29,238 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:29,238 INFO:     Epoch: 17
2022-11-28 00:41:29,971 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42078212479298766, 'Total loss': 0.42078212479298766} | train loss {'Reaction outcome loss': 0.3529144377428658, 'Total loss': 0.3529144377428658}
2022-11-28 00:41:29,971 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:29,971 INFO:     Epoch: 18
2022-11-28 00:41:30,702 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.38196810809048737, 'Total loss': 0.38196810809048737} | train loss {'Reaction outcome loss': 0.3496228487211831, 'Total loss': 0.3496228487211831}
2022-11-28 00:41:30,702 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:30,702 INFO:     Epoch: 19
2022-11-28 00:41:31,436 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41201426258141344, 'Total loss': 0.41201426258141344} | train loss {'Reaction outcome loss': 0.3607643812134558, 'Total loss': 0.3607643812134558}
2022-11-28 00:41:31,436 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:31,436 INFO:     Epoch: 20
2022-11-28 00:41:32,169 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4198481310158968, 'Total loss': 0.4198481310158968} | train loss {'Reaction outcome loss': 0.3321176281997136, 'Total loss': 0.3321176281997136}
2022-11-28 00:41:32,169 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:32,169 INFO:     Epoch: 21
2022-11-28 00:41:32,904 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3725370627573945, 'Total loss': 0.3725370627573945} | train loss {'Reaction outcome loss': 0.3414794029325855, 'Total loss': 0.3414794029325855}
2022-11-28 00:41:32,904 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:32,905 INFO:     Epoch: 22
2022-11-28 00:41:33,640 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4160369104621085, 'Total loss': 0.4160369104621085} | train loss {'Reaction outcome loss': 0.34221963295523, 'Total loss': 0.34221963295523}
2022-11-28 00:41:33,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:33,640 INFO:     Epoch: 23
2022-11-28 00:41:34,374 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4281579381362958, 'Total loss': 0.4281579381362958} | train loss {'Reaction outcome loss': 0.34382925374167306, 'Total loss': 0.34382925374167306}
2022-11-28 00:41:34,374 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:34,374 INFO:     Epoch: 24
2022-11-28 00:41:35,108 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4042885554107753, 'Total loss': 0.4042885554107753} | train loss {'Reaction outcome loss': 0.3426293674476293, 'Total loss': 0.3426293674476293}
2022-11-28 00:41:35,108 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:35,108 INFO:     Epoch: 25
2022-11-28 00:41:35,836 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3903563137758862, 'Total loss': 0.3903563137758862} | train loss {'Reaction outcome loss': 0.3226694661135576, 'Total loss': 0.3226694661135576}
2022-11-28 00:41:35,836 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:35,836 INFO:     Epoch: 26
2022-11-28 00:41:36,567 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3773145750588314, 'Total loss': 0.3773145750588314} | train loss {'Reaction outcome loss': 0.32769582031332717, 'Total loss': 0.32769582031332717}
2022-11-28 00:41:36,567 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:36,568 INFO:     Epoch: 27
2022-11-28 00:41:37,304 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3835697812451558, 'Total loss': 0.3835697812451558} | train loss {'Reaction outcome loss': 0.33904908290322944, 'Total loss': 0.33904908290322944}
2022-11-28 00:41:37,304 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:37,304 INFO:     Epoch: 28
2022-11-28 00:41:38,038 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.36983007057146594, 'Total loss': 0.36983007057146594} | train loss {'Reaction outcome loss': 0.320586468066488, 'Total loss': 0.320586468066488}
2022-11-28 00:41:38,039 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:38,039 INFO:     Epoch: 29
2022-11-28 00:41:38,775 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.366916877979582, 'Total loss': 0.366916877979582} | train loss {'Reaction outcome loss': 0.33378256451414556, 'Total loss': 0.33378256451414556}
2022-11-28 00:41:38,775 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:38,775 INFO:     Epoch: 30
2022-11-28 00:41:39,512 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39497850835323334, 'Total loss': 0.39497850835323334} | train loss {'Reaction outcome loss': 0.32685504099544216, 'Total loss': 0.32685504099544216}
2022-11-28 00:41:39,512 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:39,512 INFO:     Epoch: 31
2022-11-28 00:41:40,253 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3863609697331082, 'Total loss': 0.3863609697331082} | train loss {'Reaction outcome loss': 0.33087635453866454, 'Total loss': 0.33087635453866454}
2022-11-28 00:41:40,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:40,253 INFO:     Epoch: 32
2022-11-28 00:41:40,995 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3738296404480934, 'Total loss': 0.3738296404480934} | train loss {'Reaction outcome loss': 0.3258685316662399, 'Total loss': 0.3258685316662399}
2022-11-28 00:41:40,995 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:40,995 INFO:     Epoch: 33
2022-11-28 00:41:41,739 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3769173456186598, 'Total loss': 0.3769173456186598} | train loss {'Reaction outcome loss': 0.3398902721398947, 'Total loss': 0.3398902721398947}
2022-11-28 00:41:41,739 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:41,739 INFO:     Epoch: 34
2022-11-28 00:41:42,488 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38165103034539655, 'Total loss': 0.38165103034539655} | train loss {'Reaction outcome loss': 0.3173283848531392, 'Total loss': 0.3173283848531392}
2022-11-28 00:41:42,488 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:42,488 INFO:     Epoch: 35
2022-11-28 00:41:43,235 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3789169639348984, 'Total loss': 0.3789169639348984} | train loss {'Reaction outcome loss': 0.32506665608712604, 'Total loss': 0.32506665608712604}
2022-11-28 00:41:43,235 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:43,235 INFO:     Epoch: 36
2022-11-28 00:41:43,981 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3700456267053431, 'Total loss': 0.3700456267053431} | train loss {'Reaction outcome loss': 0.3217872138230168, 'Total loss': 0.3217872138230168}
2022-11-28 00:41:43,981 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:43,981 INFO:     Epoch: 37
2022-11-28 00:41:44,725 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38385135494172573, 'Total loss': 0.38385135494172573} | train loss {'Reaction outcome loss': 0.32630888016856446, 'Total loss': 0.32630888016856446}
2022-11-28 00:41:44,725 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:44,725 INFO:     Epoch: 38
2022-11-28 00:41:45,475 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.37834063765000214, 'Total loss': 0.37834063765000214} | train loss {'Reaction outcome loss': 0.320674194730058, 'Total loss': 0.320674194730058}
2022-11-28 00:41:45,475 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:45,476 INFO:     Epoch: 39
2022-11-28 00:41:46,221 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3917403617365794, 'Total loss': 0.3917403617365794} | train loss {'Reaction outcome loss': 0.3149335387562002, 'Total loss': 0.3149335387562002}
2022-11-28 00:41:46,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:46,221 INFO:     Epoch: 40
2022-11-28 00:41:46,968 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.35656947710297326, 'Total loss': 0.35656947710297326} | train loss {'Reaction outcome loss': 0.32203164635872356, 'Total loss': 0.32203164635872356}
2022-11-28 00:41:46,968 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:46,968 INFO:     Epoch: 41
2022-11-28 00:41:47,714 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3975698535584591, 'Total loss': 0.3975698535584591} | train loss {'Reaction outcome loss': 0.320606170351408, 'Total loss': 0.320606170351408}
2022-11-28 00:41:47,715 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:47,715 INFO:     Epoch: 42
2022-11-28 00:41:48,458 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43053681775927544, 'Total loss': 0.43053681775927544} | train loss {'Reaction outcome loss': 0.32199129348202626, 'Total loss': 0.32199129348202626}
2022-11-28 00:41:48,459 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:48,459 INFO:     Epoch: 43
2022-11-28 00:41:49,202 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.38879742134701123, 'Total loss': 0.38879742134701123} | train loss {'Reaction outcome loss': 0.32209070747604174, 'Total loss': 0.32209070747604174}
2022-11-28 00:41:49,202 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:49,202 INFO:     Epoch: 44
2022-11-28 00:41:49,946 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3942598909647627, 'Total loss': 0.3942598909647627} | train loss {'Reaction outcome loss': 0.32002526368109546, 'Total loss': 0.32002526368109546}
2022-11-28 00:41:49,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:49,946 INFO:     Epoch: 45
2022-11-28 00:41:50,690 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38842811418527906, 'Total loss': 0.38842811418527906} | train loss {'Reaction outcome loss': 0.32238556104046956, 'Total loss': 0.32238556104046956}
2022-11-28 00:41:50,690 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:50,690 INFO:     Epoch: 46
2022-11-28 00:41:51,434 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.347498120486059, 'Total loss': 0.347498120486059} | train loss {'Reaction outcome loss': 0.3164478152686236, 'Total loss': 0.3164478152686236}
2022-11-28 00:41:51,434 INFO:     Found new best model at epoch 46
2022-11-28 00:41:51,435 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:51,435 INFO:     Epoch: 47
2022-11-28 00:41:52,179 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3908701291815801, 'Total loss': 0.3908701291815801} | train loss {'Reaction outcome loss': 0.32254517266944965, 'Total loss': 0.32254517266944965}
2022-11-28 00:41:52,179 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:52,179 INFO:     Epoch: 48
2022-11-28 00:41:52,924 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38453253968195483, 'Total loss': 0.38453253968195483} | train loss {'Reaction outcome loss': 0.30983018069242946, 'Total loss': 0.30983018069242946}
2022-11-28 00:41:52,924 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:52,924 INFO:     Epoch: 49
2022-11-28 00:41:53,667 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.36565948235379025, 'Total loss': 0.36565948235379025} | train loss {'Reaction outcome loss': 0.31641455764064985, 'Total loss': 0.31641455764064985}
2022-11-28 00:41:53,667 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:53,667 INFO:     Epoch: 50
2022-11-28 00:41:54,413 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40813418037512084, 'Total loss': 0.40813418037512084} | train loss {'Reaction outcome loss': 0.32122066775146796, 'Total loss': 0.32122066775146796}
2022-11-28 00:41:54,413 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:54,413 INFO:     Epoch: 51
2022-11-28 00:41:55,161 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4080208287659017, 'Total loss': 0.4080208287659017} | train loss {'Reaction outcome loss': 0.31610957633475867, 'Total loss': 0.31610957633475867}
2022-11-28 00:41:55,161 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:55,161 INFO:     Epoch: 52
2022-11-28 00:41:55,904 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.37614295970309863, 'Total loss': 0.37614295970309863} | train loss {'Reaction outcome loss': 0.3210752929351768, 'Total loss': 0.3210752929351768}
2022-11-28 00:41:55,904 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:55,905 INFO:     Epoch: 53
2022-11-28 00:41:56,646 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3703212905675173, 'Total loss': 0.3703212905675173} | train loss {'Reaction outcome loss': 0.316981102191672, 'Total loss': 0.316981102191672}
2022-11-28 00:41:56,646 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:56,646 INFO:     Epoch: 54
2022-11-28 00:41:57,388 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3673512747680599, 'Total loss': 0.3673512747680599} | train loss {'Reaction outcome loss': 0.31755685927916544, 'Total loss': 0.31755685927916544}
2022-11-28 00:41:57,389 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:57,389 INFO:     Epoch: 55
2022-11-28 00:41:58,135 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4641234031455083, 'Total loss': 0.4641234031455083} | train loss {'Reaction outcome loss': 0.3102772167446662, 'Total loss': 0.3102772167446662}
2022-11-28 00:41:58,135 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:58,135 INFO:     Epoch: 56
2022-11-28 00:41:58,879 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3983155619353056, 'Total loss': 0.3983155619353056} | train loss {'Reaction outcome loss': 0.31763068264236255, 'Total loss': 0.31763068264236255}
2022-11-28 00:41:58,880 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:58,880 INFO:     Epoch: 57
2022-11-28 00:41:59,622 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3620125033300031, 'Total loss': 0.3620125033300031} | train loss {'Reaction outcome loss': 0.3226146998150008, 'Total loss': 0.3226146998150008}
2022-11-28 00:41:59,622 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:41:59,622 INFO:     Epoch: 58
2022-11-28 00:42:00,365 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39333601973273535, 'Total loss': 0.39333601973273535} | train loss {'Reaction outcome loss': 0.31989308635191044, 'Total loss': 0.31989308635191044}
2022-11-28 00:42:00,366 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:00,366 INFO:     Epoch: 59
2022-11-28 00:42:01,113 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37678883258592, 'Total loss': 0.37678883258592} | train loss {'Reaction outcome loss': 0.3163043141669157, 'Total loss': 0.3163043141669157}
2022-11-28 00:42:01,113 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:01,113 INFO:     Epoch: 60
2022-11-28 00:42:01,859 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.38026596436446364, 'Total loss': 0.38026596436446364} | train loss {'Reaction outcome loss': 0.31346462134804043, 'Total loss': 0.31346462134804043}
2022-11-28 00:42:01,859 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:01,859 INFO:     Epoch: 61
2022-11-28 00:42:02,603 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40406722304495896, 'Total loss': 0.40406722304495896} | train loss {'Reaction outcome loss': 0.32478277328975347, 'Total loss': 0.32478277328975347}
2022-11-28 00:42:02,603 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:02,603 INFO:     Epoch: 62
2022-11-28 00:42:03,347 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37723672660914337, 'Total loss': 0.37723672660914337} | train loss {'Reaction outcome loss': 0.3189428995458447, 'Total loss': 0.3189428995458447}
2022-11-28 00:42:03,347 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:03,347 INFO:     Epoch: 63
2022-11-28 00:42:04,090 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40171787921677937, 'Total loss': 0.40171787921677937} | train loss {'Reaction outcome loss': 0.32105062102176707, 'Total loss': 0.32105062102176707}
2022-11-28 00:42:04,091 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:04,091 INFO:     Epoch: 64
2022-11-28 00:42:04,831 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39299130880019884, 'Total loss': 0.39299130880019884} | train loss {'Reaction outcome loss': 0.308964086521645, 'Total loss': 0.308964086521645}
2022-11-28 00:42:04,831 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:04,831 INFO:     Epoch: 65
2022-11-28 00:42:05,574 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37283172085881233, 'Total loss': 0.37283172085881233} | train loss {'Reaction outcome loss': 0.319390731137626, 'Total loss': 0.319390731137626}
2022-11-28 00:42:05,574 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:05,574 INFO:     Epoch: 66
2022-11-28 00:42:06,316 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39430615170435473, 'Total loss': 0.39430615170435473} | train loss {'Reaction outcome loss': 0.31590911855503007, 'Total loss': 0.31590911855503007}
2022-11-28 00:42:06,316 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:06,316 INFO:     Epoch: 67
2022-11-28 00:42:07,058 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.376444512470202, 'Total loss': 0.376444512470202} | train loss {'Reaction outcome loss': 0.3229090149001199, 'Total loss': 0.3229090149001199}
2022-11-28 00:42:07,058 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:07,058 INFO:     Epoch: 68
2022-11-28 00:42:07,801 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40543146803975105, 'Total loss': 0.40543146803975105} | train loss {'Reaction outcome loss': 0.3086292195989161, 'Total loss': 0.3086292195989161}
2022-11-28 00:42:07,801 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:07,801 INFO:     Epoch: 69
2022-11-28 00:42:08,544 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3686624384400519, 'Total loss': 0.3686624384400519} | train loss {'Reaction outcome loss': 0.31652868429617004, 'Total loss': 0.31652868429617004}
2022-11-28 00:42:08,544 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:08,544 INFO:     Epoch: 70
2022-11-28 00:42:09,291 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.392902202734893, 'Total loss': 0.392902202734893} | train loss {'Reaction outcome loss': 0.3173585799579718, 'Total loss': 0.3173585799579718}
2022-11-28 00:42:09,291 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:09,291 INFO:     Epoch: 71
2022-11-28 00:42:10,038 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37521931271343917, 'Total loss': 0.37521931271343917} | train loss {'Reaction outcome loss': 0.3065109505337112, 'Total loss': 0.3065109505337112}
2022-11-28 00:42:10,039 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:10,039 INFO:     Epoch: 72
2022-11-28 00:42:10,785 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.386167242445729, 'Total loss': 0.386167242445729} | train loss {'Reaction outcome loss': 0.3174264881075645, 'Total loss': 0.3174264881075645}
2022-11-28 00:42:10,786 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:10,786 INFO:     Epoch: 73
2022-11-28 00:42:11,531 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3983318348499862, 'Total loss': 0.3983318348499862} | train loss {'Reaction outcome loss': 0.3128153898278061, 'Total loss': 0.3128153898278061}
2022-11-28 00:42:11,531 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:11,531 INFO:     Epoch: 74
2022-11-28 00:42:12,274 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4218000244687904, 'Total loss': 0.4218000244687904} | train loss {'Reaction outcome loss': 0.31039568289202085, 'Total loss': 0.31039568289202085}
2022-11-28 00:42:12,274 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:12,274 INFO:     Epoch: 75
2022-11-28 00:42:13,019 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40299787203019316, 'Total loss': 0.40299787203019316} | train loss {'Reaction outcome loss': 0.30418967105904404, 'Total loss': 0.30418967105904404}
2022-11-28 00:42:13,020 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:13,020 INFO:     Epoch: 76
2022-11-28 00:42:13,765 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4437331219034439, 'Total loss': 0.4437331219034439} | train loss {'Reaction outcome loss': 0.3115102086064159, 'Total loss': 0.3115102086064159}
2022-11-28 00:42:13,765 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:13,765 INFO:     Epoch: 77
2022-11-28 00:42:14,508 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3935450312088836, 'Total loss': 0.3935450312088836} | train loss {'Reaction outcome loss': 0.31057762430638686, 'Total loss': 0.31057762430638686}
2022-11-28 00:42:14,508 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:14,508 INFO:     Epoch: 78
2022-11-28 00:42:15,253 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47288203137842094, 'Total loss': 0.47288203137842094} | train loss {'Reaction outcome loss': 0.3150514258718004, 'Total loss': 0.3150514258718004}
2022-11-28 00:42:15,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:15,253 INFO:     Epoch: 79
2022-11-28 00:42:16,000 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39371750283647666, 'Total loss': 0.39371750283647666} | train loss {'Reaction outcome loss': 0.3224586392543754, 'Total loss': 0.3224586392543754}
2022-11-28 00:42:16,000 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:16,000 INFO:     Epoch: 80
2022-11-28 00:42:16,744 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43452411551367154, 'Total loss': 0.43452411551367154} | train loss {'Reaction outcome loss': 0.31933604646093994, 'Total loss': 0.31933604646093994}
2022-11-28 00:42:16,745 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:16,745 INFO:     Epoch: 81
2022-11-28 00:42:17,486 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38325620916756714, 'Total loss': 0.38325620916756714} | train loss {'Reaction outcome loss': 0.310259039395926, 'Total loss': 0.310259039395926}
2022-11-28 00:42:17,486 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:17,486 INFO:     Epoch: 82
2022-11-28 00:42:18,228 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4009216385470195, 'Total loss': 0.4009216385470195} | train loss {'Reaction outcome loss': 0.3077985589449503, 'Total loss': 0.3077985589449503}
2022-11-28 00:42:18,228 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:18,228 INFO:     Epoch: 83
2022-11-28 00:42:18,973 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4082858233966611, 'Total loss': 0.4082858233966611} | train loss {'Reaction outcome loss': 0.32487586034195765, 'Total loss': 0.32487586034195765}
2022-11-28 00:42:18,973 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:18,973 INFO:     Epoch: 84
2022-11-28 00:42:19,718 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3721800827505914, 'Total loss': 0.3721800827505914} | train loss {'Reaction outcome loss': 0.3086144640889703, 'Total loss': 0.3086144640889703}
2022-11-28 00:42:19,718 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:19,718 INFO:     Epoch: 85
2022-11-28 00:42:20,462 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40502873029221187, 'Total loss': 0.40502873029221187} | train loss {'Reaction outcome loss': 0.310249198638663, 'Total loss': 0.310249198638663}
2022-11-28 00:42:20,463 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:20,463 INFO:     Epoch: 86
2022-11-28 00:42:21,208 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.397212858565829, 'Total loss': 0.397212858565829} | train loss {'Reaction outcome loss': 0.309118519586568, 'Total loss': 0.309118519586568}
2022-11-28 00:42:21,208 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:21,208 INFO:     Epoch: 87
2022-11-28 00:42:21,952 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3818243440579284, 'Total loss': 0.3818243440579284} | train loss {'Reaction outcome loss': 0.31850224404918903, 'Total loss': 0.31850224404918903}
2022-11-28 00:42:21,952 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:21,952 INFO:     Epoch: 88
2022-11-28 00:42:22,693 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41191184012727305, 'Total loss': 0.41191184012727305} | train loss {'Reaction outcome loss': 0.3137742064437088, 'Total loss': 0.3137742064437088}
2022-11-28 00:42:22,693 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:22,693 INFO:     Epoch: 89
2022-11-28 00:42:23,443 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38919279453429306, 'Total loss': 0.38919279453429306} | train loss {'Reaction outcome loss': 0.31286809131199, 'Total loss': 0.31286809131199}
2022-11-28 00:42:23,443 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:23,443 INFO:     Epoch: 90
2022-11-28 00:42:24,185 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3995624560524117, 'Total loss': 0.3995624560524117} | train loss {'Reaction outcome loss': 0.3160683457340513, 'Total loss': 0.3160683457340513}
2022-11-28 00:42:24,185 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:24,185 INFO:     Epoch: 91
2022-11-28 00:42:24,930 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3761057228865949, 'Total loss': 0.3761057228865949} | train loss {'Reaction outcome loss': 0.3086154307942001, 'Total loss': 0.3086154307942001}
2022-11-28 00:42:24,930 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:24,930 INFO:     Epoch: 92
2022-11-28 00:42:25,674 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37274225445633585, 'Total loss': 0.37274225445633585} | train loss {'Reaction outcome loss': 0.3076165715954742, 'Total loss': 0.3076165715954742}
2022-11-28 00:42:25,674 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:25,674 INFO:     Epoch: 93
2022-11-28 00:42:26,415 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3775325123305348, 'Total loss': 0.3775325123305348} | train loss {'Reaction outcome loss': 0.30618161692911267, 'Total loss': 0.30618161692911267}
2022-11-28 00:42:26,415 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:26,415 INFO:     Epoch: 94
2022-11-28 00:42:27,160 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4054747280580076, 'Total loss': 0.4054747280580076} | train loss {'Reaction outcome loss': 0.30224751480379886, 'Total loss': 0.30224751480379886}
2022-11-28 00:42:27,160 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:27,160 INFO:     Epoch: 95
2022-11-28 00:42:27,904 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40048871595751157, 'Total loss': 0.40048871595751157} | train loss {'Reaction outcome loss': 0.3198264697072457, 'Total loss': 0.3198264697072457}
2022-11-28 00:42:27,904 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:27,905 INFO:     Epoch: 96
2022-11-28 00:42:28,647 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3755111666290428, 'Total loss': 0.3755111666290428} | train loss {'Reaction outcome loss': 0.3109580498872971, 'Total loss': 0.3109580498872971}
2022-11-28 00:42:28,648 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:28,648 INFO:     Epoch: 97
2022-11-28 00:42:29,395 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3883366580544548, 'Total loss': 0.3883366580544548} | train loss {'Reaction outcome loss': 0.30844510547360593, 'Total loss': 0.30844510547360593}
2022-11-28 00:42:29,395 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:29,395 INFO:     Epoch: 98
2022-11-28 00:42:30,138 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4199891442602331, 'Total loss': 0.4199891442602331} | train loss {'Reaction outcome loss': 0.3136105822969456, 'Total loss': 0.3136105822969456}
2022-11-28 00:42:30,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:30,138 INFO:     Epoch: 99
2022-11-28 00:42:30,878 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3809926702894948, 'Total loss': 0.3809926702894948} | train loss {'Reaction outcome loss': 0.31538994205849513, 'Total loss': 0.31538994205849513}
2022-11-28 00:42:30,878 INFO:     Best model found after epoch 47 of 100.
2022-11-28 00:42:30,878 INFO:   Done with stage: TRAINING
2022-11-28 00:42:30,878 INFO:   Starting stage: EVALUATION
2022-11-28 00:42:31,004 INFO:   Done with stage: EVALUATION
2022-11-28 00:42:31,004 INFO:   Leaving out SEQ value Fold_3
2022-11-28 00:42:31,017 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 00:42:31,017 INFO:   Starting stage: FEATURE SCALING
2022-11-28 00:42:31,668 INFO:   Done with stage: FEATURE SCALING
2022-11-28 00:42:31,668 INFO:   Starting stage: SCALING TARGETS
2022-11-28 00:42:31,739 INFO:   Done with stage: SCALING TARGETS
2022-11-28 00:42:31,740 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:42:31,740 INFO:     No hyperparam tuning for this model
2022-11-28 00:42:31,740 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:42:31,740 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 00:42:31,740 INFO:     None feature selector for col prot
2022-11-28 00:42:31,741 INFO:     None feature selector for col prot
2022-11-28 00:42:31,741 INFO:     None feature selector for col prot
2022-11-28 00:42:31,741 INFO:     None feature selector for col chem
2022-11-28 00:42:31,741 INFO:     None feature selector for col chem
2022-11-28 00:42:31,741 INFO:     None feature selector for col chem
2022-11-28 00:42:31,741 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 00:42:31,742 INFO:   Starting stage: BUILD MODEL
2022-11-28 00:42:31,743 INFO:     Number of params in model 169741
2022-11-28 00:42:31,746 INFO:   Done with stage: BUILD MODEL
2022-11-28 00:42:31,746 INFO:   Starting stage: TRAINING
2022-11-28 00:42:31,800 INFO:     Val loss before train {'Reaction outcome loss': 0.9607793580402028, 'Total loss': 0.9607793580402028}
2022-11-28 00:42:31,800 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:31,800 INFO:     Epoch: 0
2022-11-28 00:42:32,542 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5229422886940566, 'Total loss': 0.5229422886940566} | train loss {'Reaction outcome loss': 0.6480752387825324, 'Total loss': 0.6480752387825324}
2022-11-28 00:42:32,542 INFO:     Found new best model at epoch 0
2022-11-28 00:42:32,543 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:32,543 INFO:     Epoch: 1
2022-11-28 00:42:33,286 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5266606292941354, 'Total loss': 0.5266606292941354} | train loss {'Reaction outcome loss': 0.5173092045346085, 'Total loss': 0.5173092045346085}
2022-11-28 00:42:33,286 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:33,287 INFO:     Epoch: 2
2022-11-28 00:42:34,025 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48098312758586625, 'Total loss': 0.48098312758586625} | train loss {'Reaction outcome loss': 0.47074774163109917, 'Total loss': 0.47074774163109917}
2022-11-28 00:42:34,025 INFO:     Found new best model at epoch 2
2022-11-28 00:42:34,026 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:34,026 INFO:     Epoch: 3
2022-11-28 00:42:34,762 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4920324104076082, 'Total loss': 0.4920324104076082} | train loss {'Reaction outcome loss': 0.4476747261018169, 'Total loss': 0.4476747261018169}
2022-11-28 00:42:34,763 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:34,763 INFO:     Epoch: 4
2022-11-28 00:42:35,506 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45843582625754853, 'Total loss': 0.45843582625754853} | train loss {'Reaction outcome loss': 0.44555282452884987, 'Total loss': 0.44555282452884987}
2022-11-28 00:42:35,506 INFO:     Found new best model at epoch 4
2022-11-28 00:42:35,507 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:35,507 INFO:     Epoch: 5
2022-11-28 00:42:36,244 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4512173222716559, 'Total loss': 0.4512173222716559} | train loss {'Reaction outcome loss': 0.4268978860913491, 'Total loss': 0.4268978860913491}
2022-11-28 00:42:36,245 INFO:     Found new best model at epoch 5
2022-11-28 00:42:36,245 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:36,245 INFO:     Epoch: 6
2022-11-28 00:42:36,984 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45430207692764024, 'Total loss': 0.45430207692764024} | train loss {'Reaction outcome loss': 0.41126316591184964, 'Total loss': 0.41126316591184964}
2022-11-28 00:42:36,984 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:36,984 INFO:     Epoch: 7
2022-11-28 00:42:37,724 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4418648498302156, 'Total loss': 0.4418648498302156} | train loss {'Reaction outcome loss': 0.40284598427159446, 'Total loss': 0.40284598427159446}
2022-11-28 00:42:37,725 INFO:     Found new best model at epoch 7
2022-11-28 00:42:37,725 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:37,725 INFO:     Epoch: 8
2022-11-28 00:42:38,464 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44307670843872154, 'Total loss': 0.44307670843872154} | train loss {'Reaction outcome loss': 0.4058717206120491, 'Total loss': 0.4058717206120491}
2022-11-28 00:42:38,464 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:38,464 INFO:     Epoch: 9
2022-11-28 00:42:39,207 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4649153168905865, 'Total loss': 0.4649153168905865} | train loss {'Reaction outcome loss': 0.3916378445163065, 'Total loss': 0.3916378445163065}
2022-11-28 00:42:39,207 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:39,207 INFO:     Epoch: 10
2022-11-28 00:42:39,952 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4156912951306863, 'Total loss': 0.4156912951306863} | train loss {'Reaction outcome loss': 0.3893824102319017, 'Total loss': 0.3893824102319017}
2022-11-28 00:42:39,952 INFO:     Found new best model at epoch 10
2022-11-28 00:42:39,953 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:39,953 INFO:     Epoch: 11
2022-11-28 00:42:40,693 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4757891581817107, 'Total loss': 0.4757891581817107} | train loss {'Reaction outcome loss': 0.3837385615828086, 'Total loss': 0.3837385615828086}
2022-11-28 00:42:40,693 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:40,694 INFO:     Epoch: 12
2022-11-28 00:42:41,432 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45651616562496533, 'Total loss': 0.45651616562496533} | train loss {'Reaction outcome loss': 0.3823606401377795, 'Total loss': 0.3823606401377795}
2022-11-28 00:42:41,432 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:41,432 INFO:     Epoch: 13
2022-11-28 00:42:42,171 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4278211343017491, 'Total loss': 0.4278211343017491} | train loss {'Reaction outcome loss': 0.37059858739376067, 'Total loss': 0.37059858739376067}
2022-11-28 00:42:42,171 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:42,171 INFO:     Epoch: 14
2022-11-28 00:42:42,908 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45146031745455484, 'Total loss': 0.45146031745455484} | train loss {'Reaction outcome loss': 0.3740928587560751, 'Total loss': 0.3740928587560751}
2022-11-28 00:42:42,908 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:42,908 INFO:     Epoch: 15
2022-11-28 00:42:43,647 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44876751269806514, 'Total loss': 0.44876751269806514} | train loss {'Reaction outcome loss': 0.36095392223523587, 'Total loss': 0.36095392223523587}
2022-11-28 00:42:43,647 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:43,647 INFO:     Epoch: 16
2022-11-28 00:42:44,382 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4543124335733327, 'Total loss': 0.4543124335733327} | train loss {'Reaction outcome loss': 0.36140968267406737, 'Total loss': 0.36140968267406737}
2022-11-28 00:42:44,383 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:44,383 INFO:     Epoch: 17
2022-11-28 00:42:45,119 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42809130251407623, 'Total loss': 0.42809130251407623} | train loss {'Reaction outcome loss': 0.36749974720332085, 'Total loss': 0.36749974720332085}
2022-11-28 00:42:45,119 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:45,119 INFO:     Epoch: 18
2022-11-28 00:42:45,857 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4334527057680217, 'Total loss': 0.4334527057680217} | train loss {'Reaction outcome loss': 0.3555168982975337, 'Total loss': 0.3555168982975337}
2022-11-28 00:42:45,857 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:45,857 INFO:     Epoch: 19
2022-11-28 00:42:46,597 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43862100081010297, 'Total loss': 0.43862100081010297} | train loss {'Reaction outcome loss': 0.35737408925684133, 'Total loss': 0.35737408925684133}
2022-11-28 00:42:46,598 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:46,598 INFO:     Epoch: 20
2022-11-28 00:42:47,335 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4222822714258324, 'Total loss': 0.4222822714258324} | train loss {'Reaction outcome loss': 0.3540372932747919, 'Total loss': 0.3540372932747919}
2022-11-28 00:42:47,335 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:47,336 INFO:     Epoch: 21
2022-11-28 00:42:48,074 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42831417511809955, 'Total loss': 0.42831417511809955} | train loss {'Reaction outcome loss': 0.352755726949901, 'Total loss': 0.352755726949901}
2022-11-28 00:42:48,074 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:48,074 INFO:     Epoch: 22
2022-11-28 00:42:48,809 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4151987294581803, 'Total loss': 0.4151987294581803} | train loss {'Reaction outcome loss': 0.35206720117403534, 'Total loss': 0.35206720117403534}
2022-11-28 00:42:48,809 INFO:     Found new best model at epoch 22
2022-11-28 00:42:48,810 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:48,810 INFO:     Epoch: 23
2022-11-28 00:42:49,551 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4210356098007072, 'Total loss': 0.4210356098007072} | train loss {'Reaction outcome loss': 0.3427386983316772, 'Total loss': 0.3427386983316772}
2022-11-28 00:42:49,552 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:49,552 INFO:     Epoch: 24
2022-11-28 00:42:50,292 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4164309258657423, 'Total loss': 0.4164309258657423} | train loss {'Reaction outcome loss': 0.3490104005348926, 'Total loss': 0.3490104005348926}
2022-11-28 00:42:50,292 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:50,292 INFO:     Epoch: 25
2022-11-28 00:42:51,029 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41004680774428626, 'Total loss': 0.41004680774428626} | train loss {'Reaction outcome loss': 0.3413279122235824, 'Total loss': 0.3413279122235824}
2022-11-28 00:42:51,029 INFO:     Found new best model at epoch 25
2022-11-28 00:42:51,029 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:51,030 INFO:     Epoch: 26
2022-11-28 00:42:51,768 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4354741685092449, 'Total loss': 0.4354741685092449} | train loss {'Reaction outcome loss': 0.3397478415345659, 'Total loss': 0.3397478415345659}
2022-11-28 00:42:51,769 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:51,769 INFO:     Epoch: 27
2022-11-28 00:42:52,506 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42725155130028725, 'Total loss': 0.42725155130028725} | train loss {'Reaction outcome loss': 0.350983398027566, 'Total loss': 0.350983398027566}
2022-11-28 00:42:52,506 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:52,506 INFO:     Epoch: 28
2022-11-28 00:42:53,244 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4181263799017126, 'Total loss': 0.4181263799017126} | train loss {'Reaction outcome loss': 0.3335637091069805, 'Total loss': 0.3335637091069805}
2022-11-28 00:42:53,244 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:53,244 INFO:     Epoch: 29
2022-11-28 00:42:53,984 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43867373195561493, 'Total loss': 0.43867373195561493} | train loss {'Reaction outcome loss': 0.3446554533376986, 'Total loss': 0.3446554533376986}
2022-11-28 00:42:53,985 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:53,985 INFO:     Epoch: 30
2022-11-28 00:42:54,721 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42755296250635927, 'Total loss': 0.42755296250635927} | train loss {'Reaction outcome loss': 0.34455220504682893, 'Total loss': 0.34455220504682893}
2022-11-28 00:42:54,721 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:54,722 INFO:     Epoch: 31
2022-11-28 00:42:55,461 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4314978203990243, 'Total loss': 0.4314978203990243} | train loss {'Reaction outcome loss': 0.33535652124151893, 'Total loss': 0.33535652124151893}
2022-11-28 00:42:55,461 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:55,461 INFO:     Epoch: 32
2022-11-28 00:42:56,195 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43232929994436825, 'Total loss': 0.43232929994436825} | train loss {'Reaction outcome loss': 0.3473476920504959, 'Total loss': 0.3473476920504959}
2022-11-28 00:42:56,195 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:56,195 INFO:     Epoch: 33
2022-11-28 00:42:56,934 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4169575907289982, 'Total loss': 0.4169575907289982} | train loss {'Reaction outcome loss': 0.3372841543232908, 'Total loss': 0.3372841543232908}
2022-11-28 00:42:56,934 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:56,934 INFO:     Epoch: 34
2022-11-28 00:42:57,673 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4303109628910368, 'Total loss': 0.4303109628910368} | train loss {'Reaction outcome loss': 0.33838202679643825, 'Total loss': 0.33838202679643825}
2022-11-28 00:42:57,674 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:57,674 INFO:     Epoch: 35
2022-11-28 00:42:58,414 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44068823991851375, 'Total loss': 0.44068823991851375} | train loss {'Reaction outcome loss': 0.3409835116595638, 'Total loss': 0.3409835116595638}
2022-11-28 00:42:58,414 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:58,414 INFO:     Epoch: 36
2022-11-28 00:42:59,154 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4476509051905437, 'Total loss': 0.4476509051905437} | train loss {'Reaction outcome loss': 0.33708571895044676, 'Total loss': 0.33708571895044676}
2022-11-28 00:42:59,154 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:59,155 INFO:     Epoch: 37
2022-11-28 00:42:59,890 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.416338461027904, 'Total loss': 0.416338461027904} | train loss {'Reaction outcome loss': 0.33284225384799804, 'Total loss': 0.33284225384799804}
2022-11-28 00:42:59,891 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:42:59,891 INFO:     Epoch: 38
2022-11-28 00:43:00,630 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40370599349791353, 'Total loss': 0.40370599349791353} | train loss {'Reaction outcome loss': 0.3287941430296217, 'Total loss': 0.3287941430296217}
2022-11-28 00:43:00,631 INFO:     Found new best model at epoch 38
2022-11-28 00:43:00,631 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:00,632 INFO:     Epoch: 39
2022-11-28 00:43:01,370 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4635043242438273, 'Total loss': 0.4635043242438273} | train loss {'Reaction outcome loss': 0.3294163072595791, 'Total loss': 0.3294163072595791}
2022-11-28 00:43:01,370 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:01,371 INFO:     Epoch: 40
2022-11-28 00:43:02,113 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44521907242861664, 'Total loss': 0.44521907242861664} | train loss {'Reaction outcome loss': 0.3435889563998398, 'Total loss': 0.3435889563998398}
2022-11-28 00:43:02,113 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:02,113 INFO:     Epoch: 41
2022-11-28 00:43:02,850 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45101947303522716, 'Total loss': 0.45101947303522716} | train loss {'Reaction outcome loss': 0.33304732575708507, 'Total loss': 0.33304732575708507}
2022-11-28 00:43:02,850 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:02,850 INFO:     Epoch: 42
2022-11-28 00:43:03,588 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4550218571993438, 'Total loss': 0.4550218571993438} | train loss {'Reaction outcome loss': 0.32606158718770867, 'Total loss': 0.32606158718770867}
2022-11-28 00:43:03,589 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:03,589 INFO:     Epoch: 43
2022-11-28 00:43:04,327 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43377100777896965, 'Total loss': 0.43377100777896965} | train loss {'Reaction outcome loss': 0.3327138984081697, 'Total loss': 0.3327138984081697}
2022-11-28 00:43:04,327 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:04,327 INFO:     Epoch: 44
2022-11-28 00:43:05,063 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4468591772019863, 'Total loss': 0.4468591772019863} | train loss {'Reaction outcome loss': 0.331481846421957, 'Total loss': 0.331481846421957}
2022-11-28 00:43:05,063 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:05,063 INFO:     Epoch: 45
2022-11-28 00:43:05,803 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43933157893744385, 'Total loss': 0.43933157893744385} | train loss {'Reaction outcome loss': 0.3229476183652878, 'Total loss': 0.3229476183652878}
2022-11-28 00:43:05,803 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:05,803 INFO:     Epoch: 46
2022-11-28 00:43:06,539 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43288781629367307, 'Total loss': 0.43288781629367307} | train loss {'Reaction outcome loss': 0.328736723503288, 'Total loss': 0.328736723503288}
2022-11-28 00:43:06,540 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:06,540 INFO:     Epoch: 47
2022-11-28 00:43:07,276 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4297274580564011, 'Total loss': 0.4297274580564011} | train loss {'Reaction outcome loss': 0.3320558525773944, 'Total loss': 0.3320558525773944}
2022-11-28 00:43:07,276 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:07,277 INFO:     Epoch: 48
2022-11-28 00:43:08,013 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44007309212942014, 'Total loss': 0.44007309212942014} | train loss {'Reaction outcome loss': 0.33091148332673676, 'Total loss': 0.33091148332673676}
2022-11-28 00:43:08,013 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:08,013 INFO:     Epoch: 49
2022-11-28 00:43:08,753 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45483045415444806, 'Total loss': 0.45483045415444806} | train loss {'Reaction outcome loss': 0.3338116734003534, 'Total loss': 0.3338116734003534}
2022-11-28 00:43:08,753 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:08,753 INFO:     Epoch: 50
2022-11-28 00:43:09,488 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.438357797535983, 'Total loss': 0.438357797535983} | train loss {'Reaction outcome loss': 0.32432663326664846, 'Total loss': 0.32432663326664846}
2022-11-28 00:43:09,489 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:09,489 INFO:     Epoch: 51
2022-11-28 00:43:10,225 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44004708291454747, 'Total loss': 0.44004708291454747} | train loss {'Reaction outcome loss': 0.327738337309993, 'Total loss': 0.327738337309993}
2022-11-28 00:43:10,226 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:10,226 INFO:     Epoch: 52
2022-11-28 00:43:10,962 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43558762764388864, 'Total loss': 0.43558762764388864} | train loss {'Reaction outcome loss': 0.3275726921552298, 'Total loss': 0.3275726921552298}
2022-11-28 00:43:10,962 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:10,962 INFO:     Epoch: 53
2022-11-28 00:43:11,695 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4211436924947934, 'Total loss': 0.4211436924947934} | train loss {'Reaction outcome loss': 0.32975304184519516, 'Total loss': 0.32975304184519516}
2022-11-28 00:43:11,695 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:11,695 INFO:     Epoch: 54
2022-11-28 00:43:12,430 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4050499285486611, 'Total loss': 0.4050499285486611} | train loss {'Reaction outcome loss': 0.334116396520819, 'Total loss': 0.334116396520819}
2022-11-28 00:43:12,430 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:12,430 INFO:     Epoch: 55
2022-11-28 00:43:13,166 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.480423320423473, 'Total loss': 0.480423320423473} | train loss {'Reaction outcome loss': 0.32037963979706474, 'Total loss': 0.32037963979706474}
2022-11-28 00:43:13,166 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:13,166 INFO:     Epoch: 56
2022-11-28 00:43:13,902 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4523676017468626, 'Total loss': 0.4523676017468626} | train loss {'Reaction outcome loss': 0.33073587715625763, 'Total loss': 0.33073587715625763}
2022-11-28 00:43:13,902 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:13,902 INFO:     Epoch: 57
2022-11-28 00:43:14,641 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4451016705821861, 'Total loss': 0.4451016705821861} | train loss {'Reaction outcome loss': 0.3336902900009739, 'Total loss': 0.3336902900009739}
2022-11-28 00:43:14,641 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:14,641 INFO:     Epoch: 58
2022-11-28 00:43:15,377 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4208559024740349, 'Total loss': 0.4208559024740349} | train loss {'Reaction outcome loss': 0.31361604542756566, 'Total loss': 0.31361604542756566}
2022-11-28 00:43:15,377 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:15,377 INFO:     Epoch: 59
2022-11-28 00:43:16,112 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4249062216417356, 'Total loss': 0.4249062216417356} | train loss {'Reaction outcome loss': 0.3265813808051907, 'Total loss': 0.3265813808051907}
2022-11-28 00:43:16,112 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:16,112 INFO:     Epoch: 60
2022-11-28 00:43:16,847 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4709364268928766, 'Total loss': 0.4709364268928766} | train loss {'Reaction outcome loss': 0.3274985794206055, 'Total loss': 0.3274985794206055}
2022-11-28 00:43:16,847 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:16,847 INFO:     Epoch: 61
2022-11-28 00:43:17,586 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48511265277523885, 'Total loss': 0.48511265277523885} | train loss {'Reaction outcome loss': 0.32270571273200366, 'Total loss': 0.32270571273200366}
2022-11-28 00:43:17,586 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:17,586 INFO:     Epoch: 62
2022-11-28 00:43:18,320 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41576334766366263, 'Total loss': 0.41576334766366263} | train loss {'Reaction outcome loss': 0.3189618846439585, 'Total loss': 0.3189618846439585}
2022-11-28 00:43:18,320 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:18,320 INFO:     Epoch: 63
2022-11-28 00:43:19,054 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44016728787259624, 'Total loss': 0.44016728787259624} | train loss {'Reaction outcome loss': 0.32137163944390357, 'Total loss': 0.32137163944390357}
2022-11-28 00:43:19,054 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:19,055 INFO:     Epoch: 64
2022-11-28 00:43:19,790 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4601900814609094, 'Total loss': 0.4601900814609094} | train loss {'Reaction outcome loss': 0.318629706970283, 'Total loss': 0.318629706970283}
2022-11-28 00:43:19,790 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:19,790 INFO:     Epoch: 65
2022-11-28 00:43:20,528 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45786215060136537, 'Total loss': 0.45786215060136537} | train loss {'Reaction outcome loss': 0.32129447098289216, 'Total loss': 0.32129447098289216}
2022-11-28 00:43:20,528 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:20,528 INFO:     Epoch: 66
2022-11-28 00:43:21,263 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41802254590121185, 'Total loss': 0.41802254590121185} | train loss {'Reaction outcome loss': 0.3249603622117821, 'Total loss': 0.3249603622117821}
2022-11-28 00:43:21,263 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:21,263 INFO:     Epoch: 67
2022-11-28 00:43:22,001 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43366534398360684, 'Total loss': 0.43366534398360684} | train loss {'Reaction outcome loss': 0.31537599327917004, 'Total loss': 0.31537599327917004}
2022-11-28 00:43:22,001 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:22,002 INFO:     Epoch: 68
2022-11-28 00:43:22,740 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41497438130053604, 'Total loss': 0.41497438130053604} | train loss {'Reaction outcome loss': 0.32738341302896035, 'Total loss': 0.32738341302896035}
2022-11-28 00:43:22,740 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:22,740 INFO:     Epoch: 69
2022-11-28 00:43:23,476 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41996215961196204, 'Total loss': 0.41996215961196204} | train loss {'Reaction outcome loss': 0.32080467855747863, 'Total loss': 0.32080467855747863}
2022-11-28 00:43:23,476 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:23,476 INFO:     Epoch: 70
2022-11-28 00:43:24,211 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4651166292076761, 'Total loss': 0.4651166292076761} | train loss {'Reaction outcome loss': 0.3214899852719842, 'Total loss': 0.3214899852719842}
2022-11-28 00:43:24,211 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:24,211 INFO:     Epoch: 71
2022-11-28 00:43:24,948 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.400393195704303, 'Total loss': 0.400393195704303} | train loss {'Reaction outcome loss': 0.3198976218396304, 'Total loss': 0.3198976218396304}
2022-11-28 00:43:24,948 INFO:     Found new best model at epoch 71
2022-11-28 00:43:24,949 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:24,949 INFO:     Epoch: 72
2022-11-28 00:43:25,685 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4131217934191227, 'Total loss': 0.4131217934191227} | train loss {'Reaction outcome loss': 0.3204676431052539, 'Total loss': 0.3204676431052539}
2022-11-28 00:43:25,685 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:25,685 INFO:     Epoch: 73
2022-11-28 00:43:26,422 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4171769942410968, 'Total loss': 0.4171769942410968} | train loss {'Reaction outcome loss': 0.31494820847803234, 'Total loss': 0.31494820847803234}
2022-11-28 00:43:26,422 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:26,422 INFO:     Epoch: 74
2022-11-28 00:43:27,157 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4367976534095677, 'Total loss': 0.4367976534095677} | train loss {'Reaction outcome loss': 0.31796034680945534, 'Total loss': 0.31796034680945534}
2022-11-28 00:43:27,157 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:27,157 INFO:     Epoch: 75
2022-11-28 00:43:27,891 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42542796819047496, 'Total loss': 0.42542796819047496} | train loss {'Reaction outcome loss': 0.31701041663787805, 'Total loss': 0.31701041663787805}
2022-11-28 00:43:27,891 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:27,891 INFO:     Epoch: 76
2022-11-28 00:43:28,626 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4328478522260081, 'Total loss': 0.4328478522260081} | train loss {'Reaction outcome loss': 0.3123702806173539, 'Total loss': 0.3123702806173539}
2022-11-28 00:43:28,626 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:28,626 INFO:     Epoch: 77
2022-11-28 00:43:29,363 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42684739184650505, 'Total loss': 0.42684739184650505} | train loss {'Reaction outcome loss': 0.3115828116633454, 'Total loss': 0.3115828116633454}
2022-11-28 00:43:29,363 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:29,363 INFO:     Epoch: 78
2022-11-28 00:43:30,098 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44161358949812973, 'Total loss': 0.44161358949812973} | train loss {'Reaction outcome loss': 0.318914885058695, 'Total loss': 0.318914885058695}
2022-11-28 00:43:30,098 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:30,098 INFO:     Epoch: 79
2022-11-28 00:43:30,837 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.426859168166464, 'Total loss': 0.426859168166464} | train loss {'Reaction outcome loss': 0.3204354414374245, 'Total loss': 0.3204354414374245}
2022-11-28 00:43:30,838 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:30,838 INFO:     Epoch: 80
2022-11-28 00:43:31,580 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43224288523197174, 'Total loss': 0.43224288523197174} | train loss {'Reaction outcome loss': 0.31598545905886866, 'Total loss': 0.31598545905886866}
2022-11-28 00:43:31,580 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:31,580 INFO:     Epoch: 81
2022-11-28 00:43:32,317 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4311922900378704, 'Total loss': 0.4311922900378704} | train loss {'Reaction outcome loss': 0.31317686979867976, 'Total loss': 0.31317686979867976}
2022-11-28 00:43:32,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:32,317 INFO:     Epoch: 82
2022-11-28 00:43:33,054 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4254143966192549, 'Total loss': 0.4254143966192549} | train loss {'Reaction outcome loss': 0.32813543005257234, 'Total loss': 0.32813543005257234}
2022-11-28 00:43:33,054 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:33,054 INFO:     Epoch: 83
2022-11-28 00:43:33,793 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4443579543043267, 'Total loss': 0.4443579543043267} | train loss {'Reaction outcome loss': 0.3189841838363482, 'Total loss': 0.3189841838363482}
2022-11-28 00:43:33,794 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:33,794 INFO:     Epoch: 84
2022-11-28 00:43:34,531 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4489841467954896, 'Total loss': 0.4489841467954896} | train loss {'Reaction outcome loss': 0.31121297630728506, 'Total loss': 0.31121297630728506}
2022-11-28 00:43:34,531 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:34,531 INFO:     Epoch: 85
2022-11-28 00:43:35,271 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4586028609086167, 'Total loss': 0.4586028609086167} | train loss {'Reaction outcome loss': 0.3240099164600275, 'Total loss': 0.3240099164600275}
2022-11-28 00:43:35,271 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:35,271 INFO:     Epoch: 86
2022-11-28 00:43:36,014 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4300819496539506, 'Total loss': 0.4300819496539506} | train loss {'Reaction outcome loss': 0.31880517487927357, 'Total loss': 0.31880517487927357}
2022-11-28 00:43:36,014 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:36,014 INFO:     Epoch: 87
2022-11-28 00:43:36,756 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4324724826623093, 'Total loss': 0.4324724826623093} | train loss {'Reaction outcome loss': 0.32148195739303315, 'Total loss': 0.32148195739303315}
2022-11-28 00:43:36,757 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:36,757 INFO:     Epoch: 88
2022-11-28 00:43:37,501 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45200380617329344, 'Total loss': 0.45200380617329344} | train loss {'Reaction outcome loss': 0.3164120209764461, 'Total loss': 0.3164120209764461}
2022-11-28 00:43:37,501 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:37,501 INFO:     Epoch: 89
2022-11-28 00:43:38,242 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4571692379699512, 'Total loss': 0.4571692379699512} | train loss {'Reaction outcome loss': 0.31140541020704776, 'Total loss': 0.31140541020704776}
2022-11-28 00:43:38,242 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:38,242 INFO:     Epoch: 90
2022-11-28 00:43:38,981 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42803727225823834, 'Total loss': 0.42803727225823834} | train loss {'Reaction outcome loss': 0.3183786597026854, 'Total loss': 0.3183786597026854}
2022-11-28 00:43:38,981 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:38,981 INFO:     Epoch: 91
2022-11-28 00:43:39,722 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4184899106621742, 'Total loss': 0.4184899106621742} | train loss {'Reaction outcome loss': 0.3183234092532372, 'Total loss': 0.3183234092532372}
2022-11-28 00:43:39,722 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:39,722 INFO:     Epoch: 92
2022-11-28 00:43:40,467 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4729261567646807, 'Total loss': 0.4729261567646807} | train loss {'Reaction outcome loss': 0.30850578760918307, 'Total loss': 0.30850578760918307}
2022-11-28 00:43:40,467 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:40,467 INFO:     Epoch: 93
2022-11-28 00:43:41,212 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41216809962960804, 'Total loss': 0.41216809962960804} | train loss {'Reaction outcome loss': 0.3313606964082134, 'Total loss': 0.3313606964082134}
2022-11-28 00:43:41,212 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:41,212 INFO:     Epoch: 94
2022-11-28 00:43:41,953 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4189323860813271, 'Total loss': 0.4189323860813271} | train loss {'Reaction outcome loss': 0.32119917653653085, 'Total loss': 0.32119917653653085}
2022-11-28 00:43:41,953 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:41,953 INFO:     Epoch: 95
2022-11-28 00:43:42,697 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4193639167669145, 'Total loss': 0.4193639167669145} | train loss {'Reaction outcome loss': 0.31603642650404756, 'Total loss': 0.31603642650404756}
2022-11-28 00:43:42,697 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:42,697 INFO:     Epoch: 96
2022-11-28 00:43:43,434 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4226483167572455, 'Total loss': 0.4226483167572455} | train loss {'Reaction outcome loss': 0.31255742171589207, 'Total loss': 0.31255742171589207}
2022-11-28 00:43:43,435 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:43,435 INFO:     Epoch: 97
2022-11-28 00:43:44,178 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4356786778027361, 'Total loss': 0.4356786778027361} | train loss {'Reaction outcome loss': 0.31737711902479737, 'Total loss': 0.31737711902479737}
2022-11-28 00:43:44,178 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:44,178 INFO:     Epoch: 98
2022-11-28 00:43:44,917 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44139823588457977, 'Total loss': 0.44139823588457977} | train loss {'Reaction outcome loss': 0.3213687811274918, 'Total loss': 0.3213687811274918}
2022-11-28 00:43:44,917 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:44,918 INFO:     Epoch: 99
2022-11-28 00:43:45,657 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4330766847865148, 'Total loss': 0.4330766847865148} | train loss {'Reaction outcome loss': 0.31471520089069194, 'Total loss': 0.31471520089069194}
2022-11-28 00:43:45,658 INFO:     Best model found after epoch 72 of 100.
2022-11-28 00:43:45,658 INFO:   Done with stage: TRAINING
2022-11-28 00:43:45,658 INFO:   Starting stage: EVALUATION
2022-11-28 00:43:45,784 INFO:   Done with stage: EVALUATION
2022-11-28 00:43:45,784 INFO:   Leaving out SEQ value Fold_4
2022-11-28 00:43:45,797 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 00:43:45,797 INFO:   Starting stage: FEATURE SCALING
2022-11-28 00:43:46,447 INFO:   Done with stage: FEATURE SCALING
2022-11-28 00:43:46,447 INFO:   Starting stage: SCALING TARGETS
2022-11-28 00:43:46,518 INFO:   Done with stage: SCALING TARGETS
2022-11-28 00:43:46,518 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:43:46,518 INFO:     No hyperparam tuning for this model
2022-11-28 00:43:46,518 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:43:46,518 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 00:43:46,519 INFO:     None feature selector for col prot
2022-11-28 00:43:46,519 INFO:     None feature selector for col prot
2022-11-28 00:43:46,519 INFO:     None feature selector for col prot
2022-11-28 00:43:46,520 INFO:     None feature selector for col chem
2022-11-28 00:43:46,520 INFO:     None feature selector for col chem
2022-11-28 00:43:46,520 INFO:     None feature selector for col chem
2022-11-28 00:43:46,520 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 00:43:46,520 INFO:   Starting stage: BUILD MODEL
2022-11-28 00:43:46,522 INFO:     Number of params in model 169741
2022-11-28 00:43:46,525 INFO:   Done with stage: BUILD MODEL
2022-11-28 00:43:46,525 INFO:   Starting stage: TRAINING
2022-11-28 00:43:46,579 INFO:     Val loss before train {'Reaction outcome loss': 0.9719623984260992, 'Total loss': 0.9719623984260992}
2022-11-28 00:43:46,579 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:46,579 INFO:     Epoch: 0
2022-11-28 00:43:47,320 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.48687806962565944, 'Total loss': 0.48687806962565944} | train loss {'Reaction outcome loss': 0.622778263201519, 'Total loss': 0.622778263201519}
2022-11-28 00:43:47,320 INFO:     Found new best model at epoch 0
2022-11-28 00:43:47,321 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:47,321 INFO:     Epoch: 1
2022-11-28 00:43:48,059 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4787066158923236, 'Total loss': 0.4787066158923236} | train loss {'Reaction outcome loss': 0.48626067486344554, 'Total loss': 0.48626067486344554}
2022-11-28 00:43:48,059 INFO:     Found new best model at epoch 1
2022-11-28 00:43:48,060 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:48,060 INFO:     Epoch: 2
2022-11-28 00:43:48,799 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46410444226454606, 'Total loss': 0.46410444226454606} | train loss {'Reaction outcome loss': 0.4500190554832926, 'Total loss': 0.4500190554832926}
2022-11-28 00:43:48,799 INFO:     Found new best model at epoch 2
2022-11-28 00:43:48,800 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:48,800 INFO:     Epoch: 3
2022-11-28 00:43:49,542 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.42768377370455046, 'Total loss': 0.42768377370455046} | train loss {'Reaction outcome loss': 0.4274994417416806, 'Total loss': 0.4274994417416806}
2022-11-28 00:43:49,543 INFO:     Found new best model at epoch 3
2022-11-28 00:43:49,544 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:49,544 INFO:     Epoch: 4
2022-11-28 00:43:50,280 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45159588754177094, 'Total loss': 0.45159588754177094} | train loss {'Reaction outcome loss': 0.4109563983824788, 'Total loss': 0.4109563983824788}
2022-11-28 00:43:50,280 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:50,281 INFO:     Epoch: 5
2022-11-28 00:43:51,019 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4198698672381314, 'Total loss': 0.4198698672381314} | train loss {'Reaction outcome loss': 0.40303999933661244, 'Total loss': 0.40303999933661244}
2022-11-28 00:43:51,019 INFO:     Found new best model at epoch 5
2022-11-28 00:43:51,020 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:51,020 INFO:     Epoch: 6
2022-11-28 00:43:51,760 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3946753430434249, 'Total loss': 0.3946753430434249} | train loss {'Reaction outcome loss': 0.3995190908714217, 'Total loss': 0.3995190908714217}
2022-11-28 00:43:51,761 INFO:     Found new best model at epoch 6
2022-11-28 00:43:51,761 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:51,761 INFO:     Epoch: 7
2022-11-28 00:43:52,502 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40189278904687276, 'Total loss': 0.40189278904687276} | train loss {'Reaction outcome loss': 0.3855952781986217, 'Total loss': 0.3855952781986217}
2022-11-28 00:43:52,502 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:52,502 INFO:     Epoch: 8
2022-11-28 00:43:53,239 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4086824025620114, 'Total loss': 0.4086824025620114} | train loss {'Reaction outcome loss': 0.38299002981915764, 'Total loss': 0.38299002981915764}
2022-11-28 00:43:53,239 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:53,239 INFO:     Epoch: 9
2022-11-28 00:43:53,975 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43500054763122037, 'Total loss': 0.43500054763122037} | train loss {'Reaction outcome loss': 0.37533561185914643, 'Total loss': 0.37533561185914643}
2022-11-28 00:43:53,975 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:53,975 INFO:     Epoch: 10
2022-11-28 00:43:54,713 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42288626730442047, 'Total loss': 0.42288626730442047} | train loss {'Reaction outcome loss': 0.3678761842603586, 'Total loss': 0.3678761842603586}
2022-11-28 00:43:54,713 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:54,713 INFO:     Epoch: 11
2022-11-28 00:43:55,450 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.37773735922845925, 'Total loss': 0.37773735922845925} | train loss {'Reaction outcome loss': 0.3692013045354765, 'Total loss': 0.3692013045354765}
2022-11-28 00:43:55,451 INFO:     Found new best model at epoch 11
2022-11-28 00:43:55,451 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:55,451 INFO:     Epoch: 12
2022-11-28 00:43:56,187 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39709007062695245, 'Total loss': 0.39709007062695245} | train loss {'Reaction outcome loss': 0.37038690669804203, 'Total loss': 0.37038690669804203}
2022-11-28 00:43:56,187 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:56,187 INFO:     Epoch: 13
2022-11-28 00:43:56,926 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4198656244711442, 'Total loss': 0.4198656244711442} | train loss {'Reaction outcome loss': 0.36052308493122764, 'Total loss': 0.36052308493122764}
2022-11-28 00:43:56,926 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:56,926 INFO:     Epoch: 14
2022-11-28 00:43:57,663 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39881569147109985, 'Total loss': 0.39881569147109985} | train loss {'Reaction outcome loss': 0.3574423269045596, 'Total loss': 0.3574423269045596}
2022-11-28 00:43:57,663 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:57,663 INFO:     Epoch: 15
2022-11-28 00:43:58,400 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43203686990521173, 'Total loss': 0.43203686990521173} | train loss {'Reaction outcome loss': 0.3546132329167152, 'Total loss': 0.3546132329167152}
2022-11-28 00:43:58,400 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:58,400 INFO:     Epoch: 16
2022-11-28 00:43:59,144 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3977752441371029, 'Total loss': 0.3977752441371029} | train loss {'Reaction outcome loss': 0.3561295186986729, 'Total loss': 0.3561295186986729}
2022-11-28 00:43:59,144 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:59,144 INFO:     Epoch: 17
2022-11-28 00:43:59,886 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41253879192200577, 'Total loss': 0.41253879192200577} | train loss {'Reaction outcome loss': 0.35099547812525106, 'Total loss': 0.35099547812525106}
2022-11-28 00:43:59,886 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:43:59,886 INFO:     Epoch: 18
2022-11-28 00:44:00,621 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41601157984273, 'Total loss': 0.41601157984273} | train loss {'Reaction outcome loss': 0.35211830330746513, 'Total loss': 0.35211830330746513}
2022-11-28 00:44:00,622 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:00,622 INFO:     Epoch: 19
2022-11-28 00:44:01,361 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4049884131262926, 'Total loss': 0.4049884131262926} | train loss {'Reaction outcome loss': 0.34407886783687436, 'Total loss': 0.34407886783687436}
2022-11-28 00:44:01,361 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:01,361 INFO:     Epoch: 20
2022-11-28 00:44:02,098 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3908200240270658, 'Total loss': 0.3908200240270658} | train loss {'Reaction outcome loss': 0.3480753490511252, 'Total loss': 0.3480753490511252}
2022-11-28 00:44:02,100 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:02,100 INFO:     Epoch: 21
2022-11-28 00:44:02,837 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.446530943736434, 'Total loss': 0.446530943736434} | train loss {'Reaction outcome loss': 0.3437998598023337, 'Total loss': 0.3437998598023337}
2022-11-28 00:44:02,837 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:02,838 INFO:     Epoch: 22
2022-11-28 00:44:03,575 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4156958284703168, 'Total loss': 0.4156958284703168} | train loss {'Reaction outcome loss': 0.3482675513746787, 'Total loss': 0.3482675513746787}
2022-11-28 00:44:03,575 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:03,575 INFO:     Epoch: 23
2022-11-28 00:44:04,314 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39903101104904304, 'Total loss': 0.39903101104904304} | train loss {'Reaction outcome loss': 0.34066149452511146, 'Total loss': 0.34066149452511146}
2022-11-28 00:44:04,314 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:04,314 INFO:     Epoch: 24
2022-11-28 00:44:05,060 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4336223971437324, 'Total loss': 0.4336223971437324} | train loss {'Reaction outcome loss': 0.3291615623296524, 'Total loss': 0.3291615623296524}
2022-11-28 00:44:05,060 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:05,060 INFO:     Epoch: 25
2022-11-28 00:44:05,801 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39289834680543706, 'Total loss': 0.39289834680543706} | train loss {'Reaction outcome loss': 0.3365136061700023, 'Total loss': 0.3365136061700023}
2022-11-28 00:44:05,801 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:05,802 INFO:     Epoch: 26
2022-11-28 00:44:06,539 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4447530409829183, 'Total loss': 0.4447530409829183} | train loss {'Reaction outcome loss': 0.32913037030672543, 'Total loss': 0.32913037030672543}
2022-11-28 00:44:06,539 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:06,539 INFO:     Epoch: 27
2022-11-28 00:44:07,274 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4238740388642658, 'Total loss': 0.4238740388642658} | train loss {'Reaction outcome loss': 0.335876376470741, 'Total loss': 0.335876376470741}
2022-11-28 00:44:07,274 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:07,274 INFO:     Epoch: 28
2022-11-28 00:44:08,013 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.387634143571962, 'Total loss': 0.387634143571962} | train loss {'Reaction outcome loss': 0.33493884464307705, 'Total loss': 0.33493884464307705}
2022-11-28 00:44:08,013 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:08,013 INFO:     Epoch: 29
2022-11-28 00:44:08,750 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45239029960198834, 'Total loss': 0.45239029960198834} | train loss {'Reaction outcome loss': 0.33022529367281467, 'Total loss': 0.33022529367281467}
2022-11-28 00:44:08,750 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:08,750 INFO:     Epoch: 30
2022-11-28 00:44:09,486 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4092939634892074, 'Total loss': 0.4092939634892074} | train loss {'Reaction outcome loss': 0.3302034529496212, 'Total loss': 0.3302034529496212}
2022-11-28 00:44:09,486 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:09,487 INFO:     Epoch: 31
2022-11-28 00:44:10,223 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3993117849935185, 'Total loss': 0.3993117849935185} | train loss {'Reaction outcome loss': 0.32544981714109983, 'Total loss': 0.32544981714109983}
2022-11-28 00:44:10,223 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:10,223 INFO:     Epoch: 32
2022-11-28 00:44:10,965 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4238511461087249, 'Total loss': 0.4238511461087249} | train loss {'Reaction outcome loss': 0.32051878747891405, 'Total loss': 0.32051878747891405}
2022-11-28 00:44:10,965 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:10,965 INFO:     Epoch: 33
2022-11-28 00:44:11,707 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3830113316124136, 'Total loss': 0.3830113316124136} | train loss {'Reaction outcome loss': 0.3239434677119158, 'Total loss': 0.3239434677119158}
2022-11-28 00:44:11,707 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:11,707 INFO:     Epoch: 34
2022-11-28 00:44:12,445 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41705904562364926, 'Total loss': 0.41705904562364926} | train loss {'Reaction outcome loss': 0.32689150574864173, 'Total loss': 0.32689150574864173}
2022-11-28 00:44:12,446 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:12,446 INFO:     Epoch: 35
2022-11-28 00:44:13,188 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4155703234401616, 'Total loss': 0.4155703234401616} | train loss {'Reaction outcome loss': 0.32801529117384737, 'Total loss': 0.32801529117384737}
2022-11-28 00:44:13,188 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:13,189 INFO:     Epoch: 36
2022-11-28 00:44:13,925 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43292745778506453, 'Total loss': 0.43292745778506453} | train loss {'Reaction outcome loss': 0.3407978618023347, 'Total loss': 0.3407978618023347}
2022-11-28 00:44:13,925 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:13,925 INFO:     Epoch: 37
2022-11-28 00:44:14,661 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38966774652627384, 'Total loss': 0.38966774652627384} | train loss {'Reaction outcome loss': 0.3211939879826137, 'Total loss': 0.3211939879826137}
2022-11-28 00:44:14,661 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:14,661 INFO:     Epoch: 38
2022-11-28 00:44:15,398 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42077443918043916, 'Total loss': 0.42077443918043916} | train loss {'Reaction outcome loss': 0.3250366570694106, 'Total loss': 0.3250366570694106}
2022-11-28 00:44:15,398 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:15,398 INFO:     Epoch: 39
2022-11-28 00:44:16,133 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3796021535315297, 'Total loss': 0.3796021535315297} | train loss {'Reaction outcome loss': 0.3272591966451431, 'Total loss': 0.3272591966451431}
2022-11-28 00:44:16,133 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:16,134 INFO:     Epoch: 40
2022-11-28 00:44:16,870 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40739087624983356, 'Total loss': 0.40739087624983356} | train loss {'Reaction outcome loss': 0.3258826087628092, 'Total loss': 0.3258826087628092}
2022-11-28 00:44:16,870 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:16,870 INFO:     Epoch: 41
2022-11-28 00:44:17,605 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4103769339113073, 'Total loss': 0.4103769339113073} | train loss {'Reaction outcome loss': 0.31907882573349133, 'Total loss': 0.31907882573349133}
2022-11-28 00:44:17,605 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:17,605 INFO:     Epoch: 42
2022-11-28 00:44:18,343 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40132257251322945, 'Total loss': 0.40132257251322945} | train loss {'Reaction outcome loss': 0.31669212322758167, 'Total loss': 0.31669212322758167}
2022-11-28 00:44:18,343 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:18,343 INFO:     Epoch: 43
2022-11-28 00:44:19,079 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40218958258628845, 'Total loss': 0.40218958258628845} | train loss {'Reaction outcome loss': 0.31545001539040585, 'Total loss': 0.31545001539040585}
2022-11-28 00:44:19,079 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:19,079 INFO:     Epoch: 44
2022-11-28 00:44:19,813 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4067573862319643, 'Total loss': 0.4067573862319643} | train loss {'Reaction outcome loss': 0.3247729523145423, 'Total loss': 0.3247729523145423}
2022-11-28 00:44:19,814 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:19,814 INFO:     Epoch: 45
2022-11-28 00:44:20,552 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4003287506374446, 'Total loss': 0.4003287506374446} | train loss {'Reaction outcome loss': 0.3174079281943185, 'Total loss': 0.3174079281943185}
2022-11-28 00:44:20,552 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:20,552 INFO:     Epoch: 46
2022-11-28 00:44:21,289 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.37428893318230455, 'Total loss': 0.37428893318230455} | train loss {'Reaction outcome loss': 0.3203411614104193, 'Total loss': 0.3203411614104193}
2022-11-28 00:44:21,290 INFO:     Found new best model at epoch 46
2022-11-28 00:44:21,291 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:21,291 INFO:     Epoch: 47
2022-11-28 00:44:22,030 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.364308612421155, 'Total loss': 0.364308612421155} | train loss {'Reaction outcome loss': 0.3148614034208716, 'Total loss': 0.3148614034208716}
2022-11-28 00:44:22,030 INFO:     Found new best model at epoch 47
2022-11-28 00:44:22,031 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:22,031 INFO:     Epoch: 48
2022-11-28 00:44:22,770 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4414787732742049, 'Total loss': 0.4414787732742049} | train loss {'Reaction outcome loss': 0.31477370161791235, 'Total loss': 0.31477370161791235}
2022-11-28 00:44:22,771 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:22,771 INFO:     Epoch: 49
2022-11-28 00:44:23,509 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3919640610163862, 'Total loss': 0.3919640610163862} | train loss {'Reaction outcome loss': 0.3150621969480904, 'Total loss': 0.3150621969480904}
2022-11-28 00:44:23,510 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:23,510 INFO:     Epoch: 50
2022-11-28 00:44:24,250 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4354558146812699, 'Total loss': 0.4354558146812699} | train loss {'Reaction outcome loss': 0.32468135058879855, 'Total loss': 0.32468135058879855}
2022-11-28 00:44:24,250 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:24,250 INFO:     Epoch: 51
2022-11-28 00:44:24,992 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39874635569073935, 'Total loss': 0.39874635569073935} | train loss {'Reaction outcome loss': 0.31467801150010555, 'Total loss': 0.31467801150010555}
2022-11-28 00:44:24,992 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:24,992 INFO:     Epoch: 52
2022-11-28 00:44:25,736 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4085504294119098, 'Total loss': 0.4085504294119098} | train loss {'Reaction outcome loss': 0.31033219936854983, 'Total loss': 0.31033219936854983}
2022-11-28 00:44:25,736 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:25,736 INFO:     Epoch: 53
2022-11-28 00:44:26,476 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3980545357547023, 'Total loss': 0.3980545357547023} | train loss {'Reaction outcome loss': 0.32052720082657676, 'Total loss': 0.32052720082657676}
2022-11-28 00:44:26,477 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:26,477 INFO:     Epoch: 54
2022-11-28 00:44:27,215 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3814558698372407, 'Total loss': 0.3814558698372407} | train loss {'Reaction outcome loss': 0.3098462118482103, 'Total loss': 0.3098462118482103}
2022-11-28 00:44:27,215 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:27,215 INFO:     Epoch: 55
2022-11-28 00:44:27,951 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3919237698005004, 'Total loss': 0.3919237698005004} | train loss {'Reaction outcome loss': 0.3131889927448059, 'Total loss': 0.3131889927448059}
2022-11-28 00:44:27,951 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:27,951 INFO:     Epoch: 56
2022-11-28 00:44:28,688 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42331300862133503, 'Total loss': 0.42331300862133503} | train loss {'Reaction outcome loss': 0.3127897813916206, 'Total loss': 0.3127897813916206}
2022-11-28 00:44:28,689 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:28,689 INFO:     Epoch: 57
2022-11-28 00:44:29,431 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3989909583364021, 'Total loss': 0.3989909583364021} | train loss {'Reaction outcome loss': 0.31216539206857585, 'Total loss': 0.31216539206857585}
2022-11-28 00:44:29,431 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:29,431 INFO:     Epoch: 58
2022-11-28 00:44:30,174 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38216535594653, 'Total loss': 0.38216535594653} | train loss {'Reaction outcome loss': 0.31091212979993044, 'Total loss': 0.31091212979993044}
2022-11-28 00:44:30,174 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:30,174 INFO:     Epoch: 59
2022-11-28 00:44:30,909 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4548603536730463, 'Total loss': 0.4548603536730463} | train loss {'Reaction outcome loss': 0.3092656117008657, 'Total loss': 0.3092656117008657}
2022-11-28 00:44:30,909 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:30,909 INFO:     Epoch: 60
2022-11-28 00:44:31,647 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.36354315517978236, 'Total loss': 0.36354315517978236} | train loss {'Reaction outcome loss': 0.3284554945875187, 'Total loss': 0.3284554945875187}
2022-11-28 00:44:31,647 INFO:     Found new best model at epoch 60
2022-11-28 00:44:31,648 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:31,648 INFO:     Epoch: 61
2022-11-28 00:44:32,386 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4025523777712475, 'Total loss': 0.4025523777712475} | train loss {'Reaction outcome loss': 0.309684402799728, 'Total loss': 0.309684402799728}
2022-11-28 00:44:32,386 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:32,386 INFO:     Epoch: 62
2022-11-28 00:44:33,128 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.390814895064316, 'Total loss': 0.390814895064316} | train loss {'Reaction outcome loss': 0.30799100344278374, 'Total loss': 0.30799100344278374}
2022-11-28 00:44:33,129 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:33,129 INFO:     Epoch: 63
2022-11-28 00:44:33,865 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38068659976124763, 'Total loss': 0.38068659976124763} | train loss {'Reaction outcome loss': 0.31277520510615137, 'Total loss': 0.31277520510615137}
2022-11-28 00:44:33,865 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:33,865 INFO:     Epoch: 64
2022-11-28 00:44:34,600 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3987836976620284, 'Total loss': 0.3987836976620284} | train loss {'Reaction outcome loss': 0.312569430607314, 'Total loss': 0.312569430607314}
2022-11-28 00:44:34,600 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:34,600 INFO:     Epoch: 65
2022-11-28 00:44:35,337 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39983030781149864, 'Total loss': 0.39983030781149864} | train loss {'Reaction outcome loss': 0.31004909330180713, 'Total loss': 0.31004909330180713}
2022-11-28 00:44:35,337 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:35,338 INFO:     Epoch: 66
2022-11-28 00:44:36,076 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43813239715316077, 'Total loss': 0.43813239715316077} | train loss {'Reaction outcome loss': 0.3129822383729779, 'Total loss': 0.3129822383729779}
2022-11-28 00:44:36,076 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:36,076 INFO:     Epoch: 67
2022-11-28 00:44:36,810 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3722811447964473, 'Total loss': 0.3722811447964473} | train loss {'Reaction outcome loss': 0.31187361977538286, 'Total loss': 0.31187361977538286}
2022-11-28 00:44:36,811 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:36,811 INFO:     Epoch: 68
2022-11-28 00:44:37,547 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3950987495481968, 'Total loss': 0.3950987495481968} | train loss {'Reaction outcome loss': 0.31490970415120223, 'Total loss': 0.31490970415120223}
2022-11-28 00:44:37,547 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:37,547 INFO:     Epoch: 69
2022-11-28 00:44:38,283 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3948274254798889, 'Total loss': 0.3948274254798889} | train loss {'Reaction outcome loss': 0.31097495253292884, 'Total loss': 0.31097495253292884}
2022-11-28 00:44:38,283 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:38,283 INFO:     Epoch: 70
2022-11-28 00:44:39,020 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3758664400401441, 'Total loss': 0.3758664400401441} | train loss {'Reaction outcome loss': 0.308821927467171, 'Total loss': 0.308821927467171}
2022-11-28 00:44:39,020 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:39,020 INFO:     Epoch: 71
2022-11-28 00:44:39,758 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3658653883771463, 'Total loss': 0.3658653883771463} | train loss {'Reaction outcome loss': 0.3105906827717411, 'Total loss': 0.3105906827717411}
2022-11-28 00:44:39,759 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:39,759 INFO:     Epoch: 72
2022-11-28 00:44:40,497 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4331101162189787, 'Total loss': 0.4331101162189787} | train loss {'Reaction outcome loss': 0.3248989555604604, 'Total loss': 0.3248989555604604}
2022-11-28 00:44:40,497 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:40,498 INFO:     Epoch: 73
2022-11-28 00:44:41,234 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39559161561456596, 'Total loss': 0.39559161561456596} | train loss {'Reaction outcome loss': 0.3161459603175825, 'Total loss': 0.3161459603175825}
2022-11-28 00:44:41,234 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:41,234 INFO:     Epoch: 74
2022-11-28 00:44:41,971 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4110453724861145, 'Total loss': 0.4110453724861145} | train loss {'Reaction outcome loss': 0.3052933085025573, 'Total loss': 0.3052933085025573}
2022-11-28 00:44:41,971 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:41,971 INFO:     Epoch: 75
2022-11-28 00:44:42,708 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4277225891974839, 'Total loss': 0.4277225891974839} | train loss {'Reaction outcome loss': 0.299419517526213, 'Total loss': 0.299419517526213}
2022-11-28 00:44:42,708 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:42,708 INFO:     Epoch: 76
2022-11-28 00:44:43,443 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4169263954020359, 'Total loss': 0.4169263954020359} | train loss {'Reaction outcome loss': 0.31338491604036217, 'Total loss': 0.31338491604036217}
2022-11-28 00:44:43,443 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:43,443 INFO:     Epoch: 77
2022-11-28 00:44:44,183 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40999014218422497, 'Total loss': 0.40999014218422497} | train loss {'Reaction outcome loss': 0.31081413036706496, 'Total loss': 0.31081413036706496}
2022-11-28 00:44:44,183 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:44,183 INFO:     Epoch: 78
2022-11-28 00:44:44,925 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39358044212514703, 'Total loss': 0.39358044212514703} | train loss {'Reaction outcome loss': 0.31687210773935126, 'Total loss': 0.31687210773935126}
2022-11-28 00:44:44,925 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:44,925 INFO:     Epoch: 79
2022-11-28 00:44:45,662 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42212227427146654, 'Total loss': 0.42212227427146654} | train loss {'Reaction outcome loss': 0.3160801958672854, 'Total loss': 0.3160801958672854}
2022-11-28 00:44:45,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:45,662 INFO:     Epoch: 80
2022-11-28 00:44:46,407 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38426181563938205, 'Total loss': 0.38426181563938205} | train loss {'Reaction outcome loss': 0.3057406383813644, 'Total loss': 0.3057406383813644}
2022-11-28 00:44:46,407 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:46,408 INFO:     Epoch: 81
2022-11-28 00:44:47,147 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39513350125740876, 'Total loss': 0.39513350125740876} | train loss {'Reaction outcome loss': 0.30639456969742873, 'Total loss': 0.30639456969742873}
2022-11-28 00:44:47,147 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:47,147 INFO:     Epoch: 82
2022-11-28 00:44:47,888 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4108095693994652, 'Total loss': 0.4108095693994652} | train loss {'Reaction outcome loss': 0.31015058299716636, 'Total loss': 0.31015058299716636}
2022-11-28 00:44:47,888 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:47,888 INFO:     Epoch: 83
2022-11-28 00:44:48,627 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3992133184590123, 'Total loss': 0.3992133184590123} | train loss {'Reaction outcome loss': 0.3103996977057992, 'Total loss': 0.3103996977057992}
2022-11-28 00:44:48,627 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:48,627 INFO:     Epoch: 84
2022-11-28 00:44:49,365 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38683604972902685, 'Total loss': 0.38683604972902685} | train loss {'Reaction outcome loss': 0.3037469068352057, 'Total loss': 0.3037469068352057}
2022-11-28 00:44:49,365 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:49,366 INFO:     Epoch: 85
2022-11-28 00:44:50,107 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3872375979342244, 'Total loss': 0.3872375979342244} | train loss {'Reaction outcome loss': 0.31733679969091805, 'Total loss': 0.31733679969091805}
2022-11-28 00:44:50,107 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:50,107 INFO:     Epoch: 86
2022-11-28 00:44:50,843 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4424149811437184, 'Total loss': 0.4424149811437184} | train loss {'Reaction outcome loss': 0.309618763808085, 'Total loss': 0.309618763808085}
2022-11-28 00:44:50,844 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:50,844 INFO:     Epoch: 87
2022-11-28 00:44:51,580 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39896907327188685, 'Total loss': 0.39896907327188685} | train loss {'Reaction outcome loss': 0.31034748368725484, 'Total loss': 0.31034748368725484}
2022-11-28 00:44:51,581 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:51,581 INFO:     Epoch: 88
2022-11-28 00:44:52,317 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44537303054874594, 'Total loss': 0.44537303054874594} | train loss {'Reaction outcome loss': 0.3090524560334731, 'Total loss': 0.3090524560334731}
2022-11-28 00:44:52,318 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:52,318 INFO:     Epoch: 89
2022-11-28 00:44:53,062 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3995315297083421, 'Total loss': 0.3995315297083421} | train loss {'Reaction outcome loss': 0.3051495142433108, 'Total loss': 0.3051495142433108}
2022-11-28 00:44:53,062 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:53,062 INFO:     Epoch: 90
2022-11-28 00:44:53,806 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.437191073528745, 'Total loss': 0.437191073528745} | train loss {'Reaction outcome loss': 0.3152365333875831, 'Total loss': 0.3152365333875831}
2022-11-28 00:44:53,806 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:53,806 INFO:     Epoch: 91
2022-11-28 00:44:54,553 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4213247670030052, 'Total loss': 0.4213247670030052} | train loss {'Reaction outcome loss': 0.30169129113153537, 'Total loss': 0.30169129113153537}
2022-11-28 00:44:54,553 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:54,553 INFO:     Epoch: 92
2022-11-28 00:44:55,297 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.38601131216538226, 'Total loss': 0.38601131216538226} | train loss {'Reaction outcome loss': 0.3143920938883509, 'Total loss': 0.3143920938883509}
2022-11-28 00:44:55,297 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:55,297 INFO:     Epoch: 93
2022-11-28 00:44:56,040 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38270905715498055, 'Total loss': 0.38270905715498055} | train loss {'Reaction outcome loss': 0.3057181154586831, 'Total loss': 0.3057181154586831}
2022-11-28 00:44:56,040 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:56,040 INFO:     Epoch: 94
2022-11-28 00:44:56,782 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4354198097505353, 'Total loss': 0.4354198097505353} | train loss {'Reaction outcome loss': 0.3060787529057386, 'Total loss': 0.3060787529057386}
2022-11-28 00:44:56,783 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:56,783 INFO:     Epoch: 95
2022-11-28 00:44:57,531 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39827974513173103, 'Total loss': 0.39827974513173103} | train loss {'Reaction outcome loss': 0.3068558520352354, 'Total loss': 0.3068558520352354}
2022-11-28 00:44:57,531 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:57,531 INFO:     Epoch: 96
2022-11-28 00:44:58,274 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3914934518662366, 'Total loss': 0.3914934518662366} | train loss {'Reaction outcome loss': 0.30837155323551624, 'Total loss': 0.30837155323551624}
2022-11-28 00:44:58,274 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:58,274 INFO:     Epoch: 97
2022-11-28 00:44:59,016 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41366602582010353, 'Total loss': 0.41366602582010353} | train loss {'Reaction outcome loss': 0.30136700561460184, 'Total loss': 0.30136700561460184}
2022-11-28 00:44:59,016 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:59,016 INFO:     Epoch: 98
2022-11-28 00:44:59,760 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3932477963072332, 'Total loss': 0.3932477963072332} | train loss {'Reaction outcome loss': 0.3065116474518971, 'Total loss': 0.3065116474518971}
2022-11-28 00:44:59,760 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:44:59,760 INFO:     Epoch: 99
2022-11-28 00:45:00,505 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3974898687976582, 'Total loss': 0.3974898687976582} | train loss {'Reaction outcome loss': 0.3087263482717835, 'Total loss': 0.3087263482717835}
2022-11-28 00:45:00,505 INFO:     Best model found after epoch 61 of 100.
2022-11-28 00:45:00,505 INFO:   Done with stage: TRAINING
2022-11-28 00:45:00,505 INFO:   Starting stage: EVALUATION
2022-11-28 00:45:00,631 INFO:   Done with stage: EVALUATION
2022-11-28 00:45:00,631 INFO:   Leaving out SEQ value Fold_5
2022-11-28 00:45:00,644 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 00:45:00,644 INFO:   Starting stage: FEATURE SCALING
2022-11-28 00:45:01,294 INFO:   Done with stage: FEATURE SCALING
2022-11-28 00:45:01,294 INFO:   Starting stage: SCALING TARGETS
2022-11-28 00:45:01,365 INFO:   Done with stage: SCALING TARGETS
2022-11-28 00:45:01,366 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:45:01,366 INFO:     No hyperparam tuning for this model
2022-11-28 00:45:01,366 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:45:01,366 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 00:45:01,367 INFO:     None feature selector for col prot
2022-11-28 00:45:01,367 INFO:     None feature selector for col prot
2022-11-28 00:45:01,367 INFO:     None feature selector for col prot
2022-11-28 00:45:01,367 INFO:     None feature selector for col chem
2022-11-28 00:45:01,367 INFO:     None feature selector for col chem
2022-11-28 00:45:01,368 INFO:     None feature selector for col chem
2022-11-28 00:45:01,368 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 00:45:01,368 INFO:   Starting stage: BUILD MODEL
2022-11-28 00:45:01,369 INFO:     Number of params in model 169741
2022-11-28 00:45:01,373 INFO:   Done with stage: BUILD MODEL
2022-11-28 00:45:01,373 INFO:   Starting stage: TRAINING
2022-11-28 00:45:01,427 INFO:     Val loss before train {'Reaction outcome loss': 1.017699121074243, 'Total loss': 1.017699121074243}
2022-11-28 00:45:01,427 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:01,427 INFO:     Epoch: 0
2022-11-28 00:45:02,179 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5418897149237719, 'Total loss': 0.5418897149237719} | train loss {'Reaction outcome loss': 0.6206178996968366, 'Total loss': 0.6206178996968366}
2022-11-28 00:45:02,179 INFO:     Found new best model at epoch 0
2022-11-28 00:45:02,180 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:02,180 INFO:     Epoch: 1
2022-11-28 00:45:02,927 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.502776600420475, 'Total loss': 0.502776600420475} | train loss {'Reaction outcome loss': 0.4985069576122983, 'Total loss': 0.4985069576122983}
2022-11-28 00:45:02,927 INFO:     Found new best model at epoch 1
2022-11-28 00:45:02,928 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:02,928 INFO:     Epoch: 2
2022-11-28 00:45:03,677 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.501824215054512, 'Total loss': 0.501824215054512} | train loss {'Reaction outcome loss': 0.45570091760683396, 'Total loss': 0.45570091760683396}
2022-11-28 00:45:03,677 INFO:     Found new best model at epoch 2
2022-11-28 00:45:03,678 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:03,678 INFO:     Epoch: 3
2022-11-28 00:45:04,431 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4633213979276744, 'Total loss': 0.4633213979276744} | train loss {'Reaction outcome loss': 0.4401567294771372, 'Total loss': 0.4401567294771372}
2022-11-28 00:45:04,432 INFO:     Found new best model at epoch 3
2022-11-28 00:45:04,433 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:04,433 INFO:     Epoch: 4
2022-11-28 00:45:05,184 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4884746479378505, 'Total loss': 0.4884746479378505} | train loss {'Reaction outcome loss': 0.42552368020872594, 'Total loss': 0.42552368020872594}
2022-11-28 00:45:05,184 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:05,184 INFO:     Epoch: 5
2022-11-28 00:45:05,939 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4696530950340358, 'Total loss': 0.4696530950340358} | train loss {'Reaction outcome loss': 0.40416957733602177, 'Total loss': 0.40416957733602177}
2022-11-28 00:45:05,939 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:05,939 INFO:     Epoch: 6
2022-11-28 00:45:06,693 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4358984424986623, 'Total loss': 0.4358984424986623} | train loss {'Reaction outcome loss': 0.3959172314960464, 'Total loss': 0.3959172314960464}
2022-11-28 00:45:06,693 INFO:     Found new best model at epoch 6
2022-11-28 00:45:06,694 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:06,694 INFO:     Epoch: 7
2022-11-28 00:45:07,438 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42418992485512386, 'Total loss': 0.42418992485512386} | train loss {'Reaction outcome loss': 0.38369995765840476, 'Total loss': 0.38369995765840476}
2022-11-28 00:45:07,438 INFO:     Found new best model at epoch 7
2022-11-28 00:45:07,439 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:07,439 INFO:     Epoch: 8
2022-11-28 00:45:08,188 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42335895144126634, 'Total loss': 0.42335895144126634} | train loss {'Reaction outcome loss': 0.38886608901294134, 'Total loss': 0.38886608901294134}
2022-11-28 00:45:08,188 INFO:     Found new best model at epoch 8
2022-11-28 00:45:08,189 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:08,189 INFO:     Epoch: 9
2022-11-28 00:45:08,935 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4619253304871646, 'Total loss': 0.4619253304871646} | train loss {'Reaction outcome loss': 0.3928177100323472, 'Total loss': 0.3928177100323472}
2022-11-28 00:45:08,935 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:08,936 INFO:     Epoch: 10
2022-11-28 00:45:09,677 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45986393839120865, 'Total loss': 0.45986393839120865} | train loss {'Reaction outcome loss': 0.38545847455650445, 'Total loss': 0.38545847455650445}
2022-11-28 00:45:09,677 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:09,677 INFO:     Epoch: 11
2022-11-28 00:45:10,416 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4650626548311927, 'Total loss': 0.4650626548311927} | train loss {'Reaction outcome loss': 0.36129076597902937, 'Total loss': 0.36129076597902937}
2022-11-28 00:45:10,416 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:10,416 INFO:     Epoch: 12
2022-11-28 00:45:11,157 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46512751772322436, 'Total loss': 0.46512751772322436} | train loss {'Reaction outcome loss': 0.3661522231845238, 'Total loss': 0.3661522231845238}
2022-11-28 00:45:11,158 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:11,158 INFO:     Epoch: 13
2022-11-28 00:45:11,900 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4417415312068029, 'Total loss': 0.4417415312068029} | train loss {'Reaction outcome loss': 0.3672347341170195, 'Total loss': 0.3672347341170195}
2022-11-28 00:45:11,900 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:11,900 INFO:     Epoch: 14
2022-11-28 00:45:12,640 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47542266615412454, 'Total loss': 0.47542266615412454} | train loss {'Reaction outcome loss': 0.3747788227883428, 'Total loss': 0.3747788227883428}
2022-11-28 00:45:12,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:12,640 INFO:     Epoch: 15
2022-11-28 00:45:13,381 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45209188522263005, 'Total loss': 0.45209188522263005} | train loss {'Reaction outcome loss': 0.3961999948449463, 'Total loss': 0.3961999948449463}
2022-11-28 00:45:13,381 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:13,381 INFO:     Epoch: 16
2022-11-28 00:45:14,120 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4465565048158169, 'Total loss': 0.4465565048158169} | train loss {'Reaction outcome loss': 0.3755739171223843, 'Total loss': 0.3755739171223843}
2022-11-28 00:45:14,120 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:14,120 INFO:     Epoch: 17
2022-11-28 00:45:14,859 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41900117763064126, 'Total loss': 0.41900117763064126} | train loss {'Reaction outcome loss': 0.3639435731930289, 'Total loss': 0.3639435731930289}
2022-11-28 00:45:14,859 INFO:     Found new best model at epoch 17
2022-11-28 00:45:14,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:14,860 INFO:     Epoch: 18
2022-11-28 00:45:15,599 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42452756010673265, 'Total loss': 0.42452756010673265} | train loss {'Reaction outcome loss': 0.34987156745517695, 'Total loss': 0.34987156745517695}
2022-11-28 00:45:15,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:15,599 INFO:     Epoch: 19
2022-11-28 00:45:16,344 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4484398178756237, 'Total loss': 0.4484398178756237} | train loss {'Reaction outcome loss': 0.3496875353308342, 'Total loss': 0.3496875353308342}
2022-11-28 00:45:16,344 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:16,344 INFO:     Epoch: 20
2022-11-28 00:45:17,084 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4270727012983777, 'Total loss': 0.4270727012983777} | train loss {'Reaction outcome loss': 0.34543604667294725, 'Total loss': 0.34543604667294725}
2022-11-28 00:45:17,084 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:17,085 INFO:     Epoch: 21
2022-11-28 00:45:17,823 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43349016694860026, 'Total loss': 0.43349016694860026} | train loss {'Reaction outcome loss': 0.34757959384184617, 'Total loss': 0.34757959384184617}
2022-11-28 00:45:17,824 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:17,824 INFO:     Epoch: 22
2022-11-28 00:45:18,569 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44357177682898263, 'Total loss': 0.44357177682898263} | train loss {'Reaction outcome loss': 0.3493388983825653, 'Total loss': 0.3493388983825653}
2022-11-28 00:45:18,569 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:18,569 INFO:     Epoch: 23
2022-11-28 00:45:19,311 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.431532007726756, 'Total loss': 0.431532007726756} | train loss {'Reaction outcome loss': 0.343839545947969, 'Total loss': 0.343839545947969}
2022-11-28 00:45:19,311 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:19,311 INFO:     Epoch: 24
2022-11-28 00:45:20,050 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41743534261530096, 'Total loss': 0.41743534261530096} | train loss {'Reaction outcome loss': 0.3376762622341453, 'Total loss': 0.3376762622341453}
2022-11-28 00:45:20,050 INFO:     Found new best model at epoch 24
2022-11-28 00:45:20,051 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:20,051 INFO:     Epoch: 25
2022-11-28 00:45:20,790 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4131624380295927, 'Total loss': 0.4131624380295927} | train loss {'Reaction outcome loss': 0.34137591238318366, 'Total loss': 0.34137591238318366}
2022-11-28 00:45:20,790 INFO:     Found new best model at epoch 25
2022-11-28 00:45:20,791 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:20,791 INFO:     Epoch: 26
2022-11-28 00:45:21,528 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4394104555249214, 'Total loss': 0.4394104555249214} | train loss {'Reaction outcome loss': 0.33137521027070793, 'Total loss': 0.33137521027070793}
2022-11-28 00:45:21,529 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:21,529 INFO:     Epoch: 27
2022-11-28 00:45:22,266 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4767188917506825, 'Total loss': 0.4767188917506825} | train loss {'Reaction outcome loss': 0.3301654575385063, 'Total loss': 0.3301654575385063}
2022-11-28 00:45:22,266 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:22,267 INFO:     Epoch: 28
2022-11-28 00:45:23,010 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4205295937982472, 'Total loss': 0.4205295937982472} | train loss {'Reaction outcome loss': 0.3367477500074079, 'Total loss': 0.3367477500074079}
2022-11-28 00:45:23,010 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:23,010 INFO:     Epoch: 29
2022-11-28 00:45:23,758 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45289222557436337, 'Total loss': 0.45289222557436337} | train loss {'Reaction outcome loss': 0.33396758169297747, 'Total loss': 0.33396758169297747}
2022-11-28 00:45:23,759 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:23,759 INFO:     Epoch: 30
2022-11-28 00:45:24,509 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4475623504682021, 'Total loss': 0.4475623504682021} | train loss {'Reaction outcome loss': 0.35485322147547477, 'Total loss': 0.35485322147547477}
2022-11-28 00:45:24,509 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:24,509 INFO:     Epoch: 31
2022-11-28 00:45:25,258 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42451401528987015, 'Total loss': 0.42451401528987015} | train loss {'Reaction outcome loss': 0.3424863422719332, 'Total loss': 0.3424863422719332}
2022-11-28 00:45:25,258 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:25,259 INFO:     Epoch: 32
2022-11-28 00:45:26,010 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.444012887775898, 'Total loss': 0.444012887775898} | train loss {'Reaction outcome loss': 0.3305859722890835, 'Total loss': 0.3305859722890835}
2022-11-28 00:45:26,010 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:26,010 INFO:     Epoch: 33
2022-11-28 00:45:26,771 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43500361489978706, 'Total loss': 0.43500361489978706} | train loss {'Reaction outcome loss': 0.3320338696133919, 'Total loss': 0.3320338696133919}
2022-11-28 00:45:26,771 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:26,771 INFO:     Epoch: 34
2022-11-28 00:45:27,523 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45283086208457296, 'Total loss': 0.45283086208457296} | train loss {'Reaction outcome loss': 0.32109319301028, 'Total loss': 0.32109319301028}
2022-11-28 00:45:27,523 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:27,523 INFO:     Epoch: 35
2022-11-28 00:45:28,278 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4321567602455616, 'Total loss': 0.4321567602455616} | train loss {'Reaction outcome loss': 0.32763440881361844, 'Total loss': 0.32763440881361844}
2022-11-28 00:45:28,278 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:28,278 INFO:     Epoch: 36
2022-11-28 00:45:29,030 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4455582777207548, 'Total loss': 0.4455582777207548} | train loss {'Reaction outcome loss': 0.326289378408237, 'Total loss': 0.326289378408237}
2022-11-28 00:45:29,030 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:29,030 INFO:     Epoch: 37
2022-11-28 00:45:29,776 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4168283830989491, 'Total loss': 0.4168283830989491} | train loss {'Reaction outcome loss': 0.34333420858571406, 'Total loss': 0.34333420858571406}
2022-11-28 00:45:29,777 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:29,777 INFO:     Epoch: 38
2022-11-28 00:45:30,525 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5330605036155744, 'Total loss': 0.5330605036155744} | train loss {'Reaction outcome loss': 0.3311539907988749, 'Total loss': 0.3311539907988749}
2022-11-28 00:45:30,525 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:30,525 INFO:     Epoch: 39
2022-11-28 00:45:31,278 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4113438278436661, 'Total loss': 0.4113438278436661} | train loss {'Reaction outcome loss': 0.33597957356437014, 'Total loss': 0.33597957356437014}
2022-11-28 00:45:31,278 INFO:     Found new best model at epoch 39
2022-11-28 00:45:31,279 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:31,279 INFO:     Epoch: 40
2022-11-28 00:45:32,027 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4235181144692681, 'Total loss': 0.4235181144692681} | train loss {'Reaction outcome loss': 0.3290778418723871, 'Total loss': 0.3290778418723871}
2022-11-28 00:45:32,027 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:32,027 INFO:     Epoch: 41
2022-11-28 00:45:32,776 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4670396084812554, 'Total loss': 0.4670396084812554} | train loss {'Reaction outcome loss': 0.32525570844469764, 'Total loss': 0.32525570844469764}
2022-11-28 00:45:32,777 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:32,777 INFO:     Epoch: 42
2022-11-28 00:45:33,527 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4263946210796183, 'Total loss': 0.4263946210796183} | train loss {'Reaction outcome loss': 0.3243688038787861, 'Total loss': 0.3243688038787861}
2022-11-28 00:45:33,527 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:33,527 INFO:     Epoch: 43
2022-11-28 00:45:34,278 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43963080712340097, 'Total loss': 0.43963080712340097} | train loss {'Reaction outcome loss': 0.3423432212790497, 'Total loss': 0.3423432212790497}
2022-11-28 00:45:34,279 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:34,279 INFO:     Epoch: 44
2022-11-28 00:45:35,027 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41516273333267734, 'Total loss': 0.41516273333267734} | train loss {'Reaction outcome loss': 0.3238964943820422, 'Total loss': 0.3238964943820422}
2022-11-28 00:45:35,027 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:35,027 INFO:     Epoch: 45
2022-11-28 00:45:35,776 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4365209601819515, 'Total loss': 0.4365209601819515} | train loss {'Reaction outcome loss': 0.3267215150087951, 'Total loss': 0.3267215150087951}
2022-11-28 00:45:35,777 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:35,777 INFO:     Epoch: 46
2022-11-28 00:45:36,521 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4082026678052815, 'Total loss': 0.4082026678052815} | train loss {'Reaction outcome loss': 0.34956819389104044, 'Total loss': 0.34956819389104044}
2022-11-28 00:45:36,522 INFO:     Found new best model at epoch 46
2022-11-28 00:45:36,522 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:36,522 INFO:     Epoch: 47
2022-11-28 00:45:37,267 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3993095293302428, 'Total loss': 0.3993095293302428} | train loss {'Reaction outcome loss': 0.3185710866562268, 'Total loss': 0.3185710866562268}
2022-11-28 00:45:37,267 INFO:     Found new best model at epoch 47
2022-11-28 00:45:37,268 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:37,268 INFO:     Epoch: 48
2022-11-28 00:45:38,016 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41393569721416995, 'Total loss': 0.41393569721416995} | train loss {'Reaction outcome loss': 0.3177131930524521, 'Total loss': 0.3177131930524521}
2022-11-28 00:45:38,016 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:38,016 INFO:     Epoch: 49
2022-11-28 00:45:38,766 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4015882465649735, 'Total loss': 0.4015882465649735} | train loss {'Reaction outcome loss': 0.3298389692809659, 'Total loss': 0.3298389692809659}
2022-11-28 00:45:38,767 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:38,767 INFO:     Epoch: 50
2022-11-28 00:45:39,515 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41737767918543384, 'Total loss': 0.41737767918543384} | train loss {'Reaction outcome loss': 0.31658637372275855, 'Total loss': 0.31658637372275855}
2022-11-28 00:45:39,515 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:39,515 INFO:     Epoch: 51
2022-11-28 00:45:40,262 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.469150534407659, 'Total loss': 0.469150534407659} | train loss {'Reaction outcome loss': 0.31429628041471064, 'Total loss': 0.31429628041471064}
2022-11-28 00:45:40,262 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:40,262 INFO:     Epoch: 52
2022-11-28 00:45:41,011 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4275983504273675, 'Total loss': 0.4275983504273675} | train loss {'Reaction outcome loss': 0.3248492442523902, 'Total loss': 0.3248492442523902}
2022-11-28 00:45:41,011 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:41,011 INFO:     Epoch: 53
2022-11-28 00:45:41,760 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4237815023145892, 'Total loss': 0.4237815023145892} | train loss {'Reaction outcome loss': 0.32702330997598317, 'Total loss': 0.32702330997598317}
2022-11-28 00:45:41,760 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:41,760 INFO:     Epoch: 54
2022-11-28 00:45:42,504 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44015134329145605, 'Total loss': 0.44015134329145605} | train loss {'Reaction outcome loss': 0.3300149667299228, 'Total loss': 0.3300149667299228}
2022-11-28 00:45:42,505 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:42,505 INFO:     Epoch: 55
2022-11-28 00:45:43,252 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4297014874490825, 'Total loss': 0.4297014874490825} | train loss {'Reaction outcome loss': 0.3329884111749287, 'Total loss': 0.3329884111749287}
2022-11-28 00:45:43,252 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:43,252 INFO:     Epoch: 56
2022-11-28 00:45:43,996 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44397862594236026, 'Total loss': 0.44397862594236026} | train loss {'Reaction outcome loss': 0.32013995173247717, 'Total loss': 0.32013995173247717}
2022-11-28 00:45:43,996 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:43,996 INFO:     Epoch: 57
2022-11-28 00:45:44,744 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4080264202573083, 'Total loss': 0.4080264202573083} | train loss {'Reaction outcome loss': 0.3174238667054185, 'Total loss': 0.3174238667054185}
2022-11-28 00:45:44,744 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:44,744 INFO:     Epoch: 58
2022-11-28 00:45:45,486 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4175731607458808, 'Total loss': 0.4175731607458808} | train loss {'Reaction outcome loss': 0.3105278059930695, 'Total loss': 0.3105278059930695}
2022-11-28 00:45:45,486 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:45,486 INFO:     Epoch: 59
2022-11-28 00:45:46,234 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43791019781069324, 'Total loss': 0.43791019781069324} | train loss {'Reaction outcome loss': 0.31815132477626146, 'Total loss': 0.31815132477626146}
2022-11-28 00:45:46,235 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:46,235 INFO:     Epoch: 60
2022-11-28 00:45:46,978 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4633309455080466, 'Total loss': 0.4633309455080466} | train loss {'Reaction outcome loss': 0.32668969065312914, 'Total loss': 0.32668969065312914}
2022-11-28 00:45:46,978 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:46,978 INFO:     Epoch: 61
2022-11-28 00:45:47,724 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.439566700973294, 'Total loss': 0.439566700973294} | train loss {'Reaction outcome loss': 0.3102712303942997, 'Total loss': 0.3102712303942997}
2022-11-28 00:45:47,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:47,724 INFO:     Epoch: 62
2022-11-28 00:45:48,467 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40699259394949133, 'Total loss': 0.40699259394949133} | train loss {'Reaction outcome loss': 0.3203621903351444, 'Total loss': 0.3203621903351444}
2022-11-28 00:45:48,467 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:48,468 INFO:     Epoch: 63
2022-11-28 00:45:49,212 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43519001081585884, 'Total loss': 0.43519001081585884} | train loss {'Reaction outcome loss': 0.31581118190472546, 'Total loss': 0.31581118190472546}
2022-11-28 00:45:49,212 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:49,212 INFO:     Epoch: 64
2022-11-28 00:45:49,959 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42253062840212474, 'Total loss': 0.42253062840212474} | train loss {'Reaction outcome loss': 0.3127404047677723, 'Total loss': 0.3127404047677723}
2022-11-28 00:45:49,960 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:49,960 INFO:     Epoch: 65
2022-11-28 00:45:50,708 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4207057035104795, 'Total loss': 0.4207057035104795} | train loss {'Reaction outcome loss': 0.3075952859904602, 'Total loss': 0.3075952859904602}
2022-11-28 00:45:50,708 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:50,709 INFO:     Epoch: 66
2022-11-28 00:45:51,451 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4267905205488205, 'Total loss': 0.4267905205488205} | train loss {'Reaction outcome loss': 0.3093390414596871, 'Total loss': 0.3093390414596871}
2022-11-28 00:45:51,451 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:51,451 INFO:     Epoch: 67
2022-11-28 00:45:52,199 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45702874626625667, 'Total loss': 0.45702874626625667} | train loss {'Reaction outcome loss': 0.3146597109282548, 'Total loss': 0.3146597109282548}
2022-11-28 00:45:52,199 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:52,199 INFO:     Epoch: 68
2022-11-28 00:45:52,943 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4209451937878674, 'Total loss': 0.4209451937878674} | train loss {'Reaction outcome loss': 0.31697592072882635, 'Total loss': 0.31697592072882635}
2022-11-28 00:45:52,943 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:52,944 INFO:     Epoch: 69
2022-11-28 00:45:53,691 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4087844773788344, 'Total loss': 0.4087844773788344} | train loss {'Reaction outcome loss': 0.31703985657030154, 'Total loss': 0.31703985657030154}
2022-11-28 00:45:53,691 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:53,692 INFO:     Epoch: 70
2022-11-28 00:45:54,435 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4240306524390524, 'Total loss': 0.4240306524390524} | train loss {'Reaction outcome loss': 0.315844424351718, 'Total loss': 0.315844424351718}
2022-11-28 00:45:54,435 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:54,435 INFO:     Epoch: 71
2022-11-28 00:45:55,178 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4630308855663646, 'Total loss': 0.4630308855663646} | train loss {'Reaction outcome loss': 0.3186124692018698, 'Total loss': 0.3186124692018698}
2022-11-28 00:45:55,179 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:55,179 INFO:     Epoch: 72
2022-11-28 00:45:55,923 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3972583308138631, 'Total loss': 0.3972583308138631} | train loss {'Reaction outcome loss': 0.3309793265362983, 'Total loss': 0.3309793265362983}
2022-11-28 00:45:55,923 INFO:     Found new best model at epoch 72
2022-11-28 00:45:55,924 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:55,924 INFO:     Epoch: 73
2022-11-28 00:45:56,669 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41274207322434947, 'Total loss': 0.41274207322434947} | train loss {'Reaction outcome loss': 0.31834871747233123, 'Total loss': 0.31834871747233123}
2022-11-28 00:45:56,669 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:56,669 INFO:     Epoch: 74
2022-11-28 00:45:57,417 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4255166683684696, 'Total loss': 0.4255166683684696} | train loss {'Reaction outcome loss': 0.31516861487255404, 'Total loss': 0.31516861487255404}
2022-11-28 00:45:57,417 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:57,417 INFO:     Epoch: 75
2022-11-28 00:45:58,164 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43375560675155034, 'Total loss': 0.43375560675155034} | train loss {'Reaction outcome loss': 0.3210128334989283, 'Total loss': 0.3210128334989283}
2022-11-28 00:45:58,165 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:58,165 INFO:     Epoch: 76
2022-11-28 00:45:58,913 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47368956526572054, 'Total loss': 0.47368956526572054} | train loss {'Reaction outcome loss': 0.3153830268665364, 'Total loss': 0.3153830268665364}
2022-11-28 00:45:58,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:58,914 INFO:     Epoch: 77
2022-11-28 00:45:59,659 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4456702670590444, 'Total loss': 0.4456702670590444} | train loss {'Reaction outcome loss': 0.31727889545171367, 'Total loss': 0.31727889545171367}
2022-11-28 00:45:59,659 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:45:59,660 INFO:     Epoch: 78
2022-11-28 00:46:00,406 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4397318647666411, 'Total loss': 0.4397318647666411} | train loss {'Reaction outcome loss': 0.3212068360223461, 'Total loss': 0.3212068360223461}
2022-11-28 00:46:00,407 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:00,407 INFO:     Epoch: 79
2022-11-28 00:46:01,151 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4733718538826162, 'Total loss': 0.4733718538826162} | train loss {'Reaction outcome loss': 0.3119042960074749, 'Total loss': 0.3119042960074749}
2022-11-28 00:46:01,151 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:01,151 INFO:     Epoch: 80
2022-11-28 00:46:01,893 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44838501614603127, 'Total loss': 0.44838501614603127} | train loss {'Reaction outcome loss': 0.341292145432007, 'Total loss': 0.341292145432007}
2022-11-28 00:46:01,893 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:01,893 INFO:     Epoch: 81
2022-11-28 00:46:02,643 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4520170336419886, 'Total loss': 0.4520170336419886} | train loss {'Reaction outcome loss': 0.32419723184847155, 'Total loss': 0.32419723184847155}
2022-11-28 00:46:02,644 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:02,644 INFO:     Epoch: 82
2022-11-28 00:46:03,391 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4311233887618238, 'Total loss': 0.4311233887618238} | train loss {'Reaction outcome loss': 0.3152558250194378, 'Total loss': 0.3152558250194378}
2022-11-28 00:46:03,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:03,392 INFO:     Epoch: 83
2022-11-28 00:46:04,133 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44011063111776655, 'Total loss': 0.44011063111776655} | train loss {'Reaction outcome loss': 0.31360495995413434, 'Total loss': 0.31360495995413434}
2022-11-28 00:46:04,133 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:04,133 INFO:     Epoch: 84
2022-11-28 00:46:04,876 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42074353755875066, 'Total loss': 0.42074353755875066} | train loss {'Reaction outcome loss': 0.32202391964402277, 'Total loss': 0.32202391964402277}
2022-11-28 00:46:04,876 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:04,876 INFO:     Epoch: 85
2022-11-28 00:46:05,620 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.422453459860249, 'Total loss': 0.422453459860249} | train loss {'Reaction outcome loss': 0.3124904133470659, 'Total loss': 0.3124904133470659}
2022-11-28 00:46:05,621 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:05,621 INFO:     Epoch: 86
2022-11-28 00:46:06,360 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4561516253108328, 'Total loss': 0.4561516253108328} | train loss {'Reaction outcome loss': 0.32046049104075924, 'Total loss': 0.32046049104075924}
2022-11-28 00:46:06,361 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:06,361 INFO:     Epoch: 87
2022-11-28 00:46:07,107 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4398313950408589, 'Total loss': 0.4398313950408589} | train loss {'Reaction outcome loss': 0.3085595006613355, 'Total loss': 0.3085595006613355}
2022-11-28 00:46:07,108 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:07,108 INFO:     Epoch: 88
2022-11-28 00:46:07,856 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42127015204592183, 'Total loss': 0.42127015204592183} | train loss {'Reaction outcome loss': 0.3121465306789407, 'Total loss': 0.3121465306789407}
2022-11-28 00:46:07,856 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:07,856 INFO:     Epoch: 89
2022-11-28 00:46:08,599 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4541531584479592, 'Total loss': 0.4541531584479592} | train loss {'Reaction outcome loss': 0.3096017933491644, 'Total loss': 0.3096017933491644}
2022-11-28 00:46:08,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:08,599 INFO:     Epoch: 90
2022-11-28 00:46:09,345 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42876738106662576, 'Total loss': 0.42876738106662576} | train loss {'Reaction outcome loss': 0.31309119062988383, 'Total loss': 0.31309119062988383}
2022-11-28 00:46:09,345 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:09,345 INFO:     Epoch: 91
2022-11-28 00:46:10,092 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4149666069583459, 'Total loss': 0.4149666069583459} | train loss {'Reaction outcome loss': 0.31400190268903366, 'Total loss': 0.31400190268903366}
2022-11-28 00:46:10,092 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:10,093 INFO:     Epoch: 92
2022-11-28 00:46:10,839 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4051342760636048, 'Total loss': 0.4051342760636048} | train loss {'Reaction outcome loss': 0.3067256113597256, 'Total loss': 0.3067256113597256}
2022-11-28 00:46:10,839 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:10,839 INFO:     Epoch: 93
2022-11-28 00:46:11,585 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4393635934049433, 'Total loss': 0.4393635934049433} | train loss {'Reaction outcome loss': 0.30600110621513, 'Total loss': 0.30600110621513}
2022-11-28 00:46:11,585 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:11,585 INFO:     Epoch: 94
2022-11-28 00:46:12,329 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4236425151201812, 'Total loss': 0.4236425151201812} | train loss {'Reaction outcome loss': 0.3073258648517161, 'Total loss': 0.3073258648517161}
2022-11-28 00:46:12,329 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:12,329 INFO:     Epoch: 95
2022-11-28 00:46:13,080 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4184435081075538, 'Total loss': 0.4184435081075538} | train loss {'Reaction outcome loss': 0.31712556153777155, 'Total loss': 0.31712556153777155}
2022-11-28 00:46:13,080 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:13,080 INFO:     Epoch: 96
2022-11-28 00:46:13,825 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45925829593430867, 'Total loss': 0.45925829593430867} | train loss {'Reaction outcome loss': 0.3120093049428724, 'Total loss': 0.3120093049428724}
2022-11-28 00:46:13,826 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:13,826 INFO:     Epoch: 97
2022-11-28 00:46:14,569 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44159636307846417, 'Total loss': 0.44159636307846417} | train loss {'Reaction outcome loss': 0.3128832329803633, 'Total loss': 0.3128832329803633}
2022-11-28 00:46:14,569 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:14,569 INFO:     Epoch: 98
2022-11-28 00:46:15,318 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4621476578441533, 'Total loss': 0.4621476578441533} | train loss {'Reaction outcome loss': 0.3214967274050481, 'Total loss': 0.3214967274050481}
2022-11-28 00:46:15,318 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:15,319 INFO:     Epoch: 99
2022-11-28 00:46:16,060 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4284177500415932, 'Total loss': 0.4284177500415932} | train loss {'Reaction outcome loss': 0.30626840164002617, 'Total loss': 0.30626840164002617}
2022-11-28 00:46:16,061 INFO:     Best model found after epoch 73 of 100.
2022-11-28 00:46:16,061 INFO:   Done with stage: TRAINING
2022-11-28 00:46:16,061 INFO:   Starting stage: EVALUATION
2022-11-28 00:46:16,183 INFO:   Done with stage: EVALUATION
2022-11-28 00:46:16,183 INFO:   Leaving out SEQ value Fold_6
2022-11-28 00:46:16,195 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 00:46:16,195 INFO:   Starting stage: FEATURE SCALING
2022-11-28 00:46:16,840 INFO:   Done with stage: FEATURE SCALING
2022-11-28 00:46:16,840 INFO:   Starting stage: SCALING TARGETS
2022-11-28 00:46:16,912 INFO:   Done with stage: SCALING TARGETS
2022-11-28 00:46:16,912 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:46:16,912 INFO:     No hyperparam tuning for this model
2022-11-28 00:46:16,912 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:46:16,912 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 00:46:16,913 INFO:     None feature selector for col prot
2022-11-28 00:46:16,913 INFO:     None feature selector for col prot
2022-11-28 00:46:16,913 INFO:     None feature selector for col prot
2022-11-28 00:46:16,913 INFO:     None feature selector for col chem
2022-11-28 00:46:16,914 INFO:     None feature selector for col chem
2022-11-28 00:46:16,914 INFO:     None feature selector for col chem
2022-11-28 00:46:16,914 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 00:46:16,914 INFO:   Starting stage: BUILD MODEL
2022-11-28 00:46:16,915 INFO:     Number of params in model 169741
2022-11-28 00:46:16,918 INFO:   Done with stage: BUILD MODEL
2022-11-28 00:46:16,918 INFO:   Starting stage: TRAINING
2022-11-28 00:46:16,972 INFO:     Val loss before train {'Reaction outcome loss': 1.002237863161347, 'Total loss': 1.002237863161347}
2022-11-28 00:46:16,972 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:16,973 INFO:     Epoch: 0
2022-11-28 00:46:17,722 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5608381608670409, 'Total loss': 0.5608381608670409} | train loss {'Reaction outcome loss': 0.6429097463166521, 'Total loss': 0.6429097463166521}
2022-11-28 00:46:17,722 INFO:     Found new best model at epoch 0
2022-11-28 00:46:17,723 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:17,723 INFO:     Epoch: 1
2022-11-28 00:46:18,471 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5184423693201758, 'Total loss': 0.5184423693201758} | train loss {'Reaction outcome loss': 0.49863226243084474, 'Total loss': 0.49863226243084474}
2022-11-28 00:46:18,471 INFO:     Found new best model at epoch 1
2022-11-28 00:46:18,472 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:18,472 INFO:     Epoch: 2
2022-11-28 00:46:19,218 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49217546290972014, 'Total loss': 0.49217546290972014} | train loss {'Reaction outcome loss': 0.4535108832342009, 'Total loss': 0.4535108832342009}
2022-11-28 00:46:19,218 INFO:     Found new best model at epoch 2
2022-11-28 00:46:19,219 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:19,219 INFO:     Epoch: 3
2022-11-28 00:46:19,970 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48352929238568654, 'Total loss': 0.48352929238568654} | train loss {'Reaction outcome loss': 0.43743649407500224, 'Total loss': 0.43743649407500224}
2022-11-28 00:46:19,970 INFO:     Found new best model at epoch 3
2022-11-28 00:46:19,970 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:19,971 INFO:     Epoch: 4
2022-11-28 00:46:20,720 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4613546884872697, 'Total loss': 0.4613546884872697} | train loss {'Reaction outcome loss': 0.4183990654325293, 'Total loss': 0.4183990654325293}
2022-11-28 00:46:20,720 INFO:     Found new best model at epoch 4
2022-11-28 00:46:20,721 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:20,721 INFO:     Epoch: 5
2022-11-28 00:46:21,470 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49287020178003743, 'Total loss': 0.49287020178003743} | train loss {'Reaction outcome loss': 0.4080407627888264, 'Total loss': 0.4080407627888264}
2022-11-28 00:46:21,471 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:21,471 INFO:     Epoch: 6
2022-11-28 00:46:22,216 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45377997952428734, 'Total loss': 0.45377997952428734} | train loss {'Reaction outcome loss': 0.3965607379833537, 'Total loss': 0.3965607379833537}
2022-11-28 00:46:22,216 INFO:     Found new best model at epoch 6
2022-11-28 00:46:22,217 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:22,217 INFO:     Epoch: 7
2022-11-28 00:46:22,963 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46346425874666736, 'Total loss': 0.46346425874666736} | train loss {'Reaction outcome loss': 0.39440632335120634, 'Total loss': 0.39440632335120634}
2022-11-28 00:46:22,963 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:22,963 INFO:     Epoch: 8
2022-11-28 00:46:23,711 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4610232734544711, 'Total loss': 0.4610232734544711} | train loss {'Reaction outcome loss': 0.37914863210772315, 'Total loss': 0.37914863210772315}
2022-11-28 00:46:23,711 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:23,711 INFO:     Epoch: 9
2022-11-28 00:46:24,456 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45363073152574623, 'Total loss': 0.45363073152574623} | train loss {'Reaction outcome loss': 0.3774961682577287, 'Total loss': 0.3774961682577287}
2022-11-28 00:46:24,456 INFO:     Found new best model at epoch 9
2022-11-28 00:46:24,457 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:24,457 INFO:     Epoch: 10
2022-11-28 00:46:25,204 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4566379457034848, 'Total loss': 0.4566379457034848} | train loss {'Reaction outcome loss': 0.3827924475734753, 'Total loss': 0.3827924475734753}
2022-11-28 00:46:25,204 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:25,204 INFO:     Epoch: 11
2022-11-28 00:46:25,956 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4818013141101057, 'Total loss': 0.4818013141101057} | train loss {'Reaction outcome loss': 0.3610214998404826, 'Total loss': 0.3610214998404826}
2022-11-28 00:46:25,957 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:25,957 INFO:     Epoch: 12
2022-11-28 00:46:26,705 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.469167250123891, 'Total loss': 0.469167250123891} | train loss {'Reaction outcome loss': 0.3671080368390727, 'Total loss': 0.3671080368390727}
2022-11-28 00:46:26,705 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:26,706 INFO:     Epoch: 13
2022-11-28 00:46:27,455 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.446728895672343, 'Total loss': 0.446728895672343} | train loss {'Reaction outcome loss': 0.37282374624403253, 'Total loss': 0.37282374624403253}
2022-11-28 00:46:27,455 INFO:     Found new best model at epoch 13
2022-11-28 00:46:27,455 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:27,456 INFO:     Epoch: 14
2022-11-28 00:46:28,201 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4391812299462882, 'Total loss': 0.4391812299462882} | train loss {'Reaction outcome loss': 0.3523404245535212, 'Total loss': 0.3523404245535212}
2022-11-28 00:46:28,201 INFO:     Found new best model at epoch 14
2022-11-28 00:46:28,201 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:28,202 INFO:     Epoch: 15
2022-11-28 00:46:28,946 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44750147770074283, 'Total loss': 0.44750147770074283} | train loss {'Reaction outcome loss': 0.36255146693738716, 'Total loss': 0.36255146693738716}
2022-11-28 00:46:28,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:28,946 INFO:     Epoch: 16
2022-11-28 00:46:29,687 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44819332930174743, 'Total loss': 0.44819332930174743} | train loss {'Reaction outcome loss': 0.3522957592241226, 'Total loss': 0.3522957592241226}
2022-11-28 00:46:29,687 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:29,687 INFO:     Epoch: 17
2022-11-28 00:46:30,435 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4407594351267273, 'Total loss': 0.4407594351267273} | train loss {'Reaction outcome loss': 0.36072287627405697, 'Total loss': 0.36072287627405697}
2022-11-28 00:46:30,435 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:30,435 INFO:     Epoch: 18
2022-11-28 00:46:31,181 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4136649586937644, 'Total loss': 0.4136649586937644} | train loss {'Reaction outcome loss': 0.3427167189337553, 'Total loss': 0.3427167189337553}
2022-11-28 00:46:31,181 INFO:     Found new best model at epoch 18
2022-11-28 00:46:31,182 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:31,182 INFO:     Epoch: 19
2022-11-28 00:46:31,926 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44580569287592714, 'Total loss': 0.44580569287592714} | train loss {'Reaction outcome loss': 0.3467853166343224, 'Total loss': 0.3467853166343224}
2022-11-28 00:46:31,927 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:31,927 INFO:     Epoch: 20
2022-11-28 00:46:32,673 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44534645873037254, 'Total loss': 0.44534645873037254} | train loss {'Reaction outcome loss': 0.3434989359380016, 'Total loss': 0.3434989359380016}
2022-11-28 00:46:32,674 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:32,674 INFO:     Epoch: 21
2022-11-28 00:46:33,422 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4378364692357453, 'Total loss': 0.4378364692357453} | train loss {'Reaction outcome loss': 0.341029868791661, 'Total loss': 0.341029868791661}
2022-11-28 00:46:33,422 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:33,422 INFO:     Epoch: 22
2022-11-28 00:46:34,166 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4276361438361081, 'Total loss': 0.4276361438361081} | train loss {'Reaction outcome loss': 0.34546355095000997, 'Total loss': 0.34546355095000997}
2022-11-28 00:46:34,166 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:34,167 INFO:     Epoch: 23
2022-11-28 00:46:34,913 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4576448767699979, 'Total loss': 0.4576448767699979} | train loss {'Reaction outcome loss': 0.32655710784057457, 'Total loss': 0.32655710784057457}
2022-11-28 00:46:34,913 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:34,914 INFO:     Epoch: 24
2022-11-28 00:46:35,659 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47473366863348265, 'Total loss': 0.47473366863348265} | train loss {'Reaction outcome loss': 0.34168432679988686, 'Total loss': 0.34168432679988686}
2022-11-28 00:46:35,659 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:35,659 INFO:     Epoch: 25
2022-11-28 00:46:36,402 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43988619931042194, 'Total loss': 0.43988619931042194} | train loss {'Reaction outcome loss': 0.3455567736959746, 'Total loss': 0.3455567736959746}
2022-11-28 00:46:36,402 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:36,402 INFO:     Epoch: 26
2022-11-28 00:46:37,147 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40924186259508133, 'Total loss': 0.40924186259508133} | train loss {'Reaction outcome loss': 0.32938656514330256, 'Total loss': 0.32938656514330256}
2022-11-28 00:46:37,147 INFO:     Found new best model at epoch 26
2022-11-28 00:46:37,148 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:37,148 INFO:     Epoch: 27
2022-11-28 00:46:37,894 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43558563088828867, 'Total loss': 0.43558563088828867} | train loss {'Reaction outcome loss': 0.33390424169239497, 'Total loss': 0.33390424169239497}
2022-11-28 00:46:37,895 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:37,895 INFO:     Epoch: 28
2022-11-28 00:46:38,641 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4298731181770563, 'Total loss': 0.4298731181770563} | train loss {'Reaction outcome loss': 0.3310442177218295, 'Total loss': 0.3310442177218295}
2022-11-28 00:46:38,642 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:38,642 INFO:     Epoch: 29
2022-11-28 00:46:39,389 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44184685024348175, 'Total loss': 0.44184685024348175} | train loss {'Reaction outcome loss': 0.33824930638976153, 'Total loss': 0.33824930638976153}
2022-11-28 00:46:39,389 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:39,389 INFO:     Epoch: 30
2022-11-28 00:46:40,135 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4189730579541488, 'Total loss': 0.4189730579541488} | train loss {'Reaction outcome loss': 0.3325848332512373, 'Total loss': 0.3325848332512373}
2022-11-28 00:46:40,135 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:40,135 INFO:     Epoch: 31
2022-11-28 00:46:40,882 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4272528453306718, 'Total loss': 0.4272528453306718} | train loss {'Reaction outcome loss': 0.33906649086143703, 'Total loss': 0.33906649086143703}
2022-11-28 00:46:40,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:40,882 INFO:     Epoch: 32
2022-11-28 00:46:41,625 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4191026691008698, 'Total loss': 0.4191026691008698} | train loss {'Reaction outcome loss': 0.3276516612649204, 'Total loss': 0.3276516612649204}
2022-11-28 00:46:41,625 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:41,626 INFO:     Epoch: 33
2022-11-28 00:46:42,371 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43940170617266133, 'Total loss': 0.43940170617266133} | train loss {'Reaction outcome loss': 0.3292864721058117, 'Total loss': 0.3292864721058117}
2022-11-28 00:46:42,372 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:42,372 INFO:     Epoch: 34
2022-11-28 00:46:43,114 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4221104478294199, 'Total loss': 0.4221104478294199} | train loss {'Reaction outcome loss': 0.3294200601747199, 'Total loss': 0.3294200601747199}
2022-11-28 00:46:43,114 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:43,114 INFO:     Epoch: 35
2022-11-28 00:46:43,859 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42444904724305327, 'Total loss': 0.42444904724305327} | train loss {'Reaction outcome loss': 0.32643602118496934, 'Total loss': 0.32643602118496934}
2022-11-28 00:46:43,859 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:43,859 INFO:     Epoch: 36
2022-11-28 00:46:44,602 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43173977021466603, 'Total loss': 0.43173977021466603} | train loss {'Reaction outcome loss': 0.32440949778162664, 'Total loss': 0.32440949778162664}
2022-11-28 00:46:44,603 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:44,603 INFO:     Epoch: 37
2022-11-28 00:46:45,344 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4567467814142054, 'Total loss': 0.4567467814142054} | train loss {'Reaction outcome loss': 0.3345406602377132, 'Total loss': 0.3345406602377132}
2022-11-28 00:46:45,345 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:45,345 INFO:     Epoch: 38
2022-11-28 00:46:46,091 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43606040931560774, 'Total loss': 0.43606040931560774} | train loss {'Reaction outcome loss': 0.32638670822545407, 'Total loss': 0.32638670822545407}
2022-11-28 00:46:46,091 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:46,091 INFO:     Epoch: 39
2022-11-28 00:46:46,837 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40995696491815825, 'Total loss': 0.40995696491815825} | train loss {'Reaction outcome loss': 0.31950629141271836, 'Total loss': 0.31950629141271836}
2022-11-28 00:46:46,837 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:46,837 INFO:     Epoch: 40
2022-11-28 00:46:47,583 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4408982096409256, 'Total loss': 0.4408982096409256} | train loss {'Reaction outcome loss': 0.32758273995451387, 'Total loss': 0.32758273995451387}
2022-11-28 00:46:47,583 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:47,583 INFO:     Epoch: 41
2022-11-28 00:46:48,328 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44526404582641343, 'Total loss': 0.44526404582641343} | train loss {'Reaction outcome loss': 0.32672177274681385, 'Total loss': 0.32672177274681385}
2022-11-28 00:46:48,328 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:48,328 INFO:     Epoch: 42
2022-11-28 00:46:49,081 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4271450269628655, 'Total loss': 0.4271450269628655} | train loss {'Reaction outcome loss': 0.3245580875044388, 'Total loss': 0.3245580875044388}
2022-11-28 00:46:49,081 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:49,081 INFO:     Epoch: 43
2022-11-28 00:46:49,833 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4167770756916566, 'Total loss': 0.4167770756916566} | train loss {'Reaction outcome loss': 0.31788359834782537, 'Total loss': 0.31788359834782537}
2022-11-28 00:46:49,833 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:49,833 INFO:     Epoch: 44
2022-11-28 00:46:50,586 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4107482142069123, 'Total loss': 0.4107482142069123} | train loss {'Reaction outcome loss': 0.32272331105665336, 'Total loss': 0.32272331105665336}
2022-11-28 00:46:50,586 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:50,586 INFO:     Epoch: 45
2022-11-28 00:46:51,333 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43200242570178077, 'Total loss': 0.43200242570178077} | train loss {'Reaction outcome loss': 0.32715166831809667, 'Total loss': 0.32715166831809667}
2022-11-28 00:46:51,333 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:51,333 INFO:     Epoch: 46
2022-11-28 00:46:52,086 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42197727784514427, 'Total loss': 0.42197727784514427} | train loss {'Reaction outcome loss': 0.320930487281012, 'Total loss': 0.320930487281012}
2022-11-28 00:46:52,086 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:52,086 INFO:     Epoch: 47
2022-11-28 00:46:52,834 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4292801307006316, 'Total loss': 0.4292801307006316} | train loss {'Reaction outcome loss': 0.32730409953623046, 'Total loss': 0.32730409953623046}
2022-11-28 00:46:52,834 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:52,834 INFO:     Epoch: 48
2022-11-28 00:46:53,581 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4715417670932683, 'Total loss': 0.4715417670932683} | train loss {'Reaction outcome loss': 0.3189640638208197, 'Total loss': 0.3189640638208197}
2022-11-28 00:46:53,582 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:53,582 INFO:     Epoch: 49
2022-11-28 00:46:54,331 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44233459200371394, 'Total loss': 0.44233459200371394} | train loss {'Reaction outcome loss': 0.32264336327751797, 'Total loss': 0.32264336327751797}
2022-11-28 00:46:54,331 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:54,331 INFO:     Epoch: 50
2022-11-28 00:46:55,078 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45373460379513825, 'Total loss': 0.45373460379513825} | train loss {'Reaction outcome loss': 0.3197794945069378, 'Total loss': 0.3197794945069378}
2022-11-28 00:46:55,078 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:55,078 INFO:     Epoch: 51
2022-11-28 00:46:55,824 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4244196411560882, 'Total loss': 0.4244196411560882} | train loss {'Reaction outcome loss': 0.31318106533839335, 'Total loss': 0.31318106533839335}
2022-11-28 00:46:55,824 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:55,824 INFO:     Epoch: 52
2022-11-28 00:46:56,574 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4218513789502057, 'Total loss': 0.4218513789502057} | train loss {'Reaction outcome loss': 0.31057595248304065, 'Total loss': 0.31057595248304065}
2022-11-28 00:46:56,574 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:56,574 INFO:     Epoch: 53
2022-11-28 00:46:57,324 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42479072883725166, 'Total loss': 0.42479072883725166} | train loss {'Reaction outcome loss': 0.3201253321021795, 'Total loss': 0.3201253321021795}
2022-11-28 00:46:57,324 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:57,325 INFO:     Epoch: 54
2022-11-28 00:46:58,074 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42744655026630923, 'Total loss': 0.42744655026630923} | train loss {'Reaction outcome loss': 0.314367163475723, 'Total loss': 0.314367163475723}
2022-11-28 00:46:58,074 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:58,074 INFO:     Epoch: 55
2022-11-28 00:46:58,822 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4162513989616524, 'Total loss': 0.4162513989616524} | train loss {'Reaction outcome loss': 0.31990630885646226, 'Total loss': 0.31990630885646226}
2022-11-28 00:46:58,822 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:58,822 INFO:     Epoch: 56
2022-11-28 00:46:59,568 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4465404193509709, 'Total loss': 0.4465404193509709} | train loss {'Reaction outcome loss': 0.31791386852461484, 'Total loss': 0.31791386852461484}
2022-11-28 00:46:59,568 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:46:59,568 INFO:     Epoch: 57
2022-11-28 00:47:00,318 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4257550486786799, 'Total loss': 0.4257550486786799} | train loss {'Reaction outcome loss': 0.3198804939391031, 'Total loss': 0.3198804939391031}
2022-11-28 00:47:00,318 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:00,318 INFO:     Epoch: 58
2022-11-28 00:47:01,068 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43011040138927376, 'Total loss': 0.43011040138927376} | train loss {'Reaction outcome loss': 0.30650235954371674, 'Total loss': 0.30650235954371674}
2022-11-28 00:47:01,068 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:01,069 INFO:     Epoch: 59
2022-11-28 00:47:01,816 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4186714139174331, 'Total loss': 0.4186714139174331} | train loss {'Reaction outcome loss': 0.3282198782769903, 'Total loss': 0.3282198782769903}
2022-11-28 00:47:01,816 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:01,816 INFO:     Epoch: 60
2022-11-28 00:47:02,566 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43348450687798584, 'Total loss': 0.43348450687798584} | train loss {'Reaction outcome loss': 0.3159970865855294, 'Total loss': 0.3159970865855294}
2022-11-28 00:47:02,566 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:02,566 INFO:     Epoch: 61
2022-11-28 00:47:03,313 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42261791483245115, 'Total loss': 0.42261791483245115} | train loss {'Reaction outcome loss': 0.32100032549351454, 'Total loss': 0.32100032549351454}
2022-11-28 00:47:03,313 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:03,313 INFO:     Epoch: 62
2022-11-28 00:47:04,063 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4517914920367978, 'Total loss': 0.4517914920367978} | train loss {'Reaction outcome loss': 0.3239213593544499, 'Total loss': 0.3239213593544499}
2022-11-28 00:47:04,063 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:04,063 INFO:     Epoch: 63
2022-11-28 00:47:04,817 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44192719865929, 'Total loss': 0.44192719865929} | train loss {'Reaction outcome loss': 0.30998012360425725, 'Total loss': 0.30998012360425725}
2022-11-28 00:47:04,817 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:04,817 INFO:     Epoch: 64
2022-11-28 00:47:05,565 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46644184636798774, 'Total loss': 0.46644184636798774} | train loss {'Reaction outcome loss': 0.3116815005158705, 'Total loss': 0.3116815005158705}
2022-11-28 00:47:05,565 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:05,565 INFO:     Epoch: 65
2022-11-28 00:47:06,312 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4355726594274694, 'Total loss': 0.4355726594274694} | train loss {'Reaction outcome loss': 0.318432355750232, 'Total loss': 0.318432355750232}
2022-11-28 00:47:06,312 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:06,312 INFO:     Epoch: 66
2022-11-28 00:47:07,059 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4447931864044883, 'Total loss': 0.4447931864044883} | train loss {'Reaction outcome loss': 0.31391706442340245, 'Total loss': 0.31391706442340245}
2022-11-28 00:47:07,059 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:07,059 INFO:     Epoch: 67
2022-11-28 00:47:07,804 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4401855959810994, 'Total loss': 0.4401855959810994} | train loss {'Reaction outcome loss': 0.31281082533420096, 'Total loss': 0.31281082533420096}
2022-11-28 00:47:07,804 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:07,804 INFO:     Epoch: 68
2022-11-28 00:47:08,558 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43570094724947755, 'Total loss': 0.43570094724947755} | train loss {'Reaction outcome loss': 0.31124939874655777, 'Total loss': 0.31124939874655777}
2022-11-28 00:47:08,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:08,558 INFO:     Epoch: 69
2022-11-28 00:47:09,311 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44609130859713664, 'Total loss': 0.44609130859713664} | train loss {'Reaction outcome loss': 0.3099269371690048, 'Total loss': 0.3099269371690048}
2022-11-28 00:47:09,312 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:09,313 INFO:     Epoch: 70
2022-11-28 00:47:10,065 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43516925688494335, 'Total loss': 0.43516925688494335} | train loss {'Reaction outcome loss': 0.3137454330740917, 'Total loss': 0.3137454330740917}
2022-11-28 00:47:10,065 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:10,065 INFO:     Epoch: 71
2022-11-28 00:47:10,816 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4573739022016525, 'Total loss': 0.4573739022016525} | train loss {'Reaction outcome loss': 0.30317152594967234, 'Total loss': 0.30317152594967234}
2022-11-28 00:47:10,816 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:10,816 INFO:     Epoch: 72
2022-11-28 00:47:11,565 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5156358070671558, 'Total loss': 0.5156358070671558} | train loss {'Reaction outcome loss': 0.306929231677655, 'Total loss': 0.306929231677655}
2022-11-28 00:47:11,565 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:11,566 INFO:     Epoch: 73
2022-11-28 00:47:12,319 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41121129590001976, 'Total loss': 0.41121129590001976} | train loss {'Reaction outcome loss': 0.30798856418339476, 'Total loss': 0.30798856418339476}
2022-11-28 00:47:12,320 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:12,320 INFO:     Epoch: 74
2022-11-28 00:47:13,071 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4106022170321508, 'Total loss': 0.4106022170321508} | train loss {'Reaction outcome loss': 0.31498604810105696, 'Total loss': 0.31498604810105696}
2022-11-28 00:47:13,071 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:13,071 INFO:     Epoch: 75
2022-11-28 00:47:13,824 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43173056468367577, 'Total loss': 0.43173056468367577} | train loss {'Reaction outcome loss': 0.31010616862124973, 'Total loss': 0.31010616862124973}
2022-11-28 00:47:13,824 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:13,824 INFO:     Epoch: 76
2022-11-28 00:47:14,576 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4512664645232938, 'Total loss': 0.4512664645232938} | train loss {'Reaction outcome loss': 0.31688135022658015, 'Total loss': 0.31688135022658015}
2022-11-28 00:47:14,576 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:14,576 INFO:     Epoch: 77
2022-11-28 00:47:15,329 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40583978974345053, 'Total loss': 0.40583978974345053} | train loss {'Reaction outcome loss': 0.31462780407239355, 'Total loss': 0.31462780407239355}
2022-11-28 00:47:15,329 INFO:     Found new best model at epoch 77
2022-11-28 00:47:15,330 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:15,330 INFO:     Epoch: 78
2022-11-28 00:47:16,083 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4386537549170581, 'Total loss': 0.4386537549170581} | train loss {'Reaction outcome loss': 0.31093816089654164, 'Total loss': 0.31093816089654164}
2022-11-28 00:47:16,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:16,083 INFO:     Epoch: 79
2022-11-28 00:47:16,832 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4576122425496578, 'Total loss': 0.4576122425496578} | train loss {'Reaction outcome loss': 0.3122338941771417, 'Total loss': 0.3122338941771417}
2022-11-28 00:47:16,832 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:16,832 INFO:     Epoch: 80
2022-11-28 00:47:17,584 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43146800859407947, 'Total loss': 0.43146800859407947} | train loss {'Reaction outcome loss': 0.3191344616333804, 'Total loss': 0.3191344616333804}
2022-11-28 00:47:17,584 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:17,584 INFO:     Epoch: 81
2022-11-28 00:47:18,333 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4559052156453783, 'Total loss': 0.4559052156453783} | train loss {'Reaction outcome loss': 0.3313248951528822, 'Total loss': 0.3313248951528822}
2022-11-28 00:47:18,333 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:18,333 INFO:     Epoch: 82
2022-11-28 00:47:19,087 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47021952813321893, 'Total loss': 0.47021952813321893} | train loss {'Reaction outcome loss': 0.3157278416047414, 'Total loss': 0.3157278416047414}
2022-11-28 00:47:19,087 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:19,087 INFO:     Epoch: 83
2022-11-28 00:47:19,835 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45557937754148786, 'Total loss': 0.45557937754148786} | train loss {'Reaction outcome loss': 0.31165930088008603, 'Total loss': 0.31165930088008603}
2022-11-28 00:47:19,836 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:19,836 INFO:     Epoch: 84
2022-11-28 00:47:20,584 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4384624045342207, 'Total loss': 0.4384624045342207} | train loss {'Reaction outcome loss': 0.3101288027190153, 'Total loss': 0.3101288027190153}
2022-11-28 00:47:20,585 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:20,585 INFO:     Epoch: 85
2022-11-28 00:47:21,335 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40104552426121454, 'Total loss': 0.40104552426121454} | train loss {'Reaction outcome loss': 0.3118724672634515, 'Total loss': 0.3118724672634515}
2022-11-28 00:47:21,335 INFO:     Found new best model at epoch 85
2022-11-28 00:47:21,336 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:21,336 INFO:     Epoch: 86
2022-11-28 00:47:22,083 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40635730360041966, 'Total loss': 0.40635730360041966} | train loss {'Reaction outcome loss': 0.3056562748557377, 'Total loss': 0.3056562748557377}
2022-11-28 00:47:22,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:22,083 INFO:     Epoch: 87
2022-11-28 00:47:22,832 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42726958983323793, 'Total loss': 0.42726958983323793} | train loss {'Reaction outcome loss': 0.30587155550658224, 'Total loss': 0.30587155550658224}
2022-11-28 00:47:22,833 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:22,833 INFO:     Epoch: 88
2022-11-28 00:47:23,584 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4383983833884651, 'Total loss': 0.4383983833884651} | train loss {'Reaction outcome loss': 0.30668117454455746, 'Total loss': 0.30668117454455746}
2022-11-28 00:47:23,584 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:23,584 INFO:     Epoch: 89
2022-11-28 00:47:24,337 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4349304833872752, 'Total loss': 0.4349304833872752} | train loss {'Reaction outcome loss': 0.308631467482736, 'Total loss': 0.308631467482736}
2022-11-28 00:47:24,337 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:24,337 INFO:     Epoch: 90
2022-11-28 00:47:25,085 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42409621822563087, 'Total loss': 0.42409621822563087} | train loss {'Reaction outcome loss': 0.30845700306517465, 'Total loss': 0.30845700306517465}
2022-11-28 00:47:25,085 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:25,085 INFO:     Epoch: 91
2022-11-28 00:47:25,828 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4428185522556305, 'Total loss': 0.4428185522556305} | train loss {'Reaction outcome loss': 0.3146997844920524, 'Total loss': 0.3146997844920524}
2022-11-28 00:47:25,828 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:25,828 INFO:     Epoch: 92
2022-11-28 00:47:26,574 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41628859395330603, 'Total loss': 0.41628859395330603} | train loss {'Reaction outcome loss': 0.3147175427556278, 'Total loss': 0.3147175427556278}
2022-11-28 00:47:26,574 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:26,574 INFO:     Epoch: 93
2022-11-28 00:47:27,318 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4448721253059127, 'Total loss': 0.4448721253059127} | train loss {'Reaction outcome loss': 0.3129548387782228, 'Total loss': 0.3129548387782228}
2022-11-28 00:47:27,318 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:27,318 INFO:     Epoch: 94
2022-11-28 00:47:28,062 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4404137527400797, 'Total loss': 0.4404137527400797} | train loss {'Reaction outcome loss': 0.30468563465101106, 'Total loss': 0.30468563465101106}
2022-11-28 00:47:28,063 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:28,063 INFO:     Epoch: 95
2022-11-28 00:47:28,807 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4674835923043164, 'Total loss': 0.4674835923043164} | train loss {'Reaction outcome loss': 0.30950404183879016, 'Total loss': 0.30950404183879016}
2022-11-28 00:47:28,807 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:28,807 INFO:     Epoch: 96
2022-11-28 00:47:29,554 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4400301372463053, 'Total loss': 0.4400301372463053} | train loss {'Reaction outcome loss': 0.32074007735918125, 'Total loss': 0.32074007735918125}
2022-11-28 00:47:29,554 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:29,554 INFO:     Epoch: 97
2022-11-28 00:47:30,303 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4290617975321683, 'Total loss': 0.4290617975321683} | train loss {'Reaction outcome loss': 0.30957748822026676, 'Total loss': 0.30957748822026676}
2022-11-28 00:47:30,303 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:30,303 INFO:     Epoch: 98
2022-11-28 00:47:31,047 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42337253892963583, 'Total loss': 0.42337253892963583} | train loss {'Reaction outcome loss': 0.3057466934344942, 'Total loss': 0.3057466934344942}
2022-11-28 00:47:31,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:31,048 INFO:     Epoch: 99
2022-11-28 00:47:31,796 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4278788383711468, 'Total loss': 0.4278788383711468} | train loss {'Reaction outcome loss': 0.31044664921899956, 'Total loss': 0.31044664921899956}
2022-11-28 00:47:31,797 INFO:     Best model found after epoch 86 of 100.
2022-11-28 00:47:31,797 INFO:   Done with stage: TRAINING
2022-11-28 00:47:31,797 INFO:   Starting stage: EVALUATION
2022-11-28 00:47:31,912 INFO:   Done with stage: EVALUATION
2022-11-28 00:47:31,912 INFO:   Leaving out SEQ value Fold_7
2022-11-28 00:47:31,925 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 00:47:31,925 INFO:   Starting stage: FEATURE SCALING
2022-11-28 00:47:32,573 INFO:   Done with stage: FEATURE SCALING
2022-11-28 00:47:32,573 INFO:   Starting stage: SCALING TARGETS
2022-11-28 00:47:32,643 INFO:   Done with stage: SCALING TARGETS
2022-11-28 00:47:32,644 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:47:32,644 INFO:     No hyperparam tuning for this model
2022-11-28 00:47:32,644 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:47:32,644 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 00:47:32,645 INFO:     None feature selector for col prot
2022-11-28 00:47:32,645 INFO:     None feature selector for col prot
2022-11-28 00:47:32,645 INFO:     None feature selector for col prot
2022-11-28 00:47:32,645 INFO:     None feature selector for col chem
2022-11-28 00:47:32,645 INFO:     None feature selector for col chem
2022-11-28 00:47:32,645 INFO:     None feature selector for col chem
2022-11-28 00:47:32,645 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 00:47:32,646 INFO:   Starting stage: BUILD MODEL
2022-11-28 00:47:32,647 INFO:     Number of params in model 169741
2022-11-28 00:47:32,651 INFO:   Done with stage: BUILD MODEL
2022-11-28 00:47:32,651 INFO:   Starting stage: TRAINING
2022-11-28 00:47:32,704 INFO:     Val loss before train {'Reaction outcome loss': 0.9984614591706883, 'Total loss': 0.9984614591706883}
2022-11-28 00:47:32,704 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:32,704 INFO:     Epoch: 0
2022-11-28 00:47:33,444 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5535043325613845, 'Total loss': 0.5535043325613845} | train loss {'Reaction outcome loss': 0.6291611346638637, 'Total loss': 0.6291611346638637}
2022-11-28 00:47:33,444 INFO:     Found new best model at epoch 0
2022-11-28 00:47:33,445 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:33,445 INFO:     Epoch: 1
2022-11-28 00:47:34,189 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5340337848121469, 'Total loss': 0.5340337848121469} | train loss {'Reaction outcome loss': 0.49911414943484644, 'Total loss': 0.49911414943484644}
2022-11-28 00:47:34,189 INFO:     Found new best model at epoch 1
2022-11-28 00:47:34,190 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:34,190 INFO:     Epoch: 2
2022-11-28 00:47:34,936 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47771925546906213, 'Total loss': 0.47771925546906213} | train loss {'Reaction outcome loss': 0.46156891468565475, 'Total loss': 0.46156891468565475}
2022-11-28 00:47:34,937 INFO:     Found new best model at epoch 2
2022-11-28 00:47:34,937 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:34,937 INFO:     Epoch: 3
2022-11-28 00:47:35,684 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4846251637420871, 'Total loss': 0.4846251637420871} | train loss {'Reaction outcome loss': 0.44581318728867086, 'Total loss': 0.44581318728867086}
2022-11-28 00:47:35,684 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:35,684 INFO:     Epoch: 4
2022-11-28 00:47:36,435 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46334296464920044, 'Total loss': 0.46334296464920044} | train loss {'Reaction outcome loss': 0.4229026205747234, 'Total loss': 0.4229026205747234}
2022-11-28 00:47:36,435 INFO:     Found new best model at epoch 4
2022-11-28 00:47:36,436 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:36,436 INFO:     Epoch: 5
2022-11-28 00:47:37,188 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.450598865408789, 'Total loss': 0.450598865408789} | train loss {'Reaction outcome loss': 0.41567472320215904, 'Total loss': 0.41567472320215904}
2022-11-28 00:47:37,188 INFO:     Found new best model at epoch 5
2022-11-28 00:47:37,189 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:37,189 INFO:     Epoch: 6
2022-11-28 00:47:37,938 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45196188342842186, 'Total loss': 0.45196188342842186} | train loss {'Reaction outcome loss': 0.4056045048632603, 'Total loss': 0.4056045048632603}
2022-11-28 00:47:37,938 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:37,938 INFO:     Epoch: 7
2022-11-28 00:47:38,684 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.462149632925337, 'Total loss': 0.462149632925337} | train loss {'Reaction outcome loss': 0.40463884940996825, 'Total loss': 0.40463884940996825}
2022-11-28 00:47:38,684 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:38,684 INFO:     Epoch: 8
2022-11-28 00:47:39,429 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44956859133460303, 'Total loss': 0.44956859133460303} | train loss {'Reaction outcome loss': 0.3922719232406211, 'Total loss': 0.3922719232406211}
2022-11-28 00:47:39,429 INFO:     Found new best model at epoch 8
2022-11-28 00:47:39,430 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:39,430 INFO:     Epoch: 9
2022-11-28 00:47:40,175 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45124679058790207, 'Total loss': 0.45124679058790207} | train loss {'Reaction outcome loss': 0.4134828385553862, 'Total loss': 0.4134828385553862}
2022-11-28 00:47:40,176 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:40,176 INFO:     Epoch: 10
2022-11-28 00:47:40,923 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4326021559536457, 'Total loss': 0.4326021559536457} | train loss {'Reaction outcome loss': 0.3745302613409847, 'Total loss': 0.3745302613409847}
2022-11-28 00:47:40,923 INFO:     Found new best model at epoch 10
2022-11-28 00:47:40,924 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:40,924 INFO:     Epoch: 11
2022-11-28 00:47:41,672 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4364746988496997, 'Total loss': 0.4364746988496997} | train loss {'Reaction outcome loss': 0.3812630748459202, 'Total loss': 0.3812630748459202}
2022-11-28 00:47:41,672 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:41,672 INFO:     Epoch: 12
2022-11-28 00:47:42,422 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4300223605876619, 'Total loss': 0.4300223605876619} | train loss {'Reaction outcome loss': 0.38605579872604323, 'Total loss': 0.38605579872604323}
2022-11-28 00:47:42,422 INFO:     Found new best model at epoch 12
2022-11-28 00:47:42,422 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:42,423 INFO:     Epoch: 13
2022-11-28 00:47:43,166 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46479402584108437, 'Total loss': 0.46479402584108437} | train loss {'Reaction outcome loss': 0.37639283903154286, 'Total loss': 0.37639283903154286}
2022-11-28 00:47:43,167 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:43,167 INFO:     Epoch: 14
2022-11-28 00:47:43,909 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4098723249679262, 'Total loss': 0.4098723249679262} | train loss {'Reaction outcome loss': 0.3707461903392062, 'Total loss': 0.3707461903392062}
2022-11-28 00:47:43,909 INFO:     Found new best model at epoch 14
2022-11-28 00:47:43,910 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:43,910 INFO:     Epoch: 15
2022-11-28 00:47:44,653 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4355474795130166, 'Total loss': 0.4355474795130166} | train loss {'Reaction outcome loss': 0.3564043344499973, 'Total loss': 0.3564043344499973}
2022-11-28 00:47:44,653 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:44,653 INFO:     Epoch: 16
2022-11-28 00:47:45,397 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4321636218916286, 'Total loss': 0.4321636218916286} | train loss {'Reaction outcome loss': 0.3469234410869448, 'Total loss': 0.3469234410869448}
2022-11-28 00:47:45,397 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:45,397 INFO:     Epoch: 17
2022-11-28 00:47:46,142 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45629923892292107, 'Total loss': 0.45629923892292107} | train loss {'Reaction outcome loss': 0.3580384895748455, 'Total loss': 0.3580384895748455}
2022-11-28 00:47:46,142 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:46,142 INFO:     Epoch: 18
2022-11-28 00:47:46,892 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43032515997236426, 'Total loss': 0.43032515997236426} | train loss {'Reaction outcome loss': 0.3465010924830369, 'Total loss': 0.3465010924830369}
2022-11-28 00:47:46,892 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:46,893 INFO:     Epoch: 19
2022-11-28 00:47:47,638 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46783317388458684, 'Total loss': 0.46783317388458684} | train loss {'Reaction outcome loss': 0.3396462175042108, 'Total loss': 0.3396462175042108}
2022-11-28 00:47:47,638 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:47,638 INFO:     Epoch: 20
2022-11-28 00:47:48,380 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42011315070770006, 'Total loss': 0.42011315070770006} | train loss {'Reaction outcome loss': 0.34554739892181113, 'Total loss': 0.34554739892181113}
2022-11-28 00:47:48,380 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:48,380 INFO:     Epoch: 21
2022-11-28 00:47:49,124 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42324716462330386, 'Total loss': 0.42324716462330386} | train loss {'Reaction outcome loss': 0.34422741100373055, 'Total loss': 0.34422741100373055}
2022-11-28 00:47:49,124 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:49,124 INFO:     Epoch: 22
2022-11-28 00:47:49,864 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4231586320833726, 'Total loss': 0.4231586320833726} | train loss {'Reaction outcome loss': 0.3543946844363502, 'Total loss': 0.3543946844363502}
2022-11-28 00:47:49,864 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:49,864 INFO:     Epoch: 23
2022-11-28 00:47:50,606 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4298316622999581, 'Total loss': 0.4298316622999581} | train loss {'Reaction outcome loss': 0.3346715392318633, 'Total loss': 0.3346715392318633}
2022-11-28 00:47:50,606 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:50,606 INFO:     Epoch: 24
2022-11-28 00:47:51,344 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.422833179039034, 'Total loss': 0.422833179039034} | train loss {'Reaction outcome loss': 0.33961124667286996, 'Total loss': 0.33961124667286996}
2022-11-28 00:47:51,344 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:51,344 INFO:     Epoch: 25
2022-11-28 00:47:52,085 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4360348108139905, 'Total loss': 0.4360348108139905} | train loss {'Reaction outcome loss': 0.34053719149306716, 'Total loss': 0.34053719149306716}
2022-11-28 00:47:52,085 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:52,085 INFO:     Epoch: 26
2022-11-28 00:47:52,827 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42384478923949326, 'Total loss': 0.42384478923949326} | train loss {'Reaction outcome loss': 0.3335264778586655, 'Total loss': 0.3335264778586655}
2022-11-28 00:47:52,827 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:52,827 INFO:     Epoch: 27
2022-11-28 00:47:53,568 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42627568627622997, 'Total loss': 0.42627568627622997} | train loss {'Reaction outcome loss': 0.33313081832791147, 'Total loss': 0.33313081832791147}
2022-11-28 00:47:53,568 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:53,568 INFO:     Epoch: 28
2022-11-28 00:47:54,310 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41518525406718254, 'Total loss': 0.41518525406718254} | train loss {'Reaction outcome loss': 0.35235025827218647, 'Total loss': 0.35235025827218647}
2022-11-28 00:47:54,310 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:54,310 INFO:     Epoch: 29
2022-11-28 00:47:55,057 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4089720391414382, 'Total loss': 0.4089720391414382} | train loss {'Reaction outcome loss': 0.3546458100259063, 'Total loss': 0.3546458100259063}
2022-11-28 00:47:55,057 INFO:     Found new best model at epoch 29
2022-11-28 00:47:55,058 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:55,058 INFO:     Epoch: 30
2022-11-28 00:47:55,803 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43793346563523466, 'Total loss': 0.43793346563523466} | train loss {'Reaction outcome loss': 0.3397863389780888, 'Total loss': 0.3397863389780888}
2022-11-28 00:47:55,803 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:55,803 INFO:     Epoch: 31
2022-11-28 00:47:56,547 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4146434888243675, 'Total loss': 0.4146434888243675} | train loss {'Reaction outcome loss': 0.3475598042299651, 'Total loss': 0.3475598042299651}
2022-11-28 00:47:56,547 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:56,548 INFO:     Epoch: 32
2022-11-28 00:47:57,296 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4038056003099138, 'Total loss': 0.4038056003099138} | train loss {'Reaction outcome loss': 0.3242512170662764, 'Total loss': 0.3242512170662764}
2022-11-28 00:47:57,296 INFO:     Found new best model at epoch 32
2022-11-28 00:47:57,297 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:57,297 INFO:     Epoch: 33
2022-11-28 00:47:58,046 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4038724221966483, 'Total loss': 0.4038724221966483} | train loss {'Reaction outcome loss': 0.33237205555866123, 'Total loss': 0.33237205555866123}
2022-11-28 00:47:58,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:58,047 INFO:     Epoch: 34
2022-11-28 00:47:58,795 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4657075164670294, 'Total loss': 0.4657075164670294} | train loss {'Reaction outcome loss': 0.33687402767427116, 'Total loss': 0.33687402767427116}
2022-11-28 00:47:58,795 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:58,795 INFO:     Epoch: 35
2022-11-28 00:47:59,544 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4164274331520904, 'Total loss': 0.4164274331520904} | train loss {'Reaction outcome loss': 0.323969263399608, 'Total loss': 0.323969263399608}
2022-11-28 00:47:59,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:47:59,545 INFO:     Epoch: 36
2022-11-28 00:48:00,296 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44217596643350343, 'Total loss': 0.44217596643350343} | train loss {'Reaction outcome loss': 0.32871748516072147, 'Total loss': 0.32871748516072147}
2022-11-28 00:48:00,297 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:00,297 INFO:     Epoch: 37
2022-11-28 00:48:01,051 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43773825822228735, 'Total loss': 0.43773825822228735} | train loss {'Reaction outcome loss': 0.3432206325253014, 'Total loss': 0.3432206325253014}
2022-11-28 00:48:01,051 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:01,052 INFO:     Epoch: 38
2022-11-28 00:48:01,806 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4434584238651124, 'Total loss': 0.4434584238651124} | train loss {'Reaction outcome loss': 0.32367704336640807, 'Total loss': 0.32367704336640807}
2022-11-28 00:48:01,806 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:01,806 INFO:     Epoch: 39
2022-11-28 00:48:02,556 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3955395458774133, 'Total loss': 0.3955395458774133} | train loss {'Reaction outcome loss': 0.319356382722676, 'Total loss': 0.319356382722676}
2022-11-28 00:48:02,556 INFO:     Found new best model at epoch 39
2022-11-28 00:48:02,557 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:02,557 INFO:     Epoch: 40
2022-11-28 00:48:03,308 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45097254792397673, 'Total loss': 0.45097254792397673} | train loss {'Reaction outcome loss': 0.32659553902351907, 'Total loss': 0.32659553902351907}
2022-11-28 00:48:03,308 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:03,308 INFO:     Epoch: 41
2022-11-28 00:48:04,057 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4259208796376532, 'Total loss': 0.4259208796376532} | train loss {'Reaction outcome loss': 0.33384268616254514, 'Total loss': 0.33384268616254514}
2022-11-28 00:48:04,057 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:04,057 INFO:     Epoch: 42
2022-11-28 00:48:04,805 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41544223779981787, 'Total loss': 0.41544223779981787} | train loss {'Reaction outcome loss': 0.3662748233045674, 'Total loss': 0.3662748233045674}
2022-11-28 00:48:04,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:04,805 INFO:     Epoch: 43
2022-11-28 00:48:05,555 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4249407354403626, 'Total loss': 0.4249407354403626} | train loss {'Reaction outcome loss': 0.3234616139835795, 'Total loss': 0.3234616139835795}
2022-11-28 00:48:05,555 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:05,555 INFO:     Epoch: 44
2022-11-28 00:48:06,305 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42514159428802406, 'Total loss': 0.42514159428802406} | train loss {'Reaction outcome loss': 0.3232678605869473, 'Total loss': 0.3232678605869473}
2022-11-28 00:48:06,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:06,305 INFO:     Epoch: 45
2022-11-28 00:48:07,049 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4594984298402613, 'Total loss': 0.4594984298402613} | train loss {'Reaction outcome loss': 0.31575917301752304, 'Total loss': 0.31575917301752304}
2022-11-28 00:48:07,049 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:07,049 INFO:     Epoch: 46
2022-11-28 00:48:07,797 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4151812340556221, 'Total loss': 0.4151812340556221} | train loss {'Reaction outcome loss': 0.32720352826180005, 'Total loss': 0.32720352826180005}
2022-11-28 00:48:07,797 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:07,798 INFO:     Epoch: 47
2022-11-28 00:48:08,545 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42421338470144704, 'Total loss': 0.42421338470144704} | train loss {'Reaction outcome loss': 0.3233245788556844, 'Total loss': 0.3233245788556844}
2022-11-28 00:48:08,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:08,545 INFO:     Epoch: 48
2022-11-28 00:48:09,292 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4585378217426213, 'Total loss': 0.4585378217426213} | train loss {'Reaction outcome loss': 0.32745670065706073, 'Total loss': 0.32745670065706073}
2022-11-28 00:48:09,292 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:09,292 INFO:     Epoch: 49
2022-11-28 00:48:10,050 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4256630221551115, 'Total loss': 0.4256630221551115} | train loss {'Reaction outcome loss': 0.3253215534785981, 'Total loss': 0.3253215534785981}
2022-11-28 00:48:10,050 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:10,050 INFO:     Epoch: 50
2022-11-28 00:48:10,803 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4157240428030491, 'Total loss': 0.4157240428030491} | train loss {'Reaction outcome loss': 0.31982168973035174, 'Total loss': 0.31982168973035174}
2022-11-28 00:48:10,803 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:10,803 INFO:     Epoch: 51
2022-11-28 00:48:11,556 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4434766105630181, 'Total loss': 0.4434766105630181} | train loss {'Reaction outcome loss': 0.3191291175873173, 'Total loss': 0.3191291175873173}
2022-11-28 00:48:11,557 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:11,557 INFO:     Epoch: 52
2022-11-28 00:48:12,309 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40912256051193585, 'Total loss': 0.40912256051193585} | train loss {'Reaction outcome loss': 0.3272554510789603, 'Total loss': 0.3272554510789603}
2022-11-28 00:48:12,309 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:12,309 INFO:     Epoch: 53
2022-11-28 00:48:13,061 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4017424723133445, 'Total loss': 0.4017424723133445} | train loss {'Reaction outcome loss': 0.3164767031746385, 'Total loss': 0.3164767031746385}
2022-11-28 00:48:13,061 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:13,061 INFO:     Epoch: 54
2022-11-28 00:48:13,810 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43702401440929284, 'Total loss': 0.43702401440929284} | train loss {'Reaction outcome loss': 0.3172381783002301, 'Total loss': 0.3172381783002301}
2022-11-28 00:48:13,810 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:13,810 INFO:     Epoch: 55
2022-11-28 00:48:14,559 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42724944007667626, 'Total loss': 0.42724944007667626} | train loss {'Reaction outcome loss': 0.32467344457562636, 'Total loss': 0.32467344457562636}
2022-11-28 00:48:14,559 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:14,559 INFO:     Epoch: 56
2022-11-28 00:48:15,314 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44647801328789105, 'Total loss': 0.44647801328789105} | train loss {'Reaction outcome loss': 0.33464518059723775, 'Total loss': 0.33464518059723775}
2022-11-28 00:48:15,314 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:15,314 INFO:     Epoch: 57
2022-11-28 00:48:16,062 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43633912334387953, 'Total loss': 0.43633912334387953} | train loss {'Reaction outcome loss': 0.3290834195218105, 'Total loss': 0.3290834195218105}
2022-11-28 00:48:16,062 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:16,062 INFO:     Epoch: 58
2022-11-28 00:48:16,813 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4107530364258723, 'Total loss': 0.4107530364258723} | train loss {'Reaction outcome loss': 0.32452828415974916, 'Total loss': 0.32452828415974916}
2022-11-28 00:48:16,813 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:16,813 INFO:     Epoch: 59
2022-11-28 00:48:17,564 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40988849729976873, 'Total loss': 0.40988849729976873} | train loss {'Reaction outcome loss': 0.32339439670383735, 'Total loss': 0.32339439670383735}
2022-11-28 00:48:17,564 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:17,564 INFO:     Epoch: 60
2022-11-28 00:48:18,312 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40263190831650386, 'Total loss': 0.40263190831650386} | train loss {'Reaction outcome loss': 0.31880269097051156, 'Total loss': 0.31880269097051156}
2022-11-28 00:48:18,312 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:18,312 INFO:     Epoch: 61
2022-11-28 00:48:19,067 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44243708422238176, 'Total loss': 0.44243708422238176} | train loss {'Reaction outcome loss': 0.3214507064959298, 'Total loss': 0.3214507064959298}
2022-11-28 00:48:19,067 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:19,067 INFO:     Epoch: 62
2022-11-28 00:48:19,823 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4042121944949031, 'Total loss': 0.4042121944949031} | train loss {'Reaction outcome loss': 0.33686383942006387, 'Total loss': 0.33686383942006387}
2022-11-28 00:48:19,823 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:19,823 INFO:     Epoch: 63
2022-11-28 00:48:20,575 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4550160594623197, 'Total loss': 0.4550160594623197} | train loss {'Reaction outcome loss': 0.31854139995357766, 'Total loss': 0.31854139995357766}
2022-11-28 00:48:20,575 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:20,575 INFO:     Epoch: 64
2022-11-28 00:48:21,326 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4121367425065149, 'Total loss': 0.4121367425065149} | train loss {'Reaction outcome loss': 0.32910611806248846, 'Total loss': 0.32910611806248846}
2022-11-28 00:48:21,326 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:21,326 INFO:     Epoch: 65
2022-11-28 00:48:22,078 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4391986106268384, 'Total loss': 0.4391986106268384} | train loss {'Reaction outcome loss': 0.31431650610165557, 'Total loss': 0.31431650610165557}
2022-11-28 00:48:22,078 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:22,078 INFO:     Epoch: 66
2022-11-28 00:48:22,827 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44025425477461383, 'Total loss': 0.44025425477461383} | train loss {'Reaction outcome loss': 0.32333001360176544, 'Total loss': 0.32333001360176544}
2022-11-28 00:48:22,827 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:22,827 INFO:     Epoch: 67
2022-11-28 00:48:23,576 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44691120960157027, 'Total loss': 0.44691120960157027} | train loss {'Reaction outcome loss': 0.31893322918458505, 'Total loss': 0.31893322918458505}
2022-11-28 00:48:23,576 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:23,576 INFO:     Epoch: 68
2022-11-28 00:48:24,319 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40153372152285144, 'Total loss': 0.40153372152285144} | train loss {'Reaction outcome loss': 0.32978869811726, 'Total loss': 0.32978869811726}
2022-11-28 00:48:24,319 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:24,319 INFO:     Epoch: 69
2022-11-28 00:48:25,063 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40384855798699637, 'Total loss': 0.40384855798699637} | train loss {'Reaction outcome loss': 0.3149942934120956, 'Total loss': 0.3149942934120956}
2022-11-28 00:48:25,063 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:25,063 INFO:     Epoch: 70
2022-11-28 00:48:25,808 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3986912884495475, 'Total loss': 0.3986912884495475} | train loss {'Reaction outcome loss': 0.3125858061177739, 'Total loss': 0.3125858061177739}
2022-11-28 00:48:25,808 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:25,808 INFO:     Epoch: 71
2022-11-28 00:48:26,560 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4188699388707226, 'Total loss': 0.4188699388707226} | train loss {'Reaction outcome loss': 0.32013813062356067, 'Total loss': 0.32013813062356067}
2022-11-28 00:48:26,560 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:26,560 INFO:     Epoch: 72
2022-11-28 00:48:27,306 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39636631682515144, 'Total loss': 0.39636631682515144} | train loss {'Reaction outcome loss': 0.3163092441329929, 'Total loss': 0.3163092441329929}
2022-11-28 00:48:27,306 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:27,306 INFO:     Epoch: 73
2022-11-28 00:48:28,054 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42706007087095216, 'Total loss': 0.42706007087095216} | train loss {'Reaction outcome loss': 0.30640130097174695, 'Total loss': 0.30640130097174695}
2022-11-28 00:48:28,054 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:28,054 INFO:     Epoch: 74
2022-11-28 00:48:28,803 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4257016181945801, 'Total loss': 0.4257016181945801} | train loss {'Reaction outcome loss': 0.3110193785747536, 'Total loss': 0.3110193785747536}
2022-11-28 00:48:28,803 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:28,804 INFO:     Epoch: 75
2022-11-28 00:48:29,548 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4266940162263133, 'Total loss': 0.4266940162263133} | train loss {'Reaction outcome loss': 0.3257181802349776, 'Total loss': 0.3257181802349776}
2022-11-28 00:48:29,548 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:29,548 INFO:     Epoch: 76
2022-11-28 00:48:30,297 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4227802042256702, 'Total loss': 0.4227802042256702} | train loss {'Reaction outcome loss': 0.33036464688025025, 'Total loss': 0.33036464688025025}
2022-11-28 00:48:30,298 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:30,298 INFO:     Epoch: 77
2022-11-28 00:48:31,046 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4382058009505272, 'Total loss': 0.4382058009505272} | train loss {'Reaction outcome loss': 0.3186042933962364, 'Total loss': 0.3186042933962364}
2022-11-28 00:48:31,046 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:31,046 INFO:     Epoch: 78
2022-11-28 00:48:31,792 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4233144022185694, 'Total loss': 0.4233144022185694} | train loss {'Reaction outcome loss': 0.32816495085776093, 'Total loss': 0.32816495085776093}
2022-11-28 00:48:31,792 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:31,792 INFO:     Epoch: 79
2022-11-28 00:48:32,538 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.417281064120206, 'Total loss': 0.417281064120206} | train loss {'Reaction outcome loss': 0.31890003452537513, 'Total loss': 0.31890003452537513}
2022-11-28 00:48:32,538 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:32,538 INFO:     Epoch: 80
2022-11-28 00:48:33,283 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4127792221578685, 'Total loss': 0.4127792221578685} | train loss {'Reaction outcome loss': 0.3323654857000359, 'Total loss': 0.3323654857000359}
2022-11-28 00:48:33,283 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:33,283 INFO:     Epoch: 81
2022-11-28 00:48:34,032 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40139504826881667, 'Total loss': 0.40139504826881667} | train loss {'Reaction outcome loss': 0.3254439411496344, 'Total loss': 0.3254439411496344}
2022-11-28 00:48:34,032 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:34,032 INFO:     Epoch: 82
2022-11-28 00:48:34,782 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4592617829753594, 'Total loss': 0.4592617829753594} | train loss {'Reaction outcome loss': 0.3102347579641411, 'Total loss': 0.3102347579641411}
2022-11-28 00:48:34,782 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:34,782 INFO:     Epoch: 83
2022-11-28 00:48:35,530 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4028897244821895, 'Total loss': 0.4028897244821895} | train loss {'Reaction outcome loss': 0.31732678657698327, 'Total loss': 0.31732678657698327}
2022-11-28 00:48:35,530 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:35,531 INFO:     Epoch: 84
2022-11-28 00:48:36,274 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4325123710388487, 'Total loss': 0.4325123710388487} | train loss {'Reaction outcome loss': 0.31316417561248244, 'Total loss': 0.31316417561248244}
2022-11-28 00:48:36,274 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:36,274 INFO:     Epoch: 85
2022-11-28 00:48:37,019 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4265924370424314, 'Total loss': 0.4265924370424314} | train loss {'Reaction outcome loss': 0.30822784302054873, 'Total loss': 0.30822784302054873}
2022-11-28 00:48:37,019 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:37,019 INFO:     Epoch: 86
2022-11-28 00:48:37,765 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4599397676912221, 'Total loss': 0.4599397676912221} | train loss {'Reaction outcome loss': 0.31404315245899594, 'Total loss': 0.31404315245899594}
2022-11-28 00:48:37,765 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:37,765 INFO:     Epoch: 87
2022-11-28 00:48:38,508 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39868801332671533, 'Total loss': 0.39868801332671533} | train loss {'Reaction outcome loss': 0.3292798101600365, 'Total loss': 0.3292798101600365}
2022-11-28 00:48:38,508 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:38,509 INFO:     Epoch: 88
2022-11-28 00:48:39,253 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43083929643034935, 'Total loss': 0.43083929643034935} | train loss {'Reaction outcome loss': 0.3305541483858819, 'Total loss': 0.3305541483858819}
2022-11-28 00:48:39,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:39,253 INFO:     Epoch: 89
2022-11-28 00:48:40,002 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41143103959885513, 'Total loss': 0.41143103959885513} | train loss {'Reaction outcome loss': 0.3222409540463073, 'Total loss': 0.3222409540463073}
2022-11-28 00:48:40,002 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:40,002 INFO:     Epoch: 90
2022-11-28 00:48:40,749 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4193998859687285, 'Total loss': 0.4193998859687285} | train loss {'Reaction outcome loss': 0.32433426760227574, 'Total loss': 0.32433426760227574}
2022-11-28 00:48:40,749 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:40,749 INFO:     Epoch: 91
2022-11-28 00:48:41,492 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46766096048734407, 'Total loss': 0.46766096048734407} | train loss {'Reaction outcome loss': 0.34101520263050733, 'Total loss': 0.34101520263050733}
2022-11-28 00:48:41,492 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:41,492 INFO:     Epoch: 92
2022-11-28 00:48:42,239 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3892312935468825, 'Total loss': 0.3892312935468825} | train loss {'Reaction outcome loss': 0.3120238750433994, 'Total loss': 0.3120238750433994}
2022-11-28 00:48:42,240 INFO:     Found new best model at epoch 92
2022-11-28 00:48:42,241 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:42,241 INFO:     Epoch: 93
2022-11-28 00:48:42,983 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4232608526945114, 'Total loss': 0.4232608526945114} | train loss {'Reaction outcome loss': 0.3169331772908991, 'Total loss': 0.3169331772908991}
2022-11-28 00:48:42,983 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:42,983 INFO:     Epoch: 94
2022-11-28 00:48:43,727 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4128567799925804, 'Total loss': 0.4128567799925804} | train loss {'Reaction outcome loss': 0.3237238350184823, 'Total loss': 0.3237238350184823}
2022-11-28 00:48:43,727 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:43,727 INFO:     Epoch: 95
2022-11-28 00:48:44,472 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4138471287759868, 'Total loss': 0.4138471287759868} | train loss {'Reaction outcome loss': 0.3148982945965369, 'Total loss': 0.3148982945965369}
2022-11-28 00:48:44,472 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:44,472 INFO:     Epoch: 96
2022-11-28 00:48:45,218 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47678798775781284, 'Total loss': 0.47678798775781284} | train loss {'Reaction outcome loss': 0.30931466486048603, 'Total loss': 0.30931466486048603}
2022-11-28 00:48:45,218 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:45,218 INFO:     Epoch: 97
2022-11-28 00:48:45,963 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.39769434691830113, 'Total loss': 0.39769434691830113} | train loss {'Reaction outcome loss': 0.31429571522633554, 'Total loss': 0.31429571522633554}
2022-11-28 00:48:45,963 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:45,963 INFO:     Epoch: 98
2022-11-28 00:48:46,707 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4573145203969695, 'Total loss': 0.4573145203969695} | train loss {'Reaction outcome loss': 0.31435942607611295, 'Total loss': 0.31435942607611295}
2022-11-28 00:48:46,707 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:46,707 INFO:     Epoch: 99
2022-11-28 00:48:47,452 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4107793467965993, 'Total loss': 0.4107793467965993} | train loss {'Reaction outcome loss': 0.3088816685926335, 'Total loss': 0.3088816685926335}
2022-11-28 00:48:47,452 INFO:     Best model found after epoch 93 of 100.
2022-11-28 00:48:47,452 INFO:   Done with stage: TRAINING
2022-11-28 00:48:47,452 INFO:   Starting stage: EVALUATION
2022-11-28 00:48:47,573 INFO:   Done with stage: EVALUATION
2022-11-28 00:48:47,573 INFO:   Leaving out SEQ value Fold_8
2022-11-28 00:48:47,586 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 00:48:47,586 INFO:   Starting stage: FEATURE SCALING
2022-11-28 00:48:48,229 INFO:   Done with stage: FEATURE SCALING
2022-11-28 00:48:48,229 INFO:   Starting stage: SCALING TARGETS
2022-11-28 00:48:48,298 INFO:   Done with stage: SCALING TARGETS
2022-11-28 00:48:48,299 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:48:48,299 INFO:     No hyperparam tuning for this model
2022-11-28 00:48:48,299 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:48:48,299 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 00:48:48,300 INFO:     None feature selector for col prot
2022-11-28 00:48:48,300 INFO:     None feature selector for col prot
2022-11-28 00:48:48,300 INFO:     None feature selector for col prot
2022-11-28 00:48:48,300 INFO:     None feature selector for col chem
2022-11-28 00:48:48,300 INFO:     None feature selector for col chem
2022-11-28 00:48:48,300 INFO:     None feature selector for col chem
2022-11-28 00:48:48,300 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 00:48:48,301 INFO:   Starting stage: BUILD MODEL
2022-11-28 00:48:48,302 INFO:     Number of params in model 169741
2022-11-28 00:48:48,305 INFO:   Done with stage: BUILD MODEL
2022-11-28 00:48:48,305 INFO:   Starting stage: TRAINING
2022-11-28 00:48:48,358 INFO:     Val loss before train {'Reaction outcome loss': 0.9676745337518778, 'Total loss': 0.9676745337518778}
2022-11-28 00:48:48,359 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:48,359 INFO:     Epoch: 0
2022-11-28 00:48:49,100 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5467793067747896, 'Total loss': 0.5467793067747896} | train loss {'Reaction outcome loss': 0.663815050593272, 'Total loss': 0.663815050593272}
2022-11-28 00:48:49,100 INFO:     Found new best model at epoch 0
2022-11-28 00:48:49,101 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:49,101 INFO:     Epoch: 1
2022-11-28 00:48:49,842 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49947488138621504, 'Total loss': 0.49947488138621504} | train loss {'Reaction outcome loss': 0.5099701079038473, 'Total loss': 0.5099701079038473}
2022-11-28 00:48:49,842 INFO:     Found new best model at epoch 1
2022-11-28 00:48:49,843 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:49,843 INFO:     Epoch: 2
2022-11-28 00:48:50,582 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5002657615325667, 'Total loss': 0.5002657615325667} | train loss {'Reaction outcome loss': 0.47709739051367106, 'Total loss': 0.47709739051367106}
2022-11-28 00:48:50,582 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:50,582 INFO:     Epoch: 3
2022-11-28 00:48:51,319 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.468368609520522, 'Total loss': 0.468368609520522} | train loss {'Reaction outcome loss': 0.45292267939339764, 'Total loss': 0.45292267939339764}
2022-11-28 00:48:51,319 INFO:     Found new best model at epoch 3
2022-11-28 00:48:51,320 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:51,320 INFO:     Epoch: 4
2022-11-28 00:48:52,059 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46482551301067526, 'Total loss': 0.46482551301067526} | train loss {'Reaction outcome loss': 0.4349817902543526, 'Total loss': 0.4349817902543526}
2022-11-28 00:48:52,059 INFO:     Found new best model at epoch 4
2022-11-28 00:48:52,060 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:52,060 INFO:     Epoch: 5
2022-11-28 00:48:52,802 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4657745554365895, 'Total loss': 0.4657745554365895} | train loss {'Reaction outcome loss': 0.41773675937160304, 'Total loss': 0.41773675937160304}
2022-11-28 00:48:52,802 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:52,802 INFO:     Epoch: 6
2022-11-28 00:48:53,543 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46513364565643395, 'Total loss': 0.46513364565643395} | train loss {'Reaction outcome loss': 0.41160768511806906, 'Total loss': 0.41160768511806906}
2022-11-28 00:48:53,543 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:53,543 INFO:     Epoch: 7
2022-11-28 00:48:54,288 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47623288157311355, 'Total loss': 0.47623288157311355} | train loss {'Reaction outcome loss': 0.41520127316235533, 'Total loss': 0.41520127316235533}
2022-11-28 00:48:54,288 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:54,288 INFO:     Epoch: 8
2022-11-28 00:48:55,032 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4574028338220986, 'Total loss': 0.4574028338220986} | train loss {'Reaction outcome loss': 0.4038826252526117, 'Total loss': 0.4038826252526117}
2022-11-28 00:48:55,032 INFO:     Found new best model at epoch 8
2022-11-28 00:48:55,033 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:55,033 INFO:     Epoch: 9
2022-11-28 00:48:55,774 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44387674433263863, 'Total loss': 0.44387674433263863} | train loss {'Reaction outcome loss': 0.39194182677548906, 'Total loss': 0.39194182677548906}
2022-11-28 00:48:55,774 INFO:     Found new best model at epoch 9
2022-11-28 00:48:55,775 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:55,775 INFO:     Epoch: 10
2022-11-28 00:48:56,520 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45945892279798334, 'Total loss': 0.45945892279798334} | train loss {'Reaction outcome loss': 0.38392350354669275, 'Total loss': 0.38392350354669275}
2022-11-28 00:48:56,520 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:56,520 INFO:     Epoch: 11
2022-11-28 00:48:57,266 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45747730135917664, 'Total loss': 0.45747730135917664} | train loss {'Reaction outcome loss': 0.3878795540163874, 'Total loss': 0.3878795540163874}
2022-11-28 00:48:57,267 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:57,267 INFO:     Epoch: 12
2022-11-28 00:48:58,016 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.444930821318518, 'Total loss': 0.444930821318518} | train loss {'Reaction outcome loss': 0.3823961480954277, 'Total loss': 0.3823961480954277}
2022-11-28 00:48:58,016 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:58,016 INFO:     Epoch: 13
2022-11-28 00:48:58,762 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45898196744647896, 'Total loss': 0.45898196744647896} | train loss {'Reaction outcome loss': 0.38041379302740097, 'Total loss': 0.38041379302740097}
2022-11-28 00:48:58,762 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:58,762 INFO:     Epoch: 14
2022-11-28 00:48:59,507 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4551327533342622, 'Total loss': 0.4551327533342622} | train loss {'Reaction outcome loss': 0.38351310717190806, 'Total loss': 0.38351310717190806}
2022-11-28 00:48:59,507 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:48:59,507 INFO:     Epoch: 15
2022-11-28 00:49:00,250 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4897389371286739, 'Total loss': 0.4897389371286739} | train loss {'Reaction outcome loss': 0.3804393431043577, 'Total loss': 0.3804393431043577}
2022-11-28 00:49:00,251 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:00,251 INFO:     Epoch: 16
2022-11-28 00:49:00,993 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49806982634419744, 'Total loss': 0.49806982634419744} | train loss {'Reaction outcome loss': 0.3582926833255571, 'Total loss': 0.3582926833255571}
2022-11-28 00:49:00,994 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:00,994 INFO:     Epoch: 17
2022-11-28 00:49:01,738 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4394169429486448, 'Total loss': 0.4394169429486448} | train loss {'Reaction outcome loss': 0.37513769963974897, 'Total loss': 0.37513769963974897}
2022-11-28 00:49:01,738 INFO:     Found new best model at epoch 17
2022-11-28 00:49:01,739 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:01,739 INFO:     Epoch: 18
2022-11-28 00:49:02,482 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41773750870065257, 'Total loss': 0.41773750870065257} | train loss {'Reaction outcome loss': 0.3662990163483842, 'Total loss': 0.3662990163483842}
2022-11-28 00:49:02,482 INFO:     Found new best model at epoch 18
2022-11-28 00:49:02,483 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:02,483 INFO:     Epoch: 19
2022-11-28 00:49:03,224 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4342801953581246, 'Total loss': 0.4342801953581246} | train loss {'Reaction outcome loss': 0.3738578183478431, 'Total loss': 0.3738578183478431}
2022-11-28 00:49:03,224 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:03,224 INFO:     Epoch: 20
2022-11-28 00:49:03,970 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43850563297217543, 'Total loss': 0.43850563297217543} | train loss {'Reaction outcome loss': 0.35115786693115464, 'Total loss': 0.35115786693115464}
2022-11-28 00:49:03,971 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:03,971 INFO:     Epoch: 21
2022-11-28 00:49:04,716 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4219832620160146, 'Total loss': 0.4219832620160146} | train loss {'Reaction outcome loss': 0.35242933161586887, 'Total loss': 0.35242933161586887}
2022-11-28 00:49:04,716 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:04,716 INFO:     Epoch: 22
2022-11-28 00:49:05,456 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42766924456439237, 'Total loss': 0.42766924456439237} | train loss {'Reaction outcome loss': 0.3443303259187623, 'Total loss': 0.3443303259187623}
2022-11-28 00:49:05,456 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:05,456 INFO:     Epoch: 23
2022-11-28 00:49:06,200 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43716168141161854, 'Total loss': 0.43716168141161854} | train loss {'Reaction outcome loss': 0.3473684910820563, 'Total loss': 0.3473684910820563}
2022-11-28 00:49:06,200 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:06,200 INFO:     Epoch: 24
2022-11-28 00:49:06,937 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45147956467487593, 'Total loss': 0.45147956467487593} | train loss {'Reaction outcome loss': 0.3505649896647766, 'Total loss': 0.3505649896647766}
2022-11-28 00:49:06,937 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:06,937 INFO:     Epoch: 25
2022-11-28 00:49:07,677 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.47174545377492905, 'Total loss': 0.47174545377492905} | train loss {'Reaction outcome loss': 0.33777606861311416, 'Total loss': 0.33777606861311416}
2022-11-28 00:49:07,677 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:07,677 INFO:     Epoch: 26
2022-11-28 00:49:08,422 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4396874735301191, 'Total loss': 0.4396874735301191} | train loss {'Reaction outcome loss': 0.33682740337935535, 'Total loss': 0.33682740337935535}
2022-11-28 00:49:08,422 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:08,422 INFO:     Epoch: 27
2022-11-28 00:49:09,176 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4328218793327158, 'Total loss': 0.4328218793327158} | train loss {'Reaction outcome loss': 0.34194587934234366, 'Total loss': 0.34194587934234366}
2022-11-28 00:49:09,176 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:09,176 INFO:     Epoch: 28
2022-11-28 00:49:09,935 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45931539312005043, 'Total loss': 0.45931539312005043} | train loss {'Reaction outcome loss': 0.34117654076049686, 'Total loss': 0.34117654076049686}
2022-11-28 00:49:09,935 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:09,935 INFO:     Epoch: 29
2022-11-28 00:49:10,690 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45986517654223874, 'Total loss': 0.45986517654223874} | train loss {'Reaction outcome loss': 0.34515934952945726, 'Total loss': 0.34515934952945726}
2022-11-28 00:49:10,690 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:10,690 INFO:     Epoch: 30
2022-11-28 00:49:11,447 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45131473429501057, 'Total loss': 0.45131473429501057} | train loss {'Reaction outcome loss': 0.3367766203765987, 'Total loss': 0.3367766203765987}
2022-11-28 00:49:11,447 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:11,447 INFO:     Epoch: 31
2022-11-28 00:49:12,202 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4948526898568327, 'Total loss': 0.4948526898568327} | train loss {'Reaction outcome loss': 0.336588430621846, 'Total loss': 0.336588430621846}
2022-11-28 00:49:12,202 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:12,202 INFO:     Epoch: 32
2022-11-28 00:49:12,959 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4219428683546456, 'Total loss': 0.4219428683546456} | train loss {'Reaction outcome loss': 0.34079575453421124, 'Total loss': 0.34079575453421124}
2022-11-28 00:49:12,960 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:12,961 INFO:     Epoch: 33
2022-11-28 00:49:13,714 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4373651590536941, 'Total loss': 0.4373651590536941} | train loss {'Reaction outcome loss': 0.33092550320648834, 'Total loss': 0.33092550320648834}
2022-11-28 00:49:13,714 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:13,715 INFO:     Epoch: 34
2022-11-28 00:49:14,470 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41028563949194824, 'Total loss': 0.41028563949194824} | train loss {'Reaction outcome loss': 0.3291598333701914, 'Total loss': 0.3291598333701914}
2022-11-28 00:49:14,471 INFO:     Found new best model at epoch 34
2022-11-28 00:49:14,471 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:14,471 INFO:     Epoch: 35
2022-11-28 00:49:15,229 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4483304673975164, 'Total loss': 0.4483304673975164} | train loss {'Reaction outcome loss': 0.35419684378543365, 'Total loss': 0.35419684378543365}
2022-11-28 00:49:15,229 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:15,229 INFO:     Epoch: 36
2022-11-28 00:49:15,987 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4832678945227103, 'Total loss': 0.4832678945227103} | train loss {'Reaction outcome loss': 0.339890717434497, 'Total loss': 0.339890717434497}
2022-11-28 00:49:15,987 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:15,987 INFO:     Epoch: 37
2022-11-28 00:49:16,744 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45371654020114377, 'Total loss': 0.45371654020114377} | train loss {'Reaction outcome loss': 0.35560034553290376, 'Total loss': 0.35560034553290376}
2022-11-28 00:49:16,744 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:16,744 INFO:     Epoch: 38
2022-11-28 00:49:17,503 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43604732948270714, 'Total loss': 0.43604732948270714} | train loss {'Reaction outcome loss': 0.3310367037892824, 'Total loss': 0.3310367037892824}
2022-11-28 00:49:17,503 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:17,503 INFO:     Epoch: 39
2022-11-28 00:49:18,260 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45649792524901306, 'Total loss': 0.45649792524901306} | train loss {'Reaction outcome loss': 0.3470348761330249, 'Total loss': 0.3470348761330249}
2022-11-28 00:49:18,260 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:18,260 INFO:     Epoch: 40
2022-11-28 00:49:19,018 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4224891618571498, 'Total loss': 0.4224891618571498} | train loss {'Reaction outcome loss': 0.3362817540887351, 'Total loss': 0.3362817540887351}
2022-11-28 00:49:19,019 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:19,019 INFO:     Epoch: 41
2022-11-28 00:49:19,777 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44224338605999947, 'Total loss': 0.44224338605999947} | train loss {'Reaction outcome loss': 0.3257052473109291, 'Total loss': 0.3257052473109291}
2022-11-28 00:49:19,777 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:19,777 INFO:     Epoch: 42
2022-11-28 00:49:20,533 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4557256651195613, 'Total loss': 0.4557256651195613} | train loss {'Reaction outcome loss': 0.32410927095755876, 'Total loss': 0.32410927095755876}
2022-11-28 00:49:20,533 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:20,533 INFO:     Epoch: 43
2022-11-28 00:49:21,290 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44491423429413274, 'Total loss': 0.44491423429413274} | train loss {'Reaction outcome loss': 0.3310331076624905, 'Total loss': 0.3310331076624905}
2022-11-28 00:49:21,290 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:21,290 INFO:     Epoch: 44
2022-11-28 00:49:22,047 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43007954447106883, 'Total loss': 0.43007954447106883} | train loss {'Reaction outcome loss': 0.33306935121897263, 'Total loss': 0.33306935121897263}
2022-11-28 00:49:22,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:22,047 INFO:     Epoch: 45
2022-11-28 00:49:22,808 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47646024518392305, 'Total loss': 0.47646024518392305} | train loss {'Reaction outcome loss': 0.3207803209861816, 'Total loss': 0.3207803209861816}
2022-11-28 00:49:22,808 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:22,808 INFO:     Epoch: 46
2022-11-28 00:49:23,568 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46603627706115897, 'Total loss': 0.46603627706115897} | train loss {'Reaction outcome loss': 0.3274970860163934, 'Total loss': 0.3274970860163934}
2022-11-28 00:49:23,568 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:23,568 INFO:     Epoch: 47
2022-11-28 00:49:24,328 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43191003663973376, 'Total loss': 0.43191003663973376} | train loss {'Reaction outcome loss': 0.33966407921874087, 'Total loss': 0.33966407921874087}
2022-11-28 00:49:24,328 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:24,328 INFO:     Epoch: 48
2022-11-28 00:49:25,087 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45376516675407236, 'Total loss': 0.45376516675407236} | train loss {'Reaction outcome loss': 0.3258257637079428, 'Total loss': 0.3258257637079428}
2022-11-28 00:49:25,088 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:25,088 INFO:     Epoch: 49
2022-11-28 00:49:25,849 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43071290190246975, 'Total loss': 0.43071290190246975} | train loss {'Reaction outcome loss': 0.335428452714976, 'Total loss': 0.335428452714976}
2022-11-28 00:49:25,849 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:25,849 INFO:     Epoch: 50
2022-11-28 00:49:26,606 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4522583994337104, 'Total loss': 0.4522583994337104} | train loss {'Reaction outcome loss': 0.3266773839530192, 'Total loss': 0.3266773839530192}
2022-11-28 00:49:26,606 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:26,606 INFO:     Epoch: 51
2022-11-28 00:49:27,363 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4589172259650447, 'Total loss': 0.4589172259650447} | train loss {'Reaction outcome loss': 0.31988744182806267, 'Total loss': 0.31988744182806267}
2022-11-28 00:49:27,363 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:27,364 INFO:     Epoch: 52
2022-11-28 00:49:28,120 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4604093303734606, 'Total loss': 0.4604093303734606} | train loss {'Reaction outcome loss': 0.3243077075795123, 'Total loss': 0.3243077075795123}
2022-11-28 00:49:28,121 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:28,121 INFO:     Epoch: 53
2022-11-28 00:49:28,886 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4488169584761966, 'Total loss': 0.4488169584761966} | train loss {'Reaction outcome loss': 0.339733711138428, 'Total loss': 0.339733711138428}
2022-11-28 00:49:28,886 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:28,886 INFO:     Epoch: 54
2022-11-28 00:49:29,644 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42564479718831455, 'Total loss': 0.42564479718831455} | train loss {'Reaction outcome loss': 0.3336858461282936, 'Total loss': 0.3336858461282936}
2022-11-28 00:49:29,645 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:29,645 INFO:     Epoch: 55
2022-11-28 00:49:30,408 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4634380228817463, 'Total loss': 0.4634380228817463} | train loss {'Reaction outcome loss': 0.32155379677108425, 'Total loss': 0.32155379677108425}
2022-11-28 00:49:30,408 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:30,408 INFO:     Epoch: 56
2022-11-28 00:49:31,168 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4221918342465704, 'Total loss': 0.4221918342465704} | train loss {'Reaction outcome loss': 0.3212810636758201, 'Total loss': 0.3212810636758201}
2022-11-28 00:49:31,169 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:31,169 INFO:     Epoch: 57
2022-11-28 00:49:31,922 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4579906263812022, 'Total loss': 0.4579906263812022} | train loss {'Reaction outcome loss': 0.315960198940581, 'Total loss': 0.315960198940581}
2022-11-28 00:49:31,922 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:31,922 INFO:     Epoch: 58
2022-11-28 00:49:32,681 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43376877294345334, 'Total loss': 0.43376877294345334} | train loss {'Reaction outcome loss': 0.3170826901914552, 'Total loss': 0.3170826901914552}
2022-11-28 00:49:32,681 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:32,681 INFO:     Epoch: 59
2022-11-28 00:49:33,434 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44629957763986156, 'Total loss': 0.44629957763986156} | train loss {'Reaction outcome loss': 0.31581220489281875, 'Total loss': 0.31581220489281875}
2022-11-28 00:49:33,434 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:33,434 INFO:     Epoch: 60
2022-11-28 00:49:34,183 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4804031461138617, 'Total loss': 0.4804031461138617} | train loss {'Reaction outcome loss': 0.32713503936524335, 'Total loss': 0.32713503936524335}
2022-11-28 00:49:34,183 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:34,183 INFO:     Epoch: 61
2022-11-28 00:49:34,930 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48383856226097455, 'Total loss': 0.48383856226097455} | train loss {'Reaction outcome loss': 0.3295725875596331, 'Total loss': 0.3295725875596331}
2022-11-28 00:49:34,930 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:34,930 INFO:     Epoch: 62
2022-11-28 00:49:35,679 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44818390668793157, 'Total loss': 0.44818390668793157} | train loss {'Reaction outcome loss': 0.32079280169326285, 'Total loss': 0.32079280169326285}
2022-11-28 00:49:35,679 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:35,679 INFO:     Epoch: 63
2022-11-28 00:49:36,426 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45322156799110497, 'Total loss': 0.45322156799110497} | train loss {'Reaction outcome loss': 0.32071613258472925, 'Total loss': 0.32071613258472925}
2022-11-28 00:49:36,426 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:36,426 INFO:     Epoch: 64
2022-11-28 00:49:37,174 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44228096170858905, 'Total loss': 0.44228096170858905} | train loss {'Reaction outcome loss': 0.3244029147784237, 'Total loss': 0.3244029147784237}
2022-11-28 00:49:37,174 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:37,174 INFO:     Epoch: 65
2022-11-28 00:49:37,925 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4326011579145085, 'Total loss': 0.4326011579145085} | train loss {'Reaction outcome loss': 0.3260701786470317, 'Total loss': 0.3260701786470317}
2022-11-28 00:49:37,925 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:37,925 INFO:     Epoch: 66
2022-11-28 00:49:38,672 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4382361861115152, 'Total loss': 0.4382361861115152} | train loss {'Reaction outcome loss': 0.3199832179708037, 'Total loss': 0.3199832179708037}
2022-11-28 00:49:38,672 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:38,672 INFO:     Epoch: 67
2022-11-28 00:49:39,418 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4852543093941428, 'Total loss': 0.4852543093941428} | train loss {'Reaction outcome loss': 0.329977301239726, 'Total loss': 0.329977301239726}
2022-11-28 00:49:39,419 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:39,419 INFO:     Epoch: 68
2022-11-28 00:49:40,167 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4818112911148505, 'Total loss': 0.4818112911148505} | train loss {'Reaction outcome loss': 0.3306389696865912, 'Total loss': 0.3306389696865912}
2022-11-28 00:49:40,167 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:40,167 INFO:     Epoch: 69
2022-11-28 00:49:40,914 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45826417580246925, 'Total loss': 0.45826417580246925} | train loss {'Reaction outcome loss': 0.32223654568557314, 'Total loss': 0.32223654568557314}
2022-11-28 00:49:40,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:40,914 INFO:     Epoch: 70
2022-11-28 00:49:41,664 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4292203309861096, 'Total loss': 0.4292203309861096} | train loss {'Reaction outcome loss': 0.3184654827414435, 'Total loss': 0.3184654827414435}
2022-11-28 00:49:41,664 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:41,664 INFO:     Epoch: 71
2022-11-28 00:49:42,413 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44484092362902383, 'Total loss': 0.44484092362902383} | train loss {'Reaction outcome loss': 0.31003295986155266, 'Total loss': 0.31003295986155266}
2022-11-28 00:49:42,414 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:42,414 INFO:     Epoch: 72
2022-11-28 00:49:43,159 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4198574610054493, 'Total loss': 0.4198574610054493} | train loss {'Reaction outcome loss': 0.32492549727229697, 'Total loss': 0.32492549727229697}
2022-11-28 00:49:43,159 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:43,159 INFO:     Epoch: 73
2022-11-28 00:49:43,908 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4631189734420993, 'Total loss': 0.4631189734420993} | train loss {'Reaction outcome loss': 0.31024223481595276, 'Total loss': 0.31024223481595276}
2022-11-28 00:49:43,909 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:43,909 INFO:     Epoch: 74
2022-11-28 00:49:44,658 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4921689886938442, 'Total loss': 0.4921689886938442} | train loss {'Reaction outcome loss': 0.31470765438881, 'Total loss': 0.31470765438881}
2022-11-28 00:49:44,658 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:44,658 INFO:     Epoch: 75
2022-11-28 00:49:45,404 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43020645596764306, 'Total loss': 0.43020645596764306} | train loss {'Reaction outcome loss': 0.331515676096866, 'Total loss': 0.331515676096866}
2022-11-28 00:49:45,404 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:45,404 INFO:     Epoch: 76
2022-11-28 00:49:46,152 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4225679883225398, 'Total loss': 0.4225679883225398} | train loss {'Reaction outcome loss': 0.3670186964033345, 'Total loss': 0.3670186964033345}
2022-11-28 00:49:46,152 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:46,152 INFO:     Epoch: 77
2022-11-28 00:49:46,901 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43858899209987035, 'Total loss': 0.43858899209987035} | train loss {'Reaction outcome loss': 0.32632044253320347, 'Total loss': 0.32632044253320347}
2022-11-28 00:49:46,901 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:46,901 INFO:     Epoch: 78
2022-11-28 00:49:47,647 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45608444952151994, 'Total loss': 0.45608444952151994} | train loss {'Reaction outcome loss': 0.3224596671532907, 'Total loss': 0.3224596671532907}
2022-11-28 00:49:47,648 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:47,648 INFO:     Epoch: 79
2022-11-28 00:49:48,396 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4563790481876243, 'Total loss': 0.4563790481876243} | train loss {'Reaction outcome loss': 0.3293364821718289, 'Total loss': 0.3293364821718289}
2022-11-28 00:49:48,396 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:48,396 INFO:     Epoch: 80
2022-11-28 00:49:49,145 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.414691355756738, 'Total loss': 0.414691355756738} | train loss {'Reaction outcome loss': 0.32511658423584, 'Total loss': 0.32511658423584}
2022-11-28 00:49:49,145 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:49,145 INFO:     Epoch: 81
2022-11-28 00:49:49,890 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4200867146930911, 'Total loss': 0.4200867146930911} | train loss {'Reaction outcome loss': 0.3311670040674055, 'Total loss': 0.3311670040674055}
2022-11-28 00:49:49,890 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:49,890 INFO:     Epoch: 82
2022-11-28 00:49:50,641 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43995997428216715, 'Total loss': 0.43995997428216715} | train loss {'Reaction outcome loss': 0.3212396474743662, 'Total loss': 0.3212396474743662}
2022-11-28 00:49:50,642 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:50,642 INFO:     Epoch: 83
2022-11-28 00:49:51,389 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4453536800362847, 'Total loss': 0.4453536800362847} | train loss {'Reaction outcome loss': 0.3318895649766787, 'Total loss': 0.3318895649766787}
2022-11-28 00:49:51,389 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:51,389 INFO:     Epoch: 84
2022-11-28 00:49:52,137 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4510328701951287, 'Total loss': 0.4510328701951287} | train loss {'Reaction outcome loss': 0.3211684071266579, 'Total loss': 0.3211684071266579}
2022-11-28 00:49:52,137 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:52,137 INFO:     Epoch: 85
2022-11-28 00:49:52,885 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42005391825329175, 'Total loss': 0.42005391825329175} | train loss {'Reaction outcome loss': 0.3164956074656715, 'Total loss': 0.3164956074656715}
2022-11-28 00:49:52,886 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:52,886 INFO:     Epoch: 86
2022-11-28 00:49:53,634 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4133774126795205, 'Total loss': 0.4133774126795205} | train loss {'Reaction outcome loss': 0.32022185361216426, 'Total loss': 0.32022185361216426}
2022-11-28 00:49:53,634 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:53,634 INFO:     Epoch: 87
2022-11-28 00:49:54,382 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43711791322989896, 'Total loss': 0.43711791322989896} | train loss {'Reaction outcome loss': 0.3254861553550249, 'Total loss': 0.3254861553550249}
2022-11-28 00:49:54,382 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:54,382 INFO:     Epoch: 88
2022-11-28 00:49:55,129 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4429324935613708, 'Total loss': 0.4429324935613708} | train loss {'Reaction outcome loss': 0.32297535457833093, 'Total loss': 0.32297535457833093}
2022-11-28 00:49:55,129 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:55,129 INFO:     Epoch: 89
2022-11-28 00:49:55,877 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43714525347406213, 'Total loss': 0.43714525347406213} | train loss {'Reaction outcome loss': 0.32800512323495346, 'Total loss': 0.32800512323495346}
2022-11-28 00:49:55,877 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:55,877 INFO:     Epoch: 90
2022-11-28 00:49:56,627 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49321792579509993, 'Total loss': 0.49321792579509993} | train loss {'Reaction outcome loss': 0.3256706401313606, 'Total loss': 0.3256706401313606}
2022-11-28 00:49:56,627 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:56,628 INFO:     Epoch: 91
2022-11-28 00:49:57,372 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4361663687635552, 'Total loss': 0.4361663687635552} | train loss {'Reaction outcome loss': 0.32602439181283416, 'Total loss': 0.32602439181283416}
2022-11-28 00:49:57,373 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:57,373 INFO:     Epoch: 92
2022-11-28 00:49:58,119 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.446210385046222, 'Total loss': 0.446210385046222} | train loss {'Reaction outcome loss': 0.3308270223106933, 'Total loss': 0.3308270223106933}
2022-11-28 00:49:58,119 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:58,119 INFO:     Epoch: 93
2022-11-28 00:49:58,865 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.438633311370557, 'Total loss': 0.438633311370557} | train loss {'Reaction outcome loss': 0.3149239390424871, 'Total loss': 0.3149239390424871}
2022-11-28 00:49:58,865 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:58,866 INFO:     Epoch: 94
2022-11-28 00:49:59,620 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4608271389522336, 'Total loss': 0.4608271389522336} | train loss {'Reaction outcome loss': 0.3270310407866411, 'Total loss': 0.3270310407866411}
2022-11-28 00:49:59,621 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:49:59,621 INFO:     Epoch: 95
2022-11-28 00:50:00,369 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41407840698957443, 'Total loss': 0.41407840698957443} | train loss {'Reaction outcome loss': 0.30643032988917973, 'Total loss': 0.30643032988917973}
2022-11-28 00:50:00,369 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:00,369 INFO:     Epoch: 96
2022-11-28 00:50:01,122 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44650477916002274, 'Total loss': 0.44650477916002274} | train loss {'Reaction outcome loss': 0.3138591371314517, 'Total loss': 0.3138591371314517}
2022-11-28 00:50:01,122 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:01,122 INFO:     Epoch: 97
2022-11-28 00:50:01,874 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41317453811114485, 'Total loss': 0.41317453811114485} | train loss {'Reaction outcome loss': 0.30840080752840354, 'Total loss': 0.30840080752840354}
2022-11-28 00:50:01,874 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:01,874 INFO:     Epoch: 98
2022-11-28 00:50:02,622 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44990464401516045, 'Total loss': 0.44990464401516045} | train loss {'Reaction outcome loss': 0.3203540258260391, 'Total loss': 0.3203540258260391}
2022-11-28 00:50:02,623 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:02,623 INFO:     Epoch: 99
2022-11-28 00:50:03,370 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4731629578904672, 'Total loss': 0.4731629578904672} | train loss {'Reaction outcome loss': 0.34074092819261165, 'Total loss': 0.34074092819261165}
2022-11-28 00:50:03,370 INFO:     Best model found after epoch 35 of 100.
2022-11-28 00:50:03,371 INFO:   Done with stage: TRAINING
2022-11-28 00:50:03,371 INFO:   Starting stage: EVALUATION
2022-11-28 00:50:03,492 INFO:   Done with stage: EVALUATION
2022-11-28 00:50:03,492 INFO:   Leaving out SEQ value Fold_9
2022-11-28 00:50:03,504 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 00:50:03,504 INFO:   Starting stage: FEATURE SCALING
2022-11-28 00:50:04,151 INFO:   Done with stage: FEATURE SCALING
2022-11-28 00:50:04,152 INFO:   Starting stage: SCALING TARGETS
2022-11-28 00:50:04,222 INFO:   Done with stage: SCALING TARGETS
2022-11-28 00:50:04,222 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:50:04,222 INFO:     No hyperparam tuning for this model
2022-11-28 00:50:04,222 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:50:04,222 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 00:50:04,223 INFO:     None feature selector for col prot
2022-11-28 00:50:04,223 INFO:     None feature selector for col prot
2022-11-28 00:50:04,223 INFO:     None feature selector for col prot
2022-11-28 00:50:04,224 INFO:     None feature selector for col chem
2022-11-28 00:50:04,224 INFO:     None feature selector for col chem
2022-11-28 00:50:04,224 INFO:     None feature selector for col chem
2022-11-28 00:50:04,224 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 00:50:04,224 INFO:   Starting stage: BUILD MODEL
2022-11-28 00:50:04,225 INFO:     Number of params in model 169741
2022-11-28 00:50:04,228 INFO:   Done with stage: BUILD MODEL
2022-11-28 00:50:04,229 INFO:   Starting stage: TRAINING
2022-11-28 00:50:04,283 INFO:     Val loss before train {'Reaction outcome loss': 1.0236640125513077, 'Total loss': 1.0236640125513077}
2022-11-28 00:50:04,283 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:04,284 INFO:     Epoch: 0
2022-11-28 00:50:05,032 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5103638774969361, 'Total loss': 0.5103638774969361} | train loss {'Reaction outcome loss': 0.638528820353481, 'Total loss': 0.638528820353481}
2022-11-28 00:50:05,032 INFO:     Found new best model at epoch 0
2022-11-28 00:50:05,033 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:05,033 INFO:     Epoch: 1
2022-11-28 00:50:05,781 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4770285102792762, 'Total loss': 0.4770285102792762} | train loss {'Reaction outcome loss': 0.5098435324937226, 'Total loss': 0.5098435324937226}
2022-11-28 00:50:05,782 INFO:     Found new best model at epoch 1
2022-11-28 00:50:05,782 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:05,782 INFO:     Epoch: 2
2022-11-28 00:50:06,531 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4817935986952348, 'Total loss': 0.4817935986952348} | train loss {'Reaction outcome loss': 0.4705315099554023, 'Total loss': 0.4705315099554023}
2022-11-28 00:50:06,532 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:06,532 INFO:     Epoch: 3
2022-11-28 00:50:07,278 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46364832161502406, 'Total loss': 0.46364832161502406} | train loss {'Reaction outcome loss': 0.46537905865111334, 'Total loss': 0.46537905865111334}
2022-11-28 00:50:07,279 INFO:     Found new best model at epoch 3
2022-11-28 00:50:07,279 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:07,279 INFO:     Epoch: 4
2022-11-28 00:50:08,024 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47087257355451584, 'Total loss': 0.47087257355451584} | train loss {'Reaction outcome loss': 0.43383343212366826, 'Total loss': 0.43383343212366826}
2022-11-28 00:50:08,024 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:08,024 INFO:     Epoch: 5
2022-11-28 00:50:08,768 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4211769268255342, 'Total loss': 0.4211769268255342} | train loss {'Reaction outcome loss': 0.4174468835989232, 'Total loss': 0.4174468835989232}
2022-11-28 00:50:08,768 INFO:     Found new best model at epoch 5
2022-11-28 00:50:08,769 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:08,769 INFO:     Epoch: 6
2022-11-28 00:50:09,516 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45543175360018556, 'Total loss': 0.45543175360018556} | train loss {'Reaction outcome loss': 0.4061313193095358, 'Total loss': 0.4061313193095358}
2022-11-28 00:50:09,517 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:09,517 INFO:     Epoch: 7
2022-11-28 00:50:10,263 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4688170393082229, 'Total loss': 0.4688170393082229} | train loss {'Reaction outcome loss': 0.41876742641935466, 'Total loss': 0.41876742641935466}
2022-11-28 00:50:10,263 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:10,263 INFO:     Epoch: 8
2022-11-28 00:50:11,012 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4358145220374519, 'Total loss': 0.4358145220374519} | train loss {'Reaction outcome loss': 0.3945546152620663, 'Total loss': 0.3945546152620663}
2022-11-28 00:50:11,012 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:11,013 INFO:     Epoch: 9
2022-11-28 00:50:11,763 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4404975436627865, 'Total loss': 0.4404975436627865} | train loss {'Reaction outcome loss': 0.386146143078804, 'Total loss': 0.386146143078804}
2022-11-28 00:50:11,763 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:11,763 INFO:     Epoch: 10
2022-11-28 00:50:12,508 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4296664273874326, 'Total loss': 0.4296664273874326} | train loss {'Reaction outcome loss': 0.3753138973042067, 'Total loss': 0.3753138973042067}
2022-11-28 00:50:12,508 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:12,508 INFO:     Epoch: 11
2022-11-28 00:50:13,255 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4135810709135099, 'Total loss': 0.4135810709135099} | train loss {'Reaction outcome loss': 0.37452432128642255, 'Total loss': 0.37452432128642255}
2022-11-28 00:50:13,255 INFO:     Found new best model at epoch 11
2022-11-28 00:50:13,255 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:13,256 INFO:     Epoch: 12
2022-11-28 00:50:14,000 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4416402591900392, 'Total loss': 0.4416402591900392} | train loss {'Reaction outcome loss': 0.3751438540606364, 'Total loss': 0.3751438540606364}
2022-11-28 00:50:14,000 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:14,000 INFO:     Epoch: 13
2022-11-28 00:50:14,747 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43991021100770344, 'Total loss': 0.43991021100770344} | train loss {'Reaction outcome loss': 0.3674621408039832, 'Total loss': 0.3674621408039832}
2022-11-28 00:50:14,748 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:14,748 INFO:     Epoch: 14
2022-11-28 00:50:15,496 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.442608022893017, 'Total loss': 0.442608022893017} | train loss {'Reaction outcome loss': 0.3607744867498666, 'Total loss': 0.3607744867498666}
2022-11-28 00:50:15,496 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:15,496 INFO:     Epoch: 15
2022-11-28 00:50:16,239 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43991507386619394, 'Total loss': 0.43991507386619394} | train loss {'Reaction outcome loss': 0.3607513190281053, 'Total loss': 0.3607513190281053}
2022-11-28 00:50:16,239 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:16,239 INFO:     Epoch: 16
2022-11-28 00:50:16,989 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45021323013034736, 'Total loss': 0.45021323013034736} | train loss {'Reaction outcome loss': 0.35357613665869964, 'Total loss': 0.35357613665869964}
2022-11-28 00:50:16,989 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:16,989 INFO:     Epoch: 17
2022-11-28 00:50:17,733 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46083874119953677, 'Total loss': 0.46083874119953677} | train loss {'Reaction outcome loss': 0.3548230978882747, 'Total loss': 0.3548230978882747}
2022-11-28 00:50:17,734 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:17,734 INFO:     Epoch: 18
2022-11-28 00:50:18,477 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41332677684047003, 'Total loss': 0.41332677684047003} | train loss {'Reaction outcome loss': 0.3623919559393817, 'Total loss': 0.3623919559393817}
2022-11-28 00:50:18,477 INFO:     Found new best model at epoch 18
2022-11-28 00:50:18,478 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:18,478 INFO:     Epoch: 19
2022-11-28 00:50:19,226 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4394346648319201, 'Total loss': 0.4394346648319201} | train loss {'Reaction outcome loss': 0.35191552149818134, 'Total loss': 0.35191552149818134}
2022-11-28 00:50:19,226 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:19,227 INFO:     Epoch: 20
2022-11-28 00:50:19,972 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41242903149263427, 'Total loss': 0.41242903149263427} | train loss {'Reaction outcome loss': 0.35071479941262046, 'Total loss': 0.35071479941262046}
2022-11-28 00:50:19,972 INFO:     Found new best model at epoch 20
2022-11-28 00:50:19,972 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:19,973 INFO:     Epoch: 21
2022-11-28 00:50:20,718 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40262595835057174, 'Total loss': 0.40262595835057174} | train loss {'Reaction outcome loss': 0.34183184847778636, 'Total loss': 0.34183184847778636}
2022-11-28 00:50:20,718 INFO:     Found new best model at epoch 21
2022-11-28 00:50:20,719 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:20,719 INFO:     Epoch: 22
2022-11-28 00:50:21,466 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45155281302603806, 'Total loss': 0.45155281302603806} | train loss {'Reaction outcome loss': 0.3397284586299286, 'Total loss': 0.3397284586299286}
2022-11-28 00:50:21,467 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:21,467 INFO:     Epoch: 23
2022-11-28 00:50:22,214 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.38792081448164856, 'Total loss': 0.38792081448164856} | train loss {'Reaction outcome loss': 0.34540487521211144, 'Total loss': 0.34540487521211144}
2022-11-28 00:50:22,215 INFO:     Found new best model at epoch 23
2022-11-28 00:50:22,215 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:22,216 INFO:     Epoch: 24
2022-11-28 00:50:22,960 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41333875906738365, 'Total loss': 0.41333875906738365} | train loss {'Reaction outcome loss': 0.33663769886802564, 'Total loss': 0.33663769886802564}
2022-11-28 00:50:22,960 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:22,960 INFO:     Epoch: 25
2022-11-28 00:50:23,707 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42766877196051856, 'Total loss': 0.42766877196051856} | train loss {'Reaction outcome loss': 0.3373450176631994, 'Total loss': 0.3373450176631994}
2022-11-28 00:50:23,708 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:23,708 INFO:     Epoch: 26
2022-11-28 00:50:24,452 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4671511450274424, 'Total loss': 0.4671511450274424} | train loss {'Reaction outcome loss': 0.331308716354771, 'Total loss': 0.331308716354771}
2022-11-28 00:50:24,452 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:24,452 INFO:     Epoch: 27
2022-11-28 00:50:25,198 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4183868007226424, 'Total loss': 0.4183868007226424} | train loss {'Reaction outcome loss': 0.33472502705177315, 'Total loss': 0.33472502705177315}
2022-11-28 00:50:25,198 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:25,198 INFO:     Epoch: 28
2022-11-28 00:50:25,946 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4048608456822959, 'Total loss': 0.4048608456822959} | train loss {'Reaction outcome loss': 0.34545107599091435, 'Total loss': 0.34545107599091435}
2022-11-28 00:50:25,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:25,946 INFO:     Epoch: 29
2022-11-28 00:50:26,695 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4232992015101693, 'Total loss': 0.4232992015101693} | train loss {'Reaction outcome loss': 0.3303060181587859, 'Total loss': 0.3303060181587859}
2022-11-28 00:50:26,695 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:26,695 INFO:     Epoch: 30
2022-11-28 00:50:27,443 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.424917072057724, 'Total loss': 0.424917072057724} | train loss {'Reaction outcome loss': 0.33503884466191536, 'Total loss': 0.33503884466191536}
2022-11-28 00:50:27,443 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:27,443 INFO:     Epoch: 31
2022-11-28 00:50:28,192 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4236216357147152, 'Total loss': 0.4236216357147152} | train loss {'Reaction outcome loss': 0.3391287592107709, 'Total loss': 0.3391287592107709}
2022-11-28 00:50:28,192 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:28,192 INFO:     Epoch: 32
2022-11-28 00:50:28,946 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40139435820112174, 'Total loss': 0.40139435820112174} | train loss {'Reaction outcome loss': 0.3299450992874288, 'Total loss': 0.3299450992874288}
2022-11-28 00:50:28,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:28,946 INFO:     Epoch: 33
2022-11-28 00:50:29,699 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4080761735412208, 'Total loss': 0.4080761735412208} | train loss {'Reaction outcome loss': 0.34030236352823284, 'Total loss': 0.34030236352823284}
2022-11-28 00:50:29,699 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:29,699 INFO:     Epoch: 34
2022-11-28 00:50:30,448 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41100051863627, 'Total loss': 0.41100051863627} | train loss {'Reaction outcome loss': 0.3254468134766528, 'Total loss': 0.3254468134766528}
2022-11-28 00:50:30,448 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:30,448 INFO:     Epoch: 35
2022-11-28 00:50:31,198 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3980115218596025, 'Total loss': 0.3980115218596025} | train loss {'Reaction outcome loss': 0.3322615112490982, 'Total loss': 0.3322615112490982}
2022-11-28 00:50:31,198 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:31,198 INFO:     Epoch: 36
2022-11-28 00:50:31,947 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4094774397513406, 'Total loss': 0.4094774397513406} | train loss {'Reaction outcome loss': 0.3453959090265668, 'Total loss': 0.3453959090265668}
2022-11-28 00:50:31,947 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:31,947 INFO:     Epoch: 37
2022-11-28 00:50:32,694 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44849569215015933, 'Total loss': 0.44849569215015933} | train loss {'Reaction outcome loss': 0.3393280937483436, 'Total loss': 0.3393280937483436}
2022-11-28 00:50:32,695 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:32,695 INFO:     Epoch: 38
2022-11-28 00:50:33,440 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4159935010089116, 'Total loss': 0.4159935010089116} | train loss {'Reaction outcome loss': 0.3315062848964201, 'Total loss': 0.3315062848964201}
2022-11-28 00:50:33,440 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:33,440 INFO:     Epoch: 39
2022-11-28 00:50:34,188 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3998538296331059, 'Total loss': 0.3998538296331059} | train loss {'Reaction outcome loss': 0.32697158243492064, 'Total loss': 0.32697158243492064}
2022-11-28 00:50:34,189 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:34,189 INFO:     Epoch: 40
2022-11-28 00:50:34,939 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42022071981971915, 'Total loss': 0.42022071981971915} | train loss {'Reaction outcome loss': 0.3287864344214327, 'Total loss': 0.3287864344214327}
2022-11-28 00:50:34,939 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:34,939 INFO:     Epoch: 41
2022-11-28 00:50:35,684 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4244613667569039, 'Total loss': 0.4244613667569039} | train loss {'Reaction outcome loss': 0.32185634439773403, 'Total loss': 0.32185634439773403}
2022-11-28 00:50:35,684 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:35,684 INFO:     Epoch: 42
2022-11-28 00:50:36,429 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39755076271566475, 'Total loss': 0.39755076271566475} | train loss {'Reaction outcome loss': 0.32180134333700305, 'Total loss': 0.32180134333700305}
2022-11-28 00:50:36,429 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:36,429 INFO:     Epoch: 43
2022-11-28 00:50:37,176 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4248296137560498, 'Total loss': 0.4248296137560498} | train loss {'Reaction outcome loss': 0.32969004292981813, 'Total loss': 0.32969004292981813}
2022-11-28 00:50:37,176 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:37,176 INFO:     Epoch: 44
2022-11-28 00:50:37,926 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40477694672617043, 'Total loss': 0.40477694672617043} | train loss {'Reaction outcome loss': 0.32159091233603865, 'Total loss': 0.32159091233603865}
2022-11-28 00:50:37,926 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:37,926 INFO:     Epoch: 45
2022-11-28 00:50:38,671 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4381877414204858, 'Total loss': 0.4381877414204858} | train loss {'Reaction outcome loss': 0.31928934799394143, 'Total loss': 0.31928934799394143}
2022-11-28 00:50:38,671 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:38,671 INFO:     Epoch: 46
2022-11-28 00:50:39,421 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.446934465657581, 'Total loss': 0.446934465657581} | train loss {'Reaction outcome loss': 0.3222434746350354, 'Total loss': 0.3222434746350354}
2022-11-28 00:50:39,421 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:39,421 INFO:     Epoch: 47
2022-11-28 00:50:40,170 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4207536954094063, 'Total loss': 0.4207536954094063} | train loss {'Reaction outcome loss': 0.33024914656588544, 'Total loss': 0.33024914656588544}
2022-11-28 00:50:40,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:40,170 INFO:     Epoch: 48
2022-11-28 00:50:40,922 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4319490488957275, 'Total loss': 0.4319490488957275} | train loss {'Reaction outcome loss': 0.31551448041610874, 'Total loss': 0.31551448041610874}
2022-11-28 00:50:40,923 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:40,923 INFO:     Epoch: 49
2022-11-28 00:50:41,670 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4354244294491681, 'Total loss': 0.4354244294491681} | train loss {'Reaction outcome loss': 0.3411636132943003, 'Total loss': 0.3411636132943003}
2022-11-28 00:50:41,671 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:41,671 INFO:     Epoch: 50
2022-11-28 00:50:42,418 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43901405889879574, 'Total loss': 0.43901405889879574} | train loss {'Reaction outcome loss': 0.3419219039471043, 'Total loss': 0.3419219039471043}
2022-11-28 00:50:42,418 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:42,418 INFO:     Epoch: 51
2022-11-28 00:50:43,170 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45322765613144095, 'Total loss': 0.45322765613144095} | train loss {'Reaction outcome loss': 0.31737468522117446, 'Total loss': 0.31737468522117446}
2022-11-28 00:50:43,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:43,170 INFO:     Epoch: 52
2022-11-28 00:50:43,920 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4507866518741304, 'Total loss': 0.4507866518741304} | train loss {'Reaction outcome loss': 0.3218748877465966, 'Total loss': 0.3218748877465966}
2022-11-28 00:50:43,920 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:43,920 INFO:     Epoch: 53
2022-11-28 00:50:44,669 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44163664091717114, 'Total loss': 0.44163664091717114} | train loss {'Reaction outcome loss': 0.3848063354550103, 'Total loss': 0.3848063354550103}
2022-11-28 00:50:44,669 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:44,669 INFO:     Epoch: 54
2022-11-28 00:50:45,415 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47365163097327406, 'Total loss': 0.47365163097327406} | train loss {'Reaction outcome loss': 0.40217633494119415, 'Total loss': 0.40217633494119415}
2022-11-28 00:50:45,415 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:45,415 INFO:     Epoch: 55
2022-11-28 00:50:46,162 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4303251565857367, 'Total loss': 0.4303251565857367} | train loss {'Reaction outcome loss': 0.33322112168833945, 'Total loss': 0.33322112168833945}
2022-11-28 00:50:46,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:46,163 INFO:     Epoch: 56
2022-11-28 00:50:46,912 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4003248248587955, 'Total loss': 0.4003248248587955} | train loss {'Reaction outcome loss': 0.3238991081473316, 'Total loss': 0.3238991081473316}
2022-11-28 00:50:46,912 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:46,912 INFO:     Epoch: 57
2022-11-28 00:50:47,663 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3871586143293164, 'Total loss': 0.3871586143293164} | train loss {'Reaction outcome loss': 0.3280510542064015, 'Total loss': 0.3280510542064015}
2022-11-28 00:50:47,663 INFO:     Found new best model at epoch 57
2022-11-28 00:50:47,664 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:47,664 INFO:     Epoch: 58
2022-11-28 00:50:48,413 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4517615721984343, 'Total loss': 0.4517615721984343} | train loss {'Reaction outcome loss': 0.32049588006939966, 'Total loss': 0.32049588006939966}
2022-11-28 00:50:48,413 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:48,413 INFO:     Epoch: 59
2022-11-28 00:50:49,164 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40936405228620226, 'Total loss': 0.40936405228620226} | train loss {'Reaction outcome loss': 0.33095331182458293, 'Total loss': 0.33095331182458293}
2022-11-28 00:50:49,164 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:49,164 INFO:     Epoch: 60
2022-11-28 00:50:49,909 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45792560355568473, 'Total loss': 0.45792560355568473} | train loss {'Reaction outcome loss': 0.3102656496982825, 'Total loss': 0.3102656496982825}
2022-11-28 00:50:49,909 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:49,909 INFO:     Epoch: 61
2022-11-28 00:50:50,658 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42503649910742586, 'Total loss': 0.42503649910742586} | train loss {'Reaction outcome loss': 0.32785491042050274, 'Total loss': 0.32785491042050274}
2022-11-28 00:50:50,658 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:50,658 INFO:     Epoch: 62
2022-11-28 00:50:51,406 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42805514653975313, 'Total loss': 0.42805514653975313} | train loss {'Reaction outcome loss': 0.317465517162779, 'Total loss': 0.317465517162779}
2022-11-28 00:50:51,406 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:51,406 INFO:     Epoch: 63
2022-11-28 00:50:52,151 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4122444645247676, 'Total loss': 0.4122444645247676} | train loss {'Reaction outcome loss': 0.32097020874983867, 'Total loss': 0.32097020874983867}
2022-11-28 00:50:52,151 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:52,151 INFO:     Epoch: 64
2022-11-28 00:50:52,896 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41085873781280086, 'Total loss': 0.41085873781280086} | train loss {'Reaction outcome loss': 0.33562513347338085, 'Total loss': 0.33562513347338085}
2022-11-28 00:50:52,897 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:52,897 INFO:     Epoch: 65
2022-11-28 00:50:53,646 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42332537878643384, 'Total loss': 0.42332537878643384} | train loss {'Reaction outcome loss': 0.3343638605230793, 'Total loss': 0.3343638605230793}
2022-11-28 00:50:53,646 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:53,646 INFO:     Epoch: 66
2022-11-28 00:50:54,391 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44308632578362117, 'Total loss': 0.44308632578362117} | train loss {'Reaction outcome loss': 0.3198335090810471, 'Total loss': 0.3198335090810471}
2022-11-28 00:50:54,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:54,391 INFO:     Epoch: 67
2022-11-28 00:50:55,139 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42732145298611035, 'Total loss': 0.42732145298611035} | train loss {'Reaction outcome loss': 0.3767027547846922, 'Total loss': 0.3767027547846922}
2022-11-28 00:50:55,139 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:55,139 INFO:     Epoch: 68
2022-11-28 00:50:55,890 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4405699602582238, 'Total loss': 0.4405699602582238} | train loss {'Reaction outcome loss': 0.3272612463185179, 'Total loss': 0.3272612463185179}
2022-11-28 00:50:55,890 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:55,890 INFO:     Epoch: 69
2022-11-28 00:50:56,640 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.384312518787655, 'Total loss': 0.384312518787655} | train loss {'Reaction outcome loss': 0.32074962734331486, 'Total loss': 0.32074962734331486}
2022-11-28 00:50:56,641 INFO:     Found new best model at epoch 69
2022-11-28 00:50:56,641 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:56,641 INFO:     Epoch: 70
2022-11-28 00:50:57,391 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4568401487036185, 'Total loss': 0.4568401487036185} | train loss {'Reaction outcome loss': 0.3345632989276276, 'Total loss': 0.3345632989276276}
2022-11-28 00:50:57,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:57,391 INFO:     Epoch: 71
2022-11-28 00:50:58,139 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4165146283128045, 'Total loss': 0.4165146283128045} | train loss {'Reaction outcome loss': 0.3373383977243051, 'Total loss': 0.3373383977243051}
2022-11-28 00:50:58,139 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:58,139 INFO:     Epoch: 72
2022-11-28 00:50:58,891 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41895556856285443, 'Total loss': 0.41895556856285443} | train loss {'Reaction outcome loss': 0.33708343692859144, 'Total loss': 0.33708343692859144}
2022-11-28 00:50:58,891 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:58,891 INFO:     Epoch: 73
2022-11-28 00:50:59,640 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40471515161069954, 'Total loss': 0.40471515161069954} | train loss {'Reaction outcome loss': 0.31302442192759833, 'Total loss': 0.31302442192759833}
2022-11-28 00:50:59,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:50:59,640 INFO:     Epoch: 74
2022-11-28 00:51:00,389 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42376973310654814, 'Total loss': 0.42376973310654814} | train loss {'Reaction outcome loss': 0.31845977247847235, 'Total loss': 0.31845977247847235}
2022-11-28 00:51:00,389 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:00,389 INFO:     Epoch: 75
2022-11-28 00:51:01,136 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40940629927949473, 'Total loss': 0.40940629927949473} | train loss {'Reaction outcome loss': 0.3193634947392381, 'Total loss': 0.3193634947392381}
2022-11-28 00:51:01,136 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:01,136 INFO:     Epoch: 76
2022-11-28 00:51:01,888 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3894926981831139, 'Total loss': 0.3894926981831139} | train loss {'Reaction outcome loss': 0.31236515115750463, 'Total loss': 0.31236515115750463}
2022-11-28 00:51:01,888 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:01,888 INFO:     Epoch: 77
2022-11-28 00:51:02,638 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3892204907130111, 'Total loss': 0.3892204907130111} | train loss {'Reaction outcome loss': 0.3018710321788243, 'Total loss': 0.3018710321788243}
2022-11-28 00:51:02,638 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:02,638 INFO:     Epoch: 78
2022-11-28 00:51:03,385 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43090797385031526, 'Total loss': 0.43090797385031526} | train loss {'Reaction outcome loss': 0.32349354987926326, 'Total loss': 0.32349354987926326}
2022-11-28 00:51:03,385 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:03,385 INFO:     Epoch: 79
2022-11-28 00:51:04,132 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45986879007382825, 'Total loss': 0.45986879007382825} | train loss {'Reaction outcome loss': 0.32120017277883733, 'Total loss': 0.32120017277883733}
2022-11-28 00:51:04,132 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:04,132 INFO:     Epoch: 80
2022-11-28 00:51:04,873 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38770525208251044, 'Total loss': 0.38770525208251044} | train loss {'Reaction outcome loss': 0.3216470216630924, 'Total loss': 0.3216470216630924}
2022-11-28 00:51:04,873 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:04,873 INFO:     Epoch: 81
2022-11-28 00:51:05,621 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4221311296251687, 'Total loss': 0.4221311296251687} | train loss {'Reaction outcome loss': 0.31957038232174356, 'Total loss': 0.31957038232174356}
2022-11-28 00:51:05,622 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:05,622 INFO:     Epoch: 82
2022-11-28 00:51:06,368 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4206430827352134, 'Total loss': 0.4206430827352134} | train loss {'Reaction outcome loss': 0.3179065086822278, 'Total loss': 0.3179065086822278}
2022-11-28 00:51:06,368 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:06,368 INFO:     Epoch: 83
2022-11-28 00:51:07,116 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39898738061839883, 'Total loss': 0.39898738061839883} | train loss {'Reaction outcome loss': 0.3680050297063372, 'Total loss': 0.3680050297063372}
2022-11-28 00:51:07,116 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:07,116 INFO:     Epoch: 84
2022-11-28 00:51:07,866 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4078857627781955, 'Total loss': 0.4078857627781955} | train loss {'Reaction outcome loss': 0.33052378355974127, 'Total loss': 0.33052378355974127}
2022-11-28 00:51:07,866 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:07,866 INFO:     Epoch: 85
2022-11-28 00:51:08,606 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4312655119733377, 'Total loss': 0.4312655119733377} | train loss {'Reaction outcome loss': 0.31898478442720074, 'Total loss': 0.31898478442720074}
2022-11-28 00:51:08,606 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:08,606 INFO:     Epoch: 86
2022-11-28 00:51:09,350 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40926725129512226, 'Total loss': 0.40926725129512226} | train loss {'Reaction outcome loss': 0.3186772622399952, 'Total loss': 0.3186772622399952}
2022-11-28 00:51:09,350 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:09,350 INFO:     Epoch: 87
2022-11-28 00:51:10,097 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40699864246628503, 'Total loss': 0.40699864246628503} | train loss {'Reaction outcome loss': 0.3138665540618935, 'Total loss': 0.3138665540618935}
2022-11-28 00:51:10,097 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:10,097 INFO:     Epoch: 88
2022-11-28 00:51:10,842 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40496041761203244, 'Total loss': 0.40496041761203244} | train loss {'Reaction outcome loss': 0.31954685127035515, 'Total loss': 0.31954685127035515}
2022-11-28 00:51:10,842 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:10,842 INFO:     Epoch: 89
2022-11-28 00:51:11,581 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4136180752380328, 'Total loss': 0.4136180752380328} | train loss {'Reaction outcome loss': 0.3134545593066254, 'Total loss': 0.3134545593066254}
2022-11-28 00:51:11,581 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:11,582 INFO:     Epoch: 90
2022-11-28 00:51:12,324 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43224017694592476, 'Total loss': 0.43224017694592476} | train loss {'Reaction outcome loss': 0.32793182233416357, 'Total loss': 0.32793182233416357}
2022-11-28 00:51:12,324 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:12,324 INFO:     Epoch: 91
2022-11-28 00:51:13,067 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4637711291963404, 'Total loss': 0.4637711291963404} | train loss {'Reaction outcome loss': 0.3220010760922724, 'Total loss': 0.3220010760922724}
2022-11-28 00:51:13,068 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:13,068 INFO:     Epoch: 92
2022-11-28 00:51:13,807 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41029549576342106, 'Total loss': 0.41029549576342106} | train loss {'Reaction outcome loss': 0.3221069807748768, 'Total loss': 0.3221069807748768}
2022-11-28 00:51:13,807 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:13,807 INFO:     Epoch: 93
2022-11-28 00:51:14,549 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41413044167513197, 'Total loss': 0.41413044167513197} | train loss {'Reaction outcome loss': 0.31412101467611336, 'Total loss': 0.31412101467611336}
2022-11-28 00:51:14,549 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:14,550 INFO:     Epoch: 94
2022-11-28 00:51:15,295 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40584928389977326, 'Total loss': 0.40584928389977326} | train loss {'Reaction outcome loss': 0.3235234561095133, 'Total loss': 0.3235234561095133}
2022-11-28 00:51:15,295 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:15,295 INFO:     Epoch: 95
2022-11-28 00:51:16,037 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4262431081045758, 'Total loss': 0.4262431081045758} | train loss {'Reaction outcome loss': 0.30820688235795934, 'Total loss': 0.30820688235795934}
2022-11-28 00:51:16,037 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:16,037 INFO:     Epoch: 96
2022-11-28 00:51:16,784 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41924005492844363, 'Total loss': 0.41924005492844363} | train loss {'Reaction outcome loss': 0.30843496027021755, 'Total loss': 0.30843496027021755}
2022-11-28 00:51:16,784 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:16,784 INFO:     Epoch: 97
2022-11-28 00:51:17,526 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41008367423306813, 'Total loss': 0.41008367423306813} | train loss {'Reaction outcome loss': 0.3212492955237748, 'Total loss': 0.3212492955237748}
2022-11-28 00:51:17,527 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:17,528 INFO:     Epoch: 98
2022-11-28 00:51:18,268 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4413920265029777, 'Total loss': 0.4413920265029777} | train loss {'Reaction outcome loss': 0.3188301424989816, 'Total loss': 0.3188301424989816}
2022-11-28 00:51:18,268 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:18,268 INFO:     Epoch: 99
2022-11-28 00:51:19,009 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4253618243065747, 'Total loss': 0.4253618243065747} | train loss {'Reaction outcome loss': 0.31077774369764904, 'Total loss': 0.31077774369764904}
2022-11-28 00:51:19,009 INFO:     Best model found after epoch 70 of 100.
2022-11-28 00:51:19,010 INFO:   Done with stage: TRAINING
2022-11-28 00:51:19,010 INFO:   Starting stage: EVALUATION
2022-11-28 00:51:19,129 INFO:   Done with stage: EVALUATION
2022-11-28 00:51:19,138 INFO:   Leaving out SEQ value Fold_0
2022-11-28 00:51:19,150 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-28 00:51:19,150 INFO:   Starting stage: FEATURE SCALING
2022-11-28 00:51:19,779 INFO:   Done with stage: FEATURE SCALING
2022-11-28 00:51:19,779 INFO:   Starting stage: SCALING TARGETS
2022-11-28 00:51:19,848 INFO:   Done with stage: SCALING TARGETS
2022-11-28 00:51:19,848 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:51:19,848 INFO:     No hyperparam tuning for this model
2022-11-28 00:51:19,848 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:51:19,848 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 00:51:19,849 INFO:     None feature selector for col prot
2022-11-28 00:51:19,849 INFO:     None feature selector for col prot
2022-11-28 00:51:19,849 INFO:     None feature selector for col prot
2022-11-28 00:51:19,850 INFO:     None feature selector for col chem
2022-11-28 00:51:19,850 INFO:     None feature selector for col chem
2022-11-28 00:51:19,850 INFO:     None feature selector for col chem
2022-11-28 00:51:19,850 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 00:51:19,850 INFO:   Starting stage: BUILD MODEL
2022-11-28 00:51:19,852 INFO:     Number of params in model 169741
2022-11-28 00:51:19,855 INFO:   Done with stage: BUILD MODEL
2022-11-28 00:51:19,855 INFO:   Starting stage: TRAINING
2022-11-28 00:51:19,907 INFO:     Val loss before train {'Reaction outcome loss': 0.968660059363343, 'Total loss': 0.968660059363343}
2022-11-28 00:51:19,907 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:19,907 INFO:     Epoch: 0
2022-11-28 00:51:20,635 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5545080129143803, 'Total loss': 0.5545080129143803} | train loss {'Reaction outcome loss': 0.6249563182577674, 'Total loss': 0.6249563182577674}
2022-11-28 00:51:20,635 INFO:     Found new best model at epoch 0
2022-11-28 00:51:20,636 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:20,636 INFO:     Epoch: 1
2022-11-28 00:51:21,365 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4671877463196599, 'Total loss': 0.4671877463196599} | train loss {'Reaction outcome loss': 0.49180515156483945, 'Total loss': 0.49180515156483945}
2022-11-28 00:51:21,366 INFO:     Found new best model at epoch 1
2022-11-28 00:51:21,366 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:21,366 INFO:     Epoch: 2
2022-11-28 00:51:22,097 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45859442685925683, 'Total loss': 0.45859442685925683} | train loss {'Reaction outcome loss': 0.45045417492036466, 'Total loss': 0.45045417492036466}
2022-11-28 00:51:22,097 INFO:     Found new best model at epoch 2
2022-11-28 00:51:22,097 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:22,098 INFO:     Epoch: 3
2022-11-28 00:51:22,827 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.43080176620982413, 'Total loss': 0.43080176620982413} | train loss {'Reaction outcome loss': 0.4311508836814896, 'Total loss': 0.4311508836814896}
2022-11-28 00:51:22,827 INFO:     Found new best model at epoch 3
2022-11-28 00:51:22,828 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:22,828 INFO:     Epoch: 4
2022-11-28 00:51:23,562 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45880474219488543, 'Total loss': 0.45880474219488543} | train loss {'Reaction outcome loss': 0.4117541253689385, 'Total loss': 0.4117541253689385}
2022-11-28 00:51:23,563 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:23,563 INFO:     Epoch: 5
2022-11-28 00:51:24,292 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4322683790395426, 'Total loss': 0.4322683790395426} | train loss {'Reaction outcome loss': 0.41012398389631827, 'Total loss': 0.41012398389631827}
2022-11-28 00:51:24,292 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:24,292 INFO:     Epoch: 6
2022-11-28 00:51:25,024 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4310521750256073, 'Total loss': 0.4310521750256073} | train loss {'Reaction outcome loss': 0.39927190033251364, 'Total loss': 0.39927190033251364}
2022-11-28 00:51:25,024 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:25,024 INFO:     Epoch: 7
2022-11-28 00:51:25,757 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4065946558880251, 'Total loss': 0.4065946558880251} | train loss {'Reaction outcome loss': 0.391340409072093, 'Total loss': 0.391340409072093}
2022-11-28 00:51:25,757 INFO:     Found new best model at epoch 7
2022-11-28 00:51:25,758 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:25,758 INFO:     Epoch: 8
2022-11-28 00:51:26,488 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42438387870788574, 'Total loss': 0.42438387870788574} | train loss {'Reaction outcome loss': 0.38623321519344433, 'Total loss': 0.38623321519344433}
2022-11-28 00:51:26,488 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:26,488 INFO:     Epoch: 9
2022-11-28 00:51:27,219 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40809394835039625, 'Total loss': 0.40809394835039625} | train loss {'Reaction outcome loss': 0.37475720001959506, 'Total loss': 0.37475720001959506}
2022-11-28 00:51:27,219 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:27,219 INFO:     Epoch: 10
2022-11-28 00:51:27,952 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43134752297124196, 'Total loss': 0.43134752297124196} | train loss {'Reaction outcome loss': 0.3675399996309614, 'Total loss': 0.3675399996309614}
2022-11-28 00:51:27,952 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:27,952 INFO:     Epoch: 11
2022-11-28 00:51:28,681 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.400602437035982, 'Total loss': 0.400602437035982} | train loss {'Reaction outcome loss': 0.3641328980893265, 'Total loss': 0.3641328980893265}
2022-11-28 00:51:28,681 INFO:     Found new best model at epoch 11
2022-11-28 00:51:28,682 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:28,682 INFO:     Epoch: 12
2022-11-28 00:51:29,411 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40443685910729477, 'Total loss': 0.40443685910729477} | train loss {'Reaction outcome loss': 0.3625209716535767, 'Total loss': 0.3625209716535767}
2022-11-28 00:51:29,412 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:29,412 INFO:     Epoch: 13
2022-11-28 00:51:30,142 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40901799499988556, 'Total loss': 0.40901799499988556} | train loss {'Reaction outcome loss': 0.3715846404862502, 'Total loss': 0.3715846404862502}
2022-11-28 00:51:30,142 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:30,142 INFO:     Epoch: 14
2022-11-28 00:51:30,873 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.438136481615, 'Total loss': 0.438136481615} | train loss {'Reaction outcome loss': 0.3579518805744717, 'Total loss': 0.3579518805744717}
2022-11-28 00:51:30,873 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:30,873 INFO:     Epoch: 15
2022-11-28 00:51:31,603 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4530830424885417, 'Total loss': 0.4530830424885417} | train loss {'Reaction outcome loss': 0.360721034584222, 'Total loss': 0.360721034584222}
2022-11-28 00:51:31,604 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:31,604 INFO:     Epoch: 16
2022-11-28 00:51:32,334 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42670139635718146, 'Total loss': 0.42670139635718146} | train loss {'Reaction outcome loss': 0.3502367444244432, 'Total loss': 0.3502367444244432}
2022-11-28 00:51:32,334 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:32,334 INFO:     Epoch: 17
2022-11-28 00:51:33,063 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42578126559423846, 'Total loss': 0.42578126559423846} | train loss {'Reaction outcome loss': 0.3457194639699449, 'Total loss': 0.3457194639699449}
2022-11-28 00:51:33,064 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:33,064 INFO:     Epoch: 18
2022-11-28 00:51:33,795 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39307955652475357, 'Total loss': 0.39307955652475357} | train loss {'Reaction outcome loss': 0.34316290813831635, 'Total loss': 0.34316290813831635}
2022-11-28 00:51:33,795 INFO:     Found new best model at epoch 18
2022-11-28 00:51:33,796 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:33,796 INFO:     Epoch: 19
2022-11-28 00:51:34,524 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.400984400753365, 'Total loss': 0.400984400753365} | train loss {'Reaction outcome loss': 0.3393682995696127, 'Total loss': 0.3393682995696127}
2022-11-28 00:51:34,524 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:34,524 INFO:     Epoch: 20
2022-11-28 00:51:35,251 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4138941113338914, 'Total loss': 0.4138941113338914} | train loss {'Reaction outcome loss': 0.3404340648356779, 'Total loss': 0.3404340648356779}
2022-11-28 00:51:35,251 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:35,251 INFO:     Epoch: 21
2022-11-28 00:51:35,982 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40933758401593495, 'Total loss': 0.40933758401593495} | train loss {'Reaction outcome loss': 0.3417458318081903, 'Total loss': 0.3417458318081903}
2022-11-28 00:51:35,982 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:35,982 INFO:     Epoch: 22
2022-11-28 00:51:36,710 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4133668805277625, 'Total loss': 0.4133668805277625} | train loss {'Reaction outcome loss': 0.33224109535722574, 'Total loss': 0.33224109535722574}
2022-11-28 00:51:36,710 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:36,711 INFO:     Epoch: 23
2022-11-28 00:51:37,436 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4083893309498942, 'Total loss': 0.4083893309498942} | train loss {'Reaction outcome loss': 0.3260011852339462, 'Total loss': 0.3260011852339462}
2022-11-28 00:51:37,436 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:37,436 INFO:     Epoch: 24
2022-11-28 00:51:38,165 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3874890152798143, 'Total loss': 0.3874890152798143} | train loss {'Reaction outcome loss': 0.3341037781119592, 'Total loss': 0.3341037781119592}
2022-11-28 00:51:38,165 INFO:     Found new best model at epoch 24
2022-11-28 00:51:38,166 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:38,166 INFO:     Epoch: 25
2022-11-28 00:51:38,892 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40636819826309073, 'Total loss': 0.40636819826309073} | train loss {'Reaction outcome loss': 0.3366079185571935, 'Total loss': 0.3366079185571935}
2022-11-28 00:51:38,892 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:38,892 INFO:     Epoch: 26
2022-11-28 00:51:39,622 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4336692018564357, 'Total loss': 0.4336692018564357} | train loss {'Reaction outcome loss': 0.3278028300269641, 'Total loss': 0.3278028300269641}
2022-11-28 00:51:39,622 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:39,622 INFO:     Epoch: 27
2022-11-28 00:51:40,352 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40957436277422793, 'Total loss': 0.40957436277422793} | train loss {'Reaction outcome loss': 0.3287991810084125, 'Total loss': 0.3287991810084125}
2022-11-28 00:51:40,353 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:40,353 INFO:     Epoch: 28
2022-11-28 00:51:41,084 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4281313017357227, 'Total loss': 0.4281313017357227} | train loss {'Reaction outcome loss': 0.3205054694242438, 'Total loss': 0.3205054694242438}
2022-11-28 00:51:41,084 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:41,084 INFO:     Epoch: 29
2022-11-28 00:51:41,814 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41562548695608625, 'Total loss': 0.41562548695608625} | train loss {'Reaction outcome loss': 0.32365371927680303, 'Total loss': 0.32365371927680303}
2022-11-28 00:51:41,814 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:41,814 INFO:     Epoch: 30
2022-11-28 00:51:42,547 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3882528928130172, 'Total loss': 0.3882528928130172} | train loss {'Reaction outcome loss': 0.3188421799812788, 'Total loss': 0.3188421799812788}
2022-11-28 00:51:42,547 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:42,547 INFO:     Epoch: 31
2022-11-28 00:51:43,280 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41574761271476746, 'Total loss': 0.41574761271476746} | train loss {'Reaction outcome loss': 0.31968743326487364, 'Total loss': 0.31968743326487364}
2022-11-28 00:51:43,280 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:43,281 INFO:     Epoch: 32
2022-11-28 00:51:44,011 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39428352859131127, 'Total loss': 0.39428352859131127} | train loss {'Reaction outcome loss': 0.32732399547694885, 'Total loss': 0.32732399547694885}
2022-11-28 00:51:44,011 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:44,011 INFO:     Epoch: 33
2022-11-28 00:51:44,741 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40259795930496484, 'Total loss': 0.40259795930496484} | train loss {'Reaction outcome loss': 0.3183583663661539, 'Total loss': 0.3183583663661539}
2022-11-28 00:51:44,742 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:44,742 INFO:     Epoch: 34
2022-11-28 00:51:45,472 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42553307081377784, 'Total loss': 0.42553307081377784} | train loss {'Reaction outcome loss': 0.3177412289957451, 'Total loss': 0.3177412289957451}
2022-11-28 00:51:45,473 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:45,473 INFO:     Epoch: 35
2022-11-28 00:51:46,206 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4328869823799577, 'Total loss': 0.4328869823799577} | train loss {'Reaction outcome loss': 0.32818023838991983, 'Total loss': 0.32818023838991983}
2022-11-28 00:51:46,206 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:46,206 INFO:     Epoch: 36
2022-11-28 00:51:46,937 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37012588596621226, 'Total loss': 0.37012588596621226} | train loss {'Reaction outcome loss': 0.31897846951222225, 'Total loss': 0.31897846951222225}
2022-11-28 00:51:46,937 INFO:     Found new best model at epoch 36
2022-11-28 00:51:46,938 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:46,938 INFO:     Epoch: 37
2022-11-28 00:51:47,669 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39931410620378893, 'Total loss': 0.39931410620378893} | train loss {'Reaction outcome loss': 0.32500427150370653, 'Total loss': 0.32500427150370653}
2022-11-28 00:51:47,669 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:47,669 INFO:     Epoch: 38
2022-11-28 00:51:48,400 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39349831068931623, 'Total loss': 0.39349831068931623} | train loss {'Reaction outcome loss': 0.31748407554847224, 'Total loss': 0.31748407554847224}
2022-11-28 00:51:48,402 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:48,402 INFO:     Epoch: 39
2022-11-28 00:51:49,137 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39256470737069155, 'Total loss': 0.39256470737069155} | train loss {'Reaction outcome loss': 0.31534600007987806, 'Total loss': 0.31534600007987806}
2022-11-28 00:51:49,137 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:49,138 INFO:     Epoch: 40
2022-11-28 00:51:49,873 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4014917036821676, 'Total loss': 0.4014917036821676} | train loss {'Reaction outcome loss': 0.3298823395935596, 'Total loss': 0.3298823395935596}
2022-11-28 00:51:49,873 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:49,873 INFO:     Epoch: 41
2022-11-28 00:51:50,608 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40926357445328737, 'Total loss': 0.40926357445328737} | train loss {'Reaction outcome loss': 0.30831170626321935, 'Total loss': 0.30831170626321935}
2022-11-28 00:51:50,608 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:50,608 INFO:     Epoch: 42
2022-11-28 00:51:51,337 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42975167895472327, 'Total loss': 0.42975167895472327} | train loss {'Reaction outcome loss': 0.3221591617682098, 'Total loss': 0.3221591617682098}
2022-11-28 00:51:51,337 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:51,337 INFO:     Epoch: 43
2022-11-28 00:51:52,068 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39505433239216026, 'Total loss': 0.39505433239216026} | train loss {'Reaction outcome loss': 0.31664963538754626, 'Total loss': 0.31664963538754626}
2022-11-28 00:51:52,068 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:52,068 INFO:     Epoch: 44
2022-11-28 00:51:52,797 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40395148375699685, 'Total loss': 0.40395148375699685} | train loss {'Reaction outcome loss': 0.3144491262534641, 'Total loss': 0.3144491262534641}
2022-11-28 00:51:52,797 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:52,797 INFO:     Epoch: 45
2022-11-28 00:51:53,528 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3777350225420885, 'Total loss': 0.3777350225420885} | train loss {'Reaction outcome loss': 0.3140476697082382, 'Total loss': 0.3140476697082382}
2022-11-28 00:51:53,528 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:53,529 INFO:     Epoch: 46
2022-11-28 00:51:54,260 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3797391549099323, 'Total loss': 0.3797391549099323} | train loss {'Reaction outcome loss': 0.31851087584171767, 'Total loss': 0.31851087584171767}
2022-11-28 00:51:54,261 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:54,261 INFO:     Epoch: 47
2022-11-28 00:51:54,994 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3943862020969391, 'Total loss': 0.3943862020969391} | train loss {'Reaction outcome loss': 0.3213354239063989, 'Total loss': 0.3213354239063989}
2022-11-28 00:51:54,994 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:54,995 INFO:     Epoch: 48
2022-11-28 00:51:55,722 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41851335971854453, 'Total loss': 0.41851335971854453} | train loss {'Reaction outcome loss': 0.3059113799084606, 'Total loss': 0.3059113799084606}
2022-11-28 00:51:55,722 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:55,722 INFO:     Epoch: 49
2022-11-28 00:51:56,455 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4296953962292782, 'Total loss': 0.4296953962292782} | train loss {'Reaction outcome loss': 0.3200672254456905, 'Total loss': 0.3200672254456905}
2022-11-28 00:51:56,455 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:56,455 INFO:     Epoch: 50
2022-11-28 00:51:57,184 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.398455545999283, 'Total loss': 0.398455545999283} | train loss {'Reaction outcome loss': 0.3113723148289041, 'Total loss': 0.3113723148289041}
2022-11-28 00:51:57,184 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:57,185 INFO:     Epoch: 51
2022-11-28 00:51:57,910 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3922143784719844, 'Total loss': 0.3922143784719844} | train loss {'Reaction outcome loss': 0.3152930633444722, 'Total loss': 0.3152930633444722}
2022-11-28 00:51:57,911 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:57,911 INFO:     Epoch: 52
2022-11-28 00:51:58,639 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4062310928522154, 'Total loss': 0.4062310928522154} | train loss {'Reaction outcome loss': 0.30937968706520497, 'Total loss': 0.30937968706520497}
2022-11-28 00:51:58,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:58,640 INFO:     Epoch: 53
2022-11-28 00:51:59,371 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37614403665065765, 'Total loss': 0.37614403665065765} | train loss {'Reaction outcome loss': 0.3118078248429691, 'Total loss': 0.3118078248429691}
2022-11-28 00:51:59,371 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:51:59,371 INFO:     Epoch: 54
2022-11-28 00:52:00,097 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3885833291813385, 'Total loss': 0.3885833291813385} | train loss {'Reaction outcome loss': 0.31343348344228394, 'Total loss': 0.31343348344228394}
2022-11-28 00:52:00,097 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:00,097 INFO:     Epoch: 55
2022-11-28 00:52:00,824 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3877137894200724, 'Total loss': 0.3877137894200724} | train loss {'Reaction outcome loss': 0.31038500560225285, 'Total loss': 0.31038500560225285}
2022-11-28 00:52:00,824 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:00,824 INFO:     Epoch: 56
2022-11-28 00:52:01,553 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3823773164388745, 'Total loss': 0.3823773164388745} | train loss {'Reaction outcome loss': 0.30181144931403453, 'Total loss': 0.30181144931403453}
2022-11-28 00:52:01,553 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:01,553 INFO:     Epoch: 57
2022-11-28 00:52:02,283 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45648439748342645, 'Total loss': 0.45648439748342645} | train loss {'Reaction outcome loss': 0.30351993705264824, 'Total loss': 0.30351993705264824}
2022-11-28 00:52:02,284 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:02,284 INFO:     Epoch: 58
2022-11-28 00:52:03,010 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38212805743827377, 'Total loss': 0.38212805743827377} | train loss {'Reaction outcome loss': 0.3063295283067374, 'Total loss': 0.3063295283067374}
2022-11-28 00:52:03,010 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:03,010 INFO:     Epoch: 59
2022-11-28 00:52:03,740 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43408294056737146, 'Total loss': 0.43408294056737146} | train loss {'Reaction outcome loss': 0.29883406194762435, 'Total loss': 0.29883406194762435}
2022-11-28 00:52:03,740 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:03,740 INFO:     Epoch: 60
2022-11-28 00:52:04,474 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40742601350296376, 'Total loss': 0.40742601350296376} | train loss {'Reaction outcome loss': 0.31775797098691083, 'Total loss': 0.31775797098691083}
2022-11-28 00:52:04,475 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:04,475 INFO:     Epoch: 61
2022-11-28 00:52:05,218 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4029796390339386, 'Total loss': 0.4029796390339386} | train loss {'Reaction outcome loss': 0.30141651812833525, 'Total loss': 0.30141651812833525}
2022-11-28 00:52:05,218 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:05,218 INFO:     Epoch: 62
2022-11-28 00:52:05,955 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4020221694264301, 'Total loss': 0.4020221694264301} | train loss {'Reaction outcome loss': 0.30149786117574806, 'Total loss': 0.30149786117574806}
2022-11-28 00:52:05,955 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:05,955 INFO:     Epoch: 63
2022-11-28 00:52:06,692 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4312292758462041, 'Total loss': 0.4312292758462041} | train loss {'Reaction outcome loss': 0.3022917068636221, 'Total loss': 0.3022917068636221}
2022-11-28 00:52:06,692 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:06,692 INFO:     Epoch: 64
2022-11-28 00:52:07,430 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39470523699771526, 'Total loss': 0.39470523699771526} | train loss {'Reaction outcome loss': 0.30385858976807245, 'Total loss': 0.30385858976807245}
2022-11-28 00:52:07,431 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:07,431 INFO:     Epoch: 65
2022-11-28 00:52:08,166 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40119715069615564, 'Total loss': 0.40119715069615564} | train loss {'Reaction outcome loss': 0.3034231885041229, 'Total loss': 0.3034231885041229}
2022-11-28 00:52:08,166 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:08,166 INFO:     Epoch: 66
2022-11-28 00:52:08,904 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40603980058154393, 'Total loss': 0.40603980058154393} | train loss {'Reaction outcome loss': 0.31327142124926605, 'Total loss': 0.31327142124926605}
2022-11-28 00:52:08,904 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:08,904 INFO:     Epoch: 67
2022-11-28 00:52:09,640 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3948349089816559, 'Total loss': 0.3948349089816559} | train loss {'Reaction outcome loss': 0.313320896201173, 'Total loss': 0.313320896201173}
2022-11-28 00:52:09,641 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:09,641 INFO:     Epoch: 68
2022-11-28 00:52:10,376 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3980426058866257, 'Total loss': 0.3980426058866257} | train loss {'Reaction outcome loss': 0.3116759478340669, 'Total loss': 0.3116759478340669}
2022-11-28 00:52:10,377 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:10,377 INFO:     Epoch: 69
2022-11-28 00:52:11,119 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3877661264566488, 'Total loss': 0.3877661264566488} | train loss {'Reaction outcome loss': 0.30355637220075593, 'Total loss': 0.30355637220075593}
2022-11-28 00:52:11,119 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:11,119 INFO:     Epoch: 70
2022-11-28 00:52:11,857 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38002584042937254, 'Total loss': 0.38002584042937254} | train loss {'Reaction outcome loss': 0.29963369118701283, 'Total loss': 0.29963369118701283}
2022-11-28 00:52:11,857 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:11,857 INFO:     Epoch: 71
2022-11-28 00:52:12,598 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4042456803280254, 'Total loss': 0.4042456803280254} | train loss {'Reaction outcome loss': 0.30746637664949944, 'Total loss': 0.30746637664949944}
2022-11-28 00:52:12,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:12,599 INFO:     Epoch: 72
2022-11-28 00:52:13,338 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37890093825584237, 'Total loss': 0.37890093825584237} | train loss {'Reaction outcome loss': 0.3019205686548119, 'Total loss': 0.3019205686548119}
2022-11-28 00:52:13,338 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:13,338 INFO:     Epoch: 73
2022-11-28 00:52:14,076 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.378941482236219, 'Total loss': 0.378941482236219} | train loss {'Reaction outcome loss': 0.3014230691816336, 'Total loss': 0.3014230691816336}
2022-11-28 00:52:14,076 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:14,076 INFO:     Epoch: 74
2022-11-28 00:52:14,814 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3761026450367861, 'Total loss': 0.3761026450367861} | train loss {'Reaction outcome loss': 0.3082904505539578, 'Total loss': 0.3082904505539578}
2022-11-28 00:52:14,814 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:14,814 INFO:     Epoch: 75
2022-11-28 00:52:15,552 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39189079923685205, 'Total loss': 0.39189079923685205} | train loss {'Reaction outcome loss': 0.3018913373979644, 'Total loss': 0.3018913373979644}
2022-11-28 00:52:15,552 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:15,552 INFO:     Epoch: 76
2022-11-28 00:52:16,288 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40207259218360103, 'Total loss': 0.40207259218360103} | train loss {'Reaction outcome loss': 0.3013091118002134, 'Total loss': 0.3013091118002134}
2022-11-28 00:52:16,292 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:16,293 INFO:     Epoch: 77
2022-11-28 00:52:17,029 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39316266237996345, 'Total loss': 0.39316266237996345} | train loss {'Reaction outcome loss': 0.3136796908828702, 'Total loss': 0.3136796908828702}
2022-11-28 00:52:17,029 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:17,029 INFO:     Epoch: 78
2022-11-28 00:52:17,771 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40108792864999104, 'Total loss': 0.40108792864999104} | train loss {'Reaction outcome loss': 0.30454990457850717, 'Total loss': 0.30454990457850717}
2022-11-28 00:52:17,772 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:17,772 INFO:     Epoch: 79
2022-11-28 00:52:18,509 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3860842672198318, 'Total loss': 0.3860842672198318} | train loss {'Reaction outcome loss': 0.30782716690635487, 'Total loss': 0.30782716690635487}
2022-11-28 00:52:18,509 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:18,509 INFO:     Epoch: 80
2022-11-28 00:52:19,250 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3991431502062221, 'Total loss': 0.3991431502062221} | train loss {'Reaction outcome loss': 0.30059951656486517, 'Total loss': 0.30059951656486517}
2022-11-28 00:52:19,250 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:19,251 INFO:     Epoch: 81
2022-11-28 00:52:19,990 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.462299989059914, 'Total loss': 0.462299989059914} | train loss {'Reaction outcome loss': 0.30499736878852296, 'Total loss': 0.30499736878852296}
2022-11-28 00:52:19,991 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:19,991 INFO:     Epoch: 82
2022-11-28 00:52:20,729 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4011858233878779, 'Total loss': 0.4011858233878779} | train loss {'Reaction outcome loss': 0.3058742336438271, 'Total loss': 0.3058742336438271}
2022-11-28 00:52:20,729 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:20,729 INFO:     Epoch: 83
2022-11-28 00:52:21,464 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4027262825605481, 'Total loss': 0.4027262825605481} | train loss {'Reaction outcome loss': 0.30861984627175726, 'Total loss': 0.30861984627175726}
2022-11-28 00:52:21,464 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:21,465 INFO:     Epoch: 84
2022-11-28 00:52:22,201 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4110194912483526, 'Total loss': 0.4110194912483526} | train loss {'Reaction outcome loss': 0.31885798065444076, 'Total loss': 0.31885798065444076}
2022-11-28 00:52:22,201 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:22,201 INFO:     Epoch: 85
2022-11-28 00:52:22,937 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39036970949450206, 'Total loss': 0.39036970949450206} | train loss {'Reaction outcome loss': 0.3083624715299763, 'Total loss': 0.3083624715299763}
2022-11-28 00:52:22,937 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:22,937 INFO:     Epoch: 86
2022-11-28 00:52:23,679 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3944300738878028, 'Total loss': 0.3944300738878028} | train loss {'Reaction outcome loss': 0.2997866559911657, 'Total loss': 0.2997866559911657}
2022-11-28 00:52:23,679 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:23,679 INFO:     Epoch: 87
2022-11-28 00:52:24,409 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3744265222272208, 'Total loss': 0.3744265222272208} | train loss {'Reaction outcome loss': 0.2996800613777382, 'Total loss': 0.2996800613777382}
2022-11-28 00:52:24,410 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:24,410 INFO:     Epoch: 88
2022-11-28 00:52:25,141 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41376975057430043, 'Total loss': 0.41376975057430043} | train loss {'Reaction outcome loss': 0.29796175516130013, 'Total loss': 0.29796175516130013}
2022-11-28 00:52:25,141 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:25,141 INFO:     Epoch: 89
2022-11-28 00:52:25,874 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4090432763792748, 'Total loss': 0.4090432763792748} | train loss {'Reaction outcome loss': 0.31292960780515594, 'Total loss': 0.31292960780515594}
2022-11-28 00:52:25,874 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:25,874 INFO:     Epoch: 90
2022-11-28 00:52:26,607 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3888690922149392, 'Total loss': 0.3888690922149392} | train loss {'Reaction outcome loss': 0.30541123796269726, 'Total loss': 0.30541123796269726}
2022-11-28 00:52:26,608 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:26,608 INFO:     Epoch: 91
2022-11-28 00:52:27,345 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42108427196048026, 'Total loss': 0.42108427196048026} | train loss {'Reaction outcome loss': 0.2983610409277457, 'Total loss': 0.2983610409277457}
2022-11-28 00:52:27,345 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:27,345 INFO:     Epoch: 92
2022-11-28 00:52:28,079 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3923594612021779, 'Total loss': 0.3923594612021779} | train loss {'Reaction outcome loss': 0.30264379927282964, 'Total loss': 0.30264379927282964}
2022-11-28 00:52:28,079 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:28,079 INFO:     Epoch: 93
2022-11-28 00:52:28,813 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4093495475691418, 'Total loss': 0.4093495475691418} | train loss {'Reaction outcome loss': 0.3025405461911434, 'Total loss': 0.3025405461911434}
2022-11-28 00:52:28,813 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:28,813 INFO:     Epoch: 94
2022-11-28 00:52:29,553 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4272156231278597, 'Total loss': 0.4272156231278597} | train loss {'Reaction outcome loss': 0.3044724172218837, 'Total loss': 0.3044724172218837}
2022-11-28 00:52:29,553 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:29,553 INFO:     Epoch: 95
2022-11-28 00:52:30,283 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3653348718964776, 'Total loss': 0.3653348718964776} | train loss {'Reaction outcome loss': 0.30677096726595127, 'Total loss': 0.30677096726595127}
2022-11-28 00:52:30,283 INFO:     Found new best model at epoch 95
2022-11-28 00:52:30,284 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:30,284 INFO:     Epoch: 96
2022-11-28 00:52:31,016 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3677451988292295, 'Total loss': 0.3677451988292295} | train loss {'Reaction outcome loss': 0.3033731289345909, 'Total loss': 0.3033731289345909}
2022-11-28 00:52:31,016 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:31,016 INFO:     Epoch: 97
2022-11-28 00:52:31,753 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38873532137205435, 'Total loss': 0.38873532137205435} | train loss {'Reaction outcome loss': 0.29780785865131226, 'Total loss': 0.29780785865131226}
2022-11-28 00:52:31,753 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:31,754 INFO:     Epoch: 98
2022-11-28 00:52:32,487 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4403267849323361, 'Total loss': 0.4403267849323361} | train loss {'Reaction outcome loss': 0.3064291238815451, 'Total loss': 0.3064291238815451}
2022-11-28 00:52:32,487 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:32,487 INFO:     Epoch: 99
2022-11-28 00:52:33,217 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38893503964293835, 'Total loss': 0.38893503964293835} | train loss {'Reaction outcome loss': 0.29420023661398104, 'Total loss': 0.29420023661398104}
2022-11-28 00:52:33,217 INFO:     Best model found after epoch 96 of 100.
2022-11-28 00:52:33,217 INFO:   Done with stage: TRAINING
2022-11-28 00:52:33,218 INFO:   Starting stage: EVALUATION
2022-11-28 00:52:33,355 INFO:   Done with stage: EVALUATION
2022-11-28 00:52:33,355 INFO:   Leaving out SEQ value Fold_1
2022-11-28 00:52:33,367 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 00:52:33,367 INFO:   Starting stage: FEATURE SCALING
2022-11-28 00:52:34,004 INFO:   Done with stage: FEATURE SCALING
2022-11-28 00:52:34,004 INFO:   Starting stage: SCALING TARGETS
2022-11-28 00:52:34,073 INFO:   Done with stage: SCALING TARGETS
2022-11-28 00:52:34,074 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:52:34,074 INFO:     No hyperparam tuning for this model
2022-11-28 00:52:34,074 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:52:34,074 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 00:52:34,074 INFO:     None feature selector for col prot
2022-11-28 00:52:34,075 INFO:     None feature selector for col prot
2022-11-28 00:52:34,075 INFO:     None feature selector for col prot
2022-11-28 00:52:34,075 INFO:     None feature selector for col chem
2022-11-28 00:52:34,075 INFO:     None feature selector for col chem
2022-11-28 00:52:34,075 INFO:     None feature selector for col chem
2022-11-28 00:52:34,075 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 00:52:34,075 INFO:   Starting stage: BUILD MODEL
2022-11-28 00:52:34,077 INFO:     Number of params in model 169741
2022-11-28 00:52:34,080 INFO:   Done with stage: BUILD MODEL
2022-11-28 00:52:34,080 INFO:   Starting stage: TRAINING
2022-11-28 00:52:34,133 INFO:     Val loss before train {'Reaction outcome loss': 1.0279148072004318, 'Total loss': 1.0279148072004318}
2022-11-28 00:52:34,133 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:34,133 INFO:     Epoch: 0
2022-11-28 00:52:34,879 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.549714636396278, 'Total loss': 0.549714636396278} | train loss {'Reaction outcome loss': 0.6592111092226708, 'Total loss': 0.6592111092226708}
2022-11-28 00:52:34,879 INFO:     Found new best model at epoch 0
2022-11-28 00:52:34,879 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:34,880 INFO:     Epoch: 1
2022-11-28 00:52:35,620 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5136805522170934, 'Total loss': 0.5136805522170934} | train loss {'Reaction outcome loss': 0.5168492741852637, 'Total loss': 0.5168492741852637}
2022-11-28 00:52:35,620 INFO:     Found new best model at epoch 1
2022-11-28 00:52:35,621 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:35,621 INFO:     Epoch: 2
2022-11-28 00:52:36,365 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46472426097501407, 'Total loss': 0.46472426097501407} | train loss {'Reaction outcome loss': 0.473453875736669, 'Total loss': 0.473453875736669}
2022-11-28 00:52:36,365 INFO:     Found new best model at epoch 2
2022-11-28 00:52:36,366 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:36,366 INFO:     Epoch: 3
2022-11-28 00:52:37,108 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4172110842032866, 'Total loss': 0.4172110842032866} | train loss {'Reaction outcome loss': 0.4474382170962419, 'Total loss': 0.4474382170962419}
2022-11-28 00:52:37,108 INFO:     Found new best model at epoch 3
2022-11-28 00:52:37,109 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:37,109 INFO:     Epoch: 4
2022-11-28 00:52:37,851 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4424264725636352, 'Total loss': 0.4424264725636352} | train loss {'Reaction outcome loss': 0.4358076459166371, 'Total loss': 0.4358076459166371}
2022-11-28 00:52:37,851 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:37,851 INFO:     Epoch: 5
2022-11-28 00:52:38,594 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4346797601743178, 'Total loss': 0.4346797601743178} | train loss {'Reaction outcome loss': 0.4181951172499039, 'Total loss': 0.4181951172499039}
2022-11-28 00:52:38,594 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:38,594 INFO:     Epoch: 6
2022-11-28 00:52:39,339 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45189178125424817, 'Total loss': 0.45189178125424817} | train loss {'Reaction outcome loss': 0.41138599886509936, 'Total loss': 0.41138599886509936}
2022-11-28 00:52:39,339 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:39,340 INFO:     Epoch: 7
2022-11-28 00:52:40,087 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4117056659676812, 'Total loss': 0.4117056659676812} | train loss {'Reaction outcome loss': 0.4004042594116709, 'Total loss': 0.4004042594116709}
2022-11-28 00:52:40,088 INFO:     Found new best model at epoch 7
2022-11-28 00:52:40,088 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:40,089 INFO:     Epoch: 8
2022-11-28 00:52:40,833 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.442185521803119, 'Total loss': 0.442185521803119} | train loss {'Reaction outcome loss': 0.402005311508893, 'Total loss': 0.402005311508893}
2022-11-28 00:52:40,834 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:40,834 INFO:     Epoch: 9
2022-11-28 00:52:41,582 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42238979786634445, 'Total loss': 0.42238979786634445} | train loss {'Reaction outcome loss': 0.43414741338264606, 'Total loss': 0.43414741338264606}
2022-11-28 00:52:41,582 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:41,582 INFO:     Epoch: 10
2022-11-28 00:52:42,331 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4264068319038911, 'Total loss': 0.4264068319038911} | train loss {'Reaction outcome loss': 0.39200685115960926, 'Total loss': 0.39200685115960926}
2022-11-28 00:52:42,331 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:42,331 INFO:     Epoch: 11
2022-11-28 00:52:43,075 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4115017737177285, 'Total loss': 0.4115017737177285} | train loss {'Reaction outcome loss': 0.379064774796789, 'Total loss': 0.379064774796789}
2022-11-28 00:52:43,076 INFO:     Found new best model at epoch 11
2022-11-28 00:52:43,076 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:43,076 INFO:     Epoch: 12
2022-11-28 00:52:43,821 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.392034611241384, 'Total loss': 0.392034611241384} | train loss {'Reaction outcome loss': 0.36994806738939845, 'Total loss': 0.36994806738939845}
2022-11-28 00:52:43,821 INFO:     Found new best model at epoch 12
2022-11-28 00:52:43,822 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:43,822 INFO:     Epoch: 13
2022-11-28 00:52:44,564 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41497518071396783, 'Total loss': 0.41497518071396783} | train loss {'Reaction outcome loss': 0.3783762308388104, 'Total loss': 0.3783762308388104}
2022-11-28 00:52:44,564 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:44,564 INFO:     Epoch: 14
2022-11-28 00:52:45,307 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4328843436457894, 'Total loss': 0.4328843436457894} | train loss {'Reaction outcome loss': 0.3720770883204242, 'Total loss': 0.3720770883204242}
2022-11-28 00:52:45,307 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:45,308 INFO:     Epoch: 15
2022-11-28 00:52:46,053 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40836578675291757, 'Total loss': 0.40836578675291757} | train loss {'Reaction outcome loss': 0.3670525973481748, 'Total loss': 0.3670525973481748}
2022-11-28 00:52:46,053 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:46,053 INFO:     Epoch: 16
2022-11-28 00:52:46,799 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3997189490632577, 'Total loss': 0.3997189490632577} | train loss {'Reaction outcome loss': 0.3631844701554611, 'Total loss': 0.3631844701554611}
2022-11-28 00:52:46,799 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:46,799 INFO:     Epoch: 17
2022-11-28 00:52:47,543 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3983371433886615, 'Total loss': 0.3983371433886615} | train loss {'Reaction outcome loss': 0.37662552342361766, 'Total loss': 0.37662552342361766}
2022-11-28 00:52:47,544 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:47,544 INFO:     Epoch: 18
2022-11-28 00:52:48,285 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4298061742023988, 'Total loss': 0.4298061742023988} | train loss {'Reaction outcome loss': 0.3904765175602697, 'Total loss': 0.3904765175602697}
2022-11-28 00:52:48,285 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:48,286 INFO:     Epoch: 19
2022-11-28 00:52:49,030 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4177905923940919, 'Total loss': 0.4177905923940919} | train loss {'Reaction outcome loss': 0.3635720162075541, 'Total loss': 0.3635720162075541}
2022-11-28 00:52:49,030 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:49,030 INFO:     Epoch: 20
2022-11-28 00:52:49,775 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.37879289483482187, 'Total loss': 0.37879289483482187} | train loss {'Reaction outcome loss': 0.35507399689873703, 'Total loss': 0.35507399689873703}
2022-11-28 00:52:49,775 INFO:     Found new best model at epoch 20
2022-11-28 00:52:49,776 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:49,776 INFO:     Epoch: 21
2022-11-28 00:52:50,522 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42408919402144174, 'Total loss': 0.42408919402144174} | train loss {'Reaction outcome loss': 0.3564111203679189, 'Total loss': 0.3564111203679189}
2022-11-28 00:52:50,523 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:50,523 INFO:     Epoch: 22
2022-11-28 00:52:51,270 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4181482849473303, 'Total loss': 0.4181482849473303} | train loss {'Reaction outcome loss': 0.36072106148127603, 'Total loss': 0.36072106148127603}
2022-11-28 00:52:51,270 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:51,270 INFO:     Epoch: 23
2022-11-28 00:52:52,016 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4103964479132132, 'Total loss': 0.4103964479132132} | train loss {'Reaction outcome loss': 0.3448501243765055, 'Total loss': 0.3448501243765055}
2022-11-28 00:52:52,016 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:52,016 INFO:     Epoch: 24
2022-11-28 00:52:52,760 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3831720480864698, 'Total loss': 0.3831720480864698} | train loss {'Reaction outcome loss': 0.35220153527975323, 'Total loss': 0.35220153527975323}
2022-11-28 00:52:52,760 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:52,760 INFO:     Epoch: 25
2022-11-28 00:52:53,505 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4148673083294522, 'Total loss': 0.4148673083294522} | train loss {'Reaction outcome loss': 0.33953450056384904, 'Total loss': 0.33953450056384904}
2022-11-28 00:52:53,505 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:53,505 INFO:     Epoch: 26
2022-11-28 00:52:54,253 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4016154188324105, 'Total loss': 0.4016154188324105} | train loss {'Reaction outcome loss': 0.3388255278917825, 'Total loss': 0.3388255278917825}
2022-11-28 00:52:54,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:54,253 INFO:     Epoch: 27
2022-11-28 00:52:54,996 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4089760292660106, 'Total loss': 0.4089760292660106} | train loss {'Reaction outcome loss': 0.35125292976893985, 'Total loss': 0.35125292976893985}
2022-11-28 00:52:54,996 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:54,997 INFO:     Epoch: 28
2022-11-28 00:52:55,741 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38584086671471596, 'Total loss': 0.38584086671471596} | train loss {'Reaction outcome loss': 0.34137170764840086, 'Total loss': 0.34137170764840086}
2022-11-28 00:52:55,741 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:55,741 INFO:     Epoch: 29
2022-11-28 00:52:56,484 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3978700512512164, 'Total loss': 0.3978700512512164} | train loss {'Reaction outcome loss': 0.33390721772243137, 'Total loss': 0.33390721772243137}
2022-11-28 00:52:56,484 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:56,484 INFO:     Epoch: 30
2022-11-28 00:52:57,231 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40794045393439854, 'Total loss': 0.40794045393439854} | train loss {'Reaction outcome loss': 0.3586817489341203, 'Total loss': 0.3586817489341203}
2022-11-28 00:52:57,232 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:57,232 INFO:     Epoch: 31
2022-11-28 00:52:57,976 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4145509976555001, 'Total loss': 0.4145509976555001} | train loss {'Reaction outcome loss': 0.3326580761837573, 'Total loss': 0.3326580761837573}
2022-11-28 00:52:57,976 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:57,976 INFO:     Epoch: 32
2022-11-28 00:52:58,721 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41212771155617456, 'Total loss': 0.41212771155617456} | train loss {'Reaction outcome loss': 0.33085806378227495, 'Total loss': 0.33085806378227495}
2022-11-28 00:52:58,721 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:58,721 INFO:     Epoch: 33
2022-11-28 00:52:59,464 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3913023956120014, 'Total loss': 0.3913023956120014} | train loss {'Reaction outcome loss': 0.3384752915908209, 'Total loss': 0.3384752915908209}
2022-11-28 00:52:59,464 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:52:59,464 INFO:     Epoch: 34
2022-11-28 00:53:00,208 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41916493157094176, 'Total loss': 0.41916493157094176} | train loss {'Reaction outcome loss': 0.34077789966273403, 'Total loss': 0.34077789966273403}
2022-11-28 00:53:00,208 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:00,208 INFO:     Epoch: 35
2022-11-28 00:53:00,952 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3890786689113487, 'Total loss': 0.3890786689113487} | train loss {'Reaction outcome loss': 0.3321542212747128, 'Total loss': 0.3321542212747128}
2022-11-28 00:53:00,953 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:00,953 INFO:     Epoch: 36
2022-11-28 00:53:01,698 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40623619305816566, 'Total loss': 0.40623619305816566} | train loss {'Reaction outcome loss': 0.3395872504001687, 'Total loss': 0.3395872504001687}
2022-11-28 00:53:01,699 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:01,699 INFO:     Epoch: 37
2022-11-28 00:53:02,440 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41020936298776756, 'Total loss': 0.41020936298776756} | train loss {'Reaction outcome loss': 0.33080621253744313, 'Total loss': 0.33080621253744313}
2022-11-28 00:53:02,440 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:02,440 INFO:     Epoch: 38
2022-11-28 00:53:03,185 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.37460747869177297, 'Total loss': 0.37460747869177297} | train loss {'Reaction outcome loss': 0.33903556751362557, 'Total loss': 0.33903556751362557}
2022-11-28 00:53:03,185 INFO:     Found new best model at epoch 38
2022-11-28 00:53:03,186 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:03,186 INFO:     Epoch: 39
2022-11-28 00:53:03,930 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3946299522437833, 'Total loss': 0.3946299522437833} | train loss {'Reaction outcome loss': 0.3443462097572412, 'Total loss': 0.3443462097572412}
2022-11-28 00:53:03,930 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:03,930 INFO:     Epoch: 40
2022-11-28 00:53:04,675 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42296450077132747, 'Total loss': 0.42296450077132747} | train loss {'Reaction outcome loss': 0.3355286809340542, 'Total loss': 0.3355286809340542}
2022-11-28 00:53:04,675 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:04,675 INFO:     Epoch: 41
2022-11-28 00:53:05,421 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.48017552799799224, 'Total loss': 0.48017552799799224} | train loss {'Reaction outcome loss': 0.3360429545675936, 'Total loss': 0.3360429545675936}
2022-11-28 00:53:05,422 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:05,422 INFO:     Epoch: 42
2022-11-28 00:53:06,170 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4131206656721505, 'Total loss': 0.4131206656721505} | train loss {'Reaction outcome loss': 0.33222049626954553, 'Total loss': 0.33222049626954553}
2022-11-28 00:53:06,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:06,170 INFO:     Epoch: 43
2022-11-28 00:53:06,914 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42113439383154566, 'Total loss': 0.42113439383154566} | train loss {'Reaction outcome loss': 0.32772841491559257, 'Total loss': 0.32772841491559257}
2022-11-28 00:53:06,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:06,914 INFO:     Epoch: 44
2022-11-28 00:53:07,659 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3862681776623834, 'Total loss': 0.3862681776623834} | train loss {'Reaction outcome loss': 0.3344121662831982, 'Total loss': 0.3344121662831982}
2022-11-28 00:53:07,659 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:07,659 INFO:     Epoch: 45
2022-11-28 00:53:08,405 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4275043257935481, 'Total loss': 0.4275043257935481} | train loss {'Reaction outcome loss': 0.3297086435290966, 'Total loss': 0.3297086435290966}
2022-11-28 00:53:08,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:08,406 INFO:     Epoch: 46
2022-11-28 00:53:09,147 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39238380098884756, 'Total loss': 0.39238380098884756} | train loss {'Reaction outcome loss': 0.32572971602622797, 'Total loss': 0.32572971602622797}
2022-11-28 00:53:09,148 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:09,148 INFO:     Epoch: 47
2022-11-28 00:53:09,892 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3855436369776726, 'Total loss': 0.3855436369776726} | train loss {'Reaction outcome loss': 0.3225380807157289, 'Total loss': 0.3225380807157289}
2022-11-28 00:53:09,893 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:09,893 INFO:     Epoch: 48
2022-11-28 00:53:10,636 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3719955330545252, 'Total loss': 0.3719955330545252} | train loss {'Reaction outcome loss': 0.32935326986169433, 'Total loss': 0.32935326986169433}
2022-11-28 00:53:10,636 INFO:     Found new best model at epoch 48
2022-11-28 00:53:10,637 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:10,637 INFO:     Epoch: 49
2022-11-28 00:53:11,386 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3787832852791656, 'Total loss': 0.3787832852791656} | train loss {'Reaction outcome loss': 0.3194534667783609, 'Total loss': 0.3194534667783609}
2022-11-28 00:53:11,386 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:11,386 INFO:     Epoch: 50
2022-11-28 00:53:12,134 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38287212648852303, 'Total loss': 0.38287212648852303} | train loss {'Reaction outcome loss': 0.3231064416538841, 'Total loss': 0.3231064416538841}
2022-11-28 00:53:12,134 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:12,134 INFO:     Epoch: 51
2022-11-28 00:53:12,882 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.38505866649475967, 'Total loss': 0.38505866649475967} | train loss {'Reaction outcome loss': 0.3279726388996188, 'Total loss': 0.3279726388996188}
2022-11-28 00:53:12,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:12,882 INFO:     Epoch: 52
2022-11-28 00:53:13,631 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42524328421462665, 'Total loss': 0.42524328421462665} | train loss {'Reaction outcome loss': 0.33892592796791904, 'Total loss': 0.33892592796791904}
2022-11-28 00:53:13,631 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:13,631 INFO:     Epoch: 53
2022-11-28 00:53:14,377 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37545073980634863, 'Total loss': 0.37545073980634863} | train loss {'Reaction outcome loss': 0.32906213665177464, 'Total loss': 0.32906213665177464}
2022-11-28 00:53:14,377 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:14,377 INFO:     Epoch: 54
2022-11-28 00:53:15,122 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3755793903361667, 'Total loss': 0.3755793903361667} | train loss {'Reaction outcome loss': 0.33435421663257275, 'Total loss': 0.33435421663257275}
2022-11-28 00:53:15,122 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:15,122 INFO:     Epoch: 55
2022-11-28 00:53:15,864 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3937229592014443, 'Total loss': 0.3937229592014443} | train loss {'Reaction outcome loss': 0.32734837508967773, 'Total loss': 0.32734837508967773}
2022-11-28 00:53:15,864 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:15,865 INFO:     Epoch: 56
2022-11-28 00:53:16,608 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4267553118142215, 'Total loss': 0.4267553118142215} | train loss {'Reaction outcome loss': 0.3224085265627274, 'Total loss': 0.3224085265627274}
2022-11-28 00:53:16,608 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:16,608 INFO:     Epoch: 57
2022-11-28 00:53:17,356 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38777293772860005, 'Total loss': 0.38777293772860005} | train loss {'Reaction outcome loss': 0.3258456275289358, 'Total loss': 0.3258456275289358}
2022-11-28 00:53:17,356 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:17,356 INFO:     Epoch: 58
2022-11-28 00:53:18,104 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41442602330988104, 'Total loss': 0.41442602330988104} | train loss {'Reaction outcome loss': 0.3388225991987748, 'Total loss': 0.3388225991987748}
2022-11-28 00:53:18,104 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:18,104 INFO:     Epoch: 59
2022-11-28 00:53:18,851 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3800237128003077, 'Total loss': 0.3800237128003077} | train loss {'Reaction outcome loss': 0.3259677213101402, 'Total loss': 0.3259677213101402}
2022-11-28 00:53:18,851 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:18,851 INFO:     Epoch: 60
2022-11-28 00:53:19,596 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4321942383592779, 'Total loss': 0.4321942383592779} | train loss {'Reaction outcome loss': 0.3210629002028051, 'Total loss': 0.3210629002028051}
2022-11-28 00:53:19,596 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:19,596 INFO:     Epoch: 61
2022-11-28 00:53:20,344 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38019097901203414, 'Total loss': 0.38019097901203414} | train loss {'Reaction outcome loss': 0.3257920836147509, 'Total loss': 0.3257920836147509}
2022-11-28 00:53:20,344 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:20,344 INFO:     Epoch: 62
2022-11-28 00:53:21,090 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3751270418817347, 'Total loss': 0.3751270418817347} | train loss {'Reaction outcome loss': 0.3144656290970757, 'Total loss': 0.3144656290970757}
2022-11-28 00:53:21,090 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:21,090 INFO:     Epoch: 63
2022-11-28 00:53:21,835 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38664653863419185, 'Total loss': 0.38664653863419185} | train loss {'Reaction outcome loss': 0.3132719902708412, 'Total loss': 0.3132719902708412}
2022-11-28 00:53:21,836 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:21,836 INFO:     Epoch: 64
2022-11-28 00:53:22,587 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3789487746967511, 'Total loss': 0.3789487746967511} | train loss {'Reaction outcome loss': 0.3252310914549268, 'Total loss': 0.3252310914549268}
2022-11-28 00:53:22,587 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:22,587 INFO:     Epoch: 65
2022-11-28 00:53:23,335 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39256073331291025, 'Total loss': 0.39256073331291025} | train loss {'Reaction outcome loss': 0.32751228880544425, 'Total loss': 0.32751228880544425}
2022-11-28 00:53:23,335 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:23,335 INFO:     Epoch: 66
2022-11-28 00:53:24,081 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3921734463762153, 'Total loss': 0.3921734463762153} | train loss {'Reaction outcome loss': 0.32822629350505256, 'Total loss': 0.32822629350505256}
2022-11-28 00:53:24,081 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:24,082 INFO:     Epoch: 67
2022-11-28 00:53:24,829 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.36281144923784514, 'Total loss': 0.36281144923784514} | train loss {'Reaction outcome loss': 0.3239903946516485, 'Total loss': 0.3239903946516485}
2022-11-28 00:53:24,829 INFO:     Found new best model at epoch 67
2022-11-28 00:53:24,830 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:24,830 INFO:     Epoch: 68
2022-11-28 00:53:25,576 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38923661004413257, 'Total loss': 0.38923661004413257} | train loss {'Reaction outcome loss': 0.3170564886831079, 'Total loss': 0.3170564886831079}
2022-11-28 00:53:25,577 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:25,577 INFO:     Epoch: 69
2022-11-28 00:53:26,322 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49153759533708746, 'Total loss': 0.49153759533708746} | train loss {'Reaction outcome loss': 0.33728695769421, 'Total loss': 0.33728695769421}
2022-11-28 00:53:26,322 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:26,322 INFO:     Epoch: 70
2022-11-28 00:53:27,069 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4193206233057109, 'Total loss': 0.4193206233057109} | train loss {'Reaction outcome loss': 0.34103938987489985, 'Total loss': 0.34103938987489985}
2022-11-28 00:53:27,069 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:27,069 INFO:     Epoch: 71
2022-11-28 00:53:27,821 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4016791937703436, 'Total loss': 0.4016791937703436} | train loss {'Reaction outcome loss': 0.32092265347358184, 'Total loss': 0.32092265347358184}
2022-11-28 00:53:27,821 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:27,821 INFO:     Epoch: 72
2022-11-28 00:53:28,570 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38321429321711714, 'Total loss': 0.38321429321711714} | train loss {'Reaction outcome loss': 0.3244136662980323, 'Total loss': 0.3244136662980323}
2022-11-28 00:53:28,571 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:28,571 INFO:     Epoch: 73
2022-11-28 00:53:29,319 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38118967024440115, 'Total loss': 0.38118967024440115} | train loss {'Reaction outcome loss': 0.32095901188459475, 'Total loss': 0.32095901188459475}
2022-11-28 00:53:29,319 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:29,319 INFO:     Epoch: 74
2022-11-28 00:53:30,069 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3879983320154927, 'Total loss': 0.3879983320154927} | train loss {'Reaction outcome loss': 0.32409762782151347, 'Total loss': 0.32409762782151347}
2022-11-28 00:53:30,069 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:30,069 INFO:     Epoch: 75
2022-11-28 00:53:30,818 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39355333759026095, 'Total loss': 0.39355333759026095} | train loss {'Reaction outcome loss': 0.3184737320367232, 'Total loss': 0.3184737320367232}
2022-11-28 00:53:30,818 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:30,818 INFO:     Epoch: 76
2022-11-28 00:53:31,569 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39829750020395627, 'Total loss': 0.39829750020395627} | train loss {'Reaction outcome loss': 0.3149153989046173, 'Total loss': 0.3149153989046173}
2022-11-28 00:53:31,569 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:31,569 INFO:     Epoch: 77
2022-11-28 00:53:32,321 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3802835699170828, 'Total loss': 0.3802835699170828} | train loss {'Reaction outcome loss': 0.31988601446875675, 'Total loss': 0.31988601446875675}
2022-11-28 00:53:32,321 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:32,321 INFO:     Epoch: 78
2022-11-28 00:53:33,075 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4001998816701499, 'Total loss': 0.4001998816701499} | train loss {'Reaction outcome loss': 0.31523765729144515, 'Total loss': 0.31523765729144515}
2022-11-28 00:53:33,076 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:33,076 INFO:     Epoch: 79
2022-11-28 00:53:33,831 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.36659387837756763, 'Total loss': 0.36659387837756763} | train loss {'Reaction outcome loss': 0.32313369378176054, 'Total loss': 0.32313369378176054}
2022-11-28 00:53:33,831 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:33,831 INFO:     Epoch: 80
2022-11-28 00:53:34,579 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4063346673819152, 'Total loss': 0.4063346673819152} | train loss {'Reaction outcome loss': 0.32649332357321675, 'Total loss': 0.32649332357321675}
2022-11-28 00:53:34,580 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:34,580 INFO:     Epoch: 81
2022-11-28 00:53:35,329 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39589245668189094, 'Total loss': 0.39589245668189094} | train loss {'Reaction outcome loss': 0.32132229267955126, 'Total loss': 0.32132229267955126}
2022-11-28 00:53:35,329 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:35,329 INFO:     Epoch: 82
2022-11-28 00:53:36,079 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40084726871414617, 'Total loss': 0.40084726871414617} | train loss {'Reaction outcome loss': 0.3227794946506921, 'Total loss': 0.3227794946506921}
2022-11-28 00:53:36,079 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:36,079 INFO:     Epoch: 83
2022-11-28 00:53:36,831 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3770342931490053, 'Total loss': 0.3770342931490053} | train loss {'Reaction outcome loss': 0.33065824591634413, 'Total loss': 0.33065824591634413}
2022-11-28 00:53:36,832 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:36,832 INFO:     Epoch: 84
2022-11-28 00:53:37,585 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37327512980184774, 'Total loss': 0.37327512980184774} | train loss {'Reaction outcome loss': 0.31565298272548, 'Total loss': 0.31565298272548}
2022-11-28 00:53:37,585 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:37,585 INFO:     Epoch: 85
2022-11-28 00:53:38,337 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4287892183796926, 'Total loss': 0.4287892183796926} | train loss {'Reaction outcome loss': 0.31335991065532703, 'Total loss': 0.31335991065532703}
2022-11-28 00:53:38,338 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:38,338 INFO:     Epoch: 86
2022-11-28 00:53:39,082 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.39791747284206475, 'Total loss': 0.39791747284206475} | train loss {'Reaction outcome loss': 0.31987537637443436, 'Total loss': 0.31987537637443436}
2022-11-28 00:53:39,082 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:39,082 INFO:     Epoch: 87
2022-11-28 00:53:39,831 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38147407499226654, 'Total loss': 0.38147407499226654} | train loss {'Reaction outcome loss': 0.31670022599560754, 'Total loss': 0.31670022599560754}
2022-11-28 00:53:39,831 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:39,831 INFO:     Epoch: 88
2022-11-28 00:53:40,581 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3874953026798638, 'Total loss': 0.3874953026798638} | train loss {'Reaction outcome loss': 0.32634103548550897, 'Total loss': 0.32634103548550897}
2022-11-28 00:53:40,582 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:40,582 INFO:     Epoch: 89
2022-11-28 00:53:41,334 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38054050369696185, 'Total loss': 0.38054050369696185} | train loss {'Reaction outcome loss': 0.32316224599777443, 'Total loss': 0.32316224599777443}
2022-11-28 00:53:41,334 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:41,334 INFO:     Epoch: 90
2022-11-28 00:53:42,083 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3782345237718387, 'Total loss': 0.3782345237718387} | train loss {'Reaction outcome loss': 0.3220587698252578, 'Total loss': 0.3220587698252578}
2022-11-28 00:53:42,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:42,084 INFO:     Epoch: 91
2022-11-28 00:53:42,834 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3945752473717386, 'Total loss': 0.3945752473717386} | train loss {'Reaction outcome loss': 0.32318286178445044, 'Total loss': 0.32318286178445044}
2022-11-28 00:53:42,834 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:42,834 INFO:     Epoch: 92
2022-11-28 00:53:43,581 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3907657858322967, 'Total loss': 0.3907657858322967} | train loss {'Reaction outcome loss': 0.32589227953541133, 'Total loss': 0.32589227953541133}
2022-11-28 00:53:43,581 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:43,581 INFO:     Epoch: 93
2022-11-28 00:53:44,330 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3998230028558861, 'Total loss': 0.3998230028558861} | train loss {'Reaction outcome loss': 0.3156509012802078, 'Total loss': 0.3156509012802078}
2022-11-28 00:53:44,330 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:44,330 INFO:     Epoch: 94
2022-11-28 00:53:45,075 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3907862923700701, 'Total loss': 0.3907862923700701} | train loss {'Reaction outcome loss': 0.3105017612518569, 'Total loss': 0.3105017612518569}
2022-11-28 00:53:45,075 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:45,075 INFO:     Epoch: 95
2022-11-28 00:53:45,820 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.37994717230851, 'Total loss': 0.37994717230851} | train loss {'Reaction outcome loss': 0.3212052704049991, 'Total loss': 0.3212052704049991}
2022-11-28 00:53:45,820 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:45,820 INFO:     Epoch: 96
2022-11-28 00:53:46,570 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43043582480062137, 'Total loss': 0.43043582480062137} | train loss {'Reaction outcome loss': 0.34937962594061245, 'Total loss': 0.34937962594061245}
2022-11-28 00:53:46,570 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:46,570 INFO:     Epoch: 97
2022-11-28 00:53:47,316 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43530847640200093, 'Total loss': 0.43530847640200093} | train loss {'Reaction outcome loss': 0.31814820038886205, 'Total loss': 0.31814820038886205}
2022-11-28 00:53:47,316 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:47,316 INFO:     Epoch: 98
2022-11-28 00:53:48,072 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4099093357270414, 'Total loss': 0.4099093357270414} | train loss {'Reaction outcome loss': 0.3231402671319029, 'Total loss': 0.3231402671319029}
2022-11-28 00:53:48,072 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:48,072 INFO:     Epoch: 99
2022-11-28 00:53:48,827 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4299355708062649, 'Total loss': 0.4299355708062649} | train loss {'Reaction outcome loss': 0.31543288346726883, 'Total loss': 0.31543288346726883}
2022-11-28 00:53:48,828 INFO:     Best model found after epoch 68 of 100.
2022-11-28 00:53:48,828 INFO:   Done with stage: TRAINING
2022-11-28 00:53:48,828 INFO:   Starting stage: EVALUATION
2022-11-28 00:53:48,948 INFO:   Done with stage: EVALUATION
2022-11-28 00:53:48,948 INFO:   Leaving out SEQ value Fold_2
2022-11-28 00:53:48,961 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 00:53:48,962 INFO:   Starting stage: FEATURE SCALING
2022-11-28 00:53:49,612 INFO:   Done with stage: FEATURE SCALING
2022-11-28 00:53:49,612 INFO:   Starting stage: SCALING TARGETS
2022-11-28 00:53:49,682 INFO:   Done with stage: SCALING TARGETS
2022-11-28 00:53:49,682 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:53:49,682 INFO:     No hyperparam tuning for this model
2022-11-28 00:53:49,682 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:53:49,682 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 00:53:49,683 INFO:     None feature selector for col prot
2022-11-28 00:53:49,683 INFO:     None feature selector for col prot
2022-11-28 00:53:49,683 INFO:     None feature selector for col prot
2022-11-28 00:53:49,684 INFO:     None feature selector for col chem
2022-11-28 00:53:49,684 INFO:     None feature selector for col chem
2022-11-28 00:53:49,684 INFO:     None feature selector for col chem
2022-11-28 00:53:49,684 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 00:53:49,684 INFO:   Starting stage: BUILD MODEL
2022-11-28 00:53:49,685 INFO:     Number of params in model 169741
2022-11-28 00:53:49,689 INFO:   Done with stage: BUILD MODEL
2022-11-28 00:53:49,689 INFO:   Starting stage: TRAINING
2022-11-28 00:53:49,743 INFO:     Val loss before train {'Reaction outcome loss': 1.0279151194474914, 'Total loss': 1.0279151194474914}
2022-11-28 00:53:49,743 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:49,743 INFO:     Epoch: 0
2022-11-28 00:53:50,489 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5707551701502367, 'Total loss': 0.5707551701502367} | train loss {'Reaction outcome loss': 0.6517853940628013, 'Total loss': 0.6517853940628013}
2022-11-28 00:53:50,489 INFO:     Found new best model at epoch 0
2022-11-28 00:53:50,490 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:50,490 INFO:     Epoch: 1
2022-11-28 00:53:51,237 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5163708565841344, 'Total loss': 0.5163708565841344} | train loss {'Reaction outcome loss': 0.5074458808315043, 'Total loss': 0.5074458808315043}
2022-11-28 00:53:51,237 INFO:     Found new best model at epoch 1
2022-11-28 00:53:51,238 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:51,238 INFO:     Epoch: 2
2022-11-28 00:53:51,980 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.544089937074618, 'Total loss': 0.544089937074618} | train loss {'Reaction outcome loss': 0.472316425977921, 'Total loss': 0.472316425977921}
2022-11-28 00:53:51,980 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:51,980 INFO:     Epoch: 3
2022-11-28 00:53:52,722 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.495347858491269, 'Total loss': 0.495347858491269} | train loss {'Reaction outcome loss': 0.44175280922529647, 'Total loss': 0.44175280922529647}
2022-11-28 00:53:52,723 INFO:     Found new best model at epoch 3
2022-11-28 00:53:52,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:52,724 INFO:     Epoch: 4
2022-11-28 00:53:53,466 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4825271005657586, 'Total loss': 0.4825271005657586} | train loss {'Reaction outcome loss': 0.4223795162779944, 'Total loss': 0.4223795162779944}
2022-11-28 00:53:53,466 INFO:     Found new best model at epoch 4
2022-11-28 00:53:53,467 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:53,467 INFO:     Epoch: 5
2022-11-28 00:53:54,207 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49616668170148676, 'Total loss': 0.49616668170148676} | train loss {'Reaction outcome loss': 0.4179331029556235, 'Total loss': 0.4179331029556235}
2022-11-28 00:53:54,207 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:54,207 INFO:     Epoch: 6
2022-11-28 00:53:54,947 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4460291715169495, 'Total loss': 0.4460291715169495} | train loss {'Reaction outcome loss': 0.4097249689454935, 'Total loss': 0.4097249689454935}
2022-11-28 00:53:54,948 INFO:     Found new best model at epoch 6
2022-11-28 00:53:54,948 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:54,949 INFO:     Epoch: 7
2022-11-28 00:53:55,692 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47268265147100796, 'Total loss': 0.47268265147100796} | train loss {'Reaction outcome loss': 0.3953026680313811, 'Total loss': 0.3953026680313811}
2022-11-28 00:53:55,693 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:55,693 INFO:     Epoch: 8
2022-11-28 00:53:56,437 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4714410841803659, 'Total loss': 0.4714410841803659} | train loss {'Reaction outcome loss': 0.39277654092530817, 'Total loss': 0.39277654092530817}
2022-11-28 00:53:56,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:56,437 INFO:     Epoch: 9
2022-11-28 00:53:57,177 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4712476469576359, 'Total loss': 0.4712476469576359} | train loss {'Reaction outcome loss': 0.382190959581307, 'Total loss': 0.382190959581307}
2022-11-28 00:53:57,178 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:57,178 INFO:     Epoch: 10
2022-11-28 00:53:57,923 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47949249822307716, 'Total loss': 0.47949249822307716} | train loss {'Reaction outcome loss': 0.37915786185434885, 'Total loss': 0.37915786185434885}
2022-11-28 00:53:57,923 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:57,923 INFO:     Epoch: 11
2022-11-28 00:53:58,670 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48694630509073084, 'Total loss': 0.48694630509073084} | train loss {'Reaction outcome loss': 0.373310600616494, 'Total loss': 0.373310600616494}
2022-11-28 00:53:58,670 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:58,670 INFO:     Epoch: 12
2022-11-28 00:53:59,410 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4621027372777462, 'Total loss': 0.4621027372777462} | train loss {'Reaction outcome loss': 0.37279239783481677, 'Total loss': 0.37279239783481677}
2022-11-28 00:53:59,410 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:53:59,410 INFO:     Epoch: 13
2022-11-28 00:54:00,148 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49348886514251883, 'Total loss': 0.49348886514251883} | train loss {'Reaction outcome loss': 0.36844487187205527, 'Total loss': 0.36844487187205527}
2022-11-28 00:54:00,148 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:00,148 INFO:     Epoch: 14
2022-11-28 00:54:00,886 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46789430488239636, 'Total loss': 0.46789430488239636} | train loss {'Reaction outcome loss': 0.3723709046232457, 'Total loss': 0.3723709046232457}
2022-11-28 00:54:00,886 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:00,887 INFO:     Epoch: 15
2022-11-28 00:54:01,629 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4461038960038092, 'Total loss': 0.4461038960038092} | train loss {'Reaction outcome loss': 0.3631349583061374, 'Total loss': 0.3631349583061374}
2022-11-28 00:54:01,629 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:01,629 INFO:     Epoch: 16
2022-11-28 00:54:02,374 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4599891963668845, 'Total loss': 0.4599891963668845} | train loss {'Reaction outcome loss': 0.35138426948794904, 'Total loss': 0.35138426948794904}
2022-11-28 00:54:02,375 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:02,375 INFO:     Epoch: 17
2022-11-28 00:54:03,118 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4712996022267775, 'Total loss': 0.4712996022267775} | train loss {'Reaction outcome loss': 0.3540903835576408, 'Total loss': 0.3540903835576408}
2022-11-28 00:54:03,118 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:03,118 INFO:     Epoch: 18
2022-11-28 00:54:03,859 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5326331312006171, 'Total loss': 0.5326331312006171} | train loss {'Reaction outcome loss': 0.3603202110346483, 'Total loss': 0.3603202110346483}
2022-11-28 00:54:03,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:03,860 INFO:     Epoch: 19
2022-11-28 00:54:04,603 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47317448698661546, 'Total loss': 0.47317448698661546} | train loss {'Reaction outcome loss': 0.3480827985369429, 'Total loss': 0.3480827985369429}
2022-11-28 00:54:04,603 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:04,603 INFO:     Epoch: 20
2022-11-28 00:54:05,345 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49194030971689656, 'Total loss': 0.49194030971689656} | train loss {'Reaction outcome loss': 0.34905041550495186, 'Total loss': 0.34905041550495186}
2022-11-28 00:54:05,345 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:05,345 INFO:     Epoch: 21
2022-11-28 00:54:06,088 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45937608487226744, 'Total loss': 0.45937608487226744} | train loss {'Reaction outcome loss': 0.34550747695017836, 'Total loss': 0.34550747695017836}
2022-11-28 00:54:06,088 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:06,088 INFO:     Epoch: 22
2022-11-28 00:54:06,830 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47042386504736816, 'Total loss': 0.47042386504736816} | train loss {'Reaction outcome loss': 0.3354142310668011, 'Total loss': 0.3354142310668011}
2022-11-28 00:54:06,830 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:06,830 INFO:     Epoch: 23
2022-11-28 00:54:07,570 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47043475034562027, 'Total loss': 0.47043475034562027} | train loss {'Reaction outcome loss': 0.3382480858235943, 'Total loss': 0.3382480858235943}
2022-11-28 00:54:07,571 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:07,571 INFO:     Epoch: 24
2022-11-28 00:54:08,313 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48605482889847323, 'Total loss': 0.48605482889847323} | train loss {'Reaction outcome loss': 0.3464150606673591, 'Total loss': 0.3464150606673591}
2022-11-28 00:54:08,313 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:08,313 INFO:     Epoch: 25
2022-11-28 00:54:09,055 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4841168841177767, 'Total loss': 0.4841168841177767} | train loss {'Reaction outcome loss': 0.3380079963681649, 'Total loss': 0.3380079963681649}
2022-11-28 00:54:09,056 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:09,056 INFO:     Epoch: 26
2022-11-28 00:54:09,796 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.449430077760057, 'Total loss': 0.449430077760057} | train loss {'Reaction outcome loss': 0.338089447970293, 'Total loss': 0.338089447970293}
2022-11-28 00:54:09,796 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:09,796 INFO:     Epoch: 27
2022-11-28 00:54:10,536 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5124517130580816, 'Total loss': 0.5124517130580816} | train loss {'Reaction outcome loss': 0.3347451169880069, 'Total loss': 0.3347451169880069}
2022-11-28 00:54:10,537 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:10,537 INFO:     Epoch: 28
2022-11-28 00:54:11,280 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4550337595018474, 'Total loss': 0.4550337595018474} | train loss {'Reaction outcome loss': 0.3380482063001516, 'Total loss': 0.3380482063001516}
2022-11-28 00:54:11,280 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:11,280 INFO:     Epoch: 29
2022-11-28 00:54:12,021 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4659647775644606, 'Total loss': 0.4659647775644606} | train loss {'Reaction outcome loss': 0.34081135164110027, 'Total loss': 0.34081135164110027}
2022-11-28 00:54:12,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:12,022 INFO:     Epoch: 30
2022-11-28 00:54:12,767 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4775307725437663, 'Total loss': 0.4775307725437663} | train loss {'Reaction outcome loss': 0.33216094295589293, 'Total loss': 0.33216094295589293}
2022-11-28 00:54:12,767 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:12,767 INFO:     Epoch: 31
2022-11-28 00:54:13,510 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48030857199972327, 'Total loss': 0.48030857199972327} | train loss {'Reaction outcome loss': 0.3461572037211486, 'Total loss': 0.3461572037211486}
2022-11-28 00:54:13,511 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:13,511 INFO:     Epoch: 32
2022-11-28 00:54:14,253 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4739841368388046, 'Total loss': 0.4739841368388046} | train loss {'Reaction outcome loss': 0.3246003399089891, 'Total loss': 0.3246003399089891}
2022-11-28 00:54:14,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:14,253 INFO:     Epoch: 33
2022-11-28 00:54:14,998 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4385559724813158, 'Total loss': 0.4385559724813158} | train loss {'Reaction outcome loss': 0.32876614286583294, 'Total loss': 0.32876614286583294}
2022-11-28 00:54:14,998 INFO:     Found new best model at epoch 33
2022-11-28 00:54:14,999 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:14,999 INFO:     Epoch: 34
2022-11-28 00:54:15,742 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4552977880970998, 'Total loss': 0.4552977880970998} | train loss {'Reaction outcome loss': 0.3352136778892303, 'Total loss': 0.3352136778892303}
2022-11-28 00:54:15,742 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:15,743 INFO:     Epoch: 35
2022-11-28 00:54:16,485 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46001955519684334, 'Total loss': 0.46001955519684334} | train loss {'Reaction outcome loss': 0.329582284026, 'Total loss': 0.329582284026}
2022-11-28 00:54:16,485 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:16,485 INFO:     Epoch: 36
2022-11-28 00:54:17,227 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4967851479622451, 'Total loss': 0.4967851479622451} | train loss {'Reaction outcome loss': 0.3291707863613051, 'Total loss': 0.3291707863613051}
2022-11-28 00:54:17,227 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:17,227 INFO:     Epoch: 37
2022-11-28 00:54:17,968 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4643243668092923, 'Total loss': 0.4643243668092923} | train loss {'Reaction outcome loss': 0.32541411509927437, 'Total loss': 0.32541411509927437}
2022-11-28 00:54:17,968 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:17,968 INFO:     Epoch: 38
2022-11-28 00:54:18,709 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47528602656992996, 'Total loss': 0.47528602656992996} | train loss {'Reaction outcome loss': 0.32862014884547314, 'Total loss': 0.32862014884547314}
2022-11-28 00:54:18,709 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:18,710 INFO:     Epoch: 39
2022-11-28 00:54:19,452 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4429615492170507, 'Total loss': 0.4429615492170507} | train loss {'Reaction outcome loss': 0.32515828132021185, 'Total loss': 0.32515828132021185}
2022-11-28 00:54:19,452 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:19,452 INFO:     Epoch: 40
2022-11-28 00:54:20,194 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5017347972501408, 'Total loss': 0.5017347972501408} | train loss {'Reaction outcome loss': 0.32114610112443265, 'Total loss': 0.32114610112443265}
2022-11-28 00:54:20,194 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:20,194 INFO:     Epoch: 41
2022-11-28 00:54:20,940 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4774042005566033, 'Total loss': 0.4774042005566033} | train loss {'Reaction outcome loss': 0.3293830071785012, 'Total loss': 0.3293830071785012}
2022-11-28 00:54:20,940 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:20,940 INFO:     Epoch: 42
2022-11-28 00:54:21,679 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.488996378400109, 'Total loss': 0.488996378400109} | train loss {'Reaction outcome loss': 0.32457492010934014, 'Total loss': 0.32457492010934014}
2022-11-28 00:54:21,679 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:21,679 INFO:     Epoch: 43
2022-11-28 00:54:22,420 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42900028892538766, 'Total loss': 0.42900028892538766} | train loss {'Reaction outcome loss': 0.33817435956122927, 'Total loss': 0.33817435956122927}
2022-11-28 00:54:22,420 INFO:     Found new best model at epoch 43
2022-11-28 00:54:22,421 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:22,421 INFO:     Epoch: 44
2022-11-28 00:54:23,165 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45723874866962433, 'Total loss': 0.45723874866962433} | train loss {'Reaction outcome loss': 0.3186014246271581, 'Total loss': 0.3186014246271581}
2022-11-28 00:54:23,165 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:23,165 INFO:     Epoch: 45
2022-11-28 00:54:23,907 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.478182255205783, 'Total loss': 0.478182255205783} | train loss {'Reaction outcome loss': 0.3200163739676378, 'Total loss': 0.3200163739676378}
2022-11-28 00:54:23,908 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:23,908 INFO:     Epoch: 46
2022-11-28 00:54:24,650 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47426275367086584, 'Total loss': 0.47426275367086584} | train loss {'Reaction outcome loss': 0.3182180714850523, 'Total loss': 0.3182180714850523}
2022-11-28 00:54:24,650 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:24,650 INFO:     Epoch: 47
2022-11-28 00:54:25,396 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4831957827237519, 'Total loss': 0.4831957827237519} | train loss {'Reaction outcome loss': 0.31317285417902224, 'Total loss': 0.31317285417902224}
2022-11-28 00:54:25,396 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:25,396 INFO:     Epoch: 48
2022-11-28 00:54:26,139 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4734665815803138, 'Total loss': 0.4734665815803138} | train loss {'Reaction outcome loss': 0.33294974945637645, 'Total loss': 0.33294974945637645}
2022-11-28 00:54:26,139 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:26,139 INFO:     Epoch: 49
2022-11-28 00:54:26,881 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44510448910295963, 'Total loss': 0.44510448910295963} | train loss {'Reaction outcome loss': 0.31890600049982265, 'Total loss': 0.31890600049982265}
2022-11-28 00:54:26,881 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:26,881 INFO:     Epoch: 50
2022-11-28 00:54:27,624 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47355089759962127, 'Total loss': 0.47355089759962127} | train loss {'Reaction outcome loss': 0.3244676367360718, 'Total loss': 0.3244676367360718}
2022-11-28 00:54:27,624 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:27,625 INFO:     Epoch: 51
2022-11-28 00:54:28,365 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4760190715843981, 'Total loss': 0.4760190715843981} | train loss {'Reaction outcome loss': 0.32442525652598364, 'Total loss': 0.32442525652598364}
2022-11-28 00:54:28,365 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:28,365 INFO:     Epoch: 52
2022-11-28 00:54:29,109 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4532922994006764, 'Total loss': 0.4532922994006764} | train loss {'Reaction outcome loss': 0.3132486544093307, 'Total loss': 0.3132486544093307}
2022-11-28 00:54:29,109 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:29,109 INFO:     Epoch: 53
2022-11-28 00:54:29,850 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46297072526067495, 'Total loss': 0.46297072526067495} | train loss {'Reaction outcome loss': 0.31147872653542735, 'Total loss': 0.31147872653542735}
2022-11-28 00:54:29,850 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:29,850 INFO:     Epoch: 54
2022-11-28 00:54:30,594 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4793422364375808, 'Total loss': 0.4793422364375808} | train loss {'Reaction outcome loss': 0.31799748670689915, 'Total loss': 0.31799748670689915}
2022-11-28 00:54:30,595 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:30,595 INFO:     Epoch: 55
2022-11-28 00:54:31,337 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5130548504265872, 'Total loss': 0.5130548504265872} | train loss {'Reaction outcome loss': 0.32803132549232367, 'Total loss': 0.32803132549232367}
2022-11-28 00:54:31,337 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:31,337 INFO:     Epoch: 56
2022-11-28 00:54:32,080 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4783844758163799, 'Total loss': 0.4783844758163799} | train loss {'Reaction outcome loss': 0.316287134831049, 'Total loss': 0.316287134831049}
2022-11-28 00:54:32,080 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:32,080 INFO:     Epoch: 57
2022-11-28 00:54:32,824 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4718443477018313, 'Total loss': 0.4718443477018313} | train loss {'Reaction outcome loss': 0.31719699891246095, 'Total loss': 0.31719699891246095}
2022-11-28 00:54:32,824 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:32,824 INFO:     Epoch: 58
2022-11-28 00:54:33,568 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47336243093013763, 'Total loss': 0.47336243093013763} | train loss {'Reaction outcome loss': 0.32524182635302445, 'Total loss': 0.32524182635302445}
2022-11-28 00:54:33,568 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:33,568 INFO:     Epoch: 59
2022-11-28 00:54:34,309 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44797024808146735, 'Total loss': 0.44797024808146735} | train loss {'Reaction outcome loss': 0.32154761528482245, 'Total loss': 0.32154761528482245}
2022-11-28 00:54:34,309 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:34,310 INFO:     Epoch: 60
2022-11-28 00:54:35,052 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45880104702982033, 'Total loss': 0.45880104702982033} | train loss {'Reaction outcome loss': 0.3134804978966713, 'Total loss': 0.3134804978966713}
2022-11-28 00:54:35,053 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:35,053 INFO:     Epoch: 61
2022-11-28 00:54:35,796 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.6173578968102281, 'Total loss': 0.6173578968102281} | train loss {'Reaction outcome loss': 0.31955969905366705, 'Total loss': 0.31955969905366705}
2022-11-28 00:54:35,796 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:35,796 INFO:     Epoch: 62
2022-11-28 00:54:36,540 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4716005233878439, 'Total loss': 0.4716005233878439} | train loss {'Reaction outcome loss': 0.3178846430717682, 'Total loss': 0.3178846430717682}
2022-11-28 00:54:36,540 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:36,540 INFO:     Epoch: 63
2022-11-28 00:54:37,282 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4822207751937888, 'Total loss': 0.4822207751937888} | train loss {'Reaction outcome loss': 0.31686961629561017, 'Total loss': 0.31686961629561017}
2022-11-28 00:54:37,282 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:37,282 INFO:     Epoch: 64
2022-11-28 00:54:38,025 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4382816397807222, 'Total loss': 0.4382816397807222} | train loss {'Reaction outcome loss': 0.3067152813989289, 'Total loss': 0.3067152813989289}
2022-11-28 00:54:38,025 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:38,025 INFO:     Epoch: 65
2022-11-28 00:54:38,767 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4469562318514694, 'Total loss': 0.4469562318514694} | train loss {'Reaction outcome loss': 0.3116922846862248, 'Total loss': 0.3116922846862248}
2022-11-28 00:54:38,767 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:38,767 INFO:     Epoch: 66
2022-11-28 00:54:39,512 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45433783277191897, 'Total loss': 0.45433783277191897} | train loss {'Reaction outcome loss': 0.32324287152411985, 'Total loss': 0.32324287152411985}
2022-11-28 00:54:39,512 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:39,512 INFO:     Epoch: 67
2022-11-28 00:54:40,258 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4628297517245466, 'Total loss': 0.4628297517245466} | train loss {'Reaction outcome loss': 0.31161336179594606, 'Total loss': 0.31161336179594606}
2022-11-28 00:54:40,258 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:40,258 INFO:     Epoch: 68
2022-11-28 00:54:41,003 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4726038228043101, 'Total loss': 0.4726038228043101} | train loss {'Reaction outcome loss': 0.31147468357670066, 'Total loss': 0.31147468357670066}
2022-11-28 00:54:41,003 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:41,003 INFO:     Epoch: 69
2022-11-28 00:54:41,748 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45885181528600777, 'Total loss': 0.45885181528600777} | train loss {'Reaction outcome loss': 0.3107236907190206, 'Total loss': 0.3107236907190206}
2022-11-28 00:54:41,748 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:41,748 INFO:     Epoch: 70
2022-11-28 00:54:42,491 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5126917199655012, 'Total loss': 0.5126917199655012} | train loss {'Reaction outcome loss': 0.31376209408044814, 'Total loss': 0.31376209408044814}
2022-11-28 00:54:42,491 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:42,492 INFO:     Epoch: 71
2022-11-28 00:54:43,235 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4683798309415579, 'Total loss': 0.4683798309415579} | train loss {'Reaction outcome loss': 0.3176422760498767, 'Total loss': 0.3176422760498767}
2022-11-28 00:54:43,236 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:43,236 INFO:     Epoch: 72
2022-11-28 00:54:43,979 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47184338115833024, 'Total loss': 0.47184338115833024} | train loss {'Reaction outcome loss': 0.3225719875523022, 'Total loss': 0.3225719875523022}
2022-11-28 00:54:43,979 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:43,979 INFO:     Epoch: 73
2022-11-28 00:54:44,720 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5255400344560092, 'Total loss': 0.5255400344560092} | train loss {'Reaction outcome loss': 0.31627613190485504, 'Total loss': 0.31627613190485504}
2022-11-28 00:54:44,721 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:44,721 INFO:     Epoch: 74
2022-11-28 00:54:45,462 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.50591730190949, 'Total loss': 0.50591730190949} | train loss {'Reaction outcome loss': 0.31904541440308093, 'Total loss': 0.31904541440308093}
2022-11-28 00:54:45,462 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:45,462 INFO:     Epoch: 75
2022-11-28 00:54:46,212 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4638702309351753, 'Total loss': 0.4638702309351753} | train loss {'Reaction outcome loss': 0.31240969744263863, 'Total loss': 0.31240969744263863}
2022-11-28 00:54:46,212 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:46,212 INFO:     Epoch: 76
2022-11-28 00:54:46,957 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44755289364944806, 'Total loss': 0.44755289364944806} | train loss {'Reaction outcome loss': 0.32265694877322837, 'Total loss': 0.32265694877322837}
2022-11-28 00:54:46,957 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:46,957 INFO:     Epoch: 77
2022-11-28 00:54:47,703 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4594715748998252, 'Total loss': 0.4594715748998252} | train loss {'Reaction outcome loss': 0.30781392667974744, 'Total loss': 0.30781392667974744}
2022-11-28 00:54:47,703 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:47,703 INFO:     Epoch: 78
2022-11-28 00:54:48,448 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45060091973705724, 'Total loss': 0.45060091973705724} | train loss {'Reaction outcome loss': 0.31923631791557583, 'Total loss': 0.31923631791557583}
2022-11-28 00:54:48,448 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:48,448 INFO:     Epoch: 79
2022-11-28 00:54:49,191 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4558117067949338, 'Total loss': 0.4558117067949338} | train loss {'Reaction outcome loss': 0.3080448017892789, 'Total loss': 0.3080448017892789}
2022-11-28 00:54:49,191 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:49,191 INFO:     Epoch: 80
2022-11-28 00:54:49,939 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4700105332515456, 'Total loss': 0.4700105332515456} | train loss {'Reaction outcome loss': 0.3237006955304924, 'Total loss': 0.3237006955304924}
2022-11-28 00:54:49,939 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:49,939 INFO:     Epoch: 81
2022-11-28 00:54:50,686 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46437284316528926, 'Total loss': 0.46437284316528926} | train loss {'Reaction outcome loss': 0.32520466109319607, 'Total loss': 0.32520466109319607}
2022-11-28 00:54:50,687 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:50,687 INFO:     Epoch: 82
2022-11-28 00:54:51,433 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.454814901067452, 'Total loss': 0.454814901067452} | train loss {'Reaction outcome loss': 0.3054792113450109, 'Total loss': 0.3054792113450109}
2022-11-28 00:54:51,433 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:51,433 INFO:     Epoch: 83
2022-11-28 00:54:52,179 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46369340270757675, 'Total loss': 0.46369340270757675} | train loss {'Reaction outcome loss': 0.3115748463540661, 'Total loss': 0.3115748463540661}
2022-11-28 00:54:52,179 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:52,179 INFO:     Epoch: 84
2022-11-28 00:54:52,925 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44299958138303325, 'Total loss': 0.44299958138303325} | train loss {'Reaction outcome loss': 0.3117823566709246, 'Total loss': 0.3117823566709246}
2022-11-28 00:54:52,926 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:52,926 INFO:     Epoch: 85
2022-11-28 00:54:53,671 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4619341367347674, 'Total loss': 0.4619341367347674} | train loss {'Reaction outcome loss': 0.3124385638504612, 'Total loss': 0.3124385638504612}
2022-11-28 00:54:53,671 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:53,671 INFO:     Epoch: 86
2022-11-28 00:54:54,418 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4446362307803197, 'Total loss': 0.4446362307803197} | train loss {'Reaction outcome loss': 0.31599249636032145, 'Total loss': 0.31599249636032145}
2022-11-28 00:54:54,418 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:54,418 INFO:     Epoch: 87
2022-11-28 00:54:55,165 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47661839391697536, 'Total loss': 0.47661839391697536} | train loss {'Reaction outcome loss': 0.3128018931922864, 'Total loss': 0.3128018931922864}
2022-11-28 00:54:55,166 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:55,166 INFO:     Epoch: 88
2022-11-28 00:54:55,912 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5152075082402338, 'Total loss': 0.5152075082402338} | train loss {'Reaction outcome loss': 0.3077624346224629, 'Total loss': 0.3077624346224629}
2022-11-28 00:54:55,912 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:55,912 INFO:     Epoch: 89
2022-11-28 00:54:56,662 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4425315518270839, 'Total loss': 0.4425315518270839} | train loss {'Reaction outcome loss': 0.31245431300936916, 'Total loss': 0.31245431300936916}
2022-11-28 00:54:56,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:56,662 INFO:     Epoch: 90
2022-11-28 00:54:57,407 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4638483148406852, 'Total loss': 0.4638483148406852} | train loss {'Reaction outcome loss': 0.32139951601928596, 'Total loss': 0.32139951601928596}
2022-11-28 00:54:57,407 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:57,407 INFO:     Epoch: 91
2022-11-28 00:54:58,152 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5316499779847536, 'Total loss': 0.5316499779847536} | train loss {'Reaction outcome loss': 0.31279628942815624, 'Total loss': 0.31279628942815624}
2022-11-28 00:54:58,152 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:58,152 INFO:     Epoch: 92
2022-11-28 00:54:58,897 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44196651774373924, 'Total loss': 0.44196651774373924} | train loss {'Reaction outcome loss': 0.3126129227633379, 'Total loss': 0.3126129227633379}
2022-11-28 00:54:58,897 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:58,897 INFO:     Epoch: 93
2022-11-28 00:54:59,647 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45432610538872803, 'Total loss': 0.45432610538872803} | train loss {'Reaction outcome loss': 0.3104485043153471, 'Total loss': 0.3104485043153471}
2022-11-28 00:54:59,647 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:54:59,647 INFO:     Epoch: 94
2022-11-28 00:55:00,393 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4579689898951487, 'Total loss': 0.4579689898951487} | train loss {'Reaction outcome loss': 0.3133131356871858, 'Total loss': 0.3133131356871858}
2022-11-28 00:55:00,393 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:00,393 INFO:     Epoch: 95
2022-11-28 00:55:01,139 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.463456110793314, 'Total loss': 0.463456110793314} | train loss {'Reaction outcome loss': 0.3247213723404067, 'Total loss': 0.3247213723404067}
2022-11-28 00:55:01,139 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:01,140 INFO:     Epoch: 96
2022-11-28 00:55:01,882 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4492335194213824, 'Total loss': 0.4492335194213824} | train loss {'Reaction outcome loss': 0.29947305537608204, 'Total loss': 0.29947305537608204}
2022-11-28 00:55:01,883 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:01,883 INFO:     Epoch: 97
2022-11-28 00:55:02,623 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4451628794724291, 'Total loss': 0.4451628794724291} | train loss {'Reaction outcome loss': 0.31727460367339, 'Total loss': 0.31727460367339}
2022-11-28 00:55:02,623 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:02,623 INFO:     Epoch: 98
2022-11-28 00:55:03,368 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47844723950732837, 'Total loss': 0.47844723950732837} | train loss {'Reaction outcome loss': 0.3121823888348073, 'Total loss': 0.3121823888348073}
2022-11-28 00:55:03,368 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:03,368 INFO:     Epoch: 99
2022-11-28 00:55:04,109 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4639087309214202, 'Total loss': 0.4639087309214202} | train loss {'Reaction outcome loss': 0.3180962910457533, 'Total loss': 0.3180962910457533}
2022-11-28 00:55:04,109 INFO:     Best model found after epoch 44 of 100.
2022-11-28 00:55:04,109 INFO:   Done with stage: TRAINING
2022-11-28 00:55:04,109 INFO:   Starting stage: EVALUATION
2022-11-28 00:55:04,235 INFO:   Done with stage: EVALUATION
2022-11-28 00:55:04,235 INFO:   Leaving out SEQ value Fold_3
2022-11-28 00:55:04,248 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 00:55:04,248 INFO:   Starting stage: FEATURE SCALING
2022-11-28 00:55:04,890 INFO:   Done with stage: FEATURE SCALING
2022-11-28 00:55:04,890 INFO:   Starting stage: SCALING TARGETS
2022-11-28 00:55:04,960 INFO:   Done with stage: SCALING TARGETS
2022-11-28 00:55:04,961 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:55:04,961 INFO:     No hyperparam tuning for this model
2022-11-28 00:55:04,961 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:55:04,961 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 00:55:04,961 INFO:     None feature selector for col prot
2022-11-28 00:55:04,962 INFO:     None feature selector for col prot
2022-11-28 00:55:04,962 INFO:     None feature selector for col prot
2022-11-28 00:55:04,962 INFO:     None feature selector for col chem
2022-11-28 00:55:04,962 INFO:     None feature selector for col chem
2022-11-28 00:55:04,962 INFO:     None feature selector for col chem
2022-11-28 00:55:04,962 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 00:55:04,962 INFO:   Starting stage: BUILD MODEL
2022-11-28 00:55:04,964 INFO:     Number of params in model 169741
2022-11-28 00:55:04,967 INFO:   Done with stage: BUILD MODEL
2022-11-28 00:55:04,967 INFO:   Starting stage: TRAINING
2022-11-28 00:55:05,021 INFO:     Val loss before train {'Reaction outcome loss': 1.0032546450925428, 'Total loss': 1.0032546450925428}
2022-11-28 00:55:05,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:05,021 INFO:     Epoch: 0
2022-11-28 00:55:05,759 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5313304912212283, 'Total loss': 0.5313304912212283} | train loss {'Reaction outcome loss': 0.6163904061693637, 'Total loss': 0.6163904061693637}
2022-11-28 00:55:05,759 INFO:     Found new best model at epoch 0
2022-11-28 00:55:05,760 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:05,760 INFO:     Epoch: 1
2022-11-28 00:55:06,497 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48631088816842366, 'Total loss': 0.48631088816842366} | train loss {'Reaction outcome loss': 0.4907744927484481, 'Total loss': 0.4907744927484481}
2022-11-28 00:55:06,497 INFO:     Found new best model at epoch 1
2022-11-28 00:55:06,498 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:06,498 INFO:     Epoch: 2
2022-11-28 00:55:07,235 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4837799949008365, 'Total loss': 0.4837799949008365} | train loss {'Reaction outcome loss': 0.44984571379227717, 'Total loss': 0.44984571379227717}
2022-11-28 00:55:07,236 INFO:     Found new best model at epoch 2
2022-11-28 00:55:07,236 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:07,237 INFO:     Epoch: 3
2022-11-28 00:55:07,973 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.457244997454244, 'Total loss': 0.457244997454244} | train loss {'Reaction outcome loss': 0.4218662112462716, 'Total loss': 0.4218662112462716}
2022-11-28 00:55:07,973 INFO:     Found new best model at epoch 3
2022-11-28 00:55:07,973 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:07,974 INFO:     Epoch: 4
2022-11-28 00:55:08,710 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4707362083501594, 'Total loss': 0.4707362083501594} | train loss {'Reaction outcome loss': 0.41847582280513695, 'Total loss': 0.41847582280513695}
2022-11-28 00:55:08,710 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:08,710 INFO:     Epoch: 5
2022-11-28 00:55:09,448 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4761075509148975, 'Total loss': 0.4761075509148975} | train loss {'Reaction outcome loss': 0.39771805361646123, 'Total loss': 0.39771805361646123}
2022-11-28 00:55:09,448 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:09,448 INFO:     Epoch: 6
2022-11-28 00:55:10,189 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4222238157377687, 'Total loss': 0.4222238157377687} | train loss {'Reaction outcome loss': 0.39372103276555653, 'Total loss': 0.39372103276555653}
2022-11-28 00:55:10,189 INFO:     Found new best model at epoch 6
2022-11-28 00:55:10,190 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:10,190 INFO:     Epoch: 7
2022-11-28 00:55:10,927 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4311948702778927, 'Total loss': 0.4311948702778927} | train loss {'Reaction outcome loss': 0.39248697575731356, 'Total loss': 0.39248697575731356}
2022-11-28 00:55:10,928 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:10,928 INFO:     Epoch: 8
2022-11-28 00:55:11,666 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45643167093742726, 'Total loss': 0.45643167093742726} | train loss {'Reaction outcome loss': 0.38082837945491566, 'Total loss': 0.38082837945491566}
2022-11-28 00:55:11,667 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:11,667 INFO:     Epoch: 9
2022-11-28 00:55:12,406 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46406450243883357, 'Total loss': 0.46406450243883357} | train loss {'Reaction outcome loss': 0.381251684771698, 'Total loss': 0.381251684771698}
2022-11-28 00:55:12,406 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:12,406 INFO:     Epoch: 10
2022-11-28 00:55:13,146 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4403928518295288, 'Total loss': 0.4403928518295288} | train loss {'Reaction outcome loss': 0.3673305431777825, 'Total loss': 0.3673305431777825}
2022-11-28 00:55:13,146 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:13,147 INFO:     Epoch: 11
2022-11-28 00:55:13,883 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4563922216725904, 'Total loss': 0.4563922216725904} | train loss {'Reaction outcome loss': 0.3715560222197263, 'Total loss': 0.3715560222197263}
2022-11-28 00:55:13,884 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:13,884 INFO:     Epoch: 12
2022-11-28 00:55:14,618 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.413924757477849, 'Total loss': 0.413924757477849} | train loss {'Reaction outcome loss': 0.3701996275025313, 'Total loss': 0.3701996275025313}
2022-11-28 00:55:14,619 INFO:     Found new best model at epoch 12
2022-11-28 00:55:14,619 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:14,620 INFO:     Epoch: 13
2022-11-28 00:55:15,355 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.440496027469635, 'Total loss': 0.440496027469635} | train loss {'Reaction outcome loss': 0.36435438784175234, 'Total loss': 0.36435438784175234}
2022-11-28 00:55:15,355 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:15,355 INFO:     Epoch: 14
2022-11-28 00:55:16,090 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4495930571195691, 'Total loss': 0.4495930571195691} | train loss {'Reaction outcome loss': 0.3643031540464182, 'Total loss': 0.3643031540464182}
2022-11-28 00:55:16,090 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:16,090 INFO:     Epoch: 15
2022-11-28 00:55:16,825 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42062847524188285, 'Total loss': 0.42062847524188285} | train loss {'Reaction outcome loss': 0.3557385121334772, 'Total loss': 0.3557385121334772}
2022-11-28 00:55:16,825 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:16,825 INFO:     Epoch: 16
2022-11-28 00:55:17,561 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4411364183869473, 'Total loss': 0.4411364183869473} | train loss {'Reaction outcome loss': 0.35420338009468844, 'Total loss': 0.35420338009468844}
2022-11-28 00:55:17,561 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:17,561 INFO:     Epoch: 17
2022-11-28 00:55:18,294 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4118061065673828, 'Total loss': 0.4118061065673828} | train loss {'Reaction outcome loss': 0.3509335818349338, 'Total loss': 0.3509335818349338}
2022-11-28 00:55:18,294 INFO:     Found new best model at epoch 17
2022-11-28 00:55:18,295 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:18,295 INFO:     Epoch: 18
2022-11-28 00:55:19,032 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.414707311710646, 'Total loss': 0.414707311710646} | train loss {'Reaction outcome loss': 0.3481288907408226, 'Total loss': 0.3481288907408226}
2022-11-28 00:55:19,032 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:19,032 INFO:     Epoch: 19
2022-11-28 00:55:19,767 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42174641857313555, 'Total loss': 0.42174641857313555} | train loss {'Reaction outcome loss': 0.34890716596216453, 'Total loss': 0.34890716596216453}
2022-11-28 00:55:19,767 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:19,767 INFO:     Epoch: 20
2022-11-28 00:55:20,504 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4254351940958999, 'Total loss': 0.4254351940958999} | train loss {'Reaction outcome loss': 0.34510343005789107, 'Total loss': 0.34510343005789107}
2022-11-28 00:55:20,504 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:20,504 INFO:     Epoch: 21
2022-11-28 00:55:21,233 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46136287859705993, 'Total loss': 0.46136287859705993} | train loss {'Reaction outcome loss': 0.340723953408296, 'Total loss': 0.340723953408296}
2022-11-28 00:55:21,234 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:21,234 INFO:     Epoch: 22
2022-11-28 00:55:21,969 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43725100332914396, 'Total loss': 0.43725100332914396} | train loss {'Reaction outcome loss': 0.34677063200439584, 'Total loss': 0.34677063200439584}
2022-11-28 00:55:21,969 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:21,970 INFO:     Epoch: 23
2022-11-28 00:55:22,702 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39818637488886366, 'Total loss': 0.39818637488886366} | train loss {'Reaction outcome loss': 0.3376454223313781, 'Total loss': 0.3376454223313781}
2022-11-28 00:55:22,702 INFO:     Found new best model at epoch 23
2022-11-28 00:55:22,703 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:22,703 INFO:     Epoch: 24
2022-11-28 00:55:23,437 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4509050101041794, 'Total loss': 0.4509050101041794} | train loss {'Reaction outcome loss': 0.33999261394387387, 'Total loss': 0.33999261394387387}
2022-11-28 00:55:23,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:23,437 INFO:     Epoch: 25
2022-11-28 00:55:24,170 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41302028974128324, 'Total loss': 0.41302028974128324} | train loss {'Reaction outcome loss': 0.3398722092025593, 'Total loss': 0.3398722092025593}
2022-11-28 00:55:24,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:24,170 INFO:     Epoch: 26
2022-11-28 00:55:24,904 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4272235041094381, 'Total loss': 0.4272235041094381} | train loss {'Reaction outcome loss': 0.3329241492281683, 'Total loss': 0.3329241492281683}
2022-11-28 00:55:24,904 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:24,904 INFO:     Epoch: 27
2022-11-28 00:55:25,642 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.421130521352901, 'Total loss': 0.421130521352901} | train loss {'Reaction outcome loss': 0.34010496027156956, 'Total loss': 0.34010496027156956}
2022-11-28 00:55:25,642 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:25,642 INFO:     Epoch: 28
2022-11-28 00:55:26,377 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41254370018493297, 'Total loss': 0.41254370018493297} | train loss {'Reaction outcome loss': 0.33013227239983983, 'Total loss': 0.33013227239983983}
2022-11-28 00:55:26,378 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:26,379 INFO:     Epoch: 29
2022-11-28 00:55:27,112 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.417325240234996, 'Total loss': 0.417325240234996} | train loss {'Reaction outcome loss': 0.3276933791634978, 'Total loss': 0.3276933791634978}
2022-11-28 00:55:27,113 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:27,113 INFO:     Epoch: 30
2022-11-28 00:55:27,845 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4504474058400753, 'Total loss': 0.4504474058400753} | train loss {'Reaction outcome loss': 0.326386103681365, 'Total loss': 0.326386103681365}
2022-11-28 00:55:27,845 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:27,845 INFO:     Epoch: 31
2022-11-28 00:55:28,579 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4136118736377982, 'Total loss': 0.4136118736377982} | train loss {'Reaction outcome loss': 0.33631209656596184, 'Total loss': 0.33631209656596184}
2022-11-28 00:55:28,579 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:28,579 INFO:     Epoch: 32
2022-11-28 00:55:29,315 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4027893369974092, 'Total loss': 0.4027893369974092} | train loss {'Reaction outcome loss': 0.3308351510433388, 'Total loss': 0.3308351510433388}
2022-11-28 00:55:29,315 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:29,315 INFO:     Epoch: 33
2022-11-28 00:55:30,053 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4299259767975918, 'Total loss': 0.4299259767975918} | train loss {'Reaction outcome loss': 0.32848273684866114, 'Total loss': 0.32848273684866114}
2022-11-28 00:55:30,054 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:30,054 INFO:     Epoch: 34
2022-11-28 00:55:30,794 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42626844745042713, 'Total loss': 0.42626844745042713} | train loss {'Reaction outcome loss': 0.3296353589193743, 'Total loss': 0.3296353589193743}
2022-11-28 00:55:30,794 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:30,794 INFO:     Epoch: 35
2022-11-28 00:55:31,532 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4191189082555993, 'Total loss': 0.4191189082555993} | train loss {'Reaction outcome loss': 0.325417165018496, 'Total loss': 0.325417165018496}
2022-11-28 00:55:31,533 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:31,533 INFO:     Epoch: 36
2022-11-28 00:55:32,266 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39804230734359386, 'Total loss': 0.39804230734359386} | train loss {'Reaction outcome loss': 0.32966342776036656, 'Total loss': 0.32966342776036656}
2022-11-28 00:55:32,266 INFO:     Found new best model at epoch 36
2022-11-28 00:55:32,267 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:32,267 INFO:     Epoch: 37
2022-11-28 00:55:32,999 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40222126002921615, 'Total loss': 0.40222126002921615} | train loss {'Reaction outcome loss': 0.3272722640120592, 'Total loss': 0.3272722640120592}
2022-11-28 00:55:33,000 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:33,000 INFO:     Epoch: 38
2022-11-28 00:55:33,735 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4139256134282711, 'Total loss': 0.4139256134282711} | train loss {'Reaction outcome loss': 0.33339496057663787, 'Total loss': 0.33339496057663787}
2022-11-28 00:55:33,735 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:33,735 INFO:     Epoch: 39
2022-11-28 00:55:34,471 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.405723454647286, 'Total loss': 0.405723454647286} | train loss {'Reaction outcome loss': 0.32547526067641913, 'Total loss': 0.32547526067641913}
2022-11-28 00:55:34,471 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:34,471 INFO:     Epoch: 40
2022-11-28 00:55:35,207 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4256050785960153, 'Total loss': 0.4256050785960153} | train loss {'Reaction outcome loss': 0.3215127368228602, 'Total loss': 0.3215127368228602}
2022-11-28 00:55:35,207 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:35,207 INFO:     Epoch: 41
2022-11-28 00:55:35,939 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39760072286738907, 'Total loss': 0.39760072286738907} | train loss {'Reaction outcome loss': 0.3264551125161472, 'Total loss': 0.3264551125161472}
2022-11-28 00:55:35,940 INFO:     Found new best model at epoch 41
2022-11-28 00:55:35,941 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:35,941 INFO:     Epoch: 42
2022-11-28 00:55:36,674 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4170008991346803, 'Total loss': 0.4170008991346803} | train loss {'Reaction outcome loss': 0.3250309722498059, 'Total loss': 0.3250309722498059}
2022-11-28 00:55:36,674 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:36,674 INFO:     Epoch: 43
2022-11-28 00:55:37,410 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4272911711487659, 'Total loss': 0.4272911711487659} | train loss {'Reaction outcome loss': 0.3200170095460337, 'Total loss': 0.3200170095460337}
2022-11-28 00:55:37,410 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:37,410 INFO:     Epoch: 44
2022-11-28 00:55:38,144 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42961569338343863, 'Total loss': 0.42961569338343863} | train loss {'Reaction outcome loss': 0.32279577646709856, 'Total loss': 0.32279577646709856}
2022-11-28 00:55:38,144 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:38,144 INFO:     Epoch: 45
2022-11-28 00:55:38,875 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4052669038606245, 'Total loss': 0.4052669038606245} | train loss {'Reaction outcome loss': 0.3206370048774559, 'Total loss': 0.3206370048774559}
2022-11-28 00:55:38,875 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:38,876 INFO:     Epoch: 46
2022-11-28 00:55:39,610 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.399982362465803, 'Total loss': 0.399982362465803} | train loss {'Reaction outcome loss': 0.3239074093518687, 'Total loss': 0.3239074093518687}
2022-11-28 00:55:39,611 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:39,611 INFO:     Epoch: 47
2022-11-28 00:55:40,346 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41292382222275403, 'Total loss': 0.41292382222275403} | train loss {'Reaction outcome loss': 0.31733860063259717, 'Total loss': 0.31733860063259717}
2022-11-28 00:55:40,346 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:40,346 INFO:     Epoch: 48
2022-11-28 00:55:41,080 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4248869370582492, 'Total loss': 0.4248869370582492} | train loss {'Reaction outcome loss': 0.31287106957103383, 'Total loss': 0.31287106957103383}
2022-11-28 00:55:41,080 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:41,080 INFO:     Epoch: 49
2022-11-28 00:55:41,818 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40081882407498914, 'Total loss': 0.40081882407498914} | train loss {'Reaction outcome loss': 0.321615083402664, 'Total loss': 0.321615083402664}
2022-11-28 00:55:41,818 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:41,819 INFO:     Epoch: 50
2022-11-28 00:55:42,556 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41218115839847297, 'Total loss': 0.41218115839847297} | train loss {'Reaction outcome loss': 0.30475650797979753, 'Total loss': 0.30475650797979753}
2022-11-28 00:55:42,556 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:42,556 INFO:     Epoch: 51
2022-11-28 00:55:43,294 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40917935118425725, 'Total loss': 0.40917935118425725} | train loss {'Reaction outcome loss': 0.31884608891044486, 'Total loss': 0.31884608891044486}
2022-11-28 00:55:43,294 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:43,294 INFO:     Epoch: 52
2022-11-28 00:55:44,034 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4134342812521513, 'Total loss': 0.4134342812521513} | train loss {'Reaction outcome loss': 0.3143159090617641, 'Total loss': 0.3143159090617641}
2022-11-28 00:55:44,034 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:44,034 INFO:     Epoch: 53
2022-11-28 00:55:44,773 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44319686362909716, 'Total loss': 0.44319686362909716} | train loss {'Reaction outcome loss': 0.30907975946415644, 'Total loss': 0.30907975946415644}
2022-11-28 00:55:44,773 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:44,773 INFO:     Epoch: 54
2022-11-28 00:55:45,508 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40173705338045607, 'Total loss': 0.40173705338045607} | train loss {'Reaction outcome loss': 0.3147812053011578, 'Total loss': 0.3147812053011578}
2022-11-28 00:55:45,509 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:45,509 INFO:     Epoch: 55
2022-11-28 00:55:46,248 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3957461652367614, 'Total loss': 0.3957461652367614} | train loss {'Reaction outcome loss': 0.31610384131552743, 'Total loss': 0.31610384131552743}
2022-11-28 00:55:46,248 INFO:     Found new best model at epoch 55
2022-11-28 00:55:46,249 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:46,249 INFO:     Epoch: 56
2022-11-28 00:55:46,988 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4530950285667597, 'Total loss': 0.4530950285667597} | train loss {'Reaction outcome loss': 0.31172089565728534, 'Total loss': 0.31172089565728534}
2022-11-28 00:55:46,988 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:46,988 INFO:     Epoch: 57
2022-11-28 00:55:47,729 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43301126846047333, 'Total loss': 0.43301126846047333} | train loss {'Reaction outcome loss': 0.31071209492253477, 'Total loss': 0.31071209492253477}
2022-11-28 00:55:47,729 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:47,729 INFO:     Epoch: 58
2022-11-28 00:55:48,468 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4121358022093773, 'Total loss': 0.4121358022093773} | train loss {'Reaction outcome loss': 0.31645508273886364, 'Total loss': 0.31645508273886364}
2022-11-28 00:55:48,468 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:48,469 INFO:     Epoch: 59
2022-11-28 00:55:49,206 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4236037963351538, 'Total loss': 0.4236037963351538} | train loss {'Reaction outcome loss': 0.30631325003065046, 'Total loss': 0.30631325003065046}
2022-11-28 00:55:49,207 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:49,207 INFO:     Epoch: 60
2022-11-28 00:55:49,946 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40569666669119236, 'Total loss': 0.40569666669119236} | train loss {'Reaction outcome loss': 0.31446510886193296, 'Total loss': 0.31446510886193296}
2022-11-28 00:55:49,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:49,946 INFO:     Epoch: 61
2022-11-28 00:55:50,686 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40658315271139145, 'Total loss': 0.40658315271139145} | train loss {'Reaction outcome loss': 0.30431248012502665, 'Total loss': 0.30431248012502665}
2022-11-28 00:55:50,686 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:50,686 INFO:     Epoch: 62
2022-11-28 00:55:51,423 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4548764381297799, 'Total loss': 0.4548764381297799} | train loss {'Reaction outcome loss': 0.30713550506739834, 'Total loss': 0.30713550506739834}
2022-11-28 00:55:51,423 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:51,423 INFO:     Epoch: 63
2022-11-28 00:55:52,161 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39544802973436755, 'Total loss': 0.39544802973436755} | train loss {'Reaction outcome loss': 0.31695282094363797, 'Total loss': 0.31695282094363797}
2022-11-28 00:55:52,161 INFO:     Found new best model at epoch 63
2022-11-28 00:55:52,162 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:52,162 INFO:     Epoch: 64
2022-11-28 00:55:52,899 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40210624593634936, 'Total loss': 0.40210624593634936} | train loss {'Reaction outcome loss': 0.3078232778877508, 'Total loss': 0.3078232778877508}
2022-11-28 00:55:52,900 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:52,900 INFO:     Epoch: 65
2022-11-28 00:55:53,639 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3966495181585467, 'Total loss': 0.3966495181585467} | train loss {'Reaction outcome loss': 0.3066709560998639, 'Total loss': 0.3066709560998639}
2022-11-28 00:55:53,639 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:53,639 INFO:     Epoch: 66
2022-11-28 00:55:54,380 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40798296051663024, 'Total loss': 0.40798296051663024} | train loss {'Reaction outcome loss': 0.317482428625226, 'Total loss': 0.317482428625226}
2022-11-28 00:55:54,380 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:54,380 INFO:     Epoch: 67
2022-11-28 00:55:55,120 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42589262370453324, 'Total loss': 0.42589262370453324} | train loss {'Reaction outcome loss': 0.3185611888766289, 'Total loss': 0.3185611888766289}
2022-11-28 00:55:55,121 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:55,121 INFO:     Epoch: 68
2022-11-28 00:55:55,860 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39930767999138944, 'Total loss': 0.39930767999138944} | train loss {'Reaction outcome loss': 0.31395245767885543, 'Total loss': 0.31395245767885543}
2022-11-28 00:55:55,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:55,860 INFO:     Epoch: 69
2022-11-28 00:55:56,600 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40769584719524826, 'Total loss': 0.40769584719524826} | train loss {'Reaction outcome loss': 0.3103252489302979, 'Total loss': 0.3103252489302979}
2022-11-28 00:55:56,600 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:56,601 INFO:     Epoch: 70
2022-11-28 00:55:57,345 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37972896494144615, 'Total loss': 0.37972896494144615} | train loss {'Reaction outcome loss': 0.32028423739810946, 'Total loss': 0.32028423739810946}
2022-11-28 00:55:57,346 INFO:     Found new best model at epoch 70
2022-11-28 00:55:57,347 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:57,347 INFO:     Epoch: 71
2022-11-28 00:55:58,085 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39026507319406023, 'Total loss': 0.39026507319406023} | train loss {'Reaction outcome loss': 0.30133720749958615, 'Total loss': 0.30133720749958615}
2022-11-28 00:55:58,085 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:58,086 INFO:     Epoch: 72
2022-11-28 00:55:58,823 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41791596315627877, 'Total loss': 0.41791596315627877} | train loss {'Reaction outcome loss': 0.3152060618043923, 'Total loss': 0.3152060618043923}
2022-11-28 00:55:58,823 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:58,823 INFO:     Epoch: 73
2022-11-28 00:55:59,560 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40289581861606866, 'Total loss': 0.40289581861606866} | train loss {'Reaction outcome loss': 0.3091246642050196, 'Total loss': 0.3091246642050196}
2022-11-28 00:55:59,560 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:55:59,561 INFO:     Epoch: 74
2022-11-28 00:56:00,301 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4187721769477046, 'Total loss': 0.4187721769477046} | train loss {'Reaction outcome loss': 0.3000767305340679, 'Total loss': 0.3000767305340679}
2022-11-28 00:56:00,301 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:00,301 INFO:     Epoch: 75
2022-11-28 00:56:01,038 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46102275578088536, 'Total loss': 0.46102275578088536} | train loss {'Reaction outcome loss': 0.3078022201347058, 'Total loss': 0.3078022201347058}
2022-11-28 00:56:01,038 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:01,038 INFO:     Epoch: 76
2022-11-28 00:56:01,773 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42348331767459246, 'Total loss': 0.42348331767459246} | train loss {'Reaction outcome loss': 0.30864243762048543, 'Total loss': 0.30864243762048543}
2022-11-28 00:56:01,773 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:01,773 INFO:     Epoch: 77
2022-11-28 00:56:02,512 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3942798481777657, 'Total loss': 0.3942798481777657} | train loss {'Reaction outcome loss': 0.3080798849829885, 'Total loss': 0.3080798849829885}
2022-11-28 00:56:02,512 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:02,512 INFO:     Epoch: 78
2022-11-28 00:56:03,254 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3986256923093352, 'Total loss': 0.3986256923093352} | train loss {'Reaction outcome loss': 0.3109817700613229, 'Total loss': 0.3109817700613229}
2022-11-28 00:56:03,254 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:03,254 INFO:     Epoch: 79
2022-11-28 00:56:03,993 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3994947041189948, 'Total loss': 0.3994947041189948} | train loss {'Reaction outcome loss': 0.3117924644230086, 'Total loss': 0.3117924644230086}
2022-11-28 00:56:03,994 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:03,994 INFO:     Epoch: 80
2022-11-28 00:56:04,731 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4048063599093016, 'Total loss': 0.4048063599093016} | train loss {'Reaction outcome loss': 0.302577941693732, 'Total loss': 0.302577941693732}
2022-11-28 00:56:04,731 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:04,731 INFO:     Epoch: 81
2022-11-28 00:56:05,468 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42021584337533907, 'Total loss': 0.42021584337533907} | train loss {'Reaction outcome loss': 0.31449598805276585, 'Total loss': 0.31449598805276585}
2022-11-28 00:56:05,468 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:05,468 INFO:     Epoch: 82
2022-11-28 00:56:06,202 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4036802559397941, 'Total loss': 0.4036802559397941} | train loss {'Reaction outcome loss': 0.30880502168638785, 'Total loss': 0.30880502168638785}
2022-11-28 00:56:06,202 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:06,202 INFO:     Epoch: 83
2022-11-28 00:56:06,937 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41810983107533567, 'Total loss': 0.41810983107533567} | train loss {'Reaction outcome loss': 0.3096416275337583, 'Total loss': 0.3096416275337583}
2022-11-28 00:56:06,937 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:06,937 INFO:     Epoch: 84
2022-11-28 00:56:07,678 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40197963804699655, 'Total loss': 0.40197963804699655} | train loss {'Reaction outcome loss': 0.3050793227205267, 'Total loss': 0.3050793227205267}
2022-11-28 00:56:07,678 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:07,678 INFO:     Epoch: 85
2022-11-28 00:56:08,416 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3834688122882399, 'Total loss': 0.3834688122882399} | train loss {'Reaction outcome loss': 0.31078222445899345, 'Total loss': 0.31078222445899345}
2022-11-28 00:56:08,416 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:08,416 INFO:     Epoch: 86
2022-11-28 00:56:09,151 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40184975086256514, 'Total loss': 0.40184975086256514} | train loss {'Reaction outcome loss': 0.30839269467797437, 'Total loss': 0.30839269467797437}
2022-11-28 00:56:09,151 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:09,151 INFO:     Epoch: 87
2022-11-28 00:56:09,886 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40145163272702417, 'Total loss': 0.40145163272702417} | train loss {'Reaction outcome loss': 0.3068643953101557, 'Total loss': 0.3068643953101557}
2022-11-28 00:56:09,886 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:09,886 INFO:     Epoch: 88
2022-11-28 00:56:10,626 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39624412738999654, 'Total loss': 0.39624412738999654} | train loss {'Reaction outcome loss': 0.3054468786557678, 'Total loss': 0.3054468786557678}
2022-11-28 00:56:10,626 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:10,626 INFO:     Epoch: 89
2022-11-28 00:56:11,362 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4199876750624457, 'Total loss': 0.4199876750624457} | train loss {'Reaction outcome loss': 0.3071254775477726, 'Total loss': 0.3071254775477726}
2022-11-28 00:56:11,362 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:11,362 INFO:     Epoch: 90
2022-11-28 00:56:12,101 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4080929877453072, 'Total loss': 0.4080929877453072} | train loss {'Reaction outcome loss': 0.29626832743648623, 'Total loss': 0.29626832743648623}
2022-11-28 00:56:12,101 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:12,101 INFO:     Epoch: 91
2022-11-28 00:56:12,840 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4402245893034824, 'Total loss': 0.4402245893034824} | train loss {'Reaction outcome loss': 0.3041562558319725, 'Total loss': 0.3041562558319725}
2022-11-28 00:56:12,840 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:12,840 INFO:     Epoch: 92
2022-11-28 00:56:13,578 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42750394378983697, 'Total loss': 0.42750394378983697} | train loss {'Reaction outcome loss': 0.30637127822112353, 'Total loss': 0.30637127822112353}
2022-11-28 00:56:13,578 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:13,578 INFO:     Epoch: 93
2022-11-28 00:56:14,320 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40637602865002875, 'Total loss': 0.40637602865002875} | train loss {'Reaction outcome loss': 0.2963308058679104, 'Total loss': 0.2963308058679104}
2022-11-28 00:56:14,321 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:14,321 INFO:     Epoch: 94
2022-11-28 00:56:15,060 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39697517610566563, 'Total loss': 0.39697517610566563} | train loss {'Reaction outcome loss': 0.30226788010265004, 'Total loss': 0.30226788010265004}
2022-11-28 00:56:15,060 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:15,061 INFO:     Epoch: 95
2022-11-28 00:56:15,799 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.392605762495551, 'Total loss': 0.392605762495551} | train loss {'Reaction outcome loss': 0.30503562395079215, 'Total loss': 0.30503562395079215}
2022-11-28 00:56:15,799 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:15,799 INFO:     Epoch: 96
2022-11-28 00:56:16,538 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4120596643797187, 'Total loss': 0.4120596643797187} | train loss {'Reaction outcome loss': 0.30764153172246744, 'Total loss': 0.30764153172246744}
2022-11-28 00:56:16,539 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:16,539 INFO:     Epoch: 97
2022-11-28 00:56:17,275 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41408603413160455, 'Total loss': 0.41408603413160455} | train loss {'Reaction outcome loss': 0.30116337626317485, 'Total loss': 0.30116337626317485}
2022-11-28 00:56:17,275 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:17,275 INFO:     Epoch: 98
2022-11-28 00:56:18,008 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4019244874632636, 'Total loss': 0.4019244874632636} | train loss {'Reaction outcome loss': 0.3020738206925939, 'Total loss': 0.3020738206925939}
2022-11-28 00:56:18,008 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:18,008 INFO:     Epoch: 99
2022-11-28 00:56:18,744 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3960512756954792, 'Total loss': 0.3960512756954792} | train loss {'Reaction outcome loss': 0.3040197873946096, 'Total loss': 0.3040197873946096}
2022-11-28 00:56:18,744 INFO:     Best model found after epoch 71 of 100.
2022-11-28 00:56:18,744 INFO:   Done with stage: TRAINING
2022-11-28 00:56:18,744 INFO:   Starting stage: EVALUATION
2022-11-28 00:56:18,875 INFO:   Done with stage: EVALUATION
2022-11-28 00:56:18,876 INFO:   Leaving out SEQ value Fold_4
2022-11-28 00:56:18,888 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 00:56:18,888 INFO:   Starting stage: FEATURE SCALING
2022-11-28 00:56:19,533 INFO:   Done with stage: FEATURE SCALING
2022-11-28 00:56:19,533 INFO:   Starting stage: SCALING TARGETS
2022-11-28 00:56:19,603 INFO:   Done with stage: SCALING TARGETS
2022-11-28 00:56:19,603 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:56:19,603 INFO:     No hyperparam tuning for this model
2022-11-28 00:56:19,603 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:56:19,603 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 00:56:19,604 INFO:     None feature selector for col prot
2022-11-28 00:56:19,604 INFO:     None feature selector for col prot
2022-11-28 00:56:19,604 INFO:     None feature selector for col prot
2022-11-28 00:56:19,605 INFO:     None feature selector for col chem
2022-11-28 00:56:19,605 INFO:     None feature selector for col chem
2022-11-28 00:56:19,605 INFO:     None feature selector for col chem
2022-11-28 00:56:19,605 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 00:56:19,605 INFO:   Starting stage: BUILD MODEL
2022-11-28 00:56:19,606 INFO:     Number of params in model 169741
2022-11-28 00:56:19,609 INFO:   Done with stage: BUILD MODEL
2022-11-28 00:56:19,609 INFO:   Starting stage: TRAINING
2022-11-28 00:56:19,663 INFO:     Val loss before train {'Reaction outcome loss': 0.9997156736525622, 'Total loss': 0.9997156736525622}
2022-11-28 00:56:19,663 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:19,664 INFO:     Epoch: 0
2022-11-28 00:56:20,403 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5812399543144486, 'Total loss': 0.5812399543144486} | train loss {'Reaction outcome loss': 0.6664163657597133, 'Total loss': 0.6664163657597133}
2022-11-28 00:56:20,403 INFO:     Found new best model at epoch 0
2022-11-28 00:56:20,404 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:20,404 INFO:     Epoch: 1
2022-11-28 00:56:21,144 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.47863071818243375, 'Total loss': 0.47863071818243375} | train loss {'Reaction outcome loss': 0.5122033131669979, 'Total loss': 0.5122033131669979}
2022-11-28 00:56:21,144 INFO:     Found new best model at epoch 1
2022-11-28 00:56:21,145 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:21,145 INFO:     Epoch: 2
2022-11-28 00:56:21,884 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48308947682380676, 'Total loss': 0.48308947682380676} | train loss {'Reaction outcome loss': 0.4779421853775881, 'Total loss': 0.4779421853775881}
2022-11-28 00:56:21,884 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:21,884 INFO:     Epoch: 3
2022-11-28 00:56:22,629 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4503619396551089, 'Total loss': 0.4503619396551089} | train loss {'Reaction outcome loss': 0.45572815896296986, 'Total loss': 0.45572815896296986}
2022-11-28 00:56:22,629 INFO:     Found new best model at epoch 3
2022-11-28 00:56:22,630 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:22,630 INFO:     Epoch: 4
2022-11-28 00:56:23,374 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45125446502457967, 'Total loss': 0.45125446502457967} | train loss {'Reaction outcome loss': 0.43615716476829686, 'Total loss': 0.43615716476829686}
2022-11-28 00:56:23,374 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:23,374 INFO:     Epoch: 5
2022-11-28 00:56:24,121 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.439540219577876, 'Total loss': 0.439540219577876} | train loss {'Reaction outcome loss': 0.4250921469561908, 'Total loss': 0.4250921469561908}
2022-11-28 00:56:24,121 INFO:     Found new best model at epoch 5
2022-11-28 00:56:24,122 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:24,122 INFO:     Epoch: 6
2022-11-28 00:56:24,863 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4238376898521727, 'Total loss': 0.4238376898521727} | train loss {'Reaction outcome loss': 0.4205550346143392, 'Total loss': 0.4205550346143392}
2022-11-28 00:56:24,863 INFO:     Found new best model at epoch 6
2022-11-28 00:56:24,864 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:24,864 INFO:     Epoch: 7
2022-11-28 00:56:25,603 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4366686919873411, 'Total loss': 0.4366686919873411} | train loss {'Reaction outcome loss': 0.4012054209806481, 'Total loss': 0.4012054209806481}
2022-11-28 00:56:25,603 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:25,603 INFO:     Epoch: 8
2022-11-28 00:56:26,343 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42033363269134, 'Total loss': 0.42033363269134} | train loss {'Reaction outcome loss': 0.40761087089776993, 'Total loss': 0.40761087089776993}
2022-11-28 00:56:26,343 INFO:     Found new best model at epoch 8
2022-11-28 00:56:26,344 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:26,344 INFO:     Epoch: 9
2022-11-28 00:56:27,082 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42359180409799924, 'Total loss': 0.42359180409799924} | train loss {'Reaction outcome loss': 0.39548039004510765, 'Total loss': 0.39548039004510765}
2022-11-28 00:56:27,082 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:27,082 INFO:     Epoch: 10
2022-11-28 00:56:27,821 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4157135124233636, 'Total loss': 0.4157135124233636} | train loss {'Reaction outcome loss': 0.38834666576312515, 'Total loss': 0.38834666576312515}
2022-11-28 00:56:27,821 INFO:     Found new best model at epoch 10
2022-11-28 00:56:27,822 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:27,822 INFO:     Epoch: 11
2022-11-28 00:56:28,561 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40925935486500914, 'Total loss': 0.40925935486500914} | train loss {'Reaction outcome loss': 0.3837141086252368, 'Total loss': 0.3837141086252368}
2022-11-28 00:56:28,563 INFO:     Found new best model at epoch 11
2022-11-28 00:56:28,563 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:28,563 INFO:     Epoch: 12
2022-11-28 00:56:29,301 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45207280022176827, 'Total loss': 0.45207280022176827} | train loss {'Reaction outcome loss': 0.37946234208588697, 'Total loss': 0.37946234208588697}
2022-11-28 00:56:29,301 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:29,301 INFO:     Epoch: 13
2022-11-28 00:56:30,046 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3964287547225302, 'Total loss': 0.3964287547225302} | train loss {'Reaction outcome loss': 0.37489798464337176, 'Total loss': 0.37489798464337176}
2022-11-28 00:56:30,046 INFO:     Found new best model at epoch 13
2022-11-28 00:56:30,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:30,047 INFO:     Epoch: 14
2022-11-28 00:56:30,793 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4143672768365253, 'Total loss': 0.4143672768365253} | train loss {'Reaction outcome loss': 0.3745274615531065, 'Total loss': 0.3745274615531065}
2022-11-28 00:56:30,793 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:30,793 INFO:     Epoch: 15
2022-11-28 00:56:31,538 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4151048625565388, 'Total loss': 0.4151048625565388} | train loss {'Reaction outcome loss': 0.36819072946601983, 'Total loss': 0.36819072946601983}
2022-11-28 00:56:31,538 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:31,538 INFO:     Epoch: 16
2022-11-28 00:56:32,276 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4523236809129065, 'Total loss': 0.4523236809129065} | train loss {'Reaction outcome loss': 0.36613667923576976, 'Total loss': 0.36613667923576976}
2022-11-28 00:56:32,276 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:32,276 INFO:     Epoch: 17
2022-11-28 00:56:33,020 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39543585682457144, 'Total loss': 0.39543585682457144} | train loss {'Reaction outcome loss': 0.36348761070747765, 'Total loss': 0.36348761070747765}
2022-11-28 00:56:33,020 INFO:     Found new best model at epoch 17
2022-11-28 00:56:33,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:33,021 INFO:     Epoch: 18
2022-11-28 00:56:33,761 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4262139116498557, 'Total loss': 0.4262139116498557} | train loss {'Reaction outcome loss': 0.36561449921252775, 'Total loss': 0.36561449921252775}
2022-11-28 00:56:33,762 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:33,762 INFO:     Epoch: 19
2022-11-28 00:56:34,497 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4221953627738086, 'Total loss': 0.4221953627738086} | train loss {'Reaction outcome loss': 0.36061736555123813, 'Total loss': 0.36061736555123813}
2022-11-28 00:56:34,497 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:34,498 INFO:     Epoch: 20
2022-11-28 00:56:35,235 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4262785423885692, 'Total loss': 0.4262785423885692} | train loss {'Reaction outcome loss': 0.3539714572989211, 'Total loss': 0.3539714572989211}
2022-11-28 00:56:35,235 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:35,235 INFO:     Epoch: 21
2022-11-28 00:56:35,972 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4147638593885032, 'Total loss': 0.4147638593885032} | train loss {'Reaction outcome loss': 0.35552097622837336, 'Total loss': 0.35552097622837336}
2022-11-28 00:56:35,972 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:35,973 INFO:     Epoch: 22
2022-11-28 00:56:36,709 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4073350971395319, 'Total loss': 0.4073350971395319} | train loss {'Reaction outcome loss': 0.3444611041825645, 'Total loss': 0.3444611041825645}
2022-11-28 00:56:36,709 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:36,710 INFO:     Epoch: 23
2022-11-28 00:56:37,445 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4436996162615039, 'Total loss': 0.4436996162615039} | train loss {'Reaction outcome loss': 0.34830606160115224, 'Total loss': 0.34830606160115224}
2022-11-28 00:56:37,445 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:37,446 INFO:     Epoch: 24
2022-11-28 00:56:38,179 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3961453800174323, 'Total loss': 0.3961453800174323} | train loss {'Reaction outcome loss': 0.3441091934333042, 'Total loss': 0.3441091934333042}
2022-11-28 00:56:38,179 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:38,179 INFO:     Epoch: 25
2022-11-28 00:56:38,919 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43207951906052505, 'Total loss': 0.43207951906052505} | train loss {'Reaction outcome loss': 0.345922753549352, 'Total loss': 0.345922753549352}
2022-11-28 00:56:38,919 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:38,919 INFO:     Epoch: 26
2022-11-28 00:56:39,656 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42963362485170364, 'Total loss': 0.42963362485170364} | train loss {'Reaction outcome loss': 0.3425625606459014, 'Total loss': 0.3425625606459014}
2022-11-28 00:56:39,657 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:39,657 INFO:     Epoch: 27
2022-11-28 00:56:40,391 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4285991351035508, 'Total loss': 0.4285991351035508} | train loss {'Reaction outcome loss': 0.3456633703441036, 'Total loss': 0.3456633703441036}
2022-11-28 00:56:40,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:40,391 INFO:     Epoch: 28
2022-11-28 00:56:41,132 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3931813971562819, 'Total loss': 0.3931813971562819} | train loss {'Reaction outcome loss': 0.34252656898936445, 'Total loss': 0.34252656898936445}
2022-11-28 00:56:41,132 INFO:     Found new best model at epoch 28
2022-11-28 00:56:41,132 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:41,133 INFO:     Epoch: 29
2022-11-28 00:56:41,872 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.466559691185301, 'Total loss': 0.466559691185301} | train loss {'Reaction outcome loss': 0.33755680717984027, 'Total loss': 0.33755680717984027}
2022-11-28 00:56:41,873 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:41,873 INFO:     Epoch: 30
2022-11-28 00:56:42,609 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42206894809549506, 'Total loss': 0.42206894809549506} | train loss {'Reaction outcome loss': 0.3338393887390896, 'Total loss': 0.3338393887390896}
2022-11-28 00:56:42,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:42,609 INFO:     Epoch: 31
2022-11-28 00:56:43,347 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44365108893676236, 'Total loss': 0.44365108893676236} | train loss {'Reaction outcome loss': 0.33409532825557553, 'Total loss': 0.33409532825557553}
2022-11-28 00:56:43,347 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:43,347 INFO:     Epoch: 32
2022-11-28 00:56:44,085 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42305269329385325, 'Total loss': 0.42305269329385325} | train loss {'Reaction outcome loss': 0.3356085282199237, 'Total loss': 0.3356085282199237}
2022-11-28 00:56:44,085 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:44,085 INFO:     Epoch: 33
2022-11-28 00:56:44,822 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44386724856766785, 'Total loss': 0.44386724856766785} | train loss {'Reaction outcome loss': 0.33020224893579675, 'Total loss': 0.33020224893579675}
2022-11-28 00:56:44,823 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:44,823 INFO:     Epoch: 34
2022-11-28 00:56:45,558 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43686494536020537, 'Total loss': 0.43686494536020537} | train loss {'Reaction outcome loss': 0.3338102757778703, 'Total loss': 0.3338102757778703}
2022-11-28 00:56:45,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:45,558 INFO:     Epoch: 35
2022-11-28 00:56:46,302 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39420007304711774, 'Total loss': 0.39420007304711774} | train loss {'Reaction outcome loss': 0.32880168794369213, 'Total loss': 0.32880168794369213}
2022-11-28 00:56:46,302 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:46,302 INFO:     Epoch: 36
2022-11-28 00:56:47,042 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4145109175958417, 'Total loss': 0.4145109175958417} | train loss {'Reaction outcome loss': 0.32309254012545763, 'Total loss': 0.32309254012545763}
2022-11-28 00:56:47,042 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:47,042 INFO:     Epoch: 37
2022-11-28 00:56:47,784 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40004203688691964, 'Total loss': 0.40004203688691964} | train loss {'Reaction outcome loss': 0.32898324937844764, 'Total loss': 0.32898324937844764}
2022-11-28 00:56:47,784 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:47,784 INFO:     Epoch: 38
2022-11-28 00:56:48,523 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43141339414499025, 'Total loss': 0.43141339414499025} | train loss {'Reaction outcome loss': 0.34137644305521125, 'Total loss': 0.34137644305521125}
2022-11-28 00:56:48,523 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:48,523 INFO:     Epoch: 39
2022-11-28 00:56:49,267 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42397094443863764, 'Total loss': 0.42397094443863764} | train loss {'Reaction outcome loss': 0.33036487216548044, 'Total loss': 0.33036487216548044}
2022-11-28 00:56:49,267 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:49,267 INFO:     Epoch: 40
2022-11-28 00:56:50,008 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43695694275877695, 'Total loss': 0.43695694275877695} | train loss {'Reaction outcome loss': 0.33260756290080595, 'Total loss': 0.33260756290080595}
2022-11-28 00:56:50,008 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:50,008 INFO:     Epoch: 41
2022-11-28 00:56:50,748 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3881874345242977, 'Total loss': 0.3881874345242977} | train loss {'Reaction outcome loss': 0.3278047000115015, 'Total loss': 0.3278047000115015}
2022-11-28 00:56:50,748 INFO:     Found new best model at epoch 41
2022-11-28 00:56:50,749 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:50,749 INFO:     Epoch: 42
2022-11-28 00:56:51,491 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42800496789542114, 'Total loss': 0.42800496789542114} | train loss {'Reaction outcome loss': 0.32575674619601697, 'Total loss': 0.32575674619601697}
2022-11-28 00:56:51,491 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:51,491 INFO:     Epoch: 43
2022-11-28 00:56:52,233 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41112337803298776, 'Total loss': 0.41112337803298776} | train loss {'Reaction outcome loss': 0.320796906172621, 'Total loss': 0.320796906172621}
2022-11-28 00:56:52,234 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:52,234 INFO:     Epoch: 44
2022-11-28 00:56:52,974 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41682354326952586, 'Total loss': 0.41682354326952586} | train loss {'Reaction outcome loss': 0.3149296589347781, 'Total loss': 0.3149296589347781}
2022-11-28 00:56:52,974 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:52,974 INFO:     Epoch: 45
2022-11-28 00:56:53,717 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4066379903392358, 'Total loss': 0.4066379903392358} | train loss {'Reaction outcome loss': 0.3215890306903392, 'Total loss': 0.3215890306903392}
2022-11-28 00:56:53,717 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:53,717 INFO:     Epoch: 46
2022-11-28 00:56:54,459 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4209126057949933, 'Total loss': 0.4209126057949933} | train loss {'Reaction outcome loss': 0.3247229662780859, 'Total loss': 0.3247229662780859}
2022-11-28 00:56:54,459 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:54,459 INFO:     Epoch: 47
2022-11-28 00:56:55,199 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41376832453534007, 'Total loss': 0.41376832453534007} | train loss {'Reaction outcome loss': 0.31429972353638436, 'Total loss': 0.31429972353638436}
2022-11-28 00:56:55,199 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:55,199 INFO:     Epoch: 48
2022-11-28 00:56:55,938 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.444286584854126, 'Total loss': 0.444286584854126} | train loss {'Reaction outcome loss': 0.32429131281619167, 'Total loss': 0.32429131281619167}
2022-11-28 00:56:55,938 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:55,939 INFO:     Epoch: 49
2022-11-28 00:56:56,680 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42724961144003, 'Total loss': 0.42724961144003} | train loss {'Reaction outcome loss': 0.3234902431466142, 'Total loss': 0.3234902431466142}
2022-11-28 00:56:56,680 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:56,680 INFO:     Epoch: 50
2022-11-28 00:56:57,420 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4059420714832165, 'Total loss': 0.4059420714832165} | train loss {'Reaction outcome loss': 0.31994758893032466, 'Total loss': 0.31994758893032466}
2022-11-28 00:56:57,420 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:57,420 INFO:     Epoch: 51
2022-11-28 00:56:58,159 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4481266015632586, 'Total loss': 0.4481266015632586} | train loss {'Reaction outcome loss': 0.3199410898040752, 'Total loss': 0.3199410898040752}
2022-11-28 00:56:58,159 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:58,159 INFO:     Epoch: 52
2022-11-28 00:56:58,907 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42010595446283167, 'Total loss': 0.42010595446283167} | train loss {'Reaction outcome loss': 0.3218467482802819, 'Total loss': 0.3218467482802819}
2022-11-28 00:56:58,907 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:58,907 INFO:     Epoch: 53
2022-11-28 00:56:59,656 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40775933116674423, 'Total loss': 0.40775933116674423} | train loss {'Reaction outcome loss': 0.3235402359950299, 'Total loss': 0.3235402359950299}
2022-11-28 00:56:59,657 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:56:59,658 INFO:     Epoch: 54
2022-11-28 00:57:00,402 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4283667750317942, 'Total loss': 0.4283667750317942} | train loss {'Reaction outcome loss': 0.3162821036820509, 'Total loss': 0.3162821036820509}
2022-11-28 00:57:00,403 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:00,403 INFO:     Epoch: 55
2022-11-28 00:57:01,145 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.440762496130033, 'Total loss': 0.440762496130033} | train loss {'Reaction outcome loss': 0.3132193323604915, 'Total loss': 0.3132193323604915}
2022-11-28 00:57:01,145 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:01,145 INFO:     Epoch: 56
2022-11-28 00:57:01,890 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40303186970678245, 'Total loss': 0.40303186970678245} | train loss {'Reaction outcome loss': 0.3225696963619213, 'Total loss': 0.3225696963619213}
2022-11-28 00:57:01,890 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:01,891 INFO:     Epoch: 57
2022-11-28 00:57:02,638 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3960432523692196, 'Total loss': 0.3960432523692196} | train loss {'Reaction outcome loss': 0.3166584248445472, 'Total loss': 0.3166584248445472}
2022-11-28 00:57:02,638 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:02,638 INFO:     Epoch: 58
2022-11-28 00:57:03,385 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43140860748561943, 'Total loss': 0.43140860748561943} | train loss {'Reaction outcome loss': 0.3131343054224034, 'Total loss': 0.3131343054224034}
2022-11-28 00:57:03,385 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:03,385 INFO:     Epoch: 59
2022-11-28 00:57:04,129 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4101840088313276, 'Total loss': 0.4101840088313276} | train loss {'Reaction outcome loss': 0.32414757658024224, 'Total loss': 0.32414757658024224}
2022-11-28 00:57:04,129 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:04,129 INFO:     Epoch: 60
2022-11-28 00:57:04,876 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4401701455089179, 'Total loss': 0.4401701455089179} | train loss {'Reaction outcome loss': 0.31832852351422214, 'Total loss': 0.31832852351422214}
2022-11-28 00:57:04,876 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:04,876 INFO:     Epoch: 61
2022-11-28 00:57:05,622 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4158668287775733, 'Total loss': 0.4158668287775733} | train loss {'Reaction outcome loss': 0.3155621211443629, 'Total loss': 0.3155621211443629}
2022-11-28 00:57:05,622 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:05,622 INFO:     Epoch: 62
2022-11-28 00:57:06,364 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42198513651436026, 'Total loss': 0.42198513651436026} | train loss {'Reaction outcome loss': 0.3212065218966834, 'Total loss': 0.3212065218966834}
2022-11-28 00:57:06,365 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:06,365 INFO:     Epoch: 63
2022-11-28 00:57:07,111 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43577907336029137, 'Total loss': 0.43577907336029137} | train loss {'Reaction outcome loss': 0.32303746269673717, 'Total loss': 0.32303746269673717}
2022-11-28 00:57:07,111 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:07,111 INFO:     Epoch: 64
2022-11-28 00:57:07,854 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41352085396647453, 'Total loss': 0.41352085396647453} | train loss {'Reaction outcome loss': 0.3144804016363864, 'Total loss': 0.3144804016363864}
2022-11-28 00:57:07,854 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:07,854 INFO:     Epoch: 65
2022-11-28 00:57:08,598 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44547627002678136, 'Total loss': 0.44547627002678136} | train loss {'Reaction outcome loss': 0.31163531170055575, 'Total loss': 0.31163531170055575}
2022-11-28 00:57:08,598 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:08,598 INFO:     Epoch: 66
2022-11-28 00:57:09,341 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43590591119771654, 'Total loss': 0.43590591119771654} | train loss {'Reaction outcome loss': 0.3128599439956704, 'Total loss': 0.3128599439956704}
2022-11-28 00:57:09,341 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:09,341 INFO:     Epoch: 67
2022-11-28 00:57:10,089 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4322975758801807, 'Total loss': 0.4322975758801807} | train loss {'Reaction outcome loss': 0.3112927910928823, 'Total loss': 0.3112927910928823}
2022-11-28 00:57:10,090 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:10,090 INFO:     Epoch: 68
2022-11-28 00:57:10,831 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41087922149083833, 'Total loss': 0.41087922149083833} | train loss {'Reaction outcome loss': 0.3112402016715128, 'Total loss': 0.3112402016715128}
2022-11-28 00:57:10,831 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:10,831 INFO:     Epoch: 69
2022-11-28 00:57:11,576 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40780682184479455, 'Total loss': 0.40780682184479455} | train loss {'Reaction outcome loss': 0.3321322705976817, 'Total loss': 0.3321322705976817}
2022-11-28 00:57:11,576 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:11,576 INFO:     Epoch: 70
2022-11-28 00:57:12,319 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3899148800833659, 'Total loss': 0.3899148800833659} | train loss {'Reaction outcome loss': 0.3131453216988213, 'Total loss': 0.3131453216988213}
2022-11-28 00:57:12,319 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:12,320 INFO:     Epoch: 71
2022-11-28 00:57:13,064 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4019892965866761, 'Total loss': 0.4019892965866761} | train loss {'Reaction outcome loss': 0.3081159128218281, 'Total loss': 0.3081159128218281}
2022-11-28 00:57:13,064 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:13,064 INFO:     Epoch: 72
2022-11-28 00:57:13,808 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43225685879588127, 'Total loss': 0.43225685879588127} | train loss {'Reaction outcome loss': 0.31813916676506704, 'Total loss': 0.31813916676506704}
2022-11-28 00:57:13,808 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:13,808 INFO:     Epoch: 73
2022-11-28 00:57:14,551 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42488627474416385, 'Total loss': 0.42488627474416385} | train loss {'Reaction outcome loss': 0.3133217679298654, 'Total loss': 0.3133217679298654}
2022-11-28 00:57:14,552 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:14,552 INFO:     Epoch: 74
2022-11-28 00:57:15,292 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.401435134339739, 'Total loss': 0.401435134339739} | train loss {'Reaction outcome loss': 0.3130241297033368, 'Total loss': 0.3130241297033368}
2022-11-28 00:57:15,293 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:15,293 INFO:     Epoch: 75
2022-11-28 00:57:16,038 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4292407299984585, 'Total loss': 0.4292407299984585} | train loss {'Reaction outcome loss': 0.3041130287306649, 'Total loss': 0.3041130287306649}
2022-11-28 00:57:16,038 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:16,038 INFO:     Epoch: 76
2022-11-28 00:57:16,780 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44579237123781984, 'Total loss': 0.44579237123781984} | train loss {'Reaction outcome loss': 0.317027772963047, 'Total loss': 0.317027772963047}
2022-11-28 00:57:16,781 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:16,781 INFO:     Epoch: 77
2022-11-28 00:57:17,529 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4488670776852153, 'Total loss': 0.4488670776852153} | train loss {'Reaction outcome loss': 0.3190015753617092, 'Total loss': 0.3190015753617092}
2022-11-28 00:57:17,529 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:17,529 INFO:     Epoch: 78
2022-11-28 00:57:18,287 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42189135165377095, 'Total loss': 0.42189135165377095} | train loss {'Reaction outcome loss': 0.3172095653505958, 'Total loss': 0.3172095653505958}
2022-11-28 00:57:18,287 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:18,288 INFO:     Epoch: 79
2022-11-28 00:57:19,046 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41301416063850577, 'Total loss': 0.41301416063850577} | train loss {'Reaction outcome loss': 0.3135122733456748, 'Total loss': 0.3135122733456748}
2022-11-28 00:57:19,046 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:19,047 INFO:     Epoch: 80
2022-11-28 00:57:19,810 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4381745027547533, 'Total loss': 0.4381745027547533} | train loss {'Reaction outcome loss': 0.32607691674208156, 'Total loss': 0.32607691674208156}
2022-11-28 00:57:19,810 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:19,811 INFO:     Epoch: 81
2022-11-28 00:57:20,574 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4086104197300632, 'Total loss': 0.4086104197300632} | train loss {'Reaction outcome loss': 0.31340138177786553, 'Total loss': 0.31340138177786553}
2022-11-28 00:57:20,574 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:20,574 INFO:     Epoch: 82
2022-11-28 00:57:21,336 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43916180035607383, 'Total loss': 0.43916180035607383} | train loss {'Reaction outcome loss': 0.31356641913251, 'Total loss': 0.31356641913251}
2022-11-28 00:57:21,336 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:21,336 INFO:     Epoch: 83
2022-11-28 00:57:22,098 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43389924827285786, 'Total loss': 0.43389924827285786} | train loss {'Reaction outcome loss': 0.3238241409464758, 'Total loss': 0.3238241409464758}
2022-11-28 00:57:22,098 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:22,098 INFO:     Epoch: 84
2022-11-28 00:57:22,857 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45107426934621553, 'Total loss': 0.45107426934621553} | train loss {'Reaction outcome loss': 0.3062737557504858, 'Total loss': 0.3062737557504858}
2022-11-28 00:57:22,857 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:22,857 INFO:     Epoch: 85
2022-11-28 00:57:23,617 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4143013429235328, 'Total loss': 0.4143013429235328} | train loss {'Reaction outcome loss': 0.3171899886155615, 'Total loss': 0.3171899886155615}
2022-11-28 00:57:23,618 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:23,618 INFO:     Epoch: 86
2022-11-28 00:57:24,378 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4080143785950812, 'Total loss': 0.4080143785950812} | train loss {'Reaction outcome loss': 0.3037356471224707, 'Total loss': 0.3037356471224707}
2022-11-28 00:57:24,378 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:24,378 INFO:     Epoch: 87
2022-11-28 00:57:25,139 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4075288132510402, 'Total loss': 0.4075288132510402} | train loss {'Reaction outcome loss': 0.31779074069796776, 'Total loss': 0.31779074069796776}
2022-11-28 00:57:25,140 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:25,140 INFO:     Epoch: 88
2022-11-28 00:57:25,901 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39741323071277956, 'Total loss': 0.39741323071277956} | train loss {'Reaction outcome loss': 0.30849043468431553, 'Total loss': 0.30849043468431553}
2022-11-28 00:57:25,901 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:25,901 INFO:     Epoch: 89
2022-11-28 00:57:26,660 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4204821769486774, 'Total loss': 0.4204821769486774} | train loss {'Reaction outcome loss': 0.31779161503120346, 'Total loss': 0.31779161503120346}
2022-11-28 00:57:26,660 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:26,660 INFO:     Epoch: 90
2022-11-28 00:57:27,420 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4220431900837205, 'Total loss': 0.4220431900837205} | train loss {'Reaction outcome loss': 0.31357942488120527, 'Total loss': 0.31357942488120527}
2022-11-28 00:57:27,420 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:27,420 INFO:     Epoch: 91
2022-11-28 00:57:28,180 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39974616518752143, 'Total loss': 0.39974616518752143} | train loss {'Reaction outcome loss': 0.3138558701593049, 'Total loss': 0.3138558701593049}
2022-11-28 00:57:28,180 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:28,181 INFO:     Epoch: 92
2022-11-28 00:57:28,943 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4381854066794569, 'Total loss': 0.4381854066794569} | train loss {'Reaction outcome loss': 0.3085882005338766, 'Total loss': 0.3085882005338766}
2022-11-28 00:57:28,943 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:28,944 INFO:     Epoch: 93
2022-11-28 00:57:29,709 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.422924435951493, 'Total loss': 0.422924435951493} | train loss {'Reaction outcome loss': 0.3209975691170109, 'Total loss': 0.3209975691170109}
2022-11-28 00:57:29,709 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:29,710 INFO:     Epoch: 94
2022-11-28 00:57:30,474 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4227643683552742, 'Total loss': 0.4227643683552742} | train loss {'Reaction outcome loss': 0.30454901684911884, 'Total loss': 0.30454901684911884}
2022-11-28 00:57:30,475 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:30,475 INFO:     Epoch: 95
2022-11-28 00:57:31,234 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4192538352852518, 'Total loss': 0.4192538352852518} | train loss {'Reaction outcome loss': 0.3058884657159144, 'Total loss': 0.3058884657159144}
2022-11-28 00:57:31,235 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:31,235 INFO:     Epoch: 96
2022-11-28 00:57:31,994 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43467649103099987, 'Total loss': 0.43467649103099987} | train loss {'Reaction outcome loss': 0.3118488742684831, 'Total loss': 0.3118488742684831}
2022-11-28 00:57:31,995 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:31,995 INFO:     Epoch: 97
2022-11-28 00:57:32,756 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45764268646863376, 'Total loss': 0.45764268646863376} | train loss {'Reaction outcome loss': 0.30392979622191313, 'Total loss': 0.30392979622191313}
2022-11-28 00:57:32,756 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:32,757 INFO:     Epoch: 98
2022-11-28 00:57:33,517 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40484472330320964, 'Total loss': 0.40484472330320964} | train loss {'Reaction outcome loss': 0.3152118051310583, 'Total loss': 0.3152118051310583}
2022-11-28 00:57:33,517 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:33,517 INFO:     Epoch: 99
2022-11-28 00:57:34,278 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39559727924113924, 'Total loss': 0.39559727924113924} | train loss {'Reaction outcome loss': 0.30900378427943404, 'Total loss': 0.30900378427943404}
2022-11-28 00:57:34,278 INFO:     Best model found after epoch 42 of 100.
2022-11-28 00:57:34,278 INFO:   Done with stage: TRAINING
2022-11-28 00:57:34,278 INFO:   Starting stage: EVALUATION
2022-11-28 00:57:34,405 INFO:   Done with stage: EVALUATION
2022-11-28 00:57:34,405 INFO:   Leaving out SEQ value Fold_5
2022-11-28 00:57:34,417 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 00:57:34,418 INFO:   Starting stage: FEATURE SCALING
2022-11-28 00:57:35,062 INFO:   Done with stage: FEATURE SCALING
2022-11-28 00:57:35,062 INFO:   Starting stage: SCALING TARGETS
2022-11-28 00:57:35,132 INFO:   Done with stage: SCALING TARGETS
2022-11-28 00:57:35,132 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:57:35,132 INFO:     No hyperparam tuning for this model
2022-11-28 00:57:35,132 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:57:35,132 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 00:57:35,133 INFO:     None feature selector for col prot
2022-11-28 00:57:35,133 INFO:     None feature selector for col prot
2022-11-28 00:57:35,133 INFO:     None feature selector for col prot
2022-11-28 00:57:35,134 INFO:     None feature selector for col chem
2022-11-28 00:57:35,134 INFO:     None feature selector for col chem
2022-11-28 00:57:35,134 INFO:     None feature selector for col chem
2022-11-28 00:57:35,134 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 00:57:35,134 INFO:   Starting stage: BUILD MODEL
2022-11-28 00:57:35,135 INFO:     Number of params in model 169741
2022-11-28 00:57:35,138 INFO:   Done with stage: BUILD MODEL
2022-11-28 00:57:35,139 INFO:   Starting stage: TRAINING
2022-11-28 00:57:35,192 INFO:     Val loss before train {'Reaction outcome loss': 1.0481966666199944, 'Total loss': 1.0481966666199944}
2022-11-28 00:57:35,193 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:35,193 INFO:     Epoch: 0
2022-11-28 00:57:35,959 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5763906477527185, 'Total loss': 0.5763906477527185} | train loss {'Reaction outcome loss': 0.6375095368879526, 'Total loss': 0.6375095368879526}
2022-11-28 00:57:35,960 INFO:     Found new best model at epoch 0
2022-11-28 00:57:35,960 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:35,960 INFO:     Epoch: 1
2022-11-28 00:57:36,729 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4889640841971744, 'Total loss': 0.4889640841971744} | train loss {'Reaction outcome loss': 0.49970006858289, 'Total loss': 0.49970006858289}
2022-11-28 00:57:36,730 INFO:     Found new best model at epoch 1
2022-11-28 00:57:36,731 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:36,731 INFO:     Epoch: 2
2022-11-28 00:57:37,500 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47262710840864613, 'Total loss': 0.47262710840864613} | train loss {'Reaction outcome loss': 0.46195935895327134, 'Total loss': 0.46195935895327134}
2022-11-28 00:57:37,500 INFO:     Found new best model at epoch 2
2022-11-28 00:57:37,501 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:37,501 INFO:     Epoch: 3
2022-11-28 00:57:38,267 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46021967245773837, 'Total loss': 0.46021967245773837} | train loss {'Reaction outcome loss': 0.44157853286886806, 'Total loss': 0.44157853286886806}
2022-11-28 00:57:38,267 INFO:     Found new best model at epoch 3
2022-11-28 00:57:38,268 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:38,268 INFO:     Epoch: 4
2022-11-28 00:57:39,037 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5061930431561037, 'Total loss': 0.5061930431561037} | train loss {'Reaction outcome loss': 0.4313332029742751, 'Total loss': 0.4313332029742751}
2022-11-28 00:57:39,037 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:39,037 INFO:     Epoch: 5
2022-11-28 00:57:39,805 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4498885599896312, 'Total loss': 0.4498885599896312} | train loss {'Reaction outcome loss': 0.45292849929226553, 'Total loss': 0.45292849929226553}
2022-11-28 00:57:39,805 INFO:     Found new best model at epoch 5
2022-11-28 00:57:39,806 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:39,806 INFO:     Epoch: 6
2022-11-28 00:57:40,575 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45382409915328026, 'Total loss': 0.45382409915328026} | train loss {'Reaction outcome loss': 0.41131116917379473, 'Total loss': 0.41131116917379473}
2022-11-28 00:57:40,575 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:40,575 INFO:     Epoch: 7
2022-11-28 00:57:41,343 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43786167725920677, 'Total loss': 0.43786167725920677} | train loss {'Reaction outcome loss': 0.4053233037834708, 'Total loss': 0.4053233037834708}
2022-11-28 00:57:41,344 INFO:     Found new best model at epoch 7
2022-11-28 00:57:41,344 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:41,344 INFO:     Epoch: 8
2022-11-28 00:57:42,115 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4606002454053272, 'Total loss': 0.4606002454053272} | train loss {'Reaction outcome loss': 0.38699923627651656, 'Total loss': 0.38699923627651656}
2022-11-28 00:57:42,115 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:42,116 INFO:     Epoch: 9
2022-11-28 00:57:42,883 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45692599124529143, 'Total loss': 0.45692599124529143} | train loss {'Reaction outcome loss': 0.38803858841629885, 'Total loss': 0.38803858841629885}
2022-11-28 00:57:42,883 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:42,883 INFO:     Epoch: 10
2022-11-28 00:57:43,646 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4598473212258382, 'Total loss': 0.4598473212258382} | train loss {'Reaction outcome loss': 0.3843337149087807, 'Total loss': 0.3843337149087807}
2022-11-28 00:57:43,647 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:43,647 INFO:     Epoch: 11
2022-11-28 00:57:44,401 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4441331990740516, 'Total loss': 0.4441331990740516} | train loss {'Reaction outcome loss': 0.37970278010918546, 'Total loss': 0.37970278010918546}
2022-11-28 00:57:44,401 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:44,401 INFO:     Epoch: 12
2022-11-28 00:57:45,148 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42953985184431076, 'Total loss': 0.42953985184431076} | train loss {'Reaction outcome loss': 0.3759335136957286, 'Total loss': 0.3759335136957286}
2022-11-28 00:57:45,149 INFO:     Found new best model at epoch 12
2022-11-28 00:57:45,149 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:45,150 INFO:     Epoch: 13
2022-11-28 00:57:45,899 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4094603383405642, 'Total loss': 0.4094603383405642} | train loss {'Reaction outcome loss': 0.37653278595643486, 'Total loss': 0.37653278595643486}
2022-11-28 00:57:45,899 INFO:     Found new best model at epoch 13
2022-11-28 00:57:45,900 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:45,900 INFO:     Epoch: 14
2022-11-28 00:57:46,646 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42221940749070863, 'Total loss': 0.42221940749070863} | train loss {'Reaction outcome loss': 0.3856136718018335, 'Total loss': 0.3856136718018335}
2022-11-28 00:57:46,646 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:46,646 INFO:     Epoch: 15
2022-11-28 00:57:47,384 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4373927681960843, 'Total loss': 0.4373927681960843} | train loss {'Reaction outcome loss': 0.37458744473182237, 'Total loss': 0.37458744473182237}
2022-11-28 00:57:47,384 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:47,384 INFO:     Epoch: 16
2022-11-28 00:57:48,125 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.414482615549456, 'Total loss': 0.414482615549456} | train loss {'Reaction outcome loss': 0.363154366061936, 'Total loss': 0.363154366061936}
2022-11-28 00:57:48,125 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:48,125 INFO:     Epoch: 17
2022-11-28 00:57:48,861 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4212844016199762, 'Total loss': 0.4212844016199762} | train loss {'Reaction outcome loss': 0.34942204701273066, 'Total loss': 0.34942204701273066}
2022-11-28 00:57:48,862 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:48,862 INFO:     Epoch: 18
2022-11-28 00:57:49,602 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3992588863792745, 'Total loss': 0.3992588863792745} | train loss {'Reaction outcome loss': 0.35269898999772725, 'Total loss': 0.35269898999772725}
2022-11-28 00:57:49,602 INFO:     Found new best model at epoch 18
2022-11-28 00:57:49,603 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:49,603 INFO:     Epoch: 19
2022-11-28 00:57:50,342 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3977116370065646, 'Total loss': 0.3977116370065646} | train loss {'Reaction outcome loss': 0.34362897857541014, 'Total loss': 0.34362897857541014}
2022-11-28 00:57:50,342 INFO:     Found new best model at epoch 19
2022-11-28 00:57:50,343 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:50,343 INFO:     Epoch: 20
2022-11-28 00:57:51,099 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4411208622834899, 'Total loss': 0.4411208622834899} | train loss {'Reaction outcome loss': 0.35386728070796986, 'Total loss': 0.35386728070796986}
2022-11-28 00:57:51,099 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:51,099 INFO:     Epoch: 21
2022-11-28 00:57:51,853 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42829731716351077, 'Total loss': 0.42829731716351077} | train loss {'Reaction outcome loss': 0.3533452863876636, 'Total loss': 0.3533452863876636}
2022-11-28 00:57:51,853 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:51,853 INFO:     Epoch: 22
2022-11-28 00:57:52,606 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4425880248573693, 'Total loss': 0.4425880248573693} | train loss {'Reaction outcome loss': 0.34822763458859585, 'Total loss': 0.34822763458859585}
2022-11-28 00:57:52,606 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:52,606 INFO:     Epoch: 23
2022-11-28 00:57:53,365 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.447256209498102, 'Total loss': 0.447256209498102} | train loss {'Reaction outcome loss': 0.34807633901314683, 'Total loss': 0.34807633901314683}
2022-11-28 00:57:53,365 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:53,365 INFO:     Epoch: 24
2022-11-28 00:57:54,122 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4317294572564689, 'Total loss': 0.4317294572564689} | train loss {'Reaction outcome loss': 0.34685381978508917, 'Total loss': 0.34685381978508917}
2022-11-28 00:57:54,122 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:54,122 INFO:     Epoch: 25
2022-11-28 00:57:54,877 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43832908096638595, 'Total loss': 0.43832908096638595} | train loss {'Reaction outcome loss': 0.3500268576659172, 'Total loss': 0.3500268576659172}
2022-11-28 00:57:54,877 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:54,877 INFO:     Epoch: 26
2022-11-28 00:57:55,633 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4496329077942805, 'Total loss': 0.4496329077942805} | train loss {'Reaction outcome loss': 0.34045831545403127, 'Total loss': 0.34045831545403127}
2022-11-28 00:57:55,634 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:55,634 INFO:     Epoch: 27
2022-11-28 00:57:56,387 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4577244059606032, 'Total loss': 0.4577244059606032} | train loss {'Reaction outcome loss': 0.35284307312506896, 'Total loss': 0.35284307312506896}
2022-11-28 00:57:56,387 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:56,387 INFO:     Epoch: 28
2022-11-28 00:57:57,144 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4010045643557202, 'Total loss': 0.4010045643557202} | train loss {'Reaction outcome loss': 0.3480706685769413, 'Total loss': 0.3480706685769413}
2022-11-28 00:57:57,144 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:57,144 INFO:     Epoch: 29
2022-11-28 00:57:57,898 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41390019993890415, 'Total loss': 0.41390019993890415} | train loss {'Reaction outcome loss': 0.34209165900101063, 'Total loss': 0.34209165900101063}
2022-11-28 00:57:57,898 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:57,898 INFO:     Epoch: 30
2022-11-28 00:57:58,656 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42103287882425566, 'Total loss': 0.42103287882425566} | train loss {'Reaction outcome loss': 0.34588788727275754, 'Total loss': 0.34588788727275754}
2022-11-28 00:57:58,656 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:58,656 INFO:     Epoch: 31
2022-11-28 00:57:59,412 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4108063404194333, 'Total loss': 0.4108063404194333} | train loss {'Reaction outcome loss': 0.33767652659024666, 'Total loss': 0.33767652659024666}
2022-11-28 00:57:59,412 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:57:59,413 INFO:     Epoch: 32
2022-11-28 00:58:00,171 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42748685011809523, 'Total loss': 0.42748685011809523} | train loss {'Reaction outcome loss': 0.3339710939404091, 'Total loss': 0.3339710939404091}
2022-11-28 00:58:00,171 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:00,171 INFO:     Epoch: 33
2022-11-28 00:58:00,927 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.449893593788147, 'Total loss': 0.449893593788147} | train loss {'Reaction outcome loss': 0.32502120443683885, 'Total loss': 0.32502120443683885}
2022-11-28 00:58:00,927 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:00,927 INFO:     Epoch: 34
2022-11-28 00:58:01,685 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4150668956678022, 'Total loss': 0.4150668956678022} | train loss {'Reaction outcome loss': 0.35161695909886226, 'Total loss': 0.35161695909886226}
2022-11-28 00:58:01,686 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:01,686 INFO:     Epoch: 35
2022-11-28 00:58:02,441 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45320713333785534, 'Total loss': 0.45320713333785534} | train loss {'Reaction outcome loss': 0.3570804835753402, 'Total loss': 0.3570804835753402}
2022-11-28 00:58:02,441 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:02,441 INFO:     Epoch: 36
2022-11-28 00:58:03,199 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4217489944262938, 'Total loss': 0.4217489944262938} | train loss {'Reaction outcome loss': 0.3496417840603392, 'Total loss': 0.3496417840603392}
2022-11-28 00:58:03,199 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:03,199 INFO:     Epoch: 37
2022-11-28 00:58:03,958 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41682878305966203, 'Total loss': 0.41682878305966203} | train loss {'Reaction outcome loss': 0.3314183788140293, 'Total loss': 0.3314183788140293}
2022-11-28 00:58:03,958 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:03,958 INFO:     Epoch: 38
2022-11-28 00:58:04,702 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42278487303040246, 'Total loss': 0.42278487303040246} | train loss {'Reaction outcome loss': 0.32894939380256755, 'Total loss': 0.32894939380256755}
2022-11-28 00:58:04,703 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:04,703 INFO:     Epoch: 39
2022-11-28 00:58:05,445 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44961255484006624, 'Total loss': 0.44961255484006624} | train loss {'Reaction outcome loss': 0.33725349252161224, 'Total loss': 0.33725349252161224}
2022-11-28 00:58:05,445 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:05,446 INFO:     Epoch: 40
2022-11-28 00:58:06,190 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42504385994239285, 'Total loss': 0.42504385994239285} | train loss {'Reaction outcome loss': 0.3270224006394083, 'Total loss': 0.3270224006394083}
2022-11-28 00:58:06,191 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:06,191 INFO:     Epoch: 41
2022-11-28 00:58:06,934 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4131692768159238, 'Total loss': 0.4131692768159238} | train loss {'Reaction outcome loss': 0.33292542244138024, 'Total loss': 0.33292542244138024}
2022-11-28 00:58:06,934 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:06,934 INFO:     Epoch: 42
2022-11-28 00:58:07,685 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43770003589716827, 'Total loss': 0.43770003589716827} | train loss {'Reaction outcome loss': 0.3247074115312534, 'Total loss': 0.3247074115312534}
2022-11-28 00:58:07,685 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:07,686 INFO:     Epoch: 43
2022-11-28 00:58:08,433 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.426782737062736, 'Total loss': 0.426782737062736} | train loss {'Reaction outcome loss': 0.334215351142864, 'Total loss': 0.334215351142864}
2022-11-28 00:58:08,433 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:08,433 INFO:     Epoch: 44
2022-11-28 00:58:09,181 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4634101577103138, 'Total loss': 0.4634101577103138} | train loss {'Reaction outcome loss': 0.3329892699717005, 'Total loss': 0.3329892699717005}
2022-11-28 00:58:09,181 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:09,181 INFO:     Epoch: 45
2022-11-28 00:58:09,927 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43157211962071335, 'Total loss': 0.43157211962071335} | train loss {'Reaction outcome loss': 0.32630681252551946, 'Total loss': 0.32630681252551946}
2022-11-28 00:58:09,927 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:09,927 INFO:     Epoch: 46
2022-11-28 00:58:10,679 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4519995159723542, 'Total loss': 0.4519995159723542} | train loss {'Reaction outcome loss': 0.3466167214217215, 'Total loss': 0.3466167214217215}
2022-11-28 00:58:10,679 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:10,679 INFO:     Epoch: 47
2022-11-28 00:58:11,423 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4211009857668118, 'Total loss': 0.4211009857668118} | train loss {'Reaction outcome loss': 0.3426528324784055, 'Total loss': 0.3426528324784055}
2022-11-28 00:58:11,423 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:11,423 INFO:     Epoch: 48
2022-11-28 00:58:12,170 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43173025650056923, 'Total loss': 0.43173025650056923} | train loss {'Reaction outcome loss': 0.3398305261545336, 'Total loss': 0.3398305261545336}
2022-11-28 00:58:12,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:12,170 INFO:     Epoch: 49
2022-11-28 00:58:12,917 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4270665513520891, 'Total loss': 0.4270665513520891} | train loss {'Reaction outcome loss': 0.3381551910146528, 'Total loss': 0.3381551910146528}
2022-11-28 00:58:12,917 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:12,918 INFO:     Epoch: 50
2022-11-28 00:58:13,661 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39802245660261676, 'Total loss': 0.39802245660261676} | train loss {'Reaction outcome loss': 0.3524844645247286, 'Total loss': 0.3524844645247286}
2022-11-28 00:58:13,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:13,662 INFO:     Epoch: 51
2022-11-28 00:58:14,410 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3944548129696738, 'Total loss': 0.3944548129696738} | train loss {'Reaction outcome loss': 0.3283106176416401, 'Total loss': 0.3283106176416401}
2022-11-28 00:58:14,410 INFO:     Found new best model at epoch 51
2022-11-28 00:58:14,411 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:14,411 INFO:     Epoch: 52
2022-11-28 00:58:15,157 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4056650996208191, 'Total loss': 0.4056650996208191} | train loss {'Reaction outcome loss': 0.3221402659046988, 'Total loss': 0.3221402659046988}
2022-11-28 00:58:15,158 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:15,158 INFO:     Epoch: 53
2022-11-28 00:58:15,904 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43887931955131615, 'Total loss': 0.43887931955131615} | train loss {'Reaction outcome loss': 0.3197908555025514, 'Total loss': 0.3197908555025514}
2022-11-28 00:58:15,904 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:15,904 INFO:     Epoch: 54
2022-11-28 00:58:16,646 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4348803335292773, 'Total loss': 0.4348803335292773} | train loss {'Reaction outcome loss': 0.3363853213245328, 'Total loss': 0.3363853213245328}
2022-11-28 00:58:16,646 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:16,646 INFO:     Epoch: 55
2022-11-28 00:58:17,389 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44149116121909837, 'Total loss': 0.44149116121909837} | train loss {'Reaction outcome loss': 0.3172722787650251, 'Total loss': 0.3172722787650251}
2022-11-28 00:58:17,389 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:17,389 INFO:     Epoch: 56
2022-11-28 00:58:18,135 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41023174029859627, 'Total loss': 0.41023174029859627} | train loss {'Reaction outcome loss': 0.32938382675049277, 'Total loss': 0.32938382675049277}
2022-11-28 00:58:18,135 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:18,135 INFO:     Epoch: 57
2022-11-28 00:58:18,880 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41096115146170964, 'Total loss': 0.41096115146170964} | train loss {'Reaction outcome loss': 0.3340251849066873, 'Total loss': 0.3340251849066873}
2022-11-28 00:58:18,881 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:18,881 INFO:     Epoch: 58
2022-11-28 00:58:19,628 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4151264310560443, 'Total loss': 0.4151264310560443} | train loss {'Reaction outcome loss': 0.3245960925875405, 'Total loss': 0.3245960925875405}
2022-11-28 00:58:19,628 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:19,628 INFO:     Epoch: 59
2022-11-28 00:58:20,372 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4508114152333953, 'Total loss': 0.4508114152333953} | train loss {'Reaction outcome loss': 0.3220344898191956, 'Total loss': 0.3220344898191956}
2022-11-28 00:58:20,372 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:20,373 INFO:     Epoch: 60
2022-11-28 00:58:21,117 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4398288940164176, 'Total loss': 0.4398288940164176} | train loss {'Reaction outcome loss': 0.32098500928294804, 'Total loss': 0.32098500928294804}
2022-11-28 00:58:21,117 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:21,118 INFO:     Epoch: 61
2022-11-28 00:58:21,859 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4203545386818322, 'Total loss': 0.4203545386818322} | train loss {'Reaction outcome loss': 0.3363274048395485, 'Total loss': 0.3363274048395485}
2022-11-28 00:58:21,859 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:21,859 INFO:     Epoch: 62
2022-11-28 00:58:22,607 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3970648744566874, 'Total loss': 0.3970648744566874} | train loss {'Reaction outcome loss': 0.3191000505267814, 'Total loss': 0.3191000505267814}
2022-11-28 00:58:22,607 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:22,607 INFO:     Epoch: 63
2022-11-28 00:58:23,355 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41271891665052285, 'Total loss': 0.41271891665052285} | train loss {'Reaction outcome loss': 0.3151473259621183, 'Total loss': 0.3151473259621183}
2022-11-28 00:58:23,355 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:23,355 INFO:     Epoch: 64
2022-11-28 00:58:24,100 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42675108708102594, 'Total loss': 0.42675108708102594} | train loss {'Reaction outcome loss': 0.32403612094610806, 'Total loss': 0.32403612094610806}
2022-11-28 00:58:24,100 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:24,100 INFO:     Epoch: 65
2022-11-28 00:58:24,841 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4534598040309819, 'Total loss': 0.4534598040309819} | train loss {'Reaction outcome loss': 0.3378725681107054, 'Total loss': 0.3378725681107054}
2022-11-28 00:58:24,841 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:24,841 INFO:     Epoch: 66
2022-11-28 00:58:25,583 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44002424011176283, 'Total loss': 0.44002424011176283} | train loss {'Reaction outcome loss': 0.3246300823473737, 'Total loss': 0.3246300823473737}
2022-11-28 00:58:25,583 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:25,583 INFO:     Epoch: 67
2022-11-28 00:58:26,328 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42340913211757486, 'Total loss': 0.42340913211757486} | train loss {'Reaction outcome loss': 0.3250310846740146, 'Total loss': 0.3250310846740146}
2022-11-28 00:58:26,328 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:26,328 INFO:     Epoch: 68
2022-11-28 00:58:27,071 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40460077283734625, 'Total loss': 0.40460077283734625} | train loss {'Reaction outcome loss': 0.32059172812381737, 'Total loss': 0.32059172812381737}
2022-11-28 00:58:27,072 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:27,072 INFO:     Epoch: 69
2022-11-28 00:58:27,816 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4015987970950929, 'Total loss': 0.4015987970950929} | train loss {'Reaction outcome loss': 0.3289200186526529, 'Total loss': 0.3289200186526529}
2022-11-28 00:58:27,816 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:27,816 INFO:     Epoch: 70
2022-11-28 00:58:28,562 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4046968770298091, 'Total loss': 0.4046968770298091} | train loss {'Reaction outcome loss': 0.3238684439085243, 'Total loss': 0.3238684439085243}
2022-11-28 00:58:28,562 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:28,562 INFO:     Epoch: 71
2022-11-28 00:58:29,309 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42112400789152493, 'Total loss': 0.42112400789152493} | train loss {'Reaction outcome loss': 0.3187805826913354, 'Total loss': 0.3187805826913354}
2022-11-28 00:58:29,309 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:29,309 INFO:     Epoch: 72
2022-11-28 00:58:30,051 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4563816216858951, 'Total loss': 0.4563816216858951} | train loss {'Reaction outcome loss': 0.3349329819865072, 'Total loss': 0.3349329819865072}
2022-11-28 00:58:30,052 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:30,052 INFO:     Epoch: 73
2022-11-28 00:58:30,796 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40383923934264615, 'Total loss': 0.40383923934264615} | train loss {'Reaction outcome loss': 0.3426091349438617, 'Total loss': 0.3426091349438617}
2022-11-28 00:58:30,796 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:30,797 INFO:     Epoch: 74
2022-11-28 00:58:31,540 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43402701954949985, 'Total loss': 0.43402701954949985} | train loss {'Reaction outcome loss': 0.31618775911572644, 'Total loss': 0.31618775911572644}
2022-11-28 00:58:31,540 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:31,540 INFO:     Epoch: 75
2022-11-28 00:58:32,283 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4048630994829265, 'Total loss': 0.4048630994829265} | train loss {'Reaction outcome loss': 0.3170907020508519, 'Total loss': 0.3170907020508519}
2022-11-28 00:58:32,284 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:32,284 INFO:     Epoch: 76
2022-11-28 00:58:33,030 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4520825469358401, 'Total loss': 0.4520825469358401} | train loss {'Reaction outcome loss': 0.3124025011442692, 'Total loss': 0.3124025011442692}
2022-11-28 00:58:33,030 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:33,030 INFO:     Epoch: 77
2022-11-28 00:58:33,775 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4079533964395523, 'Total loss': 0.4079533964395523} | train loss {'Reaction outcome loss': 0.3202154846326542, 'Total loss': 0.3202154846326542}
2022-11-28 00:58:33,775 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:33,775 INFO:     Epoch: 78
2022-11-28 00:58:34,521 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43426738713275304, 'Total loss': 0.43426738713275304} | train loss {'Reaction outcome loss': 0.3134459567818082, 'Total loss': 0.3134459567818082}
2022-11-28 00:58:34,521 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:34,521 INFO:     Epoch: 79
2022-11-28 00:58:35,267 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4091277454387058, 'Total loss': 0.4091277454387058} | train loss {'Reaction outcome loss': 0.3392657521161956, 'Total loss': 0.3392657521161956}
2022-11-28 00:58:35,268 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:35,268 INFO:     Epoch: 80
2022-11-28 00:58:36,014 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46127355708317325, 'Total loss': 0.46127355708317325} | train loss {'Reaction outcome loss': 0.3309452810931785, 'Total loss': 0.3309452810931785}
2022-11-28 00:58:36,014 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:36,014 INFO:     Epoch: 81
2022-11-28 00:58:36,760 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4269967187534679, 'Total loss': 0.4269967187534679} | train loss {'Reaction outcome loss': 0.3333587487160345, 'Total loss': 0.3333587487160345}
2022-11-28 00:58:36,760 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:36,760 INFO:     Epoch: 82
2022-11-28 00:58:37,506 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40400488911704585, 'Total loss': 0.40400488911704585} | train loss {'Reaction outcome loss': 0.3158895337571454, 'Total loss': 0.3158895337571454}
2022-11-28 00:58:37,506 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:37,506 INFO:     Epoch: 83
2022-11-28 00:58:38,248 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44227923012592574, 'Total loss': 0.44227923012592574} | train loss {'Reaction outcome loss': 0.3051803957233545, 'Total loss': 0.3051803957233545}
2022-11-28 00:58:38,248 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:38,249 INFO:     Epoch: 84
2022-11-28 00:58:38,992 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44128554822369054, 'Total loss': 0.44128554822369054} | train loss {'Reaction outcome loss': 0.31552306991749207, 'Total loss': 0.31552306991749207}
2022-11-28 00:58:38,993 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:38,993 INFO:     Epoch: 85
2022-11-28 00:58:39,738 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4153270526704463, 'Total loss': 0.4153270526704463} | train loss {'Reaction outcome loss': 0.3191297628015642, 'Total loss': 0.3191297628015642}
2022-11-28 00:58:39,738 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:39,738 INFO:     Epoch: 86
2022-11-28 00:58:40,484 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.391890152272853, 'Total loss': 0.391890152272853} | train loss {'Reaction outcome loss': 0.31906910354520385, 'Total loss': 0.31906910354520385}
2022-11-28 00:58:40,484 INFO:     Found new best model at epoch 86
2022-11-28 00:58:40,485 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:40,485 INFO:     Epoch: 87
2022-11-28 00:58:41,228 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4239120568064126, 'Total loss': 0.4239120568064126} | train loss {'Reaction outcome loss': 0.315665909138165, 'Total loss': 0.315665909138165}
2022-11-28 00:58:41,229 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:41,229 INFO:     Epoch: 88
2022-11-28 00:58:41,973 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42880232496695087, 'Total loss': 0.42880232496695087} | train loss {'Reaction outcome loss': 0.3272315045961967, 'Total loss': 0.3272315045961967}
2022-11-28 00:58:41,974 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:41,974 INFO:     Epoch: 89
2022-11-28 00:58:42,720 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41262235018340027, 'Total loss': 0.41262235018340027} | train loss {'Reaction outcome loss': 0.31095943663284364, 'Total loss': 0.31095943663284364}
2022-11-28 00:58:42,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:42,720 INFO:     Epoch: 90
2022-11-28 00:58:43,467 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43216797980395233, 'Total loss': 0.43216797980395233} | train loss {'Reaction outcome loss': 0.3187278426650097, 'Total loss': 0.3187278426650097}
2022-11-28 00:58:43,467 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:43,467 INFO:     Epoch: 91
2022-11-28 00:58:44,211 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43187455528161744, 'Total loss': 0.43187455528161744} | train loss {'Reaction outcome loss': 0.31461084597868477, 'Total loss': 0.31461084597868477}
2022-11-28 00:58:44,211 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:44,211 INFO:     Epoch: 92
2022-11-28 00:58:44,955 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4142283130098473, 'Total loss': 0.4142283130098473} | train loss {'Reaction outcome loss': 0.32214747550275163, 'Total loss': 0.32214747550275163}
2022-11-28 00:58:44,955 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:44,955 INFO:     Epoch: 93
2022-11-28 00:58:45,700 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4112263558940454, 'Total loss': 0.4112263558940454} | train loss {'Reaction outcome loss': 0.3213804803396526, 'Total loss': 0.3213804803396526}
2022-11-28 00:58:45,700 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:45,700 INFO:     Epoch: 94
2022-11-28 00:58:46,445 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4163116074421189, 'Total loss': 0.4163116074421189} | train loss {'Reaction outcome loss': 0.3166075996713579, 'Total loss': 0.3166075996713579}
2022-11-28 00:58:46,445 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:46,445 INFO:     Epoch: 95
2022-11-28 00:58:47,192 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4157805571501905, 'Total loss': 0.4157805571501905} | train loss {'Reaction outcome loss': 0.30949043002929766, 'Total loss': 0.30949043002929766}
2022-11-28 00:58:47,192 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:47,192 INFO:     Epoch: 96
2022-11-28 00:58:47,946 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4545944326303222, 'Total loss': 0.4545944326303222} | train loss {'Reaction outcome loss': 0.3148128107444172, 'Total loss': 0.3148128107444172}
2022-11-28 00:58:47,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:47,946 INFO:     Epoch: 97
2022-11-28 00:58:48,705 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45141219754110684, 'Total loss': 0.45141219754110684} | train loss {'Reaction outcome loss': 0.31001634505598125, 'Total loss': 0.31001634505598125}
2022-11-28 00:58:48,705 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:48,705 INFO:     Epoch: 98
2022-11-28 00:58:49,465 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45007010447708046, 'Total loss': 0.45007010447708046} | train loss {'Reaction outcome loss': 0.31200471957806153, 'Total loss': 0.31200471957806153}
2022-11-28 00:58:49,465 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:49,465 INFO:     Epoch: 99
2022-11-28 00:58:50,226 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41326431405137887, 'Total loss': 0.41326431405137887} | train loss {'Reaction outcome loss': 0.3229729649328027, 'Total loss': 0.3229729649328027}
2022-11-28 00:58:50,226 INFO:     Best model found after epoch 87 of 100.
2022-11-28 00:58:50,226 INFO:   Done with stage: TRAINING
2022-11-28 00:58:50,226 INFO:   Starting stage: EVALUATION
2022-11-28 00:58:50,347 INFO:   Done with stage: EVALUATION
2022-11-28 00:58:50,347 INFO:   Leaving out SEQ value Fold_6
2022-11-28 00:58:50,359 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 00:58:50,360 INFO:   Starting stage: FEATURE SCALING
2022-11-28 00:58:51,001 INFO:   Done with stage: FEATURE SCALING
2022-11-28 00:58:51,001 INFO:   Starting stage: SCALING TARGETS
2022-11-28 00:58:51,072 INFO:   Done with stage: SCALING TARGETS
2022-11-28 00:58:51,072 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:58:51,072 INFO:     No hyperparam tuning for this model
2022-11-28 00:58:51,072 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 00:58:51,072 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 00:58:51,073 INFO:     None feature selector for col prot
2022-11-28 00:58:51,073 INFO:     None feature selector for col prot
2022-11-28 00:58:51,073 INFO:     None feature selector for col prot
2022-11-28 00:58:51,074 INFO:     None feature selector for col chem
2022-11-28 00:58:51,074 INFO:     None feature selector for col chem
2022-11-28 00:58:51,074 INFO:     None feature selector for col chem
2022-11-28 00:58:51,074 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 00:58:51,074 INFO:   Starting stage: BUILD MODEL
2022-11-28 00:58:51,075 INFO:     Number of params in model 169741
2022-11-28 00:58:51,078 INFO:   Done with stage: BUILD MODEL
2022-11-28 00:58:51,079 INFO:   Starting stage: TRAINING
2022-11-28 00:58:51,132 INFO:     Val loss before train {'Reaction outcome loss': 0.973825991153717, 'Total loss': 0.973825991153717}
2022-11-28 00:58:51,132 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:51,132 INFO:     Epoch: 0
2022-11-28 00:58:51,898 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.52022404901006, 'Total loss': 0.52022404901006} | train loss {'Reaction outcome loss': 0.6411118367987294, 'Total loss': 0.6411118367987294}
2022-11-28 00:58:51,898 INFO:     Found new best model at epoch 0
2022-11-28 00:58:51,899 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:51,899 INFO:     Epoch: 1
2022-11-28 00:58:52,666 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.47140662067315797, 'Total loss': 0.47140662067315797} | train loss {'Reaction outcome loss': 0.49037730435450233, 'Total loss': 0.49037730435450233}
2022-11-28 00:58:52,667 INFO:     Found new best model at epoch 1
2022-11-28 00:58:52,667 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:52,667 INFO:     Epoch: 2
2022-11-28 00:58:53,430 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46824692663821305, 'Total loss': 0.46824692663821305} | train loss {'Reaction outcome loss': 0.4612493924796581, 'Total loss': 0.4612493924796581}
2022-11-28 00:58:53,430 INFO:     Found new best model at epoch 2
2022-11-28 00:58:53,431 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:53,431 INFO:     Epoch: 3
2022-11-28 00:58:54,196 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.43862487782131543, 'Total loss': 0.43862487782131543} | train loss {'Reaction outcome loss': 0.4343994449103071, 'Total loss': 0.4343994449103071}
2022-11-28 00:58:54,197 INFO:     Found new best model at epoch 3
2022-11-28 00:58:54,197 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:54,197 INFO:     Epoch: 4
2022-11-28 00:58:54,964 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44010585512627254, 'Total loss': 0.44010585512627254} | train loss {'Reaction outcome loss': 0.41636432250661237, 'Total loss': 0.41636432250661237}
2022-11-28 00:58:54,964 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:54,964 INFO:     Epoch: 5
2022-11-28 00:58:55,730 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4172373464839025, 'Total loss': 0.4172373464839025} | train loss {'Reaction outcome loss': 0.41335940598359994, 'Total loss': 0.41335940598359994}
2022-11-28 00:58:55,731 INFO:     Found new best model at epoch 5
2022-11-28 00:58:55,731 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:55,731 INFO:     Epoch: 6
2022-11-28 00:58:56,495 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43495699390769005, 'Total loss': 0.43495699390769005} | train loss {'Reaction outcome loss': 0.39162801067915654, 'Total loss': 0.39162801067915654}
2022-11-28 00:58:56,495 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:56,495 INFO:     Epoch: 7
2022-11-28 00:58:57,260 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44617577930065716, 'Total loss': 0.44617577930065716} | train loss {'Reaction outcome loss': 0.38027987406859476, 'Total loss': 0.38027987406859476}
2022-11-28 00:58:57,260 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:57,260 INFO:     Epoch: 8
2022-11-28 00:58:58,024 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4216684993695129, 'Total loss': 0.4216684993695129} | train loss {'Reaction outcome loss': 0.3863837724521516, 'Total loss': 0.3863837724521516}
2022-11-28 00:58:58,024 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:58,024 INFO:     Epoch: 9
2022-11-28 00:58:58,784 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4302052699706771, 'Total loss': 0.4302052699706771} | train loss {'Reaction outcome loss': 0.37817746818426157, 'Total loss': 0.37817746818426157}
2022-11-28 00:58:58,784 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:58,785 INFO:     Epoch: 10
2022-11-28 00:58:59,549 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41510823369026184, 'Total loss': 0.41510823369026184} | train loss {'Reaction outcome loss': 0.36601957756905784, 'Total loss': 0.36601957756905784}
2022-11-28 00:58:59,549 INFO:     Found new best model at epoch 10
2022-11-28 00:58:59,550 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:58:59,550 INFO:     Epoch: 11
2022-11-28 00:59:00,314 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4071018042212183, 'Total loss': 0.4071018042212183} | train loss {'Reaction outcome loss': 0.3673035410803653, 'Total loss': 0.3673035410803653}
2022-11-28 00:59:00,314 INFO:     Found new best model at epoch 11
2022-11-28 00:59:00,315 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:00,315 INFO:     Epoch: 12
2022-11-28 00:59:01,079 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4371118728410114, 'Total loss': 0.4371118728410114} | train loss {'Reaction outcome loss': 0.3545509512055545, 'Total loss': 0.3545509512055545}
2022-11-28 00:59:01,079 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:01,079 INFO:     Epoch: 13
2022-11-28 00:59:01,841 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4019910225814039, 'Total loss': 0.4019910225814039} | train loss {'Reaction outcome loss': 0.3605668243741797, 'Total loss': 0.3605668243741797}
2022-11-28 00:59:01,841 INFO:     Found new best model at epoch 13
2022-11-28 00:59:01,842 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:01,842 INFO:     Epoch: 14
2022-11-28 00:59:02,608 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4245393233881755, 'Total loss': 0.4245393233881755} | train loss {'Reaction outcome loss': 0.34929459487959263, 'Total loss': 0.34929459487959263}
2022-11-28 00:59:02,608 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:02,608 INFO:     Epoch: 15
2022-11-28 00:59:03,375 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43093993243846024, 'Total loss': 0.43093993243846024} | train loss {'Reaction outcome loss': 0.3496522525205247, 'Total loss': 0.3496522525205247}
2022-11-28 00:59:03,376 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:03,376 INFO:     Epoch: 16
2022-11-28 00:59:04,143 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42698055641217664, 'Total loss': 0.42698055641217664} | train loss {'Reaction outcome loss': 0.3404338156744357, 'Total loss': 0.3404338156744357}
2022-11-28 00:59:04,143 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:04,143 INFO:     Epoch: 17
2022-11-28 00:59:04,909 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43622001565315505, 'Total loss': 0.43622001565315505} | train loss {'Reaction outcome loss': 0.3478625202251057, 'Total loss': 0.3478625202251057}
2022-11-28 00:59:04,910 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:04,910 INFO:     Epoch: 18
2022-11-28 00:59:05,674 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45324672013521194, 'Total loss': 0.45324672013521194} | train loss {'Reaction outcome loss': 0.3466870642657722, 'Total loss': 0.3466870642657722}
2022-11-28 00:59:05,675 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:05,675 INFO:     Epoch: 19
2022-11-28 00:59:06,441 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40409771556204016, 'Total loss': 0.40409771556204016} | train loss {'Reaction outcome loss': 0.3413220469749743, 'Total loss': 0.3413220469749743}
2022-11-28 00:59:06,441 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:06,441 INFO:     Epoch: 20
2022-11-28 00:59:07,203 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4338362562385472, 'Total loss': 0.4338362562385472} | train loss {'Reaction outcome loss': 0.33811709579200516, 'Total loss': 0.33811709579200516}
2022-11-28 00:59:07,203 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:07,203 INFO:     Epoch: 21
2022-11-28 00:59:07,968 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4221803837201812, 'Total loss': 0.4221803837201812} | train loss {'Reaction outcome loss': 0.3428424401509185, 'Total loss': 0.3428424401509185}
2022-11-28 00:59:07,968 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:07,969 INFO:     Epoch: 22
2022-11-28 00:59:08,731 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42001341994513164, 'Total loss': 0.42001341994513164} | train loss {'Reaction outcome loss': 0.34005625146411117, 'Total loss': 0.34005625146411117}
2022-11-28 00:59:08,731 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:08,732 INFO:     Epoch: 23
2022-11-28 00:59:09,501 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42050264758819883, 'Total loss': 0.42050264758819883} | train loss {'Reaction outcome loss': 0.3278217108980302, 'Total loss': 0.3278217108980302}
2022-11-28 00:59:09,502 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:09,502 INFO:     Epoch: 24
2022-11-28 00:59:10,266 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4276798330247402, 'Total loss': 0.4276798330247402} | train loss {'Reaction outcome loss': 0.33116522049831765, 'Total loss': 0.33116522049831765}
2022-11-28 00:59:10,266 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:10,266 INFO:     Epoch: 25
2022-11-28 00:59:11,033 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40637405894019385, 'Total loss': 0.40637405894019385} | train loss {'Reaction outcome loss': 0.3448267162386929, 'Total loss': 0.3448267162386929}
2022-11-28 00:59:11,033 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:11,033 INFO:     Epoch: 26
2022-11-28 00:59:11,798 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4279512211003087, 'Total loss': 0.4279512211003087} | train loss {'Reaction outcome loss': 0.3254349829869405, 'Total loss': 0.3254349829869405}
2022-11-28 00:59:11,798 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:11,798 INFO:     Epoch: 27
2022-11-28 00:59:12,565 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4395383403382518, 'Total loss': 0.4395383403382518} | train loss {'Reaction outcome loss': 0.33193859482003796, 'Total loss': 0.33193859482003796}
2022-11-28 00:59:12,565 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:12,565 INFO:     Epoch: 28
2022-11-28 00:59:13,329 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39599151638421143, 'Total loss': 0.39599151638421143} | train loss {'Reaction outcome loss': 0.3236552795936023, 'Total loss': 0.3236552795936023}
2022-11-28 00:59:13,329 INFO:     Found new best model at epoch 28
2022-11-28 00:59:13,330 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:13,330 INFO:     Epoch: 29
2022-11-28 00:59:14,092 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4344990947707133, 'Total loss': 0.4344990947707133} | train loss {'Reaction outcome loss': 0.32380683422689477, 'Total loss': 0.32380683422689477}
2022-11-28 00:59:14,093 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:14,093 INFO:     Epoch: 30
2022-11-28 00:59:14,861 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42436143281784927, 'Total loss': 0.42436143281784927} | train loss {'Reaction outcome loss': 0.3266357256159667, 'Total loss': 0.3266357256159667}
2022-11-28 00:59:14,861 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:14,861 INFO:     Epoch: 31
2022-11-28 00:59:15,626 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4315440255132588, 'Total loss': 0.4315440255132588} | train loss {'Reaction outcome loss': 0.3253100903314208, 'Total loss': 0.3253100903314208}
2022-11-28 00:59:15,626 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:15,626 INFO:     Epoch: 32
2022-11-28 00:59:16,393 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41889057342301717, 'Total loss': 0.41889057342301717} | train loss {'Reaction outcome loss': 0.32653697820440414, 'Total loss': 0.32653697820440414}
2022-11-28 00:59:16,394 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:16,394 INFO:     Epoch: 33
2022-11-28 00:59:17,161 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39680828018621966, 'Total loss': 0.39680828018621966} | train loss {'Reaction outcome loss': 0.34170257456360326, 'Total loss': 0.34170257456360326}
2022-11-28 00:59:17,161 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:17,162 INFO:     Epoch: 34
2022-11-28 00:59:17,926 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4371579269116575, 'Total loss': 0.4371579269116575} | train loss {'Reaction outcome loss': 0.3204706586717117, 'Total loss': 0.3204706586717117}
2022-11-28 00:59:17,926 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:17,926 INFO:     Epoch: 35
2022-11-28 00:59:18,692 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41101281954483554, 'Total loss': 0.41101281954483554} | train loss {'Reaction outcome loss': 0.31579862429850525, 'Total loss': 0.31579862429850525}
2022-11-28 00:59:18,692 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:18,692 INFO:     Epoch: 36
2022-11-28 00:59:19,461 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43784191086888313, 'Total loss': 0.43784191086888313} | train loss {'Reaction outcome loss': 0.32259448996234324, 'Total loss': 0.32259448996234324}
2022-11-28 00:59:19,461 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:19,461 INFO:     Epoch: 37
2022-11-28 00:59:20,226 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3924141675233841, 'Total loss': 0.3924141675233841} | train loss {'Reaction outcome loss': 0.32036073671113097, 'Total loss': 0.32036073671113097}
2022-11-28 00:59:20,226 INFO:     Found new best model at epoch 37
2022-11-28 00:59:20,227 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:20,227 INFO:     Epoch: 38
2022-11-28 00:59:20,993 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4167016798799688, 'Total loss': 0.4167016798799688} | train loss {'Reaction outcome loss': 0.31894607513001366, 'Total loss': 0.31894607513001366}
2022-11-28 00:59:20,993 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:20,993 INFO:     Epoch: 39
2022-11-28 00:59:21,758 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40859664062207396, 'Total loss': 0.40859664062207396} | train loss {'Reaction outcome loss': 0.31566937420997887, 'Total loss': 0.31566937420997887}
2022-11-28 00:59:21,759 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:21,759 INFO:     Epoch: 40
2022-11-28 00:59:22,525 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4342693937095729, 'Total loss': 0.4342693937095729} | train loss {'Reaction outcome loss': 0.32185794767593184, 'Total loss': 0.32185794767593184}
2022-11-28 00:59:22,525 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:22,526 INFO:     Epoch: 41
2022-11-28 00:59:23,294 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40968711945143615, 'Total loss': 0.40968711945143615} | train loss {'Reaction outcome loss': 0.3116271638221318, 'Total loss': 0.3116271638221318}
2022-11-28 00:59:23,294 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:23,294 INFO:     Epoch: 42
2022-11-28 00:59:24,060 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47713861004872754, 'Total loss': 0.47713861004872754} | train loss {'Reaction outcome loss': 0.31890204377592574, 'Total loss': 0.31890204377592574}
2022-11-28 00:59:24,060 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:24,060 INFO:     Epoch: 43
2022-11-28 00:59:24,824 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3854351968250491, 'Total loss': 0.3854351968250491} | train loss {'Reaction outcome loss': 0.3095715726395288, 'Total loss': 0.3095715726395288}
2022-11-28 00:59:24,824 INFO:     Found new best model at epoch 43
2022-11-28 00:59:24,825 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:24,825 INFO:     Epoch: 44
2022-11-28 00:59:25,591 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.411066222935915, 'Total loss': 0.411066222935915} | train loss {'Reaction outcome loss': 0.3163753126958205, 'Total loss': 0.3163753126958205}
2022-11-28 00:59:25,592 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:25,592 INFO:     Epoch: 45
2022-11-28 00:59:26,357 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41031447290019557, 'Total loss': 0.41031447290019557} | train loss {'Reaction outcome loss': 0.3165173060410926, 'Total loss': 0.3165173060410926}
2022-11-28 00:59:26,357 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:26,357 INFO:     Epoch: 46
2022-11-28 00:59:27,121 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45162053270773456, 'Total loss': 0.45162053270773456} | train loss {'Reaction outcome loss': 0.31842766044240806, 'Total loss': 0.31842766044240806}
2022-11-28 00:59:27,121 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:27,121 INFO:     Epoch: 47
2022-11-28 00:59:27,886 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3987083594230088, 'Total loss': 0.3987083594230088} | train loss {'Reaction outcome loss': 0.31550080187979246, 'Total loss': 0.31550080187979246}
2022-11-28 00:59:27,886 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:27,886 INFO:     Epoch: 48
2022-11-28 00:59:28,649 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40546833114190534, 'Total loss': 0.40546833114190534} | train loss {'Reaction outcome loss': 0.31837734297638937, 'Total loss': 0.31837734297638937}
2022-11-28 00:59:28,650 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:28,650 INFO:     Epoch: 49
2022-11-28 00:59:29,413 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42651616951281374, 'Total loss': 0.42651616951281374} | train loss {'Reaction outcome loss': 0.3105551387754179, 'Total loss': 0.3105551387754179}
2022-11-28 00:59:29,413 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:29,413 INFO:     Epoch: 50
2022-11-28 00:59:30,176 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4257915758273818, 'Total loss': 0.4257915758273818} | train loss {'Reaction outcome loss': 0.31089735052157796, 'Total loss': 0.31089735052157796}
2022-11-28 00:59:30,176 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:30,176 INFO:     Epoch: 51
2022-11-28 00:59:30,940 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42054968428882683, 'Total loss': 0.42054968428882683} | train loss {'Reaction outcome loss': 0.3112810541905703, 'Total loss': 0.3112810541905703}
2022-11-28 00:59:30,940 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:30,940 INFO:     Epoch: 52
2022-11-28 00:59:31,705 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42869269339875743, 'Total loss': 0.42869269339875743} | train loss {'Reaction outcome loss': 0.3200855704865629, 'Total loss': 0.3200855704865629}
2022-11-28 00:59:31,706 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:31,706 INFO:     Epoch: 53
2022-11-28 00:59:32,474 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.418500425463373, 'Total loss': 0.418500425463373} | train loss {'Reaction outcome loss': 0.31424884480093757, 'Total loss': 0.31424884480093757}
2022-11-28 00:59:32,474 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:32,474 INFO:     Epoch: 54
2022-11-28 00:59:33,242 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.427779290147803, 'Total loss': 0.427779290147803} | train loss {'Reaction outcome loss': 0.3144040342210041, 'Total loss': 0.3144040342210041}
2022-11-28 00:59:33,242 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:33,242 INFO:     Epoch: 55
2022-11-28 00:59:34,007 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39953375912525435, 'Total loss': 0.39953375912525435} | train loss {'Reaction outcome loss': 0.3095027105882764, 'Total loss': 0.3095027105882764}
2022-11-28 00:59:34,008 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:34,008 INFO:     Epoch: 56
2022-11-28 00:59:34,770 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40578771518035367, 'Total loss': 0.40578771518035367} | train loss {'Reaction outcome loss': 0.31473895618992465, 'Total loss': 0.31473895618992465}
2022-11-28 00:59:34,770 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:34,770 INFO:     Epoch: 57
2022-11-28 00:59:35,537 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.405885902995413, 'Total loss': 0.405885902995413} | train loss {'Reaction outcome loss': 0.31090670033928847, 'Total loss': 0.31090670033928847}
2022-11-28 00:59:35,537 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:35,537 INFO:     Epoch: 58
2022-11-28 00:59:36,300 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4184189564125104, 'Total loss': 0.4184189564125104} | train loss {'Reaction outcome loss': 0.30979171365259156, 'Total loss': 0.30979171365259156}
2022-11-28 00:59:36,300 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:36,300 INFO:     Epoch: 59
2022-11-28 00:59:37,065 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43188303031704645, 'Total loss': 0.43188303031704645} | train loss {'Reaction outcome loss': 0.30927661379739163, 'Total loss': 0.30927661379739163}
2022-11-28 00:59:37,066 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:37,066 INFO:     Epoch: 60
2022-11-28 00:59:37,835 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42407051541588525, 'Total loss': 0.42407051541588525} | train loss {'Reaction outcome loss': 0.30513146183183115, 'Total loss': 0.30513146183183115}
2022-11-28 00:59:37,835 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:37,835 INFO:     Epoch: 61
2022-11-28 00:59:38,599 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41046528416601097, 'Total loss': 0.41046528416601097} | train loss {'Reaction outcome loss': 0.3175046172353529, 'Total loss': 0.3175046172353529}
2022-11-28 00:59:38,600 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:38,600 INFO:     Epoch: 62
2022-11-28 00:59:39,366 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39535965567285364, 'Total loss': 0.39535965567285364} | train loss {'Reaction outcome loss': 0.31194703932851553, 'Total loss': 0.31194703932851553}
2022-11-28 00:59:39,366 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:39,366 INFO:     Epoch: 63
2022-11-28 00:59:40,138 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4348635477098552, 'Total loss': 0.4348635477098552} | train loss {'Reaction outcome loss': 0.29776958828311295, 'Total loss': 0.29776958828311295}
2022-11-28 00:59:40,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:40,139 INFO:     Epoch: 64
2022-11-28 00:59:40,903 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4020368026738817, 'Total loss': 0.4020368026738817} | train loss {'Reaction outcome loss': 0.31494537291807995, 'Total loss': 0.31494537291807995}
2022-11-28 00:59:40,903 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:40,904 INFO:     Epoch: 65
2022-11-28 00:59:41,670 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4393384007906372, 'Total loss': 0.4393384007906372} | train loss {'Reaction outcome loss': 0.31148610912984415, 'Total loss': 0.31148610912984415}
2022-11-28 00:59:41,670 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:41,670 INFO:     Epoch: 66
2022-11-28 00:59:42,436 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4103339937600223, 'Total loss': 0.4103339937600223} | train loss {'Reaction outcome loss': 0.31338610782498316, 'Total loss': 0.31338610782498316}
2022-11-28 00:59:42,436 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:42,436 INFO:     Epoch: 67
2022-11-28 00:59:43,199 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4193325726823373, 'Total loss': 0.4193325726823373} | train loss {'Reaction outcome loss': 0.31586930612402575, 'Total loss': 0.31586930612402575}
2022-11-28 00:59:43,199 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:43,199 INFO:     Epoch: 68
2022-11-28 00:59:43,965 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3929705453867262, 'Total loss': 0.3929705453867262} | train loss {'Reaction outcome loss': 0.306448238361026, 'Total loss': 0.306448238361026}
2022-11-28 00:59:43,965 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:43,965 INFO:     Epoch: 69
2022-11-28 00:59:44,731 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4251402262598276, 'Total loss': 0.4251402262598276} | train loss {'Reaction outcome loss': 0.3061771817024677, 'Total loss': 0.3061771817024677}
2022-11-28 00:59:44,731 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:44,731 INFO:     Epoch: 70
2022-11-28 00:59:45,493 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4063749858601527, 'Total loss': 0.4063749858601527} | train loss {'Reaction outcome loss': 0.3096273170123177, 'Total loss': 0.3096273170123177}
2022-11-28 00:59:45,494 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:45,494 INFO:     Epoch: 71
2022-11-28 00:59:46,258 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.416656186634844, 'Total loss': 0.416656186634844} | train loss {'Reaction outcome loss': 0.31274246389887506, 'Total loss': 0.31274246389887506}
2022-11-28 00:59:46,258 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:46,258 INFO:     Epoch: 72
2022-11-28 00:59:47,025 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40308604863556946, 'Total loss': 0.40308604863556946} | train loss {'Reaction outcome loss': 0.31189474176555393, 'Total loss': 0.31189474176555393}
2022-11-28 00:59:47,025 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:47,025 INFO:     Epoch: 73
2022-11-28 00:59:47,790 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4174999858845364, 'Total loss': 0.4174999858845364} | train loss {'Reaction outcome loss': 0.30905694953135904, 'Total loss': 0.30905694953135904}
2022-11-28 00:59:47,790 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:47,790 INFO:     Epoch: 74
2022-11-28 00:59:48,555 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.406427952376279, 'Total loss': 0.406427952376279} | train loss {'Reaction outcome loss': 0.3042415016210608, 'Total loss': 0.3042415016210608}
2022-11-28 00:59:48,555 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:48,555 INFO:     Epoch: 75
2022-11-28 00:59:49,321 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4461189637129957, 'Total loss': 0.4461189637129957} | train loss {'Reaction outcome loss': 0.3128986934860868, 'Total loss': 0.3128986934860868}
2022-11-28 00:59:49,321 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:49,321 INFO:     Epoch: 76
2022-11-28 00:59:50,085 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41252417930147867, 'Total loss': 0.41252417930147867} | train loss {'Reaction outcome loss': 0.3103848806161794, 'Total loss': 0.3103848806161794}
2022-11-28 00:59:50,086 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:50,086 INFO:     Epoch: 77
2022-11-28 00:59:50,853 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42645087939771736, 'Total loss': 0.42645087939771736} | train loss {'Reaction outcome loss': 0.3161543981142102, 'Total loss': 0.3161543981142102}
2022-11-28 00:59:50,853 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:50,853 INFO:     Epoch: 78
2022-11-28 00:59:51,620 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41963910548524425, 'Total loss': 0.41963910548524425} | train loss {'Reaction outcome loss': 0.30161897546701855, 'Total loss': 0.30161897546701855}
2022-11-28 00:59:51,620 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:51,620 INFO:     Epoch: 79
2022-11-28 00:59:52,389 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41201267747039144, 'Total loss': 0.41201267747039144} | train loss {'Reaction outcome loss': 0.3061721560755564, 'Total loss': 0.3061721560755564}
2022-11-28 00:59:52,390 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:52,390 INFO:     Epoch: 80
2022-11-28 00:59:53,156 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42589983852072194, 'Total loss': 0.42589983852072194} | train loss {'Reaction outcome loss': 0.3202769117910535, 'Total loss': 0.3202769117910535}
2022-11-28 00:59:53,156 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:53,156 INFO:     Epoch: 81
2022-11-28 00:59:53,921 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4211385172199119, 'Total loss': 0.4211385172199119} | train loss {'Reaction outcome loss': 0.3058365425094962, 'Total loss': 0.3058365425094962}
2022-11-28 00:59:53,921 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:53,921 INFO:     Epoch: 82
2022-11-28 00:59:54,682 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4417600746859204, 'Total loss': 0.4417600746859204} | train loss {'Reaction outcome loss': 0.3082424219577543, 'Total loss': 0.3082424219577543}
2022-11-28 00:59:54,682 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:54,683 INFO:     Epoch: 83
2022-11-28 00:59:55,452 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4223256056958979, 'Total loss': 0.4223256056958979} | train loss {'Reaction outcome loss': 0.31208625468876094, 'Total loss': 0.31208625468876094}
2022-11-28 00:59:55,452 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:55,452 INFO:     Epoch: 84
2022-11-28 00:59:56,221 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3992761302400719, 'Total loss': 0.3992761302400719} | train loss {'Reaction outcome loss': 0.3063669737668768, 'Total loss': 0.3063669737668768}
2022-11-28 00:59:56,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:56,221 INFO:     Epoch: 85
2022-11-28 00:59:56,985 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.418578043918718, 'Total loss': 0.418578043918718} | train loss {'Reaction outcome loss': 0.30516894193245997, 'Total loss': 0.30516894193245997}
2022-11-28 00:59:56,986 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:56,986 INFO:     Epoch: 86
2022-11-28 00:59:57,751 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46152964065020735, 'Total loss': 0.46152964065020735} | train loss {'Reaction outcome loss': 0.3083459220736498, 'Total loss': 0.3083459220736498}
2022-11-28 00:59:57,751 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:57,751 INFO:     Epoch: 87
2022-11-28 00:59:58,520 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3947441268034957, 'Total loss': 0.3947441268034957} | train loss {'Reaction outcome loss': 0.30055584758520126, 'Total loss': 0.30055584758520126}
2022-11-28 00:59:58,520 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:58,520 INFO:     Epoch: 88
2022-11-28 00:59:59,288 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39165443791584537, 'Total loss': 0.39165443791584537} | train loss {'Reaction outcome loss': 0.3043203255341899, 'Total loss': 0.3043203255341899}
2022-11-28 00:59:59,289 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 00:59:59,289 INFO:     Epoch: 89
2022-11-28 01:00:00,056 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4515222432938489, 'Total loss': 0.4515222432938489} | train loss {'Reaction outcome loss': 0.305434497584018, 'Total loss': 0.305434497584018}
2022-11-28 01:00:00,057 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:00,057 INFO:     Epoch: 90
2022-11-28 01:00:00,823 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40970491854981944, 'Total loss': 0.40970491854981944} | train loss {'Reaction outcome loss': 0.3106487966292808, 'Total loss': 0.3106487966292808}
2022-11-28 01:00:00,823 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:00,823 INFO:     Epoch: 91
2022-11-28 01:00:01,596 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41154685989022255, 'Total loss': 0.41154685989022255} | train loss {'Reaction outcome loss': 0.3019106666587533, 'Total loss': 0.3019106666587533}
2022-11-28 01:00:01,596 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:01,596 INFO:     Epoch: 92
2022-11-28 01:00:02,363 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4509965306655927, 'Total loss': 0.4509965306655927} | train loss {'Reaction outcome loss': 0.3024576940318389, 'Total loss': 0.3024576940318389}
2022-11-28 01:00:02,363 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:02,363 INFO:     Epoch: 93
2022-11-28 01:00:03,130 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41633235764774407, 'Total loss': 0.41633235764774407} | train loss {'Reaction outcome loss': 0.30296044994986826, 'Total loss': 0.30296044994986826}
2022-11-28 01:00:03,131 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:03,131 INFO:     Epoch: 94
2022-11-28 01:00:03,899 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41100692545825784, 'Total loss': 0.41100692545825784} | train loss {'Reaction outcome loss': 0.30069633128662265, 'Total loss': 0.30069633128662265}
2022-11-28 01:00:03,899 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:03,899 INFO:     Epoch: 95
2022-11-28 01:00:04,667 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40357215905731375, 'Total loss': 0.40357215905731375} | train loss {'Reaction outcome loss': 0.30411341123943847, 'Total loss': 0.30411341123943847}
2022-11-28 01:00:04,667 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:04,667 INFO:     Epoch: 96
2022-11-28 01:00:05,435 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40649152106859465, 'Total loss': 0.40649152106859465} | train loss {'Reaction outcome loss': 0.3019604841247201, 'Total loss': 0.3019604841247201}
2022-11-28 01:00:05,435 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:05,435 INFO:     Epoch: 97
2022-11-28 01:00:06,206 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43451684374700894, 'Total loss': 0.43451684374700894} | train loss {'Reaction outcome loss': 0.3043222077070705, 'Total loss': 0.3043222077070705}
2022-11-28 01:00:06,207 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:06,207 INFO:     Epoch: 98
2022-11-28 01:00:06,975 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3935497382825071, 'Total loss': 0.3935497382825071} | train loss {'Reaction outcome loss': 0.3088589731243349, 'Total loss': 0.3088589731243349}
2022-11-28 01:00:06,975 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:06,975 INFO:     Epoch: 99
2022-11-28 01:00:07,741 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39704624123194, 'Total loss': 0.39704624123194} | train loss {'Reaction outcome loss': 0.2919879504629681, 'Total loss': 0.2919879504629681}
2022-11-28 01:00:07,741 INFO:     Best model found after epoch 44 of 100.
2022-11-28 01:00:07,741 INFO:   Done with stage: TRAINING
2022-11-28 01:00:07,741 INFO:   Starting stage: EVALUATION
2022-11-28 01:00:07,856 INFO:   Done with stage: EVALUATION
2022-11-28 01:00:07,856 INFO:   Leaving out SEQ value Fold_7
2022-11-28 01:00:07,869 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 01:00:07,869 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:00:08,515 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:00:08,515 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:00:08,587 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:00:08,587 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:00:08,587 INFO:     No hyperparam tuning for this model
2022-11-28 01:00:08,587 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:00:08,587 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:00:08,588 INFO:     None feature selector for col prot
2022-11-28 01:00:08,588 INFO:     None feature selector for col prot
2022-11-28 01:00:08,588 INFO:     None feature selector for col prot
2022-11-28 01:00:08,588 INFO:     None feature selector for col chem
2022-11-28 01:00:08,588 INFO:     None feature selector for col chem
2022-11-28 01:00:08,588 INFO:     None feature selector for col chem
2022-11-28 01:00:08,589 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:00:08,589 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:00:08,590 INFO:     Number of params in model 169741
2022-11-28 01:00:08,593 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:00:08,593 INFO:   Starting stage: TRAINING
2022-11-28 01:00:08,647 INFO:     Val loss before train {'Reaction outcome loss': 1.0016206082972614, 'Total loss': 1.0016206082972614}
2022-11-28 01:00:08,648 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:08,648 INFO:     Epoch: 0
2022-11-28 01:00:09,415 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5797864916649732, 'Total loss': 0.5797864916649732} | train loss {'Reaction outcome loss': 0.6355755485353931, 'Total loss': 0.6355755485353931}
2022-11-28 01:00:09,415 INFO:     Found new best model at epoch 0
2022-11-28 01:00:09,416 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:09,416 INFO:     Epoch: 1
2022-11-28 01:00:10,185 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49604209207675676, 'Total loss': 0.49604209207675676} | train loss {'Reaction outcome loss': 0.49319721890553353, 'Total loss': 0.49319721890553353}
2022-11-28 01:00:10,185 INFO:     Found new best model at epoch 1
2022-11-28 01:00:10,185 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:10,186 INFO:     Epoch: 2
2022-11-28 01:00:10,953 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49569895287806337, 'Total loss': 0.49569895287806337} | train loss {'Reaction outcome loss': 0.4526267262896703, 'Total loss': 0.4526267262896703}
2022-11-28 01:00:10,953 INFO:     Found new best model at epoch 2
2022-11-28 01:00:10,954 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:10,954 INFO:     Epoch: 3
2022-11-28 01:00:11,722 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4736000143668868, 'Total loss': 0.4736000143668868} | train loss {'Reaction outcome loss': 0.4240816706611264, 'Total loss': 0.4240816706611264}
2022-11-28 01:00:11,722 INFO:     Found new best model at epoch 3
2022-11-28 01:00:11,723 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:11,723 INFO:     Epoch: 4
2022-11-28 01:00:12,490 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5020902021364733, 'Total loss': 0.5020902021364733} | train loss {'Reaction outcome loss': 0.40551186130652506, 'Total loss': 0.40551186130652506}
2022-11-28 01:00:12,490 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:12,491 INFO:     Epoch: 5
2022-11-28 01:00:13,259 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4678159288384698, 'Total loss': 0.4678159288384698} | train loss {'Reaction outcome loss': 0.4057234965505139, 'Total loss': 0.4057234965505139}
2022-11-28 01:00:13,259 INFO:     Found new best model at epoch 5
2022-11-28 01:00:13,260 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:13,260 INFO:     Epoch: 6
2022-11-28 01:00:14,026 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4770997576415539, 'Total loss': 0.4770997576415539} | train loss {'Reaction outcome loss': 0.3889062950507768, 'Total loss': 0.3889062950507768}
2022-11-28 01:00:14,026 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:14,026 INFO:     Epoch: 7
2022-11-28 01:00:14,792 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47993414205583657, 'Total loss': 0.47993414205583657} | train loss {'Reaction outcome loss': 0.3840729403760164, 'Total loss': 0.3840729403760164}
2022-11-28 01:00:14,792 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:14,792 INFO:     Epoch: 8
2022-11-28 01:00:15,556 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4807888682592999, 'Total loss': 0.4807888682592999} | train loss {'Reaction outcome loss': 0.3795196472276603, 'Total loss': 0.3795196472276603}
2022-11-28 01:00:15,556 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:15,556 INFO:     Epoch: 9
2022-11-28 01:00:16,321 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4925109977749261, 'Total loss': 0.4925109977749261} | train loss {'Reaction outcome loss': 0.3718029451706717, 'Total loss': 0.3718029451706717}
2022-11-28 01:00:16,321 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:16,321 INFO:     Epoch: 10
2022-11-28 01:00:17,087 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4588402636687864, 'Total loss': 0.4588402636687864} | train loss {'Reaction outcome loss': 0.36591718760469266, 'Total loss': 0.36591718760469266}
2022-11-28 01:00:17,087 INFO:     Found new best model at epoch 10
2022-11-28 01:00:17,088 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:17,088 INFO:     Epoch: 11
2022-11-28 01:00:17,857 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4425939717753367, 'Total loss': 0.4425939717753367} | train loss {'Reaction outcome loss': 0.36952887292230324, 'Total loss': 0.36952887292230324}
2022-11-28 01:00:17,857 INFO:     Found new best model at epoch 11
2022-11-28 01:00:17,858 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:17,858 INFO:     Epoch: 12
2022-11-28 01:00:18,622 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44875150648030365, 'Total loss': 0.44875150648030365} | train loss {'Reaction outcome loss': 0.3638679400507, 'Total loss': 0.3638679400507}
2022-11-28 01:00:18,622 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:18,622 INFO:     Epoch: 13
2022-11-28 01:00:19,385 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4702456752684983, 'Total loss': 0.4702456752684983} | train loss {'Reaction outcome loss': 0.354067474062885, 'Total loss': 0.354067474062885}
2022-11-28 01:00:19,386 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:19,386 INFO:     Epoch: 14
2022-11-28 01:00:20,147 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4693680740892887, 'Total loss': 0.4693680740892887} | train loss {'Reaction outcome loss': 0.3509665934909736, 'Total loss': 0.3509665934909736}
2022-11-28 01:00:20,147 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:20,147 INFO:     Epoch: 15
2022-11-28 01:00:20,908 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46270832453261723, 'Total loss': 0.46270832453261723} | train loss {'Reaction outcome loss': 0.34218986383489064, 'Total loss': 0.34218986383489064}
2022-11-28 01:00:20,908 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:20,908 INFO:     Epoch: 16
2022-11-28 01:00:21,674 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4511153257705949, 'Total loss': 0.4511153257705949} | train loss {'Reaction outcome loss': 0.34166658762842417, 'Total loss': 0.34166658762842417}
2022-11-28 01:00:21,674 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:21,674 INFO:     Epoch: 17
2022-11-28 01:00:22,436 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45112178000536834, 'Total loss': 0.45112178000536834} | train loss {'Reaction outcome loss': 0.3316572952054201, 'Total loss': 0.3316572952054201}
2022-11-28 01:00:22,436 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:22,436 INFO:     Epoch: 18
2022-11-28 01:00:23,200 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4987362250685692, 'Total loss': 0.4987362250685692} | train loss {'Reaction outcome loss': 0.34007767602921496, 'Total loss': 0.34007767602921496}
2022-11-28 01:00:23,200 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:23,200 INFO:     Epoch: 19
2022-11-28 01:00:23,965 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.520871639251709, 'Total loss': 0.520871639251709} | train loss {'Reaction outcome loss': 0.34209783306165087, 'Total loss': 0.34209783306165087}
2022-11-28 01:00:23,966 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:23,966 INFO:     Epoch: 20
2022-11-28 01:00:24,729 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.452718548476696, 'Total loss': 0.452718548476696} | train loss {'Reaction outcome loss': 0.337297928609675, 'Total loss': 0.337297928609675}
2022-11-28 01:00:24,730 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:24,730 INFO:     Epoch: 21
2022-11-28 01:00:25,492 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5079341571439396, 'Total loss': 0.5079341571439396} | train loss {'Reaction outcome loss': 0.33745019936994197, 'Total loss': 0.33745019936994197}
2022-11-28 01:00:25,492 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:25,492 INFO:     Epoch: 22
2022-11-28 01:00:26,255 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4430398168888959, 'Total loss': 0.4430398168888959} | train loss {'Reaction outcome loss': 0.3324561953063934, 'Total loss': 0.3324561953063934}
2022-11-28 01:00:26,255 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:26,255 INFO:     Epoch: 23
2022-11-28 01:00:27,018 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4687118286436254, 'Total loss': 0.4687118286436254} | train loss {'Reaction outcome loss': 0.3300256650714624, 'Total loss': 0.3300256650714624}
2022-11-28 01:00:27,018 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:27,019 INFO:     Epoch: 24
2022-11-28 01:00:27,782 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4857618124647574, 'Total loss': 0.4857618124647574} | train loss {'Reaction outcome loss': 0.33004915714263916, 'Total loss': 0.33004915714263916}
2022-11-28 01:00:27,782 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:27,782 INFO:     Epoch: 25
2022-11-28 01:00:28,545 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46435851840810344, 'Total loss': 0.46435851840810344} | train loss {'Reaction outcome loss': 0.32812704985600805, 'Total loss': 0.32812704985600805}
2022-11-28 01:00:28,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:28,545 INFO:     Epoch: 26
2022-11-28 01:00:29,309 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44365069625729864, 'Total loss': 0.44365069625729864} | train loss {'Reaction outcome loss': 0.3294656135051722, 'Total loss': 0.3294656135051722}
2022-11-28 01:00:29,309 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:29,309 INFO:     Epoch: 27
2022-11-28 01:00:30,077 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44176768376068637, 'Total loss': 0.44176768376068637} | train loss {'Reaction outcome loss': 0.3223058512254107, 'Total loss': 0.3223058512254107}
2022-11-28 01:00:30,078 INFO:     Found new best model at epoch 27
2022-11-28 01:00:30,078 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:30,079 INFO:     Epoch: 28
2022-11-28 01:00:30,844 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46187753636728635, 'Total loss': 0.46187753636728635} | train loss {'Reaction outcome loss': 0.3217675065501563, 'Total loss': 0.3217675065501563}
2022-11-28 01:00:30,844 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:30,844 INFO:     Epoch: 29
2022-11-28 01:00:31,609 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4735800259831277, 'Total loss': 0.4735800259831277} | train loss {'Reaction outcome loss': 0.31998761920558827, 'Total loss': 0.31998761920558827}
2022-11-28 01:00:31,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:31,609 INFO:     Epoch: 30
2022-11-28 01:00:32,373 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45060788027264853, 'Total loss': 0.45060788027264853} | train loss {'Reaction outcome loss': 0.3230582593880113, 'Total loss': 0.3230582593880113}
2022-11-28 01:00:32,373 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:32,373 INFO:     Epoch: 31
2022-11-28 01:00:33,138 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4521174654364586, 'Total loss': 0.4521174654364586} | train loss {'Reaction outcome loss': 0.3198575453021594, 'Total loss': 0.3198575453021594}
2022-11-28 01:00:33,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:33,139 INFO:     Epoch: 32
2022-11-28 01:00:33,904 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48020526919175277, 'Total loss': 0.48020526919175277} | train loss {'Reaction outcome loss': 0.33139425951747165, 'Total loss': 0.33139425951747165}
2022-11-28 01:00:33,904 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:33,904 INFO:     Epoch: 33
2022-11-28 01:00:34,671 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4439942474392327, 'Total loss': 0.4439942474392327} | train loss {'Reaction outcome loss': 0.32339153169924695, 'Total loss': 0.32339153169924695}
2022-11-28 01:00:34,671 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:34,672 INFO:     Epoch: 34
2022-11-28 01:00:35,437 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42797706310044636, 'Total loss': 0.42797706310044636} | train loss {'Reaction outcome loss': 0.3244901944492613, 'Total loss': 0.3244901944492613}
2022-11-28 01:00:35,437 INFO:     Found new best model at epoch 34
2022-11-28 01:00:35,438 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:35,438 INFO:     Epoch: 35
2022-11-28 01:00:36,204 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46865673193877394, 'Total loss': 0.46865673193877394} | train loss {'Reaction outcome loss': 0.31829639602332344, 'Total loss': 0.31829639602332344}
2022-11-28 01:00:36,204 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:36,204 INFO:     Epoch: 36
2022-11-28 01:00:36,967 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46671494096517563, 'Total loss': 0.46671494096517563} | train loss {'Reaction outcome loss': 0.32176826602869457, 'Total loss': 0.32176826602869457}
2022-11-28 01:00:36,969 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:36,969 INFO:     Epoch: 37
2022-11-28 01:00:37,735 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4671164808625525, 'Total loss': 0.4671164808625525} | train loss {'Reaction outcome loss': 0.3219471226236032, 'Total loss': 0.3219471226236032}
2022-11-28 01:00:37,735 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:37,735 INFO:     Epoch: 38
2022-11-28 01:00:38,499 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4898079555820335, 'Total loss': 0.4898079555820335} | train loss {'Reaction outcome loss': 0.3153130529718774, 'Total loss': 0.3153130529718774}
2022-11-28 01:00:38,499 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:38,499 INFO:     Epoch: 39
2022-11-28 01:00:39,264 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.498447661711411, 'Total loss': 0.498447661711411} | train loss {'Reaction outcome loss': 0.3154875556788137, 'Total loss': 0.3154875556788137}
2022-11-28 01:00:39,264 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:39,264 INFO:     Epoch: 40
2022-11-28 01:00:40,030 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4534080502661792, 'Total loss': 0.4534080502661792} | train loss {'Reaction outcome loss': 0.32396665524931684, 'Total loss': 0.32396665524931684}
2022-11-28 01:00:40,030 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:40,030 INFO:     Epoch: 41
2022-11-28 01:00:40,800 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45484790189022367, 'Total loss': 0.45484790189022367} | train loss {'Reaction outcome loss': 0.3129355298775819, 'Total loss': 0.3129355298775819}
2022-11-28 01:00:40,800 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:40,800 INFO:     Epoch: 42
2022-11-28 01:00:41,568 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44063098627057945, 'Total loss': 0.44063098627057945} | train loss {'Reaction outcome loss': 0.31322513504194155, 'Total loss': 0.31322513504194155}
2022-11-28 01:00:41,568 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:41,568 INFO:     Epoch: 43
2022-11-28 01:00:42,333 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45359704000028694, 'Total loss': 0.45359704000028694} | train loss {'Reaction outcome loss': 0.3157289989532963, 'Total loss': 0.3157289989532963}
2022-11-28 01:00:42,333 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:42,333 INFO:     Epoch: 44
2022-11-28 01:00:43,099 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4681739380413836, 'Total loss': 0.4681739380413836} | train loss {'Reaction outcome loss': 0.31361593354132866, 'Total loss': 0.31361593354132866}
2022-11-28 01:00:43,100 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:43,100 INFO:     Epoch: 45
2022-11-28 01:00:43,865 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4755993627689101, 'Total loss': 0.4755993627689101} | train loss {'Reaction outcome loss': 0.3161254604196837, 'Total loss': 0.3161254604196837}
2022-11-28 01:00:43,865 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:43,865 INFO:     Epoch: 46
2022-11-28 01:00:44,628 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47118095274675975, 'Total loss': 0.47118095274675975} | train loss {'Reaction outcome loss': 0.3048255028683812, 'Total loss': 0.3048255028683812}
2022-11-28 01:00:44,629 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:44,629 INFO:     Epoch: 47
2022-11-28 01:00:45,391 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4552348212084987, 'Total loss': 0.4552348212084987} | train loss {'Reaction outcome loss': 0.31032159882447413, 'Total loss': 0.31032159882447413}
2022-11-28 01:00:45,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:45,391 INFO:     Epoch: 48
2022-11-28 01:00:46,156 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4932783447544683, 'Total loss': 0.4932783447544683} | train loss {'Reaction outcome loss': 0.3120319568101437, 'Total loss': 0.3120319568101437}
2022-11-28 01:00:46,156 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:46,156 INFO:     Epoch: 49
2022-11-28 01:00:46,921 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47323466634208505, 'Total loss': 0.47323466634208505} | train loss {'Reaction outcome loss': 0.30422927748652234, 'Total loss': 0.30422927748652234}
2022-11-28 01:00:46,921 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:46,921 INFO:     Epoch: 50
2022-11-28 01:00:47,686 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44248732179403305, 'Total loss': 0.44248732179403305} | train loss {'Reaction outcome loss': 0.3164168956366578, 'Total loss': 0.3164168956366578}
2022-11-28 01:00:47,686 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:47,686 INFO:     Epoch: 51
2022-11-28 01:00:48,448 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46385316347534006, 'Total loss': 0.46385316347534006} | train loss {'Reaction outcome loss': 0.3179085744064181, 'Total loss': 0.3179085744064181}
2022-11-28 01:00:48,448 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:48,448 INFO:     Epoch: 52
2022-11-28 01:00:49,213 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.436416526325047, 'Total loss': 0.436416526325047} | train loss {'Reaction outcome loss': 0.3082445676949236, 'Total loss': 0.3082445676949236}
2022-11-28 01:00:49,213 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:49,214 INFO:     Epoch: 53
2022-11-28 01:00:49,979 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4498265900395133, 'Total loss': 0.4498265900395133} | train loss {'Reaction outcome loss': 0.3128881366442769, 'Total loss': 0.3128881366442769}
2022-11-28 01:00:49,979 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:49,979 INFO:     Epoch: 54
2022-11-28 01:00:50,744 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.468048059804873, 'Total loss': 0.468048059804873} | train loss {'Reaction outcome loss': 0.309985711089065, 'Total loss': 0.309985711089065}
2022-11-28 01:00:50,744 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:50,744 INFO:     Epoch: 55
2022-11-28 01:00:51,508 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44314127652482554, 'Total loss': 0.44314127652482554} | train loss {'Reaction outcome loss': 0.31770248542870244, 'Total loss': 0.31770248542870244}
2022-11-28 01:00:51,509 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:51,509 INFO:     Epoch: 56
2022-11-28 01:00:52,267 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4755140482024713, 'Total loss': 0.4755140482024713} | train loss {'Reaction outcome loss': 0.30774159380985844, 'Total loss': 0.30774159380985844}
2022-11-28 01:00:52,267 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:52,267 INFO:     Epoch: 57
2022-11-28 01:00:53,009 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44384438815442, 'Total loss': 0.44384438815442} | train loss {'Reaction outcome loss': 0.3166145535125848, 'Total loss': 0.3166145535125848}
2022-11-28 01:00:53,009 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:53,009 INFO:     Epoch: 58
2022-11-28 01:00:53,752 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4871710413558917, 'Total loss': 0.4871710413558917} | train loss {'Reaction outcome loss': 0.3074664189330032, 'Total loss': 0.3074664189330032}
2022-11-28 01:00:53,752 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:53,752 INFO:     Epoch: 59
2022-11-28 01:00:54,496 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46064693277532404, 'Total loss': 0.46064693277532404} | train loss {'Reaction outcome loss': 0.3096864734956574, 'Total loss': 0.3096864734956574}
2022-11-28 01:00:54,497 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:54,497 INFO:     Epoch: 60
2022-11-28 01:00:55,243 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4520583799616857, 'Total loss': 0.4520583799616857} | train loss {'Reaction outcome loss': 0.3059672829244406, 'Total loss': 0.3059672829244406}
2022-11-28 01:00:55,244 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:55,244 INFO:     Epoch: 61
2022-11-28 01:00:55,987 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4744569835337726, 'Total loss': 0.4744569835337726} | train loss {'Reaction outcome loss': 0.3169312851443406, 'Total loss': 0.3169312851443406}
2022-11-28 01:00:55,987 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:55,987 INFO:     Epoch: 62
2022-11-28 01:00:56,734 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4743955253877423, 'Total loss': 0.4743955253877423} | train loss {'Reaction outcome loss': 0.3056587268928847, 'Total loss': 0.3056587268928847}
2022-11-28 01:00:56,734 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:56,734 INFO:     Epoch: 63
2022-11-28 01:00:57,480 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4672782427885316, 'Total loss': 0.4672782427885316} | train loss {'Reaction outcome loss': 0.3086257065766521, 'Total loss': 0.3086257065766521}
2022-11-28 01:00:57,480 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:57,481 INFO:     Epoch: 64
2022-11-28 01:00:58,224 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45599444108930504, 'Total loss': 0.45599444108930504} | train loss {'Reaction outcome loss': 0.30455158563751367, 'Total loss': 0.30455158563751367}
2022-11-28 01:00:58,224 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:58,224 INFO:     Epoch: 65
2022-11-28 01:00:58,974 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4538135244087739, 'Total loss': 0.4538135244087739} | train loss {'Reaction outcome loss': 0.30752759198507956, 'Total loss': 0.30752759198507956}
2022-11-28 01:00:58,974 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:58,975 INFO:     Epoch: 66
2022-11-28 01:00:59,719 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45792299576781015, 'Total loss': 0.45792299576781015} | train loss {'Reaction outcome loss': 0.3077057226741266, 'Total loss': 0.3077057226741266}
2022-11-28 01:00:59,719 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:00:59,719 INFO:     Epoch: 67
2022-11-28 01:01:00,461 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47204451296817174, 'Total loss': 0.47204451296817174} | train loss {'Reaction outcome loss': 0.30901864958145925, 'Total loss': 0.30901864958145925}
2022-11-28 01:01:00,462 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:00,462 INFO:     Epoch: 68
2022-11-28 01:01:01,205 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4539744134315036, 'Total loss': 0.4539744134315036} | train loss {'Reaction outcome loss': 0.3072605484105166, 'Total loss': 0.3072605484105166}
2022-11-28 01:01:01,205 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:01,205 INFO:     Epoch: 69
2022-11-28 01:01:01,951 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47523668611591513, 'Total loss': 0.47523668611591513} | train loss {'Reaction outcome loss': 0.3007335209197575, 'Total loss': 0.3007335209197575}
2022-11-28 01:01:01,951 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:01,951 INFO:     Epoch: 70
2022-11-28 01:01:02,694 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46903268518772995, 'Total loss': 0.46903268518772995} | train loss {'Reaction outcome loss': 0.3180774940297969, 'Total loss': 0.3180774940297969}
2022-11-28 01:01:02,694 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:02,694 INFO:     Epoch: 71
2022-11-28 01:01:03,436 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44162444838068704, 'Total loss': 0.44162444838068704} | train loss {'Reaction outcome loss': 0.3098412515114873, 'Total loss': 0.3098412515114873}
2022-11-28 01:01:03,436 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:03,436 INFO:     Epoch: 72
2022-11-28 01:01:04,178 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46400590071623976, 'Total loss': 0.46400590071623976} | train loss {'Reaction outcome loss': 0.3052337788826516, 'Total loss': 0.3052337788826516}
2022-11-28 01:01:04,178 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:04,178 INFO:     Epoch: 73
2022-11-28 01:01:04,918 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4523352464153008, 'Total loss': 0.4523352464153008} | train loss {'Reaction outcome loss': 0.3023093002698114, 'Total loss': 0.3023093002698114}
2022-11-28 01:01:04,918 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:04,919 INFO:     Epoch: 74
2022-11-28 01:01:05,661 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4341397038237615, 'Total loss': 0.4341397038237615} | train loss {'Reaction outcome loss': 0.30694327102373203, 'Total loss': 0.30694327102373203}
2022-11-28 01:01:05,661 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:05,662 INFO:     Epoch: 75
2022-11-28 01:01:06,404 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.448786276307973, 'Total loss': 0.448786276307973} | train loss {'Reaction outcome loss': 0.2994804545606096, 'Total loss': 0.2994804545606096}
2022-11-28 01:01:06,404 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:06,404 INFO:     Epoch: 76
2022-11-28 01:01:07,146 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4814086708832871, 'Total loss': 0.4814086708832871} | train loss {'Reaction outcome loss': 0.3017784375246734, 'Total loss': 0.3017784375246734}
2022-11-28 01:01:07,146 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:07,146 INFO:     Epoch: 77
2022-11-28 01:01:07,888 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46737615865739907, 'Total loss': 0.46737615865739907} | train loss {'Reaction outcome loss': 0.30646484880332625, 'Total loss': 0.30646484880332625}
2022-11-28 01:01:07,888 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:07,888 INFO:     Epoch: 78
2022-11-28 01:01:08,631 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4643397602167996, 'Total loss': 0.4643397602167996} | train loss {'Reaction outcome loss': 0.3069748806226398, 'Total loss': 0.3069748806226398}
2022-11-28 01:01:08,632 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:08,632 INFO:     Epoch: 79
2022-11-28 01:01:09,375 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4669944935224273, 'Total loss': 0.4669944935224273} | train loss {'Reaction outcome loss': 0.3034620472199975, 'Total loss': 0.3034620472199975}
2022-11-28 01:01:09,375 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:09,375 INFO:     Epoch: 80
2022-11-28 01:01:10,115 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4554708603430878, 'Total loss': 0.4554708603430878} | train loss {'Reaction outcome loss': 0.31244435891388883, 'Total loss': 0.31244435891388883}
2022-11-28 01:01:10,115 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:10,115 INFO:     Epoch: 81
2022-11-28 01:01:10,861 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46130857921459456, 'Total loss': 0.46130857921459456} | train loss {'Reaction outcome loss': 0.3093280749275319, 'Total loss': 0.3093280749275319}
2022-11-28 01:01:10,861 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:10,861 INFO:     Epoch: 82
2022-11-28 01:01:11,602 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44683682681484654, 'Total loss': 0.44683682681484654} | train loss {'Reaction outcome loss': 0.30062727152460045, 'Total loss': 0.30062727152460045}
2022-11-28 01:01:11,602 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:11,603 INFO:     Epoch: 83
2022-11-28 01:01:12,342 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45546905865723436, 'Total loss': 0.45546905865723436} | train loss {'Reaction outcome loss': 0.30954161284851933, 'Total loss': 0.30954161284851933}
2022-11-28 01:01:12,342 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:12,342 INFO:     Epoch: 84
2022-11-28 01:01:13,085 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5122933990576051, 'Total loss': 0.5122933990576051} | train loss {'Reaction outcome loss': 0.30778291259681984, 'Total loss': 0.30778291259681984}
2022-11-28 01:01:13,085 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:13,085 INFO:     Epoch: 85
2022-11-28 01:01:13,828 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4368360262702812, 'Total loss': 0.4368360262702812} | train loss {'Reaction outcome loss': 0.30768843836361365, 'Total loss': 0.30768843836361365}
2022-11-28 01:01:13,828 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:13,828 INFO:     Epoch: 86
2022-11-28 01:01:14,571 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4628224301744591, 'Total loss': 0.4628224301744591} | train loss {'Reaction outcome loss': 0.2958464895284945, 'Total loss': 0.2958464895284945}
2022-11-28 01:01:14,571 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:14,571 INFO:     Epoch: 87
2022-11-28 01:01:15,313 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44756685265085916, 'Total loss': 0.44756685265085916} | train loss {'Reaction outcome loss': 0.30387942417855224, 'Total loss': 0.30387942417855224}
2022-11-28 01:01:15,314 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:15,314 INFO:     Epoch: 88
2022-11-28 01:01:16,061 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5011415481567383, 'Total loss': 0.5011415481567383} | train loss {'Reaction outcome loss': 0.2968771502435688, 'Total loss': 0.2968771502435688}
2022-11-28 01:01:16,061 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:16,061 INFO:     Epoch: 89
2022-11-28 01:01:16,802 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4700947796756571, 'Total loss': 0.4700947796756571} | train loss {'Reaction outcome loss': 0.30442162606144146, 'Total loss': 0.30442162606144146}
2022-11-28 01:01:16,802 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:16,802 INFO:     Epoch: 90
2022-11-28 01:01:17,543 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5150048522786661, 'Total loss': 0.5150048522786661} | train loss {'Reaction outcome loss': 0.30628519529296505, 'Total loss': 0.30628519529296505}
2022-11-28 01:01:17,543 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:17,543 INFO:     Epoch: 91
2022-11-28 01:01:18,286 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46025229313156824, 'Total loss': 0.46025229313156824} | train loss {'Reaction outcome loss': 0.302945586612388, 'Total loss': 0.302945586612388}
2022-11-28 01:01:18,286 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:18,286 INFO:     Epoch: 92
2022-11-28 01:01:19,029 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4674307131631808, 'Total loss': 0.4674307131631808} | train loss {'Reaction outcome loss': 0.30416528392402875, 'Total loss': 0.30416528392402875}
2022-11-28 01:01:19,029 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:19,029 INFO:     Epoch: 93
2022-11-28 01:01:19,772 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4555039649659937, 'Total loss': 0.4555039649659937} | train loss {'Reaction outcome loss': 0.3086692582019755, 'Total loss': 0.3086692582019755}
2022-11-28 01:01:19,772 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:19,772 INFO:     Epoch: 94
2022-11-28 01:01:20,516 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4644023322246291, 'Total loss': 0.4644023322246291} | train loss {'Reaction outcome loss': 0.296333666410177, 'Total loss': 0.296333666410177}
2022-11-28 01:01:20,516 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:20,516 INFO:     Epoch: 95
2022-11-28 01:01:21,261 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4933850487524813, 'Total loss': 0.4933850487524813} | train loss {'Reaction outcome loss': 0.29997945435705686, 'Total loss': 0.29997945435705686}
2022-11-28 01:01:21,261 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:21,262 INFO:     Epoch: 96
2022-11-28 01:01:22,004 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43263956294818356, 'Total loss': 0.43263956294818356} | train loss {'Reaction outcome loss': 0.3129055588355949, 'Total loss': 0.3129055588355949}
2022-11-28 01:01:22,004 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:22,004 INFO:     Epoch: 97
2022-11-28 01:01:22,745 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5010611733252351, 'Total loss': 0.5010611733252351} | train loss {'Reaction outcome loss': 0.29871705670150056, 'Total loss': 0.29871705670150056}
2022-11-28 01:01:22,745 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:22,745 INFO:     Epoch: 98
2022-11-28 01:01:23,484 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4744209928268736, 'Total loss': 0.4744209928268736} | train loss {'Reaction outcome loss': 0.3024307129784457, 'Total loss': 0.3024307129784457}
2022-11-28 01:01:23,484 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:23,484 INFO:     Epoch: 99
2022-11-28 01:01:24,226 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4791542830115015, 'Total loss': 0.4791542830115015} | train loss {'Reaction outcome loss': 0.29142439662809333, 'Total loss': 0.29142439662809333}
2022-11-28 01:01:24,226 INFO:     Best model found after epoch 35 of 100.
2022-11-28 01:01:24,227 INFO:   Done with stage: TRAINING
2022-11-28 01:01:24,227 INFO:   Starting stage: EVALUATION
2022-11-28 01:01:24,341 INFO:   Done with stage: EVALUATION
2022-11-28 01:01:24,341 INFO:   Leaving out SEQ value Fold_8
2022-11-28 01:01:24,354 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 01:01:24,354 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:01:24,993 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:01:24,993 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:01:25,063 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:01:25,063 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:01:25,063 INFO:     No hyperparam tuning for this model
2022-11-28 01:01:25,063 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:01:25,063 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:01:25,064 INFO:     None feature selector for col prot
2022-11-28 01:01:25,064 INFO:     None feature selector for col prot
2022-11-28 01:01:25,064 INFO:     None feature selector for col prot
2022-11-28 01:01:25,065 INFO:     None feature selector for col chem
2022-11-28 01:01:25,065 INFO:     None feature selector for col chem
2022-11-28 01:01:25,065 INFO:     None feature selector for col chem
2022-11-28 01:01:25,065 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:01:25,065 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:01:25,066 INFO:     Number of params in model 169741
2022-11-28 01:01:25,069 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:01:25,070 INFO:   Starting stage: TRAINING
2022-11-28 01:01:25,122 INFO:     Val loss before train {'Reaction outcome loss': 1.040611818432808, 'Total loss': 1.040611818432808}
2022-11-28 01:01:25,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:25,123 INFO:     Epoch: 0
2022-11-28 01:01:25,860 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5683804838494821, 'Total loss': 0.5683804838494821} | train loss {'Reaction outcome loss': 0.6234198250555196, 'Total loss': 0.6234198250555196}
2022-11-28 01:01:25,860 INFO:     Found new best model at epoch 0
2022-11-28 01:01:25,861 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:25,861 INFO:     Epoch: 1
2022-11-28 01:01:26,598 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.535414613106034, 'Total loss': 0.535414613106034} | train loss {'Reaction outcome loss': 0.503936601734837, 'Total loss': 0.503936601734837}
2022-11-28 01:01:26,598 INFO:     Found new best model at epoch 1
2022-11-28 01:01:26,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:26,599 INFO:     Epoch: 2
2022-11-28 01:01:27,341 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4925913174044002, 'Total loss': 0.4925913174044002} | train loss {'Reaction outcome loss': 0.46919561723465864, 'Total loss': 0.46919561723465864}
2022-11-28 01:01:27,342 INFO:     Found new best model at epoch 2
2022-11-28 01:01:27,343 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:27,343 INFO:     Epoch: 3
2022-11-28 01:01:28,083 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49065601571717044, 'Total loss': 0.49065601571717044} | train loss {'Reaction outcome loss': 0.4409057572182373, 'Total loss': 0.4409057572182373}
2022-11-28 01:01:28,083 INFO:     Found new best model at epoch 3
2022-11-28 01:01:28,084 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:28,084 INFO:     Epoch: 4
2022-11-28 01:01:28,823 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4841849072413011, 'Total loss': 0.4841849072413011} | train loss {'Reaction outcome loss': 0.42600769498328933, 'Total loss': 0.42600769498328933}
2022-11-28 01:01:28,824 INFO:     Found new best model at epoch 4
2022-11-28 01:01:28,824 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:28,824 INFO:     Epoch: 5
2022-11-28 01:01:29,565 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5065579834309492, 'Total loss': 0.5065579834309492} | train loss {'Reaction outcome loss': 0.41530549004372314, 'Total loss': 0.41530549004372314}
2022-11-28 01:01:29,565 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:29,565 INFO:     Epoch: 6
2022-11-28 01:01:30,304 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48803524334322324, 'Total loss': 0.48803524334322324} | train loss {'Reaction outcome loss': 0.42496225879591726, 'Total loss': 0.42496225879591726}
2022-11-28 01:01:30,304 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:30,304 INFO:     Epoch: 7
2022-11-28 01:01:31,042 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.534618931737813, 'Total loss': 0.534618931737813} | train loss {'Reaction outcome loss': 0.39899564924299236, 'Total loss': 0.39899564924299236}
2022-11-28 01:01:31,042 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:31,043 INFO:     Epoch: 8
2022-11-28 01:01:31,788 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4918490241874348, 'Total loss': 0.4918490241874348} | train loss {'Reaction outcome loss': 0.38080131277622964, 'Total loss': 0.38080131277622964}
2022-11-28 01:01:31,789 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:31,789 INFO:     Epoch: 9
2022-11-28 01:01:32,533 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4799687195230614, 'Total loss': 0.4799687195230614} | train loss {'Reaction outcome loss': 0.3728755590947051, 'Total loss': 0.3728755590947051}
2022-11-28 01:01:32,533 INFO:     Found new best model at epoch 9
2022-11-28 01:01:32,534 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:32,534 INFO:     Epoch: 10
2022-11-28 01:01:33,277 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.471953228793361, 'Total loss': 0.471953228793361} | train loss {'Reaction outcome loss': 0.38578023269832856, 'Total loss': 0.38578023269832856}
2022-11-28 01:01:33,277 INFO:     Found new best model at epoch 10
2022-11-28 01:01:33,277 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:33,278 INFO:     Epoch: 11
2022-11-28 01:01:34,020 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43969610367308964, 'Total loss': 0.43969610367308964} | train loss {'Reaction outcome loss': 0.372210766924055, 'Total loss': 0.372210766924055}
2022-11-28 01:01:34,020 INFO:     Found new best model at epoch 11
2022-11-28 01:01:34,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:34,021 INFO:     Epoch: 12
2022-11-28 01:01:34,764 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4456927454607053, 'Total loss': 0.4456927454607053} | train loss {'Reaction outcome loss': 0.3702802909651266, 'Total loss': 0.3702802909651266}
2022-11-28 01:01:34,764 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:34,764 INFO:     Epoch: 13
2022-11-28 01:01:35,504 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4620619223199107, 'Total loss': 0.4620619223199107} | train loss {'Reaction outcome loss': 0.36257066583705816, 'Total loss': 0.36257066583705816}
2022-11-28 01:01:35,504 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:35,505 INFO:     Epoch: 14
2022-11-28 01:01:36,250 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45420990274711087, 'Total loss': 0.45420990274711087} | train loss {'Reaction outcome loss': 0.36848675275621146, 'Total loss': 0.36848675275621146}
2022-11-28 01:01:36,250 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:36,250 INFO:     Epoch: 15
2022-11-28 01:01:36,991 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45464088124307717, 'Total loss': 0.45464088124307717} | train loss {'Reaction outcome loss': 0.3530938105303266, 'Total loss': 0.3530938105303266}
2022-11-28 01:01:36,992 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:36,992 INFO:     Epoch: 16
2022-11-28 01:01:37,733 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45349697074429557, 'Total loss': 0.45349697074429557} | train loss {'Reaction outcome loss': 0.3550858814646358, 'Total loss': 0.3550858814646358}
2022-11-28 01:01:37,733 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:37,734 INFO:     Epoch: 17
2022-11-28 01:01:38,476 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46357303993268445, 'Total loss': 0.46357303993268445} | train loss {'Reaction outcome loss': 0.35322677244541617, 'Total loss': 0.35322677244541617}
2022-11-28 01:01:38,476 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:38,476 INFO:     Epoch: 18
2022-11-28 01:01:39,214 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46696198054335336, 'Total loss': 0.46696198054335336} | train loss {'Reaction outcome loss': 0.3498814878193473, 'Total loss': 0.3498814878193473}
2022-11-28 01:01:39,215 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:39,215 INFO:     Epoch: 19
2022-11-28 01:01:39,952 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5125817426226356, 'Total loss': 0.5125817426226356} | train loss {'Reaction outcome loss': 0.3350093029533713, 'Total loss': 0.3350093029533713}
2022-11-28 01:01:39,953 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:39,953 INFO:     Epoch: 20
2022-11-28 01:01:40,691 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46091765199195256, 'Total loss': 0.46091765199195256} | train loss {'Reaction outcome loss': 0.3427790957399331, 'Total loss': 0.3427790957399331}
2022-11-28 01:01:40,691 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:40,691 INFO:     Epoch: 21
2022-11-28 01:01:41,433 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48082382706078614, 'Total loss': 0.48082382706078614} | train loss {'Reaction outcome loss': 0.3443332234555893, 'Total loss': 0.3443332234555893}
2022-11-28 01:01:41,433 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:41,433 INFO:     Epoch: 22
2022-11-28 01:01:42,175 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4546557129784064, 'Total loss': 0.4546557129784064} | train loss {'Reaction outcome loss': 0.3519396295371326, 'Total loss': 0.3519396295371326}
2022-11-28 01:01:42,175 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:42,175 INFO:     Epoch: 23
2022-11-28 01:01:42,916 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.431254814971577, 'Total loss': 0.431254814971577} | train loss {'Reaction outcome loss': 0.3325267303056321, 'Total loss': 0.3325267303056321}
2022-11-28 01:01:42,917 INFO:     Found new best model at epoch 23
2022-11-28 01:01:42,917 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:42,917 INFO:     Epoch: 24
2022-11-28 01:01:43,658 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44573282382704993, 'Total loss': 0.44573282382704993} | train loss {'Reaction outcome loss': 0.3316033222450524, 'Total loss': 0.3316033222450524}
2022-11-28 01:01:43,659 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:43,659 INFO:     Epoch: 25
2022-11-28 01:01:44,399 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.440939605913379, 'Total loss': 0.440939605913379} | train loss {'Reaction outcome loss': 0.33936166301791965, 'Total loss': 0.33936166301791965}
2022-11-28 01:01:44,400 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:44,400 INFO:     Epoch: 26
2022-11-28 01:01:45,140 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4489941695197062, 'Total loss': 0.4489941695197062} | train loss {'Reaction outcome loss': 0.33313319310244277, 'Total loss': 0.33313319310244277}
2022-11-28 01:01:45,140 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:45,140 INFO:     Epoch: 27
2022-11-28 01:01:45,880 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4684738384729082, 'Total loss': 0.4684738384729082} | train loss {'Reaction outcome loss': 0.32769257089628384, 'Total loss': 0.32769257089628384}
2022-11-28 01:01:45,880 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:45,881 INFO:     Epoch: 28
2022-11-28 01:01:46,622 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4503904181447896, 'Total loss': 0.4503904181447896} | train loss {'Reaction outcome loss': 0.33895814943651437, 'Total loss': 0.33895814943651437}
2022-11-28 01:01:46,623 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:46,623 INFO:     Epoch: 29
2022-11-28 01:01:47,365 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45168648795648053, 'Total loss': 0.45168648795648053} | train loss {'Reaction outcome loss': 0.34164924222810067, 'Total loss': 0.34164924222810067}
2022-11-28 01:01:47,365 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:47,365 INFO:     Epoch: 30
2022-11-28 01:01:48,105 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47240234166383743, 'Total loss': 0.47240234166383743} | train loss {'Reaction outcome loss': 0.33202115147702604, 'Total loss': 0.33202115147702604}
2022-11-28 01:01:48,105 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:48,105 INFO:     Epoch: 31
2022-11-28 01:01:48,847 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4533852518282153, 'Total loss': 0.4533852518282153} | train loss {'Reaction outcome loss': 0.32501110986538745, 'Total loss': 0.32501110986538745}
2022-11-28 01:01:48,847 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:48,847 INFO:     Epoch: 32
2022-11-28 01:01:49,588 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4425859334455295, 'Total loss': 0.4425859334455295} | train loss {'Reaction outcome loss': 0.3247634851546234, 'Total loss': 0.3247634851546234}
2022-11-28 01:01:49,588 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:49,588 INFO:     Epoch: 33
2022-11-28 01:01:50,329 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4417841742661866, 'Total loss': 0.4417841742661866} | train loss {'Reaction outcome loss': 0.3289027164580851, 'Total loss': 0.3289027164580851}
2022-11-28 01:01:50,330 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:50,330 INFO:     Epoch: 34
2022-11-28 01:01:51,071 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44957707314328715, 'Total loss': 0.44957707314328715} | train loss {'Reaction outcome loss': 0.3341022611026339, 'Total loss': 0.3341022611026339}
2022-11-28 01:01:51,071 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:51,071 INFO:     Epoch: 35
2022-11-28 01:01:51,814 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.430232223123312, 'Total loss': 0.430232223123312} | train loss {'Reaction outcome loss': 0.32376133312701216, 'Total loss': 0.32376133312701216}
2022-11-28 01:01:51,814 INFO:     Found new best model at epoch 35
2022-11-28 01:01:51,815 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:51,815 INFO:     Epoch: 36
2022-11-28 01:01:52,556 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42377356880090455, 'Total loss': 0.42377356880090455} | train loss {'Reaction outcome loss': 0.3270125077803608, 'Total loss': 0.3270125077803608}
2022-11-28 01:01:52,556 INFO:     Found new best model at epoch 36
2022-11-28 01:01:52,557 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:52,557 INFO:     Epoch: 37
2022-11-28 01:01:53,298 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41727371886372566, 'Total loss': 0.41727371886372566} | train loss {'Reaction outcome loss': 0.34092441934202367, 'Total loss': 0.34092441934202367}
2022-11-28 01:01:53,298 INFO:     Found new best model at epoch 37
2022-11-28 01:01:53,299 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:53,299 INFO:     Epoch: 38
2022-11-28 01:01:54,041 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4723536798899824, 'Total loss': 0.4723536798899824} | train loss {'Reaction outcome loss': 0.325646911911772, 'Total loss': 0.325646911911772}
2022-11-28 01:01:54,041 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:54,041 INFO:     Epoch: 39
2022-11-28 01:01:54,778 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4632601985199885, 'Total loss': 0.4632601985199885} | train loss {'Reaction outcome loss': 0.30972315126705746, 'Total loss': 0.30972315126705746}
2022-11-28 01:01:54,778 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:54,778 INFO:     Epoch: 40
2022-11-28 01:01:55,517 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4370246651497754, 'Total loss': 0.4370246651497754} | train loss {'Reaction outcome loss': 0.3176361485554079, 'Total loss': 0.3176361485554079}
2022-11-28 01:01:55,517 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:55,517 INFO:     Epoch: 41
2022-11-28 01:01:56,259 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47288180887699127, 'Total loss': 0.47288180887699127} | train loss {'Reaction outcome loss': 0.3087984165516098, 'Total loss': 0.3087984165516098}
2022-11-28 01:01:56,259 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:56,259 INFO:     Epoch: 42
2022-11-28 01:01:57,000 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4530459202148698, 'Total loss': 0.4530459202148698} | train loss {'Reaction outcome loss': 0.3229283182976036, 'Total loss': 0.3229283182976036}
2022-11-28 01:01:57,000 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:57,000 INFO:     Epoch: 43
2022-11-28 01:01:57,743 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4600511890920726, 'Total loss': 0.4600511890920726} | train loss {'Reaction outcome loss': 0.31331459810329987, 'Total loss': 0.31331459810329987}
2022-11-28 01:01:57,743 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:57,743 INFO:     Epoch: 44
2022-11-28 01:01:58,482 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4251326048238711, 'Total loss': 0.4251326048238711} | train loss {'Reaction outcome loss': 0.3054496546272143, 'Total loss': 0.3054496546272143}
2022-11-28 01:01:58,482 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:58,482 INFO:     Epoch: 45
2022-11-28 01:01:59,224 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44508605348792946, 'Total loss': 0.44508605348792946} | train loss {'Reaction outcome loss': 0.3148762828148223, 'Total loss': 0.3148762828148223}
2022-11-28 01:01:59,225 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:59,225 INFO:     Epoch: 46
2022-11-28 01:01:59,968 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45015367154370656, 'Total loss': 0.45015367154370656} | train loss {'Reaction outcome loss': 0.31218350326396366, 'Total loss': 0.31218350326396366}
2022-11-28 01:01:59,968 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:01:59,968 INFO:     Epoch: 47
2022-11-28 01:02:00,711 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4518586525862867, 'Total loss': 0.4518586525862867} | train loss {'Reaction outcome loss': 0.31574799843379464, 'Total loss': 0.31574799843379464}
2022-11-28 01:02:00,711 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:00,711 INFO:     Epoch: 48
2022-11-28 01:02:01,452 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46673149547793646, 'Total loss': 0.46673149547793646} | train loss {'Reaction outcome loss': 0.30939337472442674, 'Total loss': 0.30939337472442674}
2022-11-28 01:02:01,452 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:01,452 INFO:     Epoch: 49
2022-11-28 01:02:02,193 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45105642757632514, 'Total loss': 0.45105642757632514} | train loss {'Reaction outcome loss': 0.3194268209188573, 'Total loss': 0.3194268209188573}
2022-11-28 01:02:02,194 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:02,194 INFO:     Epoch: 50
2022-11-28 01:02:02,933 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45678752051158383, 'Total loss': 0.45678752051158383} | train loss {'Reaction outcome loss': 0.31593945599820933, 'Total loss': 0.31593945599820933}
2022-11-28 01:02:02,933 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:02,934 INFO:     Epoch: 51
2022-11-28 01:02:03,670 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46773905476385896, 'Total loss': 0.46773905476385896} | train loss {'Reaction outcome loss': 0.3151907977998739, 'Total loss': 0.3151907977998739}
2022-11-28 01:02:03,670 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:03,670 INFO:     Epoch: 52
2022-11-28 01:02:04,411 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5120007741180334, 'Total loss': 0.5120007741180334} | train loss {'Reaction outcome loss': 0.3227854578601204, 'Total loss': 0.3227854578601204}
2022-11-28 01:02:04,411 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:04,411 INFO:     Epoch: 53
2022-11-28 01:02:05,152 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42029408331621776, 'Total loss': 0.42029408331621776} | train loss {'Reaction outcome loss': 0.30653967023619755, 'Total loss': 0.30653967023619755}
2022-11-28 01:02:05,152 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:05,152 INFO:     Epoch: 54
2022-11-28 01:02:05,891 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45186929540200665, 'Total loss': 0.45186929540200665} | train loss {'Reaction outcome loss': 0.31632258427830845, 'Total loss': 0.31632258427830845}
2022-11-28 01:02:05,891 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:05,891 INFO:     Epoch: 55
2022-11-28 01:02:06,632 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4236995769156651, 'Total loss': 0.4236995769156651} | train loss {'Reaction outcome loss': 0.3267254615947227, 'Total loss': 0.3267254615947227}
2022-11-28 01:02:06,632 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:06,632 INFO:     Epoch: 56
2022-11-28 01:02:07,371 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46878341483798897, 'Total loss': 0.46878341483798897} | train loss {'Reaction outcome loss': 0.31135507024492814, 'Total loss': 0.31135507024492814}
2022-11-28 01:02:07,371 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:07,372 INFO:     Epoch: 57
2022-11-28 01:02:08,113 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4164333992045034, 'Total loss': 0.4164333992045034} | train loss {'Reaction outcome loss': 0.3104112541928948, 'Total loss': 0.3104112541928948}
2022-11-28 01:02:08,113 INFO:     Found new best model at epoch 57
2022-11-28 01:02:08,114 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:08,114 INFO:     Epoch: 58
2022-11-28 01:02:08,856 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45852235196666286, 'Total loss': 0.45852235196666286} | train loss {'Reaction outcome loss': 0.3094227845123771, 'Total loss': 0.3094227845123771}
2022-11-28 01:02:08,856 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:08,856 INFO:     Epoch: 59
2022-11-28 01:02:09,598 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4720248393714428, 'Total loss': 0.4720248393714428} | train loss {'Reaction outcome loss': 0.3211335023405098, 'Total loss': 0.3211335023405098}
2022-11-28 01:02:09,598 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:09,598 INFO:     Epoch: 60
2022-11-28 01:02:10,343 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4527782134034417, 'Total loss': 0.4527782134034417} | train loss {'Reaction outcome loss': 0.3388880348387579, 'Total loss': 0.3388880348387579}
2022-11-28 01:02:10,344 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:10,344 INFO:     Epoch: 61
2022-11-28 01:02:11,082 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44832753407006914, 'Total loss': 0.44832753407006914} | train loss {'Reaction outcome loss': 0.31343636381240025, 'Total loss': 0.31343636381240025}
2022-11-28 01:02:11,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:11,083 INFO:     Epoch: 62
2022-11-28 01:02:11,826 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4595824805173007, 'Total loss': 0.4595824805173007} | train loss {'Reaction outcome loss': 0.3136290423766482, 'Total loss': 0.3136290423766482}
2022-11-28 01:02:11,826 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:11,826 INFO:     Epoch: 63
2022-11-28 01:02:12,566 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4686767279424451, 'Total loss': 0.4686767279424451} | train loss {'Reaction outcome loss': 0.3101483833733833, 'Total loss': 0.3101483833733833}
2022-11-28 01:02:12,566 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:12,566 INFO:     Epoch: 64
2022-11-28 01:02:13,306 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4435158571736379, 'Total loss': 0.4435158571736379} | train loss {'Reaction outcome loss': 0.29790875249304755, 'Total loss': 0.29790875249304755}
2022-11-28 01:02:13,306 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:13,306 INFO:     Epoch: 65
2022-11-28 01:02:14,046 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42779970135201106, 'Total loss': 0.42779970135201106} | train loss {'Reaction outcome loss': 0.3105601089505049, 'Total loss': 0.3105601089505049}
2022-11-28 01:02:14,046 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:14,046 INFO:     Epoch: 66
2022-11-28 01:02:14,786 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4908325353806669, 'Total loss': 0.4908325353806669} | train loss {'Reaction outcome loss': 0.3177518938462578, 'Total loss': 0.3177518938462578}
2022-11-28 01:02:14,786 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:14,786 INFO:     Epoch: 67
2022-11-28 01:02:15,529 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44330512901598756, 'Total loss': 0.44330512901598756} | train loss {'Reaction outcome loss': 0.3014690784571564, 'Total loss': 0.3014690784571564}
2022-11-28 01:02:15,529 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:15,530 INFO:     Epoch: 68
2022-11-28 01:02:16,274 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4411148235879161, 'Total loss': 0.4411148235879161} | train loss {'Reaction outcome loss': 0.2999331788027938, 'Total loss': 0.2999331788027938}
2022-11-28 01:02:16,274 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:16,274 INFO:     Epoch: 69
2022-11-28 01:02:17,020 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4595677977935834, 'Total loss': 0.4595677977935834} | train loss {'Reaction outcome loss': 0.30622244600643994, 'Total loss': 0.30622244600643994}
2022-11-28 01:02:17,020 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:17,020 INFO:     Epoch: 70
2022-11-28 01:02:17,760 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4740323339673606, 'Total loss': 0.4740323339673606} | train loss {'Reaction outcome loss': 0.3120823874767975, 'Total loss': 0.3120823874767975}
2022-11-28 01:02:17,760 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:17,760 INFO:     Epoch: 71
2022-11-28 01:02:18,500 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4637319120493802, 'Total loss': 0.4637319120493802} | train loss {'Reaction outcome loss': 0.3082464494410646, 'Total loss': 0.3082464494410646}
2022-11-28 01:02:18,500 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:18,500 INFO:     Epoch: 72
2022-11-28 01:02:19,242 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44896115007048304, 'Total loss': 0.44896115007048304} | train loss {'Reaction outcome loss': 0.3156208325071856, 'Total loss': 0.3156208325071856}
2022-11-28 01:02:19,242 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:19,242 INFO:     Epoch: 73
2022-11-28 01:02:19,984 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4789128696376627, 'Total loss': 0.4789128696376627} | train loss {'Reaction outcome loss': 0.3065559956676851, 'Total loss': 0.3065559956676851}
2022-11-28 01:02:19,984 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:19,984 INFO:     Epoch: 74
2022-11-28 01:02:20,723 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44061664830554614, 'Total loss': 0.44061664830554614} | train loss {'Reaction outcome loss': 0.31120306618421184, 'Total loss': 0.31120306618421184}
2022-11-28 01:02:20,723 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:20,723 INFO:     Epoch: 75
2022-11-28 01:02:21,463 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4335990263657136, 'Total loss': 0.4335990263657136} | train loss {'Reaction outcome loss': 0.3098849714677102, 'Total loss': 0.3098849714677102}
2022-11-28 01:02:21,463 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:21,464 INFO:     Epoch: 76
2022-11-28 01:02:22,203 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44149681993506174, 'Total loss': 0.44149681993506174} | train loss {'Reaction outcome loss': 0.328007373642101, 'Total loss': 0.328007373642101}
2022-11-28 01:02:22,203 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:22,203 INFO:     Epoch: 77
2022-11-28 01:02:22,942 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43824022060090845, 'Total loss': 0.43824022060090845} | train loss {'Reaction outcome loss': 0.3019350611638685, 'Total loss': 0.3019350611638685}
2022-11-28 01:02:22,942 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:22,942 INFO:     Epoch: 78
2022-11-28 01:02:23,683 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42250601066784427, 'Total loss': 0.42250601066784427} | train loss {'Reaction outcome loss': 0.31963422481227016, 'Total loss': 0.31963422481227016}
2022-11-28 01:02:23,683 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:23,683 INFO:     Epoch: 79
2022-11-28 01:02:24,422 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4408740272576159, 'Total loss': 0.4408740272576159} | train loss {'Reaction outcome loss': 0.3153202098451163, 'Total loss': 0.3153202098451163}
2022-11-28 01:02:24,422 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:24,422 INFO:     Epoch: 80
2022-11-28 01:02:25,163 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44465099376710976, 'Total loss': 0.44465099376710976} | train loss {'Reaction outcome loss': 0.3039420247026097, 'Total loss': 0.3039420247026097}
2022-11-28 01:02:25,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:25,163 INFO:     Epoch: 81
2022-11-28 01:02:25,905 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45739826424555347, 'Total loss': 0.45739826424555347} | train loss {'Reaction outcome loss': 0.3119967187705793, 'Total loss': 0.3119967187705793}
2022-11-28 01:02:25,905 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:25,905 INFO:     Epoch: 82
2022-11-28 01:02:26,647 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4494668763469566, 'Total loss': 0.4494668763469566} | train loss {'Reaction outcome loss': 0.3057430962832109, 'Total loss': 0.3057430962832109}
2022-11-28 01:02:26,647 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:26,647 INFO:     Epoch: 83
2022-11-28 01:02:27,389 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4580792771144347, 'Total loss': 0.4580792771144347} | train loss {'Reaction outcome loss': 0.32360144369756644, 'Total loss': 0.32360144369756644}
2022-11-28 01:02:27,389 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:27,389 INFO:     Epoch: 84
2022-11-28 01:02:28,135 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4551291083070365, 'Total loss': 0.4551291083070365} | train loss {'Reaction outcome loss': 0.3685778024708211, 'Total loss': 0.3685778024708211}
2022-11-28 01:02:28,135 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:28,135 INFO:     Epoch: 85
2022-11-28 01:02:28,880 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43074726922945544, 'Total loss': 0.43074726922945544} | train loss {'Reaction outcome loss': 0.30308256455157934, 'Total loss': 0.30308256455157934}
2022-11-28 01:02:28,880 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:28,880 INFO:     Epoch: 86
2022-11-28 01:02:29,621 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45870858600193803, 'Total loss': 0.45870858600193803} | train loss {'Reaction outcome loss': 0.3132967186843324, 'Total loss': 0.3132967186843324}
2022-11-28 01:02:29,621 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:29,621 INFO:     Epoch: 87
2022-11-28 01:02:30,362 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44318117370659654, 'Total loss': 0.44318117370659654} | train loss {'Reaction outcome loss': 0.31453978798167426, 'Total loss': 0.31453978798167426}
2022-11-28 01:02:30,363 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:30,363 INFO:     Epoch: 88
2022-11-28 01:02:31,102 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44397723945704376, 'Total loss': 0.44397723945704376} | train loss {'Reaction outcome loss': 0.32587372905269324, 'Total loss': 0.32587372905269324}
2022-11-28 01:02:31,102 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:31,103 INFO:     Epoch: 89
2022-11-28 01:02:31,839 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4623214622790163, 'Total loss': 0.4623214622790163} | train loss {'Reaction outcome loss': 0.3020141816694244, 'Total loss': 0.3020141816694244}
2022-11-28 01:02:31,839 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:31,840 INFO:     Epoch: 90
2022-11-28 01:02:32,580 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4466276886788281, 'Total loss': 0.4466276886788281} | train loss {'Reaction outcome loss': 0.31448933168461446, 'Total loss': 0.31448933168461446}
2022-11-28 01:02:32,580 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:32,580 INFO:     Epoch: 91
2022-11-28 01:02:33,320 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4696962757205421, 'Total loss': 0.4696962757205421} | train loss {'Reaction outcome loss': 0.3026345318314329, 'Total loss': 0.3026345318314329}
2022-11-28 01:02:33,320 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:33,320 INFO:     Epoch: 92
2022-11-28 01:02:34,061 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44767453182827344, 'Total loss': 0.44767453182827344} | train loss {'Reaction outcome loss': 0.30899758131699523, 'Total loss': 0.30899758131699523}
2022-11-28 01:02:34,061 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:34,061 INFO:     Epoch: 93
2022-11-28 01:02:34,808 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41701776669784024, 'Total loss': 0.41701776669784024} | train loss {'Reaction outcome loss': 0.3037190772187689, 'Total loss': 0.3037190772187689}
2022-11-28 01:02:34,808 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:34,808 INFO:     Epoch: 94
2022-11-28 01:02:35,559 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43598559126257896, 'Total loss': 0.43598559126257896} | train loss {'Reaction outcome loss': 0.302003626816299, 'Total loss': 0.302003626816299}
2022-11-28 01:02:35,559 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:35,560 INFO:     Epoch: 95
2022-11-28 01:02:36,313 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42935588684949005, 'Total loss': 0.42935588684949005} | train loss {'Reaction outcome loss': 0.3061644965028654, 'Total loss': 0.3061644965028654}
2022-11-28 01:02:36,313 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:36,314 INFO:     Epoch: 96
2022-11-28 01:02:37,066 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44301834397695283, 'Total loss': 0.44301834397695283} | train loss {'Reaction outcome loss': 0.30790428887027116, 'Total loss': 0.30790428887027116}
2022-11-28 01:02:37,066 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:37,066 INFO:     Epoch: 97
2022-11-28 01:02:37,815 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4555691758340055, 'Total loss': 0.4555691758340055} | train loss {'Reaction outcome loss': 0.31661359626452934, 'Total loss': 0.31661359626452934}
2022-11-28 01:02:37,815 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:37,815 INFO:     Epoch: 98
2022-11-28 01:02:38,567 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48199908198280766, 'Total loss': 0.48199908198280766} | train loss {'Reaction outcome loss': 0.3114540281239897, 'Total loss': 0.3114540281239897}
2022-11-28 01:02:38,567 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:38,567 INFO:     Epoch: 99
2022-11-28 01:02:39,317 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44806755368005147, 'Total loss': 0.44806755368005147} | train loss {'Reaction outcome loss': 0.316718221283876, 'Total loss': 0.316718221283876}
2022-11-28 01:02:39,317 INFO:     Best model found after epoch 58 of 100.
2022-11-28 01:02:39,318 INFO:   Done with stage: TRAINING
2022-11-28 01:02:39,318 INFO:   Starting stage: EVALUATION
2022-11-28 01:02:39,439 INFO:   Done with stage: EVALUATION
2022-11-28 01:02:39,439 INFO:   Leaving out SEQ value Fold_9
2022-11-28 01:02:39,452 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 01:02:39,452 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:02:40,106 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:02:40,106 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:02:40,176 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:02:40,176 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:02:40,176 INFO:     No hyperparam tuning for this model
2022-11-28 01:02:40,176 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:02:40,176 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:02:40,177 INFO:     None feature selector for col prot
2022-11-28 01:02:40,177 INFO:     None feature selector for col prot
2022-11-28 01:02:40,177 INFO:     None feature selector for col prot
2022-11-28 01:02:40,178 INFO:     None feature selector for col chem
2022-11-28 01:02:40,178 INFO:     None feature selector for col chem
2022-11-28 01:02:40,178 INFO:     None feature selector for col chem
2022-11-28 01:02:40,178 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:02:40,178 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:02:40,180 INFO:     Number of params in model 169741
2022-11-28 01:02:40,183 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:02:40,183 INFO:   Starting stage: TRAINING
2022-11-28 01:02:40,237 INFO:     Val loss before train {'Reaction outcome loss': 1.0079666958613829, 'Total loss': 1.0079666958613829}
2022-11-28 01:02:40,237 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:40,237 INFO:     Epoch: 0
2022-11-28 01:02:40,990 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5333210636268962, 'Total loss': 0.5333210636268962} | train loss {'Reaction outcome loss': 0.6490552260750725, 'Total loss': 0.6490552260750725}
2022-11-28 01:02:40,990 INFO:     Found new best model at epoch 0
2022-11-28 01:02:40,991 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:40,991 INFO:     Epoch: 1
2022-11-28 01:02:41,744 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5042913860895417, 'Total loss': 0.5042913860895417} | train loss {'Reaction outcome loss': 0.516142273922601, 'Total loss': 0.516142273922601}
2022-11-28 01:02:41,744 INFO:     Found new best model at epoch 1
2022-11-28 01:02:41,745 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:41,745 INFO:     Epoch: 2
2022-11-28 01:02:42,498 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4862140068276362, 'Total loss': 0.4862140068276362} | train loss {'Reaction outcome loss': 0.4662152650135179, 'Total loss': 0.4662152650135179}
2022-11-28 01:02:42,500 INFO:     Found new best model at epoch 2
2022-11-28 01:02:42,500 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:42,500 INFO:     Epoch: 3
2022-11-28 01:02:43,252 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5014347278259017, 'Total loss': 0.5014347278259017} | train loss {'Reaction outcome loss': 0.43496725413828125, 'Total loss': 0.43496725413828125}
2022-11-28 01:02:43,252 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:43,252 INFO:     Epoch: 4
2022-11-28 01:02:44,005 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4820266586135734, 'Total loss': 0.4820266586135734} | train loss {'Reaction outcome loss': 0.42341321274157495, 'Total loss': 0.42341321274157495}
2022-11-28 01:02:44,005 INFO:     Found new best model at epoch 4
2022-11-28 01:02:44,006 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:44,006 INFO:     Epoch: 5
2022-11-28 01:02:44,760 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44118921865116467, 'Total loss': 0.44118921865116467} | train loss {'Reaction outcome loss': 0.41790856721420444, 'Total loss': 0.41790856721420444}
2022-11-28 01:02:44,761 INFO:     Found new best model at epoch 5
2022-11-28 01:02:44,761 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:44,761 INFO:     Epoch: 6
2022-11-28 01:02:45,517 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4744111329994418, 'Total loss': 0.4744111329994418} | train loss {'Reaction outcome loss': 0.4014411507354629, 'Total loss': 0.4014411507354629}
2022-11-28 01:02:45,517 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:45,517 INFO:     Epoch: 7
2022-11-28 01:02:46,269 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4205669950355183, 'Total loss': 0.4205669950355183} | train loss {'Reaction outcome loss': 0.39850564793713633, 'Total loss': 0.39850564793713633}
2022-11-28 01:02:46,269 INFO:     Found new best model at epoch 7
2022-11-28 01:02:46,270 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:46,270 INFO:     Epoch: 8
2022-11-28 01:02:47,017 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44124641743573273, 'Total loss': 0.44124641743573273} | train loss {'Reaction outcome loss': 0.39394683784414686, 'Total loss': 0.39394683784414686}
2022-11-28 01:02:47,017 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:47,017 INFO:     Epoch: 9
2022-11-28 01:02:47,770 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4700328555296768, 'Total loss': 0.4700328555296768} | train loss {'Reaction outcome loss': 0.38228474106759797, 'Total loss': 0.38228474106759797}
2022-11-28 01:02:47,770 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:47,770 INFO:     Epoch: 10
2022-11-28 01:02:48,525 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4749546538699757, 'Total loss': 0.4749546538699757} | train loss {'Reaction outcome loss': 0.3753083980371875, 'Total loss': 0.3753083980371875}
2022-11-28 01:02:48,526 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:48,526 INFO:     Epoch: 11
2022-11-28 01:02:49,278 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4320781823586334, 'Total loss': 0.4320781823586334} | train loss {'Reaction outcome loss': 0.37089163140063325, 'Total loss': 0.37089163140063325}
2022-11-28 01:02:49,278 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:49,278 INFO:     Epoch: 12
2022-11-28 01:02:50,027 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4470619037747383, 'Total loss': 0.4470619037747383} | train loss {'Reaction outcome loss': 0.36938918700381634, 'Total loss': 0.36938918700381634}
2022-11-28 01:02:50,027 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:50,027 INFO:     Epoch: 13
2022-11-28 01:02:50,780 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43909551423381676, 'Total loss': 0.43909551423381676} | train loss {'Reaction outcome loss': 0.3642977878992115, 'Total loss': 0.3642977878992115}
2022-11-28 01:02:50,780 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:50,780 INFO:     Epoch: 14
2022-11-28 01:02:51,535 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47390847585418006, 'Total loss': 0.47390847585418006} | train loss {'Reaction outcome loss': 0.3560425104393113, 'Total loss': 0.3560425104393113}
2022-11-28 01:02:51,536 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:51,536 INFO:     Epoch: 15
2022-11-28 01:02:52,290 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45805501836267387, 'Total loss': 0.45805501836267387} | train loss {'Reaction outcome loss': 0.36221843173787477, 'Total loss': 0.36221843173787477}
2022-11-28 01:02:52,290 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:52,290 INFO:     Epoch: 16
2022-11-28 01:02:53,041 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46249064938588574, 'Total loss': 0.46249064938588574} | train loss {'Reaction outcome loss': 0.34737992502989307, 'Total loss': 0.34737992502989307}
2022-11-28 01:02:53,041 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:53,041 INFO:     Epoch: 17
2022-11-28 01:02:53,793 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4760769500651143, 'Total loss': 0.4760769500651143} | train loss {'Reaction outcome loss': 0.3566499051427649, 'Total loss': 0.3566499051427649}
2022-11-28 01:02:53,793 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:53,793 INFO:     Epoch: 18
2022-11-28 01:02:54,550 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43574927069924096, 'Total loss': 0.43574927069924096} | train loss {'Reaction outcome loss': 0.34623004817554065, 'Total loss': 0.34623004817554065}
2022-11-28 01:02:54,550 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:54,550 INFO:     Epoch: 19
2022-11-28 01:02:55,305 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42824640971693123, 'Total loss': 0.42824640971693123} | train loss {'Reaction outcome loss': 0.3531804994770115, 'Total loss': 0.3531804994770115}
2022-11-28 01:02:55,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:55,305 INFO:     Epoch: 20
2022-11-28 01:02:56,058 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4340163863856684, 'Total loss': 0.4340163863856684} | train loss {'Reaction outcome loss': 0.3406952427579991, 'Total loss': 0.3406952427579991}
2022-11-28 01:02:56,058 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:56,058 INFO:     Epoch: 21
2022-11-28 01:02:56,808 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4405707774514502, 'Total loss': 0.4405707774514502} | train loss {'Reaction outcome loss': 0.35043564934523835, 'Total loss': 0.35043564934523835}
2022-11-28 01:02:56,809 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:56,809 INFO:     Epoch: 22
2022-11-28 01:02:57,559 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41917013173753565, 'Total loss': 0.41917013173753565} | train loss {'Reaction outcome loss': 0.3389259789499544, 'Total loss': 0.3389259789499544}
2022-11-28 01:02:57,559 INFO:     Found new best model at epoch 22
2022-11-28 01:02:57,560 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:57,560 INFO:     Epoch: 23
2022-11-28 01:02:58,313 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4232176681133834, 'Total loss': 0.4232176681133834} | train loss {'Reaction outcome loss': 0.34096958307969955, 'Total loss': 0.34096958307969955}
2022-11-28 01:02:58,313 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:58,313 INFO:     Epoch: 24
2022-11-28 01:02:59,069 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4499137354168025, 'Total loss': 0.4499137354168025} | train loss {'Reaction outcome loss': 0.34374884711278064, 'Total loss': 0.34374884711278064}
2022-11-28 01:02:59,069 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:59,069 INFO:     Epoch: 25
2022-11-28 01:02:59,821 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4479097703641111, 'Total loss': 0.4479097703641111} | train loss {'Reaction outcome loss': 0.33458376409966617, 'Total loss': 0.33458376409966617}
2022-11-28 01:02:59,821 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:02:59,821 INFO:     Epoch: 26
2022-11-28 01:03:00,575 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40863711590116675, 'Total loss': 0.40863711590116675} | train loss {'Reaction outcome loss': 0.3380737100397387, 'Total loss': 0.3380737100397387}
2022-11-28 01:03:00,576 INFO:     Found new best model at epoch 26
2022-11-28 01:03:00,577 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:00,577 INFO:     Epoch: 27
2022-11-28 01:03:01,331 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4064550030637871, 'Total loss': 0.4064550030637871} | train loss {'Reaction outcome loss': 0.3345408147020686, 'Total loss': 0.3345408147020686}
2022-11-28 01:03:01,331 INFO:     Found new best model at epoch 27
2022-11-28 01:03:01,332 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:01,332 INFO:     Epoch: 28
2022-11-28 01:03:02,084 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4188310436227105, 'Total loss': 0.4188310436227105} | train loss {'Reaction outcome loss': 0.33140159144456827, 'Total loss': 0.33140159144456827}
2022-11-28 01:03:02,085 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:02,085 INFO:     Epoch: 29
2022-11-28 01:03:02,837 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4494153437289325, 'Total loss': 0.4494153437289325} | train loss {'Reaction outcome loss': 0.3360633013709899, 'Total loss': 0.3360633013709899}
2022-11-28 01:03:02,837 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:02,837 INFO:     Epoch: 30
2022-11-28 01:03:03,589 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4694197638468309, 'Total loss': 0.4694197638468309} | train loss {'Reaction outcome loss': 0.33101888863189566, 'Total loss': 0.33101888863189566}
2022-11-28 01:03:03,590 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:03,590 INFO:     Epoch: 31
2022-11-28 01:03:04,343 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43704069270329043, 'Total loss': 0.43704069270329043} | train loss {'Reaction outcome loss': 0.3390319897162338, 'Total loss': 0.3390319897162338}
2022-11-28 01:03:04,343 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:04,343 INFO:     Epoch: 32
2022-11-28 01:03:05,094 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4286955578083342, 'Total loss': 0.4286955578083342} | train loss {'Reaction outcome loss': 0.33221506243271215, 'Total loss': 0.33221506243271215}
2022-11-28 01:03:05,094 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:05,094 INFO:     Epoch: 33
2022-11-28 01:03:05,844 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42561477896842087, 'Total loss': 0.42561477896842087} | train loss {'Reaction outcome loss': 0.32689722660448284, 'Total loss': 0.32689722660448284}
2022-11-28 01:03:05,845 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:05,845 INFO:     Epoch: 34
2022-11-28 01:03:06,595 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44803367487408896, 'Total loss': 0.44803367487408896} | train loss {'Reaction outcome loss': 0.3265241656692759, 'Total loss': 0.3265241656692759}
2022-11-28 01:03:06,595 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:06,595 INFO:     Epoch: 35
2022-11-28 01:03:07,348 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4389756349000064, 'Total loss': 0.4389756349000064} | train loss {'Reaction outcome loss': 0.3297137572099605, 'Total loss': 0.3297137572099605}
2022-11-28 01:03:07,348 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:07,348 INFO:     Epoch: 36
2022-11-28 01:03:08,098 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.425428878177296, 'Total loss': 0.425428878177296} | train loss {'Reaction outcome loss': 0.3193394799206045, 'Total loss': 0.3193394799206045}
2022-11-28 01:03:08,098 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:08,098 INFO:     Epoch: 37
2022-11-28 01:03:08,851 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4375932121818716, 'Total loss': 0.4375932121818716} | train loss {'Reaction outcome loss': 0.32908956087645025, 'Total loss': 0.32908956087645025}
2022-11-28 01:03:08,851 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:08,851 INFO:     Epoch: 38
2022-11-28 01:03:09,604 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45910594290630385, 'Total loss': 0.45910594290630385} | train loss {'Reaction outcome loss': 0.3168683498797397, 'Total loss': 0.3168683498797397}
2022-11-28 01:03:09,604 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:09,604 INFO:     Epoch: 39
2022-11-28 01:03:10,357 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45680770616639743, 'Total loss': 0.45680770616639743} | train loss {'Reaction outcome loss': 0.32424427190374944, 'Total loss': 0.32424427190374944}
2022-11-28 01:03:10,357 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:10,357 INFO:     Epoch: 40
2022-11-28 01:03:11,109 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.411877252669497, 'Total loss': 0.411877252669497} | train loss {'Reaction outcome loss': 0.32107303054222175, 'Total loss': 0.32107303054222175}
2022-11-28 01:03:11,109 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:11,109 INFO:     Epoch: 41
2022-11-28 01:03:11,857 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4373297073285688, 'Total loss': 0.4373297073285688} | train loss {'Reaction outcome loss': 0.3148147974073166, 'Total loss': 0.3148147974073166}
2022-11-28 01:03:11,857 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:11,858 INFO:     Epoch: 42
2022-11-28 01:03:12,610 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4439620023423975, 'Total loss': 0.4439620023423975} | train loss {'Reaction outcome loss': 0.3176106825591095, 'Total loss': 0.3176106825591095}
2022-11-28 01:03:12,610 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:12,611 INFO:     Epoch: 43
2022-11-28 01:03:13,362 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4009149143980308, 'Total loss': 0.4009149143980308} | train loss {'Reaction outcome loss': 0.32540617760030494, 'Total loss': 0.32540617760030494}
2022-11-28 01:03:13,363 INFO:     Found new best model at epoch 43
2022-11-28 01:03:13,364 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:13,364 INFO:     Epoch: 44
2022-11-28 01:03:14,114 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44992464916272595, 'Total loss': 0.44992464916272595} | train loss {'Reaction outcome loss': 0.3168526353735116, 'Total loss': 0.3168526353735116}
2022-11-28 01:03:14,114 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:14,114 INFO:     Epoch: 45
2022-11-28 01:03:14,864 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44348422065377235, 'Total loss': 0.44348422065377235} | train loss {'Reaction outcome loss': 0.3268940124901072, 'Total loss': 0.3268940124901072}
2022-11-28 01:03:14,864 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:14,864 INFO:     Epoch: 46
2022-11-28 01:03:15,615 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4671906249767, 'Total loss': 0.4671906249767} | train loss {'Reaction outcome loss': 0.3146489748971597, 'Total loss': 0.3146489748971597}
2022-11-28 01:03:15,615 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:15,615 INFO:     Epoch: 47
2022-11-28 01:03:16,367 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4187341589819301, 'Total loss': 0.4187341589819301} | train loss {'Reaction outcome loss': 0.31459444520934937, 'Total loss': 0.31459444520934937}
2022-11-28 01:03:16,367 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:16,367 INFO:     Epoch: 48
2022-11-28 01:03:17,116 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4392850741066716, 'Total loss': 0.4392850741066716} | train loss {'Reaction outcome loss': 0.32200436537424404, 'Total loss': 0.32200436537424404}
2022-11-28 01:03:17,117 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:17,117 INFO:     Epoch: 49
2022-11-28 01:03:17,867 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4365882533179088, 'Total loss': 0.4365882533179088} | train loss {'Reaction outcome loss': 0.3165169631942145, 'Total loss': 0.3165169631942145}
2022-11-28 01:03:17,868 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:17,868 INFO:     Epoch: 50
2022-11-28 01:03:18,622 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4272422328252684, 'Total loss': 0.4272422328252684} | train loss {'Reaction outcome loss': 0.31660633193208804, 'Total loss': 0.31660633193208804}
2022-11-28 01:03:18,622 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:18,622 INFO:     Epoch: 51
2022-11-28 01:03:19,374 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4488825256174261, 'Total loss': 0.4488825256174261} | train loss {'Reaction outcome loss': 0.33035122008333284, 'Total loss': 0.33035122008333284}
2022-11-28 01:03:19,374 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:19,375 INFO:     Epoch: 52
2022-11-28 01:03:20,129 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43670530312440614, 'Total loss': 0.43670530312440614} | train loss {'Reaction outcome loss': 0.31010551807741005, 'Total loss': 0.31010551807741005}
2022-11-28 01:03:20,129 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:20,129 INFO:     Epoch: 53
2022-11-28 01:03:20,885 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4283313297412612, 'Total loss': 0.4283313297412612} | train loss {'Reaction outcome loss': 0.31330579549314513, 'Total loss': 0.31330579549314513}
2022-11-28 01:03:20,885 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:20,885 INFO:     Epoch: 54
2022-11-28 01:03:21,642 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4720187608829953, 'Total loss': 0.4720187608829953} | train loss {'Reaction outcome loss': 0.31667960588369637, 'Total loss': 0.31667960588369637}
2022-11-28 01:03:21,642 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:21,642 INFO:     Epoch: 55
2022-11-28 01:03:22,395 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4498167769475417, 'Total loss': 0.4498167769475417} | train loss {'Reaction outcome loss': 0.3160978062078357, 'Total loss': 0.3160978062078357}
2022-11-28 01:03:22,395 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:22,395 INFO:     Epoch: 56
2022-11-28 01:03:23,146 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42912174185568636, 'Total loss': 0.42912174185568636} | train loss {'Reaction outcome loss': 0.3145174840765615, 'Total loss': 0.3145174840765615}
2022-11-28 01:03:23,146 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:23,146 INFO:     Epoch: 57
2022-11-28 01:03:23,900 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4202708075331016, 'Total loss': 0.4202708075331016} | train loss {'Reaction outcome loss': 0.30773042920496196, 'Total loss': 0.30773042920496196}
2022-11-28 01:03:23,900 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:23,900 INFO:     Epoch: 58
2022-11-28 01:03:24,651 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.459909299896522, 'Total loss': 0.459909299896522} | train loss {'Reaction outcome loss': 0.3174130936874257, 'Total loss': 0.3174130936874257}
2022-11-28 01:03:24,651 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:24,651 INFO:     Epoch: 59
2022-11-28 01:03:25,405 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40155633979222993, 'Total loss': 0.40155633979222993} | train loss {'Reaction outcome loss': 0.3164335717296889, 'Total loss': 0.3164335717296889}
2022-11-28 01:03:25,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:25,405 INFO:     Epoch: 60
2022-11-28 01:03:26,163 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4224326613951813, 'Total loss': 0.4224326613951813} | train loss {'Reaction outcome loss': 0.30939903521850226, 'Total loss': 0.30939903521850226}
2022-11-28 01:03:26,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:26,163 INFO:     Epoch: 61
2022-11-28 01:03:26,917 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42411815239624545, 'Total loss': 0.42411815239624545} | train loss {'Reaction outcome loss': 0.3144016602947827, 'Total loss': 0.3144016602947827}
2022-11-28 01:03:26,917 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:26,917 INFO:     Epoch: 62
2022-11-28 01:03:27,676 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45103166421706026, 'Total loss': 0.45103166421706026} | train loss {'Reaction outcome loss': 0.3075774082793824, 'Total loss': 0.3075774082793824}
2022-11-28 01:03:27,677 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:27,677 INFO:     Epoch: 63
2022-11-28 01:03:28,431 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42713418196548114, 'Total loss': 0.42713418196548114} | train loss {'Reaction outcome loss': 0.3138254604512645, 'Total loss': 0.3138254604512645}
2022-11-28 01:03:28,431 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:28,432 INFO:     Epoch: 64
2022-11-28 01:03:29,187 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4259598824110898, 'Total loss': 0.4259598824110898} | train loss {'Reaction outcome loss': 0.3115906348872569, 'Total loss': 0.3115906348872569}
2022-11-28 01:03:29,187 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:29,188 INFO:     Epoch: 65
2022-11-28 01:03:29,941 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4408541281114925, 'Total loss': 0.4408541281114925} | train loss {'Reaction outcome loss': 0.30954408827387997, 'Total loss': 0.30954408827387997}
2022-11-28 01:03:29,941 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:29,941 INFO:     Epoch: 66
2022-11-28 01:03:30,698 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4352818874811584, 'Total loss': 0.4352818874811584} | train loss {'Reaction outcome loss': 0.3093128042415746, 'Total loss': 0.3093128042415746}
2022-11-28 01:03:30,698 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:30,698 INFO:     Epoch: 67
2022-11-28 01:03:31,448 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4190701821988279, 'Total loss': 0.4190701821988279} | train loss {'Reaction outcome loss': 0.3050224047995383, 'Total loss': 0.3050224047995383}
2022-11-28 01:03:31,449 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:31,449 INFO:     Epoch: 68
2022-11-28 01:03:32,201 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4296006346968087, 'Total loss': 0.4296006346968087} | train loss {'Reaction outcome loss': 0.3073420711011896, 'Total loss': 0.3073420711011896}
2022-11-28 01:03:32,202 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:32,202 INFO:     Epoch: 69
2022-11-28 01:03:32,953 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4671200161630457, 'Total loss': 0.4671200161630457} | train loss {'Reaction outcome loss': 0.3135853139082751, 'Total loss': 0.3135853139082751}
2022-11-28 01:03:32,953 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:32,953 INFO:     Epoch: 70
2022-11-28 01:03:33,708 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4592968709766865, 'Total loss': 0.4592968709766865} | train loss {'Reaction outcome loss': 0.3258366661086198, 'Total loss': 0.3258366661086198}
2022-11-28 01:03:33,708 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:33,709 INFO:     Epoch: 71
2022-11-28 01:03:34,465 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42530063404278323, 'Total loss': 0.42530063404278323} | train loss {'Reaction outcome loss': 0.31886161446210837, 'Total loss': 0.31886161446210837}
2022-11-28 01:03:34,465 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:34,465 INFO:     Epoch: 72
2022-11-28 01:03:35,235 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41840334372086957, 'Total loss': 0.41840334372086957} | train loss {'Reaction outcome loss': 0.2963353489495574, 'Total loss': 0.2963353489495574}
2022-11-28 01:03:35,235 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:35,235 INFO:     Epoch: 73
2022-11-28 01:03:36,008 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4792647585272789, 'Total loss': 0.4792647585272789} | train loss {'Reaction outcome loss': 0.30725029699744716, 'Total loss': 0.30725029699744716}
2022-11-28 01:03:36,008 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:36,008 INFO:     Epoch: 74
2022-11-28 01:03:36,776 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4671899022703821, 'Total loss': 0.4671899022703821} | train loss {'Reaction outcome loss': 0.31062216176501206, 'Total loss': 0.31062216176501206}
2022-11-28 01:03:36,776 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:36,776 INFO:     Epoch: 75
2022-11-28 01:03:37,545 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41418715684928675, 'Total loss': 0.41418715684928675} | train loss {'Reaction outcome loss': 0.30959911431155857, 'Total loss': 0.30959911431155857}
2022-11-28 01:03:37,546 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:37,546 INFO:     Epoch: 76
2022-11-28 01:03:38,317 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.441890092397278, 'Total loss': 0.441890092397278} | train loss {'Reaction outcome loss': 0.3095075976584227, 'Total loss': 0.3095075976584227}
2022-11-28 01:03:38,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:38,317 INFO:     Epoch: 77
2022-11-28 01:03:39,089 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4173965643752705, 'Total loss': 0.4173965643752705} | train loss {'Reaction outcome loss': 0.3141759585949682, 'Total loss': 0.3141759585949682}
2022-11-28 01:03:39,089 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:39,089 INFO:     Epoch: 78
2022-11-28 01:03:39,861 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.431707245551727, 'Total loss': 0.431707245551727} | train loss {'Reaction outcome loss': 0.3027365789298088, 'Total loss': 0.3027365789298088}
2022-11-28 01:03:39,862 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:39,862 INFO:     Epoch: 79
2022-11-28 01:03:40,632 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40232752974737773, 'Total loss': 0.40232752974737773} | train loss {'Reaction outcome loss': 0.3190164503401085, 'Total loss': 0.3190164503401085}
2022-11-28 01:03:40,633 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:40,633 INFO:     Epoch: 80
2022-11-28 01:03:41,401 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4285466256128116, 'Total loss': 0.4285466256128116} | train loss {'Reaction outcome loss': 0.3062043208628893, 'Total loss': 0.3062043208628893}
2022-11-28 01:03:41,401 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:41,401 INFO:     Epoch: 81
2022-11-28 01:03:42,171 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4346151649951935, 'Total loss': 0.4346151649951935} | train loss {'Reaction outcome loss': 0.30277996729578704, 'Total loss': 0.30277996729578704}
2022-11-28 01:03:42,171 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:42,171 INFO:     Epoch: 82
2022-11-28 01:03:42,927 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5306915071877566, 'Total loss': 0.5306915071877566} | train loss {'Reaction outcome loss': 0.3096330729763835, 'Total loss': 0.3096330729763835}
2022-11-28 01:03:42,927 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:42,927 INFO:     Epoch: 83
2022-11-28 01:03:43,677 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4953556870194999, 'Total loss': 0.4953556870194999} | train loss {'Reaction outcome loss': 0.31483975897032407, 'Total loss': 0.31483975897032407}
2022-11-28 01:03:43,677 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:43,677 INFO:     Epoch: 84
2022-11-28 01:03:44,427 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4624187897213481, 'Total loss': 0.4624187897213481} | train loss {'Reaction outcome loss': 0.3016312655301825, 'Total loss': 0.3016312655301825}
2022-11-28 01:03:44,428 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:44,428 INFO:     Epoch: 85
2022-11-28 01:03:45,180 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4390988170423291, 'Total loss': 0.4390988170423291} | train loss {'Reaction outcome loss': 0.30713573963411395, 'Total loss': 0.30713573963411395}
2022-11-28 01:03:45,181 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:45,181 INFO:     Epoch: 86
2022-11-28 01:03:45,932 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45257391543550923, 'Total loss': 0.45257391543550923} | train loss {'Reaction outcome loss': 0.30021324562990376, 'Total loss': 0.30021324562990376}
2022-11-28 01:03:45,933 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:45,933 INFO:     Epoch: 87
2022-11-28 01:03:46,692 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47210782969539816, 'Total loss': 0.47210782969539816} | train loss {'Reaction outcome loss': 0.30790988180125434, 'Total loss': 0.30790988180125434}
2022-11-28 01:03:46,693 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:46,693 INFO:     Epoch: 88
2022-11-28 01:03:47,448 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42420822754502296, 'Total loss': 0.42420822754502296} | train loss {'Reaction outcome loss': 0.29857408171219213, 'Total loss': 0.29857408171219213}
2022-11-28 01:03:47,448 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:47,449 INFO:     Epoch: 89
2022-11-28 01:03:48,204 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4418346228247339, 'Total loss': 0.4418346228247339} | train loss {'Reaction outcome loss': 0.30707944959642425, 'Total loss': 0.30707944959642425}
2022-11-28 01:03:48,204 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:48,205 INFO:     Epoch: 90
2022-11-28 01:03:48,956 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42996098880063405, 'Total loss': 0.42996098880063405} | train loss {'Reaction outcome loss': 0.3073141631339827, 'Total loss': 0.3073141631339827}
2022-11-28 01:03:48,956 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:48,956 INFO:     Epoch: 91
2022-11-28 01:03:49,710 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4746483943679116, 'Total loss': 0.4746483943679116} | train loss {'Reaction outcome loss': 0.307172270116186, 'Total loss': 0.307172270116186}
2022-11-28 01:03:49,710 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:49,710 INFO:     Epoch: 92
2022-11-28 01:03:50,460 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41570738347416575, 'Total loss': 0.41570738347416575} | train loss {'Reaction outcome loss': 0.3064477164298296, 'Total loss': 0.3064477164298296}
2022-11-28 01:03:50,461 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:50,461 INFO:     Epoch: 93
2022-11-28 01:03:51,210 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4310057061639699, 'Total loss': 0.4310057061639699} | train loss {'Reaction outcome loss': 0.30410818518289634, 'Total loss': 0.30410818518289634}
2022-11-28 01:03:51,210 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:51,210 INFO:     Epoch: 94
2022-11-28 01:03:51,959 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4326567717573859, 'Total loss': 0.4326567717573859} | train loss {'Reaction outcome loss': 0.29659457961397784, 'Total loss': 0.29659457961397784}
2022-11-28 01:03:51,959 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:51,959 INFO:     Epoch: 95
2022-11-28 01:03:52,708 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4326370693743229, 'Total loss': 0.4326370693743229} | train loss {'Reaction outcome loss': 0.30522417856921114, 'Total loss': 0.30522417856921114}
2022-11-28 01:03:52,708 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:52,708 INFO:     Epoch: 96
2022-11-28 01:03:53,456 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45980051769451663, 'Total loss': 0.45980051769451663} | train loss {'Reaction outcome loss': 0.295162622876946, 'Total loss': 0.295162622876946}
2022-11-28 01:03:53,456 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:53,456 INFO:     Epoch: 97
2022-11-28 01:03:54,204 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4256190870973197, 'Total loss': 0.4256190870973197} | train loss {'Reaction outcome loss': 0.29489084273096056, 'Total loss': 0.29489084273096056}
2022-11-28 01:03:54,204 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:54,204 INFO:     Epoch: 98
2022-11-28 01:03:54,955 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4484734697775407, 'Total loss': 0.4484734697775407} | train loss {'Reaction outcome loss': 0.29673822146029244, 'Total loss': 0.29673822146029244}
2022-11-28 01:03:54,955 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:54,955 INFO:     Epoch: 99
2022-11-28 01:03:55,703 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43167083304036746, 'Total loss': 0.43167083304036746} | train loss {'Reaction outcome loss': 0.30771246579505745, 'Total loss': 0.30771246579505745}
2022-11-28 01:03:55,704 INFO:     Best model found after epoch 44 of 100.
2022-11-28 01:03:55,704 INFO:   Done with stage: TRAINING
2022-11-28 01:03:55,704 INFO:   Starting stage: EVALUATION
2022-11-28 01:03:55,819 INFO:   Done with stage: EVALUATION
2022-11-28 01:03:55,827 INFO:   Leaving out SEQ value Fold_0
2022-11-28 01:03:55,840 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 01:03:55,840 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:03:56,497 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:03:56,498 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:03:56,567 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:03:56,567 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:03:56,567 INFO:     No hyperparam tuning for this model
2022-11-28 01:03:56,567 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:03:56,567 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:03:56,568 INFO:     None feature selector for col prot
2022-11-28 01:03:56,568 INFO:     None feature selector for col prot
2022-11-28 01:03:56,568 INFO:     None feature selector for col prot
2022-11-28 01:03:56,569 INFO:     None feature selector for col chem
2022-11-28 01:03:56,569 INFO:     None feature selector for col chem
2022-11-28 01:03:56,569 INFO:     None feature selector for col chem
2022-11-28 01:03:56,569 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:03:56,569 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:03:56,571 INFO:     Number of params in model 169741
2022-11-28 01:03:56,574 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:03:56,574 INFO:   Starting stage: TRAINING
2022-11-28 01:03:56,627 INFO:     Val loss before train {'Reaction outcome loss': 0.988142071122473, 'Total loss': 0.988142071122473}
2022-11-28 01:03:56,628 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:56,628 INFO:     Epoch: 0
2022-11-28 01:03:57,368 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5340093597769737, 'Total loss': 0.5340093597769737} | train loss {'Reaction outcome loss': 0.6295733040084645, 'Total loss': 0.6295733040084645}
2022-11-28 01:03:57,368 INFO:     Found new best model at epoch 0
2022-11-28 01:03:57,369 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:57,369 INFO:     Epoch: 1
2022-11-28 01:03:58,117 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.46499106084758585, 'Total loss': 0.46499106084758585} | train loss {'Reaction outcome loss': 0.49379406620045097, 'Total loss': 0.49379406620045097}
2022-11-28 01:03:58,118 INFO:     Found new best model at epoch 1
2022-11-28 01:03:58,118 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:58,119 INFO:     Epoch: 2
2022-11-28 01:03:58,862 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.465251854874871, 'Total loss': 0.465251854874871} | train loss {'Reaction outcome loss': 0.46049018447496454, 'Total loss': 0.46049018447496454}
2022-11-28 01:03:58,862 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:58,862 INFO:     Epoch: 3
2022-11-28 01:03:59,601 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47229843925346027, 'Total loss': 0.47229843925346027} | train loss {'Reaction outcome loss': 0.4389892696726079, 'Total loss': 0.4389892696726079}
2022-11-28 01:03:59,601 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:03:59,601 INFO:     Epoch: 4
2022-11-28 01:04:00,340 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46555475086312403, 'Total loss': 0.46555475086312403} | train loss {'Reaction outcome loss': 0.42658689484304313, 'Total loss': 0.42658689484304313}
2022-11-28 01:04:00,340 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:00,340 INFO:     Epoch: 5
2022-11-28 01:04:01,084 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46554007787596097, 'Total loss': 0.46554007787596097} | train loss {'Reaction outcome loss': 0.418276009024406, 'Total loss': 0.418276009024406}
2022-11-28 01:04:01,084 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:01,084 INFO:     Epoch: 6
2022-11-28 01:04:01,824 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4439527124843814, 'Total loss': 0.4439527124843814} | train loss {'Reaction outcome loss': 0.3998383891217563, 'Total loss': 0.3998383891217563}
2022-11-28 01:04:01,824 INFO:     Found new best model at epoch 6
2022-11-28 01:04:01,825 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:01,825 INFO:     Epoch: 7
2022-11-28 01:04:02,566 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4574489881369201, 'Total loss': 0.4574489881369201} | train loss {'Reaction outcome loss': 0.4003809844048656, 'Total loss': 0.4003809844048656}
2022-11-28 01:04:02,566 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:02,567 INFO:     Epoch: 8
2022-11-28 01:04:03,306 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4330283562568101, 'Total loss': 0.4330283562568101} | train loss {'Reaction outcome loss': 0.3943446560781829, 'Total loss': 0.3943446560781829}
2022-11-28 01:04:03,306 INFO:     Found new best model at epoch 8
2022-11-28 01:04:03,307 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:03,307 INFO:     Epoch: 9
2022-11-28 01:04:04,048 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.39022690430283546, 'Total loss': 0.39022690430283546} | train loss {'Reaction outcome loss': 0.38284801177832545, 'Total loss': 0.38284801177832545}
2022-11-28 01:04:04,048 INFO:     Found new best model at epoch 9
2022-11-28 01:04:04,049 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:04,049 INFO:     Epoch: 10
2022-11-28 01:04:04,791 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40995331752029335, 'Total loss': 0.40995331752029335} | train loss {'Reaction outcome loss': 0.3770005753453897, 'Total loss': 0.3770005753453897}
2022-11-28 01:04:04,791 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:04,792 INFO:     Epoch: 11
2022-11-28 01:04:05,530 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41650027341463347, 'Total loss': 0.41650027341463347} | train loss {'Reaction outcome loss': 0.36799305285118067, 'Total loss': 0.36799305285118067}
2022-11-28 01:04:05,530 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:05,531 INFO:     Epoch: 12
2022-11-28 01:04:06,268 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40987315672365104, 'Total loss': 0.40987315672365104} | train loss {'Reaction outcome loss': 0.3759115729709061, 'Total loss': 0.3759115729709061}
2022-11-28 01:04:06,268 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:06,268 INFO:     Epoch: 13
2022-11-28 01:04:07,006 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4214106415483085, 'Total loss': 0.4214106415483085} | train loss {'Reaction outcome loss': 0.3561709067042993, 'Total loss': 0.3561709067042993}
2022-11-28 01:04:07,006 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:07,006 INFO:     Epoch: 14
2022-11-28 01:04:07,743 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40660601447929035, 'Total loss': 0.40660601447929035} | train loss {'Reaction outcome loss': 0.35118286098752705, 'Total loss': 0.35118286098752705}
2022-11-28 01:04:07,743 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:07,743 INFO:     Epoch: 15
2022-11-28 01:04:08,483 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4455804428593679, 'Total loss': 0.4455804428593679} | train loss {'Reaction outcome loss': 0.35498384331562083, 'Total loss': 0.35498384331562083}
2022-11-28 01:04:08,483 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:08,483 INFO:     Epoch: 16
2022-11-28 01:04:09,218 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45122834345833823, 'Total loss': 0.45122834345833823} | train loss {'Reaction outcome loss': 0.35716294889547384, 'Total loss': 0.35716294889547384}
2022-11-28 01:04:09,218 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:09,218 INFO:     Epoch: 17
2022-11-28 01:04:09,953 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4204329519786618, 'Total loss': 0.4204329519786618} | train loss {'Reaction outcome loss': 0.3504927027894526, 'Total loss': 0.3504927027894526}
2022-11-28 01:04:09,953 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:09,953 INFO:     Epoch: 18
2022-11-28 01:04:10,687 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43855610422112723, 'Total loss': 0.43855610422112723} | train loss {'Reaction outcome loss': 0.356899506370632, 'Total loss': 0.356899506370632}
2022-11-28 01:04:10,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:10,688 INFO:     Epoch: 19
2022-11-28 01:04:11,424 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42728702249852096, 'Total loss': 0.42728702249852096} | train loss {'Reaction outcome loss': 0.33573566136919725, 'Total loss': 0.33573566136919725}
2022-11-28 01:04:11,425 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:11,425 INFO:     Epoch: 20
2022-11-28 01:04:12,164 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4016816560178995, 'Total loss': 0.4016816560178995} | train loss {'Reaction outcome loss': 0.342542665162865, 'Total loss': 0.342542665162865}
2022-11-28 01:04:12,165 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:12,165 INFO:     Epoch: 21
2022-11-28 01:04:12,903 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4106569029390812, 'Total loss': 0.4106569029390812} | train loss {'Reaction outcome loss': 0.34401892478368723, 'Total loss': 0.34401892478368723}
2022-11-28 01:04:12,903 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:12,903 INFO:     Epoch: 22
2022-11-28 01:04:13,645 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41616732390089467, 'Total loss': 0.41616732390089467} | train loss {'Reaction outcome loss': 0.3406344119991575, 'Total loss': 0.3406344119991575}
2022-11-28 01:04:13,645 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:13,645 INFO:     Epoch: 23
2022-11-28 01:04:14,385 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43512902133674786, 'Total loss': 0.43512902133674786} | train loss {'Reaction outcome loss': 0.3306717788990663, 'Total loss': 0.3306717788990663}
2022-11-28 01:04:14,385 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:14,385 INFO:     Epoch: 24
2022-11-28 01:04:15,121 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40584611147642136, 'Total loss': 0.40584611147642136} | train loss {'Reaction outcome loss': 0.32876383117875274, 'Total loss': 0.32876383117875274}
2022-11-28 01:04:15,122 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:15,122 INFO:     Epoch: 25
2022-11-28 01:04:15,861 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41649445857514034, 'Total loss': 0.41649445857514034} | train loss {'Reaction outcome loss': 0.33721528764890163, 'Total loss': 0.33721528764890163}
2022-11-28 01:04:15,861 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:15,861 INFO:     Epoch: 26
2022-11-28 01:04:16,597 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39518244022672827, 'Total loss': 0.39518244022672827} | train loss {'Reaction outcome loss': 0.33378586319028114, 'Total loss': 0.33378586319028114}
2022-11-28 01:04:16,597 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:16,597 INFO:     Epoch: 27
2022-11-28 01:04:17,333 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3891595673154701, 'Total loss': 0.3891595673154701} | train loss {'Reaction outcome loss': 0.33216720402848965, 'Total loss': 0.33216720402848965}
2022-11-28 01:04:17,333 INFO:     Found new best model at epoch 27
2022-11-28 01:04:17,334 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:17,334 INFO:     Epoch: 28
2022-11-28 01:04:18,082 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4239088554273952, 'Total loss': 0.4239088554273952} | train loss {'Reaction outcome loss': 0.3257516984884836, 'Total loss': 0.3257516984884836}
2022-11-28 01:04:18,082 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:18,083 INFO:     Epoch: 29
2022-11-28 01:04:18,826 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4047123597172851, 'Total loss': 0.4047123597172851} | train loss {'Reaction outcome loss': 0.32508714865056837, 'Total loss': 0.32508714865056837}
2022-11-28 01:04:18,826 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:18,826 INFO:     Epoch: 30
2022-11-28 01:04:19,567 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40923228540288453, 'Total loss': 0.40923228540288453} | train loss {'Reaction outcome loss': 0.32473705903607974, 'Total loss': 0.32473705903607974}
2022-11-28 01:04:19,567 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:19,567 INFO:     Epoch: 31
2022-11-28 01:04:20,308 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40092025392434816, 'Total loss': 0.40092025392434816} | train loss {'Reaction outcome loss': 0.33734416137544476, 'Total loss': 0.33734416137544476}
2022-11-28 01:04:20,309 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:20,309 INFO:     Epoch: 32
2022-11-28 01:04:21,047 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41253539005463774, 'Total loss': 0.41253539005463774} | train loss {'Reaction outcome loss': 0.32685238731150723, 'Total loss': 0.32685238731150723}
2022-11-28 01:04:21,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:21,047 INFO:     Epoch: 33
2022-11-28 01:04:21,788 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.428100277077068, 'Total loss': 0.428100277077068} | train loss {'Reaction outcome loss': 0.32796173317700017, 'Total loss': 0.32796173317700017}
2022-11-28 01:04:21,788 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:21,789 INFO:     Epoch: 34
2022-11-28 01:04:22,531 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4094043919308619, 'Total loss': 0.4094043919308619} | train loss {'Reaction outcome loss': 0.3310590124251891, 'Total loss': 0.3310590124251891}
2022-11-28 01:04:22,531 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:22,531 INFO:     Epoch: 35
2022-11-28 01:04:23,272 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.422020111232996, 'Total loss': 0.422020111232996} | train loss {'Reaction outcome loss': 0.3171079598519267, 'Total loss': 0.3171079598519267}
2022-11-28 01:04:23,272 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:23,272 INFO:     Epoch: 36
2022-11-28 01:04:24,012 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4146551036021926, 'Total loss': 0.4146551036021926} | train loss {'Reaction outcome loss': 0.3265410904677547, 'Total loss': 0.3265410904677547}
2022-11-28 01:04:24,012 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:24,013 INFO:     Epoch: 37
2022-11-28 01:04:24,751 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40654949708418414, 'Total loss': 0.40654949708418414} | train loss {'Reaction outcome loss': 0.3261643211148223, 'Total loss': 0.3261643211148223}
2022-11-28 01:04:24,751 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:24,751 INFO:     Epoch: 38
2022-11-28 01:04:25,493 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3948252566836097, 'Total loss': 0.3948252566836097} | train loss {'Reaction outcome loss': 0.33108493901637137, 'Total loss': 0.33108493901637137}
2022-11-28 01:04:25,493 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:25,493 INFO:     Epoch: 39
2022-11-28 01:04:26,234 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42940885692157527, 'Total loss': 0.42940885692157527} | train loss {'Reaction outcome loss': 0.32311435208028677, 'Total loss': 0.32311435208028677}
2022-11-28 01:04:26,234 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:26,234 INFO:     Epoch: 40
2022-11-28 01:04:26,971 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44607028873129323, 'Total loss': 0.44607028873129323} | train loss {'Reaction outcome loss': 0.32578571630375724, 'Total loss': 0.32578571630375724}
2022-11-28 01:04:26,972 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:26,972 INFO:     Epoch: 41
2022-11-28 01:04:27,714 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.37930811738426035, 'Total loss': 0.37930811738426035} | train loss {'Reaction outcome loss': 0.3134292800511633, 'Total loss': 0.3134292800511633}
2022-11-28 01:04:27,715 INFO:     Found new best model at epoch 41
2022-11-28 01:04:27,715 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:27,715 INFO:     Epoch: 42
2022-11-28 01:04:28,456 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45824652232907037, 'Total loss': 0.45824652232907037} | train loss {'Reaction outcome loss': 0.31758889321769984, 'Total loss': 0.31758889321769984}
2022-11-28 01:04:28,456 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:28,456 INFO:     Epoch: 43
2022-11-28 01:04:29,199 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42689684143459256, 'Total loss': 0.42689684143459256} | train loss {'Reaction outcome loss': 0.33328820248039404, 'Total loss': 0.33328820248039404}
2022-11-28 01:04:29,199 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:29,199 INFO:     Epoch: 44
2022-11-28 01:04:29,936 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.402675505050204, 'Total loss': 0.402675505050204} | train loss {'Reaction outcome loss': 0.3195888289687585, 'Total loss': 0.3195888289687585}
2022-11-28 01:04:29,936 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:29,937 INFO:     Epoch: 45
2022-11-28 01:04:30,675 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40773877112025564, 'Total loss': 0.40773877112025564} | train loss {'Reaction outcome loss': 0.3274995115642645, 'Total loss': 0.3274995115642645}
2022-11-28 01:04:30,675 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:30,675 INFO:     Epoch: 46
2022-11-28 01:04:31,417 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.37476743368262594, 'Total loss': 0.37476743368262594} | train loss {'Reaction outcome loss': 0.3195933074671395, 'Total loss': 0.3195933074671395}
2022-11-28 01:04:31,417 INFO:     Found new best model at epoch 46
2022-11-28 01:04:31,418 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:31,418 INFO:     Epoch: 47
2022-11-28 01:04:32,158 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42401311004703696, 'Total loss': 0.42401311004703696} | train loss {'Reaction outcome loss': 0.3120428988215875, 'Total loss': 0.3120428988215875}
2022-11-28 01:04:32,158 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:32,158 INFO:     Epoch: 48
2022-11-28 01:04:32,902 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40438033403320744, 'Total loss': 0.40438033403320744} | train loss {'Reaction outcome loss': 0.3151624736737232, 'Total loss': 0.3151624736737232}
2022-11-28 01:04:32,902 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:32,902 INFO:     Epoch: 49
2022-11-28 01:04:33,640 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40984672782095993, 'Total loss': 0.40984672782095993} | train loss {'Reaction outcome loss': 0.31916719100305013, 'Total loss': 0.31916719100305013}
2022-11-28 01:04:33,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:33,640 INFO:     Epoch: 50
2022-11-28 01:04:34,379 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4004088669846004, 'Total loss': 0.4004088669846004} | train loss {'Reaction outcome loss': 0.31540506895707576, 'Total loss': 0.31540506895707576}
2022-11-28 01:04:34,380 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:34,380 INFO:     Epoch: 51
2022-11-28 01:04:35,124 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41633103212172334, 'Total loss': 0.41633103212172334} | train loss {'Reaction outcome loss': 0.3113853444326289, 'Total loss': 0.3113853444326289}
2022-11-28 01:04:35,124 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:35,125 INFO:     Epoch: 52
2022-11-28 01:04:35,867 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4499226219274781, 'Total loss': 0.4499226219274781} | train loss {'Reaction outcome loss': 0.3212904483688121, 'Total loss': 0.3212904483688121}
2022-11-28 01:04:35,867 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:35,867 INFO:     Epoch: 53
2022-11-28 01:04:36,610 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39899149198423733, 'Total loss': 0.39899149198423733} | train loss {'Reaction outcome loss': 0.31966971402265587, 'Total loss': 0.31966971402265587}
2022-11-28 01:04:36,610 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:36,611 INFO:     Epoch: 54
2022-11-28 01:04:37,353 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4209702028469606, 'Total loss': 0.4209702028469606} | train loss {'Reaction outcome loss': 0.3167184139696919, 'Total loss': 0.3167184139696919}
2022-11-28 01:04:37,353 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:37,353 INFO:     Epoch: 55
2022-11-28 01:04:38,094 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41699218682267447, 'Total loss': 0.41699218682267447} | train loss {'Reaction outcome loss': 0.3101930178549825, 'Total loss': 0.3101930178549825}
2022-11-28 01:04:38,094 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:38,094 INFO:     Epoch: 56
2022-11-28 01:04:38,834 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4329426054927436, 'Total loss': 0.4329426054927436} | train loss {'Reaction outcome loss': 0.31748581733934733, 'Total loss': 0.31748581733934733}
2022-11-28 01:04:38,834 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:38,834 INFO:     Epoch: 57
2022-11-28 01:04:39,572 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4270820573649623, 'Total loss': 0.4270820573649623} | train loss {'Reaction outcome loss': 0.32239244023756103, 'Total loss': 0.32239244023756103}
2022-11-28 01:04:39,572 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:39,572 INFO:     Epoch: 58
2022-11-28 01:04:40,317 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39504359442402015, 'Total loss': 0.39504359442402015} | train loss {'Reaction outcome loss': 0.3102573645358183, 'Total loss': 0.3102573645358183}
2022-11-28 01:04:40,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:40,317 INFO:     Epoch: 59
2022-11-28 01:04:41,057 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41981320387937804, 'Total loss': 0.41981320387937804} | train loss {'Reaction outcome loss': 0.3115022576889213, 'Total loss': 0.3115022576889213}
2022-11-28 01:04:41,058 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:41,058 INFO:     Epoch: 60
2022-11-28 01:04:41,805 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40321756611493503, 'Total loss': 0.40321756611493503} | train loss {'Reaction outcome loss': 0.3081704807676831, 'Total loss': 0.3081704807676831}
2022-11-28 01:04:41,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:41,805 INFO:     Epoch: 61
2022-11-28 01:04:42,546 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4229985993694175, 'Total loss': 0.4229985993694175} | train loss {'Reaction outcome loss': 0.308381811301319, 'Total loss': 0.308381811301319}
2022-11-28 01:04:42,546 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:42,547 INFO:     Epoch: 62
2022-11-28 01:04:43,284 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4037774062122811, 'Total loss': 0.4037774062122811} | train loss {'Reaction outcome loss': 0.31434643685209507, 'Total loss': 0.31434643685209507}
2022-11-28 01:04:43,284 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:43,285 INFO:     Epoch: 63
2022-11-28 01:04:44,024 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48279639265754004, 'Total loss': 0.48279639265754004} | train loss {'Reaction outcome loss': 0.31748145613439227, 'Total loss': 0.31748145613439227}
2022-11-28 01:04:44,024 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:44,024 INFO:     Epoch: 64
2022-11-28 01:04:44,766 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3802646913311698, 'Total loss': 0.3802646913311698} | train loss {'Reaction outcome loss': 0.3101486054914338, 'Total loss': 0.3101486054914338}
2022-11-28 01:04:44,766 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:44,766 INFO:     Epoch: 65
2022-11-28 01:04:45,507 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41964542205360805, 'Total loss': 0.41964542205360805} | train loss {'Reaction outcome loss': 0.3083004273626269, 'Total loss': 0.3083004273626269}
2022-11-28 01:04:45,507 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:45,507 INFO:     Epoch: 66
2022-11-28 01:04:46,247 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4272379594093019, 'Total loss': 0.4272379594093019} | train loss {'Reaction outcome loss': 0.32556175662546744, 'Total loss': 0.32556175662546744}
2022-11-28 01:04:46,248 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:46,248 INFO:     Epoch: 67
2022-11-28 01:04:46,986 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4113424833525311, 'Total loss': 0.4113424833525311} | train loss {'Reaction outcome loss': 0.32266064532557315, 'Total loss': 0.32266064532557315}
2022-11-28 01:04:46,986 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:46,986 INFO:     Epoch: 68
2022-11-28 01:04:47,733 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4131280163472349, 'Total loss': 0.4131280163472349} | train loss {'Reaction outcome loss': 0.3205132493559195, 'Total loss': 0.3205132493559195}
2022-11-28 01:04:47,733 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:47,733 INFO:     Epoch: 69
2022-11-28 01:04:48,474 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4302621722560037, 'Total loss': 0.4302621722560037} | train loss {'Reaction outcome loss': 0.31291765996388027, 'Total loss': 0.31291765996388027}
2022-11-28 01:04:48,474 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:48,474 INFO:     Epoch: 70
2022-11-28 01:04:49,221 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42398799549449573, 'Total loss': 0.42398799549449573} | train loss {'Reaction outcome loss': 0.3120176070578852, 'Total loss': 0.3120176070578852}
2022-11-28 01:04:49,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:49,221 INFO:     Epoch: 71
2022-11-28 01:04:49,963 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4457928890531713, 'Total loss': 0.4457928890531713} | train loss {'Reaction outcome loss': 0.3074266422463923, 'Total loss': 0.3074266422463923}
2022-11-28 01:04:49,963 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:49,963 INFO:     Epoch: 72
2022-11-28 01:04:50,704 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4503392868421294, 'Total loss': 0.4503392868421294} | train loss {'Reaction outcome loss': 0.3080732464486239, 'Total loss': 0.3080732464486239}
2022-11-28 01:04:50,704 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:50,704 INFO:     Epoch: 73
2022-11-28 01:04:51,445 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39678357710892503, 'Total loss': 0.39678357710892503} | train loss {'Reaction outcome loss': 0.31357065965326464, 'Total loss': 0.31357065965326464}
2022-11-28 01:04:51,445 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:51,445 INFO:     Epoch: 74
2022-11-28 01:04:52,186 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39479644867506897, 'Total loss': 0.39479644867506897} | train loss {'Reaction outcome loss': 0.31445650905370715, 'Total loss': 0.31445650905370715}
2022-11-28 01:04:52,186 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:52,186 INFO:     Epoch: 75
2022-11-28 01:04:52,928 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40732091004875576, 'Total loss': 0.40732091004875576} | train loss {'Reaction outcome loss': 0.3130173880226758, 'Total loss': 0.3130173880226758}
2022-11-28 01:04:52,929 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:52,929 INFO:     Epoch: 76
2022-11-28 01:04:53,668 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39638136191801593, 'Total loss': 0.39638136191801593} | train loss {'Reaction outcome loss': 0.3062861323204576, 'Total loss': 0.3062861323204576}
2022-11-28 01:04:53,668 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:53,669 INFO:     Epoch: 77
2022-11-28 01:04:54,410 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42137622426856647, 'Total loss': 0.42137622426856647} | train loss {'Reaction outcome loss': 0.31406967127505614, 'Total loss': 0.31406967127505614}
2022-11-28 01:04:54,411 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:54,411 INFO:     Epoch: 78
2022-11-28 01:04:55,153 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3876112514937466, 'Total loss': 0.3876112514937466} | train loss {'Reaction outcome loss': 0.305398696919485, 'Total loss': 0.305398696919485}
2022-11-28 01:04:55,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:55,153 INFO:     Epoch: 79
2022-11-28 01:04:55,895 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3983611837029457, 'Total loss': 0.3983611837029457} | train loss {'Reaction outcome loss': 0.3173940217920712, 'Total loss': 0.3173940217920712}
2022-11-28 01:04:55,895 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:55,895 INFO:     Epoch: 80
2022-11-28 01:04:56,634 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4222652465105057, 'Total loss': 0.4222652465105057} | train loss {'Reaction outcome loss': 0.3195017051331851, 'Total loss': 0.3195017051331851}
2022-11-28 01:04:56,634 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:56,634 INFO:     Epoch: 81
2022-11-28 01:04:57,379 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3881527175280181, 'Total loss': 0.3881527175280181} | train loss {'Reaction outcome loss': 0.30969489443362974, 'Total loss': 0.30969489443362974}
2022-11-28 01:04:57,379 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:57,379 INFO:     Epoch: 82
2022-11-28 01:04:58,120 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42437996122647414, 'Total loss': 0.42437996122647414} | train loss {'Reaction outcome loss': 0.3095886838679411, 'Total loss': 0.3095886838679411}
2022-11-28 01:04:58,120 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:58,120 INFO:     Epoch: 83
2022-11-28 01:04:58,860 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4117111208933321, 'Total loss': 0.4117111208933321} | train loss {'Reaction outcome loss': 0.3086381820695741, 'Total loss': 0.3086381820695741}
2022-11-28 01:04:58,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:58,860 INFO:     Epoch: 84
2022-11-28 01:04:59,602 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4269581433724273, 'Total loss': 0.4269581433724273} | train loss {'Reaction outcome loss': 0.3077111854693111, 'Total loss': 0.3077111854693111}
2022-11-28 01:04:59,602 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:04:59,602 INFO:     Epoch: 85
2022-11-28 01:05:00,343 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45154568485238333, 'Total loss': 0.45154568485238333} | train loss {'Reaction outcome loss': 0.32324657522293987, 'Total loss': 0.32324657522293987}
2022-11-28 01:05:00,343 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:00,343 INFO:     Epoch: 86
2022-11-28 01:05:01,079 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3894531742076982, 'Total loss': 0.3894531742076982} | train loss {'Reaction outcome loss': 0.3107978416644797, 'Total loss': 0.3107978416644797}
2022-11-28 01:05:01,079 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:01,079 INFO:     Epoch: 87
2022-11-28 01:05:01,817 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4201620004393838, 'Total loss': 0.4201620004393838} | train loss {'Reaction outcome loss': 0.3090321823650477, 'Total loss': 0.3090321823650477}
2022-11-28 01:05:01,817 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:01,817 INFO:     Epoch: 88
2022-11-28 01:05:02,558 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41083715263415466, 'Total loss': 0.41083715263415466} | train loss {'Reaction outcome loss': 0.3168101409868318, 'Total loss': 0.3168101409868318}
2022-11-28 01:05:02,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:02,558 INFO:     Epoch: 89
2022-11-28 01:05:03,298 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4481008140878244, 'Total loss': 0.4481008140878244} | train loss {'Reaction outcome loss': 0.3097571291181506, 'Total loss': 0.3097571291181506}
2022-11-28 01:05:03,298 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:03,298 INFO:     Epoch: 90
2022-11-28 01:05:04,039 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44168591871857643, 'Total loss': 0.44168591871857643} | train loss {'Reaction outcome loss': 0.3056734171753027, 'Total loss': 0.3056734171753027}
2022-11-28 01:05:04,039 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:04,039 INFO:     Epoch: 91
2022-11-28 01:05:04,784 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4476297494362701, 'Total loss': 0.4476297494362701} | train loss {'Reaction outcome loss': 0.31283384304569695, 'Total loss': 0.31283384304569695}
2022-11-28 01:05:04,784 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:04,784 INFO:     Epoch: 92
2022-11-28 01:05:05,524 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39992999437857757, 'Total loss': 0.39992999437857757} | train loss {'Reaction outcome loss': 0.31990864378761275, 'Total loss': 0.31990864378761275}
2022-11-28 01:05:05,525 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:05,525 INFO:     Epoch: 93
2022-11-28 01:05:06,270 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.423590000718832, 'Total loss': 0.423590000718832} | train loss {'Reaction outcome loss': 0.3061648288551642, 'Total loss': 0.3061648288551642}
2022-11-28 01:05:06,270 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:06,270 INFO:     Epoch: 94
2022-11-28 01:05:07,011 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3950847666710615, 'Total loss': 0.3950847666710615} | train loss {'Reaction outcome loss': 0.30944516123557575, 'Total loss': 0.30944516123557575}
2022-11-28 01:05:07,011 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:07,011 INFO:     Epoch: 95
2022-11-28 01:05:07,749 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41979731009765103, 'Total loss': 0.41979731009765103} | train loss {'Reaction outcome loss': 0.30175862488697985, 'Total loss': 0.30175862488697985}
2022-11-28 01:05:07,750 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:07,750 INFO:     Epoch: 96
2022-11-28 01:05:08,489 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4206934489987113, 'Total loss': 0.4206934489987113} | train loss {'Reaction outcome loss': 0.3072670994820643, 'Total loss': 0.3072670994820643}
2022-11-28 01:05:08,489 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:08,489 INFO:     Epoch: 97
2022-11-28 01:05:09,229 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41891259293664584, 'Total loss': 0.41891259293664584} | train loss {'Reaction outcome loss': 0.31467306130394646, 'Total loss': 0.31467306130394646}
2022-11-28 01:05:09,229 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:09,229 INFO:     Epoch: 98
2022-11-28 01:05:09,971 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42021795006638224, 'Total loss': 0.42021795006638224} | train loss {'Reaction outcome loss': 0.3171278514728254, 'Total loss': 0.3171278514728254}
2022-11-28 01:05:09,971 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:09,972 INFO:     Epoch: 99
2022-11-28 01:05:10,716 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4525621844963594, 'Total loss': 0.4525621844963594} | train loss {'Reaction outcome loss': 0.3070926681769138, 'Total loss': 0.3070926681769138}
2022-11-28 01:05:10,716 INFO:     Best model found after epoch 47 of 100.
2022-11-28 01:05:10,716 INFO:   Done with stage: TRAINING
2022-11-28 01:05:10,716 INFO:   Starting stage: EVALUATION
2022-11-28 01:05:10,841 INFO:   Done with stage: EVALUATION
2022-11-28 01:05:10,842 INFO:   Leaving out SEQ value Fold_1
2022-11-28 01:05:10,854 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-28 01:05:10,854 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:05:11,487 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:05:11,487 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:05:11,557 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:05:11,557 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:05:11,557 INFO:     No hyperparam tuning for this model
2022-11-28 01:05:11,557 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:05:11,557 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:05:11,558 INFO:     None feature selector for col prot
2022-11-28 01:05:11,558 INFO:     None feature selector for col prot
2022-11-28 01:05:11,558 INFO:     None feature selector for col prot
2022-11-28 01:05:11,559 INFO:     None feature selector for col chem
2022-11-28 01:05:11,559 INFO:     None feature selector for col chem
2022-11-28 01:05:11,559 INFO:     None feature selector for col chem
2022-11-28 01:05:11,559 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:05:11,559 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:05:11,561 INFO:     Number of params in model 169741
2022-11-28 01:05:11,564 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:05:11,564 INFO:   Starting stage: TRAINING
2022-11-28 01:05:11,616 INFO:     Val loss before train {'Reaction outcome loss': 1.0068574048752008, 'Total loss': 1.0068574048752008}
2022-11-28 01:05:11,616 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:11,616 INFO:     Epoch: 0
2022-11-28 01:05:12,350 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5409681554450545, 'Total loss': 0.5409681554450545} | train loss {'Reaction outcome loss': 0.6401007106152091, 'Total loss': 0.6401007106152091}
2022-11-28 01:05:12,350 INFO:     Found new best model at epoch 0
2022-11-28 01:05:12,351 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:12,351 INFO:     Epoch: 1
2022-11-28 01:05:13,082 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5119579285383224, 'Total loss': 0.5119579285383224} | train loss {'Reaction outcome loss': 0.5071911955321277, 'Total loss': 0.5071911955321277}
2022-11-28 01:05:13,082 INFO:     Found new best model at epoch 1
2022-11-28 01:05:13,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:13,083 INFO:     Epoch: 2
2022-11-28 01:05:13,814 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5019836519346681, 'Total loss': 0.5019836519346681} | train loss {'Reaction outcome loss': 0.45750080134888244, 'Total loss': 0.45750080134888244}
2022-11-28 01:05:13,815 INFO:     Found new best model at epoch 2
2022-11-28 01:05:13,815 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:13,815 INFO:     Epoch: 3
2022-11-28 01:05:14,550 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4661973818790081, 'Total loss': 0.4661973818790081} | train loss {'Reaction outcome loss': 0.431220821392389, 'Total loss': 0.431220821392389}
2022-11-28 01:05:14,551 INFO:     Found new best model at epoch 3
2022-11-28 01:05:14,551 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:14,551 INFO:     Epoch: 4
2022-11-28 01:05:15,287 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4647997014744337, 'Total loss': 0.4647997014744337} | train loss {'Reaction outcome loss': 0.41854890402207157, 'Total loss': 0.41854890402207157}
2022-11-28 01:05:15,287 INFO:     Found new best model at epoch 4
2022-11-28 01:05:15,288 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:15,288 INFO:     Epoch: 5
2022-11-28 01:05:16,022 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4643540912589362, 'Total loss': 0.4643540912589362} | train loss {'Reaction outcome loss': 0.40281921919481256, 'Total loss': 0.40281921919481256}
2022-11-28 01:05:16,022 INFO:     Found new best model at epoch 5
2022-11-28 01:05:16,023 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:16,023 INFO:     Epoch: 6
2022-11-28 01:05:16,761 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44834046654923015, 'Total loss': 0.44834046654923015} | train loss {'Reaction outcome loss': 0.39087695180756565, 'Total loss': 0.39087695180756565}
2022-11-28 01:05:16,761 INFO:     Found new best model at epoch 6
2022-11-28 01:05:16,761 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:16,762 INFO:     Epoch: 7
2022-11-28 01:05:17,498 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45788815686869067, 'Total loss': 0.45788815686869067} | train loss {'Reaction outcome loss': 0.3862829916025876, 'Total loss': 0.3862829916025876}
2022-11-28 01:05:17,499 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:17,499 INFO:     Epoch: 8
2022-11-28 01:05:18,230 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45395744539970573, 'Total loss': 0.45395744539970573} | train loss {'Reaction outcome loss': 0.3809389316250758, 'Total loss': 0.3809389316250758}
2022-11-28 01:05:18,231 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:18,231 INFO:     Epoch: 9
2022-11-28 01:05:18,965 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47162676793198255, 'Total loss': 0.47162676793198255} | train loss {'Reaction outcome loss': 0.38092732426438314, 'Total loss': 0.38092732426438314}
2022-11-28 01:05:18,965 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:18,965 INFO:     Epoch: 10
2022-11-28 01:05:19,697 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47570276572260745, 'Total loss': 0.47570276572260745} | train loss {'Reaction outcome loss': 0.3729379208367548, 'Total loss': 0.3729379208367548}
2022-11-28 01:05:19,698 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:19,698 INFO:     Epoch: 11
2022-11-28 01:05:20,427 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4598677116771077, 'Total loss': 0.4598677116771077} | train loss {'Reaction outcome loss': 0.3648822211311678, 'Total loss': 0.3648822211311678}
2022-11-28 01:05:20,427 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:20,428 INFO:     Epoch: 12
2022-11-28 01:05:21,162 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4813750375841939, 'Total loss': 0.4813750375841939} | train loss {'Reaction outcome loss': 0.35845583045678864, 'Total loss': 0.35845583045678864}
2022-11-28 01:05:21,162 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:21,162 INFO:     Epoch: 13
2022-11-28 01:05:21,897 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42103426851505454, 'Total loss': 0.42103426851505454} | train loss {'Reaction outcome loss': 0.36009960793296003, 'Total loss': 0.36009960793296003}
2022-11-28 01:05:21,897 INFO:     Found new best model at epoch 13
2022-11-28 01:05:21,898 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:21,898 INFO:     Epoch: 14
2022-11-28 01:05:22,630 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45127303932988366, 'Total loss': 0.45127303932988366} | train loss {'Reaction outcome loss': 0.3464188857211007, 'Total loss': 0.3464188857211007}
2022-11-28 01:05:22,630 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:22,630 INFO:     Epoch: 15
2022-11-28 01:05:23,361 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4350181766027628, 'Total loss': 0.4350181766027628} | train loss {'Reaction outcome loss': 0.35164496385388905, 'Total loss': 0.35164496385388905}
2022-11-28 01:05:23,361 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:23,362 INFO:     Epoch: 16
2022-11-28 01:05:24,094 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4504311999609304, 'Total loss': 0.4504311999609304} | train loss {'Reaction outcome loss': 0.34966789189066905, 'Total loss': 0.34966789189066905}
2022-11-28 01:05:24,095 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:24,095 INFO:     Epoch: 17
2022-11-28 01:05:24,830 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42826378137566323, 'Total loss': 0.42826378137566323} | train loss {'Reaction outcome loss': 0.3435888709538758, 'Total loss': 0.3435888709538758}
2022-11-28 01:05:24,830 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:24,830 INFO:     Epoch: 18
2022-11-28 01:05:25,561 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47112166500368785, 'Total loss': 0.47112166500368785} | train loss {'Reaction outcome loss': 0.3434540983212828, 'Total loss': 0.3434540983212828}
2022-11-28 01:05:25,561 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:25,561 INFO:     Epoch: 19
2022-11-28 01:05:26,288 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4221027659815411, 'Total loss': 0.4221027659815411} | train loss {'Reaction outcome loss': 0.33645033523624324, 'Total loss': 0.33645033523624324}
2022-11-28 01:05:26,288 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:26,289 INFO:     Epoch: 20
2022-11-28 01:05:27,024 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4477829091077627, 'Total loss': 0.4477829091077627} | train loss {'Reaction outcome loss': 0.33628649457737253, 'Total loss': 0.33628649457737253}
2022-11-28 01:05:27,024 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:27,025 INFO:     Epoch: 21
2022-11-28 01:05:27,761 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44358821559784023, 'Total loss': 0.44358821559784023} | train loss {'Reaction outcome loss': 0.3428726197822104, 'Total loss': 0.3428726197822104}
2022-11-28 01:05:27,762 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:27,762 INFO:     Epoch: 22
2022-11-28 01:05:28,493 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4034665457384531, 'Total loss': 0.4034665457384531} | train loss {'Reaction outcome loss': 0.33889566613322913, 'Total loss': 0.33889566613322913}
2022-11-28 01:05:28,493 INFO:     Found new best model at epoch 22
2022-11-28 01:05:28,494 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:28,494 INFO:     Epoch: 23
2022-11-28 01:05:29,223 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41886823641699417, 'Total loss': 0.41886823641699417} | train loss {'Reaction outcome loss': 0.3413123699372688, 'Total loss': 0.3413123699372688}
2022-11-28 01:05:29,223 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:29,223 INFO:     Epoch: 24
2022-11-28 01:05:29,954 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4182043827550356, 'Total loss': 0.4182043827550356} | train loss {'Reaction outcome loss': 0.3313909722453773, 'Total loss': 0.3313909722453773}
2022-11-28 01:05:29,954 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:29,954 INFO:     Epoch: 25
2022-11-28 01:05:30,685 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4375282953991446, 'Total loss': 0.4375282953991446} | train loss {'Reaction outcome loss': 0.3253486136074174, 'Total loss': 0.3253486136074174}
2022-11-28 01:05:30,685 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:30,685 INFO:     Epoch: 26
2022-11-28 01:05:31,416 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43993160475132076, 'Total loss': 0.43993160475132076} | train loss {'Reaction outcome loss': 0.3281410215077577, 'Total loss': 0.3281410215077577}
2022-11-28 01:05:31,416 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:31,416 INFO:     Epoch: 27
2022-11-28 01:05:32,145 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43302052138849745, 'Total loss': 0.43302052138849745} | train loss {'Reaction outcome loss': 0.32608832679535626, 'Total loss': 0.32608832679535626}
2022-11-28 01:05:32,145 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:32,145 INFO:     Epoch: 28
2022-11-28 01:05:32,874 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4252521655587263, 'Total loss': 0.4252521655587263} | train loss {'Reaction outcome loss': 0.32687057122404195, 'Total loss': 0.32687057122404195}
2022-11-28 01:05:32,874 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:32,875 INFO:     Epoch: 29
2022-11-28 01:05:33,599 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43208974149338036, 'Total loss': 0.43208974149338036} | train loss {'Reaction outcome loss': 0.32169762364140264, 'Total loss': 0.32169762364140264}
2022-11-28 01:05:33,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:33,600 INFO:     Epoch: 30
2022-11-28 01:05:34,328 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4144913304683774, 'Total loss': 0.4144913304683774} | train loss {'Reaction outcome loss': 0.3332046227751936, 'Total loss': 0.3332046227751936}
2022-11-28 01:05:34,328 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:34,328 INFO:     Epoch: 31
2022-11-28 01:05:35,060 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4136475376611532, 'Total loss': 0.4136475376611532} | train loss {'Reaction outcome loss': 0.31888030858810057, 'Total loss': 0.31888030858810057}
2022-11-28 01:05:35,060 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:35,060 INFO:     Epoch: 32
2022-11-28 01:05:35,791 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4321679902631183, 'Total loss': 0.4321679902631183} | train loss {'Reaction outcome loss': 0.3268297177283362, 'Total loss': 0.3268297177283362}
2022-11-28 01:05:35,791 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:35,791 INFO:     Epoch: 33
2022-11-28 01:05:36,524 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42585474044777627, 'Total loss': 0.42585474044777627} | train loss {'Reaction outcome loss': 0.31494429449976225, 'Total loss': 0.31494429449976225}
2022-11-28 01:05:36,525 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:36,525 INFO:     Epoch: 34
2022-11-28 01:05:37,255 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4283785435349442, 'Total loss': 0.4283785435349442} | train loss {'Reaction outcome loss': 0.31205404877907944, 'Total loss': 0.31205404877907944}
2022-11-28 01:05:37,255 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:37,255 INFO:     Epoch: 35
2022-11-28 01:05:37,987 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42489167190221855, 'Total loss': 0.42489167190221855} | train loss {'Reaction outcome loss': 0.3119570445192694, 'Total loss': 0.3119570445192694}
2022-11-28 01:05:37,987 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:37,987 INFO:     Epoch: 36
2022-11-28 01:05:38,717 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45022844020710434, 'Total loss': 0.45022844020710434} | train loss {'Reaction outcome loss': 0.3162930026773072, 'Total loss': 0.3162930026773072}
2022-11-28 01:05:38,717 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:38,718 INFO:     Epoch: 37
2022-11-28 01:05:39,446 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44197220684483995, 'Total loss': 0.44197220684483995} | train loss {'Reaction outcome loss': 0.3232282522774528, 'Total loss': 0.3232282522774528}
2022-11-28 01:05:39,446 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:39,446 INFO:     Epoch: 38
2022-11-28 01:05:40,176 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4214481624752976, 'Total loss': 0.4214481624752976} | train loss {'Reaction outcome loss': 0.31608325132617243, 'Total loss': 0.31608325132617243}
2022-11-28 01:05:40,176 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:40,176 INFO:     Epoch: 39
2022-11-28 01:05:40,913 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41659162592056187, 'Total loss': 0.41659162592056187} | train loss {'Reaction outcome loss': 0.3103046108328511, 'Total loss': 0.3103046108328511}
2022-11-28 01:05:40,913 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:40,913 INFO:     Epoch: 40
2022-11-28 01:05:41,644 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44498777909334314, 'Total loss': 0.44498777909334314} | train loss {'Reaction outcome loss': 0.31737868095376365, 'Total loss': 0.31737868095376365}
2022-11-28 01:05:41,644 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:41,645 INFO:     Epoch: 41
2022-11-28 01:05:42,377 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.436017561790555, 'Total loss': 0.436017561790555} | train loss {'Reaction outcome loss': 0.3175122512527454, 'Total loss': 0.3175122512527454}
2022-11-28 01:05:42,377 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:42,377 INFO:     Epoch: 42
2022-11-28 01:05:43,111 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4444042049175085, 'Total loss': 0.4444042049175085} | train loss {'Reaction outcome loss': 0.31263939006093105, 'Total loss': 0.31263939006093105}
2022-11-28 01:05:43,112 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:43,112 INFO:     Epoch: 43
2022-11-28 01:05:43,842 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43234814426233603, 'Total loss': 0.43234814426233603} | train loss {'Reaction outcome loss': 0.322287340284375, 'Total loss': 0.322287340284375}
2022-11-28 01:05:43,842 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:43,843 INFO:     Epoch: 44
2022-11-28 01:05:44,574 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43941339469233226, 'Total loss': 0.43941339469233226} | train loss {'Reaction outcome loss': 0.3227037502904978, 'Total loss': 0.3227037502904978}
2022-11-28 01:05:44,575 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:44,575 INFO:     Epoch: 45
2022-11-28 01:05:45,309 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41443136317092316, 'Total loss': 0.41443136317092316} | train loss {'Reaction outcome loss': 0.30798783236079746, 'Total loss': 0.30798783236079746}
2022-11-28 01:05:45,309 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:45,309 INFO:     Epoch: 46
2022-11-28 01:05:46,046 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4582562734221303, 'Total loss': 0.4582562734221303} | train loss {'Reaction outcome loss': 0.31042219793477666, 'Total loss': 0.31042219793477666}
2022-11-28 01:05:46,046 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:46,046 INFO:     Epoch: 47
2022-11-28 01:05:46,783 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4249149183201235, 'Total loss': 0.4249149183201235} | train loss {'Reaction outcome loss': 0.3138881320816009, 'Total loss': 0.3138881320816009}
2022-11-28 01:05:46,783 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:46,783 INFO:     Epoch: 48
2022-11-28 01:05:47,519 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4162431189487147, 'Total loss': 0.4162431189487147} | train loss {'Reaction outcome loss': 0.3108587184683286, 'Total loss': 0.3108587184683286}
2022-11-28 01:05:47,519 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:47,519 INFO:     Epoch: 49
2022-11-28 01:05:48,254 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4389991202326708, 'Total loss': 0.4389991202326708} | train loss {'Reaction outcome loss': 0.32433788374127676, 'Total loss': 0.32433788374127676}
2022-11-28 01:05:48,255 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:48,255 INFO:     Epoch: 50
2022-11-28 01:05:48,987 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3968142385399619, 'Total loss': 0.3968142385399619} | train loss {'Reaction outcome loss': 0.3067943958159337, 'Total loss': 0.3067943958159337}
2022-11-28 01:05:48,987 INFO:     Found new best model at epoch 50
2022-11-28 01:05:48,988 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:48,988 INFO:     Epoch: 51
2022-11-28 01:05:49,720 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4032898761851843, 'Total loss': 0.4032898761851843} | train loss {'Reaction outcome loss': 0.3041655454983927, 'Total loss': 0.3041655454983927}
2022-11-28 01:05:49,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:49,720 INFO:     Epoch: 52
2022-11-28 01:05:50,455 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4426505465147107, 'Total loss': 0.4426505465147107} | train loss {'Reaction outcome loss': 0.3083944584055202, 'Total loss': 0.3083944584055202}
2022-11-28 01:05:50,455 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:50,455 INFO:     Epoch: 53
2022-11-28 01:05:51,193 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4491288138683452, 'Total loss': 0.4491288138683452} | train loss {'Reaction outcome loss': 0.29994386845410115, 'Total loss': 0.29994386845410115}
2022-11-28 01:05:51,194 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:51,194 INFO:     Epoch: 54
2022-11-28 01:05:51,932 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4100180528191633, 'Total loss': 0.4100180528191633} | train loss {'Reaction outcome loss': 0.30509175953489764, 'Total loss': 0.30509175953489764}
2022-11-28 01:05:51,932 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:51,932 INFO:     Epoch: 55
2022-11-28 01:05:52,667 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4310323672239171, 'Total loss': 0.4310323672239171} | train loss {'Reaction outcome loss': 0.3053587363274009, 'Total loss': 0.3053587363274009}
2022-11-28 01:05:52,668 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:52,668 INFO:     Epoch: 56
2022-11-28 01:05:53,404 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4983240241228148, 'Total loss': 0.4983240241228148} | train loss {'Reaction outcome loss': 0.3046133219889162, 'Total loss': 0.3046133219889162}
2022-11-28 01:05:53,404 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:53,404 INFO:     Epoch: 57
2022-11-28 01:05:54,141 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41246191325575804, 'Total loss': 0.41246191325575804} | train loss {'Reaction outcome loss': 0.31584851259802593, 'Total loss': 0.31584851259802593}
2022-11-28 01:05:54,141 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:54,141 INFO:     Epoch: 58
2022-11-28 01:05:54,877 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4293955883314443, 'Total loss': 0.4293955883314443} | train loss {'Reaction outcome loss': 0.30597824900729176, 'Total loss': 0.30597824900729176}
2022-11-28 01:05:54,878 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:54,878 INFO:     Epoch: 59
2022-11-28 01:05:55,613 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41627333053322724, 'Total loss': 0.41627333053322724} | train loss {'Reaction outcome loss': 0.2886181889492788, 'Total loss': 0.2886181889492788}
2022-11-28 01:05:55,613 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:55,613 INFO:     Epoch: 60
2022-11-28 01:05:56,354 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45807515154051226, 'Total loss': 0.45807515154051226} | train loss {'Reaction outcome loss': 0.30463155244051676, 'Total loss': 0.30463155244051676}
2022-11-28 01:05:56,354 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:56,354 INFO:     Epoch: 61
2022-11-28 01:05:57,093 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43503331722215166, 'Total loss': 0.43503331722215166} | train loss {'Reaction outcome loss': 0.30147022704896614, 'Total loss': 0.30147022704896614}
2022-11-28 01:05:57,093 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:57,093 INFO:     Epoch: 62
2022-11-28 01:05:57,832 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43569020320509755, 'Total loss': 0.43569020320509755} | train loss {'Reaction outcome loss': 0.30090198457363704, 'Total loss': 0.30090198457363704}
2022-11-28 01:05:57,833 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:57,833 INFO:     Epoch: 63
2022-11-28 01:05:58,572 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42822987915471544, 'Total loss': 0.42822987915471544} | train loss {'Reaction outcome loss': 0.2995310672271399, 'Total loss': 0.2995310672271399}
2022-11-28 01:05:58,572 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:58,572 INFO:     Epoch: 64
2022-11-28 01:05:59,310 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4487921626761902, 'Total loss': 0.4487921626761902} | train loss {'Reaction outcome loss': 0.30646245097243247, 'Total loss': 0.30646245097243247}
2022-11-28 01:05:59,310 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:05:59,310 INFO:     Epoch: 65
2022-11-28 01:06:00,048 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42034781568272167, 'Total loss': 0.42034781568272167} | train loss {'Reaction outcome loss': 0.30231588293986067, 'Total loss': 0.30231588293986067}
2022-11-28 01:06:00,048 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:00,048 INFO:     Epoch: 66
2022-11-28 01:06:00,785 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4581253348394882, 'Total loss': 0.4581253348394882} | train loss {'Reaction outcome loss': 0.29927214368441957, 'Total loss': 0.29927214368441957}
2022-11-28 01:06:00,786 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:00,786 INFO:     Epoch: 67
2022-11-28 01:06:01,527 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4422782545172891, 'Total loss': 0.4422782545172891} | train loss {'Reaction outcome loss': 0.3077807201708786, 'Total loss': 0.3077807201708786}
2022-11-28 01:06:01,527 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:01,527 INFO:     Epoch: 68
2022-11-28 01:06:02,267 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.436669239990933, 'Total loss': 0.436669239990933} | train loss {'Reaction outcome loss': 0.2995364730679449, 'Total loss': 0.2995364730679449}
2022-11-28 01:06:02,267 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:02,267 INFO:     Epoch: 69
2022-11-28 01:06:03,011 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4463544221118439, 'Total loss': 0.4463544221118439} | train loss {'Reaction outcome loss': 0.2984364083335723, 'Total loss': 0.2984364083335723}
2022-11-28 01:06:03,011 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:03,011 INFO:     Epoch: 70
2022-11-28 01:06:03,755 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4484989847554717, 'Total loss': 0.4484989847554717} | train loss {'Reaction outcome loss': 0.2949571857849757, 'Total loss': 0.2949571857849757}
2022-11-28 01:06:03,755 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:03,755 INFO:     Epoch: 71
2022-11-28 01:06:04,499 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4364293775586195, 'Total loss': 0.4364293775586195} | train loss {'Reaction outcome loss': 0.2888185051978861, 'Total loss': 0.2888185051978861}
2022-11-28 01:06:04,499 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:04,499 INFO:     Epoch: 72
2022-11-28 01:06:05,240 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43325229301009066, 'Total loss': 0.43325229301009066} | train loss {'Reaction outcome loss': 0.30769842896809796, 'Total loss': 0.30769842896809796}
2022-11-28 01:06:05,240 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:05,240 INFO:     Epoch: 73
2022-11-28 01:06:05,984 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41626406790212145, 'Total loss': 0.41626406790212145} | train loss {'Reaction outcome loss': 0.29840611439550857, 'Total loss': 0.29840611439550857}
2022-11-28 01:06:05,984 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:05,984 INFO:     Epoch: 74
2022-11-28 01:06:06,724 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44814617827881215, 'Total loss': 0.44814617827881215} | train loss {'Reaction outcome loss': 0.30681310026856606, 'Total loss': 0.30681310026856606}
2022-11-28 01:06:06,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:06,724 INFO:     Epoch: 75
2022-11-28 01:06:07,462 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45431123517973476, 'Total loss': 0.45431123517973476} | train loss {'Reaction outcome loss': 0.29625880376075553, 'Total loss': 0.29625880376075553}
2022-11-28 01:06:07,462 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:07,463 INFO:     Epoch: 76
2022-11-28 01:06:08,203 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43303772460582646, 'Total loss': 0.43303772460582646} | train loss {'Reaction outcome loss': 0.3049815012287701, 'Total loss': 0.3049815012287701}
2022-11-28 01:06:08,203 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:08,203 INFO:     Epoch: 77
2022-11-28 01:06:08,943 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41288308244805005, 'Total loss': 0.41288308244805005} | train loss {'Reaction outcome loss': 0.29092226806000915, 'Total loss': 0.29092226806000915}
2022-11-28 01:06:08,943 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:08,943 INFO:     Epoch: 78
2022-11-28 01:06:09,682 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.448452147980069, 'Total loss': 0.448452147980069} | train loss {'Reaction outcome loss': 0.3038703550358491, 'Total loss': 0.3038703550358491}
2022-11-28 01:06:09,683 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:09,683 INFO:     Epoch: 79
2022-11-28 01:06:10,420 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48056067664955937, 'Total loss': 0.48056067664955937} | train loss {'Reaction outcome loss': 0.3009274637502898, 'Total loss': 0.3009274637502898}
2022-11-28 01:06:10,421 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:10,421 INFO:     Epoch: 80
2022-11-28 01:06:11,160 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43837941905786826, 'Total loss': 0.43837941905786826} | train loss {'Reaction outcome loss': 0.2929167902334727, 'Total loss': 0.2929167902334727}
2022-11-28 01:06:11,160 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:11,160 INFO:     Epoch: 81
2022-11-28 01:06:11,900 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4143237637919049, 'Total loss': 0.4143237637919049} | train loss {'Reaction outcome loss': 0.3025933545803337, 'Total loss': 0.3025933545803337}
2022-11-28 01:06:11,900 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:11,901 INFO:     Epoch: 82
2022-11-28 01:06:12,641 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.420984031156052, 'Total loss': 0.420984031156052} | train loss {'Reaction outcome loss': 0.3084671606804118, 'Total loss': 0.3084671606804118}
2022-11-28 01:06:12,641 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:12,641 INFO:     Epoch: 83
2022-11-28 01:06:13,382 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4086690392605094, 'Total loss': 0.4086690392605094} | train loss {'Reaction outcome loss': 0.29914765452406533, 'Total loss': 0.29914765452406533}
2022-11-28 01:06:13,382 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:13,383 INFO:     Epoch: 84
2022-11-28 01:06:14,122 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4123876326998999, 'Total loss': 0.4123876326998999} | train loss {'Reaction outcome loss': 0.2905973144212868, 'Total loss': 0.2905973144212868}
2022-11-28 01:06:14,122 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:14,122 INFO:     Epoch: 85
2022-11-28 01:06:14,868 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4178272482267646, 'Total loss': 0.4178272482267646} | train loss {'Reaction outcome loss': 0.30937904309588693, 'Total loss': 0.30937904309588693}
2022-11-28 01:06:14,868 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:14,868 INFO:     Epoch: 86
2022-11-28 01:06:15,609 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44281216000401696, 'Total loss': 0.44281216000401696} | train loss {'Reaction outcome loss': 0.295535237332921, 'Total loss': 0.295535237332921}
2022-11-28 01:06:15,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:15,609 INFO:     Epoch: 87
2022-11-28 01:06:16,344 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.468530103910801, 'Total loss': 0.468530103910801} | train loss {'Reaction outcome loss': 0.2933799469299277, 'Total loss': 0.2933799469299277}
2022-11-28 01:06:16,344 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:16,344 INFO:     Epoch: 88
2022-11-28 01:06:17,078 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4534814735484678, 'Total loss': 0.4534814735484678} | train loss {'Reaction outcome loss': 0.3038271422739382, 'Total loss': 0.3038271422739382}
2022-11-28 01:06:17,078 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:17,078 INFO:     Epoch: 89
2022-11-28 01:06:17,812 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41999625882437064, 'Total loss': 0.41999625882437064} | train loss {'Reaction outcome loss': 0.30132660548750756, 'Total loss': 0.30132660548750756}
2022-11-28 01:06:17,812 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:17,812 INFO:     Epoch: 90
2022-11-28 01:06:18,548 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4554969779280729, 'Total loss': 0.4554969779280729} | train loss {'Reaction outcome loss': 0.2955326515828631, 'Total loss': 0.2955326515828631}
2022-11-28 01:06:18,549 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:18,549 INFO:     Epoch: 91
2022-11-28 01:06:19,284 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45167015250339065, 'Total loss': 0.45167015250339065} | train loss {'Reaction outcome loss': 0.29073087363638017, 'Total loss': 0.29073087363638017}
2022-11-28 01:06:19,285 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:19,285 INFO:     Epoch: 92
2022-11-28 01:06:20,021 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43119469458280607, 'Total loss': 0.43119469458280607} | train loss {'Reaction outcome loss': 0.29446306656049603, 'Total loss': 0.29446306656049603}
2022-11-28 01:06:20,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:20,021 INFO:     Epoch: 93
2022-11-28 01:06:20,753 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44691447878992835, 'Total loss': 0.44691447878992835} | train loss {'Reaction outcome loss': 0.30150068805786806, 'Total loss': 0.30150068805786806}
2022-11-28 01:06:20,754 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:20,754 INFO:     Epoch: 94
2022-11-28 01:06:21,491 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42067584655312606, 'Total loss': 0.42067584655312606} | train loss {'Reaction outcome loss': 0.29433626607980257, 'Total loss': 0.29433626607980257}
2022-11-28 01:06:21,491 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:21,491 INFO:     Epoch: 95
2022-11-28 01:06:22,224 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42239685304636176, 'Total loss': 0.42239685304636176} | train loss {'Reaction outcome loss': 0.29801532022133775, 'Total loss': 0.29801532022133775}
2022-11-28 01:06:22,224 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:22,224 INFO:     Epoch: 96
2022-11-28 01:06:22,956 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.49854246059129403, 'Total loss': 0.49854246059129403} | train loss {'Reaction outcome loss': 0.3010263983850126, 'Total loss': 0.3010263983850126}
2022-11-28 01:06:22,956 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:22,956 INFO:     Epoch: 97
2022-11-28 01:06:23,689 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4356531743393388, 'Total loss': 0.4356531743393388} | train loss {'Reaction outcome loss': 0.2889718534156619, 'Total loss': 0.2889718534156619}
2022-11-28 01:06:23,689 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:23,689 INFO:     Epoch: 98
2022-11-28 01:06:24,423 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40592491314854734, 'Total loss': 0.40592491314854734} | train loss {'Reaction outcome loss': 0.30107897156734525, 'Total loss': 0.30107897156734525}
2022-11-28 01:06:24,423 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:24,423 INFO:     Epoch: 99
2022-11-28 01:06:25,156 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40553510085094807, 'Total loss': 0.40553510085094807} | train loss {'Reaction outcome loss': 0.2847713192334636, 'Total loss': 0.2847713192334636}
2022-11-28 01:06:25,156 INFO:     Best model found after epoch 51 of 100.
2022-11-28 01:06:25,157 INFO:   Done with stage: TRAINING
2022-11-28 01:06:25,157 INFO:   Starting stage: EVALUATION
2022-11-28 01:06:25,293 INFO:   Done with stage: EVALUATION
2022-11-28 01:06:25,294 INFO:   Leaving out SEQ value Fold_2
2022-11-28 01:06:25,307 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 01:06:25,307 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:06:25,951 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:06:25,951 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:06:26,021 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:06:26,021 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:06:26,021 INFO:     No hyperparam tuning for this model
2022-11-28 01:06:26,021 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:06:26,021 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:06:26,022 INFO:     None feature selector for col prot
2022-11-28 01:06:26,022 INFO:     None feature selector for col prot
2022-11-28 01:06:26,022 INFO:     None feature selector for col prot
2022-11-28 01:06:26,023 INFO:     None feature selector for col chem
2022-11-28 01:06:26,023 INFO:     None feature selector for col chem
2022-11-28 01:06:26,023 INFO:     None feature selector for col chem
2022-11-28 01:06:26,023 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:06:26,023 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:06:26,025 INFO:     Number of params in model 169741
2022-11-28 01:06:26,028 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:06:26,028 INFO:   Starting stage: TRAINING
2022-11-28 01:06:26,082 INFO:     Val loss before train {'Reaction outcome loss': 0.9716582508249716, 'Total loss': 0.9716582508249716}
2022-11-28 01:06:26,082 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:26,082 INFO:     Epoch: 0
2022-11-28 01:06:26,828 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5364668443799019, 'Total loss': 0.5364668443799019} | train loss {'Reaction outcome loss': 0.6225864777137876, 'Total loss': 0.6225864777137876}
2022-11-28 01:06:26,828 INFO:     Found new best model at epoch 0
2022-11-28 01:06:26,829 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:26,829 INFO:     Epoch: 1
2022-11-28 01:06:27,572 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4717955673960122, 'Total loss': 0.4717955673960122} | train loss {'Reaction outcome loss': 0.4949137316601962, 'Total loss': 0.4949137316601962}
2022-11-28 01:06:27,572 INFO:     Found new best model at epoch 1
2022-11-28 01:06:27,573 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:27,573 INFO:     Epoch: 2
2022-11-28 01:06:28,320 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4544389234347777, 'Total loss': 0.4544389234347777} | train loss {'Reaction outcome loss': 0.4510382978238075, 'Total loss': 0.4510382978238075}
2022-11-28 01:06:28,320 INFO:     Found new best model at epoch 2
2022-11-28 01:06:28,320 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:28,321 INFO:     Epoch: 3
2022-11-28 01:06:29,064 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4706661558964036, 'Total loss': 0.4706661558964036} | train loss {'Reaction outcome loss': 0.42691402547513907, 'Total loss': 0.42691402547513907}
2022-11-28 01:06:29,064 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:29,064 INFO:     Epoch: 4
2022-11-28 01:06:29,807 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47078557685017586, 'Total loss': 0.47078557685017586} | train loss {'Reaction outcome loss': 0.42044646124004836, 'Total loss': 0.42044646124004836}
2022-11-28 01:06:29,807 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:29,807 INFO:     Epoch: 5
2022-11-28 01:06:30,553 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48175792599266226, 'Total loss': 0.48175792599266226} | train loss {'Reaction outcome loss': 0.4153230296455414, 'Total loss': 0.4153230296455414}
2022-11-28 01:06:30,553 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:30,553 INFO:     Epoch: 6
2022-11-28 01:06:31,296 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4415470199151473, 'Total loss': 0.4415470199151473} | train loss {'Reaction outcome loss': 0.39248333453589124, 'Total loss': 0.39248333453589124}
2022-11-28 01:06:31,296 INFO:     Found new best model at epoch 6
2022-11-28 01:06:31,297 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:31,297 INFO:     Epoch: 7
2022-11-28 01:06:32,043 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.422304353761402, 'Total loss': 0.422304353761402} | train loss {'Reaction outcome loss': 0.3907128351661358, 'Total loss': 0.3907128351661358}
2022-11-28 01:06:32,043 INFO:     Found new best model at epoch 7
2022-11-28 01:06:32,044 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:32,044 INFO:     Epoch: 8
2022-11-28 01:06:32,787 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43136500668796623, 'Total loss': 0.43136500668796623} | train loss {'Reaction outcome loss': 0.3850373318682798, 'Total loss': 0.3850373318682798}
2022-11-28 01:06:32,787 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:32,787 INFO:     Epoch: 9
2022-11-28 01:06:33,530 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.395367608320984, 'Total loss': 0.395367608320984} | train loss {'Reaction outcome loss': 0.3839168287662842, 'Total loss': 0.3839168287662842}
2022-11-28 01:06:33,531 INFO:     Found new best model at epoch 9
2022-11-28 01:06:33,531 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:33,531 INFO:     Epoch: 10
2022-11-28 01:06:34,276 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42698904330080206, 'Total loss': 0.42698904330080206} | train loss {'Reaction outcome loss': 0.40005297301834836, 'Total loss': 0.40005297301834836}
2022-11-28 01:06:34,276 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:34,276 INFO:     Epoch: 11
2022-11-28 01:06:35,021 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4215595539320599, 'Total loss': 0.4215595539320599} | train loss {'Reaction outcome loss': 0.3657704386747016, 'Total loss': 0.3657704386747016}
2022-11-28 01:06:35,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:35,021 INFO:     Epoch: 12
2022-11-28 01:06:35,766 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43472993052141234, 'Total loss': 0.43472993052141234} | train loss {'Reaction outcome loss': 0.36583880956477, 'Total loss': 0.36583880956477}
2022-11-28 01:06:35,766 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:35,766 INFO:     Epoch: 13
2022-11-28 01:06:36,510 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4393989633430134, 'Total loss': 0.4393989633430134} | train loss {'Reaction outcome loss': 0.3654886191552467, 'Total loss': 0.3654886191552467}
2022-11-28 01:06:36,511 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:36,511 INFO:     Epoch: 14
2022-11-28 01:06:37,255 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4238039031624794, 'Total loss': 0.4238039031624794} | train loss {'Reaction outcome loss': 0.36244261153193136, 'Total loss': 0.36244261153193136}
2022-11-28 01:06:37,256 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:37,256 INFO:     Epoch: 15
2022-11-28 01:06:38,001 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41723996874960984, 'Total loss': 0.41723996874960984} | train loss {'Reaction outcome loss': 0.35874675292717784, 'Total loss': 0.35874675292717784}
2022-11-28 01:06:38,002 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:38,002 INFO:     Epoch: 16
2022-11-28 01:06:38,745 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4112240585752509, 'Total loss': 0.4112240585752509} | train loss {'Reaction outcome loss': 0.361128416862565, 'Total loss': 0.361128416862565}
2022-11-28 01:06:38,746 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:38,746 INFO:     Epoch: 17
2022-11-28 01:06:39,489 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4225511615249244, 'Total loss': 0.4225511615249244} | train loss {'Reaction outcome loss': 0.3519512890623166, 'Total loss': 0.3519512890623166}
2022-11-28 01:06:39,490 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:39,490 INFO:     Epoch: 18
2022-11-28 01:06:40,237 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4098704900931228, 'Total loss': 0.4098704900931228} | train loss {'Reaction outcome loss': 0.360818665209773, 'Total loss': 0.360818665209773}
2022-11-28 01:06:40,237 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:40,237 INFO:     Epoch: 19
2022-11-28 01:06:40,978 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4438799897378141, 'Total loss': 0.4438799897378141} | train loss {'Reaction outcome loss': 0.3511209235741542, 'Total loss': 0.3511209235741542}
2022-11-28 01:06:40,978 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:40,978 INFO:     Epoch: 20
2022-11-28 01:06:41,717 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40459383448416536, 'Total loss': 0.40459383448416536} | train loss {'Reaction outcome loss': 0.35221143081965234, 'Total loss': 0.35221143081965234}
2022-11-28 01:06:41,718 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:41,718 INFO:     Epoch: 21
2022-11-28 01:06:42,462 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41969951580871234, 'Total loss': 0.41969951580871234} | train loss {'Reaction outcome loss': 0.3416312866908336, 'Total loss': 0.3416312866908336}
2022-11-28 01:06:42,462 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:42,462 INFO:     Epoch: 22
2022-11-28 01:06:43,212 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4139052126556635, 'Total loss': 0.4139052126556635} | train loss {'Reaction outcome loss': 0.35803542062187727, 'Total loss': 0.35803542062187727}
2022-11-28 01:06:43,212 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:43,212 INFO:     Epoch: 23
2022-11-28 01:06:43,956 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43142941661856393, 'Total loss': 0.43142941661856393} | train loss {'Reaction outcome loss': 0.3438965753248708, 'Total loss': 0.3438965753248708}
2022-11-28 01:06:43,956 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:43,956 INFO:     Epoch: 24
2022-11-28 01:06:44,700 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4140444416552782, 'Total loss': 0.4140444416552782} | train loss {'Reaction outcome loss': 0.336048400021999, 'Total loss': 0.336048400021999}
2022-11-28 01:06:44,700 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:44,700 INFO:     Epoch: 25
2022-11-28 01:06:45,444 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41503437743945554, 'Total loss': 0.41503437743945554} | train loss {'Reaction outcome loss': 0.3471561489317581, 'Total loss': 0.3471561489317581}
2022-11-28 01:06:45,445 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:45,445 INFO:     Epoch: 26
2022-11-28 01:06:46,190 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4012199735099619, 'Total loss': 0.4012199735099619} | train loss {'Reaction outcome loss': 0.3391096032854275, 'Total loss': 0.3391096032854275}
2022-11-28 01:06:46,190 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:46,190 INFO:     Epoch: 27
2022-11-28 01:06:46,934 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3966942210258408, 'Total loss': 0.3966942210258408} | train loss {'Reaction outcome loss': 0.3411853362613844, 'Total loss': 0.3411853362613844}
2022-11-28 01:06:46,934 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:46,934 INFO:     Epoch: 28
2022-11-28 01:06:47,676 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42228242280808365, 'Total loss': 0.42228242280808365} | train loss {'Reaction outcome loss': 0.3472271583944197, 'Total loss': 0.3472271583944197}
2022-11-28 01:06:47,676 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:47,677 INFO:     Epoch: 29
2022-11-28 01:06:48,422 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41625030304897914, 'Total loss': 0.41625030304897914} | train loss {'Reaction outcome loss': 0.3465300672819559, 'Total loss': 0.3465300672819559}
2022-11-28 01:06:48,422 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:48,422 INFO:     Epoch: 30
2022-11-28 01:06:49,167 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4064524065364491, 'Total loss': 0.4064524065364491} | train loss {'Reaction outcome loss': 0.3327635523942318, 'Total loss': 0.3327635523942318}
2022-11-28 01:06:49,167 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:49,167 INFO:     Epoch: 31
2022-11-28 01:06:49,912 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4098076308992776, 'Total loss': 0.4098076308992776} | train loss {'Reaction outcome loss': 0.3425427875670073, 'Total loss': 0.3425427875670073}
2022-11-28 01:06:49,913 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:49,913 INFO:     Epoch: 32
2022-11-28 01:06:50,658 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4032277464866638, 'Total loss': 0.4032277464866638} | train loss {'Reaction outcome loss': 0.3357849805219936, 'Total loss': 0.3357849805219936}
2022-11-28 01:06:50,659 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:50,659 INFO:     Epoch: 33
2022-11-28 01:06:51,396 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4150685522366654, 'Total loss': 0.4150685522366654} | train loss {'Reaction outcome loss': 0.3203630392790323, 'Total loss': 0.3203630392790323}
2022-11-28 01:06:51,396 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:51,396 INFO:     Epoch: 34
2022-11-28 01:06:52,136 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39838970689611003, 'Total loss': 0.39838970689611003} | train loss {'Reaction outcome loss': 0.34819430028378723, 'Total loss': 0.34819430028378723}
2022-11-28 01:06:52,136 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:52,136 INFO:     Epoch: 35
2022-11-28 01:06:52,876 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40743456747044215, 'Total loss': 0.40743456747044215} | train loss {'Reaction outcome loss': 0.3445869953586505, 'Total loss': 0.3445869953586505}
2022-11-28 01:06:52,876 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:52,876 INFO:     Epoch: 36
2022-11-28 01:06:53,612 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4117567396976731, 'Total loss': 0.4117567396976731} | train loss {'Reaction outcome loss': 0.3395899218857771, 'Total loss': 0.3395899218857771}
2022-11-28 01:06:53,612 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:53,613 INFO:     Epoch: 37
2022-11-28 01:06:54,347 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38812604411081836, 'Total loss': 0.38812604411081836} | train loss {'Reaction outcome loss': 0.3247675064506729, 'Total loss': 0.3247675064506729}
2022-11-28 01:06:54,347 INFO:     Found new best model at epoch 37
2022-11-28 01:06:54,348 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:54,348 INFO:     Epoch: 38
2022-11-28 01:06:55,088 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4358781576156616, 'Total loss': 0.4358781576156616} | train loss {'Reaction outcome loss': 0.32744133822348437, 'Total loss': 0.32744133822348437}
2022-11-28 01:06:55,088 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:55,088 INFO:     Epoch: 39
2022-11-28 01:06:55,825 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4070019738918001, 'Total loss': 0.4070019738918001} | train loss {'Reaction outcome loss': 0.3323493803349825, 'Total loss': 0.3323493803349825}
2022-11-28 01:06:55,825 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:55,825 INFO:     Epoch: 40
2022-11-28 01:06:56,565 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3962204097346826, 'Total loss': 0.3962204097346826} | train loss {'Reaction outcome loss': 0.33140669408657775, 'Total loss': 0.33140669408657775}
2022-11-28 01:06:56,565 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:56,565 INFO:     Epoch: 41
2022-11-28 01:06:57,306 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4083345014263283, 'Total loss': 0.4083345014263283} | train loss {'Reaction outcome loss': 0.34889458352087166, 'Total loss': 0.34889458352087166}
2022-11-28 01:06:57,307 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:57,307 INFO:     Epoch: 42
2022-11-28 01:06:58,046 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39137929931960325, 'Total loss': 0.39137929931960325} | train loss {'Reaction outcome loss': 0.3299055555269786, 'Total loss': 0.3299055555269786}
2022-11-28 01:06:58,046 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:58,046 INFO:     Epoch: 43
2022-11-28 01:06:58,787 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4195871315896511, 'Total loss': 0.4195871315896511} | train loss {'Reaction outcome loss': 0.3283747740293502, 'Total loss': 0.3283747740293502}
2022-11-28 01:06:58,787 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:58,787 INFO:     Epoch: 44
2022-11-28 01:06:59,527 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40321156585758383, 'Total loss': 0.40321156585758383} | train loss {'Reaction outcome loss': 0.32952609908604913, 'Total loss': 0.32952609908604913}
2022-11-28 01:06:59,527 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:06:59,527 INFO:     Epoch: 45
2022-11-28 01:07:00,268 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40456734055822546, 'Total loss': 0.40456734055822546} | train loss {'Reaction outcome loss': 0.3258476866642956, 'Total loss': 0.3258476866642956}
2022-11-28 01:07:00,268 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:00,268 INFO:     Epoch: 46
2022-11-28 01:07:01,009 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40524629029360687, 'Total loss': 0.40524629029360687} | train loss {'Reaction outcome loss': 0.35567012592124553, 'Total loss': 0.35567012592124553}
2022-11-28 01:07:01,009 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:01,009 INFO:     Epoch: 47
2022-11-28 01:07:01,749 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4250918122177774, 'Total loss': 0.4250918122177774} | train loss {'Reaction outcome loss': 0.324165477835939, 'Total loss': 0.324165477835939}
2022-11-28 01:07:01,750 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:01,750 INFO:     Epoch: 48
2022-11-28 01:07:02,491 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4291208443993872, 'Total loss': 0.4291208443993872} | train loss {'Reaction outcome loss': 0.3249928445106576, 'Total loss': 0.3249928445106576}
2022-11-28 01:07:02,491 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:02,491 INFO:     Epoch: 49
2022-11-28 01:07:03,238 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39296421815048566, 'Total loss': 0.39296421815048566} | train loss {'Reaction outcome loss': 0.32170612322777387, 'Total loss': 0.32170612322777387}
2022-11-28 01:07:03,238 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:03,238 INFO:     Epoch: 50
2022-11-28 01:07:03,980 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4312219689176841, 'Total loss': 0.4312219689176841} | train loss {'Reaction outcome loss': 0.31855028912968, 'Total loss': 0.31855028912968}
2022-11-28 01:07:03,980 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:03,980 INFO:     Epoch: 51
2022-11-28 01:07:04,722 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4084700469604947, 'Total loss': 0.4084700469604947} | train loss {'Reaction outcome loss': 0.3190574229427195, 'Total loss': 0.3190574229427195}
2022-11-28 01:07:04,722 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:04,722 INFO:     Epoch: 52
2022-11-28 01:07:05,465 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4175516939298673, 'Total loss': 0.4175516939298673} | train loss {'Reaction outcome loss': 0.3257963281065444, 'Total loss': 0.3257963281065444}
2022-11-28 01:07:05,466 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:05,466 INFO:     Epoch: 53
2022-11-28 01:07:06,206 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41217546385120263, 'Total loss': 0.41217546385120263} | train loss {'Reaction outcome loss': 0.31828910854045556, 'Total loss': 0.31828910854045556}
2022-11-28 01:07:06,206 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:06,206 INFO:     Epoch: 54
2022-11-28 01:07:06,948 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4179546030407602, 'Total loss': 0.4179546030407602} | train loss {'Reaction outcome loss': 0.31381896910208623, 'Total loss': 0.31381896910208623}
2022-11-28 01:07:06,948 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:06,948 INFO:     Epoch: 55
2022-11-28 01:07:07,689 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4239019753242081, 'Total loss': 0.4239019753242081} | train loss {'Reaction outcome loss': 0.3123278085157456, 'Total loss': 0.3123278085157456}
2022-11-28 01:07:07,689 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:07,689 INFO:     Epoch: 56
2022-11-28 01:07:08,430 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41843117477202957, 'Total loss': 0.41843117477202957} | train loss {'Reaction outcome loss': 0.3214920246323216, 'Total loss': 0.3214920246323216}
2022-11-28 01:07:08,430 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:08,430 INFO:     Epoch: 57
2022-11-28 01:07:09,170 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4231357682834972, 'Total loss': 0.4231357682834972} | train loss {'Reaction outcome loss': 0.3223578695222916, 'Total loss': 0.3223578695222916}
2022-11-28 01:07:09,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:09,170 INFO:     Epoch: 58
2022-11-28 01:07:09,915 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42090353708375583, 'Total loss': 0.42090353708375583} | train loss {'Reaction outcome loss': 0.3333471050327606, 'Total loss': 0.3333471050327606}
2022-11-28 01:07:09,916 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:09,916 INFO:     Epoch: 59
2022-11-28 01:07:10,660 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40233947573737666, 'Total loss': 0.40233947573737666} | train loss {'Reaction outcome loss': 0.31586687945523245, 'Total loss': 0.31586687945523245}
2022-11-28 01:07:10,660 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:10,660 INFO:     Epoch: 60
2022-11-28 01:07:11,404 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3906974084675312, 'Total loss': 0.3906974084675312} | train loss {'Reaction outcome loss': 0.3192772579036261, 'Total loss': 0.3192772579036261}
2022-11-28 01:07:11,404 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:11,404 INFO:     Epoch: 61
2022-11-28 01:07:12,149 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4392235270616683, 'Total loss': 0.4392235270616683} | train loss {'Reaction outcome loss': 0.3430864456979754, 'Total loss': 0.3430864456979754}
2022-11-28 01:07:12,149 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:12,149 INFO:     Epoch: 62
2022-11-28 01:07:12,888 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40990904142910783, 'Total loss': 0.40990904142910783} | train loss {'Reaction outcome loss': 0.31670481341359347, 'Total loss': 0.31670481341359347}
2022-11-28 01:07:12,888 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:12,888 INFO:     Epoch: 63
2022-11-28 01:07:13,628 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43312249501997774, 'Total loss': 0.43312249501997774} | train loss {'Reaction outcome loss': 0.3093419984164026, 'Total loss': 0.3093419984164026}
2022-11-28 01:07:13,628 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:13,628 INFO:     Epoch: 64
2022-11-28 01:07:14,373 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39740107153457677, 'Total loss': 0.39740107153457677} | train loss {'Reaction outcome loss': 0.31831084594492487, 'Total loss': 0.31831084594492487}
2022-11-28 01:07:14,373 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:14,373 INFO:     Epoch: 65
2022-11-28 01:07:15,113 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41606633280488575, 'Total loss': 0.41606633280488575} | train loss {'Reaction outcome loss': 0.3322895209074986, 'Total loss': 0.3322895209074986}
2022-11-28 01:07:15,113 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:15,113 INFO:     Epoch: 66
2022-11-28 01:07:15,861 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45212131467732514, 'Total loss': 0.45212131467732514} | train loss {'Reaction outcome loss': 0.31989459231918155, 'Total loss': 0.31989459231918155}
2022-11-28 01:07:15,861 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:15,861 INFO:     Epoch: 67
2022-11-28 01:07:16,603 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40031321211294696, 'Total loss': 0.40031321211294696} | train loss {'Reaction outcome loss': 0.32147489242285854, 'Total loss': 0.32147489242285854}
2022-11-28 01:07:16,604 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:16,604 INFO:     Epoch: 68
2022-11-28 01:07:17,349 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41455319354479964, 'Total loss': 0.41455319354479964} | train loss {'Reaction outcome loss': 0.3539367601094458, 'Total loss': 0.3539367601094458}
2022-11-28 01:07:17,349 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:17,349 INFO:     Epoch: 69
2022-11-28 01:07:18,094 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4167770326814868, 'Total loss': 0.4167770326814868} | train loss {'Reaction outcome loss': 0.3304765823670486, 'Total loss': 0.3304765823670486}
2022-11-28 01:07:18,094 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:18,094 INFO:     Epoch: 70
2022-11-28 01:07:18,841 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3994710716334256, 'Total loss': 0.3994710716334256} | train loss {'Reaction outcome loss': 0.316309859003374, 'Total loss': 0.316309859003374}
2022-11-28 01:07:18,841 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:18,841 INFO:     Epoch: 71
2022-11-28 01:07:19,585 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.390446930446408, 'Total loss': 0.390446930446408} | train loss {'Reaction outcome loss': 0.3130804796030119, 'Total loss': 0.3130804796030119}
2022-11-28 01:07:19,585 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:19,585 INFO:     Epoch: 72
2022-11-28 01:07:20,328 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.430944833565842, 'Total loss': 0.430944833565842} | train loss {'Reaction outcome loss': 0.3146405642935139, 'Total loss': 0.3146405642935139}
2022-11-28 01:07:20,328 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:20,328 INFO:     Epoch: 73
2022-11-28 01:07:21,071 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42743988656862214, 'Total loss': 0.42743988656862214} | train loss {'Reaction outcome loss': 0.33540926567516344, 'Total loss': 0.33540926567516344}
2022-11-28 01:07:21,071 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:21,071 INFO:     Epoch: 74
2022-11-28 01:07:21,817 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39119478315114975, 'Total loss': 0.39119478315114975} | train loss {'Reaction outcome loss': 0.3265135839420299, 'Total loss': 0.3265135839420299}
2022-11-28 01:07:21,818 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:21,818 INFO:     Epoch: 75
2022-11-28 01:07:22,562 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4074903548779813, 'Total loss': 0.4074903548779813} | train loss {'Reaction outcome loss': 0.3143735330717766, 'Total loss': 0.3143735330717766}
2022-11-28 01:07:22,562 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:22,562 INFO:     Epoch: 76
2022-11-28 01:07:23,306 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4378624192693017, 'Total loss': 0.4378624192693017} | train loss {'Reaction outcome loss': 0.3217696765784612, 'Total loss': 0.3217696765784612}
2022-11-28 01:07:23,306 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:23,306 INFO:     Epoch: 77
2022-11-28 01:07:24,050 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4078279325569218, 'Total loss': 0.4078279325569218} | train loss {'Reaction outcome loss': 0.3149265327494637, 'Total loss': 0.3149265327494637}
2022-11-28 01:07:24,050 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:24,050 INFO:     Epoch: 78
2022-11-28 01:07:24,793 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3841525766659867, 'Total loss': 0.3841525766659867} | train loss {'Reaction outcome loss': 0.32078147015952874, 'Total loss': 0.32078147015952874}
2022-11-28 01:07:24,793 INFO:     Found new best model at epoch 78
2022-11-28 01:07:24,794 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:24,794 INFO:     Epoch: 79
2022-11-28 01:07:25,538 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.440205130726099, 'Total loss': 0.440205130726099} | train loss {'Reaction outcome loss': 0.3210632107880434, 'Total loss': 0.3210632107880434}
2022-11-28 01:07:25,538 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:25,538 INFO:     Epoch: 80
2022-11-28 01:07:26,280 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42374955998225644, 'Total loss': 0.42374955998225644} | train loss {'Reaction outcome loss': 0.31348434273108294, 'Total loss': 0.31348434273108294}
2022-11-28 01:07:26,280 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:26,280 INFO:     Epoch: 81
2022-11-28 01:07:27,026 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40473629331046884, 'Total loss': 0.40473629331046884} | train loss {'Reaction outcome loss': 0.31480739416501785, 'Total loss': 0.31480739416501785}
2022-11-28 01:07:27,026 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:27,026 INFO:     Epoch: 82
2022-11-28 01:07:27,771 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4353310072963888, 'Total loss': 0.4353310072963888} | train loss {'Reaction outcome loss': 0.3076925956632806, 'Total loss': 0.3076925956632806}
2022-11-28 01:07:27,771 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:27,771 INFO:     Epoch: 83
2022-11-28 01:07:28,514 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41203669526360254, 'Total loss': 0.41203669526360254} | train loss {'Reaction outcome loss': 0.31672546557086684, 'Total loss': 0.31672546557086684}
2022-11-28 01:07:28,515 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:28,515 INFO:     Epoch: 84
2022-11-28 01:07:29,260 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40219168669798155, 'Total loss': 0.40219168669798155} | train loss {'Reaction outcome loss': 0.31495674422033404, 'Total loss': 0.31495674422033404}
2022-11-28 01:07:29,260 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:29,261 INFO:     Epoch: 85
2022-11-28 01:07:30,007 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4501839584924958, 'Total loss': 0.4501839584924958} | train loss {'Reaction outcome loss': 0.31712744771107004, 'Total loss': 0.31712744771107004}
2022-11-28 01:07:30,007 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:30,007 INFO:     Epoch: 86
2022-11-28 01:07:30,749 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3990088091655211, 'Total loss': 0.3990088091655211} | train loss {'Reaction outcome loss': 0.3300283896898934, 'Total loss': 0.3300283896898934}
2022-11-28 01:07:30,749 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:30,749 INFO:     Epoch: 87
2022-11-28 01:07:31,496 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42260717194188724, 'Total loss': 0.42260717194188724} | train loss {'Reaction outcome loss': 0.31589299627402534, 'Total loss': 0.31589299627402534}
2022-11-28 01:07:31,496 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:31,496 INFO:     Epoch: 88
2022-11-28 01:07:32,237 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41269822723486205, 'Total loss': 0.41269822723486205} | train loss {'Reaction outcome loss': 0.3158319900698417, 'Total loss': 0.3158319900698417}
2022-11-28 01:07:32,238 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:32,238 INFO:     Epoch: 89
2022-11-28 01:07:32,980 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4227128977125341, 'Total loss': 0.4227128977125341} | train loss {'Reaction outcome loss': 0.3140646722841714, 'Total loss': 0.3140646722841714}
2022-11-28 01:07:32,980 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:32,980 INFO:     Epoch: 90
2022-11-28 01:07:33,724 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4342199345542626, 'Total loss': 0.4342199345542626} | train loss {'Reaction outcome loss': 0.31210576024977305, 'Total loss': 0.31210576024977305}
2022-11-28 01:07:33,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:33,724 INFO:     Epoch: 91
2022-11-28 01:07:34,465 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4591586914929477, 'Total loss': 0.4591586914929477} | train loss {'Reaction outcome loss': 0.3233287697191339, 'Total loss': 0.3233287697191339}
2022-11-28 01:07:34,465 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:34,465 INFO:     Epoch: 92
2022-11-28 01:07:35,210 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45341788875785743, 'Total loss': 0.45341788875785743} | train loss {'Reaction outcome loss': 0.31213369057608037, 'Total loss': 0.31213369057608037}
2022-11-28 01:07:35,210 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:35,210 INFO:     Epoch: 93
2022-11-28 01:07:35,957 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3888351123102687, 'Total loss': 0.3888351123102687} | train loss {'Reaction outcome loss': 0.3080239982800445, 'Total loss': 0.3080239982800445}
2022-11-28 01:07:35,958 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:35,958 INFO:     Epoch: 94
2022-11-28 01:07:36,704 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4263611964204095, 'Total loss': 0.4263611964204095} | train loss {'Reaction outcome loss': 0.31699849822019277, 'Total loss': 0.31699849822019277}
2022-11-28 01:07:36,705 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:36,705 INFO:     Epoch: 95
2022-11-28 01:07:37,447 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4094618301499974, 'Total loss': 0.4094618301499974} | train loss {'Reaction outcome loss': 0.31355646848376945, 'Total loss': 0.31355646848376945}
2022-11-28 01:07:37,448 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:37,448 INFO:     Epoch: 96
2022-11-28 01:07:38,187 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3905023971403187, 'Total loss': 0.3905023971403187} | train loss {'Reaction outcome loss': 0.32014238520672444, 'Total loss': 0.32014238520672444}
2022-11-28 01:07:38,188 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:38,188 INFO:     Epoch: 97
2022-11-28 01:07:38,932 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3941439117558978, 'Total loss': 0.3941439117558978} | train loss {'Reaction outcome loss': 0.30918898629514796, 'Total loss': 0.30918898629514796}
2022-11-28 01:07:38,932 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:38,932 INFO:     Epoch: 98
2022-11-28 01:07:39,672 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41178922389041295, 'Total loss': 0.41178922389041295} | train loss {'Reaction outcome loss': 0.30802051750151255, 'Total loss': 0.30802051750151255}
2022-11-28 01:07:39,672 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:39,672 INFO:     Epoch: 99
2022-11-28 01:07:40,415 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4076968089423396, 'Total loss': 0.4076968089423396} | train loss {'Reaction outcome loss': 0.33616836734025585, 'Total loss': 0.33616836734025585}
2022-11-28 01:07:40,416 INFO:     Best model found after epoch 79 of 100.
2022-11-28 01:07:40,416 INFO:   Done with stage: TRAINING
2022-11-28 01:07:40,416 INFO:   Starting stage: EVALUATION
2022-11-28 01:07:40,536 INFO:   Done with stage: EVALUATION
2022-11-28 01:07:40,537 INFO:   Leaving out SEQ value Fold_3
2022-11-28 01:07:40,550 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 01:07:40,550 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:07:41,191 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:07:41,191 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:07:41,261 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:07:41,261 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:07:41,261 INFO:     No hyperparam tuning for this model
2022-11-28 01:07:41,261 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:07:41,261 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:07:41,262 INFO:     None feature selector for col prot
2022-11-28 01:07:41,262 INFO:     None feature selector for col prot
2022-11-28 01:07:41,262 INFO:     None feature selector for col prot
2022-11-28 01:07:41,263 INFO:     None feature selector for col chem
2022-11-28 01:07:41,263 INFO:     None feature selector for col chem
2022-11-28 01:07:41,263 INFO:     None feature selector for col chem
2022-11-28 01:07:41,263 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:07:41,263 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:07:41,265 INFO:     Number of params in model 169741
2022-11-28 01:07:41,268 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:07:41,268 INFO:   Starting stage: TRAINING
2022-11-28 01:07:41,321 INFO:     Val loss before train {'Reaction outcome loss': 1.0040636492329975, 'Total loss': 1.0040636492329975}
2022-11-28 01:07:41,321 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:41,321 INFO:     Epoch: 0
2022-11-28 01:07:42,053 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5156821352104808, 'Total loss': 0.5156821352104808} | train loss {'Reaction outcome loss': 0.628002541353468, 'Total loss': 0.628002541353468}
2022-11-28 01:07:42,053 INFO:     Found new best model at epoch 0
2022-11-28 01:07:42,054 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:42,054 INFO:     Epoch: 1
2022-11-28 01:07:42,788 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49466475359229156, 'Total loss': 0.49466475359229156} | train loss {'Reaction outcome loss': 0.4981873257116216, 'Total loss': 0.4981873257116216}
2022-11-28 01:07:42,788 INFO:     Found new best model at epoch 1
2022-11-28 01:07:42,789 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:42,789 INFO:     Epoch: 2
2022-11-28 01:07:43,525 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4408108609360318, 'Total loss': 0.4408108609360318} | train loss {'Reaction outcome loss': 0.45581297735210324, 'Total loss': 0.45581297735210324}
2022-11-28 01:07:43,526 INFO:     Found new best model at epoch 2
2022-11-28 01:07:43,526 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:43,527 INFO:     Epoch: 3
2022-11-28 01:07:44,261 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.44891263613867205, 'Total loss': 0.44891263613867205} | train loss {'Reaction outcome loss': 0.4285432156786078, 'Total loss': 0.4285432156786078}
2022-11-28 01:07:44,261 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:44,261 INFO:     Epoch: 4
2022-11-28 01:07:44,996 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43909701150517133, 'Total loss': 0.43909701150517133} | train loss {'Reaction outcome loss': 0.4173857610000939, 'Total loss': 0.4173857610000939}
2022-11-28 01:07:44,997 INFO:     Found new best model at epoch 4
2022-11-28 01:07:44,997 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:44,998 INFO:     Epoch: 5
2022-11-28 01:07:45,733 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4432273954153061, 'Total loss': 0.4432273954153061} | train loss {'Reaction outcome loss': 0.4133781139112887, 'Total loss': 0.4133781139112887}
2022-11-28 01:07:45,733 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:45,733 INFO:     Epoch: 6
2022-11-28 01:07:46,473 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4484134957540867, 'Total loss': 0.4484134957540867} | train loss {'Reaction outcome loss': 0.4037628886213557, 'Total loss': 0.4037628886213557}
2022-11-28 01:07:46,473 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:46,473 INFO:     Epoch: 7
2022-11-28 01:07:47,208 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4219176991041316, 'Total loss': 0.4219176991041316} | train loss {'Reaction outcome loss': 0.3900351808330075, 'Total loss': 0.3900351808330075}
2022-11-28 01:07:47,209 INFO:     Found new best model at epoch 7
2022-11-28 01:07:47,209 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:47,210 INFO:     Epoch: 8
2022-11-28 01:07:47,942 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4571776213340981, 'Total loss': 0.4571776213340981} | train loss {'Reaction outcome loss': 0.3858591611573442, 'Total loss': 0.3858591611573442}
2022-11-28 01:07:47,942 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:47,943 INFO:     Epoch: 9
2022-11-28 01:07:48,676 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42441650739935943, 'Total loss': 0.42441650739935943} | train loss {'Reaction outcome loss': 0.3746489370394437, 'Total loss': 0.3746489370394437}
2022-11-28 01:07:48,676 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:48,676 INFO:     Epoch: 10
2022-11-28 01:07:49,409 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44114629127258476, 'Total loss': 0.44114629127258476} | train loss {'Reaction outcome loss': 0.3705668019466713, 'Total loss': 0.3705668019466713}
2022-11-28 01:07:49,409 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:49,409 INFO:     Epoch: 11
2022-11-28 01:07:50,141 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4289400463187417, 'Total loss': 0.4289400463187417} | train loss {'Reaction outcome loss': 0.3704650172139289, 'Total loss': 0.3704650172139289}
2022-11-28 01:07:50,141 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:50,141 INFO:     Epoch: 12
2022-11-28 01:07:50,877 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4289027809403663, 'Total loss': 0.4289027809403663} | train loss {'Reaction outcome loss': 0.3659943775808225, 'Total loss': 0.3659943775808225}
2022-11-28 01:07:50,877 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:50,877 INFO:     Epoch: 13
2022-11-28 01:07:51,612 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43262064872786055, 'Total loss': 0.43262064872786055} | train loss {'Reaction outcome loss': 0.354132351694537, 'Total loss': 0.354132351694537}
2022-11-28 01:07:51,613 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:51,613 INFO:     Epoch: 14
2022-11-28 01:07:52,346 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4337466382096673, 'Total loss': 0.4337466382096673} | train loss {'Reaction outcome loss': 0.35590890223984833, 'Total loss': 0.35590890223984833}
2022-11-28 01:07:52,347 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:52,347 INFO:     Epoch: 15
2022-11-28 01:07:53,081 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42391738503478293, 'Total loss': 0.42391738503478293} | train loss {'Reaction outcome loss': 0.357691546627244, 'Total loss': 0.357691546627244}
2022-11-28 01:07:53,082 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:53,082 INFO:     Epoch: 16
2022-11-28 01:07:53,817 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44438186946303343, 'Total loss': 0.44438186946303343} | train loss {'Reaction outcome loss': 0.3383938007239924, 'Total loss': 0.3383938007239924}
2022-11-28 01:07:53,817 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:53,817 INFO:     Epoch: 17
2022-11-28 01:07:54,551 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42671090866937195, 'Total loss': 0.42671090866937195} | train loss {'Reaction outcome loss': 0.3488715163996962, 'Total loss': 0.3488715163996962}
2022-11-28 01:07:54,551 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:54,552 INFO:     Epoch: 18
2022-11-28 01:07:55,289 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4428439202696778, 'Total loss': 0.4428439202696778} | train loss {'Reaction outcome loss': 0.33770043183057036, 'Total loss': 0.33770043183057036}
2022-11-28 01:07:55,290 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:55,290 INFO:     Epoch: 19
2022-11-28 01:07:56,024 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4481237572292949, 'Total loss': 0.4481237572292949} | train loss {'Reaction outcome loss': 0.3372695614263171, 'Total loss': 0.3372695614263171}
2022-11-28 01:07:56,025 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:56,025 INFO:     Epoch: 20
2022-11-28 01:07:56,755 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4450442510288815, 'Total loss': 0.4450442510288815} | train loss {'Reaction outcome loss': 0.34276891131427323, 'Total loss': 0.34276891131427323}
2022-11-28 01:07:56,755 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:56,755 INFO:     Epoch: 21
2022-11-28 01:07:57,490 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43429167118183404, 'Total loss': 0.43429167118183404} | train loss {'Reaction outcome loss': 0.34380292119916345, 'Total loss': 0.34380292119916345}
2022-11-28 01:07:57,490 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:57,490 INFO:     Epoch: 22
2022-11-28 01:07:58,225 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42512405992940416, 'Total loss': 0.42512405992940416} | train loss {'Reaction outcome loss': 0.3384039681404829, 'Total loss': 0.3384039681404829}
2022-11-28 01:07:58,225 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:58,225 INFO:     Epoch: 23
2022-11-28 01:07:58,964 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42188941981903344, 'Total loss': 0.42188941981903344} | train loss {'Reaction outcome loss': 0.33143323385080353, 'Total loss': 0.33143323385080353}
2022-11-28 01:07:58,965 INFO:     Found new best model at epoch 23
2022-11-28 01:07:58,965 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:58,965 INFO:     Epoch: 24
2022-11-28 01:07:59,697 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4064406315947688, 'Total loss': 0.4064406315947688} | train loss {'Reaction outcome loss': 0.3347455028933091, 'Total loss': 0.3347455028933091}
2022-11-28 01:07:59,699 INFO:     Found new best model at epoch 24
2022-11-28 01:07:59,699 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:07:59,699 INFO:     Epoch: 25
2022-11-28 01:08:00,437 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46234262093555095, 'Total loss': 0.46234262093555095} | train loss {'Reaction outcome loss': 0.3296762851418042, 'Total loss': 0.3296762851418042}
2022-11-28 01:08:00,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:00,437 INFO:     Epoch: 26
2022-11-28 01:08:01,171 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43877323560936504, 'Total loss': 0.43877323560936504} | train loss {'Reaction outcome loss': 0.3308126919399031, 'Total loss': 0.3308126919399031}
2022-11-28 01:08:01,171 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:01,171 INFO:     Epoch: 27
2022-11-28 01:08:01,904 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40561247218486873, 'Total loss': 0.40561247218486873} | train loss {'Reaction outcome loss': 0.33409815782406294, 'Total loss': 0.33409815782406294}
2022-11-28 01:08:01,904 INFO:     Found new best model at epoch 27
2022-11-28 01:08:01,905 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:01,905 INFO:     Epoch: 28
2022-11-28 01:08:02,639 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42070105741190356, 'Total loss': 0.42070105741190356} | train loss {'Reaction outcome loss': 0.32472493731584706, 'Total loss': 0.32472493731584706}
2022-11-28 01:08:02,639 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:02,640 INFO:     Epoch: 29
2022-11-28 01:08:03,373 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3965333551168442, 'Total loss': 0.3965333551168442} | train loss {'Reaction outcome loss': 0.326998327568662, 'Total loss': 0.326998327568662}
2022-11-28 01:08:03,373 INFO:     Found new best model at epoch 29
2022-11-28 01:08:03,374 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:03,374 INFO:     Epoch: 30
2022-11-28 01:08:04,110 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40399781389291894, 'Total loss': 0.40399781389291894} | train loss {'Reaction outcome loss': 0.33565573501171636, 'Total loss': 0.33565573501171636}
2022-11-28 01:08:04,110 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:04,110 INFO:     Epoch: 31
2022-11-28 01:08:04,845 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4313386148491571, 'Total loss': 0.4313386148491571} | train loss {'Reaction outcome loss': 0.3237418896808732, 'Total loss': 0.3237418896808732}
2022-11-28 01:08:04,845 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:04,845 INFO:     Epoch: 32
2022-11-28 01:08:05,577 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41660755162322244, 'Total loss': 0.41660755162322244} | train loss {'Reaction outcome loss': 0.3238709118583652, 'Total loss': 0.3238709118583652}
2022-11-28 01:08:05,577 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:05,577 INFO:     Epoch: 33
2022-11-28 01:08:06,312 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4427245200373406, 'Total loss': 0.4427245200373406} | train loss {'Reaction outcome loss': 0.3218076460246668, 'Total loss': 0.3218076460246668}
2022-11-28 01:08:06,312 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:06,312 INFO:     Epoch: 34
2022-11-28 01:08:07,051 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43768672818361326, 'Total loss': 0.43768672818361326} | train loss {'Reaction outcome loss': 0.3221883508758467, 'Total loss': 0.3221883508758467}
2022-11-28 01:08:07,051 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:07,051 INFO:     Epoch: 35
2022-11-28 01:08:07,786 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4251307401546212, 'Total loss': 0.4251307401546212} | train loss {'Reaction outcome loss': 0.320788764349017, 'Total loss': 0.320788764349017}
2022-11-28 01:08:07,786 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:07,786 INFO:     Epoch: 36
2022-11-28 01:08:08,520 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4293546870697376, 'Total loss': 0.4293546870697376} | train loss {'Reaction outcome loss': 0.3062469011447469, 'Total loss': 0.3062469011447469}
2022-11-28 01:08:08,520 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:08,520 INFO:     Epoch: 37
2022-11-28 01:08:09,258 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.451605441265328, 'Total loss': 0.451605441265328} | train loss {'Reaction outcome loss': 0.32502334433623026, 'Total loss': 0.32502334433623026}
2022-11-28 01:08:09,258 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:09,258 INFO:     Epoch: 38
2022-11-28 01:08:09,997 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41356422596199566, 'Total loss': 0.41356422596199566} | train loss {'Reaction outcome loss': 0.31497827718858834, 'Total loss': 0.31497827718858834}
2022-11-28 01:08:09,997 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:09,997 INFO:     Epoch: 39
2022-11-28 01:08:10,734 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4188752961020137, 'Total loss': 0.4188752961020137} | train loss {'Reaction outcome loss': 0.3163047958104337, 'Total loss': 0.3163047958104337}
2022-11-28 01:08:10,734 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:10,734 INFO:     Epoch: 40
2022-11-28 01:08:11,473 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4259773714597835, 'Total loss': 0.4259773714597835} | train loss {'Reaction outcome loss': 0.3170033556821405, 'Total loss': 0.3170033556821405}
2022-11-28 01:08:11,473 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:11,473 INFO:     Epoch: 41
2022-11-28 01:08:12,209 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41927214625269865, 'Total loss': 0.41927214625269865} | train loss {'Reaction outcome loss': 0.3219757048932255, 'Total loss': 0.3219757048932255}
2022-11-28 01:08:12,210 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:12,210 INFO:     Epoch: 42
2022-11-28 01:08:12,943 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4219269204971402, 'Total loss': 0.4219269204971402} | train loss {'Reaction outcome loss': 0.3073433723422836, 'Total loss': 0.3073433723422836}
2022-11-28 01:08:12,943 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:12,943 INFO:     Epoch: 43
2022-11-28 01:08:13,680 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4198873417322026, 'Total loss': 0.4198873417322026} | train loss {'Reaction outcome loss': 0.3188680225342024, 'Total loss': 0.3188680225342024}
2022-11-28 01:08:13,680 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:13,681 INFO:     Epoch: 44
2022-11-28 01:08:14,418 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41061223419599757, 'Total loss': 0.41061223419599757} | train loss {'Reaction outcome loss': 0.3213881183659933, 'Total loss': 0.3213881183659933}
2022-11-28 01:08:14,418 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:14,418 INFO:     Epoch: 45
2022-11-28 01:08:15,156 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40522670468618704, 'Total loss': 0.40522670468618704} | train loss {'Reaction outcome loss': 0.31147324788521547, 'Total loss': 0.31147324788521547}
2022-11-28 01:08:15,156 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:15,156 INFO:     Epoch: 46
2022-11-28 01:08:15,896 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4103627575691356, 'Total loss': 0.4103627575691356} | train loss {'Reaction outcome loss': 0.3036659370008551, 'Total loss': 0.3036659370008551}
2022-11-28 01:08:15,896 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:15,896 INFO:     Epoch: 47
2022-11-28 01:08:16,632 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43808280884526496, 'Total loss': 0.43808280884526496} | train loss {'Reaction outcome loss': 0.31202196505409285, 'Total loss': 0.31202196505409285}
2022-11-28 01:08:16,632 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:16,632 INFO:     Epoch: 48
2022-11-28 01:08:17,368 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41579677476439364, 'Total loss': 0.41579677476439364} | train loss {'Reaction outcome loss': 0.315773000849075, 'Total loss': 0.315773000849075}
2022-11-28 01:08:17,368 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:17,368 INFO:     Epoch: 49
2022-11-28 01:08:18,103 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40478193898533665, 'Total loss': 0.40478193898533665} | train loss {'Reaction outcome loss': 0.3090555422679811, 'Total loss': 0.3090555422679811}
2022-11-28 01:08:18,103 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:18,103 INFO:     Epoch: 50
2022-11-28 01:08:18,834 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4266741788664529, 'Total loss': 0.4266741788664529} | train loss {'Reaction outcome loss': 0.3097714902069725, 'Total loss': 0.3097714902069725}
2022-11-28 01:08:18,834 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:18,834 INFO:     Epoch: 51
2022-11-28 01:08:19,569 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4211908081589743, 'Total loss': 0.4211908081589743} | train loss {'Reaction outcome loss': 0.314553897705723, 'Total loss': 0.314553897705723}
2022-11-28 01:08:19,570 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:19,570 INFO:     Epoch: 52
2022-11-28 01:08:20,303 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43126830735871957, 'Total loss': 0.43126830735871957} | train loss {'Reaction outcome loss': 0.311063551542456, 'Total loss': 0.311063551542456}
2022-11-28 01:08:20,303 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:20,303 INFO:     Epoch: 53
2022-11-28 01:08:21,038 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4528664506452028, 'Total loss': 0.4528664506452028} | train loss {'Reaction outcome loss': 0.31896317857088613, 'Total loss': 0.31896317857088613}
2022-11-28 01:08:21,038 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:21,038 INFO:     Epoch: 54
2022-11-28 01:08:21,774 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4027369216431019, 'Total loss': 0.4027369216431019} | train loss {'Reaction outcome loss': 0.30706479647731194, 'Total loss': 0.30706479647731194}
2022-11-28 01:08:21,774 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:21,774 INFO:     Epoch: 55
2022-11-28 01:08:22,507 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4349252241988515, 'Total loss': 0.4349252241988515} | train loss {'Reaction outcome loss': 0.31268953077006534, 'Total loss': 0.31268953077006534}
2022-11-28 01:08:22,507 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:22,507 INFO:     Epoch: 56
2022-11-28 01:08:23,244 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4296549565570299, 'Total loss': 0.4296549565570299} | train loss {'Reaction outcome loss': 0.3066412189089861, 'Total loss': 0.3066412189089861}
2022-11-28 01:08:23,245 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:23,245 INFO:     Epoch: 57
2022-11-28 01:08:23,980 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40139703210010086, 'Total loss': 0.40139703210010086} | train loss {'Reaction outcome loss': 0.3030304236215402, 'Total loss': 0.3030304236215402}
2022-11-28 01:08:23,981 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:23,981 INFO:     Epoch: 58
2022-11-28 01:08:24,716 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4420297769613044, 'Total loss': 0.4420297769613044} | train loss {'Reaction outcome loss': 0.30742121512284043, 'Total loss': 0.30742121512284043}
2022-11-28 01:08:24,716 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:24,716 INFO:     Epoch: 59
2022-11-28 01:08:25,452 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3998396580302438, 'Total loss': 0.3998396580302438} | train loss {'Reaction outcome loss': 0.3149637599765766, 'Total loss': 0.3149637599765766}
2022-11-28 01:08:25,452 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:25,452 INFO:     Epoch: 60
2022-11-28 01:08:26,186 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4126117860161981, 'Total loss': 0.4126117860161981} | train loss {'Reaction outcome loss': 0.3036877105898056, 'Total loss': 0.3036877105898056}
2022-11-28 01:08:26,186 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:26,186 INFO:     Epoch: 61
2022-11-28 01:08:26,918 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42043112114418385, 'Total loss': 0.42043112114418385} | train loss {'Reaction outcome loss': 0.31032325373199143, 'Total loss': 0.31032325373199143}
2022-11-28 01:08:26,918 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:26,918 INFO:     Epoch: 62
2022-11-28 01:08:27,652 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39287632773088854, 'Total loss': 0.39287632773088854} | train loss {'Reaction outcome loss': 0.31405795507560497, 'Total loss': 0.31405795507560497}
2022-11-28 01:08:27,652 INFO:     Found new best model at epoch 62
2022-11-28 01:08:27,653 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:27,653 INFO:     Epoch: 63
2022-11-28 01:08:28,385 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41721929852352585, 'Total loss': 0.41721929852352585} | train loss {'Reaction outcome loss': 0.3053915636827711, 'Total loss': 0.3053915636827711}
2022-11-28 01:08:28,385 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:28,385 INFO:     Epoch: 64
2022-11-28 01:08:29,122 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4210735147082528, 'Total loss': 0.4210735147082528} | train loss {'Reaction outcome loss': 0.30276097916066647, 'Total loss': 0.30276097916066647}
2022-11-28 01:08:29,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:29,123 INFO:     Epoch: 65
2022-11-28 01:08:29,854 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48519382469875866, 'Total loss': 0.48519382469875866} | train loss {'Reaction outcome loss': 0.3109436729831285, 'Total loss': 0.3109436729831285}
2022-11-28 01:08:29,855 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:29,855 INFO:     Epoch: 66
2022-11-28 01:08:30,589 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42410104669803794, 'Total loss': 0.42410104669803794} | train loss {'Reaction outcome loss': 0.3079349477393705, 'Total loss': 0.3079349477393705}
2022-11-28 01:08:30,590 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:30,590 INFO:     Epoch: 67
2022-11-28 01:08:31,328 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3901328260815421, 'Total loss': 0.3901328260815421} | train loss {'Reaction outcome loss': 0.309973051389832, 'Total loss': 0.309973051389832}
2022-11-28 01:08:31,328 INFO:     Found new best model at epoch 67
2022-11-28 01:08:31,329 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:31,329 INFO:     Epoch: 68
2022-11-28 01:08:32,069 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4331420821159385, 'Total loss': 0.4331420821159385} | train loss {'Reaction outcome loss': 0.3083728328347206, 'Total loss': 0.3083728328347206}
2022-11-28 01:08:32,069 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:32,069 INFO:     Epoch: 69
2022-11-28 01:08:32,808 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4711597807878672, 'Total loss': 0.4711597807878672} | train loss {'Reaction outcome loss': 0.3124659748167777, 'Total loss': 0.3124659748167777}
2022-11-28 01:08:32,808 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:32,808 INFO:     Epoch: 70
2022-11-28 01:08:33,544 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4147061757570089, 'Total loss': 0.4147061757570089} | train loss {'Reaction outcome loss': 0.3038666055339282, 'Total loss': 0.3038666055339282}
2022-11-28 01:08:33,544 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:33,544 INFO:     Epoch: 71
2022-11-28 01:08:34,285 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4215523664687955, 'Total loss': 0.4215523664687955} | train loss {'Reaction outcome loss': 0.30897785472821016, 'Total loss': 0.30897785472821016}
2022-11-28 01:08:34,285 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:34,286 INFO:     Epoch: 72
2022-11-28 01:08:35,021 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4454615263398303, 'Total loss': 0.4454615263398303} | train loss {'Reaction outcome loss': 0.2985778369436987, 'Total loss': 0.2985778369436987}
2022-11-28 01:08:35,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:35,021 INFO:     Epoch: 73
2022-11-28 01:08:35,758 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46566203444503074, 'Total loss': 0.46566203444503074} | train loss {'Reaction outcome loss': 0.3035100357393261, 'Total loss': 0.3035100357393261}
2022-11-28 01:08:35,758 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:35,758 INFO:     Epoch: 74
2022-11-28 01:08:36,494 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4062176118063372, 'Total loss': 0.4062176118063372} | train loss {'Reaction outcome loss': 0.3040293901548034, 'Total loss': 0.3040293901548034}
2022-11-28 01:08:36,495 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:36,495 INFO:     Epoch: 75
2022-11-28 01:08:37,231 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4273719233135844, 'Total loss': 0.4273719233135844} | train loss {'Reaction outcome loss': 0.29330100305378437, 'Total loss': 0.29330100305378437}
2022-11-28 01:08:37,231 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:37,231 INFO:     Epoch: 76
2022-11-28 01:08:37,966 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42294016861638356, 'Total loss': 0.42294016861638356} | train loss {'Reaction outcome loss': 0.30874983199917877, 'Total loss': 0.30874983199917877}
2022-11-28 01:08:37,966 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:37,966 INFO:     Epoch: 77
2022-11-28 01:08:38,700 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4320330508919649, 'Total loss': 0.4320330508919649} | train loss {'Reaction outcome loss': 0.3045124590060994, 'Total loss': 0.3045124590060994}
2022-11-28 01:08:38,700 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:38,700 INFO:     Epoch: 78
2022-11-28 01:08:39,435 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4248794944480408, 'Total loss': 0.4248794944480408} | train loss {'Reaction outcome loss': 0.3102962704008964, 'Total loss': 0.3102962704008964}
2022-11-28 01:08:39,435 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:39,435 INFO:     Epoch: 79
2022-11-28 01:08:40,170 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4191389170496963, 'Total loss': 0.4191389170496963} | train loss {'Reaction outcome loss': 0.3140591558862905, 'Total loss': 0.3140591558862905}
2022-11-28 01:08:40,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:40,170 INFO:     Epoch: 80
2022-11-28 01:08:40,902 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.420885341805081, 'Total loss': 0.420885341805081} | train loss {'Reaction outcome loss': 0.30234091689229986, 'Total loss': 0.30234091689229986}
2022-11-28 01:08:40,903 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:40,903 INFO:     Epoch: 81
2022-11-28 01:08:41,642 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4036354329003844, 'Total loss': 0.4036354329003844} | train loss {'Reaction outcome loss': 0.2964093432318969, 'Total loss': 0.2964093432318969}
2022-11-28 01:08:41,642 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:41,642 INFO:     Epoch: 82
2022-11-28 01:08:42,382 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40065086390389953, 'Total loss': 0.40065086390389953} | train loss {'Reaction outcome loss': 0.31355521143948445, 'Total loss': 0.31355521143948445}
2022-11-28 01:08:42,382 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:42,382 INFO:     Epoch: 83
2022-11-28 01:08:43,116 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40361679917158083, 'Total loss': 0.40361679917158083} | train loss {'Reaction outcome loss': 0.2989960271620848, 'Total loss': 0.2989960271620848}
2022-11-28 01:08:43,117 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:43,117 INFO:     Epoch: 84
2022-11-28 01:08:43,853 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4455549224864605, 'Total loss': 0.4455549224864605} | train loss {'Reaction outcome loss': 0.3003435649710601, 'Total loss': 0.3003435649710601}
2022-11-28 01:08:43,853 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:43,853 INFO:     Epoch: 85
2022-11-28 01:08:44,585 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4456644654273987, 'Total loss': 0.4456644654273987} | train loss {'Reaction outcome loss': 0.3004473214663687, 'Total loss': 0.3004473214663687}
2022-11-28 01:08:44,585 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:44,585 INFO:     Epoch: 86
2022-11-28 01:08:45,316 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4049785705499871, 'Total loss': 0.4049785705499871} | train loss {'Reaction outcome loss': 0.3001934374514662, 'Total loss': 0.3001934374514662}
2022-11-28 01:08:45,316 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:45,316 INFO:     Epoch: 87
2022-11-28 01:08:46,050 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46404500582883523, 'Total loss': 0.46404500582883523} | train loss {'Reaction outcome loss': 0.3025490793048358, 'Total loss': 0.3025490793048358}
2022-11-28 01:08:46,050 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:46,050 INFO:     Epoch: 88
2022-11-28 01:08:46,785 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45175170933091363, 'Total loss': 0.45175170933091363} | train loss {'Reaction outcome loss': 0.2991899100636117, 'Total loss': 0.2991899100636117}
2022-11-28 01:08:46,785 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:46,785 INFO:     Epoch: 89
2022-11-28 01:08:47,525 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3940069762080215, 'Total loss': 0.3940069762080215} | train loss {'Reaction outcome loss': 0.29987606821490115, 'Total loss': 0.29987606821490115}
2022-11-28 01:08:47,525 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:47,525 INFO:     Epoch: 90
2022-11-28 01:08:48,260 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42732811805813814, 'Total loss': 0.42732811805813814} | train loss {'Reaction outcome loss': 0.297227836137668, 'Total loss': 0.297227836137668}
2022-11-28 01:08:48,260 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:48,260 INFO:     Epoch: 91
2022-11-28 01:08:48,998 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43775549565636834, 'Total loss': 0.43775549565636834} | train loss {'Reaction outcome loss': 0.30297240909555406, 'Total loss': 0.30297240909555406}
2022-11-28 01:08:48,998 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:48,998 INFO:     Epoch: 92
2022-11-28 01:08:49,739 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40849780377953554, 'Total loss': 0.40849780377953554} | train loss {'Reaction outcome loss': 0.3068794581550555, 'Total loss': 0.3068794581550555}
2022-11-28 01:08:49,739 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:49,739 INFO:     Epoch: 93
2022-11-28 01:08:50,477 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4200998626129572, 'Total loss': 0.4200998626129572} | train loss {'Reaction outcome loss': 0.3054612102445032, 'Total loss': 0.3054612102445032}
2022-11-28 01:08:50,477 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:50,477 INFO:     Epoch: 94
2022-11-28 01:08:51,217 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41188171887120534, 'Total loss': 0.41188171887120534} | train loss {'Reaction outcome loss': 0.3004357130190388, 'Total loss': 0.3004357130190388}
2022-11-28 01:08:51,217 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:51,217 INFO:     Epoch: 95
2022-11-28 01:08:51,954 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4294014042893121, 'Total loss': 0.4294014042893121} | train loss {'Reaction outcome loss': 0.29379489379705953, 'Total loss': 0.29379489379705953}
2022-11-28 01:08:51,955 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:51,955 INFO:     Epoch: 96
2022-11-28 01:08:52,688 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4019966316084529, 'Total loss': 0.4019966316084529} | train loss {'Reaction outcome loss': 0.30748385987931587, 'Total loss': 0.30748385987931587}
2022-11-28 01:08:52,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:52,688 INFO:     Epoch: 97
2022-11-28 01:08:53,418 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43527839523415235, 'Total loss': 0.43527839523415235} | train loss {'Reaction outcome loss': 0.3015148634793329, 'Total loss': 0.3015148634793329}
2022-11-28 01:08:53,418 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:53,418 INFO:     Epoch: 98
2022-11-28 01:08:54,150 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44071778862975364, 'Total loss': 0.44071778862975364} | train loss {'Reaction outcome loss': 0.29954577478595446, 'Total loss': 0.29954577478595446}
2022-11-28 01:08:54,150 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:54,150 INFO:     Epoch: 99
2022-11-28 01:08:54,885 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4356591178234233, 'Total loss': 0.4356591178234233} | train loss {'Reaction outcome loss': 0.3061207750598427, 'Total loss': 0.3061207750598427}
2022-11-28 01:08:54,886 INFO:     Best model found after epoch 68 of 100.
2022-11-28 01:08:54,886 INFO:   Done with stage: TRAINING
2022-11-28 01:08:54,887 INFO:   Starting stage: EVALUATION
2022-11-28 01:08:55,018 INFO:   Done with stage: EVALUATION
2022-11-28 01:08:55,018 INFO:   Leaving out SEQ value Fold_4
2022-11-28 01:08:55,031 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 01:08:55,031 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:08:55,671 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:08:55,671 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:08:55,740 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:08:55,741 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:08:55,741 INFO:     No hyperparam tuning for this model
2022-11-28 01:08:55,741 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:08:55,741 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:08:55,741 INFO:     None feature selector for col prot
2022-11-28 01:08:55,742 INFO:     None feature selector for col prot
2022-11-28 01:08:55,742 INFO:     None feature selector for col prot
2022-11-28 01:08:55,742 INFO:     None feature selector for col chem
2022-11-28 01:08:55,742 INFO:     None feature selector for col chem
2022-11-28 01:08:55,742 INFO:     None feature selector for col chem
2022-11-28 01:08:55,742 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:08:55,742 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:08:55,744 INFO:     Number of params in model 169741
2022-11-28 01:08:55,747 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:08:55,747 INFO:   Starting stage: TRAINING
2022-11-28 01:08:55,801 INFO:     Val loss before train {'Reaction outcome loss': 1.0016728233207355, 'Total loss': 1.0016728233207355}
2022-11-28 01:08:55,801 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:55,801 INFO:     Epoch: 0
2022-11-28 01:08:56,547 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5117741982367906, 'Total loss': 0.5117741982367906} | train loss {'Reaction outcome loss': 0.6601766348485986, 'Total loss': 0.6601766348485986}
2022-11-28 01:08:56,547 INFO:     Found new best model at epoch 0
2022-11-28 01:08:56,548 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:56,548 INFO:     Epoch: 1
2022-11-28 01:08:57,294 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4934647164561532, 'Total loss': 0.4934647164561532} | train loss {'Reaction outcome loss': 0.49436144338500115, 'Total loss': 0.49436144338500115}
2022-11-28 01:08:57,294 INFO:     Found new best model at epoch 1
2022-11-28 01:08:57,295 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:57,295 INFO:     Epoch: 2
2022-11-28 01:08:58,036 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45885202796621755, 'Total loss': 0.45885202796621755} | train loss {'Reaction outcome loss': 0.4724528454244137, 'Total loss': 0.4724528454244137}
2022-11-28 01:08:58,036 INFO:     Found new best model at epoch 2
2022-11-28 01:08:58,037 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:58,037 INFO:     Epoch: 3
2022-11-28 01:08:58,784 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4671790623529391, 'Total loss': 0.4671790623529391} | train loss {'Reaction outcome loss': 0.44576382504836204, 'Total loss': 0.44576382504836204}
2022-11-28 01:08:58,784 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:58,784 INFO:     Epoch: 4
2022-11-28 01:08:59,528 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.42374118078838696, 'Total loss': 0.42374118078838696} | train loss {'Reaction outcome loss': 0.42258858665703763, 'Total loss': 0.42258858665703763}
2022-11-28 01:08:59,528 INFO:     Found new best model at epoch 4
2022-11-28 01:08:59,529 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:08:59,529 INFO:     Epoch: 5
2022-11-28 01:09:00,273 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45040409470146353, 'Total loss': 0.45040409470146353} | train loss {'Reaction outcome loss': 0.4165718126441202, 'Total loss': 0.4165718126441202}
2022-11-28 01:09:00,274 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:00,274 INFO:     Epoch: 6
2022-11-28 01:09:01,017 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44837684726173227, 'Total loss': 0.44837684726173227} | train loss {'Reaction outcome loss': 0.4066739687996526, 'Total loss': 0.4066739687996526}
2022-11-28 01:09:01,018 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:01,018 INFO:     Epoch: 7
2022-11-28 01:09:01,760 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4299276698042046, 'Total loss': 0.4299276698042046} | train loss {'Reaction outcome loss': 0.39608048644637867, 'Total loss': 0.39608048644637867}
2022-11-28 01:09:01,760 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:01,760 INFO:     Epoch: 8
2022-11-28 01:09:02,506 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43185520646246994, 'Total loss': 0.43185520646246994} | train loss {'Reaction outcome loss': 0.387262059976497, 'Total loss': 0.387262059976497}
2022-11-28 01:09:02,506 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:02,506 INFO:     Epoch: 9
2022-11-28 01:09:03,251 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41771929135376756, 'Total loss': 0.41771929135376756} | train loss {'Reaction outcome loss': 0.38107181457622397, 'Total loss': 0.38107181457622397}
2022-11-28 01:09:03,251 INFO:     Found new best model at epoch 9
2022-11-28 01:09:03,252 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:03,252 INFO:     Epoch: 10
2022-11-28 01:09:03,996 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41768070039424027, 'Total loss': 0.41768070039424027} | train loss {'Reaction outcome loss': 0.3744281053603176, 'Total loss': 0.3744281053603176}
2022-11-28 01:09:03,996 INFO:     Found new best model at epoch 10
2022-11-28 01:09:03,997 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:03,997 INFO:     Epoch: 11
2022-11-28 01:09:04,745 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4382098652422428, 'Total loss': 0.4382098652422428} | train loss {'Reaction outcome loss': 0.36983858875089115, 'Total loss': 0.36983858875089115}
2022-11-28 01:09:04,745 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:04,745 INFO:     Epoch: 12
2022-11-28 01:09:05,489 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4283406124873595, 'Total loss': 0.4283406124873595} | train loss {'Reaction outcome loss': 0.3664434290821514, 'Total loss': 0.3664434290821514}
2022-11-28 01:09:05,489 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:05,489 INFO:     Epoch: 13
2022-11-28 01:09:06,232 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4396976263008334, 'Total loss': 0.4396976263008334} | train loss {'Reaction outcome loss': 0.36755735412119855, 'Total loss': 0.36755735412119855}
2022-11-28 01:09:06,233 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:06,233 INFO:     Epoch: 14
2022-11-28 01:09:06,976 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47222894734957, 'Total loss': 0.47222894734957} | train loss {'Reaction outcome loss': 0.35885373163487644, 'Total loss': 0.35885373163487644}
2022-11-28 01:09:06,976 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:06,976 INFO:     Epoch: 15
2022-11-28 01:09:07,720 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4491945108906789, 'Total loss': 0.4491945108906789} | train loss {'Reaction outcome loss': 0.35823305218570656, 'Total loss': 0.35823305218570656}
2022-11-28 01:09:07,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:07,720 INFO:     Epoch: 16
2022-11-28 01:09:08,467 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4345647171139717, 'Total loss': 0.4345647171139717} | train loss {'Reaction outcome loss': 0.35958837068849997, 'Total loss': 0.35958837068849997}
2022-11-28 01:09:08,467 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:08,467 INFO:     Epoch: 17
2022-11-28 01:09:09,216 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43215429884466255, 'Total loss': 0.43215429884466255} | train loss {'Reaction outcome loss': 0.3484849033036059, 'Total loss': 0.3484849033036059}
2022-11-28 01:09:09,216 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:09,216 INFO:     Epoch: 18
2022-11-28 01:09:09,957 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4187078445472501, 'Total loss': 0.4187078445472501} | train loss {'Reaction outcome loss': 0.34107184485201875, 'Total loss': 0.34107184485201875}
2022-11-28 01:09:09,957 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:09,957 INFO:     Epoch: 19
2022-11-28 01:09:10,698 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4440355290743438, 'Total loss': 0.4440355290743438} | train loss {'Reaction outcome loss': 0.3383631066629483, 'Total loss': 0.3383631066629483}
2022-11-28 01:09:10,698 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:10,698 INFO:     Epoch: 20
2022-11-28 01:09:11,444 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44045432724735956, 'Total loss': 0.44045432724735956} | train loss {'Reaction outcome loss': 0.3402525170616085, 'Total loss': 0.3402525170616085}
2022-11-28 01:09:11,444 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:11,444 INFO:     Epoch: 21
2022-11-28 01:09:12,191 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4238795285875147, 'Total loss': 0.4238795285875147} | train loss {'Reaction outcome loss': 0.34376260169571443, 'Total loss': 0.34376260169571443}
2022-11-28 01:09:12,192 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:12,192 INFO:     Epoch: 22
2022-11-28 01:09:12,933 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42031806673515926, 'Total loss': 0.42031806673515926} | train loss {'Reaction outcome loss': 0.3364633085326322, 'Total loss': 0.3364633085326322}
2022-11-28 01:09:12,933 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:12,934 INFO:     Epoch: 23
2022-11-28 01:09:13,677 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.399185448884964, 'Total loss': 0.399185448884964} | train loss {'Reaction outcome loss': 0.33975123872439705, 'Total loss': 0.33975123872439705}
2022-11-28 01:09:13,678 INFO:     Found new best model at epoch 23
2022-11-28 01:09:13,679 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:13,679 INFO:     Epoch: 24
2022-11-28 01:09:14,422 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40114151246168395, 'Total loss': 0.40114151246168395} | train loss {'Reaction outcome loss': 0.3386610354927759, 'Total loss': 0.3386610354927759}
2022-11-28 01:09:14,422 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:14,422 INFO:     Epoch: 25
2022-11-28 01:09:15,171 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40926403450694954, 'Total loss': 0.40926403450694954} | train loss {'Reaction outcome loss': 0.3281401994548017, 'Total loss': 0.3281401994548017}
2022-11-28 01:09:15,171 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:15,172 INFO:     Epoch: 26
2022-11-28 01:09:15,921 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4143832295455716, 'Total loss': 0.4143832295455716} | train loss {'Reaction outcome loss': 0.3369642366024275, 'Total loss': 0.3369642366024275}
2022-11-28 01:09:15,921 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:15,921 INFO:     Epoch: 27
2022-11-28 01:09:16,664 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4414125003597953, 'Total loss': 0.4414125003597953} | train loss {'Reaction outcome loss': 0.3318067087731775, 'Total loss': 0.3318067087731775}
2022-11-28 01:09:16,664 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:16,664 INFO:     Epoch: 28
2022-11-28 01:09:17,410 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45215281200679863, 'Total loss': 0.45215281200679863} | train loss {'Reaction outcome loss': 0.3280522596511629, 'Total loss': 0.3280522596511629}
2022-11-28 01:09:17,410 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:17,410 INFO:     Epoch: 29
2022-11-28 01:09:18,155 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40920289707454766, 'Total loss': 0.40920289707454766} | train loss {'Reaction outcome loss': 0.32818469197879874, 'Total loss': 0.32818469197879874}
2022-11-28 01:09:18,155 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:18,156 INFO:     Epoch: 30
2022-11-28 01:09:18,904 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4007392657751387, 'Total loss': 0.4007392657751387} | train loss {'Reaction outcome loss': 0.32335085824372306, 'Total loss': 0.32335085824372306}
2022-11-28 01:09:18,904 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:18,904 INFO:     Epoch: 31
2022-11-28 01:09:19,647 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4425096247683872, 'Total loss': 0.4425096247683872} | train loss {'Reaction outcome loss': 0.3256528749761562, 'Total loss': 0.3256528749761562}
2022-11-28 01:09:19,647 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:19,647 INFO:     Epoch: 32
2022-11-28 01:09:20,391 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41426866772499954, 'Total loss': 0.41426866772499954} | train loss {'Reaction outcome loss': 0.33065230603660306, 'Total loss': 0.33065230603660306}
2022-11-28 01:09:20,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:20,391 INFO:     Epoch: 33
2022-11-28 01:09:21,133 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4439417997544462, 'Total loss': 0.4439417997544462} | train loss {'Reaction outcome loss': 0.3257175231833131, 'Total loss': 0.3257175231833131}
2022-11-28 01:09:21,133 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:21,134 INFO:     Epoch: 34
2022-11-28 01:09:21,879 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4307850396091288, 'Total loss': 0.4307850396091288} | train loss {'Reaction outcome loss': 0.3270231966650294, 'Total loss': 0.3270231966650294}
2022-11-28 01:09:21,879 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:21,879 INFO:     Epoch: 35
2022-11-28 01:09:22,627 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.429678889838132, 'Total loss': 0.429678889838132} | train loss {'Reaction outcome loss': 0.32709457010271087, 'Total loss': 0.32709457010271087}
2022-11-28 01:09:22,627 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:22,627 INFO:     Epoch: 36
2022-11-28 01:09:23,374 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5227839398113164, 'Total loss': 0.5227839398113164} | train loss {'Reaction outcome loss': 0.3246470732434142, 'Total loss': 0.3246470732434142}
2022-11-28 01:09:23,374 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:23,374 INFO:     Epoch: 37
2022-11-28 01:09:24,119 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4235485592349009, 'Total loss': 0.4235485592349009} | train loss {'Reaction outcome loss': 0.3230685798391219, 'Total loss': 0.3230685798391219}
2022-11-28 01:09:24,120 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:24,120 INFO:     Epoch: 38
2022-11-28 01:09:24,865 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4485998045314442, 'Total loss': 0.4485998045314442} | train loss {'Reaction outcome loss': 0.32002467487848574, 'Total loss': 0.32002467487848574}
2022-11-28 01:09:24,865 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:24,865 INFO:     Epoch: 39
2022-11-28 01:09:25,605 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4601738906719468, 'Total loss': 0.4601738906719468} | train loss {'Reaction outcome loss': 0.33441137264092125, 'Total loss': 0.33441137264092125}
2022-11-28 01:09:25,606 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:25,607 INFO:     Epoch: 40
2022-11-28 01:09:26,350 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40360617197372695, 'Total loss': 0.40360617197372695} | train loss {'Reaction outcome loss': 0.3305539731236716, 'Total loss': 0.3305539731236716}
2022-11-28 01:09:26,350 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:26,350 INFO:     Epoch: 41
2022-11-28 01:09:27,098 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40144460411234334, 'Total loss': 0.40144460411234334} | train loss {'Reaction outcome loss': 0.316005798387191, 'Total loss': 0.316005798387191}
2022-11-28 01:09:27,098 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:27,098 INFO:     Epoch: 42
2022-11-28 01:09:27,843 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45512438463893806, 'Total loss': 0.45512438463893806} | train loss {'Reaction outcome loss': 0.32249092719247263, 'Total loss': 0.32249092719247263}
2022-11-28 01:09:27,843 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:27,844 INFO:     Epoch: 43
2022-11-28 01:09:28,591 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44188993017781864, 'Total loss': 0.44188993017781864} | train loss {'Reaction outcome loss': 0.3247627636357661, 'Total loss': 0.3247627636357661}
2022-11-28 01:09:28,592 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:28,592 INFO:     Epoch: 44
2022-11-28 01:09:29,340 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41772167350758205, 'Total loss': 0.41772167350758205} | train loss {'Reaction outcome loss': 0.3167320160315402, 'Total loss': 0.3167320160315402}
2022-11-28 01:09:29,340 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:29,340 INFO:     Epoch: 45
2022-11-28 01:09:30,085 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44650170782750304, 'Total loss': 0.44650170782750304} | train loss {'Reaction outcome loss': 0.32787832490078384, 'Total loss': 0.32787832490078384}
2022-11-28 01:09:30,085 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:30,085 INFO:     Epoch: 46
2022-11-28 01:09:30,838 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4240750711072575, 'Total loss': 0.4240750711072575} | train loss {'Reaction outcome loss': 0.3294390786979948, 'Total loss': 0.3294390786979948}
2022-11-28 01:09:30,838 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:30,838 INFO:     Epoch: 47
2022-11-28 01:09:31,586 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4395136298103766, 'Total loss': 0.4395136298103766} | train loss {'Reaction outcome loss': 0.3156259448357647, 'Total loss': 0.3156259448357647}
2022-11-28 01:09:31,586 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:31,586 INFO:     Epoch: 48
2022-11-28 01:09:32,333 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42007857256314973, 'Total loss': 0.42007857256314973} | train loss {'Reaction outcome loss': 0.3199429421670615, 'Total loss': 0.3199429421670615}
2022-11-28 01:09:32,334 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:32,334 INFO:     Epoch: 49
2022-11-28 01:09:33,082 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.400436037982052, 'Total loss': 0.400436037982052} | train loss {'Reaction outcome loss': 0.3234875344581181, 'Total loss': 0.3234875344581181}
2022-11-28 01:09:33,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:33,083 INFO:     Epoch: 50
2022-11-28 01:09:33,830 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42966210740533745, 'Total loss': 0.42966210740533745} | train loss {'Reaction outcome loss': 0.3319791868449219, 'Total loss': 0.3319791868449219}
2022-11-28 01:09:33,830 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:33,830 INFO:     Epoch: 51
2022-11-28 01:09:34,581 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42228035798127, 'Total loss': 0.42228035798127} | train loss {'Reaction outcome loss': 0.31947044929068896, 'Total loss': 0.31947044929068896}
2022-11-28 01:09:34,581 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:34,581 INFO:     Epoch: 52
2022-11-28 01:09:35,327 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42755349657752295, 'Total loss': 0.42755349657752295} | train loss {'Reaction outcome loss': 0.31242322122618077, 'Total loss': 0.31242322122618077}
2022-11-28 01:09:35,327 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:35,327 INFO:     Epoch: 53
2022-11-28 01:09:36,072 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40868870609185914, 'Total loss': 0.40868870609185914} | train loss {'Reaction outcome loss': 0.31577962549823907, 'Total loss': 0.31577962549823907}
2022-11-28 01:09:36,072 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:36,072 INFO:     Epoch: 54
2022-11-28 01:09:36,820 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4247962429442189, 'Total loss': 0.4247962429442189} | train loss {'Reaction outcome loss': 0.3123993961771409, 'Total loss': 0.3123993961771409}
2022-11-28 01:09:36,820 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:36,820 INFO:     Epoch: 55
2022-11-28 01:09:37,567 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4074940945614468, 'Total loss': 0.4074940945614468} | train loss {'Reaction outcome loss': 0.3256774871880489, 'Total loss': 0.3256774871880489}
2022-11-28 01:09:37,567 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:37,567 INFO:     Epoch: 56
2022-11-28 01:09:38,312 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4216147569770163, 'Total loss': 0.4216147569770163} | train loss {'Reaction outcome loss': 0.3226635952990863, 'Total loss': 0.3226635952990863}
2022-11-28 01:09:38,312 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:38,312 INFO:     Epoch: 57
2022-11-28 01:09:39,057 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4157376763495532, 'Total loss': 0.4157376763495532} | train loss {'Reaction outcome loss': 0.318071563968495, 'Total loss': 0.318071563968495}
2022-11-28 01:09:39,058 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:39,058 INFO:     Epoch: 58
2022-11-28 01:09:39,805 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43050240217284724, 'Total loss': 0.43050240217284724} | train loss {'Reaction outcome loss': 0.3199025659010776, 'Total loss': 0.3199025659010776}
2022-11-28 01:09:39,805 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:39,805 INFO:     Epoch: 59
2022-11-28 01:09:40,556 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4402844430032102, 'Total loss': 0.4402844430032102} | train loss {'Reaction outcome loss': 0.32171810337252194, 'Total loss': 0.32171810337252194}
2022-11-28 01:09:40,556 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:40,557 INFO:     Epoch: 60
2022-11-28 01:09:41,304 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4114104521206834, 'Total loss': 0.4114104521206834} | train loss {'Reaction outcome loss': 0.3146170350392499, 'Total loss': 0.3146170350392499}
2022-11-28 01:09:41,304 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:41,304 INFO:     Epoch: 61
2022-11-28 01:09:42,050 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40725952048193326, 'Total loss': 0.40725952048193326} | train loss {'Reaction outcome loss': 0.3167385893663572, 'Total loss': 0.3167385893663572}
2022-11-28 01:09:42,050 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:42,050 INFO:     Epoch: 62
2022-11-28 01:09:42,798 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45718585225668823, 'Total loss': 0.45718585225668823} | train loss {'Reaction outcome loss': 0.3195683090316673, 'Total loss': 0.3195683090316673}
2022-11-28 01:09:42,798 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:42,798 INFO:     Epoch: 63
2022-11-28 01:09:43,544 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4135198538953608, 'Total loss': 0.4135198538953608} | train loss {'Reaction outcome loss': 0.3223957993811177, 'Total loss': 0.3223957993811177}
2022-11-28 01:09:43,544 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:43,544 INFO:     Epoch: 64
2022-11-28 01:09:44,291 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41428282179615716, 'Total loss': 0.41428282179615716} | train loss {'Reaction outcome loss': 0.31722305832250464, 'Total loss': 0.31722305832250464}
2022-11-28 01:09:44,291 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:44,291 INFO:     Epoch: 65
2022-11-28 01:09:45,046 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4319276078180833, 'Total loss': 0.4319276078180833} | train loss {'Reaction outcome loss': 0.3142295869427823, 'Total loss': 0.3142295869427823}
2022-11-28 01:09:45,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:45,047 INFO:     Epoch: 66
2022-11-28 01:09:45,811 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4228870076212016, 'Total loss': 0.4228870076212016} | train loss {'Reaction outcome loss': 0.3094932569881841, 'Total loss': 0.3094932569881841}
2022-11-28 01:09:45,811 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:45,811 INFO:     Epoch: 67
2022-11-28 01:09:46,567 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42546704242175276, 'Total loss': 0.42546704242175276} | train loss {'Reaction outcome loss': 0.31476869349998815, 'Total loss': 0.31476869349998815}
2022-11-28 01:09:46,567 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:46,567 INFO:     Epoch: 68
2022-11-28 01:09:47,321 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39373486235060473, 'Total loss': 0.39373486235060473} | train loss {'Reaction outcome loss': 0.31581203441225714, 'Total loss': 0.31581203441225714}
2022-11-28 01:09:47,321 INFO:     Found new best model at epoch 68
2022-11-28 01:09:47,322 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:47,322 INFO:     Epoch: 69
2022-11-28 01:09:48,072 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41996964372017165, 'Total loss': 0.41996964372017165} | train loss {'Reaction outcome loss': 0.31455743261763164, 'Total loss': 0.31455743261763164}
2022-11-28 01:09:48,072 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:48,072 INFO:     Epoch: 70
2022-11-28 01:09:48,825 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40641931478272786, 'Total loss': 0.40641931478272786} | train loss {'Reaction outcome loss': 0.318112050483544, 'Total loss': 0.318112050483544}
2022-11-28 01:09:48,825 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:48,825 INFO:     Epoch: 71
2022-11-28 01:09:49,570 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4156911942091855, 'Total loss': 0.4156911942091855} | train loss {'Reaction outcome loss': 0.31558764077002005, 'Total loss': 0.31558764077002005}
2022-11-28 01:09:49,570 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:49,570 INFO:     Epoch: 72
2022-11-28 01:09:50,317 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4144331558861516, 'Total loss': 0.4144331558861516} | train loss {'Reaction outcome loss': 0.3120272878196932, 'Total loss': 0.3120272878196932}
2022-11-28 01:09:50,318 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:50,318 INFO:     Epoch: 73
2022-11-28 01:09:51,064 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43590319427576935, 'Total loss': 0.43590319427576935} | train loss {'Reaction outcome loss': 0.31851753986050046, 'Total loss': 0.31851753986050046}
2022-11-28 01:09:51,065 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:51,065 INFO:     Epoch: 74
2022-11-28 01:09:51,816 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43658526546575804, 'Total loss': 0.43658526546575804} | train loss {'Reaction outcome loss': 0.3098120851622474, 'Total loss': 0.3098120851622474}
2022-11-28 01:09:51,817 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:51,817 INFO:     Epoch: 75
2022-11-28 01:09:52,563 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4123383645306934, 'Total loss': 0.4123383645306934} | train loss {'Reaction outcome loss': 0.3161431366968299, 'Total loss': 0.3161431366968299}
2022-11-28 01:09:52,564 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:52,564 INFO:     Epoch: 76
2022-11-28 01:09:53,310 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4115239605307579, 'Total loss': 0.4115239605307579} | train loss {'Reaction outcome loss': 0.308439378371282, 'Total loss': 0.308439378371282}
2022-11-28 01:09:53,310 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:53,310 INFO:     Epoch: 77
2022-11-28 01:09:54,059 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4174868433990262, 'Total loss': 0.4174868433990262} | train loss {'Reaction outcome loss': 0.31631869002575835, 'Total loss': 0.31631869002575835}
2022-11-28 01:09:54,059 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:54,059 INFO:     Epoch: 78
2022-11-28 01:09:54,810 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39566952718252485, 'Total loss': 0.39566952718252485} | train loss {'Reaction outcome loss': 0.3182226641464137, 'Total loss': 0.3182226641464137}
2022-11-28 01:09:54,810 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:54,810 INFO:     Epoch: 79
2022-11-28 01:09:55,561 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41414595615457406, 'Total loss': 0.41414595615457406} | train loss {'Reaction outcome loss': 0.31764422333048237, 'Total loss': 0.31764422333048237}
2022-11-28 01:09:55,562 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:55,562 INFO:     Epoch: 80
2022-11-28 01:09:56,312 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4282029338858344, 'Total loss': 0.4282029338858344} | train loss {'Reaction outcome loss': 0.32126476342279103, 'Total loss': 0.32126476342279103}
2022-11-28 01:09:56,313 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:56,313 INFO:     Epoch: 81
2022-11-28 01:09:57,062 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4146654023365541, 'Total loss': 0.4146654023365541} | train loss {'Reaction outcome loss': 0.3168437817254134, 'Total loss': 0.3168437817254134}
2022-11-28 01:09:57,062 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:57,063 INFO:     Epoch: 82
2022-11-28 01:09:57,810 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41347537528384815, 'Total loss': 0.41347537528384815} | train loss {'Reaction outcome loss': 0.31645159818412316, 'Total loss': 0.31645159818412316}
2022-11-28 01:09:57,810 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:57,810 INFO:     Epoch: 83
2022-11-28 01:09:58,556 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42452252622355113, 'Total loss': 0.42452252622355113} | train loss {'Reaction outcome loss': 0.3196529532151838, 'Total loss': 0.3196529532151838}
2022-11-28 01:09:58,556 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:58,556 INFO:     Epoch: 84
2022-11-28 01:09:59,301 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4176194796508009, 'Total loss': 0.4176194796508009} | train loss {'Reaction outcome loss': 0.3131704164308406, 'Total loss': 0.3131704164308406}
2022-11-28 01:09:59,301 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:09:59,301 INFO:     Epoch: 85
2022-11-28 01:10:00,049 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4171528992327777, 'Total loss': 0.4171528992327777} | train loss {'Reaction outcome loss': 0.312172066807116, 'Total loss': 0.312172066807116}
2022-11-28 01:10:00,050 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:00,051 INFO:     Epoch: 86
2022-11-28 01:10:00,799 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4095670689236034, 'Total loss': 0.4095670689236034} | train loss {'Reaction outcome loss': 0.3123483223419997, 'Total loss': 0.3123483223419997}
2022-11-28 01:10:00,799 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:00,799 INFO:     Epoch: 87
2022-11-28 01:10:01,548 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4050860289822925, 'Total loss': 0.4050860289822925} | train loss {'Reaction outcome loss': 0.3166405524637911, 'Total loss': 0.3166405524637911}
2022-11-28 01:10:01,548 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:01,548 INFO:     Epoch: 88
2022-11-28 01:10:02,296 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4112863391637802, 'Total loss': 0.4112863391637802} | train loss {'Reaction outcome loss': 0.3106390085191496, 'Total loss': 0.3106390085191496}
2022-11-28 01:10:02,297 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:02,297 INFO:     Epoch: 89
2022-11-28 01:10:03,043 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40292623232711444, 'Total loss': 0.40292623232711444} | train loss {'Reaction outcome loss': 0.3127215064521278, 'Total loss': 0.3127215064521278}
2022-11-28 01:10:03,043 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:03,043 INFO:     Epoch: 90
2022-11-28 01:10:03,789 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4304289689118212, 'Total loss': 0.4304289689118212} | train loss {'Reaction outcome loss': 0.3134374269734948, 'Total loss': 0.3134374269734948}
2022-11-28 01:10:03,789 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:03,789 INFO:     Epoch: 91
2022-11-28 01:10:04,536 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42168239114636724, 'Total loss': 0.42168239114636724} | train loss {'Reaction outcome loss': 0.3060309766160865, 'Total loss': 0.3060309766160865}
2022-11-28 01:10:04,536 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:04,536 INFO:     Epoch: 92
2022-11-28 01:10:05,285 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46675602515990083, 'Total loss': 0.46675602515990083} | train loss {'Reaction outcome loss': 0.3052742775349367, 'Total loss': 0.3052742775349367}
2022-11-28 01:10:05,285 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:05,285 INFO:     Epoch: 93
2022-11-28 01:10:06,031 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41555196622555907, 'Total loss': 0.41555196622555907} | train loss {'Reaction outcome loss': 0.3159829801879823, 'Total loss': 0.3159829801879823}
2022-11-28 01:10:06,031 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:06,031 INFO:     Epoch: 94
2022-11-28 01:10:06,779 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46167889948595653, 'Total loss': 0.46167889948595653} | train loss {'Reaction outcome loss': 0.3146257559738813, 'Total loss': 0.3146257559738813}
2022-11-28 01:10:06,780 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:06,780 INFO:     Epoch: 95
2022-11-28 01:10:07,528 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4350479966537519, 'Total loss': 0.4350479966537519} | train loss {'Reaction outcome loss': 0.3160349905731217, 'Total loss': 0.3160349905731217}
2022-11-28 01:10:07,528 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:07,528 INFO:     Epoch: 96
2022-11-28 01:10:08,277 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40719903886995534, 'Total loss': 0.40719903886995534} | train loss {'Reaction outcome loss': 0.31449768572084363, 'Total loss': 0.31449768572084363}
2022-11-28 01:10:08,277 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:08,277 INFO:     Epoch: 97
2022-11-28 01:10:09,024 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4200136959552765, 'Total loss': 0.4200136959552765} | train loss {'Reaction outcome loss': 0.31420036451891065, 'Total loss': 0.31420036451891065}
2022-11-28 01:10:09,024 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:09,024 INFO:     Epoch: 98
2022-11-28 01:10:09,769 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4166989089413123, 'Total loss': 0.4166989089413123} | train loss {'Reaction outcome loss': 0.3144292798373968, 'Total loss': 0.3144292798373968}
2022-11-28 01:10:09,769 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:09,769 INFO:     Epoch: 99
2022-11-28 01:10:10,519 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39402508142996917, 'Total loss': 0.39402508142996917} | train loss {'Reaction outcome loss': 0.3182854064770283, 'Total loss': 0.3182854064770283}
2022-11-28 01:10:10,519 INFO:     Best model found after epoch 69 of 100.
2022-11-28 01:10:10,519 INFO:   Done with stage: TRAINING
2022-11-28 01:10:10,519 INFO:   Starting stage: EVALUATION
2022-11-28 01:10:10,634 INFO:   Done with stage: EVALUATION
2022-11-28 01:10:10,634 INFO:   Leaving out SEQ value Fold_5
2022-11-28 01:10:10,647 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 01:10:10,647 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:10:11,287 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:10:11,287 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:10:11,358 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:10:11,358 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:10:11,358 INFO:     No hyperparam tuning for this model
2022-11-28 01:10:11,358 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:10:11,358 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:10:11,359 INFO:     None feature selector for col prot
2022-11-28 01:10:11,359 INFO:     None feature selector for col prot
2022-11-28 01:10:11,359 INFO:     None feature selector for col prot
2022-11-28 01:10:11,359 INFO:     None feature selector for col chem
2022-11-28 01:10:11,360 INFO:     None feature selector for col chem
2022-11-28 01:10:11,360 INFO:     None feature selector for col chem
2022-11-28 01:10:11,360 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:10:11,360 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:10:11,361 INFO:     Number of params in model 169741
2022-11-28 01:10:11,364 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:10:11,364 INFO:   Starting stage: TRAINING
2022-11-28 01:10:11,417 INFO:     Val loss before train {'Reaction outcome loss': 1.0409438102082773, 'Total loss': 1.0409438102082773}
2022-11-28 01:10:11,417 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:11,418 INFO:     Epoch: 0
2022-11-28 01:10:12,158 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5808541791682894, 'Total loss': 0.5808541791682894} | train loss {'Reaction outcome loss': 0.6359791630192807, 'Total loss': 0.6359791630192807}
2022-11-28 01:10:12,158 INFO:     Found new best model at epoch 0
2022-11-28 01:10:12,158 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:12,159 INFO:     Epoch: 1
2022-11-28 01:10:12,898 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5278599506074731, 'Total loss': 0.5278599506074731} | train loss {'Reaction outcome loss': 0.5002744644277008, 'Total loss': 0.5002744644277008}
2022-11-28 01:10:12,898 INFO:     Found new best model at epoch 1
2022-11-28 01:10:12,899 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:12,899 INFO:     Epoch: 2
2022-11-28 01:10:13,644 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.518851617181843, 'Total loss': 0.518851617181843} | train loss {'Reaction outcome loss': 0.4521404841409521, 'Total loss': 0.4521404841409521}
2022-11-28 01:10:13,644 INFO:     Found new best model at epoch 2
2022-11-28 01:10:13,645 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:13,645 INFO:     Epoch: 3
2022-11-28 01:10:14,389 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5316049734299834, 'Total loss': 0.5316049734299834} | train loss {'Reaction outcome loss': 0.4366770775211967, 'Total loss': 0.4366770775211967}
2022-11-28 01:10:14,389 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:14,389 INFO:     Epoch: 4
2022-11-28 01:10:15,132 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5010137381878766, 'Total loss': 0.5010137381878766} | train loss {'Reaction outcome loss': 0.41694125899600115, 'Total loss': 0.41694125899600115}
2022-11-28 01:10:15,132 INFO:     Found new best model at epoch 4
2022-11-28 01:10:15,133 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:15,133 INFO:     Epoch: 5
2022-11-28 01:10:15,878 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49824862656268204, 'Total loss': 0.49824862656268204} | train loss {'Reaction outcome loss': 0.4075064649466078, 'Total loss': 0.4075064649466078}
2022-11-28 01:10:15,878 INFO:     Found new best model at epoch 5
2022-11-28 01:10:15,879 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:15,879 INFO:     Epoch: 6
2022-11-28 01:10:16,620 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5005933466282758, 'Total loss': 0.5005933466282758} | train loss {'Reaction outcome loss': 0.39697018151099867, 'Total loss': 0.39697018151099867}
2022-11-28 01:10:16,620 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:16,620 INFO:     Epoch: 7
2022-11-28 01:10:17,363 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5104498141868548, 'Total loss': 0.5104498141868548} | train loss {'Reaction outcome loss': 0.39127040105430705, 'Total loss': 0.39127040105430705}
2022-11-28 01:10:17,363 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:17,364 INFO:     Epoch: 8
2022-11-28 01:10:18,105 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46221028471534903, 'Total loss': 0.46221028471534903} | train loss {'Reaction outcome loss': 0.3803249027444284, 'Total loss': 0.3803249027444284}
2022-11-28 01:10:18,106 INFO:     Found new best model at epoch 8
2022-11-28 01:10:18,106 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:18,107 INFO:     Epoch: 9
2022-11-28 01:10:18,854 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5265339298004453, 'Total loss': 0.5265339298004453} | train loss {'Reaction outcome loss': 0.37819329067039104, 'Total loss': 0.37819329067039104}
2022-11-28 01:10:18,855 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:18,855 INFO:     Epoch: 10
2022-11-28 01:10:19,603 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47137563540176913, 'Total loss': 0.47137563540176913} | train loss {'Reaction outcome loss': 0.3801697087794663, 'Total loss': 0.3801697087794663}
2022-11-28 01:10:19,603 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:19,603 INFO:     Epoch: 11
2022-11-28 01:10:20,349 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5192220502279021, 'Total loss': 0.5192220502279021} | train loss {'Reaction outcome loss': 0.40031811262401734, 'Total loss': 0.40031811262401734}
2022-11-28 01:10:20,350 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:20,350 INFO:     Epoch: 12
2022-11-28 01:10:21,096 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4959804561327804, 'Total loss': 0.4959804561327804} | train loss {'Reaction outcome loss': 0.3671037996195347, 'Total loss': 0.3671037996195347}
2022-11-28 01:10:21,097 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:21,097 INFO:     Epoch: 13
2022-11-28 01:10:21,844 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48862771080298856, 'Total loss': 0.48862771080298856} | train loss {'Reaction outcome loss': 0.3725636586215091, 'Total loss': 0.3725636586215091}
2022-11-28 01:10:21,845 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:21,845 INFO:     Epoch: 14
2022-11-28 01:10:22,588 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48850624364885414, 'Total loss': 0.48850624364885414} | train loss {'Reaction outcome loss': 0.36608458553188244, 'Total loss': 0.36608458553188244}
2022-11-28 01:10:22,589 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:22,589 INFO:     Epoch: 15
2022-11-28 01:10:23,331 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45612136545506393, 'Total loss': 0.45612136545506393} | train loss {'Reaction outcome loss': 0.3548949344407933, 'Total loss': 0.3548949344407933}
2022-11-28 01:10:23,331 INFO:     Found new best model at epoch 15
2022-11-28 01:10:23,332 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:23,332 INFO:     Epoch: 16
2022-11-28 01:10:24,074 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47005557505921886, 'Total loss': 0.47005557505921886} | train loss {'Reaction outcome loss': 0.36327562201391106, 'Total loss': 0.36327562201391106}
2022-11-28 01:10:24,074 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:24,074 INFO:     Epoch: 17
2022-11-28 01:10:24,814 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45949171991510823, 'Total loss': 0.45949171991510823} | train loss {'Reaction outcome loss': 0.3498128465214661, 'Total loss': 0.3498128465214661}
2022-11-28 01:10:24,814 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:24,815 INFO:     Epoch: 18
2022-11-28 01:10:25,552 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4632301259447228, 'Total loss': 0.4632301259447228} | train loss {'Reaction outcome loss': 0.34561661805821814, 'Total loss': 0.34561661805821814}
2022-11-28 01:10:25,552 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:25,552 INFO:     Epoch: 19
2022-11-28 01:10:26,295 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4646595498038964, 'Total loss': 0.4646595498038964} | train loss {'Reaction outcome loss': 0.34861816514117516, 'Total loss': 0.34861816514117516}
2022-11-28 01:10:26,295 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:26,295 INFO:     Epoch: 20
2022-11-28 01:10:27,038 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4692811739038337, 'Total loss': 0.4692811739038337} | train loss {'Reaction outcome loss': 0.3437181352439755, 'Total loss': 0.3437181352439755}
2022-11-28 01:10:27,038 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:27,038 INFO:     Epoch: 21
2022-11-28 01:10:27,781 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4691668647256764, 'Total loss': 0.4691668647256764} | train loss {'Reaction outcome loss': 0.34188214749821766, 'Total loss': 0.34188214749821766}
2022-11-28 01:10:27,781 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:27,781 INFO:     Epoch: 22
2022-11-28 01:10:28,525 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4510547715154561, 'Total loss': 0.4510547715154561} | train loss {'Reaction outcome loss': 0.34264538057057964, 'Total loss': 0.34264538057057964}
2022-11-28 01:10:28,526 INFO:     Found new best model at epoch 22
2022-11-28 01:10:28,526 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:28,527 INFO:     Epoch: 23
2022-11-28 01:10:29,269 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4868238161910664, 'Total loss': 0.4868238161910664} | train loss {'Reaction outcome loss': 0.3459031309495088, 'Total loss': 0.3459031309495088}
2022-11-28 01:10:29,269 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:29,269 INFO:     Epoch: 24
2022-11-28 01:10:30,010 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45594407855109736, 'Total loss': 0.45594407855109736} | train loss {'Reaction outcome loss': 0.345774516949679, 'Total loss': 0.345774516949679}
2022-11-28 01:10:30,010 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:30,010 INFO:     Epoch: 25
2022-11-28 01:10:30,753 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45469464090737427, 'Total loss': 0.45469464090737427} | train loss {'Reaction outcome loss': 0.3301725603549587, 'Total loss': 0.3301725603549587}
2022-11-28 01:10:30,753 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:30,753 INFO:     Epoch: 26
2022-11-28 01:10:31,498 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46902271394025197, 'Total loss': 0.46902271394025197} | train loss {'Reaction outcome loss': 0.33873627128773315, 'Total loss': 0.33873627128773315}
2022-11-28 01:10:31,498 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:31,498 INFO:     Epoch: 27
2022-11-28 01:10:32,241 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4452159548686309, 'Total loss': 0.4452159548686309} | train loss {'Reaction outcome loss': 0.33160460699606037, 'Total loss': 0.33160460699606037}
2022-11-28 01:10:32,241 INFO:     Found new best model at epoch 27
2022-11-28 01:10:32,242 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:32,242 INFO:     Epoch: 28
2022-11-28 01:10:32,984 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.468064582483335, 'Total loss': 0.468064582483335} | train loss {'Reaction outcome loss': 0.31914391756238725, 'Total loss': 0.31914391756238725}
2022-11-28 01:10:32,985 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:32,985 INFO:     Epoch: 29
2022-11-28 01:10:33,726 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46737225793979387, 'Total loss': 0.46737225793979387} | train loss {'Reaction outcome loss': 0.3334729368779582, 'Total loss': 0.3334729368779582}
2022-11-28 01:10:33,726 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:33,726 INFO:     Epoch: 30
2022-11-28 01:10:34,473 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4589592872018164, 'Total loss': 0.4589592872018164} | train loss {'Reaction outcome loss': 0.3279437114171654, 'Total loss': 0.3279437114171654}
2022-11-28 01:10:34,473 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:34,473 INFO:     Epoch: 31
2022-11-28 01:10:35,218 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4471041973341595, 'Total loss': 0.4471041973341595} | train loss {'Reaction outcome loss': 0.32289093678538133, 'Total loss': 0.32289093678538133}
2022-11-28 01:10:35,219 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:35,219 INFO:     Epoch: 32
2022-11-28 01:10:35,965 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48843648623336444, 'Total loss': 0.48843648623336444} | train loss {'Reaction outcome loss': 0.3243405902494303, 'Total loss': 0.3243405902494303}
2022-11-28 01:10:35,966 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:35,966 INFO:     Epoch: 33
2022-11-28 01:10:36,710 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46887338533997536, 'Total loss': 0.46887338533997536} | train loss {'Reaction outcome loss': 0.3338009676469965, 'Total loss': 0.3338009676469965}
2022-11-28 01:10:36,710 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:36,710 INFO:     Epoch: 34
2022-11-28 01:10:37,456 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46602630496702413, 'Total loss': 0.46602630496702413} | train loss {'Reaction outcome loss': 0.34124212555195155, 'Total loss': 0.34124212555195155}
2022-11-28 01:10:37,456 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:37,456 INFO:     Epoch: 35
2022-11-28 01:10:38,203 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47250120155513287, 'Total loss': 0.47250120155513287} | train loss {'Reaction outcome loss': 0.3396665275639851, 'Total loss': 0.3396665275639851}
2022-11-28 01:10:38,204 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:38,204 INFO:     Epoch: 36
2022-11-28 01:10:38,951 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47798434644937515, 'Total loss': 0.47798434644937515} | train loss {'Reaction outcome loss': 0.3260173534898809, 'Total loss': 0.3260173534898809}
2022-11-28 01:10:38,951 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:38,951 INFO:     Epoch: 37
2022-11-28 01:10:39,698 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44406086511232634, 'Total loss': 0.44406086511232634} | train loss {'Reaction outcome loss': 0.32420549238560653, 'Total loss': 0.32420549238560653}
2022-11-28 01:10:39,698 INFO:     Found new best model at epoch 37
2022-11-28 01:10:39,699 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:39,699 INFO:     Epoch: 38
2022-11-28 01:10:40,442 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47172384980050003, 'Total loss': 0.47172384980050003} | train loss {'Reaction outcome loss': 0.3270654781808255, 'Total loss': 0.3270654781808255}
2022-11-28 01:10:40,442 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:40,442 INFO:     Epoch: 39
2022-11-28 01:10:41,186 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47104318372227927, 'Total loss': 0.47104318372227927} | train loss {'Reaction outcome loss': 0.32209256430333744, 'Total loss': 0.32209256430333744}
2022-11-28 01:10:41,186 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:41,186 INFO:     Epoch: 40
2022-11-28 01:10:41,930 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48324211822314694, 'Total loss': 0.48324211822314694} | train loss {'Reaction outcome loss': 0.31129796136366694, 'Total loss': 0.31129796136366694}
2022-11-28 01:10:41,930 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:41,930 INFO:     Epoch: 41
2022-11-28 01:10:42,675 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.463504452935674, 'Total loss': 0.463504452935674} | train loss {'Reaction outcome loss': 0.3370162273346171, 'Total loss': 0.3370162273346171}
2022-11-28 01:10:42,676 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:42,676 INFO:     Epoch: 42
2022-11-28 01:10:43,419 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47095106982372026, 'Total loss': 0.47095106982372026} | train loss {'Reaction outcome loss': 0.3219729772361697, 'Total loss': 0.3219729772361697}
2022-11-28 01:10:43,419 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:43,420 INFO:     Epoch: 43
2022-11-28 01:10:44,160 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44260976361957466, 'Total loss': 0.44260976361957466} | train loss {'Reaction outcome loss': 0.3212079803350001, 'Total loss': 0.3212079803350001}
2022-11-28 01:10:44,160 INFO:     Found new best model at epoch 43
2022-11-28 01:10:44,161 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:44,161 INFO:     Epoch: 44
2022-11-28 01:10:44,907 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42432225664908235, 'Total loss': 0.42432225664908235} | train loss {'Reaction outcome loss': 0.3147468552114027, 'Total loss': 0.3147468552114027}
2022-11-28 01:10:44,907 INFO:     Found new best model at epoch 44
2022-11-28 01:10:44,908 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:44,908 INFO:     Epoch: 45
2022-11-28 01:10:45,653 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44690018926154484, 'Total loss': 0.44690018926154484} | train loss {'Reaction outcome loss': 0.33223283245616597, 'Total loss': 0.33223283245616597}
2022-11-28 01:10:45,653 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:45,653 INFO:     Epoch: 46
2022-11-28 01:10:46,399 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45520734566856513, 'Total loss': 0.45520734566856513} | train loss {'Reaction outcome loss': 0.3342945994997797, 'Total loss': 0.3342945994997797}
2022-11-28 01:10:46,399 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:46,399 INFO:     Epoch: 47
2022-11-28 01:10:47,143 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43557637752118433, 'Total loss': 0.43557637752118433} | train loss {'Reaction outcome loss': 0.36048698561032294, 'Total loss': 0.36048698561032294}
2022-11-28 01:10:47,143 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:47,143 INFO:     Epoch: 48
2022-11-28 01:10:47,884 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43943952023983, 'Total loss': 0.43943952023983} | train loss {'Reaction outcome loss': 0.3129527274262809, 'Total loss': 0.3129527274262809}
2022-11-28 01:10:47,885 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:47,885 INFO:     Epoch: 49
2022-11-28 01:10:48,628 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4571051841432398, 'Total loss': 0.4571051841432398} | train loss {'Reaction outcome loss': 0.3178360891577445, 'Total loss': 0.3178360891577445}
2022-11-28 01:10:48,629 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:48,629 INFO:     Epoch: 50
2022-11-28 01:10:49,379 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4424755671484904, 'Total loss': 0.4424755671484904} | train loss {'Reaction outcome loss': 0.31501933409613725, 'Total loss': 0.31501933409613725}
2022-11-28 01:10:49,379 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:49,379 INFO:     Epoch: 51
2022-11-28 01:10:50,122 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4503269290382212, 'Total loss': 0.4503269290382212} | train loss {'Reaction outcome loss': 0.31345594843268876, 'Total loss': 0.31345594843268876}
2022-11-28 01:10:50,122 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:50,122 INFO:     Epoch: 52
2022-11-28 01:10:50,868 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42373560199683363, 'Total loss': 0.42373560199683363} | train loss {'Reaction outcome loss': 0.333235911120046, 'Total loss': 0.333235911120046}
2022-11-28 01:10:50,868 INFO:     Found new best model at epoch 52
2022-11-28 01:10:50,869 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:50,869 INFO:     Epoch: 53
2022-11-28 01:10:51,617 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44396466186100786, 'Total loss': 0.44396466186100786} | train loss {'Reaction outcome loss': 0.3086684058544788, 'Total loss': 0.3086684058544788}
2022-11-28 01:10:51,617 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:51,617 INFO:     Epoch: 54
2022-11-28 01:10:52,363 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45384401150725107, 'Total loss': 0.45384401150725107} | train loss {'Reaction outcome loss': 0.3160953547971451, 'Total loss': 0.3160953547971451}
2022-11-28 01:10:52,363 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:52,363 INFO:     Epoch: 55
2022-11-28 01:10:53,107 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4684468097984791, 'Total loss': 0.4684468097984791} | train loss {'Reaction outcome loss': 0.31206341357788575, 'Total loss': 0.31206341357788575}
2022-11-28 01:10:53,107 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:53,107 INFO:     Epoch: 56
2022-11-28 01:10:53,850 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45017612691630016, 'Total loss': 0.45017612691630016} | train loss {'Reaction outcome loss': 0.3205023218051866, 'Total loss': 0.3205023218051866}
2022-11-28 01:10:53,850 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:53,850 INFO:     Epoch: 57
2022-11-28 01:10:54,595 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47843243791298434, 'Total loss': 0.47843243791298434} | train loss {'Reaction outcome loss': 0.32516168872354484, 'Total loss': 0.32516168872354484}
2022-11-28 01:10:54,595 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:54,595 INFO:     Epoch: 58
2022-11-28 01:10:55,341 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4353748255155303, 'Total loss': 0.4353748255155303} | train loss {'Reaction outcome loss': 0.32871862581972533, 'Total loss': 0.32871862581972533}
2022-11-28 01:10:55,341 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:55,341 INFO:     Epoch: 59
2022-11-28 01:10:56,084 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45344210212880914, 'Total loss': 0.45344210212880914} | train loss {'Reaction outcome loss': 0.3116125138740429, 'Total loss': 0.3116125138740429}
2022-11-28 01:10:56,084 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:56,084 INFO:     Epoch: 60
2022-11-28 01:10:56,830 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43468011339957063, 'Total loss': 0.43468011339957063} | train loss {'Reaction outcome loss': 0.3130492726981881, 'Total loss': 0.3130492726981881}
2022-11-28 01:10:56,830 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:56,830 INFO:     Epoch: 61
2022-11-28 01:10:57,575 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47403423657471483, 'Total loss': 0.47403423657471483} | train loss {'Reaction outcome loss': 0.3123974107726202, 'Total loss': 0.3123974107726202}
2022-11-28 01:10:57,575 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:57,575 INFO:     Epoch: 62
2022-11-28 01:10:58,322 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44547754119743, 'Total loss': 0.44547754119743} | train loss {'Reaction outcome loss': 0.31469146675064497, 'Total loss': 0.31469146675064497}
2022-11-28 01:10:58,322 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:58,323 INFO:     Epoch: 63
2022-11-28 01:10:59,067 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44097219509157265, 'Total loss': 0.44097219509157265} | train loss {'Reaction outcome loss': 0.32065790197868577, 'Total loss': 0.32065790197868577}
2022-11-28 01:10:59,068 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:59,068 INFO:     Epoch: 64
2022-11-28 01:10:59,813 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4590953412381085, 'Total loss': 0.4590953412381085} | train loss {'Reaction outcome loss': 0.3327289801317188, 'Total loss': 0.3327289801317188}
2022-11-28 01:10:59,814 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:10:59,814 INFO:     Epoch: 65
2022-11-28 01:11:00,558 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48185295577753673, 'Total loss': 0.48185295577753673} | train loss {'Reaction outcome loss': 0.3222539253563051, 'Total loss': 0.3222539253563051}
2022-11-28 01:11:00,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:00,558 INFO:     Epoch: 66
2022-11-28 01:11:01,302 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4499929642135447, 'Total loss': 0.4499929642135447} | train loss {'Reaction outcome loss': 0.327812267309017, 'Total loss': 0.327812267309017}
2022-11-28 01:11:01,302 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:01,302 INFO:     Epoch: 67
2022-11-28 01:11:02,047 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45886296745051036, 'Total loss': 0.45886296745051036} | train loss {'Reaction outcome loss': 0.3128079080328285, 'Total loss': 0.3128079080328285}
2022-11-28 01:11:02,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:02,047 INFO:     Epoch: 68
2022-11-28 01:11:02,790 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4503200262446295, 'Total loss': 0.4503200262446295} | train loss {'Reaction outcome loss': 0.3164443041307301, 'Total loss': 0.3164443041307301}
2022-11-28 01:11:02,790 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:02,790 INFO:     Epoch: 69
2022-11-28 01:11:03,534 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45125212901356543, 'Total loss': 0.45125212901356543} | train loss {'Reaction outcome loss': 0.31076119398238206, 'Total loss': 0.31076119398238206}
2022-11-28 01:11:03,534 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:03,534 INFO:     Epoch: 70
2022-11-28 01:11:04,278 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44323729520494287, 'Total loss': 0.44323729520494287} | train loss {'Reaction outcome loss': 0.3085034891269226, 'Total loss': 0.3085034891269226}
2022-11-28 01:11:04,278 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:04,278 INFO:     Epoch: 71
2022-11-28 01:11:05,024 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4448801898820834, 'Total loss': 0.4448801898820834} | train loss {'Reaction outcome loss': 0.3084200559342318, 'Total loss': 0.3084200559342318}
2022-11-28 01:11:05,024 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:05,024 INFO:     Epoch: 72
2022-11-28 01:11:05,767 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4319499717517333, 'Total loss': 0.4319499717517333} | train loss {'Reaction outcome loss': 0.3157802163001135, 'Total loss': 0.3157802163001135}
2022-11-28 01:11:05,768 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:05,768 INFO:     Epoch: 73
2022-11-28 01:11:06,508 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.452886855060404, 'Total loss': 0.452886855060404} | train loss {'Reaction outcome loss': 0.30672437238963207, 'Total loss': 0.30672437238963207}
2022-11-28 01:11:06,509 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:06,509 INFO:     Epoch: 74
2022-11-28 01:11:07,249 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45137146724896, 'Total loss': 0.45137146724896} | train loss {'Reaction outcome loss': 0.30508319867646644, 'Total loss': 0.30508319867646644}
2022-11-28 01:11:07,249 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:07,250 INFO:     Epoch: 75
2022-11-28 01:11:07,993 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47257485647093167, 'Total loss': 0.47257485647093167} | train loss {'Reaction outcome loss': 0.3095405253050057, 'Total loss': 0.3095405253050057}
2022-11-28 01:11:07,993 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:07,993 INFO:     Epoch: 76
2022-11-28 01:11:08,735 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45456949350508774, 'Total loss': 0.45456949350508774} | train loss {'Reaction outcome loss': 0.31169502417837847, 'Total loss': 0.31169502417837847}
2022-11-28 01:11:08,735 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:08,735 INFO:     Epoch: 77
2022-11-28 01:11:09,480 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46329492110420356, 'Total loss': 0.46329492110420356} | train loss {'Reaction outcome loss': 0.30537905166988916, 'Total loss': 0.30537905166988916}
2022-11-28 01:11:09,480 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:09,480 INFO:     Epoch: 78
2022-11-28 01:11:10,225 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4380159066482024, 'Total loss': 0.4380159066482024} | train loss {'Reaction outcome loss': 0.3164937875680399, 'Total loss': 0.3164937875680399}
2022-11-28 01:11:10,225 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:10,225 INFO:     Epoch: 79
2022-11-28 01:11:10,969 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42998140914873645, 'Total loss': 0.42998140914873645} | train loss {'Reaction outcome loss': 0.3122289872422875, 'Total loss': 0.3122289872422875}
2022-11-28 01:11:10,969 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:10,970 INFO:     Epoch: 80
2022-11-28 01:11:11,715 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45348222452131187, 'Total loss': 0.45348222452131187} | train loss {'Reaction outcome loss': 0.32708380256707853, 'Total loss': 0.32708380256707853}
2022-11-28 01:11:11,715 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:11,715 INFO:     Epoch: 81
2022-11-28 01:11:12,461 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4771428404545242, 'Total loss': 0.4771428404545242} | train loss {'Reaction outcome loss': 0.31677572144881677, 'Total loss': 0.31677572144881677}
2022-11-28 01:11:12,461 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:12,461 INFO:     Epoch: 82
2022-11-28 01:11:13,207 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45680838044394145, 'Total loss': 0.45680838044394145} | train loss {'Reaction outcome loss': 0.323235972569539, 'Total loss': 0.323235972569539}
2022-11-28 01:11:13,207 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:13,207 INFO:     Epoch: 83
2022-11-28 01:11:13,952 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4892928261648525, 'Total loss': 0.4892928261648525} | train loss {'Reaction outcome loss': 0.30939662239329535, 'Total loss': 0.30939662239329535}
2022-11-28 01:11:13,952 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:13,952 INFO:     Epoch: 84
2022-11-28 01:11:14,697 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41980391182005405, 'Total loss': 0.41980391182005405} | train loss {'Reaction outcome loss': 0.3150645810846797, 'Total loss': 0.3150645810846797}
2022-11-28 01:11:14,697 INFO:     Found new best model at epoch 84
2022-11-28 01:11:14,698 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:14,698 INFO:     Epoch: 85
2022-11-28 01:11:15,445 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4729346538131887, 'Total loss': 0.4729346538131887} | train loss {'Reaction outcome loss': 0.3041429978452231, 'Total loss': 0.3041429978452231}
2022-11-28 01:11:15,445 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:15,445 INFO:     Epoch: 86
2022-11-28 01:11:16,192 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47674290962855925, 'Total loss': 0.47674290962855925} | train loss {'Reaction outcome loss': 0.3189596694609931, 'Total loss': 0.3189596694609931}
2022-11-28 01:11:16,192 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:16,192 INFO:     Epoch: 87
2022-11-28 01:11:16,937 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4880897236818617, 'Total loss': 0.4880897236818617} | train loss {'Reaction outcome loss': 0.3092844802624667, 'Total loss': 0.3092844802624667}
2022-11-28 01:11:16,937 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:16,937 INFO:     Epoch: 88
2022-11-28 01:11:17,682 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4493405165320093, 'Total loss': 0.4493405165320093} | train loss {'Reaction outcome loss': 0.3128293116806972, 'Total loss': 0.3128293116806972}
2022-11-28 01:11:17,683 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:17,683 INFO:     Epoch: 89
2022-11-28 01:11:18,430 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45678016475655814, 'Total loss': 0.45678016475655814} | train loss {'Reaction outcome loss': 0.30658789030332795, 'Total loss': 0.30658789030332795}
2022-11-28 01:11:18,431 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:18,431 INFO:     Epoch: 90
2022-11-28 01:11:19,174 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45965016599405895, 'Total loss': 0.45965016599405895} | train loss {'Reaction outcome loss': 0.30020411116512197, 'Total loss': 0.30020411116512197}
2022-11-28 01:11:19,174 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:19,174 INFO:     Epoch: 91
2022-11-28 01:11:19,919 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4651281965727156, 'Total loss': 0.4651281965727156} | train loss {'Reaction outcome loss': 0.3094543542124723, 'Total loss': 0.3094543542124723}
2022-11-28 01:11:19,919 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:19,919 INFO:     Epoch: 92
2022-11-28 01:11:20,665 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4384844936430454, 'Total loss': 0.4384844936430454} | train loss {'Reaction outcome loss': 0.3263808819710424, 'Total loss': 0.3263808819710424}
2022-11-28 01:11:20,666 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:20,666 INFO:     Epoch: 93
2022-11-28 01:11:21,412 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47904610295187344, 'Total loss': 0.47904610295187344} | train loss {'Reaction outcome loss': 0.3097621880863842, 'Total loss': 0.3097621880863842}
2022-11-28 01:11:21,413 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:21,413 INFO:     Epoch: 94
2022-11-28 01:11:22,163 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4614782092923468, 'Total loss': 0.4614782092923468} | train loss {'Reaction outcome loss': 0.3004036604573852, 'Total loss': 0.3004036604573852}
2022-11-28 01:11:22,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:22,163 INFO:     Epoch: 95
2022-11-28 01:11:22,909 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47036592780866404, 'Total loss': 0.47036592780866404} | train loss {'Reaction outcome loss': 0.2929930313818368, 'Total loss': 0.2929930313818368}
2022-11-28 01:11:22,910 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:22,910 INFO:     Epoch: 96
2022-11-28 01:11:23,654 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45991698940369213, 'Total loss': 0.45991698940369213} | train loss {'Reaction outcome loss': 0.31041786996157544, 'Total loss': 0.31041786996157544}
2022-11-28 01:11:23,655 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:23,655 INFO:     Epoch: 97
2022-11-28 01:11:24,396 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47454475543715735, 'Total loss': 0.47454475543715735} | train loss {'Reaction outcome loss': 0.33749840948881527, 'Total loss': 0.33749840948881527}
2022-11-28 01:11:24,396 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:24,396 INFO:     Epoch: 98
2022-11-28 01:11:25,134 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46407536180181935, 'Total loss': 0.46407536180181935} | train loss {'Reaction outcome loss': 0.31815803279300875, 'Total loss': 0.31815803279300875}
2022-11-28 01:11:25,134 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:25,134 INFO:     Epoch: 99
2022-11-28 01:11:25,879 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5095088915391401, 'Total loss': 0.5095088915391401} | train loss {'Reaction outcome loss': 0.30506414039294244, 'Total loss': 0.30506414039294244}
2022-11-28 01:11:25,880 INFO:     Best model found after epoch 85 of 100.
2022-11-28 01:11:25,880 INFO:   Done with stage: TRAINING
2022-11-28 01:11:25,880 INFO:   Starting stage: EVALUATION
2022-11-28 01:11:26,001 INFO:   Done with stage: EVALUATION
2022-11-28 01:11:26,001 INFO:   Leaving out SEQ value Fold_6
2022-11-28 01:11:26,014 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 01:11:26,015 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:11:26,664 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:11:26,665 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:11:26,737 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:11:26,737 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:11:26,737 INFO:     No hyperparam tuning for this model
2022-11-28 01:11:26,737 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:11:26,737 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:11:26,738 INFO:     None feature selector for col prot
2022-11-28 01:11:26,738 INFO:     None feature selector for col prot
2022-11-28 01:11:26,738 INFO:     None feature selector for col prot
2022-11-28 01:11:26,738 INFO:     None feature selector for col chem
2022-11-28 01:11:26,739 INFO:     None feature selector for col chem
2022-11-28 01:11:26,739 INFO:     None feature selector for col chem
2022-11-28 01:11:26,739 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:11:26,739 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:11:26,740 INFO:     Number of params in model 169741
2022-11-28 01:11:26,743 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:11:26,744 INFO:   Starting stage: TRAINING
2022-11-28 01:11:26,797 INFO:     Val loss before train {'Reaction outcome loss': 0.9584991959008303, 'Total loss': 0.9584991959008303}
2022-11-28 01:11:26,797 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:26,797 INFO:     Epoch: 0
2022-11-28 01:11:27,546 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5808490033854138, 'Total loss': 0.5808490033854138} | train loss {'Reaction outcome loss': 0.6515727823660258, 'Total loss': 0.6515727823660258}
2022-11-28 01:11:27,546 INFO:     Found new best model at epoch 0
2022-11-28 01:11:27,547 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:27,547 INFO:     Epoch: 1
2022-11-28 01:11:28,294 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4843868626789613, 'Total loss': 0.4843868626789613} | train loss {'Reaction outcome loss': 0.5142172607443025, 'Total loss': 0.5142172607443025}
2022-11-28 01:11:28,294 INFO:     Found new best model at epoch 1
2022-11-28 01:11:28,295 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:28,295 INFO:     Epoch: 2
2022-11-28 01:11:29,038 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4595751105384393, 'Total loss': 0.4595751105384393} | train loss {'Reaction outcome loss': 0.4724487284979513, 'Total loss': 0.4724487284979513}
2022-11-28 01:11:29,038 INFO:     Found new best model at epoch 2
2022-11-28 01:11:29,039 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:29,039 INFO:     Epoch: 3
2022-11-28 01:11:29,786 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.43550659038803796, 'Total loss': 0.43550659038803796} | train loss {'Reaction outcome loss': 0.4445895694436566, 'Total loss': 0.4445895694436566}
2022-11-28 01:11:29,787 INFO:     Found new best model at epoch 3
2022-11-28 01:11:29,787 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:29,788 INFO:     Epoch: 4
2022-11-28 01:11:30,530 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45296239852905273, 'Total loss': 0.45296239852905273} | train loss {'Reaction outcome loss': 0.42354513305209335, 'Total loss': 0.42354513305209335}
2022-11-28 01:11:30,530 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:30,530 INFO:     Epoch: 5
2022-11-28 01:11:31,275 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4331308742138473, 'Total loss': 0.4331308742138473} | train loss {'Reaction outcome loss': 0.41734506592394843, 'Total loss': 0.41734506592394843}
2022-11-28 01:11:31,275 INFO:     Found new best model at epoch 5
2022-11-28 01:11:31,276 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:31,276 INFO:     Epoch: 6
2022-11-28 01:11:32,021 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46553765305063943, 'Total loss': 0.46553765305063943} | train loss {'Reaction outcome loss': 0.40943362984445786, 'Total loss': 0.40943362984445786}
2022-11-28 01:11:32,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:32,021 INFO:     Epoch: 7
2022-11-28 01:11:32,767 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4400027252056382, 'Total loss': 0.4400027252056382} | train loss {'Reaction outcome loss': 0.4062730573838757, 'Total loss': 0.4062730573838757}
2022-11-28 01:11:32,767 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:32,767 INFO:     Epoch: 8
2022-11-28 01:11:33,513 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42691791091452946, 'Total loss': 0.42691791091452946} | train loss {'Reaction outcome loss': 0.39618761513021683, 'Total loss': 0.39618761513021683}
2022-11-28 01:11:33,513 INFO:     Found new best model at epoch 8
2022-11-28 01:11:33,514 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:33,514 INFO:     Epoch: 9
2022-11-28 01:11:34,267 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44136907905340195, 'Total loss': 0.44136907905340195} | train loss {'Reaction outcome loss': 0.3833908540226759, 'Total loss': 0.3833908540226759}
2022-11-28 01:11:34,267 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:34,267 INFO:     Epoch: 10
2022-11-28 01:11:35,015 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.412900064479221, 'Total loss': 0.412900064479221} | train loss {'Reaction outcome loss': 0.385003459129122, 'Total loss': 0.385003459129122}
2022-11-28 01:11:35,015 INFO:     Found new best model at epoch 10
2022-11-28 01:11:35,016 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:35,016 INFO:     Epoch: 11
2022-11-28 01:11:35,760 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39369951086965477, 'Total loss': 0.39369951086965477} | train loss {'Reaction outcome loss': 0.3785673304791412, 'Total loss': 0.3785673304791412}
2022-11-28 01:11:35,760 INFO:     Found new best model at epoch 11
2022-11-28 01:11:35,761 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:35,761 INFO:     Epoch: 12
2022-11-28 01:11:36,511 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40804731100797653, 'Total loss': 0.40804731100797653} | train loss {'Reaction outcome loss': 0.37045773308003144, 'Total loss': 0.37045773308003144}
2022-11-28 01:11:36,512 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:36,512 INFO:     Epoch: 13
2022-11-28 01:11:37,271 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4068214866248044, 'Total loss': 0.4068214866248044} | train loss {'Reaction outcome loss': 0.38252048215438283, 'Total loss': 0.38252048215438283}
2022-11-28 01:11:37,271 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:37,271 INFO:     Epoch: 14
2022-11-28 01:11:38,028 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4061994112350724, 'Total loss': 0.4061994112350724} | train loss {'Reaction outcome loss': 0.3573415815199335, 'Total loss': 0.3573415815199335}
2022-11-28 01:11:38,028 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:38,028 INFO:     Epoch: 15
2022-11-28 01:11:38,781 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4355018809437752, 'Total loss': 0.4355018809437752} | train loss {'Reaction outcome loss': 0.3607387611822736, 'Total loss': 0.3607387611822736}
2022-11-28 01:11:38,781 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:38,781 INFO:     Epoch: 16
2022-11-28 01:11:39,538 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42722010307691316, 'Total loss': 0.42722010307691316} | train loss {'Reaction outcome loss': 0.36463718410701523, 'Total loss': 0.36463718410701523}
2022-11-28 01:11:39,538 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:39,538 INFO:     Epoch: 17
2022-11-28 01:11:40,294 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41326104138385167, 'Total loss': 0.41326104138385167} | train loss {'Reaction outcome loss': 0.36065245197424967, 'Total loss': 0.36065245197424967}
2022-11-28 01:11:40,294 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:40,295 INFO:     Epoch: 18
2022-11-28 01:11:41,052 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4015886963091113, 'Total loss': 0.4015886963091113} | train loss {'Reaction outcome loss': 0.35261810339626765, 'Total loss': 0.35261810339626765}
2022-11-28 01:11:41,052 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:41,052 INFO:     Epoch: 19
2022-11-28 01:11:41,807 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42742157490416005, 'Total loss': 0.42742157490416005} | train loss {'Reaction outcome loss': 0.34372946861830933, 'Total loss': 0.34372946861830933}
2022-11-28 01:11:41,807 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:41,808 INFO:     Epoch: 20
2022-11-28 01:11:42,564 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38459627296436916, 'Total loss': 0.38459627296436916} | train loss {'Reaction outcome loss': 0.3460865182081057, 'Total loss': 0.3460865182081057}
2022-11-28 01:11:42,564 INFO:     Found new best model at epoch 20
2022-11-28 01:11:42,565 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:42,565 INFO:     Epoch: 21
2022-11-28 01:11:43,317 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43684272739020263, 'Total loss': 0.43684272739020263} | train loss {'Reaction outcome loss': 0.3396059608147029, 'Total loss': 0.3396059608147029}
2022-11-28 01:11:43,318 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:43,318 INFO:     Epoch: 22
2022-11-28 01:11:44,069 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4305275119841099, 'Total loss': 0.4305275119841099} | train loss {'Reaction outcome loss': 0.35030186245398176, 'Total loss': 0.35030186245398176}
2022-11-28 01:11:44,069 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:44,069 INFO:     Epoch: 23
2022-11-28 01:11:44,821 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4184321744198149, 'Total loss': 0.4184321744198149} | train loss {'Reaction outcome loss': 0.35003725289096754, 'Total loss': 0.35003725289096754}
2022-11-28 01:11:44,821 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:44,821 INFO:     Epoch: 24
2022-11-28 01:11:45,572 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3759658688848669, 'Total loss': 0.3759658688848669} | train loss {'Reaction outcome loss': 0.34531700692229694, 'Total loss': 0.34531700692229694}
2022-11-28 01:11:45,572 INFO:     Found new best model at epoch 24
2022-11-28 01:11:45,573 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:45,573 INFO:     Epoch: 25
2022-11-28 01:11:46,326 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4249989473345605, 'Total loss': 0.4249989473345605} | train loss {'Reaction outcome loss': 0.33776203729212284, 'Total loss': 0.33776203729212284}
2022-11-28 01:11:46,326 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:46,326 INFO:     Epoch: 26
2022-11-28 01:11:47,077 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3945267898115245, 'Total loss': 0.3945267898115245} | train loss {'Reaction outcome loss': 0.32809905200115136, 'Total loss': 0.32809905200115136}
2022-11-28 01:11:47,077 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:47,077 INFO:     Epoch: 27
2022-11-28 01:11:47,830 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39337362281300803, 'Total loss': 0.39337362281300803} | train loss {'Reaction outcome loss': 0.3295725178754618, 'Total loss': 0.3295725178754618}
2022-11-28 01:11:47,830 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:47,830 INFO:     Epoch: 28
2022-11-28 01:11:48,588 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41792720810256223, 'Total loss': 0.41792720810256223} | train loss {'Reaction outcome loss': 0.3356780985129937, 'Total loss': 0.3356780985129937}
2022-11-28 01:11:48,589 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:48,589 INFO:     Epoch: 29
2022-11-28 01:11:49,346 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.415011685510928, 'Total loss': 0.415011685510928} | train loss {'Reaction outcome loss': 0.32999366282245085, 'Total loss': 0.32999366282245085}
2022-11-28 01:11:49,346 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:49,346 INFO:     Epoch: 30
2022-11-28 01:11:50,098 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4002259937538342, 'Total loss': 0.4002259937538342} | train loss {'Reaction outcome loss': 0.32592965602394075, 'Total loss': 0.32592965602394075}
2022-11-28 01:11:50,098 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:50,098 INFO:     Epoch: 31
2022-11-28 01:11:50,857 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3877389182082631, 'Total loss': 0.3877389182082631} | train loss {'Reaction outcome loss': 0.3330720116143986, 'Total loss': 0.3330720116143986}
2022-11-28 01:11:50,857 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:50,857 INFO:     Epoch: 32
2022-11-28 01:11:51,614 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40545694597742776, 'Total loss': 0.40545694597742776} | train loss {'Reaction outcome loss': 0.337458148148031, 'Total loss': 0.337458148148031}
2022-11-28 01:11:51,614 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:51,614 INFO:     Epoch: 33
2022-11-28 01:11:52,369 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4097999906675382, 'Total loss': 0.4097999906675382} | train loss {'Reaction outcome loss': 0.32950856758942526, 'Total loss': 0.32950856758942526}
2022-11-28 01:11:52,369 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:52,369 INFO:     Epoch: 34
2022-11-28 01:11:53,125 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43291646987199783, 'Total loss': 0.43291646987199783} | train loss {'Reaction outcome loss': 0.3314472132197191, 'Total loss': 0.3314472132197191}
2022-11-28 01:11:53,125 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:53,125 INFO:     Epoch: 35
2022-11-28 01:11:53,877 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4192669330672784, 'Total loss': 0.4192669330672784} | train loss {'Reaction outcome loss': 0.3250024440668283, 'Total loss': 0.3250024440668283}
2022-11-28 01:11:53,877 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:53,877 INFO:     Epoch: 36
2022-11-28 01:11:54,631 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4217604117637331, 'Total loss': 0.4217604117637331} | train loss {'Reaction outcome loss': 0.3299295149383045, 'Total loss': 0.3299295149383045}
2022-11-28 01:11:54,631 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:54,631 INFO:     Epoch: 37
2022-11-28 01:11:55,383 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39096552099693904, 'Total loss': 0.39096552099693904} | train loss {'Reaction outcome loss': 0.3335010808321737, 'Total loss': 0.3335010808321737}
2022-11-28 01:11:55,383 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:55,384 INFO:     Epoch: 38
2022-11-28 01:11:56,139 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4340837906030091, 'Total loss': 0.4340837906030091} | train loss {'Reaction outcome loss': 0.32009099820448506, 'Total loss': 0.32009099820448506}
2022-11-28 01:11:56,139 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:56,139 INFO:     Epoch: 39
2022-11-28 01:11:56,894 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4067061526531523, 'Total loss': 0.4067061526531523} | train loss {'Reaction outcome loss': 0.3272200977399705, 'Total loss': 0.3272200977399705}
2022-11-28 01:11:56,895 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:56,895 INFO:     Epoch: 40
2022-11-28 01:11:57,651 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4415374354205348, 'Total loss': 0.4415374354205348} | train loss {'Reaction outcome loss': 0.3244843170527489, 'Total loss': 0.3244843170527489}
2022-11-28 01:11:57,651 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:57,652 INFO:     Epoch: 41
2022-11-28 01:11:58,405 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4260892624204809, 'Total loss': 0.4260892624204809} | train loss {'Reaction outcome loss': 0.3302731416939247, 'Total loss': 0.3302731416939247}
2022-11-28 01:11:58,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:58,405 INFO:     Epoch: 42
2022-11-28 01:11:59,158 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42695114558393304, 'Total loss': 0.42695114558393304} | train loss {'Reaction outcome loss': 0.3222563771170474, 'Total loss': 0.3222563771170474}
2022-11-28 01:11:59,158 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:59,158 INFO:     Epoch: 43
2022-11-28 01:11:59,917 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39483253353021364, 'Total loss': 0.39483253353021364} | train loss {'Reaction outcome loss': 0.32428646535282174, 'Total loss': 0.32428646535282174}
2022-11-28 01:11:59,917 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:11:59,917 INFO:     Epoch: 44
2022-11-28 01:12:00,673 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4013085863129659, 'Total loss': 0.4013085863129659} | train loss {'Reaction outcome loss': 0.3190164613207021, 'Total loss': 0.3190164613207021}
2022-11-28 01:12:00,674 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:00,674 INFO:     Epoch: 45
2022-11-28 01:12:01,426 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3928555805574764, 'Total loss': 0.3928555805574764} | train loss {'Reaction outcome loss': 0.33015908041007574, 'Total loss': 0.33015908041007574}
2022-11-28 01:12:01,427 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:01,427 INFO:     Epoch: 46
2022-11-28 01:12:02,182 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39967558262023056, 'Total loss': 0.39967558262023056} | train loss {'Reaction outcome loss': 0.32001621656179907, 'Total loss': 0.32001621656179907}
2022-11-28 01:12:02,182 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:02,182 INFO:     Epoch: 47
2022-11-28 01:12:02,932 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3703620274635879, 'Total loss': 0.3703620274635879} | train loss {'Reaction outcome loss': 0.3221528270852662, 'Total loss': 0.3221528270852662}
2022-11-28 01:12:02,932 INFO:     Found new best model at epoch 47
2022-11-28 01:12:02,933 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:02,933 INFO:     Epoch: 48
2022-11-28 01:12:03,685 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4175687229091471, 'Total loss': 0.4175687229091471} | train loss {'Reaction outcome loss': 0.32941062198651416, 'Total loss': 0.32941062198651416}
2022-11-28 01:12:03,685 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:03,685 INFO:     Epoch: 49
2022-11-28 01:12:04,442 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.37960316376252606, 'Total loss': 0.37960316376252606} | train loss {'Reaction outcome loss': 0.3272165502271345, 'Total loss': 0.3272165502271345}
2022-11-28 01:12:04,442 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:04,442 INFO:     Epoch: 50
2022-11-28 01:12:05,202 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4181655713103034, 'Total loss': 0.4181655713103034} | train loss {'Reaction outcome loss': 0.3151544521021987, 'Total loss': 0.3151544521021987}
2022-11-28 01:12:05,202 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:05,202 INFO:     Epoch: 51
2022-11-28 01:12:05,958 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42999665811657906, 'Total loss': 0.42999665811657906} | train loss {'Reaction outcome loss': 0.314442987538754, 'Total loss': 0.314442987538754}
2022-11-28 01:12:05,959 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:05,959 INFO:     Epoch: 52
2022-11-28 01:12:06,712 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3839613138274713, 'Total loss': 0.3839613138274713} | train loss {'Reaction outcome loss': 0.32739693202799364, 'Total loss': 0.32739693202799364}
2022-11-28 01:12:06,713 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:06,713 INFO:     Epoch: 53
2022-11-28 01:12:07,466 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3880750262601809, 'Total loss': 0.3880750262601809} | train loss {'Reaction outcome loss': 0.3242967939304729, 'Total loss': 0.3242967939304729}
2022-11-28 01:12:07,466 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:07,466 INFO:     Epoch: 54
2022-11-28 01:12:08,224 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39943848753517325, 'Total loss': 0.39943848753517325} | train loss {'Reaction outcome loss': 0.3287190061603342, 'Total loss': 0.3287190061603342}
2022-11-28 01:12:08,224 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:08,224 INFO:     Epoch: 55
2022-11-28 01:12:08,980 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43978115543723106, 'Total loss': 0.43978115543723106} | train loss {'Reaction outcome loss': 0.32698502220333586, 'Total loss': 0.32698502220333586}
2022-11-28 01:12:08,980 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:08,980 INFO:     Epoch: 56
2022-11-28 01:12:09,734 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.404003313488581, 'Total loss': 0.404003313488581} | train loss {'Reaction outcome loss': 0.3246323872778204, 'Total loss': 0.3246323872778204}
2022-11-28 01:12:09,734 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:09,734 INFO:     Epoch: 57
2022-11-28 01:12:10,489 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41851272467862477, 'Total loss': 0.41851272467862477} | train loss {'Reaction outcome loss': 0.31965584244819417, 'Total loss': 0.31965584244819417}
2022-11-28 01:12:10,489 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:10,489 INFO:     Epoch: 58
2022-11-28 01:12:11,243 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40601516769013624, 'Total loss': 0.40601516769013624} | train loss {'Reaction outcome loss': 0.32217905430063126, 'Total loss': 0.32217905430063126}
2022-11-28 01:12:11,244 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:11,244 INFO:     Epoch: 59
2022-11-28 01:12:11,996 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3946720703758977, 'Total loss': 0.3946720703758977} | train loss {'Reaction outcome loss': 0.31975480367339426, 'Total loss': 0.31975480367339426}
2022-11-28 01:12:11,996 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:11,996 INFO:     Epoch: 60
2022-11-28 01:12:12,750 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37662452831864357, 'Total loss': 0.37662452831864357} | train loss {'Reaction outcome loss': 0.3190140042213663, 'Total loss': 0.3190140042213663}
2022-11-28 01:12:12,750 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:12,751 INFO:     Epoch: 61
2022-11-28 01:12:13,502 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3983333104036071, 'Total loss': 0.3983333104036071} | train loss {'Reaction outcome loss': 0.3256515311077237, 'Total loss': 0.3256515311077237}
2022-11-28 01:12:13,502 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:13,502 INFO:     Epoch: 62
2022-11-28 01:12:14,260 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4080086001618342, 'Total loss': 0.4080086001618342} | train loss {'Reaction outcome loss': 0.3206222986862544, 'Total loss': 0.3206222986862544}
2022-11-28 01:12:14,261 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:14,261 INFO:     Epoch: 63
2022-11-28 01:12:15,017 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39104919745163486, 'Total loss': 0.39104919745163486} | train loss {'Reaction outcome loss': 0.3222430849207505, 'Total loss': 0.3222430849207505}
2022-11-28 01:12:15,017 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:15,017 INFO:     Epoch: 64
2022-11-28 01:12:15,769 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3997373181310567, 'Total loss': 0.3997373181310567} | train loss {'Reaction outcome loss': 0.31292003082982717, 'Total loss': 0.31292003082982717}
2022-11-28 01:12:15,769 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:15,769 INFO:     Epoch: 65
2022-11-28 01:12:16,522 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4300994908606464, 'Total loss': 0.4300994908606464} | train loss {'Reaction outcome loss': 0.308358128317782, 'Total loss': 0.308358128317782}
2022-11-28 01:12:16,522 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:16,522 INFO:     Epoch: 66
2022-11-28 01:12:17,271 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4013949515806003, 'Total loss': 0.4013949515806003} | train loss {'Reaction outcome loss': 0.3173968642649631, 'Total loss': 0.3173968642649631}
2022-11-28 01:12:17,271 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:17,271 INFO:     Epoch: 67
2022-11-28 01:12:18,022 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39215941253033554, 'Total loss': 0.39215941253033554} | train loss {'Reaction outcome loss': 0.31515660731782835, 'Total loss': 0.31515660731782835}
2022-11-28 01:12:18,022 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:18,022 INFO:     Epoch: 68
2022-11-28 01:12:18,770 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38352262296459894, 'Total loss': 0.38352262296459894} | train loss {'Reaction outcome loss': 0.31818169803028146, 'Total loss': 0.31818169803028146}
2022-11-28 01:12:18,770 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:18,771 INFO:     Epoch: 69
2022-11-28 01:12:19,519 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4794057688929818, 'Total loss': 0.4794057688929818} | train loss {'Reaction outcome loss': 0.3136638594010184, 'Total loss': 0.3136638594010184}
2022-11-28 01:12:19,519 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:19,519 INFO:     Epoch: 70
2022-11-28 01:12:20,265 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4092904386872595, 'Total loss': 0.4092904386872595} | train loss {'Reaction outcome loss': 0.31944105291979447, 'Total loss': 0.31944105291979447}
2022-11-28 01:12:20,265 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:20,266 INFO:     Epoch: 71
2022-11-28 01:12:21,016 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40428998185829684, 'Total loss': 0.40428998185829684} | train loss {'Reaction outcome loss': 0.3141014304372572, 'Total loss': 0.3141014304372572}
2022-11-28 01:12:21,016 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:21,016 INFO:     Epoch: 72
2022-11-28 01:12:21,767 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3969635028730739, 'Total loss': 0.3969635028730739} | train loss {'Reaction outcome loss': 0.3084432004440215, 'Total loss': 0.3084432004440215}
2022-11-28 01:12:21,767 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:21,767 INFO:     Epoch: 73
2022-11-28 01:12:22,516 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39832154187289154, 'Total loss': 0.39832154187289154} | train loss {'Reaction outcome loss': 0.31178100572358214, 'Total loss': 0.31178100572358214}
2022-11-28 01:12:22,517 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:22,517 INFO:     Epoch: 74
2022-11-28 01:12:23,262 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42124940861355176, 'Total loss': 0.42124940861355176} | train loss {'Reaction outcome loss': 0.31230570279782816, 'Total loss': 0.31230570279782816}
2022-11-28 01:12:23,263 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:23,263 INFO:     Epoch: 75
2022-11-28 01:12:24,007 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3899964348159053, 'Total loss': 0.3899964348159053} | train loss {'Reaction outcome loss': 0.32403862567979, 'Total loss': 0.32403862567979}
2022-11-28 01:12:24,008 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:24,008 INFO:     Epoch: 76
2022-11-28 01:12:24,758 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39944514937021514, 'Total loss': 0.39944514937021514} | train loss {'Reaction outcome loss': 0.3114510173759153, 'Total loss': 0.3114510173759153}
2022-11-28 01:12:24,759 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:24,759 INFO:     Epoch: 77
2022-11-28 01:12:25,508 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4216683733869683, 'Total loss': 0.4216683733869683} | train loss {'Reaction outcome loss': 0.3146045352482507, 'Total loss': 0.3146045352482507}
2022-11-28 01:12:25,508 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:25,508 INFO:     Epoch: 78
2022-11-28 01:12:26,254 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3918976814232089, 'Total loss': 0.3918976814232089} | train loss {'Reaction outcome loss': 0.31657386455504644, 'Total loss': 0.31657386455504644}
2022-11-28 01:12:26,254 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:26,254 INFO:     Epoch: 79
2022-11-28 01:12:27,002 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40520174361088057, 'Total loss': 0.40520174361088057} | train loss {'Reaction outcome loss': 0.318160664981171, 'Total loss': 0.318160664981171}
2022-11-28 01:12:27,002 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:27,002 INFO:     Epoch: 80
2022-11-28 01:12:27,749 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3979388302700086, 'Total loss': 0.3979388302700086} | train loss {'Reaction outcome loss': 0.316007059578213, 'Total loss': 0.316007059578213}
2022-11-28 01:12:27,749 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:27,749 INFO:     Epoch: 81
2022-11-28 01:12:28,497 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38907620175318286, 'Total loss': 0.38907620175318286} | train loss {'Reaction outcome loss': 0.3118327844948057, 'Total loss': 0.3118327844948057}
2022-11-28 01:12:28,497 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:28,497 INFO:     Epoch: 82
2022-11-28 01:12:29,243 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41314410215074365, 'Total loss': 0.41314410215074365} | train loss {'Reaction outcome loss': 0.31350142037075374, 'Total loss': 0.31350142037075374}
2022-11-28 01:12:29,244 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:29,244 INFO:     Epoch: 83
2022-11-28 01:12:29,993 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40832850201563403, 'Total loss': 0.40832850201563403} | train loss {'Reaction outcome loss': 0.32032647686860255, 'Total loss': 0.32032647686860255}
2022-11-28 01:12:29,993 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:29,994 INFO:     Epoch: 84
2022-11-28 01:12:30,742 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41111778163097124, 'Total loss': 0.41111778163097124} | train loss {'Reaction outcome loss': 0.31480518016483516, 'Total loss': 0.31480518016483516}
2022-11-28 01:12:30,742 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:30,742 INFO:     Epoch: 85
2022-11-28 01:12:31,490 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38069387593052606, 'Total loss': 0.38069387593052606} | train loss {'Reaction outcome loss': 0.3125907432348017, 'Total loss': 0.3125907432348017}
2022-11-28 01:12:31,491 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:31,491 INFO:     Epoch: 86
2022-11-28 01:12:32,241 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42290905371985654, 'Total loss': 0.42290905371985654} | train loss {'Reaction outcome loss': 0.31500538276328194, 'Total loss': 0.31500538276328194}
2022-11-28 01:12:32,242 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:32,242 INFO:     Epoch: 87
2022-11-28 01:12:32,989 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4156295531852679, 'Total loss': 0.4156295531852679} | train loss {'Reaction outcome loss': 0.3200107008789576, 'Total loss': 0.3200107008789576}
2022-11-28 01:12:32,990 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:32,990 INFO:     Epoch: 88
2022-11-28 01:12:33,737 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40699693459001457, 'Total loss': 0.40699693459001457} | train loss {'Reaction outcome loss': 0.31136625070845886, 'Total loss': 0.31136625070845886}
2022-11-28 01:12:33,737 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:33,737 INFO:     Epoch: 89
2022-11-28 01:12:34,486 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3841139896857468, 'Total loss': 0.3841139896857468} | train loss {'Reaction outcome loss': 0.3090228727688232, 'Total loss': 0.3090228727688232}
2022-11-28 01:12:34,487 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:34,487 INFO:     Epoch: 90
2022-11-28 01:12:35,240 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4100137037987059, 'Total loss': 0.4100137037987059} | train loss {'Reaction outcome loss': 0.30980472374827633, 'Total loss': 0.30980472374827633}
2022-11-28 01:12:35,240 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:35,240 INFO:     Epoch: 91
2022-11-28 01:12:35,988 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39396915534003213, 'Total loss': 0.39396915534003213} | train loss {'Reaction outcome loss': 0.32929923475509687, 'Total loss': 0.32929923475509687}
2022-11-28 01:12:35,988 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:35,989 INFO:     Epoch: 92
2022-11-28 01:12:36,736 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40497069738127967, 'Total loss': 0.40497069738127967} | train loss {'Reaction outcome loss': 0.31708467894444065, 'Total loss': 0.31708467894444065}
2022-11-28 01:12:36,736 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:36,736 INFO:     Epoch: 93
2022-11-28 01:12:37,490 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3742220213806087, 'Total loss': 0.3742220213806087} | train loss {'Reaction outcome loss': 0.3116836069572356, 'Total loss': 0.3116836069572356}
2022-11-28 01:12:37,491 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:37,491 INFO:     Epoch: 94
2022-11-28 01:12:38,240 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.389815745705908, 'Total loss': 0.389815745705908} | train loss {'Reaction outcome loss': 0.3098702734456428, 'Total loss': 0.3098702734456428}
2022-11-28 01:12:38,240 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:38,240 INFO:     Epoch: 95
2022-11-28 01:12:38,991 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40713445909998636, 'Total loss': 0.40713445909998636} | train loss {'Reaction outcome loss': 0.3163090466010955, 'Total loss': 0.3163090466010955}
2022-11-28 01:12:38,991 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:38,991 INFO:     Epoch: 96
2022-11-28 01:12:39,737 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4137678291987289, 'Total loss': 0.4137678291987289} | train loss {'Reaction outcome loss': 0.31609371253439494, 'Total loss': 0.31609371253439494}
2022-11-28 01:12:39,738 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:39,738 INFO:     Epoch: 97
2022-11-28 01:12:40,486 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40194443918087264, 'Total loss': 0.40194443918087264} | train loss {'Reaction outcome loss': 0.3067377428073556, 'Total loss': 0.3067377428073556}
2022-11-28 01:12:40,486 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:40,487 INFO:     Epoch: 98
2022-11-28 01:12:41,237 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4424529949372465, 'Total loss': 0.4424529949372465} | train loss {'Reaction outcome loss': 0.31467968351658315, 'Total loss': 0.31467968351658315}
2022-11-28 01:12:41,237 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:41,237 INFO:     Epoch: 99
2022-11-28 01:12:41,982 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42625970325686713, 'Total loss': 0.42625970325686713} | train loss {'Reaction outcome loss': 0.3120791256848362, 'Total loss': 0.3120791256848362}
2022-11-28 01:12:41,983 INFO:     Best model found after epoch 48 of 100.
2022-11-28 01:12:41,983 INFO:   Done with stage: TRAINING
2022-11-28 01:12:41,983 INFO:   Starting stage: EVALUATION
2022-11-28 01:12:42,098 INFO:   Done with stage: EVALUATION
2022-11-28 01:12:42,098 INFO:   Leaving out SEQ value Fold_7
2022-11-28 01:12:42,110 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 01:12:42,110 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:12:42,749 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:12:42,749 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:12:42,819 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:12:42,819 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:12:42,819 INFO:     No hyperparam tuning for this model
2022-11-28 01:12:42,819 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:12:42,819 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:12:42,820 INFO:     None feature selector for col prot
2022-11-28 01:12:42,820 INFO:     None feature selector for col prot
2022-11-28 01:12:42,820 INFO:     None feature selector for col prot
2022-11-28 01:12:42,821 INFO:     None feature selector for col chem
2022-11-28 01:12:42,821 INFO:     None feature selector for col chem
2022-11-28 01:12:42,821 INFO:     None feature selector for col chem
2022-11-28 01:12:42,821 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:12:42,821 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:12:42,822 INFO:     Number of params in model 169741
2022-11-28 01:12:42,825 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:12:42,825 INFO:   Starting stage: TRAINING
2022-11-28 01:12:42,879 INFO:     Val loss before train {'Reaction outcome loss': 1.0479906580664895, 'Total loss': 1.0479906580664895}
2022-11-28 01:12:42,879 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:42,879 INFO:     Epoch: 0
2022-11-28 01:12:43,620 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5578996302051977, 'Total loss': 0.5578996302051977} | train loss {'Reaction outcome loss': 0.6340217675481524, 'Total loss': 0.6340217675481524}
2022-11-28 01:12:43,620 INFO:     Found new best model at epoch 0
2022-11-28 01:12:43,621 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:43,621 INFO:     Epoch: 1
2022-11-28 01:12:44,364 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4994538141922517, 'Total loss': 0.4994538141922517} | train loss {'Reaction outcome loss': 0.5032839443306534, 'Total loss': 0.5032839443306534}
2022-11-28 01:12:44,365 INFO:     Found new best model at epoch 1
2022-11-28 01:12:44,365 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:44,365 INFO:     Epoch: 2
2022-11-28 01:12:45,106 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.460409477353096, 'Total loss': 0.460409477353096} | train loss {'Reaction outcome loss': 0.4627719935713982, 'Total loss': 0.4627719935713982}
2022-11-28 01:12:45,106 INFO:     Found new best model at epoch 2
2022-11-28 01:12:45,107 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:45,107 INFO:     Epoch: 3
2022-11-28 01:12:45,851 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5110366148027506, 'Total loss': 0.5110366148027506} | train loss {'Reaction outcome loss': 0.4461050914866584, 'Total loss': 0.4461050914866584}
2022-11-28 01:12:45,851 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:45,851 INFO:     Epoch: 4
2022-11-28 01:12:46,592 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.475497994910587, 'Total loss': 0.475497994910587} | train loss {'Reaction outcome loss': 0.42651832413916685, 'Total loss': 0.42651832413916685}
2022-11-28 01:12:46,592 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:46,592 INFO:     Epoch: 5
2022-11-28 01:12:47,333 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5096958862109617, 'Total loss': 0.5096958862109617} | train loss {'Reaction outcome loss': 0.4222691035392333, 'Total loss': 0.4222691035392333}
2022-11-28 01:12:47,333 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:47,334 INFO:     Epoch: 6
2022-11-28 01:12:48,076 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4426881176504222, 'Total loss': 0.4426881176504222} | train loss {'Reaction outcome loss': 0.40810979294533634, 'Total loss': 0.40810979294533634}
2022-11-28 01:12:48,076 INFO:     Found new best model at epoch 6
2022-11-28 01:12:48,077 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:48,077 INFO:     Epoch: 7
2022-11-28 01:12:48,820 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4671212136745453, 'Total loss': 0.4671212136745453} | train loss {'Reaction outcome loss': 0.4017300318698494, 'Total loss': 0.4017300318698494}
2022-11-28 01:12:48,820 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:48,820 INFO:     Epoch: 8
2022-11-28 01:12:49,566 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4661609340797771, 'Total loss': 0.4661609340797771} | train loss {'Reaction outcome loss': 0.3985861093414073, 'Total loss': 0.3985861093414073}
2022-11-28 01:12:49,566 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:49,566 INFO:     Epoch: 9
2022-11-28 01:12:50,309 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44263297742740676, 'Total loss': 0.44263297742740676} | train loss {'Reaction outcome loss': 0.3821507554881427, 'Total loss': 0.3821507554881427}
2022-11-28 01:12:50,309 INFO:     Found new best model at epoch 9
2022-11-28 01:12:50,310 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:50,310 INFO:     Epoch: 10
2022-11-28 01:12:51,049 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4164185008372773, 'Total loss': 0.4164185008372773} | train loss {'Reaction outcome loss': 0.3807790153184716, 'Total loss': 0.3807790153184716}
2022-11-28 01:12:51,050 INFO:     Found new best model at epoch 10
2022-11-28 01:12:51,050 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:51,051 INFO:     Epoch: 11
2022-11-28 01:12:51,793 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45561891506341373, 'Total loss': 0.45561891506341373} | train loss {'Reaction outcome loss': 0.379384787988906, 'Total loss': 0.379384787988906}
2022-11-28 01:12:51,793 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:51,793 INFO:     Epoch: 12
2022-11-28 01:12:52,536 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41822683506391267, 'Total loss': 0.41822683506391267} | train loss {'Reaction outcome loss': 0.37196255323230004, 'Total loss': 0.37196255323230004}
2022-11-28 01:12:52,536 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:52,536 INFO:     Epoch: 13
2022-11-28 01:12:53,277 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4295952624895356, 'Total loss': 0.4295952624895356} | train loss {'Reaction outcome loss': 0.36801011857329585, 'Total loss': 0.36801011857329585}
2022-11-28 01:12:53,277 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:53,277 INFO:     Epoch: 14
2022-11-28 01:12:54,021 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4468858147209341, 'Total loss': 0.4468858147209341} | train loss {'Reaction outcome loss': 0.37273591367565856, 'Total loss': 0.37273591367565856}
2022-11-28 01:12:54,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:54,021 INFO:     Epoch: 15
2022-11-28 01:12:54,765 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4366092692044648, 'Total loss': 0.4366092692044648} | train loss {'Reaction outcome loss': 0.3547154686584765, 'Total loss': 0.3547154686584765}
2022-11-28 01:12:54,765 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:54,765 INFO:     Epoch: 16
2022-11-28 01:12:55,509 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42955913013693964, 'Total loss': 0.42955913013693964} | train loss {'Reaction outcome loss': 0.34805538271154673, 'Total loss': 0.34805538271154673}
2022-11-28 01:12:55,509 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:55,509 INFO:     Epoch: 17
2022-11-28 01:12:56,247 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4559268314730037, 'Total loss': 0.4559268314730037} | train loss {'Reaction outcome loss': 0.3629824816572423, 'Total loss': 0.3629824816572423}
2022-11-28 01:12:56,247 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:56,247 INFO:     Epoch: 18
2022-11-28 01:12:56,988 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4588217403401028, 'Total loss': 0.4588217403401028} | train loss {'Reaction outcome loss': 0.355284656249747, 'Total loss': 0.355284656249747}
2022-11-28 01:12:56,988 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:56,988 INFO:     Epoch: 19
2022-11-28 01:12:57,731 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4507436379790306, 'Total loss': 0.4507436379790306} | train loss {'Reaction outcome loss': 0.3451924578267701, 'Total loss': 0.3451924578267701}
2022-11-28 01:12:57,731 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:57,731 INFO:     Epoch: 20
2022-11-28 01:12:58,472 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4093278900466182, 'Total loss': 0.4093278900466182} | train loss {'Reaction outcome loss': 0.3499601916086917, 'Total loss': 0.3499601916086917}
2022-11-28 01:12:58,472 INFO:     Found new best model at epoch 20
2022-11-28 01:12:58,473 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:58,473 INFO:     Epoch: 21
2022-11-28 01:12:59,212 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4264021610036831, 'Total loss': 0.4264021610036831} | train loss {'Reaction outcome loss': 0.349666698185765, 'Total loss': 0.349666698185765}
2022-11-28 01:12:59,212 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:59,212 INFO:     Epoch: 22
2022-11-28 01:12:59,952 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4223060858520595, 'Total loss': 0.4223060858520595} | train loss {'Reaction outcome loss': 0.33929397077584755, 'Total loss': 0.33929397077584755}
2022-11-28 01:12:59,952 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:12:59,953 INFO:     Epoch: 23
2022-11-28 01:13:00,693 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44882298362526024, 'Total loss': 0.44882298362526024} | train loss {'Reaction outcome loss': 0.3383153821132621, 'Total loss': 0.3383153821132621}
2022-11-28 01:13:00,693 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:00,693 INFO:     Epoch: 24
2022-11-28 01:13:01,437 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45304385301741684, 'Total loss': 0.45304385301741684} | train loss {'Reaction outcome loss': 0.33868430025723517, 'Total loss': 0.33868430025723517}
2022-11-28 01:13:01,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:01,437 INFO:     Epoch: 25
2022-11-28 01:13:02,177 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4589751035144383, 'Total loss': 0.4589751035144383} | train loss {'Reaction outcome loss': 0.3348741401214989, 'Total loss': 0.3348741401214989}
2022-11-28 01:13:02,178 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:02,179 INFO:     Epoch: 26
2022-11-28 01:13:02,919 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4374938204207204, 'Total loss': 0.4374938204207204} | train loss {'Reaction outcome loss': 0.3405557554291219, 'Total loss': 0.3405557554291219}
2022-11-28 01:13:02,919 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:02,919 INFO:     Epoch: 27
2022-11-28 01:13:03,665 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43947209587151354, 'Total loss': 0.43947209587151354} | train loss {'Reaction outcome loss': 0.3351515988914334, 'Total loss': 0.3351515988914334}
2022-11-28 01:13:03,666 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:03,666 INFO:     Epoch: 28
2022-11-28 01:13:04,410 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43030688369816, 'Total loss': 0.43030688369816} | train loss {'Reaction outcome loss': 0.33077429712426903, 'Total loss': 0.33077429712426903}
2022-11-28 01:13:04,410 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:04,410 INFO:     Epoch: 29
2022-11-28 01:13:05,157 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4666231887584383, 'Total loss': 0.4666231887584383} | train loss {'Reaction outcome loss': 0.32858862478514106, 'Total loss': 0.32858862478514106}
2022-11-28 01:13:05,157 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:05,157 INFO:     Epoch: 30
2022-11-28 01:13:05,905 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4464010271159085, 'Total loss': 0.4464010271159085} | train loss {'Reaction outcome loss': 0.3334821135717995, 'Total loss': 0.3334821135717995}
2022-11-28 01:13:05,905 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:05,905 INFO:     Epoch: 31
2022-11-28 01:13:06,648 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42088987542824313, 'Total loss': 0.42088987542824313} | train loss {'Reaction outcome loss': 0.3291883223214928, 'Total loss': 0.3291883223214928}
2022-11-28 01:13:06,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:06,649 INFO:     Epoch: 32
2022-11-28 01:13:07,397 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4404219734397801, 'Total loss': 0.4404219734397801} | train loss {'Reaction outcome loss': 0.3288681897429787, 'Total loss': 0.3288681897429787}
2022-11-28 01:13:07,398 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:07,398 INFO:     Epoch: 33
2022-11-28 01:13:08,139 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4478959732434966, 'Total loss': 0.4478959732434966} | train loss {'Reaction outcome loss': 0.32915393919969094, 'Total loss': 0.32915393919969094}
2022-11-28 01:13:08,139 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:08,139 INFO:     Epoch: 34
2022-11-28 01:13:08,885 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4243650504133918, 'Total loss': 0.4243650504133918} | train loss {'Reaction outcome loss': 0.3267047709652356, 'Total loss': 0.3267047709652356}
2022-11-28 01:13:08,886 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:08,886 INFO:     Epoch: 35
2022-11-28 01:13:09,631 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4370452185923403, 'Total loss': 0.4370452185923403} | train loss {'Reaction outcome loss': 0.32169169020287847, 'Total loss': 0.32169169020287847}
2022-11-28 01:13:09,631 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:09,631 INFO:     Epoch: 36
2022-11-28 01:13:10,375 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46972839398817584, 'Total loss': 0.46972839398817584} | train loss {'Reaction outcome loss': 0.3195746665098229, 'Total loss': 0.3195746665098229}
2022-11-28 01:13:10,376 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:10,376 INFO:     Epoch: 37
2022-11-28 01:13:11,118 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46239575472745026, 'Total loss': 0.46239575472745026} | train loss {'Reaction outcome loss': 0.3325849245093307, 'Total loss': 0.3325849245093307}
2022-11-28 01:13:11,119 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:11,119 INFO:     Epoch: 38
2022-11-28 01:13:11,861 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4109957553446293, 'Total loss': 0.4109957553446293} | train loss {'Reaction outcome loss': 0.3257278986731354, 'Total loss': 0.3257278986731354}
2022-11-28 01:13:11,861 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:11,861 INFO:     Epoch: 39
2022-11-28 01:13:12,605 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4486109336668795, 'Total loss': 0.4486109336668795} | train loss {'Reaction outcome loss': 0.3126104943302213, 'Total loss': 0.3126104943302213}
2022-11-28 01:13:12,606 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:12,606 INFO:     Epoch: 40
2022-11-28 01:13:13,348 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4205923324281519, 'Total loss': 0.4205923324281519} | train loss {'Reaction outcome loss': 0.32689987278106264, 'Total loss': 0.32689987278106264}
2022-11-28 01:13:13,348 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:13,348 INFO:     Epoch: 41
2022-11-28 01:13:14,091 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.441276472739198, 'Total loss': 0.441276472739198} | train loss {'Reaction outcome loss': 0.3241873570546812, 'Total loss': 0.3241873570546812}
2022-11-28 01:13:14,091 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:14,091 INFO:     Epoch: 42
2022-11-28 01:13:14,831 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4276025112379681, 'Total loss': 0.4276025112379681} | train loss {'Reaction outcome loss': 0.32141455573086836, 'Total loss': 0.32141455573086836}
2022-11-28 01:13:14,831 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:14,831 INFO:     Epoch: 43
2022-11-28 01:13:15,574 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4340937997807156, 'Total loss': 0.4340937997807156} | train loss {'Reaction outcome loss': 0.3193908058258952, 'Total loss': 0.3193908058258952}
2022-11-28 01:13:15,574 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:15,574 INFO:     Epoch: 44
2022-11-28 01:13:16,316 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4299186119301753, 'Total loss': 0.4299186119301753} | train loss {'Reaction outcome loss': 0.3189221884219014, 'Total loss': 0.3189221884219014}
2022-11-28 01:13:16,316 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:16,316 INFO:     Epoch: 45
2022-11-28 01:13:17,057 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4187646454030817, 'Total loss': 0.4187646454030817} | train loss {'Reaction outcome loss': 0.32226960710725006, 'Total loss': 0.32226960710725006}
2022-11-28 01:13:17,057 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:17,057 INFO:     Epoch: 46
2022-11-28 01:13:17,800 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4296775758266449, 'Total loss': 0.4296775758266449} | train loss {'Reaction outcome loss': 0.3178159620688886, 'Total loss': 0.3178159620688886}
2022-11-28 01:13:17,800 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:17,800 INFO:     Epoch: 47
2022-11-28 01:13:18,544 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4086927656422962, 'Total loss': 0.4086927656422962} | train loss {'Reaction outcome loss': 0.32210743281306053, 'Total loss': 0.32210743281306053}
2022-11-28 01:13:18,544 INFO:     Found new best model at epoch 47
2022-11-28 01:13:18,544 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:18,545 INFO:     Epoch: 48
2022-11-28 01:13:19,291 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43259267339652235, 'Total loss': 0.43259267339652235} | train loss {'Reaction outcome loss': 0.3225468480161258, 'Total loss': 0.3225468480161258}
2022-11-28 01:13:19,291 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:19,291 INFO:     Epoch: 49
2022-11-28 01:13:20,036 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46121368557214737, 'Total loss': 0.46121368557214737} | train loss {'Reaction outcome loss': 0.31118956713043916, 'Total loss': 0.31118956713043916}
2022-11-28 01:13:20,036 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:20,037 INFO:     Epoch: 50
2022-11-28 01:13:20,783 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4270736104385419, 'Total loss': 0.4270736104385419} | train loss {'Reaction outcome loss': 0.3174652263218043, 'Total loss': 0.3174652263218043}
2022-11-28 01:13:20,783 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:20,783 INFO:     Epoch: 51
2022-11-28 01:13:21,528 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.477226949212226, 'Total loss': 0.477226949212226} | train loss {'Reaction outcome loss': 0.3109349085056052, 'Total loss': 0.3109349085056052}
2022-11-28 01:13:21,529 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:21,529 INFO:     Epoch: 52
2022-11-28 01:13:22,272 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4160378653217446, 'Total loss': 0.4160378653217446} | train loss {'Reaction outcome loss': 0.31647218982784114, 'Total loss': 0.31647218982784114}
2022-11-28 01:13:22,272 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:22,272 INFO:     Epoch: 53
2022-11-28 01:13:23,012 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46267212520946155, 'Total loss': 0.46267212520946155} | train loss {'Reaction outcome loss': 0.3119439952227534, 'Total loss': 0.3119439952227534}
2022-11-28 01:13:23,012 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:23,012 INFO:     Epoch: 54
2022-11-28 01:13:23,753 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42463013665242627, 'Total loss': 0.42463013665242627} | train loss {'Reaction outcome loss': 0.3160078544093638, 'Total loss': 0.3160078544093638}
2022-11-28 01:13:23,753 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:23,754 INFO:     Epoch: 55
2022-11-28 01:13:24,499 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4459800720214844, 'Total loss': 0.4459800720214844} | train loss {'Reaction outcome loss': 0.3146418650995712, 'Total loss': 0.3146418650995712}
2022-11-28 01:13:24,499 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:24,499 INFO:     Epoch: 56
2022-11-28 01:13:25,238 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47610599496825173, 'Total loss': 0.47610599496825173} | train loss {'Reaction outcome loss': 0.3155629848643225, 'Total loss': 0.3155629848643225}
2022-11-28 01:13:25,238 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:25,238 INFO:     Epoch: 57
2022-11-28 01:13:25,979 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42883277244188567, 'Total loss': 0.42883277244188567} | train loss {'Reaction outcome loss': 0.3208793181241775, 'Total loss': 0.3208793181241775}
2022-11-28 01:13:25,979 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:25,979 INFO:     Epoch: 58
2022-11-28 01:13:26,721 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.439757485112006, 'Total loss': 0.439757485112006} | train loss {'Reaction outcome loss': 0.311926277802915, 'Total loss': 0.311926277802915}
2022-11-28 01:13:26,722 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:26,722 INFO:     Epoch: 59
2022-11-28 01:13:27,465 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4440080950205976, 'Total loss': 0.4440080950205976} | train loss {'Reaction outcome loss': 0.30527933040747834, 'Total loss': 0.30527933040747834}
2022-11-28 01:13:27,466 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:27,466 INFO:     Epoch: 60
2022-11-28 01:13:28,207 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4502451698697934, 'Total loss': 0.4502451698697934} | train loss {'Reaction outcome loss': 0.3157731235635524, 'Total loss': 0.3157731235635524}
2022-11-28 01:13:28,208 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:28,208 INFO:     Epoch: 61
2022-11-28 01:13:28,954 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49584443257613614, 'Total loss': 0.49584443257613614} | train loss {'Reaction outcome loss': 0.3144211917507405, 'Total loss': 0.3144211917507405}
2022-11-28 01:13:28,954 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:28,954 INFO:     Epoch: 62
2022-11-28 01:13:29,695 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43442241136323323, 'Total loss': 0.43442241136323323} | train loss {'Reaction outcome loss': 0.3149273344600687, 'Total loss': 0.3149273344600687}
2022-11-28 01:13:29,696 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:29,696 INFO:     Epoch: 63
2022-11-28 01:13:30,440 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42401420189575717, 'Total loss': 0.42401420189575717} | train loss {'Reaction outcome loss': 0.3083588965997404, 'Total loss': 0.3083588965997404}
2022-11-28 01:13:30,440 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:30,440 INFO:     Epoch: 64
2022-11-28 01:13:31,184 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4192536200650714, 'Total loss': 0.4192536200650714} | train loss {'Reaction outcome loss': 0.3137181804496415, 'Total loss': 0.3137181804496415}
2022-11-28 01:13:31,184 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:31,184 INFO:     Epoch: 65
2022-11-28 01:13:31,923 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4399904673072425, 'Total loss': 0.4399904673072425} | train loss {'Reaction outcome loss': 0.3111523150941547, 'Total loss': 0.3111523150941547}
2022-11-28 01:13:31,923 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:31,923 INFO:     Epoch: 66
2022-11-28 01:13:32,664 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4248141869902611, 'Total loss': 0.4248141869902611} | train loss {'Reaction outcome loss': 0.3078947660874347, 'Total loss': 0.3078947660874347}
2022-11-28 01:13:32,664 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:32,664 INFO:     Epoch: 67
2022-11-28 01:13:33,411 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42248846319588745, 'Total loss': 0.42248846319588745} | train loss {'Reaction outcome loss': 0.3186420754054371, 'Total loss': 0.3186420754054371}
2022-11-28 01:13:33,412 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:33,412 INFO:     Epoch: 68
2022-11-28 01:13:34,158 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4519719007340344, 'Total loss': 0.4519719007340344} | train loss {'Reaction outcome loss': 0.3102430271250861, 'Total loss': 0.3102430271250861}
2022-11-28 01:13:34,158 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:34,158 INFO:     Epoch: 69
2022-11-28 01:13:34,901 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4304213442585685, 'Total loss': 0.4304213442585685} | train loss {'Reaction outcome loss': 0.30909394737409085, 'Total loss': 0.30909394737409085}
2022-11-28 01:13:34,901 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:34,901 INFO:     Epoch: 70
2022-11-28 01:13:35,644 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40661158588376234, 'Total loss': 0.40661158588376234} | train loss {'Reaction outcome loss': 0.31474771213774777, 'Total loss': 0.31474771213774777}
2022-11-28 01:13:35,644 INFO:     Found new best model at epoch 70
2022-11-28 01:13:35,644 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:35,645 INFO:     Epoch: 71
2022-11-28 01:13:36,386 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4304643070155924, 'Total loss': 0.4304643070155924} | train loss {'Reaction outcome loss': 0.3091271936893463, 'Total loss': 0.3091271936893463}
2022-11-28 01:13:36,386 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:36,386 INFO:     Epoch: 72
2022-11-28 01:13:37,132 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43249683556231583, 'Total loss': 0.43249683556231583} | train loss {'Reaction outcome loss': 0.3066625741975648, 'Total loss': 0.3066625741975648}
2022-11-28 01:13:37,132 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:37,132 INFO:     Epoch: 73
2022-11-28 01:13:37,873 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4294702436097644, 'Total loss': 0.4294702436097644} | train loss {'Reaction outcome loss': 0.3185588032311323, 'Total loss': 0.3185588032311323}
2022-11-28 01:13:37,874 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:37,874 INFO:     Epoch: 74
2022-11-28 01:13:38,618 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.415549615228718, 'Total loss': 0.415549615228718} | train loss {'Reaction outcome loss': 0.3196194971702537, 'Total loss': 0.3196194971702537}
2022-11-28 01:13:38,618 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:38,618 INFO:     Epoch: 75
2022-11-28 01:13:39,362 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44618996808474715, 'Total loss': 0.44618996808474715} | train loss {'Reaction outcome loss': 0.30683988305378934, 'Total loss': 0.30683988305378934}
2022-11-28 01:13:39,362 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:39,362 INFO:     Epoch: 76
2022-11-28 01:13:40,103 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42632706226273015, 'Total loss': 0.42632706226273015} | train loss {'Reaction outcome loss': 0.31233506731841026, 'Total loss': 0.31233506731841026}
2022-11-28 01:13:40,104 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:40,104 INFO:     Epoch: 77
2022-11-28 01:13:40,852 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43862864476713265, 'Total loss': 0.43862864476713265} | train loss {'Reaction outcome loss': 0.30606664054247795, 'Total loss': 0.30606664054247795}
2022-11-28 01:13:40,853 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:40,853 INFO:     Epoch: 78
2022-11-28 01:13:41,597 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4345218195177784, 'Total loss': 0.4345218195177784} | train loss {'Reaction outcome loss': 0.30700387808741353, 'Total loss': 0.30700387808741353}
2022-11-28 01:13:41,598 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:41,598 INFO:     Epoch: 79
2022-11-28 01:13:42,345 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43375353244217957, 'Total loss': 0.43375353244217957} | train loss {'Reaction outcome loss': 0.3232234724170091, 'Total loss': 0.3232234724170091}
2022-11-28 01:13:42,345 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:42,345 INFO:     Epoch: 80
2022-11-28 01:13:43,083 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4479171633720398, 'Total loss': 0.4479171633720398} | train loss {'Reaction outcome loss': 0.3097366693372629, 'Total loss': 0.3097366693372629}
2022-11-28 01:13:43,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:43,083 INFO:     Epoch: 81
2022-11-28 01:13:43,818 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4239203150976788, 'Total loss': 0.4239203150976788} | train loss {'Reaction outcome loss': 0.3198305277495968, 'Total loss': 0.3198305277495968}
2022-11-28 01:13:43,818 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:43,818 INFO:     Epoch: 82
2022-11-28 01:13:44,557 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3993847018785097, 'Total loss': 0.3993847018785097} | train loss {'Reaction outcome loss': 0.30706420674615975, 'Total loss': 0.30706420674615975}
2022-11-28 01:13:44,557 INFO:     Found new best model at epoch 82
2022-11-28 01:13:44,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:44,558 INFO:     Epoch: 83
2022-11-28 01:13:45,298 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43370607613839884, 'Total loss': 0.43370607613839884} | train loss {'Reaction outcome loss': 0.3127284961847626, 'Total loss': 0.3127284961847626}
2022-11-28 01:13:45,298 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:45,298 INFO:     Epoch: 84
2022-11-28 01:13:46,039 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.449025727935474, 'Total loss': 0.449025727935474} | train loss {'Reaction outcome loss': 0.3079864388521837, 'Total loss': 0.3079864388521837}
2022-11-28 01:13:46,039 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:46,039 INFO:     Epoch: 85
2022-11-28 01:13:46,781 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4015059681101279, 'Total loss': 0.4015059681101279} | train loss {'Reaction outcome loss': 0.30703439137765337, 'Total loss': 0.30703439137765337}
2022-11-28 01:13:46,781 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:46,781 INFO:     Epoch: 86
2022-11-28 01:13:47,520 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4246917956254699, 'Total loss': 0.4246917956254699} | train loss {'Reaction outcome loss': 0.3132258325815201, 'Total loss': 0.3132258325815201}
2022-11-28 01:13:47,520 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:47,520 INFO:     Epoch: 87
2022-11-28 01:13:48,259 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4162841801616279, 'Total loss': 0.4162841801616279} | train loss {'Reaction outcome loss': 0.31332997504849824, 'Total loss': 0.31332997504849824}
2022-11-28 01:13:48,259 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:48,259 INFO:     Epoch: 88
2022-11-28 01:13:48,993 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40136105431751773, 'Total loss': 0.40136105431751773} | train loss {'Reaction outcome loss': 0.3074911747203798, 'Total loss': 0.3074911747203798}
2022-11-28 01:13:48,993 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:48,993 INFO:     Epoch: 89
2022-11-28 01:13:49,731 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4393560927022587, 'Total loss': 0.4393560927022587} | train loss {'Reaction outcome loss': 0.3080249487441413, 'Total loss': 0.3080249487441413}
2022-11-28 01:13:49,731 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:49,731 INFO:     Epoch: 90
2022-11-28 01:13:50,473 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4159503196450797, 'Total loss': 0.4159503196450797} | train loss {'Reaction outcome loss': 0.31114106403321634, 'Total loss': 0.31114106403321634}
2022-11-28 01:13:50,473 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:50,473 INFO:     Epoch: 91
2022-11-28 01:13:51,207 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41997605257413606, 'Total loss': 0.41997605257413606} | train loss {'Reaction outcome loss': 0.31328454896503566, 'Total loss': 0.31328454896503566}
2022-11-28 01:13:51,207 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:51,207 INFO:     Epoch: 92
2022-11-28 01:13:51,943 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.38973221826282417, 'Total loss': 0.38973221826282417} | train loss {'Reaction outcome loss': 0.3087885544312244, 'Total loss': 0.3087885544312244}
2022-11-28 01:13:51,943 INFO:     Found new best model at epoch 92
2022-11-28 01:13:51,944 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:51,944 INFO:     Epoch: 93
2022-11-28 01:13:52,680 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4206856576387178, 'Total loss': 0.4206856576387178} | train loss {'Reaction outcome loss': 0.30150876030021784, 'Total loss': 0.30150876030021784}
2022-11-28 01:13:52,681 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:52,681 INFO:     Epoch: 94
2022-11-28 01:13:53,418 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38627744669264014, 'Total loss': 0.38627744669264014} | train loss {'Reaction outcome loss': 0.30983298737175613, 'Total loss': 0.30983298737175613}
2022-11-28 01:13:53,418 INFO:     Found new best model at epoch 94
2022-11-28 01:13:53,419 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:53,419 INFO:     Epoch: 95
2022-11-28 01:13:54,157 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40555238486690953, 'Total loss': 0.40555238486690953} | train loss {'Reaction outcome loss': 0.3028365274625165, 'Total loss': 0.3028365274625165}
2022-11-28 01:13:54,157 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:54,157 INFO:     Epoch: 96
2022-11-28 01:13:54,899 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4062209583141587, 'Total loss': 0.4062209583141587} | train loss {'Reaction outcome loss': 0.3052625508332739, 'Total loss': 0.3052625508332739}
2022-11-28 01:13:54,899 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:54,899 INFO:     Epoch: 97
2022-11-28 01:13:55,638 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42372851581736043, 'Total loss': 0.42372851581736043} | train loss {'Reaction outcome loss': 0.3099069190876825, 'Total loss': 0.3099069190876825}
2022-11-28 01:13:55,638 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:55,638 INFO:     Epoch: 98
2022-11-28 01:13:56,380 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42451786825602705, 'Total loss': 0.42451786825602705} | train loss {'Reaction outcome loss': 0.31093966860552225, 'Total loss': 0.31093966860552225}
2022-11-28 01:13:56,380 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:56,380 INFO:     Epoch: 99
2022-11-28 01:13:57,118 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45532127910039644, 'Total loss': 0.45532127910039644} | train loss {'Reaction outcome loss': 0.30434302027736393, 'Total loss': 0.30434302027736393}
2022-11-28 01:13:57,118 INFO:     Best model found after epoch 95 of 100.
2022-11-28 01:13:57,119 INFO:   Done with stage: TRAINING
2022-11-28 01:13:57,119 INFO:   Starting stage: EVALUATION
2022-11-28 01:13:57,245 INFO:   Done with stage: EVALUATION
2022-11-28 01:13:57,245 INFO:   Leaving out SEQ value Fold_8
2022-11-28 01:13:57,258 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 01:13:57,258 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:13:57,901 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:13:57,901 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:13:57,972 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:13:57,972 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:13:57,972 INFO:     No hyperparam tuning for this model
2022-11-28 01:13:57,972 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:13:57,972 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:13:57,972 INFO:     None feature selector for col prot
2022-11-28 01:13:57,973 INFO:     None feature selector for col prot
2022-11-28 01:13:57,973 INFO:     None feature selector for col prot
2022-11-28 01:13:57,973 INFO:     None feature selector for col chem
2022-11-28 01:13:57,973 INFO:     None feature selector for col chem
2022-11-28 01:13:57,973 INFO:     None feature selector for col chem
2022-11-28 01:13:57,973 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:13:57,974 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:13:57,975 INFO:     Number of params in model 169741
2022-11-28 01:13:57,978 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:13:57,978 INFO:   Starting stage: TRAINING
2022-11-28 01:13:58,031 INFO:     Val loss before train {'Reaction outcome loss': 0.9886160174554045, 'Total loss': 0.9886160174554045}
2022-11-28 01:13:58,032 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:58,032 INFO:     Epoch: 0
2022-11-28 01:13:58,779 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5369924300096252, 'Total loss': 0.5369924300096252} | train loss {'Reaction outcome loss': 0.6374798287307063, 'Total loss': 0.6374798287307063}
2022-11-28 01:13:58,779 INFO:     Found new best model at epoch 0
2022-11-28 01:13:58,780 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:58,780 INFO:     Epoch: 1
2022-11-28 01:13:59,529 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4568555297499353, 'Total loss': 0.4568555297499353} | train loss {'Reaction outcome loss': 0.5116952763449761, 'Total loss': 0.5116952763449761}
2022-11-28 01:13:59,529 INFO:     Found new best model at epoch 1
2022-11-28 01:13:59,530 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:13:59,530 INFO:     Epoch: 2
2022-11-28 01:14:00,275 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4716175432232293, 'Total loss': 0.4716175432232293} | train loss {'Reaction outcome loss': 0.4682953551171287, 'Total loss': 0.4682953551171287}
2022-11-28 01:14:00,275 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:00,275 INFO:     Epoch: 3
2022-11-28 01:14:01,018 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4281169291247021, 'Total loss': 0.4281169291247021} | train loss {'Reaction outcome loss': 0.44064019686512407, 'Total loss': 0.44064019686512407}
2022-11-28 01:14:01,018 INFO:     Found new best model at epoch 3
2022-11-28 01:14:01,019 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:01,019 INFO:     Epoch: 4
2022-11-28 01:14:01,765 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.42172915319150145, 'Total loss': 0.42172915319150145} | train loss {'Reaction outcome loss': 0.4235421862573393, 'Total loss': 0.4235421862573393}
2022-11-28 01:14:01,765 INFO:     Found new best model at epoch 4
2022-11-28 01:14:01,766 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:01,766 INFO:     Epoch: 5
2022-11-28 01:14:02,511 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4106675880876454, 'Total loss': 0.4106675880876454} | train loss {'Reaction outcome loss': 0.4151899220361825, 'Total loss': 0.4151899220361825}
2022-11-28 01:14:02,511 INFO:     Found new best model at epoch 5
2022-11-28 01:14:02,512 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:02,512 INFO:     Epoch: 6
2022-11-28 01:14:03,258 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4298134666274894, 'Total loss': 0.4298134666274894} | train loss {'Reaction outcome loss': 0.41364216879611054, 'Total loss': 0.41364216879611054}
2022-11-28 01:14:03,259 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:03,259 INFO:     Epoch: 7
2022-11-28 01:14:04,009 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.398526322435249, 'Total loss': 0.398526322435249} | train loss {'Reaction outcome loss': 0.4019466139856846, 'Total loss': 0.4019466139856846}
2022-11-28 01:14:04,009 INFO:     Found new best model at epoch 7
2022-11-28 01:14:04,010 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:04,010 INFO:     Epoch: 8
2022-11-28 01:14:04,758 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4075877500528639, 'Total loss': 0.4075877500528639} | train loss {'Reaction outcome loss': 0.38785467200702234, 'Total loss': 0.38785467200702234}
2022-11-28 01:14:04,759 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:04,759 INFO:     Epoch: 9
2022-11-28 01:14:05,503 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4294595569372177, 'Total loss': 0.4294595569372177} | train loss {'Reaction outcome loss': 0.39359594028322925, 'Total loss': 0.39359594028322925}
2022-11-28 01:14:05,504 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:05,504 INFO:     Epoch: 10
2022-11-28 01:14:06,250 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4224866757338697, 'Total loss': 0.4224866757338697} | train loss {'Reaction outcome loss': 0.38090524618183413, 'Total loss': 0.38090524618183413}
2022-11-28 01:14:06,250 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:06,250 INFO:     Epoch: 11
2022-11-28 01:14:06,996 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42956708845767105, 'Total loss': 0.42956708845767105} | train loss {'Reaction outcome loss': 0.38285745214670897, 'Total loss': 0.38285745214670897}
2022-11-28 01:14:06,996 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:06,996 INFO:     Epoch: 12
2022-11-28 01:14:07,745 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4022273218089884, 'Total loss': 0.4022273218089884} | train loss {'Reaction outcome loss': 0.3713130265955002, 'Total loss': 0.3713130265955002}
2022-11-28 01:14:07,745 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:07,745 INFO:     Epoch: 13
2022-11-28 01:14:08,489 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41874647817828436, 'Total loss': 0.41874647817828436} | train loss {'Reaction outcome loss': 0.36755417044004124, 'Total loss': 0.36755417044004124}
2022-11-28 01:14:08,489 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:08,489 INFO:     Epoch: 14
2022-11-28 01:14:09,236 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4120626254853877, 'Total loss': 0.4120626254853877} | train loss {'Reaction outcome loss': 0.36266409545656175, 'Total loss': 0.36266409545656175}
2022-11-28 01:14:09,236 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:09,236 INFO:     Epoch: 15
2022-11-28 01:14:09,979 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39977278120138426, 'Total loss': 0.39977278120138426} | train loss {'Reaction outcome loss': 0.36404420621693134, 'Total loss': 0.36404420621693134}
2022-11-28 01:14:09,980 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:09,980 INFO:     Epoch: 16
2022-11-28 01:14:10,726 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41240650618618185, 'Total loss': 0.41240650618618185} | train loss {'Reaction outcome loss': 0.3596148300435274, 'Total loss': 0.3596148300435274}
2022-11-28 01:14:10,727 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:10,727 INFO:     Epoch: 17
2022-11-28 01:14:11,472 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4296690550717441, 'Total loss': 0.4296690550717441} | train loss {'Reaction outcome loss': 0.3561277105923622, 'Total loss': 0.3561277105923622}
2022-11-28 01:14:11,473 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:11,473 INFO:     Epoch: 18
2022-11-28 01:14:12,221 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4049108707430688, 'Total loss': 0.4049108707430688} | train loss {'Reaction outcome loss': 0.3549865288059077, 'Total loss': 0.3549865288059077}
2022-11-28 01:14:12,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:12,221 INFO:     Epoch: 19
2022-11-28 01:14:12,969 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4411475424739448, 'Total loss': 0.4411475424739448} | train loss {'Reaction outcome loss': 0.354386473735494, 'Total loss': 0.354386473735494}
2022-11-28 01:14:12,969 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:12,970 INFO:     Epoch: 20
2022-11-28 01:14:13,717 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4143360910767859, 'Total loss': 0.4143360910767859} | train loss {'Reaction outcome loss': 0.3613369516547649, 'Total loss': 0.3613369516547649}
2022-11-28 01:14:13,717 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:13,717 INFO:     Epoch: 21
2022-11-28 01:14:14,460 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41871203922412614, 'Total loss': 0.41871203922412614} | train loss {'Reaction outcome loss': 0.3538964647919901, 'Total loss': 0.3538964647919901}
2022-11-28 01:14:14,460 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:14,460 INFO:     Epoch: 22
2022-11-28 01:14:15,203 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4330722825093703, 'Total loss': 0.4330722825093703} | train loss {'Reaction outcome loss': 0.3487224437957329, 'Total loss': 0.3487224437957329}
2022-11-28 01:14:15,203 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:15,203 INFO:     Epoch: 23
2022-11-28 01:14:15,947 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4601495011963628, 'Total loss': 0.4601495011963628} | train loss {'Reaction outcome loss': 0.3473028584473556, 'Total loss': 0.3473028584473556}
2022-11-28 01:14:15,947 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:15,947 INFO:     Epoch: 24
2022-11-28 01:14:16,695 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41758826679804106, 'Total loss': 0.41758826679804106} | train loss {'Reaction outcome loss': 0.34891154475870634, 'Total loss': 0.34891154475870634}
2022-11-28 01:14:16,695 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:16,695 INFO:     Epoch: 25
2022-11-28 01:14:17,443 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3956742530519312, 'Total loss': 0.3956742530519312} | train loss {'Reaction outcome loss': 0.3522081516022163, 'Total loss': 0.3522081516022163}
2022-11-28 01:14:17,443 INFO:     Found new best model at epoch 25
2022-11-28 01:14:17,444 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:17,444 INFO:     Epoch: 26
2022-11-28 01:14:18,194 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3787038790231401, 'Total loss': 0.3787038790231401} | train loss {'Reaction outcome loss': 0.3430830071109437, 'Total loss': 0.3430830071109437}
2022-11-28 01:14:18,194 INFO:     Found new best model at epoch 26
2022-11-28 01:14:18,195 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:18,195 INFO:     Epoch: 27
2022-11-28 01:14:18,946 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41884503581307153, 'Total loss': 0.41884503581307153} | train loss {'Reaction outcome loss': 0.33498946466152707, 'Total loss': 0.33498946466152707}
2022-11-28 01:14:18,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:18,946 INFO:     Epoch: 28
2022-11-28 01:14:19,693 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40150022913109173, 'Total loss': 0.40150022913109173} | train loss {'Reaction outcome loss': 0.34809447079896927, 'Total loss': 0.34809447079896927}
2022-11-28 01:14:19,693 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:19,693 INFO:     Epoch: 29
2022-11-28 01:14:20,441 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41597739861092786, 'Total loss': 0.41597739861092786} | train loss {'Reaction outcome loss': 0.3499657293901809, 'Total loss': 0.3499657293901809}
2022-11-28 01:14:20,441 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:20,441 INFO:     Epoch: 30
2022-11-28 01:14:21,188 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4204579463059252, 'Total loss': 0.4204579463059252} | train loss {'Reaction outcome loss': 0.34160715672037295, 'Total loss': 0.34160715672037295}
2022-11-28 01:14:21,188 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:21,188 INFO:     Epoch: 31
2022-11-28 01:14:21,937 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40732833641496574, 'Total loss': 0.40732833641496574} | train loss {'Reaction outcome loss': 0.3380640188772832, 'Total loss': 0.3380640188772832}
2022-11-28 01:14:21,937 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:21,937 INFO:     Epoch: 32
2022-11-28 01:14:22,685 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42773978649215266, 'Total loss': 0.42773978649215266} | train loss {'Reaction outcome loss': 0.3371972916647792, 'Total loss': 0.3371972916647792}
2022-11-28 01:14:22,686 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:22,686 INFO:     Epoch: 33
2022-11-28 01:14:23,434 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4091790897602385, 'Total loss': 0.4091790897602385} | train loss {'Reaction outcome loss': 0.33813011039408947, 'Total loss': 0.33813011039408947}
2022-11-28 01:14:23,434 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:23,434 INFO:     Epoch: 34
2022-11-28 01:14:24,178 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4368226130238988, 'Total loss': 0.4368226130238988} | train loss {'Reaction outcome loss': 0.32727718106921644, 'Total loss': 0.32727718106921644}
2022-11-28 01:14:24,179 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:24,179 INFO:     Epoch: 35
2022-11-28 01:14:24,925 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40816041657870467, 'Total loss': 0.40816041657870467} | train loss {'Reaction outcome loss': 0.3276552549833732, 'Total loss': 0.3276552549833732}
2022-11-28 01:14:24,925 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:24,925 INFO:     Epoch: 36
2022-11-28 01:14:25,673 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42624578794295137, 'Total loss': 0.42624578794295137} | train loss {'Reaction outcome loss': 0.33512723454905136, 'Total loss': 0.33512723454905136}
2022-11-28 01:14:25,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:25,673 INFO:     Epoch: 37
2022-11-28 01:14:26,420 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4132993370294571, 'Total loss': 0.4132993370294571} | train loss {'Reaction outcome loss': 0.3384996345867553, 'Total loss': 0.3384996345867553}
2022-11-28 01:14:26,420 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:26,420 INFO:     Epoch: 38
2022-11-28 01:14:27,166 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40513834289529105, 'Total loss': 0.40513834289529105} | train loss {'Reaction outcome loss': 0.33321322711004364, 'Total loss': 0.33321322711004364}
2022-11-28 01:14:27,166 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:27,167 INFO:     Epoch: 39
2022-11-28 01:14:27,915 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42250202782452106, 'Total loss': 0.42250202782452106} | train loss {'Reaction outcome loss': 0.32994277589023113, 'Total loss': 0.32994277589023113}
2022-11-28 01:14:27,915 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:27,915 INFO:     Epoch: 40
2022-11-28 01:14:28,665 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41930088062178006, 'Total loss': 0.41930088062178006} | train loss {'Reaction outcome loss': 0.3328306746458815, 'Total loss': 0.3328306746458815}
2022-11-28 01:14:28,665 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:28,665 INFO:     Epoch: 41
2022-11-28 01:14:29,414 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4111410355703397, 'Total loss': 0.4111410355703397} | train loss {'Reaction outcome loss': 0.3300299543677078, 'Total loss': 0.3300299543677078}
2022-11-28 01:14:29,414 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:29,414 INFO:     Epoch: 42
2022-11-28 01:14:30,162 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41597008501941507, 'Total loss': 0.41597008501941507} | train loss {'Reaction outcome loss': 0.3241549691846294, 'Total loss': 0.3241549691846294}
2022-11-28 01:14:30,162 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:30,163 INFO:     Epoch: 43
2022-11-28 01:14:30,910 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42809886824000964, 'Total loss': 0.42809886824000964} | train loss {'Reaction outcome loss': 0.3192974194403618, 'Total loss': 0.3192974194403618}
2022-11-28 01:14:30,910 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:30,910 INFO:     Epoch: 44
2022-11-28 01:14:31,661 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4245123578743501, 'Total loss': 0.4245123578743501} | train loss {'Reaction outcome loss': 0.3291866812524536, 'Total loss': 0.3291866812524536}
2022-11-28 01:14:31,661 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:31,661 INFO:     Epoch: 45
2022-11-28 01:14:32,412 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40598222545602103, 'Total loss': 0.40598222545602103} | train loss {'Reaction outcome loss': 0.32725392876853865, 'Total loss': 0.32725392876853865}
2022-11-28 01:14:32,412 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:32,412 INFO:     Epoch: 46
2022-11-28 01:14:33,164 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39579325033859775, 'Total loss': 0.39579325033859775} | train loss {'Reaction outcome loss': 0.31980103843154445, 'Total loss': 0.31980103843154445}
2022-11-28 01:14:33,164 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:33,164 INFO:     Epoch: 47
2022-11-28 01:14:33,915 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4258842823857611, 'Total loss': 0.4258842823857611} | train loss {'Reaction outcome loss': 0.3319970381506268, 'Total loss': 0.3319970381506268}
2022-11-28 01:14:33,915 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:33,915 INFO:     Epoch: 48
2022-11-28 01:14:34,664 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4285702383653684, 'Total loss': 0.4285702383653684} | train loss {'Reaction outcome loss': 0.3230548646721628, 'Total loss': 0.3230548646721628}
2022-11-28 01:14:34,664 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:34,664 INFO:     Epoch: 49
2022-11-28 01:14:35,414 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43145491352135484, 'Total loss': 0.43145491352135484} | train loss {'Reaction outcome loss': 0.32302683471671995, 'Total loss': 0.32302683471671995}
2022-11-28 01:14:35,415 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:35,415 INFO:     Epoch: 50
2022-11-28 01:14:36,166 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.406847459687428, 'Total loss': 0.406847459687428} | train loss {'Reaction outcome loss': 0.33716576492353795, 'Total loss': 0.33716576492353795}
2022-11-28 01:14:36,167 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:36,167 INFO:     Epoch: 51
2022-11-28 01:14:36,921 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3924490941519087, 'Total loss': 0.3924490941519087} | train loss {'Reaction outcome loss': 0.319732848164295, 'Total loss': 0.319732848164295}
2022-11-28 01:14:36,921 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:36,921 INFO:     Epoch: 52
2022-11-28 01:14:37,671 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4223709214817394, 'Total loss': 0.4223709214817394} | train loss {'Reaction outcome loss': 0.31357831601053476, 'Total loss': 0.31357831601053476}
2022-11-28 01:14:37,671 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:37,672 INFO:     Epoch: 53
2022-11-28 01:14:38,425 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41408634558320045, 'Total loss': 0.41408634558320045} | train loss {'Reaction outcome loss': 0.3270213821031634, 'Total loss': 0.3270213821031634}
2022-11-28 01:14:38,425 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:38,425 INFO:     Epoch: 54
2022-11-28 01:14:39,178 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4278063747015866, 'Total loss': 0.4278063747015866} | train loss {'Reaction outcome loss': 0.3234178906066283, 'Total loss': 0.3234178906066283}
2022-11-28 01:14:39,178 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:39,178 INFO:     Epoch: 55
2022-11-28 01:14:39,929 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39718562906438654, 'Total loss': 0.39718562906438654} | train loss {'Reaction outcome loss': 0.32324613450515655, 'Total loss': 0.32324613450515655}
2022-11-28 01:14:39,929 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:39,929 INFO:     Epoch: 56
2022-11-28 01:14:40,675 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40592966906049033, 'Total loss': 0.40592966906049033} | train loss {'Reaction outcome loss': 0.3182707683243338, 'Total loss': 0.3182707683243338}
2022-11-28 01:14:40,675 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:40,676 INFO:     Epoch: 57
2022-11-28 01:14:41,424 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4193272864954038, 'Total loss': 0.4193272864954038} | train loss {'Reaction outcome loss': 0.31705869539009945, 'Total loss': 0.31705869539009945}
2022-11-28 01:14:41,424 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:41,424 INFO:     Epoch: 58
2022-11-28 01:14:42,180 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42059152776544745, 'Total loss': 0.42059152776544745} | train loss {'Reaction outcome loss': 0.32431411625997675, 'Total loss': 0.32431411625997675}
2022-11-28 01:14:42,181 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:42,181 INFO:     Epoch: 59
2022-11-28 01:14:42,937 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4396451450884342, 'Total loss': 0.4396451450884342} | train loss {'Reaction outcome loss': 0.3205410803277646, 'Total loss': 0.3205410803277646}
2022-11-28 01:14:42,938 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:42,938 INFO:     Epoch: 60
2022-11-28 01:14:43,686 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42805268412286585, 'Total loss': 0.42805268412286585} | train loss {'Reaction outcome loss': 0.3271441958363979, 'Total loss': 0.3271441958363979}
2022-11-28 01:14:43,687 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:43,687 INFO:     Epoch: 61
2022-11-28 01:14:44,438 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4126567972654646, 'Total loss': 0.4126567972654646} | train loss {'Reaction outcome loss': 0.3248761602407021, 'Total loss': 0.3248761602407021}
2022-11-28 01:14:44,438 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:44,438 INFO:     Epoch: 62
2022-11-28 01:14:45,188 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4078942933543162, 'Total loss': 0.4078942933543162} | train loss {'Reaction outcome loss': 0.32680295271077947, 'Total loss': 0.32680295271077947}
2022-11-28 01:14:45,189 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:45,189 INFO:     Epoch: 63
2022-11-28 01:14:45,940 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4229143580252474, 'Total loss': 0.4229143580252474} | train loss {'Reaction outcome loss': 0.31426099669789115, 'Total loss': 0.31426099669789115}
2022-11-28 01:14:45,941 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:45,941 INFO:     Epoch: 64
2022-11-28 01:14:46,699 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4096655002371831, 'Total loss': 0.4096655002371831} | train loss {'Reaction outcome loss': 0.31744780819562657, 'Total loss': 0.31744780819562657}
2022-11-28 01:14:46,699 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:46,700 INFO:     Epoch: 65
2022-11-28 01:14:47,452 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4034167302941734, 'Total loss': 0.4034167302941734} | train loss {'Reaction outcome loss': 0.31466183667221376, 'Total loss': 0.31466183667221376}
2022-11-28 01:14:47,452 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:47,452 INFO:     Epoch: 66
2022-11-28 01:14:48,202 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42772013626315375, 'Total loss': 0.42772013626315375} | train loss {'Reaction outcome loss': 0.32338309441242485, 'Total loss': 0.32338309441242485}
2022-11-28 01:14:48,202 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:48,202 INFO:     Epoch: 67
2022-11-28 01:14:48,953 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.415516408668323, 'Total loss': 0.415516408668323} | train loss {'Reaction outcome loss': 0.31696424317816574, 'Total loss': 0.31696424317816574}
2022-11-28 01:14:48,953 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:48,953 INFO:     Epoch: 68
2022-11-28 01:14:49,702 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38115869902751665, 'Total loss': 0.38115869902751665} | train loss {'Reaction outcome loss': 0.308193878150515, 'Total loss': 0.308193878150515}
2022-11-28 01:14:49,702 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:49,702 INFO:     Epoch: 69
2022-11-28 01:14:50,449 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3921571946279569, 'Total loss': 0.3921571946279569} | train loss {'Reaction outcome loss': 0.3192522728274907, 'Total loss': 0.3192522728274907}
2022-11-28 01:14:50,449 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:50,449 INFO:     Epoch: 70
2022-11-28 01:14:51,199 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4094960638745265, 'Total loss': 0.4094960638745265} | train loss {'Reaction outcome loss': 0.3188330476743079, 'Total loss': 0.3188330476743079}
2022-11-28 01:14:51,199 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:51,199 INFO:     Epoch: 71
2022-11-28 01:14:51,948 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42101581513204356, 'Total loss': 0.42101581513204356} | train loss {'Reaction outcome loss': 0.30766373121690366, 'Total loss': 0.30766373121690366}
2022-11-28 01:14:51,948 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:51,948 INFO:     Epoch: 72
2022-11-28 01:14:52,700 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44318924336270854, 'Total loss': 0.44318924336270854} | train loss {'Reaction outcome loss': 0.30897384037774417, 'Total loss': 0.30897384037774417}
2022-11-28 01:14:52,700 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:52,700 INFO:     Epoch: 73
2022-11-28 01:14:53,450 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40720949982377613, 'Total loss': 0.40720949982377613} | train loss {'Reaction outcome loss': 0.3162013437118261, 'Total loss': 0.3162013437118261}
2022-11-28 01:14:53,450 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:53,450 INFO:     Epoch: 74
2022-11-28 01:14:54,199 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4474028499627655, 'Total loss': 0.4474028499627655} | train loss {'Reaction outcome loss': 0.3137157573214462, 'Total loss': 0.3137157573214462}
2022-11-28 01:14:54,200 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:54,200 INFO:     Epoch: 75
2022-11-28 01:14:54,949 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44309152459556406, 'Total loss': 0.44309152459556406} | train loss {'Reaction outcome loss': 0.31019290055959453, 'Total loss': 0.31019290055959453}
2022-11-28 01:14:54,949 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:54,949 INFO:     Epoch: 76
2022-11-28 01:14:55,701 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4394981444559314, 'Total loss': 0.4394981444559314} | train loss {'Reaction outcome loss': 0.3140680569734785, 'Total loss': 0.3140680569734785}
2022-11-28 01:14:55,701 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:55,701 INFO:     Epoch: 77
2022-11-28 01:14:56,449 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43595791641961446, 'Total loss': 0.43595791641961446} | train loss {'Reaction outcome loss': 0.3157034425605689, 'Total loss': 0.3157034425605689}
2022-11-28 01:14:56,449 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:56,449 INFO:     Epoch: 78
2022-11-28 01:14:57,200 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44688245484774763, 'Total loss': 0.44688245484774763} | train loss {'Reaction outcome loss': 0.3200723214916164, 'Total loss': 0.3200723214916164}
2022-11-28 01:14:57,200 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:57,200 INFO:     Epoch: 79
2022-11-28 01:14:57,951 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4524925256317312, 'Total loss': 0.4524925256317312} | train loss {'Reaction outcome loss': 0.311656238706482, 'Total loss': 0.311656238706482}
2022-11-28 01:14:57,951 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:57,951 INFO:     Epoch: 80
2022-11-28 01:14:58,699 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41303587112237106, 'Total loss': 0.41303587112237106} | train loss {'Reaction outcome loss': 0.3169773717621161, 'Total loss': 0.3169773717621161}
2022-11-28 01:14:58,700 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:58,700 INFO:     Epoch: 81
2022-11-28 01:14:59,450 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4134330300783569, 'Total loss': 0.4134330300783569} | train loss {'Reaction outcome loss': 0.3132074012781583, 'Total loss': 0.3132074012781583}
2022-11-28 01:14:59,450 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:14:59,450 INFO:     Epoch: 82
2022-11-28 01:15:00,198 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4299933382055976, 'Total loss': 0.4299933382055976} | train loss {'Reaction outcome loss': 0.3077856119301531, 'Total loss': 0.3077856119301531}
2022-11-28 01:15:00,198 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:00,198 INFO:     Epoch: 83
2022-11-28 01:15:00,949 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41265219348398124, 'Total loss': 0.41265219348398124} | train loss {'Reaction outcome loss': 0.31156248594784447, 'Total loss': 0.31156248594784447}
2022-11-28 01:15:00,949 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:00,949 INFO:     Epoch: 84
2022-11-28 01:15:01,698 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44091734594919463, 'Total loss': 0.44091734594919463} | train loss {'Reaction outcome loss': 0.321091866976912, 'Total loss': 0.321091866976912}
2022-11-28 01:15:01,699 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:01,699 INFO:     Epoch: 85
2022-11-28 01:15:02,447 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4179683647711169, 'Total loss': 0.4179683647711169} | train loss {'Reaction outcome loss': 0.3137297968590452, 'Total loss': 0.3137297968590452}
2022-11-28 01:15:02,447 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:02,447 INFO:     Epoch: 86
2022-11-28 01:15:03,197 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4414773580025543, 'Total loss': 0.4414773580025543} | train loss {'Reaction outcome loss': 0.3070283920293854, 'Total loss': 0.3070283920293854}
2022-11-28 01:15:03,197 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:03,198 INFO:     Epoch: 87
2022-11-28 01:15:03,949 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4149638902057301, 'Total loss': 0.4149638902057301} | train loss {'Reaction outcome loss': 0.315450499044551, 'Total loss': 0.315450499044551}
2022-11-28 01:15:03,949 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:03,949 INFO:     Epoch: 88
2022-11-28 01:15:04,699 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4369924839755351, 'Total loss': 0.4369924839755351} | train loss {'Reaction outcome loss': 0.3086176456643208, 'Total loss': 0.3086176456643208}
2022-11-28 01:15:04,699 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:04,699 INFO:     Epoch: 89
2022-11-28 01:15:05,445 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4064136784185063, 'Total loss': 0.4064136784185063} | train loss {'Reaction outcome loss': 0.3163396647320159, 'Total loss': 0.3163396647320159}
2022-11-28 01:15:05,445 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:05,445 INFO:     Epoch: 90
2022-11-28 01:15:06,190 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3999440558254719, 'Total loss': 0.3999440558254719} | train loss {'Reaction outcome loss': 0.30998349994901686, 'Total loss': 0.30998349994901686}
2022-11-28 01:15:06,190 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:06,190 INFO:     Epoch: 91
2022-11-28 01:15:06,940 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.408767991783944, 'Total loss': 0.408767991783944} | train loss {'Reaction outcome loss': 0.31826857890513155, 'Total loss': 0.31826857890513155}
2022-11-28 01:15:06,941 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:06,941 INFO:     Epoch: 92
2022-11-28 01:15:07,691 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4144910286096009, 'Total loss': 0.4144910286096009} | train loss {'Reaction outcome loss': 0.309283748990105, 'Total loss': 0.309283748990105}
2022-11-28 01:15:07,691 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:07,691 INFO:     Epoch: 93
2022-11-28 01:15:08,440 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40226504613052716, 'Total loss': 0.40226504613052716} | train loss {'Reaction outcome loss': 0.3151842462079179, 'Total loss': 0.3151842462079179}
2022-11-28 01:15:08,440 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:08,440 INFO:     Epoch: 94
2022-11-28 01:15:09,189 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41450790417465294, 'Total loss': 0.41450790417465294} | train loss {'Reaction outcome loss': 0.3111231964411995, 'Total loss': 0.3111231964411995}
2022-11-28 01:15:09,189 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:09,189 INFO:     Epoch: 95
2022-11-28 01:15:09,935 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45323060791600833, 'Total loss': 0.45323060791600833} | train loss {'Reaction outcome loss': 0.3126244435627614, 'Total loss': 0.3126244435627614}
2022-11-28 01:15:09,935 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:09,935 INFO:     Epoch: 96
2022-11-28 01:15:10,689 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43089755929329177, 'Total loss': 0.43089755929329177} | train loss {'Reaction outcome loss': 0.32023329074464496, 'Total loss': 0.32023329074464496}
2022-11-28 01:15:10,689 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:10,689 INFO:     Epoch: 97
2022-11-28 01:15:11,434 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41903506727381185, 'Total loss': 0.41903506727381185} | train loss {'Reaction outcome loss': 0.3097938923165202, 'Total loss': 0.3097938923165202}
2022-11-28 01:15:11,434 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:11,434 INFO:     Epoch: 98
2022-11-28 01:15:12,182 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4143305041573264, 'Total loss': 0.4143305041573264} | train loss {'Reaction outcome loss': 0.30929175626126026, 'Total loss': 0.30929175626126026}
2022-11-28 01:15:12,182 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:12,182 INFO:     Epoch: 99
2022-11-28 01:15:12,931 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42148573290218005, 'Total loss': 0.42148573290218005} | train loss {'Reaction outcome loss': 0.3035791470939594, 'Total loss': 0.3035791470939594}
2022-11-28 01:15:12,931 INFO:     Best model found after epoch 27 of 100.
2022-11-28 01:15:12,931 INFO:   Done with stage: TRAINING
2022-11-28 01:15:12,931 INFO:   Starting stage: EVALUATION
2022-11-28 01:15:13,046 INFO:   Done with stage: EVALUATION
2022-11-28 01:15:13,047 INFO:   Leaving out SEQ value Fold_9
2022-11-28 01:15:13,060 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 01:15:13,060 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:15:13,700 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:15:13,701 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:15:13,770 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:15:13,770 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:15:13,770 INFO:     No hyperparam tuning for this model
2022-11-28 01:15:13,770 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:15:13,770 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:15:13,771 INFO:     None feature selector for col prot
2022-11-28 01:15:13,771 INFO:     None feature selector for col prot
2022-11-28 01:15:13,771 INFO:     None feature selector for col prot
2022-11-28 01:15:13,772 INFO:     None feature selector for col chem
2022-11-28 01:15:13,772 INFO:     None feature selector for col chem
2022-11-28 01:15:13,772 INFO:     None feature selector for col chem
2022-11-28 01:15:13,772 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:15:13,772 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:15:13,774 INFO:     Number of params in model 169741
2022-11-28 01:15:13,777 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:15:13,777 INFO:   Starting stage: TRAINING
2022-11-28 01:15:13,829 INFO:     Val loss before train {'Reaction outcome loss': 1.0334029333157972, 'Total loss': 1.0334029333157972}
2022-11-28 01:15:13,829 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:13,830 INFO:     Epoch: 0
2022-11-28 01:15:14,571 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5899472331458872, 'Total loss': 0.5899472331458872} | train loss {'Reaction outcome loss': 0.6393641388488684, 'Total loss': 0.6393641388488684}
2022-11-28 01:15:14,571 INFO:     Found new best model at epoch 0
2022-11-28 01:15:14,571 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:14,572 INFO:     Epoch: 1
2022-11-28 01:15:15,319 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5234086120670493, 'Total loss': 0.5234086120670493} | train loss {'Reaction outcome loss': 0.5155650794747387, 'Total loss': 0.5155650794747387}
2022-11-28 01:15:15,319 INFO:     Found new best model at epoch 1
2022-11-28 01:15:15,320 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:15,320 INFO:     Epoch: 2
2022-11-28 01:15:16,060 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49552429061044345, 'Total loss': 0.49552429061044345} | train loss {'Reaction outcome loss': 0.47969302679845677, 'Total loss': 0.47969302679845677}
2022-11-28 01:15:16,060 INFO:     Found new best model at epoch 2
2022-11-28 01:15:16,061 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:16,061 INFO:     Epoch: 3
2022-11-28 01:15:16,803 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48460212485356763, 'Total loss': 0.48460212485356763} | train loss {'Reaction outcome loss': 0.4412857298305643, 'Total loss': 0.4412857298305643}
2022-11-28 01:15:16,803 INFO:     Found new best model at epoch 3
2022-11-28 01:15:16,804 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:16,804 INFO:     Epoch: 4
2022-11-28 01:15:17,548 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.458601345054128, 'Total loss': 0.458601345054128} | train loss {'Reaction outcome loss': 0.42965894454886555, 'Total loss': 0.42965894454886555}
2022-11-28 01:15:17,549 INFO:     Found new best model at epoch 4
2022-11-28 01:15:17,549 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:17,550 INFO:     Epoch: 5
2022-11-28 01:15:18,289 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4693611162629994, 'Total loss': 0.4693611162629994} | train loss {'Reaction outcome loss': 0.4081057477516201, 'Total loss': 0.4081057477516201}
2022-11-28 01:15:18,289 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:18,289 INFO:     Epoch: 6
2022-11-28 01:15:19,034 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.472980949011716, 'Total loss': 0.472980949011716} | train loss {'Reaction outcome loss': 0.4018102030643085, 'Total loss': 0.4018102030643085}
2022-11-28 01:15:19,034 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:19,034 INFO:     Epoch: 7
2022-11-28 01:15:19,776 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45185520669276064, 'Total loss': 0.45185520669276064} | train loss {'Reaction outcome loss': 0.3945962027363811, 'Total loss': 0.3945962027363811}
2022-11-28 01:15:19,776 INFO:     Found new best model at epoch 7
2022-11-28 01:15:19,777 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:19,777 INFO:     Epoch: 8
2022-11-28 01:15:20,520 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4520638439465653, 'Total loss': 0.4520638439465653} | train loss {'Reaction outcome loss': 0.38903180144817723, 'Total loss': 0.38903180144817723}
2022-11-28 01:15:20,521 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:20,521 INFO:     Epoch: 9
2022-11-28 01:15:21,267 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4375859746201472, 'Total loss': 0.4375859746201472} | train loss {'Reaction outcome loss': 0.3790768420225696, 'Total loss': 0.3790768420225696}
2022-11-28 01:15:21,267 INFO:     Found new best model at epoch 9
2022-11-28 01:15:21,268 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:21,268 INFO:     Epoch: 10
2022-11-28 01:15:22,009 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48207552764903416, 'Total loss': 0.48207552764903416} | train loss {'Reaction outcome loss': 0.3876120609189817, 'Total loss': 0.3876120609189817}
2022-11-28 01:15:22,009 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:22,009 INFO:     Epoch: 11
2022-11-28 01:15:22,753 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45845502174713393, 'Total loss': 0.45845502174713393} | train loss {'Reaction outcome loss': 0.39403951997578385, 'Total loss': 0.39403951997578385}
2022-11-28 01:15:22,753 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:22,753 INFO:     Epoch: 12
2022-11-28 01:15:23,500 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44971995292739436, 'Total loss': 0.44971995292739436} | train loss {'Reaction outcome loss': 0.379395987355878, 'Total loss': 0.379395987355878}
2022-11-28 01:15:23,500 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:23,500 INFO:     Epoch: 13
2022-11-28 01:15:24,243 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.430887927047231, 'Total loss': 0.430887927047231} | train loss {'Reaction outcome loss': 0.36073747425064867, 'Total loss': 0.36073747425064867}
2022-11-28 01:15:24,243 INFO:     Found new best model at epoch 13
2022-11-28 01:15:24,244 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:24,244 INFO:     Epoch: 14
2022-11-28 01:15:24,987 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46823800456794823, 'Total loss': 0.46823800456794823} | train loss {'Reaction outcome loss': 0.35660399270323123, 'Total loss': 0.35660399270323123}
2022-11-28 01:15:24,987 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:24,987 INFO:     Epoch: 15
2022-11-28 01:15:25,732 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4426343437622894, 'Total loss': 0.4426343437622894} | train loss {'Reaction outcome loss': 0.3565331922791265, 'Total loss': 0.3565331922791265}
2022-11-28 01:15:25,732 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:25,733 INFO:     Epoch: 16
2022-11-28 01:15:26,476 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43721806596625934, 'Total loss': 0.43721806596625934} | train loss {'Reaction outcome loss': 0.3579183752226232, 'Total loss': 0.3579183752226232}
2022-11-28 01:15:26,476 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:26,476 INFO:     Epoch: 17
2022-11-28 01:15:27,218 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44253632917322894, 'Total loss': 0.44253632917322894} | train loss {'Reaction outcome loss': 0.34635910218362864, 'Total loss': 0.34635910218362864}
2022-11-28 01:15:27,218 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:27,218 INFO:     Epoch: 18
2022-11-28 01:15:27,962 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4443124458193779, 'Total loss': 0.4443124458193779} | train loss {'Reaction outcome loss': 0.34459522277539073, 'Total loss': 0.34459522277539073}
2022-11-28 01:15:27,962 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:27,962 INFO:     Epoch: 19
2022-11-28 01:15:28,704 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46688309515064413, 'Total loss': 0.46688309515064413} | train loss {'Reaction outcome loss': 0.3443794501455207, 'Total loss': 0.3443794501455207}
2022-11-28 01:15:28,705 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:28,705 INFO:     Epoch: 20
2022-11-28 01:15:29,449 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43789188767021353, 'Total loss': 0.43789188767021353} | train loss {'Reaction outcome loss': 0.34548871688212945, 'Total loss': 0.34548871688212945}
2022-11-28 01:15:29,449 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:29,449 INFO:     Epoch: 21
2022-11-28 01:15:30,191 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4761338084936142, 'Total loss': 0.4761338084936142} | train loss {'Reaction outcome loss': 0.338691770412058, 'Total loss': 0.338691770412058}
2022-11-28 01:15:30,191 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:30,191 INFO:     Epoch: 22
2022-11-28 01:15:30,934 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4494363868778402, 'Total loss': 0.4494363868778402} | train loss {'Reaction outcome loss': 0.3521598626365546, 'Total loss': 0.3521598626365546}
2022-11-28 01:15:30,934 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:30,934 INFO:     Epoch: 23
2022-11-28 01:15:31,676 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4817059361799197, 'Total loss': 0.4817059361799197} | train loss {'Reaction outcome loss': 0.34711940695158383, 'Total loss': 0.34711940695158383}
2022-11-28 01:15:31,676 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:31,676 INFO:     Epoch: 24
2022-11-28 01:15:32,416 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41977310620925645, 'Total loss': 0.41977310620925645} | train loss {'Reaction outcome loss': 0.3500758311164524, 'Total loss': 0.3500758311164524}
2022-11-28 01:15:32,416 INFO:     Found new best model at epoch 24
2022-11-28 01:15:32,416 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:32,417 INFO:     Epoch: 25
2022-11-28 01:15:33,159 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4220516776496714, 'Total loss': 0.4220516776496714} | train loss {'Reaction outcome loss': 0.33926377701855864, 'Total loss': 0.33926377701855864}
2022-11-28 01:15:33,159 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:33,159 INFO:     Epoch: 26
2022-11-28 01:15:33,902 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41748582622544333, 'Total loss': 0.41748582622544333} | train loss {'Reaction outcome loss': 0.332523129850264, 'Total loss': 0.332523129850264}
2022-11-28 01:15:33,902 INFO:     Found new best model at epoch 26
2022-11-28 01:15:33,902 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:33,903 INFO:     Epoch: 27
2022-11-28 01:15:34,646 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4262215325778181, 'Total loss': 0.4262215325778181} | train loss {'Reaction outcome loss': 0.3264090823620437, 'Total loss': 0.3264090823620437}
2022-11-28 01:15:34,646 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:34,646 INFO:     Epoch: 28
2022-11-28 01:15:35,389 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4210577972910621, 'Total loss': 0.4210577972910621} | train loss {'Reaction outcome loss': 0.3300181680966003, 'Total loss': 0.3300181680966003}
2022-11-28 01:15:35,389 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:35,389 INFO:     Epoch: 29
2022-11-28 01:15:36,132 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48594596998935397, 'Total loss': 0.48594596998935397} | train loss {'Reaction outcome loss': 0.33363642413847844, 'Total loss': 0.33363642413847844}
2022-11-28 01:15:36,132 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:36,133 INFO:     Epoch: 30
2022-11-28 01:15:36,875 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4767304973846132, 'Total loss': 0.4767304973846132} | train loss {'Reaction outcome loss': 0.3375679305358696, 'Total loss': 0.3375679305358696}
2022-11-28 01:15:36,875 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:36,875 INFO:     Epoch: 31
2022-11-28 01:15:37,618 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.480256396938454, 'Total loss': 0.480256396938454} | train loss {'Reaction outcome loss': 0.32109128005721566, 'Total loss': 0.32109128005721566}
2022-11-28 01:15:37,619 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:37,619 INFO:     Epoch: 32
2022-11-28 01:15:38,361 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4633081531660123, 'Total loss': 0.4633081531660123} | train loss {'Reaction outcome loss': 0.322323030773324, 'Total loss': 0.322323030773324}
2022-11-28 01:15:38,361 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:38,361 INFO:     Epoch: 33
2022-11-28 01:15:39,109 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4330490759827874, 'Total loss': 0.4330490759827874} | train loss {'Reaction outcome loss': 0.3214721013999239, 'Total loss': 0.3214721013999239}
2022-11-28 01:15:39,109 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:39,109 INFO:     Epoch: 34
2022-11-28 01:15:39,851 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44384450262243097, 'Total loss': 0.44384450262243097} | train loss {'Reaction outcome loss': 0.32110109883040067, 'Total loss': 0.32110109883040067}
2022-11-28 01:15:39,852 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:39,852 INFO:     Epoch: 35
2022-11-28 01:15:40,597 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4502110386436636, 'Total loss': 0.4502110386436636} | train loss {'Reaction outcome loss': 0.3185333278094256, 'Total loss': 0.3185333278094256}
2022-11-28 01:15:40,597 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:40,597 INFO:     Epoch: 36
2022-11-28 01:15:41,341 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4148409464819865, 'Total loss': 0.4148409464819865} | train loss {'Reaction outcome loss': 0.317571980097267, 'Total loss': 0.317571980097267}
2022-11-28 01:15:41,341 INFO:     Found new best model at epoch 36
2022-11-28 01:15:41,342 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:41,342 INFO:     Epoch: 37
2022-11-28 01:15:42,086 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4289666986600919, 'Total loss': 0.4289666986600919} | train loss {'Reaction outcome loss': 0.32575298827669397, 'Total loss': 0.32575298827669397}
2022-11-28 01:15:42,086 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:42,086 INFO:     Epoch: 38
2022-11-28 01:15:42,828 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4233466112478213, 'Total loss': 0.4233466112478213} | train loss {'Reaction outcome loss': 0.3167782199346585, 'Total loss': 0.3167782199346585}
2022-11-28 01:15:42,828 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:42,828 INFO:     Epoch: 39
2022-11-28 01:15:43,570 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4527378407391635, 'Total loss': 0.4527378407391635} | train loss {'Reaction outcome loss': 0.3272619999734014, 'Total loss': 0.3272619999734014}
2022-11-28 01:15:43,570 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:43,570 INFO:     Epoch: 40
2022-11-28 01:15:44,314 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4209754480557008, 'Total loss': 0.4209754480557008} | train loss {'Reaction outcome loss': 0.32655108802638916, 'Total loss': 0.32655108802638916}
2022-11-28 01:15:44,314 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:44,315 INFO:     Epoch: 41
2022-11-28 01:15:45,056 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4580730467357419, 'Total loss': 0.4580730467357419} | train loss {'Reaction outcome loss': 0.31787413092676986, 'Total loss': 0.31787413092676986}
2022-11-28 01:15:45,056 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:45,056 INFO:     Epoch: 42
2022-11-28 01:15:45,799 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4533186731013385, 'Total loss': 0.4533186731013385} | train loss {'Reaction outcome loss': 0.31975211166901146, 'Total loss': 0.31975211166901146}
2022-11-28 01:15:45,799 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:45,799 INFO:     Epoch: 43
2022-11-28 01:15:46,546 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4489287148145112, 'Total loss': 0.4489287148145112} | train loss {'Reaction outcome loss': 0.3219504168005905, 'Total loss': 0.3219504168005905}
2022-11-28 01:15:46,546 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:46,547 INFO:     Epoch: 44
2022-11-28 01:15:47,290 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4410690567032857, 'Total loss': 0.4410690567032857} | train loss {'Reaction outcome loss': 0.31128980838344905, 'Total loss': 0.31128980838344905}
2022-11-28 01:15:47,290 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:47,290 INFO:     Epoch: 45
2022-11-28 01:15:48,036 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45290345122868364, 'Total loss': 0.45290345122868364} | train loss {'Reaction outcome loss': 0.31175040263637355, 'Total loss': 0.31175040263637355}
2022-11-28 01:15:48,037 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:48,037 INFO:     Epoch: 46
2022-11-28 01:15:48,781 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42312775112011214, 'Total loss': 0.42312775112011214} | train loss {'Reaction outcome loss': 0.31848125524728405, 'Total loss': 0.31848125524728405}
2022-11-28 01:15:48,781 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:48,781 INFO:     Epoch: 47
2022-11-28 01:15:49,526 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.461855734275146, 'Total loss': 0.461855734275146} | train loss {'Reaction outcome loss': 0.34556236709298394, 'Total loss': 0.34556236709298394}
2022-11-28 01:15:49,526 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:49,526 INFO:     Epoch: 48
2022-11-28 01:15:50,273 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43501122431321576, 'Total loss': 0.43501122431321576} | train loss {'Reaction outcome loss': 0.3455035226487438, 'Total loss': 0.3455035226487438}
2022-11-28 01:15:50,274 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:50,274 INFO:     Epoch: 49
2022-11-28 01:15:51,016 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4298340095715089, 'Total loss': 0.4298340095715089} | train loss {'Reaction outcome loss': 0.3104380295283881, 'Total loss': 0.3104380295283881}
2022-11-28 01:15:51,016 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:51,016 INFO:     Epoch: 50
2022-11-28 01:15:51,764 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4537744996222583, 'Total loss': 0.4537744996222583} | train loss {'Reaction outcome loss': 0.311280302730717, 'Total loss': 0.311280302730717}
2022-11-28 01:15:51,764 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:51,764 INFO:     Epoch: 51
2022-11-28 01:15:52,508 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40802172029560263, 'Total loss': 0.40802172029560263} | train loss {'Reaction outcome loss': 0.30782898862352254, 'Total loss': 0.30782898862352254}
2022-11-28 01:15:52,508 INFO:     Found new best model at epoch 51
2022-11-28 01:15:52,509 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:52,509 INFO:     Epoch: 52
2022-11-28 01:15:53,253 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41159511323679576, 'Total loss': 0.41159511323679576} | train loss {'Reaction outcome loss': 0.3118186573448934, 'Total loss': 0.3118186573448934}
2022-11-28 01:15:53,254 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:53,254 INFO:     Epoch: 53
2022-11-28 01:15:53,999 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4461539326743646, 'Total loss': 0.4461539326743646} | train loss {'Reaction outcome loss': 0.31335523902336776, 'Total loss': 0.31335523902336776}
2022-11-28 01:15:53,999 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:53,999 INFO:     Epoch: 54
2022-11-28 01:15:54,748 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44818400286815385, 'Total loss': 0.44818400286815385} | train loss {'Reaction outcome loss': 0.31639606134611586, 'Total loss': 0.31639606134611586}
2022-11-28 01:15:54,748 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:54,748 INFO:     Epoch: 55
2022-11-28 01:15:55,492 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4386384876614267, 'Total loss': 0.4386384876614267} | train loss {'Reaction outcome loss': 0.34942431499529253, 'Total loss': 0.34942431499529253}
2022-11-28 01:15:55,492 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:55,492 INFO:     Epoch: 56
2022-11-28 01:15:56,238 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42870943349870766, 'Total loss': 0.42870943349870766} | train loss {'Reaction outcome loss': 0.31977685187992294, 'Total loss': 0.31977685187992294}
2022-11-28 01:15:56,238 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:56,238 INFO:     Epoch: 57
2022-11-28 01:15:56,984 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41608164975927636, 'Total loss': 0.41608164975927636} | train loss {'Reaction outcome loss': 0.31561317265693917, 'Total loss': 0.31561317265693917}
2022-11-28 01:15:56,984 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:56,984 INFO:     Epoch: 58
2022-11-28 01:15:57,730 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4728326851671392, 'Total loss': 0.4728326851671392} | train loss {'Reaction outcome loss': 0.3046599261553181, 'Total loss': 0.3046599261553181}
2022-11-28 01:15:57,730 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:57,730 INFO:     Epoch: 59
2022-11-28 01:15:58,476 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45835761014710774, 'Total loss': 0.45835761014710774} | train loss {'Reaction outcome loss': 0.30843677868944525, 'Total loss': 0.30843677868944525}
2022-11-28 01:15:58,477 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:58,477 INFO:     Epoch: 60
2022-11-28 01:15:59,222 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4326399307359349, 'Total loss': 0.4326399307359349} | train loss {'Reaction outcome loss': 0.3120380449089927, 'Total loss': 0.3120380449089927}
2022-11-28 01:15:59,222 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:59,222 INFO:     Epoch: 61
2022-11-28 01:15:59,967 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4605537178841504, 'Total loss': 0.4605537178841504} | train loss {'Reaction outcome loss': 0.3276715591580038, 'Total loss': 0.3276715591580038}
2022-11-28 01:15:59,967 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:15:59,968 INFO:     Epoch: 62
2022-11-28 01:16:00,717 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42431504042311147, 'Total loss': 0.42431504042311147} | train loss {'Reaction outcome loss': 0.3287286234242834, 'Total loss': 0.3287286234242834}
2022-11-28 01:16:00,717 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:00,717 INFO:     Epoch: 63
2022-11-28 01:16:01,463 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4257888045500625, 'Total loss': 0.4257888045500625} | train loss {'Reaction outcome loss': 0.30540198449663786, 'Total loss': 0.30540198449663786}
2022-11-28 01:16:01,463 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:01,463 INFO:     Epoch: 64
2022-11-28 01:16:02,208 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46390010314908897, 'Total loss': 0.46390010314908897} | train loss {'Reaction outcome loss': 0.31299301369897153, 'Total loss': 0.31299301369897153}
2022-11-28 01:16:02,208 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:02,208 INFO:     Epoch: 65
2022-11-28 01:16:02,953 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45175706104121427, 'Total loss': 0.45175706104121427} | train loss {'Reaction outcome loss': 0.30888405885652975, 'Total loss': 0.30888405885652975}
2022-11-28 01:16:02,953 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:02,953 INFO:     Epoch: 66
2022-11-28 01:16:03,700 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.456507837230509, 'Total loss': 0.456507837230509} | train loss {'Reaction outcome loss': 0.30335137838882353, 'Total loss': 0.30335137838882353}
2022-11-28 01:16:03,700 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:03,700 INFO:     Epoch: 67
2022-11-28 01:16:04,449 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45848240415481006, 'Total loss': 0.45848240415481006} | train loss {'Reaction outcome loss': 0.3054863125960595, 'Total loss': 0.3054863125960595}
2022-11-28 01:16:04,449 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:04,449 INFO:     Epoch: 68
2022-11-28 01:16:05,197 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46706918999552727, 'Total loss': 0.46706918999552727} | train loss {'Reaction outcome loss': 0.32335888833535253, 'Total loss': 0.32335888833535253}
2022-11-28 01:16:05,197 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:05,197 INFO:     Epoch: 69
2022-11-28 01:16:05,944 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4597707533023574, 'Total loss': 0.4597707533023574} | train loss {'Reaction outcome loss': 0.30768247557472184, 'Total loss': 0.30768247557472184}
2022-11-28 01:16:05,945 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:05,945 INFO:     Epoch: 70
2022-11-28 01:16:06,686 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4402898143638264, 'Total loss': 0.4402898143638264} | train loss {'Reaction outcome loss': 0.3059830766487942, 'Total loss': 0.3059830766487942}
2022-11-28 01:16:06,687 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:06,687 INFO:     Epoch: 71
2022-11-28 01:16:07,433 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.434629732912237, 'Total loss': 0.434629732912237} | train loss {'Reaction outcome loss': 0.3145243157802323, 'Total loss': 0.3145243157802323}
2022-11-28 01:16:07,433 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:07,433 INFO:     Epoch: 72
2022-11-28 01:16:08,180 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44578557630831545, 'Total loss': 0.44578557630831545} | train loss {'Reaction outcome loss': 0.3238016354892901, 'Total loss': 0.3238016354892901}
2022-11-28 01:16:08,181 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:08,181 INFO:     Epoch: 73
2022-11-28 01:16:08,925 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4322346970438957, 'Total loss': 0.4322346970438957} | train loss {'Reaction outcome loss': 0.32431357411237866, 'Total loss': 0.32431357411237866}
2022-11-28 01:16:08,926 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:08,926 INFO:     Epoch: 74
2022-11-28 01:16:09,669 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44629381664774637, 'Total loss': 0.44629381664774637} | train loss {'Reaction outcome loss': 0.30419162586934656, 'Total loss': 0.30419162586934656}
2022-11-28 01:16:09,669 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:09,669 INFO:     Epoch: 75
2022-11-28 01:16:10,412 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4444243606518615, 'Total loss': 0.4444243606518615} | train loss {'Reaction outcome loss': 0.3021461013779949, 'Total loss': 0.3021461013779949}
2022-11-28 01:16:10,412 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:10,412 INFO:     Epoch: 76
2022-11-28 01:16:11,154 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43933486159552226, 'Total loss': 0.43933486159552226} | train loss {'Reaction outcome loss': 0.31130141663716904, 'Total loss': 0.31130141663716904}
2022-11-28 01:16:11,154 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:11,154 INFO:     Epoch: 77
2022-11-28 01:16:11,897 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48940116979859094, 'Total loss': 0.48940116979859094} | train loss {'Reaction outcome loss': 0.30717439004050395, 'Total loss': 0.30717439004050395}
2022-11-28 01:16:11,898 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:11,898 INFO:     Epoch: 78
2022-11-28 01:16:12,639 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4558183327317238, 'Total loss': 0.4558183327317238} | train loss {'Reaction outcome loss': 0.30312894536597046, 'Total loss': 0.30312894536597046}
2022-11-28 01:16:12,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:12,640 INFO:     Epoch: 79
2022-11-28 01:16:13,380 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44337454048747366, 'Total loss': 0.44337454048747366} | train loss {'Reaction outcome loss': 0.31509659514736066, 'Total loss': 0.31509659514736066}
2022-11-28 01:16:13,380 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:13,380 INFO:     Epoch: 80
2022-11-28 01:16:14,123 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5025657693093474, 'Total loss': 0.5025657693093474} | train loss {'Reaction outcome loss': 0.31827817744903475, 'Total loss': 0.31827817744903475}
2022-11-28 01:16:14,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:14,123 INFO:     Epoch: 81
2022-11-28 01:16:14,863 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4574103108183904, 'Total loss': 0.4574103108183904} | train loss {'Reaction outcome loss': 0.3047296382667806, 'Total loss': 0.3047296382667806}
2022-11-28 01:16:14,864 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:14,864 INFO:     Epoch: 82
2022-11-28 01:16:15,600 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45275250043381343, 'Total loss': 0.45275250043381343} | train loss {'Reaction outcome loss': 0.29992017703628554, 'Total loss': 0.29992017703628554}
2022-11-28 01:16:15,601 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:15,601 INFO:     Epoch: 83
2022-11-28 01:16:16,340 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4173226600343531, 'Total loss': 0.4173226600343531} | train loss {'Reaction outcome loss': 0.30768158230157605, 'Total loss': 0.30768158230157605}
2022-11-28 01:16:16,340 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:16,340 INFO:     Epoch: 84
2022-11-28 01:16:17,081 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4363916130228476, 'Total loss': 0.4363916130228476} | train loss {'Reaction outcome loss': 0.29666330675907465, 'Total loss': 0.29666330675907465}
2022-11-28 01:16:17,081 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:17,081 INFO:     Epoch: 85
2022-11-28 01:16:17,827 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46614615534516896, 'Total loss': 0.46614615534516896} | train loss {'Reaction outcome loss': 0.30239464966995033, 'Total loss': 0.30239464966995033}
2022-11-28 01:16:17,827 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:17,827 INFO:     Epoch: 86
2022-11-28 01:16:18,566 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45518401671539654, 'Total loss': 0.45518401671539654} | train loss {'Reaction outcome loss': 0.3185325030829882, 'Total loss': 0.3185325030829882}
2022-11-28 01:16:18,566 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:18,566 INFO:     Epoch: 87
2022-11-28 01:16:19,304 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4401880997148427, 'Total loss': 0.4401880997148427} | train loss {'Reaction outcome loss': 0.29801371198916726, 'Total loss': 0.29801371198916726}
2022-11-28 01:16:19,304 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:19,304 INFO:     Epoch: 88
2022-11-28 01:16:20,047 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44734945690090006, 'Total loss': 0.44734945690090006} | train loss {'Reaction outcome loss': 0.3052357477871211, 'Total loss': 0.3052357477871211}
2022-11-28 01:16:20,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:20,047 INFO:     Epoch: 89
2022-11-28 01:16:20,791 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4394054991955107, 'Total loss': 0.4394054991955107} | train loss {'Reaction outcome loss': 0.30121914467016453, 'Total loss': 0.30121914467016453}
2022-11-28 01:16:20,791 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:20,791 INFO:     Epoch: 90
2022-11-28 01:16:21,535 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44650978628884663, 'Total loss': 0.44650978628884663} | train loss {'Reaction outcome loss': 0.3049833488910787, 'Total loss': 0.3049833488910787}
2022-11-28 01:16:21,536 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:21,536 INFO:     Epoch: 91
2022-11-28 01:16:22,280 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.437501898882064, 'Total loss': 0.437501898882064} | train loss {'Reaction outcome loss': 0.3165419326146861, 'Total loss': 0.3165419326146861}
2022-11-28 01:16:22,281 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:22,281 INFO:     Epoch: 92
2022-11-28 01:16:23,022 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4121797216886824, 'Total loss': 0.4121797216886824} | train loss {'Reaction outcome loss': 0.2983456170219982, 'Total loss': 0.2983456170219982}
2022-11-28 01:16:23,022 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:23,023 INFO:     Epoch: 93
2022-11-28 01:16:23,764 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4471557807515968, 'Total loss': 0.4471557807515968} | train loss {'Reaction outcome loss': 0.30706709451400316, 'Total loss': 0.30706709451400316}
2022-11-28 01:16:23,764 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:23,764 INFO:     Epoch: 94
2022-11-28 01:16:24,507 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.451212169687179, 'Total loss': 0.451212169687179} | train loss {'Reaction outcome loss': 0.30718335257705276, 'Total loss': 0.30718335257705276}
2022-11-28 01:16:24,508 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:24,508 INFO:     Epoch: 95
2022-11-28 01:16:25,247 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44568881121548737, 'Total loss': 0.44568881121548737} | train loss {'Reaction outcome loss': 0.29762752468769366, 'Total loss': 0.29762752468769366}
2022-11-28 01:16:25,247 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:25,247 INFO:     Epoch: 96
2022-11-28 01:16:25,991 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46134360100735317, 'Total loss': 0.46134360100735317} | train loss {'Reaction outcome loss': 0.31080094746008574, 'Total loss': 0.31080094746008574}
2022-11-28 01:16:25,991 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:25,991 INFO:     Epoch: 97
2022-11-28 01:16:26,738 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4339769677343694, 'Total loss': 0.4339769677343694} | train loss {'Reaction outcome loss': 0.3165813659427137, 'Total loss': 0.3165813659427137}
2022-11-28 01:16:26,738 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:26,738 INFO:     Epoch: 98
2022-11-28 01:16:27,480 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4471913989294659, 'Total loss': 0.4471913989294659} | train loss {'Reaction outcome loss': 0.30657963168351093, 'Total loss': 0.30657963168351093}
2022-11-28 01:16:27,480 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:27,480 INFO:     Epoch: 99
2022-11-28 01:16:28,224 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4232475757598877, 'Total loss': 0.4232475757598877} | train loss {'Reaction outcome loss': 0.3053017726511155, 'Total loss': 0.3053017726511155}
2022-11-28 01:16:28,224 INFO:     Best model found after epoch 52 of 100.
2022-11-28 01:16:28,225 INFO:   Done with stage: TRAINING
2022-11-28 01:16:28,225 INFO:   Starting stage: EVALUATION
2022-11-28 01:16:28,346 INFO:   Done with stage: EVALUATION
2022-11-28 01:16:28,354 INFO:   Leaving out SEQ value Fold_0
2022-11-28 01:16:28,367 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 01:16:28,367 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:16:29,007 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:16:29,007 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:16:29,076 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:16:29,076 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:16:29,076 INFO:     No hyperparam tuning for this model
2022-11-28 01:16:29,076 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:16:29,076 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:16:29,077 INFO:     None feature selector for col prot
2022-11-28 01:16:29,077 INFO:     None feature selector for col prot
2022-11-28 01:16:29,077 INFO:     None feature selector for col prot
2022-11-28 01:16:29,078 INFO:     None feature selector for col chem
2022-11-28 01:16:29,078 INFO:     None feature selector for col chem
2022-11-28 01:16:29,078 INFO:     None feature selector for col chem
2022-11-28 01:16:29,078 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:16:29,078 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:16:29,080 INFO:     Number of params in model 169741
2022-11-28 01:16:29,083 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:16:29,083 INFO:   Starting stage: TRAINING
2022-11-28 01:16:29,135 INFO:     Val loss before train {'Reaction outcome loss': 1.0900286314162342, 'Total loss': 1.0900286314162342}
2022-11-28 01:16:29,135 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:29,135 INFO:     Epoch: 0
2022-11-28 01:16:29,867 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5825634856115688, 'Total loss': 0.5825634856115688} | train loss {'Reaction outcome loss': 0.6272935055956549, 'Total loss': 0.6272935055956549}
2022-11-28 01:16:29,867 INFO:     Found new best model at epoch 0
2022-11-28 01:16:29,868 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:29,868 INFO:     Epoch: 1
2022-11-28 01:16:30,606 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.520622924647548, 'Total loss': 0.520622924647548} | train loss {'Reaction outcome loss': 0.49733195481251696, 'Total loss': 0.49733195481251696}
2022-11-28 01:16:30,606 INFO:     Found new best model at epoch 1
2022-11-28 01:16:30,607 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:30,607 INFO:     Epoch: 2
2022-11-28 01:16:31,343 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4899045018987222, 'Total loss': 0.4899045018987222} | train loss {'Reaction outcome loss': 0.45404255536137794, 'Total loss': 0.45404255536137794}
2022-11-28 01:16:31,343 INFO:     Found new best model at epoch 2
2022-11-28 01:16:31,344 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:31,344 INFO:     Epoch: 3
2022-11-28 01:16:32,079 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5117599838836626, 'Total loss': 0.5117599838836626} | train loss {'Reaction outcome loss': 0.44032657706007666, 'Total loss': 0.44032657706007666}
2022-11-28 01:16:32,079 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:32,079 INFO:     Epoch: 4
2022-11-28 01:16:32,818 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.496479408307509, 'Total loss': 0.496479408307509} | train loss {'Reaction outcome loss': 0.4217729592505766, 'Total loss': 0.4217729592505766}
2022-11-28 01:16:32,818 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:32,818 INFO:     Epoch: 5
2022-11-28 01:16:33,557 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4786975407464938, 'Total loss': 0.4786975407464938} | train loss {'Reaction outcome loss': 0.40635705450359655, 'Total loss': 0.40635705450359655}
2022-11-28 01:16:33,557 INFO:     Found new best model at epoch 5
2022-11-28 01:16:33,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:33,558 INFO:     Epoch: 6
2022-11-28 01:16:34,298 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5010032359171998, 'Total loss': 0.5010032359171998} | train loss {'Reaction outcome loss': 0.3939070450104013, 'Total loss': 0.3939070450104013}
2022-11-28 01:16:34,299 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:34,299 INFO:     Epoch: 7
2022-11-28 01:16:35,038 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.471450882201845, 'Total loss': 0.471450882201845} | train loss {'Reaction outcome loss': 0.3916820622524437, 'Total loss': 0.3916820622524437}
2022-11-28 01:16:35,038 INFO:     Found new best model at epoch 7
2022-11-28 01:16:35,039 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:35,039 INFO:     Epoch: 8
2022-11-28 01:16:35,774 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49110601673072035, 'Total loss': 0.49110601673072035} | train loss {'Reaction outcome loss': 0.3801052184129248, 'Total loss': 0.3801052184129248}
2022-11-28 01:16:35,775 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:35,775 INFO:     Epoch: 9
2022-11-28 01:16:36,513 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4947825294326652, 'Total loss': 0.4947825294326652} | train loss {'Reaction outcome loss': 0.37979255312559557, 'Total loss': 0.37979255312559557}
2022-11-28 01:16:36,513 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:36,513 INFO:     Epoch: 10
2022-11-28 01:16:37,255 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44904089448126877, 'Total loss': 0.44904089448126877} | train loss {'Reaction outcome loss': 0.3793356229760209, 'Total loss': 0.3793356229760209}
2022-11-28 01:16:37,255 INFO:     Found new best model at epoch 10
2022-11-28 01:16:37,256 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:37,256 INFO:     Epoch: 11
2022-11-28 01:16:37,994 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4621100135316903, 'Total loss': 0.4621100135316903} | train loss {'Reaction outcome loss': 0.3709787016316336, 'Total loss': 0.3709787016316336}
2022-11-28 01:16:37,995 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:37,995 INFO:     Epoch: 12
2022-11-28 01:16:38,736 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5067767202854156, 'Total loss': 0.5067767202854156} | train loss {'Reaction outcome loss': 0.3619975202849933, 'Total loss': 0.3619975202849933}
2022-11-28 01:16:38,736 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:38,737 INFO:     Epoch: 13
2022-11-28 01:16:39,479 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.505727537653663, 'Total loss': 0.505727537653663} | train loss {'Reaction outcome loss': 0.358216648807331, 'Total loss': 0.358216648807331}
2022-11-28 01:16:39,479 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:39,479 INFO:     Epoch: 14
2022-11-28 01:16:40,217 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48760415241122246, 'Total loss': 0.48760415241122246} | train loss {'Reaction outcome loss': 0.3587407671371285, 'Total loss': 0.3587407671371285}
2022-11-28 01:16:40,218 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:40,218 INFO:     Epoch: 15
2022-11-28 01:16:40,957 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5315021974119273, 'Total loss': 0.5315021974119273} | train loss {'Reaction outcome loss': 0.3509816067255273, 'Total loss': 0.3509816067255273}
2022-11-28 01:16:40,958 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:40,958 INFO:     Epoch: 16
2022-11-28 01:16:41,699 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.503028198399327, 'Total loss': 0.503028198399327} | train loss {'Reaction outcome loss': 0.3511932078672915, 'Total loss': 0.3511932078672915}
2022-11-28 01:16:41,699 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:41,700 INFO:     Epoch: 17
2022-11-28 01:16:42,437 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4685590969906612, 'Total loss': 0.4685590969906612} | train loss {'Reaction outcome loss': 0.34719988576003485, 'Total loss': 0.34719988576003485}
2022-11-28 01:16:42,438 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:42,438 INFO:     Epoch: 18
2022-11-28 01:16:43,175 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4796608214012601, 'Total loss': 0.4796608214012601} | train loss {'Reaction outcome loss': 0.3432393156752294, 'Total loss': 0.3432393156752294}
2022-11-28 01:16:43,175 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:43,176 INFO:     Epoch: 19
2022-11-28 01:16:43,912 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47233385999094357, 'Total loss': 0.47233385999094357} | train loss {'Reaction outcome loss': 0.34410393134671813, 'Total loss': 0.34410393134671813}
2022-11-28 01:16:43,912 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:43,912 INFO:     Epoch: 20
2022-11-28 01:16:44,656 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4894158417591825, 'Total loss': 0.4894158417591825} | train loss {'Reaction outcome loss': 0.34239882188183923, 'Total loss': 0.34239882188183923}
2022-11-28 01:16:44,656 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:44,656 INFO:     Epoch: 21
2022-11-28 01:16:45,395 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4755996438589963, 'Total loss': 0.4755996438589963} | train loss {'Reaction outcome loss': 0.33574745904426184, 'Total loss': 0.33574745904426184}
2022-11-28 01:16:45,395 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:45,395 INFO:     Epoch: 22
2022-11-28 01:16:46,138 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4585970172827894, 'Total loss': 0.4585970172827894} | train loss {'Reaction outcome loss': 0.3302700244042338, 'Total loss': 0.3302700244042338}
2022-11-28 01:16:46,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:46,138 INFO:     Epoch: 23
2022-11-28 01:16:46,877 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44676620817997237, 'Total loss': 0.44676620817997237} | train loss {'Reaction outcome loss': 0.3426086419090933, 'Total loss': 0.3426086419090933}
2022-11-28 01:16:46,877 INFO:     Found new best model at epoch 23
2022-11-28 01:16:46,878 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:46,878 INFO:     Epoch: 24
2022-11-28 01:16:47,616 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4718602512201125, 'Total loss': 0.4718602512201125} | train loss {'Reaction outcome loss': 0.3286977123393088, 'Total loss': 0.3286977123393088}
2022-11-28 01:16:47,616 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:47,616 INFO:     Epoch: 25
2022-11-28 01:16:48,350 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.47099740092049946, 'Total loss': 0.47099740092049946} | train loss {'Reaction outcome loss': 0.3242293222218144, 'Total loss': 0.3242293222218144}
2022-11-28 01:16:48,350 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:48,350 INFO:     Epoch: 26
2022-11-28 01:16:49,083 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4818669982593168, 'Total loss': 0.4818669982593168} | train loss {'Reaction outcome loss': 0.335886713284619, 'Total loss': 0.335886713284619}
2022-11-28 01:16:49,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:49,084 INFO:     Epoch: 27
2022-11-28 01:16:49,818 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5153414322571321, 'Total loss': 0.5153414322571321} | train loss {'Reaction outcome loss': 0.32209954644952504, 'Total loss': 0.32209954644952504}
2022-11-28 01:16:49,819 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:49,819 INFO:     Epoch: 28
2022-11-28 01:16:50,559 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.465113498439843, 'Total loss': 0.465113498439843} | train loss {'Reaction outcome loss': 0.3309165204057888, 'Total loss': 0.3309165204057888}
2022-11-28 01:16:50,559 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:50,559 INFO:     Epoch: 29
2022-11-28 01:16:51,292 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47229898619380867, 'Total loss': 0.47229898619380867} | train loss {'Reaction outcome loss': 0.3285391389107218, 'Total loss': 0.3285391389107218}
2022-11-28 01:16:51,292 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:51,292 INFO:     Epoch: 30
2022-11-28 01:16:52,030 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4514671022241766, 'Total loss': 0.4514671022241766} | train loss {'Reaction outcome loss': 0.32997310748513864, 'Total loss': 0.32997310748513864}
2022-11-28 01:16:52,030 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:52,030 INFO:     Epoch: 31
2022-11-28 01:16:52,766 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5074053115465424, 'Total loss': 0.5074053115465424} | train loss {'Reaction outcome loss': 0.32591046964635656, 'Total loss': 0.32591046964635656}
2022-11-28 01:16:52,766 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:52,766 INFO:     Epoch: 32
2022-11-28 01:16:53,504 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4616455493325537, 'Total loss': 0.4616455493325537} | train loss {'Reaction outcome loss': 0.32572492957115173, 'Total loss': 0.32572492957115173}
2022-11-28 01:16:53,504 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:53,504 INFO:     Epoch: 33
2022-11-28 01:16:54,237 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4683119475164197, 'Total loss': 0.4683119475164197} | train loss {'Reaction outcome loss': 0.31437951019223853, 'Total loss': 0.31437951019223853}
2022-11-28 01:16:54,237 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:54,237 INFO:     Epoch: 34
2022-11-28 01:16:54,972 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45955187420953403, 'Total loss': 0.45955187420953403} | train loss {'Reaction outcome loss': 0.31444978625798714, 'Total loss': 0.31444978625798714}
2022-11-28 01:16:54,972 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:54,972 INFO:     Epoch: 35
2022-11-28 01:16:55,712 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4615984227169644, 'Total loss': 0.4615984227169644} | train loss {'Reaction outcome loss': 0.31838122296090027, 'Total loss': 0.31838122296090027}
2022-11-28 01:16:55,713 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:55,713 INFO:     Epoch: 36
2022-11-28 01:16:56,452 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4736823717301542, 'Total loss': 0.4736823717301542} | train loss {'Reaction outcome loss': 0.3168074203693137, 'Total loss': 0.3168074203693137}
2022-11-28 01:16:56,452 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:56,452 INFO:     Epoch: 37
2022-11-28 01:16:57,189 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4891836636445739, 'Total loss': 0.4891836636445739} | train loss {'Reaction outcome loss': 0.3195589623737092, 'Total loss': 0.3195589623737092}
2022-11-28 01:16:57,189 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:57,189 INFO:     Epoch: 38
2022-11-28 01:16:57,923 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4622328020632267, 'Total loss': 0.4622328020632267} | train loss {'Reaction outcome loss': 0.31286555756719747, 'Total loss': 0.31286555756719747}
2022-11-28 01:16:57,924 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:57,924 INFO:     Epoch: 39
2022-11-28 01:16:58,660 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5006129619750109, 'Total loss': 0.5006129619750109} | train loss {'Reaction outcome loss': 0.31694440862962175, 'Total loss': 0.31694440862962175}
2022-11-28 01:16:58,660 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:58,660 INFO:     Epoch: 40
2022-11-28 01:16:59,395 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4853432076898488, 'Total loss': 0.4853432076898488} | train loss {'Reaction outcome loss': 0.32481961727750547, 'Total loss': 0.32481961727750547}
2022-11-28 01:16:59,396 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:16:59,396 INFO:     Epoch: 41
2022-11-28 01:17:00,138 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4574537023224614, 'Total loss': 0.4574537023224614} | train loss {'Reaction outcome loss': 0.3211671161408327, 'Total loss': 0.3211671161408327}
2022-11-28 01:17:00,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:00,138 INFO:     Epoch: 42
2022-11-28 01:17:00,874 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5055096217177131, 'Total loss': 0.5055096217177131} | train loss {'Reaction outcome loss': 0.3172002418308842, 'Total loss': 0.3172002418308842}
2022-11-28 01:17:00,874 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:00,874 INFO:     Epoch: 43
2022-11-28 01:17:01,607 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4589649699628353, 'Total loss': 0.4589649699628353} | train loss {'Reaction outcome loss': 0.31393294237097913, 'Total loss': 0.31393294237097913}
2022-11-28 01:17:01,607 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:01,607 INFO:     Epoch: 44
2022-11-28 01:17:02,347 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4605769877406684, 'Total loss': 0.4605769877406684} | train loss {'Reaction outcome loss': 0.314414409137502, 'Total loss': 0.314414409137502}
2022-11-28 01:17:02,347 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:02,347 INFO:     Epoch: 45
2022-11-28 01:17:03,090 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.450805548239838, 'Total loss': 0.450805548239838} | train loss {'Reaction outcome loss': 0.3164322297183835, 'Total loss': 0.3164322297183835}
2022-11-28 01:17:03,090 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:03,090 INFO:     Epoch: 46
2022-11-28 01:17:03,830 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.471308421343565, 'Total loss': 0.471308421343565} | train loss {'Reaction outcome loss': 0.29702394768899804, 'Total loss': 0.29702394768899804}
2022-11-28 01:17:03,830 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:03,830 INFO:     Epoch: 47
2022-11-28 01:17:04,572 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4432500207966024, 'Total loss': 0.4432500207966024} | train loss {'Reaction outcome loss': 0.3096723648966575, 'Total loss': 0.3096723648966575}
2022-11-28 01:17:04,572 INFO:     Found new best model at epoch 47
2022-11-28 01:17:04,573 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:04,573 INFO:     Epoch: 48
2022-11-28 01:17:05,316 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4432827796448361, 'Total loss': 0.4432827796448361} | train loss {'Reaction outcome loss': 0.3173544686667773, 'Total loss': 0.3173544686667773}
2022-11-28 01:17:05,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:05,317 INFO:     Epoch: 49
2022-11-28 01:17:06,056 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4822413059459491, 'Total loss': 0.4822413059459491} | train loss {'Reaction outcome loss': 0.3038968161508745, 'Total loss': 0.3038968161508745}
2022-11-28 01:17:06,057 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:06,057 INFO:     Epoch: 50
2022-11-28 01:17:06,802 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4433244419368831, 'Total loss': 0.4433244419368831} | train loss {'Reaction outcome loss': 0.3097365170413134, 'Total loss': 0.3097365170413134}
2022-11-28 01:17:06,802 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:06,802 INFO:     Epoch: 51
2022-11-28 01:17:07,544 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4912794977426529, 'Total loss': 0.4912794977426529} | train loss {'Reaction outcome loss': 0.30546181065087413, 'Total loss': 0.30546181065087413}
2022-11-28 01:17:07,544 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:07,544 INFO:     Epoch: 52
2022-11-28 01:17:08,288 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47547639601609926, 'Total loss': 0.47547639601609926} | train loss {'Reaction outcome loss': 0.3075914099204297, 'Total loss': 0.3075914099204297}
2022-11-28 01:17:08,289 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:08,289 INFO:     Epoch: 53
2022-11-28 01:17:09,027 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4570534222505309, 'Total loss': 0.4570534222505309} | train loss {'Reaction outcome loss': 0.30501279131490355, 'Total loss': 0.30501279131490355}
2022-11-28 01:17:09,027 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:09,027 INFO:     Epoch: 54
2022-11-28 01:17:09,765 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4759259329770099, 'Total loss': 0.4759259329770099} | train loss {'Reaction outcome loss': 0.3029030418213533, 'Total loss': 0.3029030418213533}
2022-11-28 01:17:09,765 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:09,765 INFO:     Epoch: 55
2022-11-28 01:17:10,508 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.519905103201216, 'Total loss': 0.519905103201216} | train loss {'Reaction outcome loss': 0.3080019490451229, 'Total loss': 0.3080019490451229}
2022-11-28 01:17:10,508 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:10,508 INFO:     Epoch: 56
2022-11-28 01:17:11,247 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5048180049793287, 'Total loss': 0.5048180049793287} | train loss {'Reaction outcome loss': 0.3129221533482172, 'Total loss': 0.3129221533482172}
2022-11-28 01:17:11,248 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:11,248 INFO:     Epoch: 57
2022-11-28 01:17:11,986 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46083207470788196, 'Total loss': 0.46083207470788196} | train loss {'Reaction outcome loss': 0.3035511220292169, 'Total loss': 0.3035511220292169}
2022-11-28 01:17:11,987 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:11,987 INFO:     Epoch: 58
2022-11-28 01:17:12,724 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4756445793265646, 'Total loss': 0.4756445793265646} | train loss {'Reaction outcome loss': 0.3037606898315099, 'Total loss': 0.3037606898315099}
2022-11-28 01:17:12,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:12,724 INFO:     Epoch: 59
2022-11-28 01:17:13,465 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45009994447569956, 'Total loss': 0.45009994447569956} | train loss {'Reaction outcome loss': 0.3128504562134645, 'Total loss': 0.3128504562134645}
2022-11-28 01:17:13,465 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:13,465 INFO:     Epoch: 60
2022-11-28 01:17:14,202 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45373261110349133, 'Total loss': 0.45373261110349133} | train loss {'Reaction outcome loss': 0.30255563681831166, 'Total loss': 0.30255563681831166}
2022-11-28 01:17:14,202 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:14,202 INFO:     Epoch: 61
2022-11-28 01:17:14,942 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4819140864366835, 'Total loss': 0.4819140864366835} | train loss {'Reaction outcome loss': 0.29453179526085754, 'Total loss': 0.29453179526085754}
2022-11-28 01:17:14,942 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:14,942 INFO:     Epoch: 62
2022-11-28 01:17:15,680 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46016081693497574, 'Total loss': 0.46016081693497574} | train loss {'Reaction outcome loss': 0.30497854990618567, 'Total loss': 0.30497854990618567}
2022-11-28 01:17:15,680 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:15,680 INFO:     Epoch: 63
2022-11-28 01:17:16,421 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47713393853469327, 'Total loss': 0.47713393853469327} | train loss {'Reaction outcome loss': 0.2957746629052016, 'Total loss': 0.2957746629052016}
2022-11-28 01:17:16,421 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:16,421 INFO:     Epoch: 64
2022-11-28 01:17:17,160 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4783576571128585, 'Total loss': 0.4783576571128585} | train loss {'Reaction outcome loss': 0.304933682965989, 'Total loss': 0.304933682965989}
2022-11-28 01:17:17,160 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:17,160 INFO:     Epoch: 65
2022-11-28 01:17:17,896 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44691774079745467, 'Total loss': 0.44691774079745467} | train loss {'Reaction outcome loss': 0.30195814337657423, 'Total loss': 0.30195814337657423}
2022-11-28 01:17:17,897 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:17,897 INFO:     Epoch: 66
2022-11-28 01:17:18,636 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45597298443317413, 'Total loss': 0.45597298443317413} | train loss {'Reaction outcome loss': 0.2899293194619977, 'Total loss': 0.2899293194619977}
2022-11-28 01:17:18,637 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:18,637 INFO:     Epoch: 67
2022-11-28 01:17:19,377 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.465803209353577, 'Total loss': 0.465803209353577} | train loss {'Reaction outcome loss': 0.2979218516726883, 'Total loss': 0.2979218516726883}
2022-11-28 01:17:19,377 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:19,377 INFO:     Epoch: 68
2022-11-28 01:17:20,113 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46939585798166017, 'Total loss': 0.46939585798166017} | train loss {'Reaction outcome loss': 0.3060701056706662, 'Total loss': 0.3060701056706662}
2022-11-28 01:17:20,114 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:20,114 INFO:     Epoch: 69
2022-11-28 01:17:20,853 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4550305137580091, 'Total loss': 0.4550305137580091} | train loss {'Reaction outcome loss': 0.2973530294031513, 'Total loss': 0.2973530294031513}
2022-11-28 01:17:20,853 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:20,853 INFO:     Epoch: 70
2022-11-28 01:17:21,592 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4985972727564248, 'Total loss': 0.4985972727564248} | train loss {'Reaction outcome loss': 0.30416804653953533, 'Total loss': 0.30416804653953533}
2022-11-28 01:17:21,592 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:21,592 INFO:     Epoch: 71
2022-11-28 01:17:22,329 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4760383418337865, 'Total loss': 0.4760383418337865} | train loss {'Reaction outcome loss': 0.3057421080007845, 'Total loss': 0.3057421080007845}
2022-11-28 01:17:22,329 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:22,329 INFO:     Epoch: 72
2022-11-28 01:17:23,066 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4365576278756965, 'Total loss': 0.4365576278756965} | train loss {'Reaction outcome loss': 0.30134967144350616, 'Total loss': 0.30134967144350616}
2022-11-28 01:17:23,066 INFO:     Found new best model at epoch 72
2022-11-28 01:17:23,067 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:23,067 INFO:     Epoch: 73
2022-11-28 01:17:23,802 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5051303268833593, 'Total loss': 0.5051303268833593} | train loss {'Reaction outcome loss': 0.29952270595394836, 'Total loss': 0.29952270595394836}
2022-11-28 01:17:23,802 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:23,802 INFO:     Epoch: 74
2022-11-28 01:17:24,541 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47931052947586233, 'Total loss': 0.47931052947586233} | train loss {'Reaction outcome loss': 0.3043112302465098, 'Total loss': 0.3043112302465098}
2022-11-28 01:17:24,541 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:24,541 INFO:     Epoch: 75
2022-11-28 01:17:25,284 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44629588384519925, 'Total loss': 0.44629588384519925} | train loss {'Reaction outcome loss': 0.30164997641529356, 'Total loss': 0.30164997641529356}
2022-11-28 01:17:25,284 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:25,284 INFO:     Epoch: 76
2022-11-28 01:17:26,021 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4675314873456955, 'Total loss': 0.4675314873456955} | train loss {'Reaction outcome loss': 0.2940715480823906, 'Total loss': 0.2940715480823906}
2022-11-28 01:17:26,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:26,021 INFO:     Epoch: 77
2022-11-28 01:17:26,762 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46890255504033784, 'Total loss': 0.46890255504033784} | train loss {'Reaction outcome loss': 0.2982263724718775, 'Total loss': 0.2982263724718775}
2022-11-28 01:17:26,762 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:26,762 INFO:     Epoch: 78
2022-11-28 01:17:27,496 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4790162405168468, 'Total loss': 0.4790162405168468} | train loss {'Reaction outcome loss': 0.3074624964017041, 'Total loss': 0.3074624964017041}
2022-11-28 01:17:27,496 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:27,496 INFO:     Epoch: 79
2022-11-28 01:17:28,228 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4426505315032872, 'Total loss': 0.4426505315032872} | train loss {'Reaction outcome loss': 0.2993026554280398, 'Total loss': 0.2993026554280398}
2022-11-28 01:17:28,228 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:28,228 INFO:     Epoch: 80
2022-11-28 01:17:28,962 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43671180003068666, 'Total loss': 0.43671180003068666} | train loss {'Reaction outcome loss': 0.3056682684591838, 'Total loss': 0.3056682684591838}
2022-11-28 01:17:28,962 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:28,962 INFO:     Epoch: 81
2022-11-28 01:17:29,698 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5095523690635507, 'Total loss': 0.5095523690635507} | train loss {'Reaction outcome loss': 0.3050250802417191, 'Total loss': 0.3050250802417191}
2022-11-28 01:17:29,698 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:29,698 INFO:     Epoch: 82
2022-11-28 01:17:30,432 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.488455304029313, 'Total loss': 0.488455304029313} | train loss {'Reaction outcome loss': 0.29838666347216586, 'Total loss': 0.29838666347216586}
2022-11-28 01:17:30,433 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:30,433 INFO:     Epoch: 83
2022-11-28 01:17:31,171 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4685662001032721, 'Total loss': 0.4685662001032721} | train loss {'Reaction outcome loss': 0.31127951732095405, 'Total loss': 0.31127951732095405}
2022-11-28 01:17:31,171 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:31,171 INFO:     Epoch: 84
2022-11-28 01:17:31,905 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4832838133654811, 'Total loss': 0.4832838133654811} | train loss {'Reaction outcome loss': 0.30103027310070335, 'Total loss': 0.30103027310070335}
2022-11-28 01:17:31,906 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:31,906 INFO:     Epoch: 85
2022-11-28 01:17:32,643 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4739318928596648, 'Total loss': 0.4739318928596648} | train loss {'Reaction outcome loss': 0.3026887671071656, 'Total loss': 0.3026887671071656}
2022-11-28 01:17:32,644 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:32,644 INFO:     Epoch: 86
2022-11-28 01:17:33,381 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5130810571665113, 'Total loss': 0.5130810571665113} | train loss {'Reaction outcome loss': 0.29912455865010923, 'Total loss': 0.29912455865010923}
2022-11-28 01:17:33,381 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:33,381 INFO:     Epoch: 87
2022-11-28 01:17:34,114 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.479883844202215, 'Total loss': 0.479883844202215} | train loss {'Reaction outcome loss': 0.30370699832481995, 'Total loss': 0.30370699832481995}
2022-11-28 01:17:34,114 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:34,114 INFO:     Epoch: 88
2022-11-28 01:17:34,852 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47321657700972125, 'Total loss': 0.47321657700972125} | train loss {'Reaction outcome loss': 0.3020953494979411, 'Total loss': 0.3020953494979411}
2022-11-28 01:17:34,852 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:34,852 INFO:     Epoch: 89
2022-11-28 01:17:35,584 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4345126091079278, 'Total loss': 0.4345126091079278} | train loss {'Reaction outcome loss': 0.2986082138759749, 'Total loss': 0.2986082138759749}
2022-11-28 01:17:35,584 INFO:     Found new best model at epoch 89
2022-11-28 01:17:35,585 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:35,585 INFO:     Epoch: 90
2022-11-28 01:17:36,323 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43986753577535803, 'Total loss': 0.43986753577535803} | train loss {'Reaction outcome loss': 0.29621885356550315, 'Total loss': 0.29621885356550315}
2022-11-28 01:17:36,323 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:36,323 INFO:     Epoch: 91
2022-11-28 01:17:37,063 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4810400131073865, 'Total loss': 0.4810400131073865} | train loss {'Reaction outcome loss': 0.30162532866305236, 'Total loss': 0.30162532866305236}
2022-11-28 01:17:37,063 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:37,063 INFO:     Epoch: 92
2022-11-28 01:17:37,802 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4739674085920507, 'Total loss': 0.4739674085920507} | train loss {'Reaction outcome loss': 0.29728861156166814, 'Total loss': 0.29728861156166814}
2022-11-28 01:17:37,802 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:37,802 INFO:     Epoch: 93
2022-11-28 01:17:38,545 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4649146321144971, 'Total loss': 0.4649146321144971} | train loss {'Reaction outcome loss': 0.2912696040102414, 'Total loss': 0.2912696040102414}
2022-11-28 01:17:38,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:38,546 INFO:     Epoch: 94
2022-11-28 01:17:39,286 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43897854147309606, 'Total loss': 0.43897854147309606} | train loss {'Reaction outcome loss': 0.2970502370018132, 'Total loss': 0.2970502370018132}
2022-11-28 01:17:39,287 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:39,287 INFO:     Epoch: 95
2022-11-28 01:17:40,027 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4608608430082148, 'Total loss': 0.4608608430082148} | train loss {'Reaction outcome loss': 0.296929645933667, 'Total loss': 0.296929645933667}
2022-11-28 01:17:40,028 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:40,028 INFO:     Epoch: 96
2022-11-28 01:17:40,768 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5099917372519319, 'Total loss': 0.5099917372519319} | train loss {'Reaction outcome loss': 0.3014302915760449, 'Total loss': 0.3014302915760449}
2022-11-28 01:17:40,768 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:40,768 INFO:     Epoch: 97
2022-11-28 01:17:41,510 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4825957068665461, 'Total loss': 0.4825957068665461} | train loss {'Reaction outcome loss': 0.29931859869738014, 'Total loss': 0.29931859869738014}
2022-11-28 01:17:41,510 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:41,510 INFO:     Epoch: 98
2022-11-28 01:17:42,252 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46127085319974204, 'Total loss': 0.46127085319974204} | train loss {'Reaction outcome loss': 0.2961025897337466, 'Total loss': 0.2961025897337466}
2022-11-28 01:17:42,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:42,253 INFO:     Epoch: 99
2022-11-28 01:17:42,992 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.468098253689029, 'Total loss': 0.468098253689029} | train loss {'Reaction outcome loss': 0.30590411059710443, 'Total loss': 0.30590411059710443}
2022-11-28 01:17:42,992 INFO:     Best model found after epoch 90 of 100.
2022-11-28 01:17:42,992 INFO:   Done with stage: TRAINING
2022-11-28 01:17:42,992 INFO:   Starting stage: EVALUATION
2022-11-28 01:17:43,118 INFO:   Done with stage: EVALUATION
2022-11-28 01:17:43,118 INFO:   Leaving out SEQ value Fold_1
2022-11-28 01:17:43,131 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 01:17:43,131 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:17:43,772 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:17:43,772 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:17:43,841 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:17:43,841 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:17:43,841 INFO:     No hyperparam tuning for this model
2022-11-28 01:17:43,841 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:17:43,841 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:17:43,842 INFO:     None feature selector for col prot
2022-11-28 01:17:43,842 INFO:     None feature selector for col prot
2022-11-28 01:17:43,842 INFO:     None feature selector for col prot
2022-11-28 01:17:43,843 INFO:     None feature selector for col chem
2022-11-28 01:17:43,843 INFO:     None feature selector for col chem
2022-11-28 01:17:43,843 INFO:     None feature selector for col chem
2022-11-28 01:17:43,843 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:17:43,843 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:17:43,844 INFO:     Number of params in model 169741
2022-11-28 01:17:43,848 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:17:43,848 INFO:   Starting stage: TRAINING
2022-11-28 01:17:43,901 INFO:     Val loss before train {'Reaction outcome loss': 0.9796387146819722, 'Total loss': 0.9796387146819722}
2022-11-28 01:17:43,901 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:43,901 INFO:     Epoch: 0
2022-11-28 01:17:44,640 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5645273077217016, 'Total loss': 0.5645273077217016} | train loss {'Reaction outcome loss': 0.6306195653822957, 'Total loss': 0.6306195653822957}
2022-11-28 01:17:44,640 INFO:     Found new best model at epoch 0
2022-11-28 01:17:44,641 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:44,641 INFO:     Epoch: 1
2022-11-28 01:17:45,381 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4970949136398055, 'Total loss': 0.4970949136398055} | train loss {'Reaction outcome loss': 0.4946814998680232, 'Total loss': 0.4946814998680232}
2022-11-28 01:17:45,381 INFO:     Found new best model at epoch 1
2022-11-28 01:17:45,382 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:45,382 INFO:     Epoch: 2
2022-11-28 01:17:46,123 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4754398681900718, 'Total loss': 0.4754398681900718} | train loss {'Reaction outcome loss': 0.4671670185668128, 'Total loss': 0.4671670185668128}
2022-11-28 01:17:46,124 INFO:     Found new best model at epoch 2
2022-11-28 01:17:46,124 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:46,124 INFO:     Epoch: 3
2022-11-28 01:17:46,863 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45577539097179065, 'Total loss': 0.45577539097179065} | train loss {'Reaction outcome loss': 0.4379659804762626, 'Total loss': 0.4379659804762626}
2022-11-28 01:17:46,863 INFO:     Found new best model at epoch 3
2022-11-28 01:17:46,863 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:46,864 INFO:     Epoch: 4
2022-11-28 01:17:47,603 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5047065801918507, 'Total loss': 0.5047065801918507} | train loss {'Reaction outcome loss': 0.4294660712991442, 'Total loss': 0.4294660712991442}
2022-11-28 01:17:47,603 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:47,603 INFO:     Epoch: 5
2022-11-28 01:17:48,342 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4909049157391895, 'Total loss': 0.4909049157391895} | train loss {'Reaction outcome loss': 0.41148699284816276, 'Total loss': 0.41148699284816276}
2022-11-28 01:17:48,342 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:48,342 INFO:     Epoch: 6
2022-11-28 01:17:49,081 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48700225861235097, 'Total loss': 0.48700225861235097} | train loss {'Reaction outcome loss': 0.40924898580629, 'Total loss': 0.40924898580629}
2022-11-28 01:17:49,081 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:49,081 INFO:     Epoch: 7
2022-11-28 01:17:49,821 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42902043309401383, 'Total loss': 0.42902043309401383} | train loss {'Reaction outcome loss': 0.4036192636708824, 'Total loss': 0.4036192636708824}
2022-11-28 01:17:49,821 INFO:     Found new best model at epoch 7
2022-11-28 01:17:49,822 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:49,822 INFO:     Epoch: 8
2022-11-28 01:17:50,564 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45243957604874263, 'Total loss': 0.45243957604874263} | train loss {'Reaction outcome loss': 0.38399451742975077, 'Total loss': 0.38399451742975077}
2022-11-28 01:17:50,564 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:50,564 INFO:     Epoch: 9
2022-11-28 01:17:51,304 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4680414531718601, 'Total loss': 0.4680414531718601} | train loss {'Reaction outcome loss': 0.3802768599926209, 'Total loss': 0.3802768599926209}
2022-11-28 01:17:51,304 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:51,304 INFO:     Epoch: 10
2022-11-28 01:17:52,045 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4466873895038258, 'Total loss': 0.4466873895038258} | train loss {'Reaction outcome loss': 0.38955756967165034, 'Total loss': 0.38955756967165034}
2022-11-28 01:17:52,045 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:52,045 INFO:     Epoch: 11
2022-11-28 01:17:52,789 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46813582290302624, 'Total loss': 0.46813582290302624} | train loss {'Reaction outcome loss': 0.3726136460292096, 'Total loss': 0.3726136460292096}
2022-11-28 01:17:52,789 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:52,789 INFO:     Epoch: 12
2022-11-28 01:17:53,528 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4744099334559657, 'Total loss': 0.4744099334559657} | train loss {'Reaction outcome loss': 0.36058142519727043, 'Total loss': 0.36058142519727043}
2022-11-28 01:17:53,529 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:53,529 INFO:     Epoch: 13
2022-11-28 01:17:54,266 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4583180838857185, 'Total loss': 0.4583180838857185} | train loss {'Reaction outcome loss': 0.36551495787440513, 'Total loss': 0.36551495787440513}
2022-11-28 01:17:54,266 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:54,266 INFO:     Epoch: 14
2022-11-28 01:17:55,006 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4279122456103902, 'Total loss': 0.4279122456103902} | train loss {'Reaction outcome loss': 0.36927985390838314, 'Total loss': 0.36927985390838314}
2022-11-28 01:17:55,007 INFO:     Found new best model at epoch 14
2022-11-28 01:17:55,007 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:55,007 INFO:     Epoch: 15
2022-11-28 01:17:55,746 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4973012601787394, 'Total loss': 0.4973012601787394} | train loss {'Reaction outcome loss': 0.3559926489178015, 'Total loss': 0.3559926489178015}
2022-11-28 01:17:55,747 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:55,747 INFO:     Epoch: 16
2022-11-28 01:17:56,484 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4718745134093545, 'Total loss': 0.4718745134093545} | train loss {'Reaction outcome loss': 0.3539725154942396, 'Total loss': 0.3539725154942396}
2022-11-28 01:17:56,484 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:56,484 INFO:     Epoch: 17
2022-11-28 01:17:57,224 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44861955534328113, 'Total loss': 0.44861955534328113} | train loss {'Reaction outcome loss': 0.35853683370716716, 'Total loss': 0.35853683370716716}
2022-11-28 01:17:57,224 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:57,224 INFO:     Epoch: 18
2022-11-28 01:17:57,967 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4323403042825786, 'Total loss': 0.4323403042825786} | train loss {'Reaction outcome loss': 0.34609793859476945, 'Total loss': 0.34609793859476945}
2022-11-28 01:17:57,967 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:57,967 INFO:     Epoch: 19
2022-11-28 01:17:58,708 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43552604385397653, 'Total loss': 0.43552604385397653} | train loss {'Reaction outcome loss': 0.35179415863691543, 'Total loss': 0.35179415863691543}
2022-11-28 01:17:58,709 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:58,709 INFO:     Epoch: 20
2022-11-28 01:17:59,451 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45987139947035094, 'Total loss': 0.45987139947035094} | train loss {'Reaction outcome loss': 0.34132149027926584, 'Total loss': 0.34132149027926584}
2022-11-28 01:17:59,451 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:17:59,451 INFO:     Epoch: 21
2022-11-28 01:18:00,194 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44767743992534553, 'Total loss': 0.44767743992534553} | train loss {'Reaction outcome loss': 0.3439739762216198, 'Total loss': 0.3439739762216198}
2022-11-28 01:18:00,195 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:00,195 INFO:     Epoch: 22
2022-11-28 01:18:00,932 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4286521449685097, 'Total loss': 0.4286521449685097} | train loss {'Reaction outcome loss': 0.3380031046818714, 'Total loss': 0.3380031046818714}
2022-11-28 01:18:00,933 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:00,933 INFO:     Epoch: 23
2022-11-28 01:18:01,677 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4272170217538422, 'Total loss': 0.4272170217538422} | train loss {'Reaction outcome loss': 0.3325218292219298, 'Total loss': 0.3325218292219298}
2022-11-28 01:18:01,677 INFO:     Found new best model at epoch 23
2022-11-28 01:18:01,678 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:01,678 INFO:     Epoch: 24
2022-11-28 01:18:02,416 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4736297364262017, 'Total loss': 0.4736297364262017} | train loss {'Reaction outcome loss': 0.33594572982009574, 'Total loss': 0.33594572982009574}
2022-11-28 01:18:02,416 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:02,417 INFO:     Epoch: 25
2022-11-28 01:18:03,158 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43390584974126384, 'Total loss': 0.43390584974126384} | train loss {'Reaction outcome loss': 0.3357281271292239, 'Total loss': 0.3357281271292239}
2022-11-28 01:18:03,158 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:03,158 INFO:     Epoch: 26
2022-11-28 01:18:03,899 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40125376798889856, 'Total loss': 0.40125376798889856} | train loss {'Reaction outcome loss': 0.33847109091525174, 'Total loss': 0.33847109091525174}
2022-11-28 01:18:03,899 INFO:     Found new best model at epoch 26
2022-11-28 01:18:03,900 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:03,900 INFO:     Epoch: 27
2022-11-28 01:18:04,643 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44548576867038553, 'Total loss': 0.44548576867038553} | train loss {'Reaction outcome loss': 0.32644833606116624, 'Total loss': 0.32644833606116624}
2022-11-28 01:18:04,643 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:04,643 INFO:     Epoch: 28
2022-11-28 01:18:05,385 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4434553296728568, 'Total loss': 0.4434553296728568} | train loss {'Reaction outcome loss': 0.3341710723328347, 'Total loss': 0.3341710723328347}
2022-11-28 01:18:05,385 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:05,386 INFO:     Epoch: 29
2022-11-28 01:18:06,123 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44839364154772327, 'Total loss': 0.44839364154772327} | train loss {'Reaction outcome loss': 0.3350614551986967, 'Total loss': 0.3350614551986967}
2022-11-28 01:18:06,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:06,123 INFO:     Epoch: 30
2022-11-28 01:18:06,859 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38922617861747066, 'Total loss': 0.38922617861747066} | train loss {'Reaction outcome loss': 0.32637024822891975, 'Total loss': 0.32637024822891975}
2022-11-28 01:18:06,859 INFO:     Found new best model at epoch 30
2022-11-28 01:18:06,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:06,860 INFO:     Epoch: 31
2022-11-28 01:18:07,596 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4342160885306922, 'Total loss': 0.4342160885306922} | train loss {'Reaction outcome loss': 0.32852206665034195, 'Total loss': 0.32852206665034195}
2022-11-28 01:18:07,596 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:07,596 INFO:     Epoch: 32
2022-11-28 01:18:08,339 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4191702560267665, 'Total loss': 0.4191702560267665} | train loss {'Reaction outcome loss': 0.3253599671684966, 'Total loss': 0.3253599671684966}
2022-11-28 01:18:08,339 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:08,339 INFO:     Epoch: 33
2022-11-28 01:18:09,081 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4285531203177842, 'Total loss': 0.4285531203177842} | train loss {'Reaction outcome loss': 0.3272074071424348, 'Total loss': 0.3272074071424348}
2022-11-28 01:18:09,081 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:09,081 INFO:     Epoch: 34
2022-11-28 01:18:09,823 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45168160884217784, 'Total loss': 0.45168160884217784} | train loss {'Reaction outcome loss': 0.32508675671961845, 'Total loss': 0.32508675671961845}
2022-11-28 01:18:09,823 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:09,823 INFO:     Epoch: 35
2022-11-28 01:18:10,564 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4136381149291992, 'Total loss': 0.4136381149291992} | train loss {'Reaction outcome loss': 0.31501007816013027, 'Total loss': 0.31501007816013027}
2022-11-28 01:18:10,564 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:10,565 INFO:     Epoch: 36
2022-11-28 01:18:11,305 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4199113962663846, 'Total loss': 0.4199113962663846} | train loss {'Reaction outcome loss': 0.32455541163074725, 'Total loss': 0.32455541163074725}
2022-11-28 01:18:11,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:11,305 INFO:     Epoch: 37
2022-11-28 01:18:12,045 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4467250637456097, 'Total loss': 0.4467250637456097} | train loss {'Reaction outcome loss': 0.3248871971910097, 'Total loss': 0.3248871971910097}
2022-11-28 01:18:12,046 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:12,046 INFO:     Epoch: 38
2022-11-28 01:18:12,785 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41459216008132155, 'Total loss': 0.41459216008132155} | train loss {'Reaction outcome loss': 0.321711502969265, 'Total loss': 0.321711502969265}
2022-11-28 01:18:12,785 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:12,785 INFO:     Epoch: 39
2022-11-28 01:18:13,528 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43425156616351823, 'Total loss': 0.43425156616351823} | train loss {'Reaction outcome loss': 0.3283944916056127, 'Total loss': 0.3283944916056127}
2022-11-28 01:18:13,529 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:13,529 INFO:     Epoch: 40
2022-11-28 01:18:14,274 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42344495010646904, 'Total loss': 0.42344495010646904} | train loss {'Reaction outcome loss': 0.3150791253970594, 'Total loss': 0.3150791253970594}
2022-11-28 01:18:14,274 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:14,274 INFO:     Epoch: 41
2022-11-28 01:18:15,021 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4077801082960584, 'Total loss': 0.4077801082960584} | train loss {'Reaction outcome loss': 0.32039788593443075, 'Total loss': 0.32039788593443075}
2022-11-28 01:18:15,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:15,021 INFO:     Epoch: 42
2022-11-28 01:18:15,766 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4373895881528204, 'Total loss': 0.4373895881528204} | train loss {'Reaction outcome loss': 0.3244158827832767, 'Total loss': 0.3244158827832767}
2022-11-28 01:18:15,766 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:15,766 INFO:     Epoch: 43
2022-11-28 01:18:16,509 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4250475906512954, 'Total loss': 0.4250475906512954} | train loss {'Reaction outcome loss': 0.3225234891839173, 'Total loss': 0.3225234891839173}
2022-11-28 01:18:16,509 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:16,510 INFO:     Epoch: 44
2022-11-28 01:18:17,251 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41364995085380296, 'Total loss': 0.41364995085380296} | train loss {'Reaction outcome loss': 0.31646053295354454, 'Total loss': 0.31646053295354454}
2022-11-28 01:18:17,251 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:17,251 INFO:     Epoch: 45
2022-11-28 01:18:17,994 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43499169464815746, 'Total loss': 0.43499169464815746} | train loss {'Reaction outcome loss': 0.3138616411661615, 'Total loss': 0.3138616411661615}
2022-11-28 01:18:17,994 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:17,994 INFO:     Epoch: 46
2022-11-28 01:18:18,735 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41875795901499013, 'Total loss': 0.41875795901499013} | train loss {'Reaction outcome loss': 0.31907376637872387, 'Total loss': 0.31907376637872387}
2022-11-28 01:18:18,735 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:18,735 INFO:     Epoch: 47
2022-11-28 01:18:19,476 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4321568889374083, 'Total loss': 0.4321568889374083} | train loss {'Reaction outcome loss': 0.32448226061402535, 'Total loss': 0.32448226061402535}
2022-11-28 01:18:19,476 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:19,476 INFO:     Epoch: 48
2022-11-28 01:18:20,224 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44776532680473546, 'Total loss': 0.44776532680473546} | train loss {'Reaction outcome loss': 0.3204038264495986, 'Total loss': 0.3204038264495986}
2022-11-28 01:18:20,225 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:20,225 INFO:     Epoch: 49
2022-11-28 01:18:20,973 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4820480278947137, 'Total loss': 0.4820480278947137} | train loss {'Reaction outcome loss': 0.32080014962322856, 'Total loss': 0.32080014962322856}
2022-11-28 01:18:20,973 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:20,973 INFO:     Epoch: 50
2022-11-28 01:18:21,716 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4348845434459773, 'Total loss': 0.4348845434459773} | train loss {'Reaction outcome loss': 0.31637256622922666, 'Total loss': 0.31637256622922666}
2022-11-28 01:18:21,716 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:21,716 INFO:     Epoch: 51
2022-11-28 01:18:22,459 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42139176719567994, 'Total loss': 0.42139176719567994} | train loss {'Reaction outcome loss': 0.3060788466157962, 'Total loss': 0.3060788466157962}
2022-11-28 01:18:22,460 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:22,460 INFO:     Epoch: 52
2022-11-28 01:18:23,209 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4353934604335915, 'Total loss': 0.4353934604335915} | train loss {'Reaction outcome loss': 0.3152646902720539, 'Total loss': 0.3152646902720539}
2022-11-28 01:18:23,209 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:23,209 INFO:     Epoch: 53
2022-11-28 01:18:23,949 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4242604285139929, 'Total loss': 0.4242604285139929} | train loss {'Reaction outcome loss': 0.31045983357697116, 'Total loss': 0.31045983357697116}
2022-11-28 01:18:23,949 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:23,949 INFO:     Epoch: 54
2022-11-28 01:18:24,690 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43045912886207754, 'Total loss': 0.43045912886207754} | train loss {'Reaction outcome loss': 0.3147101490625313, 'Total loss': 0.3147101490625313}
2022-11-28 01:18:24,690 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:24,690 INFO:     Epoch: 55
2022-11-28 01:18:25,428 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4235753757371144, 'Total loss': 0.4235753757371144} | train loss {'Reaction outcome loss': 0.32507064835149413, 'Total loss': 0.32507064835149413}
2022-11-28 01:18:25,428 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:25,428 INFO:     Epoch: 56
2022-11-28 01:18:26,168 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42870604314587335, 'Total loss': 0.42870604314587335} | train loss {'Reaction outcome loss': 0.3164730670652827, 'Total loss': 0.3164730670652827}
2022-11-28 01:18:26,168 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:26,168 INFO:     Epoch: 57
2022-11-28 01:18:26,907 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43621750971810386, 'Total loss': 0.43621750971810386} | train loss {'Reaction outcome loss': 0.30118529459043425, 'Total loss': 0.30118529459043425}
2022-11-28 01:18:26,908 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:26,908 INFO:     Epoch: 58
2022-11-28 01:18:27,652 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42486876621842384, 'Total loss': 0.42486876621842384} | train loss {'Reaction outcome loss': 0.3198597808881682, 'Total loss': 0.3198597808881682}
2022-11-28 01:18:27,652 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:27,652 INFO:     Epoch: 59
2022-11-28 01:18:28,398 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.430165692825209, 'Total loss': 0.430165692825209} | train loss {'Reaction outcome loss': 0.30996617648978625, 'Total loss': 0.30996617648978625}
2022-11-28 01:18:28,398 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:28,398 INFO:     Epoch: 60
2022-11-28 01:18:29,148 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4090173908255317, 'Total loss': 0.4090173908255317} | train loss {'Reaction outcome loss': 0.31140882956738375, 'Total loss': 0.31140882956738375}
2022-11-28 01:18:29,148 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:29,148 INFO:     Epoch: 61
2022-11-28 01:18:29,890 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42221536047079344, 'Total loss': 0.42221536047079344} | train loss {'Reaction outcome loss': 0.30669532991489584, 'Total loss': 0.30669532991489584}
2022-11-28 01:18:29,891 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:29,891 INFO:     Epoch: 62
2022-11-28 01:18:30,632 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4391809857704423, 'Total loss': 0.4391809857704423} | train loss {'Reaction outcome loss': 0.31648290166441273, 'Total loss': 0.31648290166441273}
2022-11-28 01:18:30,632 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:30,632 INFO:     Epoch: 63
2022-11-28 01:18:31,376 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4290796301581643, 'Total loss': 0.4290796301581643} | train loss {'Reaction outcome loss': 0.3143706367028003, 'Total loss': 0.3143706367028003}
2022-11-28 01:18:31,376 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:31,376 INFO:     Epoch: 64
2022-11-28 01:18:32,119 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4377821118316867, 'Total loss': 0.4377821118316867} | train loss {'Reaction outcome loss': 0.3099135877222431, 'Total loss': 0.3099135877222431}
2022-11-28 01:18:32,119 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:32,119 INFO:     Epoch: 65
2022-11-28 01:18:32,864 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41125127927146177, 'Total loss': 0.41125127927146177} | train loss {'Reaction outcome loss': 0.3116654329762167, 'Total loss': 0.3116654329762167}
2022-11-28 01:18:32,865 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:32,865 INFO:     Epoch: 66
2022-11-28 01:18:33,609 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42889580164443364, 'Total loss': 0.42889580164443364} | train loss {'Reaction outcome loss': 0.3089834900686935, 'Total loss': 0.3089834900686935}
2022-11-28 01:18:33,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:33,609 INFO:     Epoch: 67
2022-11-28 01:18:34,352 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.420595279132778, 'Total loss': 0.420595279132778} | train loss {'Reaction outcome loss': 0.3097148047418011, 'Total loss': 0.3097148047418011}
2022-11-28 01:18:34,352 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:34,352 INFO:     Epoch: 68
2022-11-28 01:18:35,095 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4363766461610794, 'Total loss': 0.4363766461610794} | train loss {'Reaction outcome loss': 0.30823696416859725, 'Total loss': 0.30823696416859725}
2022-11-28 01:18:35,095 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:35,095 INFO:     Epoch: 69
2022-11-28 01:18:35,839 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4247950515286489, 'Total loss': 0.4247950515286489} | train loss {'Reaction outcome loss': 0.3130623464377559, 'Total loss': 0.3130623464377559}
2022-11-28 01:18:35,839 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:35,839 INFO:     Epoch: 70
2022-11-28 01:18:36,585 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40405906262722885, 'Total loss': 0.40405906262722885} | train loss {'Reaction outcome loss': 0.3122118092313105, 'Total loss': 0.3122118092313105}
2022-11-28 01:18:36,586 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:36,586 INFO:     Epoch: 71
2022-11-28 01:18:37,335 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4383828169242902, 'Total loss': 0.4383828169242902} | train loss {'Reaction outcome loss': 0.3127096668798096, 'Total loss': 0.3127096668798096}
2022-11-28 01:18:37,335 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:37,335 INFO:     Epoch: 72
2022-11-28 01:18:38,082 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46871925043788826, 'Total loss': 0.46871925043788826} | train loss {'Reaction outcome loss': 0.301699420536051, 'Total loss': 0.301699420536051}
2022-11-28 01:18:38,082 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:38,082 INFO:     Epoch: 73
2022-11-28 01:18:38,830 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42743752693588083, 'Total loss': 0.42743752693588083} | train loss {'Reaction outcome loss': 0.2993418989436967, 'Total loss': 0.2993418989436967}
2022-11-28 01:18:38,830 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:38,831 INFO:     Epoch: 74
2022-11-28 01:18:39,584 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4162449481135065, 'Total loss': 0.4162449481135065} | train loss {'Reaction outcome loss': 0.3160167738491175, 'Total loss': 0.3160167738491175}
2022-11-28 01:18:39,584 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:39,584 INFO:     Epoch: 75
2022-11-28 01:18:40,336 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.413192596625198, 'Total loss': 0.413192596625198} | train loss {'Reaction outcome loss': 0.30063238487559923, 'Total loss': 0.30063238487559923}
2022-11-28 01:18:40,337 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:40,337 INFO:     Epoch: 76
2022-11-28 01:18:41,082 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4176591018384153, 'Total loss': 0.4176591018384153} | train loss {'Reaction outcome loss': 0.31414827391201133, 'Total loss': 0.31414827391201133}
2022-11-28 01:18:41,082 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:41,082 INFO:     Epoch: 77
2022-11-28 01:18:41,826 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44200002029538155, 'Total loss': 0.44200002029538155} | train loss {'Reaction outcome loss': 0.3139520407331233, 'Total loss': 0.3139520407331233}
2022-11-28 01:18:41,826 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:41,826 INFO:     Epoch: 78
2022-11-28 01:18:42,569 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4279650913720781, 'Total loss': 0.4279650913720781} | train loss {'Reaction outcome loss': 0.30631186013319056, 'Total loss': 0.30631186013319056}
2022-11-28 01:18:42,569 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:42,569 INFO:     Epoch: 79
2022-11-28 01:18:43,311 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42434420893815433, 'Total loss': 0.42434420893815433} | train loss {'Reaction outcome loss': 0.3130159764569633, 'Total loss': 0.3130159764569633}
2022-11-28 01:18:43,311 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:43,312 INFO:     Epoch: 80
2022-11-28 01:18:44,060 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4103299403055148, 'Total loss': 0.4103299403055148} | train loss {'Reaction outcome loss': 0.31848201809488996, 'Total loss': 0.31848201809488996}
2022-11-28 01:18:44,060 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:44,060 INFO:     Epoch: 81
2022-11-28 01:18:44,807 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4407627531750636, 'Total loss': 0.4407627531750636} | train loss {'Reaction outcome loss': 0.31809915757300905, 'Total loss': 0.31809915757300905}
2022-11-28 01:18:44,808 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:44,808 INFO:     Epoch: 82
2022-11-28 01:18:45,556 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4435376792468808, 'Total loss': 0.4435376792468808} | train loss {'Reaction outcome loss': 0.3020985360504413, 'Total loss': 0.3020985360504413}
2022-11-28 01:18:45,556 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:45,556 INFO:     Epoch: 83
2022-11-28 01:18:46,304 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3901098776947368, 'Total loss': 0.3901098776947368} | train loss {'Reaction outcome loss': 0.31757081023284367, 'Total loss': 0.31757081023284367}
2022-11-28 01:18:46,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:46,305 INFO:     Epoch: 84
2022-11-28 01:18:47,056 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4506803811951117, 'Total loss': 0.4506803811951117} | train loss {'Reaction outcome loss': 0.2992324746384913, 'Total loss': 0.2992324746384913}
2022-11-28 01:18:47,056 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:47,056 INFO:     Epoch: 85
2022-11-28 01:18:47,806 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4065015407448465, 'Total loss': 0.4065015407448465} | train loss {'Reaction outcome loss': 0.30974766569478174, 'Total loss': 0.30974766569478174}
2022-11-28 01:18:47,806 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:47,806 INFO:     Epoch: 86
2022-11-28 01:18:48,554 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4198084947737781, 'Total loss': 0.4198084947737781} | train loss {'Reaction outcome loss': 0.3084914978061404, 'Total loss': 0.3084914978061404}
2022-11-28 01:18:48,554 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:48,554 INFO:     Epoch: 87
2022-11-28 01:18:49,301 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43245211065831507, 'Total loss': 0.43245211065831507} | train loss {'Reaction outcome loss': 0.3086335106771819, 'Total loss': 0.3086335106771819}
2022-11-28 01:18:49,301 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:49,302 INFO:     Epoch: 88
2022-11-28 01:18:50,046 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44149294089187274, 'Total loss': 0.44149294089187274} | train loss {'Reaction outcome loss': 0.30512516072818213, 'Total loss': 0.30512516072818213}
2022-11-28 01:18:50,046 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:50,046 INFO:     Epoch: 89
2022-11-28 01:18:50,792 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4132708321240815, 'Total loss': 0.4132708321240815} | train loss {'Reaction outcome loss': 0.2960519439103652, 'Total loss': 0.2960519439103652}
2022-11-28 01:18:50,792 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:50,793 INFO:     Epoch: 90
2022-11-28 01:18:51,539 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42689141334796493, 'Total loss': 0.42689141334796493} | train loss {'Reaction outcome loss': 0.3014640535627093, 'Total loss': 0.3014640535627093}
2022-11-28 01:18:51,539 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:51,540 INFO:     Epoch: 91
2022-11-28 01:18:52,284 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41779991882768547, 'Total loss': 0.41779991882768547} | train loss {'Reaction outcome loss': 0.3045838142232019, 'Total loss': 0.3045838142232019}
2022-11-28 01:18:52,284 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:52,284 INFO:     Epoch: 92
2022-11-28 01:18:53,028 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42716834728013386, 'Total loss': 0.42716834728013386} | train loss {'Reaction outcome loss': 0.3102989431090501, 'Total loss': 0.3102989431090501}
2022-11-28 01:18:53,028 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:53,029 INFO:     Epoch: 93
2022-11-28 01:18:53,778 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4432792870158499, 'Total loss': 0.4432792870158499} | train loss {'Reaction outcome loss': 0.31636777939845107, 'Total loss': 0.31636777939845107}
2022-11-28 01:18:53,778 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:53,778 INFO:     Epoch: 94
2022-11-28 01:18:54,526 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41255112703550945, 'Total loss': 0.41255112703550945} | train loss {'Reaction outcome loss': 0.3104624970378924, 'Total loss': 0.3104624970378924}
2022-11-28 01:18:54,526 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:54,526 INFO:     Epoch: 95
2022-11-28 01:18:55,273 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4258549257435582, 'Total loss': 0.4258549257435582} | train loss {'Reaction outcome loss': 0.3055419400334358, 'Total loss': 0.3055419400334358}
2022-11-28 01:18:55,273 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:55,273 INFO:     Epoch: 96
2022-11-28 01:18:56,018 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44269410419193184, 'Total loss': 0.44269410419193184} | train loss {'Reaction outcome loss': 0.30523802105869563, 'Total loss': 0.30523802105869563}
2022-11-28 01:18:56,018 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:56,018 INFO:     Epoch: 97
2022-11-28 01:18:56,763 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4339996007355777, 'Total loss': 0.4339996007355777} | train loss {'Reaction outcome loss': 0.3032693582225819, 'Total loss': 0.3032693582225819}
2022-11-28 01:18:56,763 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:56,763 INFO:     Epoch: 98
2022-11-28 01:18:57,512 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4359975303946571, 'Total loss': 0.4359975303946571} | train loss {'Reaction outcome loss': 0.30560121080096886, 'Total loss': 0.30560121080096886}
2022-11-28 01:18:57,512 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:57,512 INFO:     Epoch: 99
2022-11-28 01:18:58,262 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46612036939371715, 'Total loss': 0.46612036939371715} | train loss {'Reaction outcome loss': 0.3111902526446751, 'Total loss': 0.3111902526446751}
2022-11-28 01:18:58,262 INFO:     Best model found after epoch 31 of 100.
2022-11-28 01:18:58,262 INFO:   Done with stage: TRAINING
2022-11-28 01:18:58,262 INFO:   Starting stage: EVALUATION
2022-11-28 01:18:58,389 INFO:   Done with stage: EVALUATION
2022-11-28 01:18:58,389 INFO:   Leaving out SEQ value Fold_2
2022-11-28 01:18:58,402 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 01:18:58,402 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:18:59,054 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:18:59,054 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:18:59,124 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:18:59,124 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:18:59,124 INFO:     No hyperparam tuning for this model
2022-11-28 01:18:59,124 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:18:59,124 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:18:59,125 INFO:     None feature selector for col prot
2022-11-28 01:18:59,125 INFO:     None feature selector for col prot
2022-11-28 01:18:59,125 INFO:     None feature selector for col prot
2022-11-28 01:18:59,126 INFO:     None feature selector for col chem
2022-11-28 01:18:59,126 INFO:     None feature selector for col chem
2022-11-28 01:18:59,126 INFO:     None feature selector for col chem
2022-11-28 01:18:59,126 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:18:59,126 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:18:59,128 INFO:     Number of params in model 169741
2022-11-28 01:18:59,131 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:18:59,131 INFO:   Starting stage: TRAINING
2022-11-28 01:18:59,185 INFO:     Val loss before train {'Reaction outcome loss': 0.9801757755604658, 'Total loss': 0.9801757755604658}
2022-11-28 01:18:59,185 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:59,185 INFO:     Epoch: 0
2022-11-28 01:18:59,938 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5351279540495439, 'Total loss': 0.5351279540495439} | train loss {'Reaction outcome loss': 0.6521519018329589, 'Total loss': 0.6521519018329589}
2022-11-28 01:18:59,938 INFO:     Found new best model at epoch 0
2022-11-28 01:18:59,938 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:18:59,939 INFO:     Epoch: 1
2022-11-28 01:19:00,693 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5138579102402384, 'Total loss': 0.5138579102402384} | train loss {'Reaction outcome loss': 0.517247756664087, 'Total loss': 0.517247756664087}
2022-11-28 01:19:00,693 INFO:     Found new best model at epoch 1
2022-11-28 01:19:00,694 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:00,694 INFO:     Epoch: 2
2022-11-28 01:19:01,442 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47867170856757596, 'Total loss': 0.47867170856757596} | train loss {'Reaction outcome loss': 0.4746738948561402, 'Total loss': 0.4746738948561402}
2022-11-28 01:19:01,443 INFO:     Found new best model at epoch 2
2022-11-28 01:19:01,443 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:01,443 INFO:     Epoch: 3
2022-11-28 01:19:02,194 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.467648446559906, 'Total loss': 0.467648446559906} | train loss {'Reaction outcome loss': 0.4441260098166734, 'Total loss': 0.4441260098166734}
2022-11-28 01:19:02,194 INFO:     Found new best model at epoch 3
2022-11-28 01:19:02,195 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:02,195 INFO:     Epoch: 4
2022-11-28 01:19:02,943 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5010237002914603, 'Total loss': 0.5010237002914603} | train loss {'Reaction outcome loss': 0.43653112523227566, 'Total loss': 0.43653112523227566}
2022-11-28 01:19:02,944 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:02,944 INFO:     Epoch: 5
2022-11-28 01:19:03,698 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49009365859356796, 'Total loss': 0.49009365859356796} | train loss {'Reaction outcome loss': 0.42468009285839947, 'Total loss': 0.42468009285839947}
2022-11-28 01:19:03,699 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:03,699 INFO:     Epoch: 6
2022-11-28 01:19:04,450 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49598849429325625, 'Total loss': 0.49598849429325625} | train loss {'Reaction outcome loss': 0.43668791169097065, 'Total loss': 0.43668791169097065}
2022-11-28 01:19:04,450 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:04,450 INFO:     Epoch: 7
2022-11-28 01:19:05,200 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4667947959493507, 'Total loss': 0.4667947959493507} | train loss {'Reaction outcome loss': 0.4208276257190386, 'Total loss': 0.4208276257190386}
2022-11-28 01:19:05,201 INFO:     Found new best model at epoch 7
2022-11-28 01:19:05,201 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:05,202 INFO:     Epoch: 8
2022-11-28 01:19:05,951 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4559144408188083, 'Total loss': 0.4559144408188083} | train loss {'Reaction outcome loss': 0.40257915681763456, 'Total loss': 0.40257915681763456}
2022-11-28 01:19:05,951 INFO:     Found new best model at epoch 8
2022-11-28 01:19:05,952 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:05,952 INFO:     Epoch: 9
2022-11-28 01:19:06,701 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43404535576701164, 'Total loss': 0.43404535576701164} | train loss {'Reaction outcome loss': 0.39171286241004344, 'Total loss': 0.39171286241004344}
2022-11-28 01:19:06,701 INFO:     Found new best model at epoch 9
2022-11-28 01:19:06,702 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:06,702 INFO:     Epoch: 10
2022-11-28 01:19:07,449 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4344534345648505, 'Total loss': 0.4344534345648505} | train loss {'Reaction outcome loss': 0.38937736230219905, 'Total loss': 0.38937736230219905}
2022-11-28 01:19:07,449 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:07,449 INFO:     Epoch: 11
2022-11-28 01:19:08,197 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49867586520585144, 'Total loss': 0.49867586520585144} | train loss {'Reaction outcome loss': 0.40405843186716317, 'Total loss': 0.40405843186716317}
2022-11-28 01:19:08,197 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:08,197 INFO:     Epoch: 12
2022-11-28 01:19:08,947 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4756365249102766, 'Total loss': 0.4756365249102766} | train loss {'Reaction outcome loss': 0.3955333518535502, 'Total loss': 0.3955333518535502}
2022-11-28 01:19:08,947 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:08,947 INFO:     Epoch: 13
2022-11-28 01:19:09,694 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47586707228964026, 'Total loss': 0.47586707228964026} | train loss {'Reaction outcome loss': 0.3708140092038433, 'Total loss': 0.3708140092038433}
2022-11-28 01:19:09,694 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:09,694 INFO:     Epoch: 14
2022-11-28 01:19:10,441 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4276623763144016, 'Total loss': 0.4276623763144016} | train loss {'Reaction outcome loss': 0.3787011178700547, 'Total loss': 0.3787011178700547}
2022-11-28 01:19:10,441 INFO:     Found new best model at epoch 14
2022-11-28 01:19:10,442 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:10,442 INFO:     Epoch: 15
2022-11-28 01:19:11,193 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.448665127158165, 'Total loss': 0.448665127158165} | train loss {'Reaction outcome loss': 0.36948140466261487, 'Total loss': 0.36948140466261487}
2022-11-28 01:19:11,193 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:11,193 INFO:     Epoch: 16
2022-11-28 01:19:11,943 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46972921185872774, 'Total loss': 0.46972921185872774} | train loss {'Reaction outcome loss': 0.3642689842987157, 'Total loss': 0.3642689842987157}
2022-11-28 01:19:11,943 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:11,943 INFO:     Epoch: 17
2022-11-28 01:19:12,691 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46819461848248134, 'Total loss': 0.46819461848248134} | train loss {'Reaction outcome loss': 0.36296755087520427, 'Total loss': 0.36296755087520427}
2022-11-28 01:19:12,691 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:12,691 INFO:     Epoch: 18
2022-11-28 01:19:13,441 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4444604785266248, 'Total loss': 0.4444604785266248} | train loss {'Reaction outcome loss': 0.36044012530431574, 'Total loss': 0.36044012530431574}
2022-11-28 01:19:13,441 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:13,441 INFO:     Epoch: 19
2022-11-28 01:19:14,189 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4757701161910187, 'Total loss': 0.4757701161910187} | train loss {'Reaction outcome loss': 0.35753287869102135, 'Total loss': 0.35753287869102135}
2022-11-28 01:19:14,189 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:14,189 INFO:     Epoch: 20
2022-11-28 01:19:14,938 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47389956699176267, 'Total loss': 0.47389956699176267} | train loss {'Reaction outcome loss': 0.35613881033441797, 'Total loss': 0.35613881033441797}
2022-11-28 01:19:14,938 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:14,938 INFO:     Epoch: 21
2022-11-28 01:19:15,685 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4228785786439072, 'Total loss': 0.4228785786439072} | train loss {'Reaction outcome loss': 0.3561982116416881, 'Total loss': 0.3561982116416881}
2022-11-28 01:19:15,686 INFO:     Found new best model at epoch 21
2022-11-28 01:19:15,687 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:15,687 INFO:     Epoch: 22
2022-11-28 01:19:16,436 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4494785090739077, 'Total loss': 0.4494785090739077} | train loss {'Reaction outcome loss': 0.35515379555606347, 'Total loss': 0.35515379555606347}
2022-11-28 01:19:16,436 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:16,436 INFO:     Epoch: 23
2022-11-28 01:19:17,189 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44893962280316785, 'Total loss': 0.44893962280316785} | train loss {'Reaction outcome loss': 0.33726835232755914, 'Total loss': 0.33726835232755914}
2022-11-28 01:19:17,189 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:17,189 INFO:     Epoch: 24
2022-11-28 01:19:17,937 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47087440538135444, 'Total loss': 0.47087440538135444} | train loss {'Reaction outcome loss': 0.3500161447264405, 'Total loss': 0.3500161447264405}
2022-11-28 01:19:17,937 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:17,938 INFO:     Epoch: 25
2022-11-28 01:19:18,685 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.420500520278107, 'Total loss': 0.420500520278107} | train loss {'Reaction outcome loss': 0.3611748467995088, 'Total loss': 0.3611748467995088}
2022-11-28 01:19:18,685 INFO:     Found new best model at epoch 25
2022-11-28 01:19:18,686 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:18,686 INFO:     Epoch: 26
2022-11-28 01:19:19,433 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4435989369045604, 'Total loss': 0.4435989369045604} | train loss {'Reaction outcome loss': 0.34466154125296633, 'Total loss': 0.34466154125296633}
2022-11-28 01:19:19,434 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:19,434 INFO:     Epoch: 27
2022-11-28 01:19:20,178 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4201846979558468, 'Total loss': 0.4201846979558468} | train loss {'Reaction outcome loss': 0.3362135531358149, 'Total loss': 0.3362135531358149}
2022-11-28 01:19:20,178 INFO:     Found new best model at epoch 27
2022-11-28 01:19:20,179 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:20,179 INFO:     Epoch: 28
2022-11-28 01:19:20,933 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4491762275045568, 'Total loss': 0.4491762275045568} | train loss {'Reaction outcome loss': 0.3397170510048778, 'Total loss': 0.3397170510048778}
2022-11-28 01:19:20,933 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:20,933 INFO:     Epoch: 29
2022-11-28 01:19:21,689 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44631574607708235, 'Total loss': 0.44631574607708235} | train loss {'Reaction outcome loss': 0.3369512693270257, 'Total loss': 0.3369512693270257}
2022-11-28 01:19:21,690 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:21,690 INFO:     Epoch: 30
2022-11-28 01:19:22,438 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4647184021093629, 'Total loss': 0.4647184021093629} | train loss {'Reaction outcome loss': 0.3352794921787282, 'Total loss': 0.3352794921787282}
2022-11-28 01:19:22,438 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:22,438 INFO:     Epoch: 31
2022-11-28 01:19:23,184 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.462008556520397, 'Total loss': 0.462008556520397} | train loss {'Reaction outcome loss': 0.3390711271750782, 'Total loss': 0.3390711271750782}
2022-11-28 01:19:23,184 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:23,184 INFO:     Epoch: 32
2022-11-28 01:19:23,933 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42472734776410187, 'Total loss': 0.42472734776410187} | train loss {'Reaction outcome loss': 0.35755859767859766, 'Total loss': 0.35755859767859766}
2022-11-28 01:19:23,933 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:23,933 INFO:     Epoch: 33
2022-11-28 01:19:24,679 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.441532163457437, 'Total loss': 0.441532163457437} | train loss {'Reaction outcome loss': 0.34380159279244843, 'Total loss': 0.34380159279244843}
2022-11-28 01:19:24,679 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:24,679 INFO:     Epoch: 34
2022-11-28 01:19:25,425 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4309363951059905, 'Total loss': 0.4309363951059905} | train loss {'Reaction outcome loss': 0.3314268880406855, 'Total loss': 0.3314268880406855}
2022-11-28 01:19:25,425 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:25,426 INFO:     Epoch: 35
2022-11-28 01:19:26,172 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4532855972647667, 'Total loss': 0.4532855972647667} | train loss {'Reaction outcome loss': 0.34212979858341486, 'Total loss': 0.34212979858341486}
2022-11-28 01:19:26,172 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:26,172 INFO:     Epoch: 36
2022-11-28 01:19:26,918 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42060682279142464, 'Total loss': 0.42060682279142464} | train loss {'Reaction outcome loss': 0.33141275899492295, 'Total loss': 0.33141275899492295}
2022-11-28 01:19:26,919 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:26,919 INFO:     Epoch: 37
2022-11-28 01:19:27,665 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42058496007865126, 'Total loss': 0.42058496007865126} | train loss {'Reaction outcome loss': 0.32122789811991487, 'Total loss': 0.32122789811991487}
2022-11-28 01:19:27,665 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:27,665 INFO:     Epoch: 38
2022-11-28 01:19:28,412 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4251057133078575, 'Total loss': 0.4251057133078575} | train loss {'Reaction outcome loss': 0.3324445029400168, 'Total loss': 0.3324445029400168}
2022-11-28 01:19:28,412 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:28,413 INFO:     Epoch: 39
2022-11-28 01:19:29,160 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4860060042278333, 'Total loss': 0.4860060042278333} | train loss {'Reaction outcome loss': 0.32361682418258747, 'Total loss': 0.32361682418258747}
2022-11-28 01:19:29,161 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:29,161 INFO:     Epoch: 40
2022-11-28 01:19:29,911 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3982908817177469, 'Total loss': 0.3982908817177469} | train loss {'Reaction outcome loss': 0.3267167505133248, 'Total loss': 0.3267167505133248}
2022-11-28 01:19:29,911 INFO:     Found new best model at epoch 40
2022-11-28 01:19:29,912 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:29,912 INFO:     Epoch: 41
2022-11-28 01:19:30,658 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43554458530111745, 'Total loss': 0.43554458530111745} | train loss {'Reaction outcome loss': 0.33732520435985763, 'Total loss': 0.33732520435985763}
2022-11-28 01:19:30,658 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:30,658 INFO:     Epoch: 42
2022-11-28 01:19:31,407 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45355640605769376, 'Total loss': 0.45355640605769376} | train loss {'Reaction outcome loss': 0.36920305272104287, 'Total loss': 0.36920305272104287}
2022-11-28 01:19:31,407 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:31,407 INFO:     Epoch: 43
2022-11-28 01:19:32,153 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41812898083166644, 'Total loss': 0.41812898083166644} | train loss {'Reaction outcome loss': 0.33820309804333937, 'Total loss': 0.33820309804333937}
2022-11-28 01:19:32,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:32,153 INFO:     Epoch: 44
2022-11-28 01:19:32,901 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4670958874577826, 'Total loss': 0.4670958874577826} | train loss {'Reaction outcome loss': 0.3238337061675228, 'Total loss': 0.3238337061675228}
2022-11-28 01:19:32,901 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:32,901 INFO:     Epoch: 45
2022-11-28 01:19:33,647 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.425627010112459, 'Total loss': 0.425627010112459} | train loss {'Reaction outcome loss': 0.33310590557723874, 'Total loss': 0.33310590557723874}
2022-11-28 01:19:33,648 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:33,648 INFO:     Epoch: 46
2022-11-28 01:19:34,398 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41603123024106026, 'Total loss': 0.41603123024106026} | train loss {'Reaction outcome loss': 0.3403080494900947, 'Total loss': 0.3403080494900947}
2022-11-28 01:19:34,398 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:34,398 INFO:     Epoch: 47
2022-11-28 01:19:35,149 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4566281282088973, 'Total loss': 0.4566281282088973} | train loss {'Reaction outcome loss': 0.33156406184574044, 'Total loss': 0.33156406184574044}
2022-11-28 01:19:35,149 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:35,149 INFO:     Epoch: 48
2022-11-28 01:19:35,895 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4310766417871822, 'Total loss': 0.4310766417871822} | train loss {'Reaction outcome loss': 0.32672260769526, 'Total loss': 0.32672260769526}
2022-11-28 01:19:35,896 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:35,896 INFO:     Epoch: 49
2022-11-28 01:19:36,644 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4198272807354277, 'Total loss': 0.4198272807354277} | train loss {'Reaction outcome loss': 0.3341594200867873, 'Total loss': 0.3341594200867873}
2022-11-28 01:19:36,644 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:36,644 INFO:     Epoch: 50
2022-11-28 01:19:37,392 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4210357198661024, 'Total loss': 0.4210357198661024} | train loss {'Reaction outcome loss': 0.33247481173409626, 'Total loss': 0.33247481173409626}
2022-11-28 01:19:37,392 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:37,392 INFO:     Epoch: 51
2022-11-28 01:19:38,140 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4338762623003938, 'Total loss': 0.4338762623003938} | train loss {'Reaction outcome loss': 0.31789552529346243, 'Total loss': 0.31789552529346243}
2022-11-28 01:19:38,140 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:38,140 INFO:     Epoch: 52
2022-11-28 01:19:38,887 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4321913360194726, 'Total loss': 0.4321913360194726} | train loss {'Reaction outcome loss': 0.3267034166888428, 'Total loss': 0.3267034166888428}
2022-11-28 01:19:38,888 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:38,888 INFO:     Epoch: 53
2022-11-28 01:19:39,634 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4118052057244561, 'Total loss': 0.4118052057244561} | train loss {'Reaction outcome loss': 0.3241003427488601, 'Total loss': 0.3241003427488601}
2022-11-28 01:19:39,634 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:39,634 INFO:     Epoch: 54
2022-11-28 01:19:40,384 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42953092367811635, 'Total loss': 0.42953092367811635} | train loss {'Reaction outcome loss': 0.32854002582376846, 'Total loss': 0.32854002582376846}
2022-11-28 01:19:40,384 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:40,384 INFO:     Epoch: 55
2022-11-28 01:19:41,135 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42406247420744464, 'Total loss': 0.42406247420744464} | train loss {'Reaction outcome loss': 0.3172004729026725, 'Total loss': 0.3172004729026725}
2022-11-28 01:19:41,135 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:41,135 INFO:     Epoch: 56
2022-11-28 01:19:41,881 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4314602975818244, 'Total loss': 0.4314602975818244} | train loss {'Reaction outcome loss': 0.329189548042682, 'Total loss': 0.329189548042682}
2022-11-28 01:19:41,881 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:41,881 INFO:     Epoch: 57
2022-11-28 01:19:42,628 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4678604250604456, 'Total loss': 0.4678604250604456} | train loss {'Reaction outcome loss': 0.32310991752553386, 'Total loss': 0.32310991752553386}
2022-11-28 01:19:42,628 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:42,628 INFO:     Epoch: 58
2022-11-28 01:19:43,374 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4258946478366852, 'Total loss': 0.4258946478366852} | train loss {'Reaction outcome loss': 0.31538917697392976, 'Total loss': 0.31538917697392976}
2022-11-28 01:19:43,374 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:43,375 INFO:     Epoch: 59
2022-11-28 01:19:44,122 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45588676377453585, 'Total loss': 0.45588676377453585} | train loss {'Reaction outcome loss': 0.3260571680480411, 'Total loss': 0.3260571680480411}
2022-11-28 01:19:44,122 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:44,123 INFO:     Epoch: 60
2022-11-28 01:19:44,872 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39846639199690387, 'Total loss': 0.39846639199690387} | train loss {'Reaction outcome loss': 0.3264705790319906, 'Total loss': 0.3264705790319906}
2022-11-28 01:19:44,872 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:44,872 INFO:     Epoch: 61
2022-11-28 01:19:45,618 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4436397169801322, 'Total loss': 0.4436397169801322} | train loss {'Reaction outcome loss': 0.3204952445831376, 'Total loss': 0.3204952445831376}
2022-11-28 01:19:45,618 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:45,618 INFO:     Epoch: 62
2022-11-28 01:19:46,376 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44246713122860953, 'Total loss': 0.44246713122860953} | train loss {'Reaction outcome loss': 0.32529942187582433, 'Total loss': 0.32529942187582433}
2022-11-28 01:19:46,376 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:46,377 INFO:     Epoch: 63
2022-11-28 01:19:47,131 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3818810863251036, 'Total loss': 0.3818810863251036} | train loss {'Reaction outcome loss': 0.31629967939123693, 'Total loss': 0.31629967939123693}
2022-11-28 01:19:47,132 INFO:     Found new best model at epoch 63
2022-11-28 01:19:47,133 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:47,133 INFO:     Epoch: 64
2022-11-28 01:19:47,883 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46851755847985094, 'Total loss': 0.46851755847985094} | train loss {'Reaction outcome loss': 0.31034163300226997, 'Total loss': 0.31034163300226997}
2022-11-28 01:19:47,884 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:47,884 INFO:     Epoch: 65
2022-11-28 01:19:48,631 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4307562739334323, 'Total loss': 0.4307562739334323} | train loss {'Reaction outcome loss': 0.3183589822156468, 'Total loss': 0.3183589822156468}
2022-11-28 01:19:48,632 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:48,632 INFO:     Epoch: 66
2022-11-28 01:19:49,379 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41529909148812294, 'Total loss': 0.41529909148812294} | train loss {'Reaction outcome loss': 0.324427677341077, 'Total loss': 0.324427677341077}
2022-11-28 01:19:49,379 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:49,379 INFO:     Epoch: 67
2022-11-28 01:19:50,127 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43189308453689923, 'Total loss': 0.43189308453689923} | train loss {'Reaction outcome loss': 0.3393668863349236, 'Total loss': 0.3393668863349236}
2022-11-28 01:19:50,127 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:50,127 INFO:     Epoch: 68
2022-11-28 01:19:50,871 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4623228165913712, 'Total loss': 0.4623228165913712} | train loss {'Reaction outcome loss': 0.30733177691381347, 'Total loss': 0.30733177691381347}
2022-11-28 01:19:50,871 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:50,871 INFO:     Epoch: 69
2022-11-28 01:19:51,612 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4156256617808884, 'Total loss': 0.4156256617808884} | train loss {'Reaction outcome loss': 0.3080545779061221, 'Total loss': 0.3080545779061221}
2022-11-28 01:19:51,612 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:51,612 INFO:     Epoch: 70
2022-11-28 01:19:52,363 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43339248035441746, 'Total loss': 0.43339248035441746} | train loss {'Reaction outcome loss': 0.31710809561978226, 'Total loss': 0.31710809561978226}
2022-11-28 01:19:52,363 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:52,364 INFO:     Epoch: 71
2022-11-28 01:19:53,108 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4278572387993336, 'Total loss': 0.4278572387993336} | train loss {'Reaction outcome loss': 0.30520941287859793, 'Total loss': 0.30520941287859793}
2022-11-28 01:19:53,108 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:53,108 INFO:     Epoch: 72
2022-11-28 01:19:53,853 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44046245413747703, 'Total loss': 0.44046245413747703} | train loss {'Reaction outcome loss': 0.31407826836126657, 'Total loss': 0.31407826836126657}
2022-11-28 01:19:53,854 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:53,854 INFO:     Epoch: 73
2022-11-28 01:19:54,599 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4177191267636689, 'Total loss': 0.4177191267636689} | train loss {'Reaction outcome loss': 0.31852680692064617, 'Total loss': 0.31852680692064617}
2022-11-28 01:19:54,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:54,599 INFO:     Epoch: 74
2022-11-28 01:19:55,339 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4101184672591361, 'Total loss': 0.4101184672591361} | train loss {'Reaction outcome loss': 0.3323659253003159, 'Total loss': 0.3323659253003159}
2022-11-28 01:19:55,339 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:55,339 INFO:     Epoch: 75
2022-11-28 01:19:56,085 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43629099327054893, 'Total loss': 0.43629099327054893} | train loss {'Reaction outcome loss': 0.31887696843277585, 'Total loss': 0.31887696843277585}
2022-11-28 01:19:56,085 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:56,085 INFO:     Epoch: 76
2022-11-28 01:19:56,828 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43364905057982966, 'Total loss': 0.43364905057982966} | train loss {'Reaction outcome loss': 0.31684145168542693, 'Total loss': 0.31684145168542693}
2022-11-28 01:19:56,828 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:56,828 INFO:     Epoch: 77
2022-11-28 01:19:57,572 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43516979044811294, 'Total loss': 0.43516979044811294} | train loss {'Reaction outcome loss': 0.31259788510998565, 'Total loss': 0.31259788510998565}
2022-11-28 01:19:57,572 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:57,572 INFO:     Epoch: 78
2022-11-28 01:19:58,319 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4047249030660499, 'Total loss': 0.4047249030660499} | train loss {'Reaction outcome loss': 0.31044987881714514, 'Total loss': 0.31044987881714514}
2022-11-28 01:19:58,319 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:58,319 INFO:     Epoch: 79
2022-11-28 01:19:59,066 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4004129564220255, 'Total loss': 0.4004129564220255} | train loss {'Reaction outcome loss': 0.3221751383924291, 'Total loss': 0.3221751383924291}
2022-11-28 01:19:59,066 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:59,066 INFO:     Epoch: 80
2022-11-28 01:19:59,811 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4448884129524231, 'Total loss': 0.4448884129524231} | train loss {'Reaction outcome loss': 0.3172246904794866, 'Total loss': 0.3172246904794866}
2022-11-28 01:19:59,811 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:19:59,811 INFO:     Epoch: 81
2022-11-28 01:20:00,551 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4255250333385034, 'Total loss': 0.4255250333385034} | train loss {'Reaction outcome loss': 0.3121597273991658, 'Total loss': 0.3121597273991658}
2022-11-28 01:20:00,551 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:00,551 INFO:     Epoch: 82
2022-11-28 01:20:01,293 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4161966595460068, 'Total loss': 0.4161966595460068} | train loss {'Reaction outcome loss': 0.31164503423308554, 'Total loss': 0.31164503423308554}
2022-11-28 01:20:01,294 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:01,294 INFO:     Epoch: 83
2022-11-28 01:20:02,039 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43856704370542005, 'Total loss': 0.43856704370542005} | train loss {'Reaction outcome loss': 0.3269370837732848, 'Total loss': 0.3269370837732848}
2022-11-28 01:20:02,039 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:02,039 INFO:     Epoch: 84
2022-11-28 01:20:02,781 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.440985518084331, 'Total loss': 0.440985518084331} | train loss {'Reaction outcome loss': 0.3219353353627298, 'Total loss': 0.3219353353627298}
2022-11-28 01:20:02,781 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:02,782 INFO:     Epoch: 85
2022-11-28 01:20:03,524 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43729616193608806, 'Total loss': 0.43729616193608806} | train loss {'Reaction outcome loss': 0.3166944246120781, 'Total loss': 0.3166944246120781}
2022-11-28 01:20:03,524 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:03,524 INFO:     Epoch: 86
2022-11-28 01:20:04,269 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42792049507525837, 'Total loss': 0.42792049507525837} | train loss {'Reaction outcome loss': 0.3060252574764509, 'Total loss': 0.3060252574764509}
2022-11-28 01:20:04,269 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:04,269 INFO:     Epoch: 87
2022-11-28 01:20:05,012 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4342655949294567, 'Total loss': 0.4342655949294567} | train loss {'Reaction outcome loss': 0.3144990212400915, 'Total loss': 0.3144990212400915}
2022-11-28 01:20:05,013 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:05,013 INFO:     Epoch: 88
2022-11-28 01:20:05,758 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42172742702744226, 'Total loss': 0.42172742702744226} | train loss {'Reaction outcome loss': 0.3091424842504596, 'Total loss': 0.3091424842504596}
2022-11-28 01:20:05,758 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:05,758 INFO:     Epoch: 89
2022-11-28 01:20:06,502 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4654664644463496, 'Total loss': 0.4654664644463496} | train loss {'Reaction outcome loss': 0.325828263858123, 'Total loss': 0.325828263858123}
2022-11-28 01:20:06,503 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:06,503 INFO:     Epoch: 90
2022-11-28 01:20:07,248 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.450267529623075, 'Total loss': 0.450267529623075} | train loss {'Reaction outcome loss': 0.3108890446785249, 'Total loss': 0.3108890446785249}
2022-11-28 01:20:07,248 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:07,248 INFO:     Epoch: 91
2022-11-28 01:20:07,992 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4695913534272801, 'Total loss': 0.4695913534272801} | train loss {'Reaction outcome loss': 0.3210968402344432, 'Total loss': 0.3210968402344432}
2022-11-28 01:20:07,992 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:07,992 INFO:     Epoch: 92
2022-11-28 01:20:08,738 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4350193677978082, 'Total loss': 0.4350193677978082} | train loss {'Reaction outcome loss': 0.3079820879497509, 'Total loss': 0.3079820879497509}
2022-11-28 01:20:08,738 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:08,738 INFO:     Epoch: 93
2022-11-28 01:20:09,489 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4378616779365323, 'Total loss': 0.4378616779365323} | train loss {'Reaction outcome loss': 0.3198413697753841, 'Total loss': 0.3198413697753841}
2022-11-28 01:20:09,489 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:09,489 INFO:     Epoch: 94
2022-11-28 01:20:10,237 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41648036834191193, 'Total loss': 0.41648036834191193} | train loss {'Reaction outcome loss': 0.3260852973531132, 'Total loss': 0.3260852973531132}
2022-11-28 01:20:10,237 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:10,237 INFO:     Epoch: 95
2022-11-28 01:20:10,983 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43298661505634134, 'Total loss': 0.43298661505634134} | train loss {'Reaction outcome loss': 0.31634393194124766, 'Total loss': 0.31634393194124766}
2022-11-28 01:20:10,983 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:10,983 INFO:     Epoch: 96
2022-11-28 01:20:11,729 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43466168574311514, 'Total loss': 0.43466168574311514} | train loss {'Reaction outcome loss': 0.31179037516717967, 'Total loss': 0.31179037516717967}
2022-11-28 01:20:11,729 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:11,729 INFO:     Epoch: 97
2022-11-28 01:20:12,474 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41645921631292865, 'Total loss': 0.41645921631292865} | train loss {'Reaction outcome loss': 0.31486207169861447, 'Total loss': 0.31486207169861447}
2022-11-28 01:20:12,474 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:12,475 INFO:     Epoch: 98
2022-11-28 01:20:13,219 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41166627153076907, 'Total loss': 0.41166627153076907} | train loss {'Reaction outcome loss': 0.3215099847196839, 'Total loss': 0.3215099847196839}
2022-11-28 01:20:13,219 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:13,220 INFO:     Epoch: 99
2022-11-28 01:20:13,962 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43388510224494065, 'Total loss': 0.43388510224494065} | train loss {'Reaction outcome loss': 0.3034278749816331, 'Total loss': 0.3034278749816331}
2022-11-28 01:20:13,962 INFO:     Best model found after epoch 64 of 100.
2022-11-28 01:20:13,962 INFO:   Done with stage: TRAINING
2022-11-28 01:20:13,962 INFO:   Starting stage: EVALUATION
2022-11-28 01:20:14,084 INFO:   Done with stage: EVALUATION
2022-11-28 01:20:14,084 INFO:   Leaving out SEQ value Fold_3
2022-11-28 01:20:14,097 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-28 01:20:14,097 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:20:14,736 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:20:14,736 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:20:14,806 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:20:14,806 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:20:14,806 INFO:     No hyperparam tuning for this model
2022-11-28 01:20:14,806 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:20:14,806 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:20:14,807 INFO:     None feature selector for col prot
2022-11-28 01:20:14,807 INFO:     None feature selector for col prot
2022-11-28 01:20:14,807 INFO:     None feature selector for col prot
2022-11-28 01:20:14,808 INFO:     None feature selector for col chem
2022-11-28 01:20:14,808 INFO:     None feature selector for col chem
2022-11-28 01:20:14,808 INFO:     None feature selector for col chem
2022-11-28 01:20:14,808 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:20:14,808 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:20:14,810 INFO:     Number of params in model 169741
2022-11-28 01:20:14,813 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:20:14,813 INFO:   Starting stage: TRAINING
2022-11-28 01:20:14,866 INFO:     Val loss before train {'Reaction outcome loss': 0.9759167835793712, 'Total loss': 0.9759167835793712}
2022-11-28 01:20:14,866 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:14,866 INFO:     Epoch: 0
2022-11-28 01:20:15,607 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5560876835476268, 'Total loss': 0.5560876835476268} | train loss {'Reaction outcome loss': 0.6207007902617357, 'Total loss': 0.6207007902617357}
2022-11-28 01:20:15,607 INFO:     Found new best model at epoch 0
2022-11-28 01:20:15,608 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:15,608 INFO:     Epoch: 1
2022-11-28 01:20:16,347 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49986092949455435, 'Total loss': 0.49986092949455435} | train loss {'Reaction outcome loss': 0.4900249619569097, 'Total loss': 0.4900249619569097}
2022-11-28 01:20:16,348 INFO:     Found new best model at epoch 1
2022-11-28 01:20:16,348 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:16,348 INFO:     Epoch: 2
2022-11-28 01:20:17,090 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4854364652525295, 'Total loss': 0.4854364652525295} | train loss {'Reaction outcome loss': 0.4598700297122099, 'Total loss': 0.4598700297122099}
2022-11-28 01:20:17,090 INFO:     Found new best model at epoch 2
2022-11-28 01:20:17,091 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:17,091 INFO:     Epoch: 3
2022-11-28 01:20:17,833 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48505775668573653, 'Total loss': 0.48505775668573653} | train loss {'Reaction outcome loss': 0.43743878158987787, 'Total loss': 0.43743878158987787}
2022-11-28 01:20:17,833 INFO:     Found new best model at epoch 3
2022-11-28 01:20:17,834 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:17,834 INFO:     Epoch: 4
2022-11-28 01:20:18,569 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4596034281633117, 'Total loss': 0.4596034281633117} | train loss {'Reaction outcome loss': 0.4209574701530593, 'Total loss': 0.4209574701530593}
2022-11-28 01:20:18,570 INFO:     Found new best model at epoch 4
2022-11-28 01:20:18,571 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:18,571 INFO:     Epoch: 5
2022-11-28 01:20:19,310 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4461768371137706, 'Total loss': 0.4461768371137706} | train loss {'Reaction outcome loss': 0.4077745818666049, 'Total loss': 0.4077745818666049}
2022-11-28 01:20:19,310 INFO:     Found new best model at epoch 5
2022-11-28 01:20:19,311 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:19,311 INFO:     Epoch: 6
2022-11-28 01:20:20,051 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45527859032154083, 'Total loss': 0.45527859032154083} | train loss {'Reaction outcome loss': 0.40042113591821826, 'Total loss': 0.40042113591821826}
2022-11-28 01:20:20,052 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:20,052 INFO:     Epoch: 7
2022-11-28 01:20:20,797 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4322900287806988, 'Total loss': 0.4322900287806988} | train loss {'Reaction outcome loss': 0.39895613333400415, 'Total loss': 0.39895613333400415}
2022-11-28 01:20:20,797 INFO:     Found new best model at epoch 7
2022-11-28 01:20:20,798 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:20,798 INFO:     Epoch: 8
2022-11-28 01:20:21,538 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4532983408055522, 'Total loss': 0.4532983408055522} | train loss {'Reaction outcome loss': 0.3820832857976154, 'Total loss': 0.3820832857976154}
2022-11-28 01:20:21,538 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:21,538 INFO:     Epoch: 9
2022-11-28 01:20:22,275 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43834108452905307, 'Total loss': 0.43834108452905307} | train loss {'Reaction outcome loss': 0.3826127648657682, 'Total loss': 0.3826127648657682}
2022-11-28 01:20:22,276 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:22,276 INFO:     Epoch: 10
2022-11-28 01:20:23,020 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4243985697288405, 'Total loss': 0.4243985697288405} | train loss {'Reaction outcome loss': 0.37350835493024515, 'Total loss': 0.37350835493024515}
2022-11-28 01:20:23,020 INFO:     Found new best model at epoch 10
2022-11-28 01:20:23,021 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:23,021 INFO:     Epoch: 11
2022-11-28 01:20:23,768 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4447427852587266, 'Total loss': 0.4447427852587266} | train loss {'Reaction outcome loss': 0.3716731161487346, 'Total loss': 0.3716731161487346}
2022-11-28 01:20:23,768 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:23,768 INFO:     Epoch: 12
2022-11-28 01:20:24,505 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47036172508854757, 'Total loss': 0.47036172508854757} | train loss {'Reaction outcome loss': 0.36207839255126156, 'Total loss': 0.36207839255126156}
2022-11-28 01:20:24,505 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:24,505 INFO:     Epoch: 13
2022-11-28 01:20:25,246 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4105298099192706, 'Total loss': 0.4105298099192706} | train loss {'Reaction outcome loss': 0.36211480051279066, 'Total loss': 0.36211480051279066}
2022-11-28 01:20:25,247 INFO:     Found new best model at epoch 13
2022-11-28 01:20:25,248 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:25,248 INFO:     Epoch: 14
2022-11-28 01:20:25,991 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4157717920501124, 'Total loss': 0.4157717920501124} | train loss {'Reaction outcome loss': 0.3649537131950563, 'Total loss': 0.3649537131950563}
2022-11-28 01:20:25,992 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:25,992 INFO:     Epoch: 15
2022-11-28 01:20:26,729 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41005058925260196, 'Total loss': 0.41005058925260196} | train loss {'Reaction outcome loss': 0.350975112799479, 'Total loss': 0.350975112799479}
2022-11-28 01:20:26,729 INFO:     Found new best model at epoch 15
2022-11-28 01:20:26,730 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:26,730 INFO:     Epoch: 16
2022-11-28 01:20:27,471 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49496297064152633, 'Total loss': 0.49496297064152633} | train loss {'Reaction outcome loss': 0.35223631296230823, 'Total loss': 0.35223631296230823}
2022-11-28 01:20:27,472 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:27,472 INFO:     Epoch: 17
2022-11-28 01:20:28,214 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43119943006472156, 'Total loss': 0.43119943006472156} | train loss {'Reaction outcome loss': 0.3534799691669795, 'Total loss': 0.3534799691669795}
2022-11-28 01:20:28,214 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:28,214 INFO:     Epoch: 18
2022-11-28 01:20:28,957 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4115687920288606, 'Total loss': 0.4115687920288606} | train loss {'Reaction outcome loss': 0.34442938043146715, 'Total loss': 0.34442938043146715}
2022-11-28 01:20:28,957 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:28,958 INFO:     Epoch: 19
2022-11-28 01:20:29,702 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4160239432345737, 'Total loss': 0.4160239432345737} | train loss {'Reaction outcome loss': 0.3500415618626439, 'Total loss': 0.3500415618626439}
2022-11-28 01:20:29,702 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:29,702 INFO:     Epoch: 20
2022-11-28 01:20:30,446 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4587831182236021, 'Total loss': 0.4587831182236021} | train loss {'Reaction outcome loss': 0.3446474089306228, 'Total loss': 0.3446474089306228}
2022-11-28 01:20:30,446 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:30,446 INFO:     Epoch: 21
2022-11-28 01:20:31,190 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4536684541539712, 'Total loss': 0.4536684541539712} | train loss {'Reaction outcome loss': 0.3425691038370132, 'Total loss': 0.3425691038370132}
2022-11-28 01:20:31,190 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:31,190 INFO:     Epoch: 22
2022-11-28 01:20:31,933 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4547381622886116, 'Total loss': 0.4547381622886116} | train loss {'Reaction outcome loss': 0.35367712031821813, 'Total loss': 0.35367712031821813}
2022-11-28 01:20:31,933 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:31,934 INFO:     Epoch: 23
2022-11-28 01:20:32,675 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42291882363232697, 'Total loss': 0.42291882363232697} | train loss {'Reaction outcome loss': 0.3389636987630202, 'Total loss': 0.3389636987630202}
2022-11-28 01:20:32,676 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:32,676 INFO:     Epoch: 24
2022-11-28 01:20:33,414 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4197313565422188, 'Total loss': 0.4197313565422188} | train loss {'Reaction outcome loss': 0.3359480122218327, 'Total loss': 0.3359480122218327}
2022-11-28 01:20:33,414 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:33,415 INFO:     Epoch: 25
2022-11-28 01:20:34,152 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43929660896008665, 'Total loss': 0.43929660896008665} | train loss {'Reaction outcome loss': 0.3310139166001154, 'Total loss': 0.3310139166001154}
2022-11-28 01:20:34,152 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:34,152 INFO:     Epoch: 26
2022-11-28 01:20:34,891 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43900921365076845, 'Total loss': 0.43900921365076845} | train loss {'Reaction outcome loss': 0.33375450862305506, 'Total loss': 0.33375450862305506}
2022-11-28 01:20:34,891 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:34,891 INFO:     Epoch: 27
2022-11-28 01:20:35,630 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4279280782423236, 'Total loss': 0.4279280782423236} | train loss {'Reaction outcome loss': 0.3380396987406575, 'Total loss': 0.3380396987406575}
2022-11-28 01:20:35,630 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:35,630 INFO:     Epoch: 28
2022-11-28 01:20:36,373 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4357422234659845, 'Total loss': 0.4357422234659845} | train loss {'Reaction outcome loss': 0.3255627811563258, 'Total loss': 0.3255627811563258}
2022-11-28 01:20:36,373 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:36,373 INFO:     Epoch: 29
2022-11-28 01:20:37,117 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4455828314477747, 'Total loss': 0.4455828314477747} | train loss {'Reaction outcome loss': 0.3293602532878214, 'Total loss': 0.3293602532878214}
2022-11-28 01:20:37,117 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:37,117 INFO:     Epoch: 30
2022-11-28 01:20:37,857 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4607831825586883, 'Total loss': 0.4607831825586883} | train loss {'Reaction outcome loss': 0.32765904756224884, 'Total loss': 0.32765904756224884}
2022-11-28 01:20:37,858 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:37,858 INFO:     Epoch: 31
2022-11-28 01:20:38,598 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4094808531755751, 'Total loss': 0.4094808531755751} | train loss {'Reaction outcome loss': 0.3193185636279534, 'Total loss': 0.3193185636279534}
2022-11-28 01:20:38,598 INFO:     Found new best model at epoch 31
2022-11-28 01:20:38,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:38,599 INFO:     Epoch: 32
2022-11-28 01:20:39,340 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4059676429764791, 'Total loss': 0.4059676429764791} | train loss {'Reaction outcome loss': 0.324849271318134, 'Total loss': 0.324849271318134}
2022-11-28 01:20:39,340 INFO:     Found new best model at epoch 32
2022-11-28 01:20:39,341 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:39,341 INFO:     Epoch: 33
2022-11-28 01:20:40,086 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43257527324286377, 'Total loss': 0.43257527324286377} | train loss {'Reaction outcome loss': 0.32518920810246954, 'Total loss': 0.32518920810246954}
2022-11-28 01:20:40,086 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:40,087 INFO:     Epoch: 34
2022-11-28 01:20:40,832 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4115139213813977, 'Total loss': 0.4115139213813977} | train loss {'Reaction outcome loss': 0.3255663990518268, 'Total loss': 0.3255663990518268}
2022-11-28 01:20:40,832 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:40,832 INFO:     Epoch: 35
2022-11-28 01:20:41,576 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3901357874274254, 'Total loss': 0.3901357874274254} | train loss {'Reaction outcome loss': 0.32293497999103704, 'Total loss': 0.32293497999103704}
2022-11-28 01:20:41,576 INFO:     Found new best model at epoch 35
2022-11-28 01:20:41,577 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:41,577 INFO:     Epoch: 36
2022-11-28 01:20:42,317 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44823233309117233, 'Total loss': 0.44823233309117233} | train loss {'Reaction outcome loss': 0.31879745676201215, 'Total loss': 0.31879745676201215}
2022-11-28 01:20:42,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:42,317 INFO:     Epoch: 37
2022-11-28 01:20:43,056 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41301422396844084, 'Total loss': 0.41301422396844084} | train loss {'Reaction outcome loss': 0.3325142845815542, 'Total loss': 0.3325142845815542}
2022-11-28 01:20:43,057 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:43,057 INFO:     Epoch: 38
2022-11-28 01:20:43,799 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43094146861271426, 'Total loss': 0.43094146861271426} | train loss {'Reaction outcome loss': 0.32159124269169204, 'Total loss': 0.32159124269169204}
2022-11-28 01:20:43,799 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:43,800 INFO:     Epoch: 39
2022-11-28 01:20:44,544 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41378406282853, 'Total loss': 0.41378406282853} | train loss {'Reaction outcome loss': 0.3225927005312881, 'Total loss': 0.3225927005312881}
2022-11-28 01:20:44,544 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:44,544 INFO:     Epoch: 40
2022-11-28 01:20:45,285 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47710502858866344, 'Total loss': 0.47710502858866344} | train loss {'Reaction outcome loss': 0.3251476898789406, 'Total loss': 0.3251476898789406}
2022-11-28 01:20:45,285 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:45,285 INFO:     Epoch: 41
2022-11-28 01:20:46,024 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4072835784066807, 'Total loss': 0.4072835784066807} | train loss {'Reaction outcome loss': 0.32005292028188703, 'Total loss': 0.32005292028188703}
2022-11-28 01:20:46,024 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:46,024 INFO:     Epoch: 42
2022-11-28 01:20:46,759 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43215612398291176, 'Total loss': 0.43215612398291176} | train loss {'Reaction outcome loss': 0.313186045082248, 'Total loss': 0.313186045082248}
2022-11-28 01:20:46,759 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:46,760 INFO:     Epoch: 43
2022-11-28 01:20:47,501 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41018436747518455, 'Total loss': 0.41018436747518455} | train loss {'Reaction outcome loss': 0.32453142809016366, 'Total loss': 0.32453142809016366}
2022-11-28 01:20:47,501 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:47,501 INFO:     Epoch: 44
2022-11-28 01:20:48,241 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40228355540470645, 'Total loss': 0.40228355540470645} | train loss {'Reaction outcome loss': 0.32156652467591423, 'Total loss': 0.32156652467591423}
2022-11-28 01:20:48,242 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:48,242 INFO:     Epoch: 45
2022-11-28 01:20:48,982 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42103589935736224, 'Total loss': 0.42103589935736224} | train loss {'Reaction outcome loss': 0.3173521341413868, 'Total loss': 0.3173521341413868}
2022-11-28 01:20:48,982 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:48,982 INFO:     Epoch: 46
2022-11-28 01:20:49,723 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3933431902392344, 'Total loss': 0.3933431902392344} | train loss {'Reaction outcome loss': 0.31519712081977297, 'Total loss': 0.31519712081977297}
2022-11-28 01:20:49,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:49,724 INFO:     Epoch: 47
2022-11-28 01:20:50,463 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42701571637933905, 'Total loss': 0.42701571637933905} | train loss {'Reaction outcome loss': 0.31235455399265094, 'Total loss': 0.31235455399265094}
2022-11-28 01:20:50,463 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:50,463 INFO:     Epoch: 48
2022-11-28 01:20:51,196 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41293209994381125, 'Total loss': 0.41293209994381125} | train loss {'Reaction outcome loss': 0.3201566246395208, 'Total loss': 0.3201566246395208}
2022-11-28 01:20:51,196 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:51,196 INFO:     Epoch: 49
2022-11-28 01:20:51,934 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3876671667464755, 'Total loss': 0.3876671667464755} | train loss {'Reaction outcome loss': 0.3218725384041971, 'Total loss': 0.3218725384041971}
2022-11-28 01:20:51,934 INFO:     Found new best model at epoch 49
2022-11-28 01:20:51,935 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:51,935 INFO:     Epoch: 50
2022-11-28 01:20:52,671 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4172258514233611, 'Total loss': 0.4172258514233611} | train loss {'Reaction outcome loss': 0.31430671181605785, 'Total loss': 0.31430671181605785}
2022-11-28 01:20:52,671 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:52,671 INFO:     Epoch: 51
2022-11-28 01:20:53,406 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43766573985869234, 'Total loss': 0.43766573985869234} | train loss {'Reaction outcome loss': 0.3091843562466758, 'Total loss': 0.3091843562466758}
2022-11-28 01:20:53,406 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:53,407 INFO:     Epoch: 52
2022-11-28 01:20:54,147 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4367688343944875, 'Total loss': 0.4367688343944875} | train loss {'Reaction outcome loss': 0.32470113850977955, 'Total loss': 0.32470113850977955}
2022-11-28 01:20:54,147 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:54,147 INFO:     Epoch: 53
2022-11-28 01:20:54,883 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43225098807703366, 'Total loss': 0.43225098807703366} | train loss {'Reaction outcome loss': 0.3187438422928051, 'Total loss': 0.3187438422928051}
2022-11-28 01:20:54,883 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:54,883 INFO:     Epoch: 54
2022-11-28 01:20:55,624 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42390504174611787, 'Total loss': 0.42390504174611787} | train loss {'Reaction outcome loss': 0.3284781899835382, 'Total loss': 0.3284781899835382}
2022-11-28 01:20:55,624 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:55,624 INFO:     Epoch: 55
2022-11-28 01:20:56,361 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44117771834135056, 'Total loss': 0.44117771834135056} | train loss {'Reaction outcome loss': 0.3171859409432022, 'Total loss': 0.3171859409432022}
2022-11-28 01:20:56,362 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:56,362 INFO:     Epoch: 56
2022-11-28 01:20:57,096 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.470539448952133, 'Total loss': 0.470539448952133} | train loss {'Reaction outcome loss': 0.3078724044318102, 'Total loss': 0.3078724044318102}
2022-11-28 01:20:57,096 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:57,096 INFO:     Epoch: 57
2022-11-28 01:20:57,828 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3907267823815346, 'Total loss': 0.3907267823815346} | train loss {'Reaction outcome loss': 0.30050829019473524, 'Total loss': 0.30050829019473524}
2022-11-28 01:20:57,828 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:57,828 INFO:     Epoch: 58
2022-11-28 01:20:58,566 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4481517110358585, 'Total loss': 0.4481517110358585} | train loss {'Reaction outcome loss': 0.3206960407750947, 'Total loss': 0.3206960407750947}
2022-11-28 01:20:58,566 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:58,566 INFO:     Epoch: 59
2022-11-28 01:20:59,304 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.426288959316232, 'Total loss': 0.426288959316232} | train loss {'Reaction outcome loss': 0.31605065054431253, 'Total loss': 0.31605065054431253}
2022-11-28 01:20:59,304 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:20:59,304 INFO:     Epoch: 60
2022-11-28 01:21:00,037 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4171261574057015, 'Total loss': 0.4171261574057015} | train loss {'Reaction outcome loss': 0.31624052827151455, 'Total loss': 0.31624052827151455}
2022-11-28 01:21:00,037 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:00,037 INFO:     Epoch: 61
2022-11-28 01:21:00,776 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43811339389702136, 'Total loss': 0.43811339389702136} | train loss {'Reaction outcome loss': 0.3125729999067832, 'Total loss': 0.3125729999067832}
2022-11-28 01:21:00,776 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:00,776 INFO:     Epoch: 62
2022-11-28 01:21:01,513 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43325327133590524, 'Total loss': 0.43325327133590524} | train loss {'Reaction outcome loss': 0.31177381401767534, 'Total loss': 0.31177381401767534}
2022-11-28 01:21:01,513 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:01,513 INFO:     Epoch: 63
2022-11-28 01:21:02,251 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4182026589458639, 'Total loss': 0.4182026589458639} | train loss {'Reaction outcome loss': 0.31630140862294603, 'Total loss': 0.31630140862294603}
2022-11-28 01:21:02,251 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:02,251 INFO:     Epoch: 64
2022-11-28 01:21:02,987 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44440376284447586, 'Total loss': 0.44440376284447586} | train loss {'Reaction outcome loss': 0.3155746370858076, 'Total loss': 0.3155746370858076}
2022-11-28 01:21:02,987 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:02,987 INFO:     Epoch: 65
2022-11-28 01:21:03,725 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4213246022435752, 'Total loss': 0.4213246022435752} | train loss {'Reaction outcome loss': 0.3170233672370716, 'Total loss': 0.3170233672370716}
2022-11-28 01:21:03,725 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:03,725 INFO:     Epoch: 66
2022-11-28 01:21:04,469 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3981387103823098, 'Total loss': 0.3981387103823098} | train loss {'Reaction outcome loss': 0.3091618301156832, 'Total loss': 0.3091618301156832}
2022-11-28 01:21:04,469 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:04,469 INFO:     Epoch: 67
2022-11-28 01:21:05,206 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40738898765465076, 'Total loss': 0.40738898765465076} | train loss {'Reaction outcome loss': 0.3108705159960961, 'Total loss': 0.3108705159960961}
2022-11-28 01:21:05,207 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:05,207 INFO:     Epoch: 68
2022-11-28 01:21:05,943 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40664841404015367, 'Total loss': 0.40664841404015367} | train loss {'Reaction outcome loss': 0.31966563298994183, 'Total loss': 0.31966563298994183}
2022-11-28 01:21:05,943 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:05,943 INFO:     Epoch: 69
2022-11-28 01:21:06,681 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43684874728999357, 'Total loss': 0.43684874728999357} | train loss {'Reaction outcome loss': 0.31171745213927055, 'Total loss': 0.31171745213927055}
2022-11-28 01:21:06,681 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:06,681 INFO:     Epoch: 70
2022-11-28 01:21:07,417 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45370328629558737, 'Total loss': 0.45370328629558737} | train loss {'Reaction outcome loss': 0.3059950631796097, 'Total loss': 0.3059950631796097}
2022-11-28 01:21:07,417 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:07,417 INFO:     Epoch: 71
2022-11-28 01:21:08,153 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4207794249735095, 'Total loss': 0.4207794249735095} | train loss {'Reaction outcome loss': 0.3144701158665881, 'Total loss': 0.3144701158665881}
2022-11-28 01:21:08,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:08,153 INFO:     Epoch: 72
2022-11-28 01:21:08,890 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39875024455514824, 'Total loss': 0.39875024455514824} | train loss {'Reaction outcome loss': 0.3160887379731451, 'Total loss': 0.3160887379731451}
2022-11-28 01:21:08,891 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:08,891 INFO:     Epoch: 73
2022-11-28 01:21:09,626 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4149609235200015, 'Total loss': 0.4149609235200015} | train loss {'Reaction outcome loss': 0.3066483229246675, 'Total loss': 0.3066483229246675}
2022-11-28 01:21:09,626 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:09,626 INFO:     Epoch: 74
2022-11-28 01:21:10,365 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40300666439262306, 'Total loss': 0.40300666439262306} | train loss {'Reaction outcome loss': 0.3149379124750896, 'Total loss': 0.3149379124750896}
2022-11-28 01:21:10,366 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:10,366 INFO:     Epoch: 75
2022-11-28 01:21:11,106 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4077161875638095, 'Total loss': 0.4077161875638095} | train loss {'Reaction outcome loss': 0.3069500231013006, 'Total loss': 0.3069500231013006}
2022-11-28 01:21:11,106 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:11,106 INFO:     Epoch: 76
2022-11-28 01:21:11,845 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41583594104105776, 'Total loss': 0.41583594104105776} | train loss {'Reaction outcome loss': 0.30614724907339835, 'Total loss': 0.30614724907339835}
2022-11-28 01:21:11,845 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:11,845 INFO:     Epoch: 77
2022-11-28 01:21:12,583 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4145693348890001, 'Total loss': 0.4145693348890001} | train loss {'Reaction outcome loss': 0.31586868641327837, 'Total loss': 0.31586868641327837}
2022-11-28 01:21:12,583 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:12,583 INFO:     Epoch: 78
2022-11-28 01:21:13,318 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38983526825904846, 'Total loss': 0.38983526825904846} | train loss {'Reaction outcome loss': 0.31199791299141183, 'Total loss': 0.31199791299141183}
2022-11-28 01:21:13,318 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:13,318 INFO:     Epoch: 79
2022-11-28 01:21:14,055 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4085404495285316, 'Total loss': 0.4085404495285316} | train loss {'Reaction outcome loss': 0.29822802032743184, 'Total loss': 0.29822802032743184}
2022-11-28 01:21:14,055 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:14,055 INFO:     Epoch: 80
2022-11-28 01:21:14,789 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40691460465843027, 'Total loss': 0.40691460465843027} | train loss {'Reaction outcome loss': 0.304997062941595, 'Total loss': 0.304997062941595}
2022-11-28 01:21:14,790 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:14,790 INFO:     Epoch: 81
2022-11-28 01:21:15,524 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4284513687545603, 'Total loss': 0.4284513687545603} | train loss {'Reaction outcome loss': 0.31109454285125343, 'Total loss': 0.31109454285125343}
2022-11-28 01:21:15,524 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:15,524 INFO:     Epoch: 82
2022-11-28 01:21:16,260 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42324064299464226, 'Total loss': 0.42324064299464226} | train loss {'Reaction outcome loss': 0.3053732806170473, 'Total loss': 0.3053732806170473}
2022-11-28 01:21:16,260 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:16,261 INFO:     Epoch: 83
2022-11-28 01:21:16,995 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4116399525241418, 'Total loss': 0.4116399525241418} | train loss {'Reaction outcome loss': 0.3110102881582416, 'Total loss': 0.3110102881582416}
2022-11-28 01:21:16,995 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:16,996 INFO:     Epoch: 84
2022-11-28 01:21:17,729 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4452291159805926, 'Total loss': 0.4452291159805926} | train loss {'Reaction outcome loss': 0.31671072457517896, 'Total loss': 0.31671072457517896}
2022-11-28 01:21:17,730 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:17,730 INFO:     Epoch: 85
2022-11-28 01:21:18,468 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4328907213427804, 'Total loss': 0.4328907213427804} | train loss {'Reaction outcome loss': 0.3089604966190396, 'Total loss': 0.3089604966190396}
2022-11-28 01:21:18,468 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:18,468 INFO:     Epoch: 86
2022-11-28 01:21:19,209 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3977632504803213, 'Total loss': 0.3977632504803213} | train loss {'Reaction outcome loss': 0.30687372806120894, 'Total loss': 0.30687372806120894}
2022-11-28 01:21:19,210 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:19,210 INFO:     Epoch: 87
2022-11-28 01:21:19,949 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4162165502255613, 'Total loss': 0.4162165502255613} | train loss {'Reaction outcome loss': 0.30230194003302224, 'Total loss': 0.30230194003302224}
2022-11-28 01:21:19,949 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:19,949 INFO:     Epoch: 88
2022-11-28 01:21:20,687 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43434172767129814, 'Total loss': 0.43434172767129814} | train loss {'Reaction outcome loss': 0.32156710983539116, 'Total loss': 0.32156710983539116}
2022-11-28 01:21:20,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:20,688 INFO:     Epoch: 89
2022-11-28 01:21:21,424 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4269909603013234, 'Total loss': 0.4269909603013234} | train loss {'Reaction outcome loss': 0.31170383044043365, 'Total loss': 0.31170383044043365}
2022-11-28 01:21:21,424 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:21,425 INFO:     Epoch: 90
2022-11-28 01:21:22,164 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41289871829477226, 'Total loss': 0.41289871829477226} | train loss {'Reaction outcome loss': 0.30525150010172203, 'Total loss': 0.30525150010172203}
2022-11-28 01:21:22,164 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:22,164 INFO:     Epoch: 91
2022-11-28 01:21:22,903 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4153408022089438, 'Total loss': 0.4153408022089438} | train loss {'Reaction outcome loss': 0.30416875656466097, 'Total loss': 0.30416875656466097}
2022-11-28 01:21:22,903 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:22,903 INFO:     Epoch: 92
2022-11-28 01:21:23,641 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43773780593817885, 'Total loss': 0.43773780593817885} | train loss {'Reaction outcome loss': 0.30964877029158633, 'Total loss': 0.30964877029158633}
2022-11-28 01:21:23,641 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:23,641 INFO:     Epoch: 93
2022-11-28 01:21:24,382 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.395508610220118, 'Total loss': 0.395508610220118} | train loss {'Reaction outcome loss': 0.31254317939889675, 'Total loss': 0.31254317939889675}
2022-11-28 01:21:24,382 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:24,382 INFO:     Epoch: 94
2022-11-28 01:21:25,120 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4089280642061071, 'Total loss': 0.4089280642061071} | train loss {'Reaction outcome loss': 0.30750974127832725, 'Total loss': 0.30750974127832725}
2022-11-28 01:21:25,120 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:25,121 INFO:     Epoch: 95
2022-11-28 01:21:25,856 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40745327981527557, 'Total loss': 0.40745327981527557} | train loss {'Reaction outcome loss': 0.3055989892811191, 'Total loss': 0.3055989892811191}
2022-11-28 01:21:25,856 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:25,856 INFO:     Epoch: 96
2022-11-28 01:21:26,590 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4356782754713839, 'Total loss': 0.4356782754713839} | train loss {'Reaction outcome loss': 0.2996474728140296, 'Total loss': 0.2996474728140296}
2022-11-28 01:21:26,590 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:26,590 INFO:     Epoch: 97
2022-11-28 01:21:27,327 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40409768508239224, 'Total loss': 0.40409768508239224} | train loss {'Reaction outcome loss': 0.30304527024225314, 'Total loss': 0.30304527024225314}
2022-11-28 01:21:27,328 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:27,328 INFO:     Epoch: 98
2022-11-28 01:21:28,065 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4346435653384436, 'Total loss': 0.4346435653384436} | train loss {'Reaction outcome loss': 0.3030117598723392, 'Total loss': 0.3030117598723392}
2022-11-28 01:21:28,065 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:28,066 INFO:     Epoch: 99
2022-11-28 01:21:28,806 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42874287644570525, 'Total loss': 0.42874287644570525} | train loss {'Reaction outcome loss': 0.3131856530296559, 'Total loss': 0.3131856530296559}
2022-11-28 01:21:28,806 INFO:     Best model found after epoch 50 of 100.
2022-11-28 01:21:28,806 INFO:   Done with stage: TRAINING
2022-11-28 01:21:28,806 INFO:   Starting stage: EVALUATION
2022-11-28 01:21:28,933 INFO:   Done with stage: EVALUATION
2022-11-28 01:21:28,933 INFO:   Leaving out SEQ value Fold_4
2022-11-28 01:21:28,946 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 01:21:28,946 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:21:29,584 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:21:29,584 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:21:29,655 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:21:29,655 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:21:29,655 INFO:     No hyperparam tuning for this model
2022-11-28 01:21:29,655 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:21:29,655 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:21:29,656 INFO:     None feature selector for col prot
2022-11-28 01:21:29,656 INFO:     None feature selector for col prot
2022-11-28 01:21:29,656 INFO:     None feature selector for col prot
2022-11-28 01:21:29,657 INFO:     None feature selector for col chem
2022-11-28 01:21:29,657 INFO:     None feature selector for col chem
2022-11-28 01:21:29,657 INFO:     None feature selector for col chem
2022-11-28 01:21:29,657 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:21:29,657 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:21:29,658 INFO:     Number of params in model 169741
2022-11-28 01:21:29,661 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:21:29,661 INFO:   Starting stage: TRAINING
2022-11-28 01:21:29,715 INFO:     Val loss before train {'Reaction outcome loss': 1.0002759071913632, 'Total loss': 1.0002759071913632}
2022-11-28 01:21:29,715 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:29,715 INFO:     Epoch: 0
2022-11-28 01:21:30,455 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5273658043958924, 'Total loss': 0.5273658043958924} | train loss {'Reaction outcome loss': 0.6536500456362118, 'Total loss': 0.6536500456362118}
2022-11-28 01:21:30,455 INFO:     Found new best model at epoch 0
2022-11-28 01:21:30,456 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:30,456 INFO:     Epoch: 1
2022-11-28 01:21:31,200 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5136003250425513, 'Total loss': 0.5136003250425513} | train loss {'Reaction outcome loss': 0.511023680208183, 'Total loss': 0.511023680208183}
2022-11-28 01:21:31,200 INFO:     Found new best model at epoch 1
2022-11-28 01:21:31,201 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:31,201 INFO:     Epoch: 2
2022-11-28 01:21:31,944 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4883706197142601, 'Total loss': 0.4883706197142601} | train loss {'Reaction outcome loss': 0.46111678329073946, 'Total loss': 0.46111678329073946}
2022-11-28 01:21:31,944 INFO:     Found new best model at epoch 2
2022-11-28 01:21:31,945 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:31,945 INFO:     Epoch: 3
2022-11-28 01:21:32,685 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4877946268428456, 'Total loss': 0.4877946268428456} | train loss {'Reaction outcome loss': 0.4575953775270265, 'Total loss': 0.4575953775270265}
2022-11-28 01:21:32,685 INFO:     Found new best model at epoch 3
2022-11-28 01:21:32,686 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:32,686 INFO:     Epoch: 4
2022-11-28 01:21:33,427 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4630381092429161, 'Total loss': 0.4630381092429161} | train loss {'Reaction outcome loss': 0.4194833473999973, 'Total loss': 0.4194833473999973}
2022-11-28 01:21:33,427 INFO:     Found new best model at epoch 4
2022-11-28 01:21:33,428 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:33,428 INFO:     Epoch: 5
2022-11-28 01:21:34,168 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4821852743625641, 'Total loss': 0.4821852743625641} | train loss {'Reaction outcome loss': 0.41835229147059716, 'Total loss': 0.41835229147059716}
2022-11-28 01:21:34,168 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:34,168 INFO:     Epoch: 6
2022-11-28 01:21:34,908 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.430070388046178, 'Total loss': 0.430070388046178} | train loss {'Reaction outcome loss': 0.40007066707831884, 'Total loss': 0.40007066707831884}
2022-11-28 01:21:34,909 INFO:     Found new best model at epoch 6
2022-11-28 01:21:34,909 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:34,909 INFO:     Epoch: 7
2022-11-28 01:21:35,649 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.465136819942431, 'Total loss': 0.465136819942431} | train loss {'Reaction outcome loss': 0.38910035068086285, 'Total loss': 0.38910035068086285}
2022-11-28 01:21:35,650 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:35,650 INFO:     Epoch: 8
2022-11-28 01:21:36,386 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44459452683275397, 'Total loss': 0.44459452683275397} | train loss {'Reaction outcome loss': 0.3917390933403602, 'Total loss': 0.3917390933403602}
2022-11-28 01:21:36,386 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:36,386 INFO:     Epoch: 9
2022-11-28 01:21:37,125 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44904667274518445, 'Total loss': 0.44904667274518445} | train loss {'Reaction outcome loss': 0.3884508834043254, 'Total loss': 0.3884508834043254}
2022-11-28 01:21:37,126 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:37,126 INFO:     Epoch: 10
2022-11-28 01:21:37,864 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46007561311125755, 'Total loss': 0.46007561311125755} | train loss {'Reaction outcome loss': 0.36712293924107725, 'Total loss': 0.36712293924107725}
2022-11-28 01:21:37,864 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:37,864 INFO:     Epoch: 11
2022-11-28 01:21:38,606 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.448268962262029, 'Total loss': 0.448268962262029} | train loss {'Reaction outcome loss': 0.36932874089370854, 'Total loss': 0.36932874089370854}
2022-11-28 01:21:38,606 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:38,606 INFO:     Epoch: 12
2022-11-28 01:21:39,346 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47001756355166435, 'Total loss': 0.47001756355166435} | train loss {'Reaction outcome loss': 0.36875420072783344, 'Total loss': 0.36875420072783344}
2022-11-28 01:21:39,347 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:39,347 INFO:     Epoch: 13
2022-11-28 01:21:40,085 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42958182333545253, 'Total loss': 0.42958182333545253} | train loss {'Reaction outcome loss': 0.3720343903853343, 'Total loss': 0.3720343903853343}
2022-11-28 01:21:40,085 INFO:     Found new best model at epoch 13
2022-11-28 01:21:40,086 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:40,086 INFO:     Epoch: 14
2022-11-28 01:21:40,825 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4400668970563195, 'Total loss': 0.4400668970563195} | train loss {'Reaction outcome loss': 0.36214930583771904, 'Total loss': 0.36214930583771904}
2022-11-28 01:21:40,825 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:40,825 INFO:     Epoch: 15
2022-11-28 01:21:41,564 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45528811317953194, 'Total loss': 0.45528811317953194} | train loss {'Reaction outcome loss': 0.3558319566341547, 'Total loss': 0.3558319566341547}
2022-11-28 01:21:41,564 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:41,564 INFO:     Epoch: 16
2022-11-28 01:21:42,301 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42386549575762317, 'Total loss': 0.42386549575762317} | train loss {'Reaction outcome loss': 0.359927982634861, 'Total loss': 0.359927982634861}
2022-11-28 01:21:42,302 INFO:     Found new best model at epoch 16
2022-11-28 01:21:42,302 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:42,302 INFO:     Epoch: 17
2022-11-28 01:21:43,044 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4395192549987273, 'Total loss': 0.4395192549987273} | train loss {'Reaction outcome loss': 0.3536781765245324, 'Total loss': 0.3536781765245324}
2022-11-28 01:21:43,045 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:43,045 INFO:     Epoch: 18
2022-11-28 01:21:43,783 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44097586687315593, 'Total loss': 0.44097586687315593} | train loss {'Reaction outcome loss': 0.34451436818490627, 'Total loss': 0.34451436818490627}
2022-11-28 01:21:43,784 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:43,784 INFO:     Epoch: 19
2022-11-28 01:21:44,525 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4591864269565452, 'Total loss': 0.4591864269565452} | train loss {'Reaction outcome loss': 0.3532128516841031, 'Total loss': 0.3532128516841031}
2022-11-28 01:21:44,525 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:44,525 INFO:     Epoch: 20
2022-11-28 01:21:45,266 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4394380216571418, 'Total loss': 0.4394380216571418} | train loss {'Reaction outcome loss': 0.35328855106101825, 'Total loss': 0.35328855106101825}
2022-11-28 01:21:45,266 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:45,267 INFO:     Epoch: 21
2022-11-28 01:21:46,008 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44219433465464547, 'Total loss': 0.44219433465464547} | train loss {'Reaction outcome loss': 0.3447745274073682, 'Total loss': 0.3447745274073682}
2022-11-28 01:21:46,008 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:46,008 INFO:     Epoch: 22
2022-11-28 01:21:46,752 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4546327550302852, 'Total loss': 0.4546327550302852} | train loss {'Reaction outcome loss': 0.33300359088640946, 'Total loss': 0.33300359088640946}
2022-11-28 01:21:46,752 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:46,752 INFO:     Epoch: 23
2022-11-28 01:21:47,492 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44566326012665575, 'Total loss': 0.44566326012665575} | train loss {'Reaction outcome loss': 0.3439847253836118, 'Total loss': 0.3439847253836118}
2022-11-28 01:21:47,493 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:47,493 INFO:     Epoch: 24
2022-11-28 01:21:48,229 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42279609360478143, 'Total loss': 0.42279609360478143} | train loss {'Reaction outcome loss': 0.3364161786883466, 'Total loss': 0.3364161786883466}
2022-11-28 01:21:48,229 INFO:     Found new best model at epoch 24
2022-11-28 01:21:48,230 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:48,230 INFO:     Epoch: 25
2022-11-28 01:21:48,969 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4413471899249337, 'Total loss': 0.4413471899249337} | train loss {'Reaction outcome loss': 0.3703952285381947, 'Total loss': 0.3703952285381947}
2022-11-28 01:21:48,969 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:48,969 INFO:     Epoch: 26
2022-11-28 01:21:49,706 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4758630516854199, 'Total loss': 0.4758630516854199} | train loss {'Reaction outcome loss': 0.36130997674305915, 'Total loss': 0.36130997674305915}
2022-11-28 01:21:49,706 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:49,706 INFO:     Epoch: 27
2022-11-28 01:21:50,445 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4886687475849282, 'Total loss': 0.4886687475849282} | train loss {'Reaction outcome loss': 0.3387275270868832, 'Total loss': 0.3387275270868832}
2022-11-28 01:21:50,445 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:50,446 INFO:     Epoch: 28
2022-11-28 01:21:51,183 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4355616718530655, 'Total loss': 0.4355616718530655} | train loss {'Reaction outcome loss': 0.33510679166447294, 'Total loss': 0.33510679166447294}
2022-11-28 01:21:51,184 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:51,184 INFO:     Epoch: 29
2022-11-28 01:21:51,924 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42229932004755194, 'Total loss': 0.42229932004755194} | train loss {'Reaction outcome loss': 0.33220656821999117, 'Total loss': 0.33220656821999117}
2022-11-28 01:21:51,925 INFO:     Found new best model at epoch 29
2022-11-28 01:21:51,926 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:51,926 INFO:     Epoch: 30
2022-11-28 01:21:52,672 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4526383382352916, 'Total loss': 0.4526383382352916} | train loss {'Reaction outcome loss': 0.330056343031557, 'Total loss': 0.330056343031557}
2022-11-28 01:21:52,672 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:52,672 INFO:     Epoch: 31
2022-11-28 01:21:53,415 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4559529670937495, 'Total loss': 0.4559529670937495} | train loss {'Reaction outcome loss': 0.3411096589647324, 'Total loss': 0.3411096589647324}
2022-11-28 01:21:53,415 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:53,415 INFO:     Epoch: 32
2022-11-28 01:21:54,154 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44449956410310487, 'Total loss': 0.44449956410310487} | train loss {'Reaction outcome loss': 0.3329702300219401, 'Total loss': 0.3329702300219401}
2022-11-28 01:21:54,154 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:54,154 INFO:     Epoch: 33
2022-11-28 01:21:54,894 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45317048782652075, 'Total loss': 0.45317048782652075} | train loss {'Reaction outcome loss': 0.3369411281064937, 'Total loss': 0.3369411281064937}
2022-11-28 01:21:54,894 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:54,894 INFO:     Epoch: 34
2022-11-28 01:21:55,636 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46655691347338935, 'Total loss': 0.46655691347338935} | train loss {'Reaction outcome loss': 0.3324251295433112, 'Total loss': 0.3324251295433112}
2022-11-28 01:21:55,636 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:55,637 INFO:     Epoch: 35
2022-11-28 01:21:56,379 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49945287812839856, 'Total loss': 0.49945287812839856} | train loss {'Reaction outcome loss': 0.3229191997031934, 'Total loss': 0.3229191997031934}
2022-11-28 01:21:56,380 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:56,380 INFO:     Epoch: 36
2022-11-28 01:21:57,121 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4176457707177509, 'Total loss': 0.4176457707177509} | train loss {'Reaction outcome loss': 0.3263970453533446, 'Total loss': 0.3263970453533446}
2022-11-28 01:21:57,122 INFO:     Found new best model at epoch 36
2022-11-28 01:21:57,122 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:57,122 INFO:     Epoch: 37
2022-11-28 01:21:57,859 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44174378128214314, 'Total loss': 0.44174378128214314} | train loss {'Reaction outcome loss': 0.3275065697759752, 'Total loss': 0.3275065697759752}
2022-11-28 01:21:57,859 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:57,859 INFO:     Epoch: 38
2022-11-28 01:21:58,598 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4436357126317241, 'Total loss': 0.4436357126317241} | train loss {'Reaction outcome loss': 0.3407053779735256, 'Total loss': 0.3407053779735256}
2022-11-28 01:21:58,599 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:58,599 INFO:     Epoch: 39
2022-11-28 01:21:59,341 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45268839529969473, 'Total loss': 0.45268839529969473} | train loss {'Reaction outcome loss': 0.3376163269524172, 'Total loss': 0.3376163269524172}
2022-11-28 01:21:59,342 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:21:59,342 INFO:     Epoch: 40
2022-11-28 01:22:00,080 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4427032025361603, 'Total loss': 0.4427032025361603} | train loss {'Reaction outcome loss': 0.3150289806008041, 'Total loss': 0.3150289806008041}
2022-11-28 01:22:00,080 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:00,080 INFO:     Epoch: 41
2022-11-28 01:22:00,818 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4440958504988389, 'Total loss': 0.4440958504988389} | train loss {'Reaction outcome loss': 0.3303959640534783, 'Total loss': 0.3303959640534783}
2022-11-28 01:22:00,818 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:00,818 INFO:     Epoch: 42
2022-11-28 01:22:01,556 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4199402410198342, 'Total loss': 0.4199402410198342} | train loss {'Reaction outcome loss': 0.32118885918908757, 'Total loss': 0.32118885918908757}
2022-11-28 01:22:01,556 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:01,556 INFO:     Epoch: 43
2022-11-28 01:22:02,296 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.481422608718276, 'Total loss': 0.481422608718276} | train loss {'Reaction outcome loss': 0.33279568026302314, 'Total loss': 0.33279568026302314}
2022-11-28 01:22:02,297 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:02,297 INFO:     Epoch: 44
2022-11-28 01:22:03,034 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4305110907351429, 'Total loss': 0.4305110907351429} | train loss {'Reaction outcome loss': 0.32493068771399103, 'Total loss': 0.32493068771399103}
2022-11-28 01:22:03,034 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:03,034 INFO:     Epoch: 45
2022-11-28 01:22:03,772 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4524006884206425, 'Total loss': 0.4524006884206425} | train loss {'Reaction outcome loss': 0.3174537411525182, 'Total loss': 0.3174537411525182}
2022-11-28 01:22:03,772 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:03,772 INFO:     Epoch: 46
2022-11-28 01:22:04,517 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45287671956149017, 'Total loss': 0.45287671956149017} | train loss {'Reaction outcome loss': 0.3180331269256499, 'Total loss': 0.3180331269256499}
2022-11-28 01:22:04,517 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:04,517 INFO:     Epoch: 47
2022-11-28 01:22:05,266 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43922834674065764, 'Total loss': 0.43922834674065764} | train loss {'Reaction outcome loss': 0.31640472424476734, 'Total loss': 0.31640472424476734}
2022-11-28 01:22:05,266 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:05,266 INFO:     Epoch: 48
2022-11-28 01:22:06,015 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47054902726615017, 'Total loss': 0.47054902726615017} | train loss {'Reaction outcome loss': 0.3170279890660815, 'Total loss': 0.3170279890660815}
2022-11-28 01:22:06,015 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:06,015 INFO:     Epoch: 49
2022-11-28 01:22:06,764 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4436977742747827, 'Total loss': 0.4436977742747827} | train loss {'Reaction outcome loss': 0.32098971228850515, 'Total loss': 0.32098971228850515}
2022-11-28 01:22:06,765 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:06,765 INFO:     Epoch: 50
2022-11-28 01:22:07,511 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4264323047616265, 'Total loss': 0.4264323047616265} | train loss {'Reaction outcome loss': 0.3213914656174569, 'Total loss': 0.3213914656174569}
2022-11-28 01:22:07,511 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:07,511 INFO:     Epoch: 51
2022-11-28 01:22:08,258 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43484321338209236, 'Total loss': 0.43484321338209236} | train loss {'Reaction outcome loss': 0.316327287841905, 'Total loss': 0.316327287841905}
2022-11-28 01:22:08,258 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:08,258 INFO:     Epoch: 52
2022-11-28 01:22:09,001 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42290014756674116, 'Total loss': 0.42290014756674116} | train loss {'Reaction outcome loss': 0.3112163001045524, 'Total loss': 0.3112163001045524}
2022-11-28 01:22:09,001 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:09,001 INFO:     Epoch: 53
2022-11-28 01:22:09,744 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48192472010850906, 'Total loss': 0.48192472010850906} | train loss {'Reaction outcome loss': 0.3180168856402882, 'Total loss': 0.3180168856402882}
2022-11-28 01:22:09,744 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:09,744 INFO:     Epoch: 54
2022-11-28 01:22:10,488 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4857528500936248, 'Total loss': 0.4857528500936248} | train loss {'Reaction outcome loss': 0.3162656103463246, 'Total loss': 0.3162656103463246}
2022-11-28 01:22:10,488 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:10,488 INFO:     Epoch: 55
2022-11-28 01:22:11,238 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45496486872434616, 'Total loss': 0.45496486872434616} | train loss {'Reaction outcome loss': 0.31423122463238834, 'Total loss': 0.31423122463238834}
2022-11-28 01:22:11,239 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:11,239 INFO:     Epoch: 56
2022-11-28 01:22:11,990 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4581918819722804, 'Total loss': 0.4581918819722804} | train loss {'Reaction outcome loss': 0.3135711931385975, 'Total loss': 0.3135711931385975}
2022-11-28 01:22:11,990 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:11,991 INFO:     Epoch: 57
2022-11-28 01:22:12,741 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4415891962972554, 'Total loss': 0.4415891962972554} | train loss {'Reaction outcome loss': 0.35113575288399995, 'Total loss': 0.35113575288399995}
2022-11-28 01:22:12,742 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:12,742 INFO:     Epoch: 58
2022-11-28 01:22:13,489 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45402628691359, 'Total loss': 0.45402628691359} | train loss {'Reaction outcome loss': 0.34221461023155014, 'Total loss': 0.34221461023155014}
2022-11-28 01:22:13,490 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:13,490 INFO:     Epoch: 59
2022-11-28 01:22:14,241 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4191102356734601, 'Total loss': 0.4191102356734601} | train loss {'Reaction outcome loss': 0.34297073146833584, 'Total loss': 0.34297073146833584}
2022-11-28 01:22:14,241 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:14,241 INFO:     Epoch: 60
2022-11-28 01:22:14,989 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.430116821419109, 'Total loss': 0.430116821419109} | train loss {'Reaction outcome loss': 0.33447412936853976, 'Total loss': 0.33447412936853976}
2022-11-28 01:22:14,989 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:14,989 INFO:     Epoch: 61
2022-11-28 01:22:15,739 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4845581562681632, 'Total loss': 0.4845581562681632} | train loss {'Reaction outcome loss': 0.32740919237677385, 'Total loss': 0.32740919237677385}
2022-11-28 01:22:15,740 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:15,740 INFO:     Epoch: 62
2022-11-28 01:22:16,492 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4479630271142179, 'Total loss': 0.4479630271142179} | train loss {'Reaction outcome loss': 0.3204780364765405, 'Total loss': 0.3204780364765405}
2022-11-28 01:22:16,492 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:16,492 INFO:     Epoch: 63
2022-11-28 01:22:17,241 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4772240661761977, 'Total loss': 0.4772240661761977} | train loss {'Reaction outcome loss': 0.3131751361404836, 'Total loss': 0.3131751361404836}
2022-11-28 01:22:17,241 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:17,241 INFO:     Epoch: 64
2022-11-28 01:22:17,989 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4446512372656302, 'Total loss': 0.4446512372656302} | train loss {'Reaction outcome loss': 0.3220225177433809, 'Total loss': 0.3220225177433809}
2022-11-28 01:22:17,989 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:17,990 INFO:     Epoch: 65
2022-11-28 01:22:18,736 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4208309894258326, 'Total loss': 0.4208309894258326} | train loss {'Reaction outcome loss': 0.31986342512282284, 'Total loss': 0.31986342512282284}
2022-11-28 01:22:18,736 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:18,736 INFO:     Epoch: 66
2022-11-28 01:22:19,484 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4428612928498875, 'Total loss': 0.4428612928498875} | train loss {'Reaction outcome loss': 0.3302061446020493, 'Total loss': 0.3302061446020493}
2022-11-28 01:22:19,484 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:19,484 INFO:     Epoch: 67
2022-11-28 01:22:20,233 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4453015908260237, 'Total loss': 0.4453015908260237} | train loss {'Reaction outcome loss': 0.31323112994724667, 'Total loss': 0.31323112994724667}
2022-11-28 01:22:20,233 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:20,233 INFO:     Epoch: 68
2022-11-28 01:22:20,982 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.462238196791573, 'Total loss': 0.462238196791573} | train loss {'Reaction outcome loss': 0.30457953360640566, 'Total loss': 0.30457953360640566}
2022-11-28 01:22:20,982 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:20,982 INFO:     Epoch: 69
2022-11-28 01:22:21,737 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.430465710603378, 'Total loss': 0.430465710603378} | train loss {'Reaction outcome loss': 0.3159881652547763, 'Total loss': 0.3159881652547763}
2022-11-28 01:22:21,737 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:21,737 INFO:     Epoch: 70
2022-11-28 01:22:22,485 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46117184175686404, 'Total loss': 0.46117184175686404} | train loss {'Reaction outcome loss': 0.30818479980232744, 'Total loss': 0.30818479980232744}
2022-11-28 01:22:22,485 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:22,485 INFO:     Epoch: 71
2022-11-28 01:22:23,232 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4451798891479319, 'Total loss': 0.4451798891479319} | train loss {'Reaction outcome loss': 0.30784243444166515, 'Total loss': 0.30784243444166515}
2022-11-28 01:22:23,233 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:23,233 INFO:     Epoch: 72
2022-11-28 01:22:23,985 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45860652794892137, 'Total loss': 0.45860652794892137} | train loss {'Reaction outcome loss': 0.31904750825603484, 'Total loss': 0.31904750825603484}
2022-11-28 01:22:23,985 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:23,985 INFO:     Epoch: 73
2022-11-28 01:22:24,733 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4529936235736717, 'Total loss': 0.4529936235736717} | train loss {'Reaction outcome loss': 0.3485667594531287, 'Total loss': 0.3485667594531287}
2022-11-28 01:22:24,733 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:24,733 INFO:     Epoch: 74
2022-11-28 01:22:25,483 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4614813039925965, 'Total loss': 0.4614813039925965} | train loss {'Reaction outcome loss': 0.32959235317793933, 'Total loss': 0.32959235317793933}
2022-11-28 01:22:25,483 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:25,483 INFO:     Epoch: 75
2022-11-28 01:22:26,233 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42029761319810693, 'Total loss': 0.42029761319810693} | train loss {'Reaction outcome loss': 0.32769453507444635, 'Total loss': 0.32769453507444635}
2022-11-28 01:22:26,234 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:26,234 INFO:     Epoch: 76
2022-11-28 01:22:26,978 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42254663563587447, 'Total loss': 0.42254663563587447} | train loss {'Reaction outcome loss': 0.3151267929047889, 'Total loss': 0.3151267929047889}
2022-11-28 01:22:26,978 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:26,979 INFO:     Epoch: 77
2022-11-28 01:22:27,725 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42472464963793755, 'Total loss': 0.42472464963793755} | train loss {'Reaction outcome loss': 0.30689299570562445, 'Total loss': 0.30689299570562445}
2022-11-28 01:22:27,725 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:27,725 INFO:     Epoch: 78
2022-11-28 01:22:28,474 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4212882620367137, 'Total loss': 0.4212882620367137} | train loss {'Reaction outcome loss': 0.30866097998091296, 'Total loss': 0.30866097998091296}
2022-11-28 01:22:28,474 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:28,474 INFO:     Epoch: 79
2022-11-28 01:22:29,223 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45582893389192497, 'Total loss': 0.45582893389192497} | train loss {'Reaction outcome loss': 0.3137489971572812, 'Total loss': 0.3137489971572812}
2022-11-28 01:22:29,223 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:29,223 INFO:     Epoch: 80
2022-11-28 01:22:29,971 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4465378014878793, 'Total loss': 0.4465378014878793} | train loss {'Reaction outcome loss': 0.3099517117326076, 'Total loss': 0.3099517117326076}
2022-11-28 01:22:29,972 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:29,972 INFO:     Epoch: 81
2022-11-28 01:22:30,721 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4321995245462114, 'Total loss': 0.4321995245462114} | train loss {'Reaction outcome loss': 0.33195849750963935, 'Total loss': 0.33195849750963935}
2022-11-28 01:22:30,722 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:30,722 INFO:     Epoch: 82
2022-11-28 01:22:31,472 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43354411829601636, 'Total loss': 0.43354411829601636} | train loss {'Reaction outcome loss': 0.3227043995852413, 'Total loss': 0.3227043995852413}
2022-11-28 01:22:31,472 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:31,472 INFO:     Epoch: 83
2022-11-28 01:22:32,219 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4541334685954181, 'Total loss': 0.4541334685954181} | train loss {'Reaction outcome loss': 0.3361203888385709, 'Total loss': 0.3361203888385709}
2022-11-28 01:22:32,219 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:32,219 INFO:     Epoch: 84
2022-11-28 01:22:32,969 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44470187750729645, 'Total loss': 0.44470187750729645} | train loss {'Reaction outcome loss': 0.3155645033314462, 'Total loss': 0.3155645033314462}
2022-11-28 01:22:32,970 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:32,970 INFO:     Epoch: 85
2022-11-28 01:22:33,716 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4422834095629779, 'Total loss': 0.4422834095629779} | train loss {'Reaction outcome loss': 0.30435398335640246, 'Total loss': 0.30435398335640246}
2022-11-28 01:22:33,716 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:33,717 INFO:     Epoch: 86
2022-11-28 01:22:34,464 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45572157271883706, 'Total loss': 0.45572157271883706} | train loss {'Reaction outcome loss': 0.31499685461704546, 'Total loss': 0.31499685461704546}
2022-11-28 01:22:34,464 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:34,464 INFO:     Epoch: 87
2022-11-28 01:22:35,220 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43190688504414126, 'Total loss': 0.43190688504414126} | train loss {'Reaction outcome loss': 0.3207362938808043, 'Total loss': 0.3207362938808043}
2022-11-28 01:22:35,220 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:35,220 INFO:     Epoch: 88
2022-11-28 01:22:35,970 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4394597624513236, 'Total loss': 0.4394597624513236} | train loss {'Reaction outcome loss': 0.3288007688770817, 'Total loss': 0.3288007688770817}
2022-11-28 01:22:35,971 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:35,971 INFO:     Epoch: 89
2022-11-28 01:22:36,725 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41575650024143135, 'Total loss': 0.41575650024143135} | train loss {'Reaction outcome loss': 0.3067905781488971, 'Total loss': 0.3067905781488971}
2022-11-28 01:22:36,725 INFO:     Found new best model at epoch 89
2022-11-28 01:22:36,726 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:36,726 INFO:     Epoch: 90
2022-11-28 01:22:37,474 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4348518665541302, 'Total loss': 0.4348518665541302} | train loss {'Reaction outcome loss': 0.30801905518178996, 'Total loss': 0.30801905518178996}
2022-11-28 01:22:37,474 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:37,475 INFO:     Epoch: 91
2022-11-28 01:22:38,225 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44103288531980733, 'Total loss': 0.44103288531980733} | train loss {'Reaction outcome loss': 0.32533742101421875, 'Total loss': 0.32533742101421875}
2022-11-28 01:22:38,225 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:38,225 INFO:     Epoch: 92
2022-11-28 01:22:38,974 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42189697159284895, 'Total loss': 0.42189697159284895} | train loss {'Reaction outcome loss': 0.3099606680359879, 'Total loss': 0.3099606680359879}
2022-11-28 01:22:38,974 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:38,974 INFO:     Epoch: 93
2022-11-28 01:22:39,724 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42440895295955916, 'Total loss': 0.42440895295955916} | train loss {'Reaction outcome loss': 0.3110970290988563, 'Total loss': 0.3110970290988563}
2022-11-28 01:22:39,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:39,724 INFO:     Epoch: 94
2022-11-28 01:22:40,471 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.438581933690743, 'Total loss': 0.438581933690743} | train loss {'Reaction outcome loss': 0.32191585919061894, 'Total loss': 0.32191585919061894}
2022-11-28 01:22:40,471 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:40,471 INFO:     Epoch: 95
2022-11-28 01:22:41,221 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4603096649728038, 'Total loss': 0.4603096649728038} | train loss {'Reaction outcome loss': 0.3101486246052541, 'Total loss': 0.3101486246052541}
2022-11-28 01:22:41,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:41,221 INFO:     Epoch: 96
2022-11-28 01:22:41,970 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42659574950283224, 'Total loss': 0.42659574950283224} | train loss {'Reaction outcome loss': 0.316625618349444, 'Total loss': 0.316625618349444}
2022-11-28 01:22:41,971 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:41,971 INFO:     Epoch: 97
2022-11-28 01:22:42,721 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43756985444236884, 'Total loss': 0.43756985444236884} | train loss {'Reaction outcome loss': 0.318055951467768, 'Total loss': 0.318055951467768}
2022-11-28 01:22:42,721 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:42,721 INFO:     Epoch: 98
2022-11-28 01:22:43,471 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42932071909308434, 'Total loss': 0.42932071909308434} | train loss {'Reaction outcome loss': 0.3138902945677761, 'Total loss': 0.3138902945677761}
2022-11-28 01:22:43,471 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:43,471 INFO:     Epoch: 99
2022-11-28 01:22:44,225 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4460452532565052, 'Total loss': 0.4460452532565052} | train loss {'Reaction outcome loss': 0.31013825860511707, 'Total loss': 0.31013825860511707}
2022-11-28 01:22:44,225 INFO:     Best model found after epoch 90 of 100.
2022-11-28 01:22:44,225 INFO:   Done with stage: TRAINING
2022-11-28 01:22:44,226 INFO:   Starting stage: EVALUATION
2022-11-28 01:22:44,346 INFO:   Done with stage: EVALUATION
2022-11-28 01:22:44,347 INFO:   Leaving out SEQ value Fold_5
2022-11-28 01:22:44,359 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 01:22:44,359 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:22:45,012 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:22:45,012 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:22:45,083 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:22:45,083 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:22:45,083 INFO:     No hyperparam tuning for this model
2022-11-28 01:22:45,083 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:22:45,084 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:22:45,084 INFO:     None feature selector for col prot
2022-11-28 01:22:45,084 INFO:     None feature selector for col prot
2022-11-28 01:22:45,084 INFO:     None feature selector for col prot
2022-11-28 01:22:45,085 INFO:     None feature selector for col chem
2022-11-28 01:22:45,085 INFO:     None feature selector for col chem
2022-11-28 01:22:45,085 INFO:     None feature selector for col chem
2022-11-28 01:22:45,085 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:22:45,085 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:22:45,087 INFO:     Number of params in model 169741
2022-11-28 01:22:45,090 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:22:45,090 INFO:   Starting stage: TRAINING
2022-11-28 01:22:45,144 INFO:     Val loss before train {'Reaction outcome loss': 0.9894211495464499, 'Total loss': 0.9894211495464499}
2022-11-28 01:22:45,144 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:45,144 INFO:     Epoch: 0
2022-11-28 01:22:45,901 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5733364620669321, 'Total loss': 0.5733364620669321} | train loss {'Reaction outcome loss': 0.6428182983110028, 'Total loss': 0.6428182983110028}
2022-11-28 01:22:45,901 INFO:     Found new best model at epoch 0
2022-11-28 01:22:45,901 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:45,902 INFO:     Epoch: 1
2022-11-28 01:22:46,656 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5234742984175682, 'Total loss': 0.5234742984175682} | train loss {'Reaction outcome loss': 0.5114016648261778, 'Total loss': 0.5114016648261778}
2022-11-28 01:22:46,657 INFO:     Found new best model at epoch 1
2022-11-28 01:22:46,657 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:46,657 INFO:     Epoch: 2
2022-11-28 01:22:47,414 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48979873074726626, 'Total loss': 0.48979873074726626} | train loss {'Reaction outcome loss': 0.4642713580641054, 'Total loss': 0.4642713580641054}
2022-11-28 01:22:47,414 INFO:     Found new best model at epoch 2
2022-11-28 01:22:47,415 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:47,415 INFO:     Epoch: 3
2022-11-28 01:22:48,169 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4806652993641116, 'Total loss': 0.4806652993641116} | train loss {'Reaction outcome loss': 0.4484606421883068, 'Total loss': 0.4484606421883068}
2022-11-28 01:22:48,169 INFO:     Found new best model at epoch 3
2022-11-28 01:22:48,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:48,170 INFO:     Epoch: 4
2022-11-28 01:22:48,925 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47771521928635513, 'Total loss': 0.47771521928635513} | train loss {'Reaction outcome loss': 0.4217519643566301, 'Total loss': 0.4217519643566301}
2022-11-28 01:22:48,925 INFO:     Found new best model at epoch 4
2022-11-28 01:22:48,926 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:48,926 INFO:     Epoch: 5
2022-11-28 01:22:49,682 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49048764597285877, 'Total loss': 0.49048764597285877} | train loss {'Reaction outcome loss': 0.41709424675472323, 'Total loss': 0.41709424675472323}
2022-11-28 01:22:49,682 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:49,682 INFO:     Epoch: 6
2022-11-28 01:22:50,436 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4714489758692004, 'Total loss': 0.4714489758692004} | train loss {'Reaction outcome loss': 0.4019121118190308, 'Total loss': 0.4019121118190308}
2022-11-28 01:22:50,436 INFO:     Found new best model at epoch 6
2022-11-28 01:22:50,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:50,437 INFO:     Epoch: 7
2022-11-28 01:22:51,191 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48069652779535815, 'Total loss': 0.48069652779535815} | train loss {'Reaction outcome loss': 0.39771643392140826, 'Total loss': 0.39771643392140826}
2022-11-28 01:22:51,191 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:51,191 INFO:     Epoch: 8
2022-11-28 01:22:51,944 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4684923599389466, 'Total loss': 0.4684923599389466} | train loss {'Reaction outcome loss': 0.3904055744229305, 'Total loss': 0.3904055744229305}
2022-11-28 01:22:51,945 INFO:     Found new best model at epoch 8
2022-11-28 01:22:51,945 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:51,945 INFO:     Epoch: 9
2022-11-28 01:22:52,699 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4928296928040006, 'Total loss': 0.4928296928040006} | train loss {'Reaction outcome loss': 0.3830655755835675, 'Total loss': 0.3830655755835675}
2022-11-28 01:22:52,699 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:52,699 INFO:     Epoch: 10
2022-11-28 01:22:53,452 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4445960765535181, 'Total loss': 0.4445960765535181} | train loss {'Reaction outcome loss': 0.37565833714700514, 'Total loss': 0.37565833714700514}
2022-11-28 01:22:53,452 INFO:     Found new best model at epoch 10
2022-11-28 01:22:53,452 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:53,453 INFO:     Epoch: 11
2022-11-28 01:22:54,206 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4751709963787686, 'Total loss': 0.4751709963787686} | train loss {'Reaction outcome loss': 0.3785268780625155, 'Total loss': 0.3785268780625155}
2022-11-28 01:22:54,207 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:54,207 INFO:     Epoch: 12
2022-11-28 01:22:54,964 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4589299874549562, 'Total loss': 0.4589299874549562} | train loss {'Reaction outcome loss': 0.3811180249096886, 'Total loss': 0.3811180249096886}
2022-11-28 01:22:54,964 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:54,964 INFO:     Epoch: 13
2022-11-28 01:22:55,728 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45379977029832924, 'Total loss': 0.45379977029832924} | train loss {'Reaction outcome loss': 0.3708603240309223, 'Total loss': 0.3708603240309223}
2022-11-28 01:22:55,728 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:55,729 INFO:     Epoch: 14
2022-11-28 01:22:56,483 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47023808041756804, 'Total loss': 0.47023808041756804} | train loss {'Reaction outcome loss': 0.36028532037932065, 'Total loss': 0.36028532037932065}
2022-11-28 01:22:56,483 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:56,484 INFO:     Epoch: 15
2022-11-28 01:22:57,241 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44702026806771755, 'Total loss': 0.44702026806771755} | train loss {'Reaction outcome loss': 0.35711801169259894, 'Total loss': 0.35711801169259894}
2022-11-28 01:22:57,241 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:57,241 INFO:     Epoch: 16
2022-11-28 01:22:58,005 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4356347339397127, 'Total loss': 0.4356347339397127} | train loss {'Reaction outcome loss': 0.3589742801062042, 'Total loss': 0.3589742801062042}
2022-11-28 01:22:58,005 INFO:     Found new best model at epoch 16
2022-11-28 01:22:58,006 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:58,006 INFO:     Epoch: 17
2022-11-28 01:22:58,762 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4366146463223479, 'Total loss': 0.4366146463223479} | train loss {'Reaction outcome loss': 0.35512337172704356, 'Total loss': 0.35512337172704356}
2022-11-28 01:22:58,762 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:58,763 INFO:     Epoch: 18
2022-11-28 01:22:59,520 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4424716637215831, 'Total loss': 0.4424716637215831} | train loss {'Reaction outcome loss': 0.35505607458312183, 'Total loss': 0.35505607458312183}
2022-11-28 01:22:59,521 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:22:59,521 INFO:     Epoch: 19
2022-11-28 01:23:00,275 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4513880332762545, 'Total loss': 0.4513880332762545} | train loss {'Reaction outcome loss': 0.34794568156282746, 'Total loss': 0.34794568156282746}
2022-11-28 01:23:00,275 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:00,276 INFO:     Epoch: 20
2022-11-28 01:23:01,026 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4511791772463105, 'Total loss': 0.4511791772463105} | train loss {'Reaction outcome loss': 0.33975746894195197, 'Total loss': 0.33975746894195197}
2022-11-28 01:23:01,026 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:01,026 INFO:     Epoch: 21
2022-11-28 01:23:01,782 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42329461059787055, 'Total loss': 0.42329461059787055} | train loss {'Reaction outcome loss': 0.34122395665655214, 'Total loss': 0.34122395665655214}
2022-11-28 01:23:01,782 INFO:     Found new best model at epoch 21
2022-11-28 01:23:01,783 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:01,783 INFO:     Epoch: 22
2022-11-28 01:23:02,542 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44987706061113963, 'Total loss': 0.44987706061113963} | train loss {'Reaction outcome loss': 0.3388227197161365, 'Total loss': 0.3388227197161365}
2022-11-28 01:23:02,542 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:02,542 INFO:     Epoch: 23
2022-11-28 01:23:03,296 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4674091400070624, 'Total loss': 0.4674091400070624} | train loss {'Reaction outcome loss': 0.33311965331555377, 'Total loss': 0.33311965331555377}
2022-11-28 01:23:03,297 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:03,297 INFO:     Epoch: 24
2022-11-28 01:23:04,054 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4389985589818521, 'Total loss': 0.4389985589818521} | train loss {'Reaction outcome loss': 0.32978097508631404, 'Total loss': 0.32978097508631404}
2022-11-28 01:23:04,054 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:04,054 INFO:     Epoch: 25
2022-11-28 01:23:04,806 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43511637672781944, 'Total loss': 0.43511637672781944} | train loss {'Reaction outcome loss': 0.33098799332736, 'Total loss': 0.33098799332736}
2022-11-28 01:23:04,806 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:04,806 INFO:     Epoch: 26
2022-11-28 01:23:05,558 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4262346625328064, 'Total loss': 0.4262346625328064} | train loss {'Reaction outcome loss': 0.3346909227210187, 'Total loss': 0.3346909227210187}
2022-11-28 01:23:05,559 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:05,559 INFO:     Epoch: 27
2022-11-28 01:23:06,309 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4349169951270927, 'Total loss': 0.4349169951270927} | train loss {'Reaction outcome loss': 0.3350638245502787, 'Total loss': 0.3350638245502787}
2022-11-28 01:23:06,309 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:06,310 INFO:     Epoch: 28
2022-11-28 01:23:07,063 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43408183177763765, 'Total loss': 0.43408183177763765} | train loss {'Reaction outcome loss': 0.33362414504611687, 'Total loss': 0.33362414504611687}
2022-11-28 01:23:07,063 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:07,063 INFO:     Epoch: 29
2022-11-28 01:23:07,818 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40918353250758216, 'Total loss': 0.40918353250758216} | train loss {'Reaction outcome loss': 0.33153655884727357, 'Total loss': 0.33153655884727357}
2022-11-28 01:23:07,818 INFO:     Found new best model at epoch 29
2022-11-28 01:23:07,819 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:07,819 INFO:     Epoch: 30
2022-11-28 01:23:08,572 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41773187775503506, 'Total loss': 0.41773187775503506} | train loss {'Reaction outcome loss': 0.32676189089374197, 'Total loss': 0.32676189089374197}
2022-11-28 01:23:08,572 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:08,572 INFO:     Epoch: 31
2022-11-28 01:23:09,326 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4170797084542838, 'Total loss': 0.4170797084542838} | train loss {'Reaction outcome loss': 0.318794181765688, 'Total loss': 0.318794181765688}
2022-11-28 01:23:09,327 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:09,327 INFO:     Epoch: 32
2022-11-28 01:23:10,079 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4040852375328541, 'Total loss': 0.4040852375328541} | train loss {'Reaction outcome loss': 0.3316863367273923, 'Total loss': 0.3316863367273923}
2022-11-28 01:23:10,079 INFO:     Found new best model at epoch 32
2022-11-28 01:23:10,080 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:10,080 INFO:     Epoch: 33
2022-11-28 01:23:10,832 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4276400086554614, 'Total loss': 0.4276400086554614} | train loss {'Reaction outcome loss': 0.32400883034232164, 'Total loss': 0.32400883034232164}
2022-11-28 01:23:10,832 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:10,832 INFO:     Epoch: 34
2022-11-28 01:23:11,587 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4309590721333569, 'Total loss': 0.4309590721333569} | train loss {'Reaction outcome loss': 0.3190994592263333, 'Total loss': 0.3190994592263333}
2022-11-28 01:23:11,587 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:11,587 INFO:     Epoch: 35
2022-11-28 01:23:12,343 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.432971422306516, 'Total loss': 0.432971422306516} | train loss {'Reaction outcome loss': 0.32379624549479735, 'Total loss': 0.32379624549479735}
2022-11-28 01:23:12,344 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:12,344 INFO:     Epoch: 36
2022-11-28 01:23:13,094 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4410601564767686, 'Total loss': 0.4410601564767686} | train loss {'Reaction outcome loss': 0.32761501935460874, 'Total loss': 0.32761501935460874}
2022-11-28 01:23:13,095 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:13,095 INFO:     Epoch: 37
2022-11-28 01:23:13,851 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4389866893603043, 'Total loss': 0.4389866893603043} | train loss {'Reaction outcome loss': 0.3210134255669771, 'Total loss': 0.3210134255669771}
2022-11-28 01:23:13,851 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:13,851 INFO:     Epoch: 38
2022-11-28 01:23:14,603 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42645002190362324, 'Total loss': 0.42645002190362324} | train loss {'Reaction outcome loss': 0.32052311502517233, 'Total loss': 0.32052311502517233}
2022-11-28 01:23:14,604 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:14,604 INFO:     Epoch: 39
2022-11-28 01:23:15,358 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4568193615837531, 'Total loss': 0.4568193615837531} | train loss {'Reaction outcome loss': 0.32664808970425396, 'Total loss': 0.32664808970425396}
2022-11-28 01:23:15,358 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:15,358 INFO:     Epoch: 40
2022-11-28 01:23:16,111 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44266097484664485, 'Total loss': 0.44266097484664485} | train loss {'Reaction outcome loss': 0.31433235029239326, 'Total loss': 0.31433235029239326}
2022-11-28 01:23:16,111 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:16,111 INFO:     Epoch: 41
2022-11-28 01:23:16,863 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4665846949951215, 'Total loss': 0.4665846949951215} | train loss {'Reaction outcome loss': 0.3245492959995904, 'Total loss': 0.3245492959995904}
2022-11-28 01:23:16,863 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:16,864 INFO:     Epoch: 42
2022-11-28 01:23:17,618 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4165877090259032, 'Total loss': 0.4165877090259032} | train loss {'Reaction outcome loss': 0.3263120139017701, 'Total loss': 0.3263120139017701}
2022-11-28 01:23:17,618 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:17,618 INFO:     Epoch: 43
2022-11-28 01:23:18,374 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4093198468062011, 'Total loss': 0.4093198468062011} | train loss {'Reaction outcome loss': 0.3203858175585347, 'Total loss': 0.3203858175585347}
2022-11-28 01:23:18,374 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:18,374 INFO:     Epoch: 44
2022-11-28 01:23:19,128 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42669007927179337, 'Total loss': 0.42669007927179337} | train loss {'Reaction outcome loss': 0.31159252569740337, 'Total loss': 0.31159252569740337}
2022-11-28 01:23:19,128 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:19,129 INFO:     Epoch: 45
2022-11-28 01:23:19,878 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4047600935128602, 'Total loss': 0.4047600935128602} | train loss {'Reaction outcome loss': 0.31924411768634475, 'Total loss': 0.31924411768634475}
2022-11-28 01:23:19,878 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:19,878 INFO:     Epoch: 46
2022-11-28 01:23:20,630 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47242513637651096, 'Total loss': 0.47242513637651096} | train loss {'Reaction outcome loss': 0.31373982035344644, 'Total loss': 0.31373982035344644}
2022-11-28 01:23:20,630 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:20,630 INFO:     Epoch: 47
2022-11-28 01:23:21,382 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45479803972623567, 'Total loss': 0.45479803972623567} | train loss {'Reaction outcome loss': 0.3183363519548889, 'Total loss': 0.3183363519548889}
2022-11-28 01:23:21,382 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:21,382 INFO:     Epoch: 48
2022-11-28 01:23:22,135 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4506099213930694, 'Total loss': 0.4506099213930694} | train loss {'Reaction outcome loss': 0.3185538649859448, 'Total loss': 0.3185538649859448}
2022-11-28 01:23:22,135 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:22,135 INFO:     Epoch: 49
2022-11-28 01:23:22,889 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4202555065805262, 'Total loss': 0.4202555065805262} | train loss {'Reaction outcome loss': 0.31888806707255785, 'Total loss': 0.31888806707255785}
2022-11-28 01:23:22,889 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:22,889 INFO:     Epoch: 50
2022-11-28 01:23:23,643 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46197868333282793, 'Total loss': 0.46197868333282793} | train loss {'Reaction outcome loss': 0.3107495443715203, 'Total loss': 0.3107495443715203}
2022-11-28 01:23:23,643 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:23,643 INFO:     Epoch: 51
2022-11-28 01:23:24,397 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4257707514546134, 'Total loss': 0.4257707514546134} | train loss {'Reaction outcome loss': 0.31439139237326963, 'Total loss': 0.31439139237326963}
2022-11-28 01:23:24,397 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:24,398 INFO:     Epoch: 52
2022-11-28 01:23:25,152 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42125124230303546, 'Total loss': 0.42125124230303546} | train loss {'Reaction outcome loss': 0.31993148680175504, 'Total loss': 0.31993148680175504}
2022-11-28 01:23:25,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:25,153 INFO:     Epoch: 53
2022-11-28 01:23:25,906 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44393774968656624, 'Total loss': 0.44393774968656624} | train loss {'Reaction outcome loss': 0.3141322151247051, 'Total loss': 0.3141322151247051}
2022-11-28 01:23:25,906 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:25,906 INFO:     Epoch: 54
2022-11-28 01:23:26,662 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4477637931704521, 'Total loss': 0.4477637931704521} | train loss {'Reaction outcome loss': 0.31538503438294413, 'Total loss': 0.31538503438294413}
2022-11-28 01:23:26,663 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:26,663 INFO:     Epoch: 55
2022-11-28 01:23:27,422 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4475026640363715, 'Total loss': 0.4475026640363715} | train loss {'Reaction outcome loss': 0.31527348094049, 'Total loss': 0.31527348094049}
2022-11-28 01:23:27,422 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:27,422 INFO:     Epoch: 56
2022-11-28 01:23:28,179 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4303292486477982, 'Total loss': 0.4303292486477982} | train loss {'Reaction outcome loss': 0.31779791024183074, 'Total loss': 0.31779791024183074}
2022-11-28 01:23:28,179 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:28,179 INFO:     Epoch: 57
2022-11-28 01:23:28,933 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46420565247535706, 'Total loss': 0.46420565247535706} | train loss {'Reaction outcome loss': 0.3252442446687529, 'Total loss': 0.3252442446687529}
2022-11-28 01:23:28,933 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:28,933 INFO:     Epoch: 58
2022-11-28 01:23:29,687 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41592738641933963, 'Total loss': 0.41592738641933963} | train loss {'Reaction outcome loss': 0.3187913118501104, 'Total loss': 0.3187913118501104}
2022-11-28 01:23:29,687 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:29,687 INFO:     Epoch: 59
2022-11-28 01:23:30,440 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4497634074227376, 'Total loss': 0.4497634074227376} | train loss {'Reaction outcome loss': 0.307577091809963, 'Total loss': 0.307577091809963}
2022-11-28 01:23:30,440 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:30,440 INFO:     Epoch: 60
2022-11-28 01:23:31,192 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42896331677382643, 'Total loss': 0.42896331677382643} | train loss {'Reaction outcome loss': 0.31739712296234024, 'Total loss': 0.31739712296234024}
2022-11-28 01:23:31,192 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:31,193 INFO:     Epoch: 61
2022-11-28 01:23:31,948 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4181455732746558, 'Total loss': 0.4181455732746558} | train loss {'Reaction outcome loss': 0.3224019549126106, 'Total loss': 0.3224019549126106}
2022-11-28 01:23:31,948 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:31,948 INFO:     Epoch: 62
2022-11-28 01:23:32,701 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.49918207187544217, 'Total loss': 0.49918207187544217} | train loss {'Reaction outcome loss': 0.3092117524976211, 'Total loss': 0.3092117524976211}
2022-11-28 01:23:32,701 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:32,701 INFO:     Epoch: 63
2022-11-28 01:23:33,456 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4543606246059591, 'Total loss': 0.4543606246059591} | train loss {'Reaction outcome loss': 0.3243166416763298, 'Total loss': 0.3243166416763298}
2022-11-28 01:23:33,456 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:33,456 INFO:     Epoch: 64
2022-11-28 01:23:34,209 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4462315802547065, 'Total loss': 0.4462315802547065} | train loss {'Reaction outcome loss': 0.31548987653466964, 'Total loss': 0.31548987653466964}
2022-11-28 01:23:34,210 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:34,210 INFO:     Epoch: 65
2022-11-28 01:23:34,969 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40706744349815627, 'Total loss': 0.40706744349815627} | train loss {'Reaction outcome loss': 0.3028054785343908, 'Total loss': 0.3028054785343908}
2022-11-28 01:23:34,969 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:34,970 INFO:     Epoch: 66
2022-11-28 01:23:35,724 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4377893151884729, 'Total loss': 0.4377893151884729} | train loss {'Reaction outcome loss': 0.31180948232330624, 'Total loss': 0.31180948232330624}
2022-11-28 01:23:35,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:35,724 INFO:     Epoch: 67
2022-11-28 01:23:36,479 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4286405486478047, 'Total loss': 0.4286405486478047} | train loss {'Reaction outcome loss': 0.314526523463428, 'Total loss': 0.314526523463428}
2022-11-28 01:23:36,479 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:36,480 INFO:     Epoch: 68
2022-11-28 01:23:37,235 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43605081195181067, 'Total loss': 0.43605081195181067} | train loss {'Reaction outcome loss': 0.3087737052851627, 'Total loss': 0.3087737052851627}
2022-11-28 01:23:37,235 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:37,235 INFO:     Epoch: 69
2022-11-28 01:23:37,990 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.417086574672298, 'Total loss': 0.417086574672298} | train loss {'Reaction outcome loss': 0.31541073544611853, 'Total loss': 0.31541073544611853}
2022-11-28 01:23:37,991 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:37,991 INFO:     Epoch: 70
2022-11-28 01:23:38,745 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.422385191375559, 'Total loss': 0.422385191375559} | train loss {'Reaction outcome loss': 0.3042775933750935, 'Total loss': 0.3042775933750935}
2022-11-28 01:23:38,745 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:38,745 INFO:     Epoch: 71
2022-11-28 01:23:39,501 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4149950427765196, 'Total loss': 0.4149950427765196} | train loss {'Reaction outcome loss': 0.3074571409773442, 'Total loss': 0.3074571409773442}
2022-11-28 01:23:39,502 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:39,502 INFO:     Epoch: 72
2022-11-28 01:23:40,255 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43880627338181843, 'Total loss': 0.43880627338181843} | train loss {'Reaction outcome loss': 0.2952141024532818, 'Total loss': 0.2952141024532818}
2022-11-28 01:23:40,255 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:40,255 INFO:     Epoch: 73
2022-11-28 01:23:41,006 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43663702837445517, 'Total loss': 0.43663702837445517} | train loss {'Reaction outcome loss': 0.3114327091964022, 'Total loss': 0.3114327091964022}
2022-11-28 01:23:41,007 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:41,007 INFO:     Epoch: 74
2022-11-28 01:23:41,767 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4662166393615983, 'Total loss': 0.4662166393615983} | train loss {'Reaction outcome loss': 0.3111947230814445, 'Total loss': 0.3111947230814445}
2022-11-28 01:23:41,767 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:41,767 INFO:     Epoch: 75
2022-11-28 01:23:42,526 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.436908289112828, 'Total loss': 0.436908289112828} | train loss {'Reaction outcome loss': 0.31112755016393717, 'Total loss': 0.31112755016393717}
2022-11-28 01:23:42,526 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:42,526 INFO:     Epoch: 76
2022-11-28 01:23:43,282 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4375894266096028, 'Total loss': 0.4375894266096028} | train loss {'Reaction outcome loss': 0.30674464061796186, 'Total loss': 0.30674464061796186}
2022-11-28 01:23:43,283 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:43,283 INFO:     Epoch: 77
2022-11-28 01:23:44,046 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4318495077843016, 'Total loss': 0.4318495077843016} | train loss {'Reaction outcome loss': 0.3047210006644168, 'Total loss': 0.3047210006644168}
2022-11-28 01:23:44,046 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:44,046 INFO:     Epoch: 78
2022-11-28 01:23:44,801 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4675488278947093, 'Total loss': 0.4675488278947093} | train loss {'Reaction outcome loss': 0.30913913529366255, 'Total loss': 0.30913913529366255}
2022-11-28 01:23:44,801 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:44,801 INFO:     Epoch: 79
2022-11-28 01:23:45,559 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.420434025878256, 'Total loss': 0.420434025878256} | train loss {'Reaction outcome loss': 0.3115742224899511, 'Total loss': 0.3115742224899511}
2022-11-28 01:23:45,559 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:45,559 INFO:     Epoch: 80
2022-11-28 01:23:46,310 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41709056665951555, 'Total loss': 0.41709056665951555} | train loss {'Reaction outcome loss': 0.30509498982780403, 'Total loss': 0.30509498982780403}
2022-11-28 01:23:46,310 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:46,310 INFO:     Epoch: 81
2022-11-28 01:23:47,068 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48494626649401407, 'Total loss': 0.48494626649401407} | train loss {'Reaction outcome loss': 0.30911704011621977, 'Total loss': 0.30911704011621977}
2022-11-28 01:23:47,068 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:47,068 INFO:     Epoch: 82
2022-11-28 01:23:47,823 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4118580852042545, 'Total loss': 0.4118580852042545} | train loss {'Reaction outcome loss': 0.3149098062046593, 'Total loss': 0.3149098062046593}
2022-11-28 01:23:47,823 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:47,823 INFO:     Epoch: 83
2022-11-28 01:23:48,582 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4394957646727562, 'Total loss': 0.4394957646727562} | train loss {'Reaction outcome loss': 0.3075329793557044, 'Total loss': 0.3075329793557044}
2022-11-28 01:23:48,582 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:48,582 INFO:     Epoch: 84
2022-11-28 01:23:49,336 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4281934025612744, 'Total loss': 0.4281934025612744} | train loss {'Reaction outcome loss': 0.3111312353923436, 'Total loss': 0.3111312353923436}
2022-11-28 01:23:49,336 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:49,336 INFO:     Epoch: 85
2022-11-28 01:23:50,088 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44932784072377463, 'Total loss': 0.44932784072377463} | train loss {'Reaction outcome loss': 0.3065329923504783, 'Total loss': 0.3065329923504783}
2022-11-28 01:23:50,088 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:50,088 INFO:     Epoch: 86
2022-11-28 01:23:50,841 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.425529347224669, 'Total loss': 0.425529347224669} | train loss {'Reaction outcome loss': 0.30482467158787674, 'Total loss': 0.30482467158787674}
2022-11-28 01:23:50,841 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:50,841 INFO:     Epoch: 87
2022-11-28 01:23:51,593 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4364970424635844, 'Total loss': 0.4364970424635844} | train loss {'Reaction outcome loss': 0.3051255958815736, 'Total loss': 0.3051255958815736}
2022-11-28 01:23:51,593 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:51,593 INFO:     Epoch: 88
2022-11-28 01:23:52,342 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44749554856257007, 'Total loss': 0.44749554856257007} | train loss {'Reaction outcome loss': 0.29865037380237014, 'Total loss': 0.29865037380237014}
2022-11-28 01:23:52,342 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:52,342 INFO:     Epoch: 89
2022-11-28 01:23:53,091 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4322020612995733, 'Total loss': 0.4322020612995733} | train loss {'Reaction outcome loss': 0.31297720492547076, 'Total loss': 0.31297720492547076}
2022-11-28 01:23:53,091 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:53,091 INFO:     Epoch: 90
2022-11-28 01:23:53,836 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41078425639054994, 'Total loss': 0.41078425639054994} | train loss {'Reaction outcome loss': 0.30237697757359955, 'Total loss': 0.30237697757359955}
2022-11-28 01:23:53,836 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:53,836 INFO:     Epoch: 91
2022-11-28 01:23:54,581 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44303850998932665, 'Total loss': 0.44303850998932665} | train loss {'Reaction outcome loss': 0.3015155956870125, 'Total loss': 0.3015155956870125}
2022-11-28 01:23:54,581 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:54,581 INFO:     Epoch: 92
2022-11-28 01:23:55,324 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44239771213721146, 'Total loss': 0.44239771213721146} | train loss {'Reaction outcome loss': 0.31319406009729833, 'Total loss': 0.31319406009729833}
2022-11-28 01:23:55,325 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:55,325 INFO:     Epoch: 93
2022-11-28 01:23:56,069 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4151391801847653, 'Total loss': 0.4151391801847653} | train loss {'Reaction outcome loss': 0.30383657447753415, 'Total loss': 0.30383657447753415}
2022-11-28 01:23:56,070 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:56,070 INFO:     Epoch: 94
2022-11-28 01:23:56,814 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41871446320279077, 'Total loss': 0.41871446320279077} | train loss {'Reaction outcome loss': 0.307938966209129, 'Total loss': 0.307938966209129}
2022-11-28 01:23:56,814 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:56,815 INFO:     Epoch: 95
2022-11-28 01:23:57,559 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4127012321894819, 'Total loss': 0.4127012321894819} | train loss {'Reaction outcome loss': 0.3045696055426473, 'Total loss': 0.3045696055426473}
2022-11-28 01:23:57,559 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:57,560 INFO:     Epoch: 96
2022-11-28 01:23:58,305 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4292760205201127, 'Total loss': 0.4292760205201127} | train loss {'Reaction outcome loss': 0.3165296486038114, 'Total loss': 0.3165296486038114}
2022-11-28 01:23:58,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:58,305 INFO:     Epoch: 97
2022-11-28 01:23:59,056 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42849845642393286, 'Total loss': 0.42849845642393286} | train loss {'Reaction outcome loss': 0.3028566789242529, 'Total loss': 0.3028566789242529}
2022-11-28 01:23:59,056 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:59,056 INFO:     Epoch: 98
2022-11-28 01:23:59,801 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4104436266828667, 'Total loss': 0.4104436266828667} | train loss {'Reaction outcome loss': 0.2973113033860441, 'Total loss': 0.2973113033860441}
2022-11-28 01:23:59,801 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:23:59,801 INFO:     Epoch: 99
2022-11-28 01:24:00,547 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4513868455859748, 'Total loss': 0.4513868455859748} | train loss {'Reaction outcome loss': 0.31051110965950834, 'Total loss': 0.31051110965950834}
2022-11-28 01:24:00,548 INFO:     Best model found after epoch 33 of 100.
2022-11-28 01:24:00,548 INFO:   Done with stage: TRAINING
2022-11-28 01:24:00,548 INFO:   Starting stage: EVALUATION
2022-11-28 01:24:00,662 INFO:   Done with stage: EVALUATION
2022-11-28 01:24:00,662 INFO:   Leaving out SEQ value Fold_6
2022-11-28 01:24:00,675 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 01:24:00,675 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:24:01,315 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:24:01,315 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:24:01,386 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:24:01,386 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:24:01,386 INFO:     No hyperparam tuning for this model
2022-11-28 01:24:01,386 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:24:01,386 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:24:01,387 INFO:     None feature selector for col prot
2022-11-28 01:24:01,387 INFO:     None feature selector for col prot
2022-11-28 01:24:01,387 INFO:     None feature selector for col prot
2022-11-28 01:24:01,387 INFO:     None feature selector for col chem
2022-11-28 01:24:01,388 INFO:     None feature selector for col chem
2022-11-28 01:24:01,388 INFO:     None feature selector for col chem
2022-11-28 01:24:01,388 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:24:01,388 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:24:01,389 INFO:     Number of params in model 169741
2022-11-28 01:24:01,392 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:24:01,392 INFO:   Starting stage: TRAINING
2022-11-28 01:24:01,446 INFO:     Val loss before train {'Reaction outcome loss': 1.0244026251814582, 'Total loss': 1.0244026251814582}
2022-11-28 01:24:01,446 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:01,446 INFO:     Epoch: 0
2022-11-28 01:24:02,188 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5918193696574732, 'Total loss': 0.5918193696574732} | train loss {'Reaction outcome loss': 0.6352126653860455, 'Total loss': 0.6352126653860455}
2022-11-28 01:24:02,188 INFO:     Found new best model at epoch 0
2022-11-28 01:24:02,189 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:02,189 INFO:     Epoch: 1
2022-11-28 01:24:02,928 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5260412716730074, 'Total loss': 0.5260412716730074} | train loss {'Reaction outcome loss': 0.5037528702363312, 'Total loss': 0.5037528702363312}
2022-11-28 01:24:02,928 INFO:     Found new best model at epoch 1
2022-11-28 01:24:02,929 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:02,929 INFO:     Epoch: 2
2022-11-28 01:24:03,669 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4608682492239909, 'Total loss': 0.4608682492239909} | train loss {'Reaction outcome loss': 0.4571029743564274, 'Total loss': 0.4571029743564274}
2022-11-28 01:24:03,670 INFO:     Found new best model at epoch 2
2022-11-28 01:24:03,670 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:03,670 INFO:     Epoch: 3
2022-11-28 01:24:04,414 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5201498540964994, 'Total loss': 0.5201498540964994} | train loss {'Reaction outcome loss': 0.4240324367365615, 'Total loss': 0.4240324367365615}
2022-11-28 01:24:04,414 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:04,414 INFO:     Epoch: 4
2022-11-28 01:24:05,156 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4525450302118605, 'Total loss': 0.4525450302118605} | train loss {'Reaction outcome loss': 0.41739517363610296, 'Total loss': 0.41739517363610296}
2022-11-28 01:24:05,156 INFO:     Found new best model at epoch 4
2022-11-28 01:24:05,156 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:05,157 INFO:     Epoch: 5
2022-11-28 01:24:05,897 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45336476442488755, 'Total loss': 0.45336476442488755} | train loss {'Reaction outcome loss': 0.4087506301610576, 'Total loss': 0.4087506301610576}
2022-11-28 01:24:05,898 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:05,898 INFO:     Epoch: 6
2022-11-28 01:24:06,641 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4546309272673997, 'Total loss': 0.4546309272673997} | train loss {'Reaction outcome loss': 0.40503007924629125, 'Total loss': 0.40503007924629125}
2022-11-28 01:24:06,641 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:06,641 INFO:     Epoch: 7
2022-11-28 01:24:07,384 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4196404255926609, 'Total loss': 0.4196404255926609} | train loss {'Reaction outcome loss': 0.4021702167476237, 'Total loss': 0.4021702167476237}
2022-11-28 01:24:07,384 INFO:     Found new best model at epoch 7
2022-11-28 01:24:07,385 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:07,385 INFO:     Epoch: 8
2022-11-28 01:24:08,127 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44234153628349304, 'Total loss': 0.44234153628349304} | train loss {'Reaction outcome loss': 0.37988317959945694, 'Total loss': 0.37988317959945694}
2022-11-28 01:24:08,128 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:08,128 INFO:     Epoch: 9
2022-11-28 01:24:08,869 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41093014468523587, 'Total loss': 0.41093014468523587} | train loss {'Reaction outcome loss': 0.38577436981534186, 'Total loss': 0.38577436981534186}
2022-11-28 01:24:08,869 INFO:     Found new best model at epoch 9
2022-11-28 01:24:08,870 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:08,870 INFO:     Epoch: 10
2022-11-28 01:24:09,612 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.442660201002251, 'Total loss': 0.442660201002251} | train loss {'Reaction outcome loss': 0.377501272871668, 'Total loss': 0.377501272871668}
2022-11-28 01:24:09,612 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:09,612 INFO:     Epoch: 11
2022-11-28 01:24:10,356 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5123671963810921, 'Total loss': 0.5123671963810921} | train loss {'Reaction outcome loss': 0.3646658361863028, 'Total loss': 0.3646658361863028}
2022-11-28 01:24:10,357 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:10,357 INFO:     Epoch: 12
2022-11-28 01:24:11,103 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41394409842111846, 'Total loss': 0.41394409842111846} | train loss {'Reaction outcome loss': 0.3722177508026965, 'Total loss': 0.3722177508026965}
2022-11-28 01:24:11,103 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:11,103 INFO:     Epoch: 13
2022-11-28 01:24:11,846 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43213055113499815, 'Total loss': 0.43213055113499815} | train loss {'Reaction outcome loss': 0.3592871831567875, 'Total loss': 0.3592871831567875}
2022-11-28 01:24:11,846 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:11,846 INFO:     Epoch: 14
2022-11-28 01:24:12,588 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42294789071787486, 'Total loss': 0.42294789071787486} | train loss {'Reaction outcome loss': 0.350067332537792, 'Total loss': 0.350067332537792}
2022-11-28 01:24:12,588 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:12,588 INFO:     Epoch: 15
2022-11-28 01:24:13,331 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43137747658924624, 'Total loss': 0.43137747658924624} | train loss {'Reaction outcome loss': 0.3598676272460565, 'Total loss': 0.3598676272460565}
2022-11-28 01:24:13,331 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:13,331 INFO:     Epoch: 16
2022-11-28 01:24:14,075 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45043489133769815, 'Total loss': 0.45043489133769815} | train loss {'Reaction outcome loss': 0.39077502431777805, 'Total loss': 0.39077502431777805}
2022-11-28 01:24:14,075 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:14,075 INFO:     Epoch: 17
2022-11-28 01:24:14,820 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4309843663464893, 'Total loss': 0.4309843663464893} | train loss {'Reaction outcome loss': 0.35845008294705133, 'Total loss': 0.35845008294705133}
2022-11-28 01:24:14,821 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:14,821 INFO:     Epoch: 18
2022-11-28 01:24:15,568 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42273738844828174, 'Total loss': 0.42273738844828174} | train loss {'Reaction outcome loss': 0.34600908018889937, 'Total loss': 0.34600908018889937}
2022-11-28 01:24:15,568 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:15,568 INFO:     Epoch: 19
2022-11-28 01:24:16,314 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4380140964957801, 'Total loss': 0.4380140964957801} | train loss {'Reaction outcome loss': 0.34778958361460127, 'Total loss': 0.34778958361460127}
2022-11-28 01:24:16,314 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:16,314 INFO:     Epoch: 20
2022-11-28 01:24:17,064 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4808279313147068, 'Total loss': 0.4808279313147068} | train loss {'Reaction outcome loss': 0.34680968194234707, 'Total loss': 0.34680968194234707}
2022-11-28 01:24:17,064 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:17,064 INFO:     Epoch: 21
2022-11-28 01:24:17,805 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4039061123674566, 'Total loss': 0.4039061123674566} | train loss {'Reaction outcome loss': 0.34884672032797387, 'Total loss': 0.34884672032797387}
2022-11-28 01:24:17,805 INFO:     Found new best model at epoch 21
2022-11-28 01:24:17,806 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:17,806 INFO:     Epoch: 22
2022-11-28 01:24:18,549 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4419508222490549, 'Total loss': 0.4419508222490549} | train loss {'Reaction outcome loss': 0.3494251209654306, 'Total loss': 0.3494251209654306}
2022-11-28 01:24:18,550 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:18,550 INFO:     Epoch: 23
2022-11-28 01:24:19,295 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4047539569437504, 'Total loss': 0.4047539569437504} | train loss {'Reaction outcome loss': 0.3489892273605895, 'Total loss': 0.3489892273605895}
2022-11-28 01:24:19,295 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:19,295 INFO:     Epoch: 24
2022-11-28 01:24:20,038 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42701486362652347, 'Total loss': 0.42701486362652347} | train loss {'Reaction outcome loss': 0.3382324164635257, 'Total loss': 0.3382324164635257}
2022-11-28 01:24:20,038 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:20,038 INFO:     Epoch: 25
2022-11-28 01:24:20,782 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4150597673248161, 'Total loss': 0.4150597673248161} | train loss {'Reaction outcome loss': 0.3404466122754582, 'Total loss': 0.3404466122754582}
2022-11-28 01:24:20,782 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:20,782 INFO:     Epoch: 26
2022-11-28 01:24:21,525 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43789862553504383, 'Total loss': 0.43789862553504383} | train loss {'Reaction outcome loss': 0.33538978688630017, 'Total loss': 0.33538978688630017}
2022-11-28 01:24:21,526 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:21,526 INFO:     Epoch: 27
2022-11-28 01:24:22,267 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4126584692434831, 'Total loss': 0.4126584692434831} | train loss {'Reaction outcome loss': 0.3340472432705555, 'Total loss': 0.3340472432705555}
2022-11-28 01:24:22,267 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:22,267 INFO:     Epoch: 28
2022-11-28 01:24:23,013 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.395072590559721, 'Total loss': 0.395072590559721} | train loss {'Reaction outcome loss': 0.3394069696968866, 'Total loss': 0.3394069696968866}
2022-11-28 01:24:23,013 INFO:     Found new best model at epoch 28
2022-11-28 01:24:23,014 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:23,014 INFO:     Epoch: 29
2022-11-28 01:24:23,762 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41396786678921094, 'Total loss': 0.41396786678921094} | train loss {'Reaction outcome loss': 0.330624663974215, 'Total loss': 0.330624663974215}
2022-11-28 01:24:23,762 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:23,763 INFO:     Epoch: 30
2022-11-28 01:24:24,505 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39651650664481247, 'Total loss': 0.39651650664481247} | train loss {'Reaction outcome loss': 0.32069449809941686, 'Total loss': 0.32069449809941686}
2022-11-28 01:24:24,505 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:24,505 INFO:     Epoch: 31
2022-11-28 01:24:25,248 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41731771352616226, 'Total loss': 0.41731771352616226} | train loss {'Reaction outcome loss': 0.3251531289716964, 'Total loss': 0.3251531289716964}
2022-11-28 01:24:25,248 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:25,248 INFO:     Epoch: 32
2022-11-28 01:24:25,991 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41585158285769547, 'Total loss': 0.41585158285769547} | train loss {'Reaction outcome loss': 0.34095721954276204, 'Total loss': 0.34095721954276204}
2022-11-28 01:24:25,992 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:25,992 INFO:     Epoch: 33
2022-11-28 01:24:26,735 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4077671966092153, 'Total loss': 0.4077671966092153} | train loss {'Reaction outcome loss': 0.3367116947315241, 'Total loss': 0.3367116947315241}
2022-11-28 01:24:26,736 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:26,737 INFO:     Epoch: 34
2022-11-28 01:24:27,477 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4076806259426204, 'Total loss': 0.4076806259426204} | train loss {'Reaction outcome loss': 0.32044882434401434, 'Total loss': 0.32044882434401434}
2022-11-28 01:24:27,477 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:27,477 INFO:     Epoch: 35
2022-11-28 01:24:28,219 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42128547094762325, 'Total loss': 0.42128547094762325} | train loss {'Reaction outcome loss': 0.31520458506910426, 'Total loss': 0.31520458506910426}
2022-11-28 01:24:28,219 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:28,219 INFO:     Epoch: 36
2022-11-28 01:24:28,963 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45277606628157874, 'Total loss': 0.45277606628157874} | train loss {'Reaction outcome loss': 0.35242577384297663, 'Total loss': 0.35242577384297663}
2022-11-28 01:24:28,963 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:28,963 INFO:     Epoch: 37
2022-11-28 01:24:29,707 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39214665070176125, 'Total loss': 0.39214665070176125} | train loss {'Reaction outcome loss': 0.32470068451665673, 'Total loss': 0.32470068451665673}
2022-11-28 01:24:29,707 INFO:     Found new best model at epoch 37
2022-11-28 01:24:29,708 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:29,708 INFO:     Epoch: 38
2022-11-28 01:24:30,449 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43196476420218294, 'Total loss': 0.43196476420218294} | train loss {'Reaction outcome loss': 0.32221560234482954, 'Total loss': 0.32221560234482954}
2022-11-28 01:24:30,449 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:30,449 INFO:     Epoch: 39
2022-11-28 01:24:31,189 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4284165906296535, 'Total loss': 0.4284165906296535} | train loss {'Reaction outcome loss': 0.3453984464469709, 'Total loss': 0.3453984464469709}
2022-11-28 01:24:31,189 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:31,189 INFO:     Epoch: 40
2022-11-28 01:24:31,932 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39598788422617043, 'Total loss': 0.39598788422617043} | train loss {'Reaction outcome loss': 0.3238905212476186, 'Total loss': 0.3238905212476186}
2022-11-28 01:24:31,932 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:31,932 INFO:     Epoch: 41
2022-11-28 01:24:32,673 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4176985577426173, 'Total loss': 0.4176985577426173} | train loss {'Reaction outcome loss': 0.3106482368611131, 'Total loss': 0.3106482368611131}
2022-11-28 01:24:32,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:32,673 INFO:     Epoch: 42
2022-11-28 01:24:33,413 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40839459120549937, 'Total loss': 0.40839459120549937} | train loss {'Reaction outcome loss': 0.30725486489080706, 'Total loss': 0.30725486489080706}
2022-11-28 01:24:33,414 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:33,414 INFO:     Epoch: 43
2022-11-28 01:24:34,153 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4164272787218744, 'Total loss': 0.4164272787218744} | train loss {'Reaction outcome loss': 0.31341095826765786, 'Total loss': 0.31341095826765786}
2022-11-28 01:24:34,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:34,153 INFO:     Epoch: 44
2022-11-28 01:24:34,897 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41139829480512574, 'Total loss': 0.41139829480512574} | train loss {'Reaction outcome loss': 0.31351271428559957, 'Total loss': 0.31351271428559957}
2022-11-28 01:24:34,897 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:34,897 INFO:     Epoch: 45
2022-11-28 01:24:35,637 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40767617659135297, 'Total loss': 0.40767617659135297} | train loss {'Reaction outcome loss': 0.3250346305640603, 'Total loss': 0.3250346305640603}
2022-11-28 01:24:35,637 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:35,637 INFO:     Epoch: 46
2022-11-28 01:24:36,375 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.410235856236382, 'Total loss': 0.410235856236382} | train loss {'Reaction outcome loss': 0.3355120190905656, 'Total loss': 0.3355120190905656}
2022-11-28 01:24:36,375 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:36,375 INFO:     Epoch: 47
2022-11-28 01:24:37,116 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4031836502254009, 'Total loss': 0.4031836502254009} | train loss {'Reaction outcome loss': 0.3234564664694462, 'Total loss': 0.3234564664694462}
2022-11-28 01:24:37,116 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:37,116 INFO:     Epoch: 48
2022-11-28 01:24:37,857 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4112969098443335, 'Total loss': 0.4112969098443335} | train loss {'Reaction outcome loss': 0.33213900521337264, 'Total loss': 0.33213900521337264}
2022-11-28 01:24:37,857 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:37,857 INFO:     Epoch: 49
2022-11-28 01:24:38,598 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39611242745410313, 'Total loss': 0.39611242745410313} | train loss {'Reaction outcome loss': 0.3157149969867849, 'Total loss': 0.3157149969867849}
2022-11-28 01:24:38,598 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:38,598 INFO:     Epoch: 50
2022-11-28 01:24:39,339 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.410185405137864, 'Total loss': 0.410185405137864} | train loss {'Reaction outcome loss': 0.31865769902221586, 'Total loss': 0.31865769902221586}
2022-11-28 01:24:39,340 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:39,340 INFO:     Epoch: 51
2022-11-28 01:24:40,081 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41585690900683403, 'Total loss': 0.41585690900683403} | train loss {'Reaction outcome loss': 0.3178369080730778, 'Total loss': 0.3178369080730778}
2022-11-28 01:24:40,081 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:40,081 INFO:     Epoch: 52
2022-11-28 01:24:40,824 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4041687609119849, 'Total loss': 0.4041687609119849} | train loss {'Reaction outcome loss': 0.314494971122177, 'Total loss': 0.314494971122177}
2022-11-28 01:24:40,824 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:40,824 INFO:     Epoch: 53
2022-11-28 01:24:41,571 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41033386676148936, 'Total loss': 0.41033386676148936} | train loss {'Reaction outcome loss': 0.30719312784160197, 'Total loss': 0.30719312784160197}
2022-11-28 01:24:41,571 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:41,571 INFO:     Epoch: 54
2022-11-28 01:24:42,317 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43981267274780705, 'Total loss': 0.43981267274780705} | train loss {'Reaction outcome loss': 0.3122908095056229, 'Total loss': 0.3122908095056229}
2022-11-28 01:24:42,317 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:42,317 INFO:     Epoch: 55
2022-11-28 01:24:43,062 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4263305271213705, 'Total loss': 0.4263305271213705} | train loss {'Reaction outcome loss': 0.3235235987645894, 'Total loss': 0.3235235987645894}
2022-11-28 01:24:43,062 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:43,062 INFO:     Epoch: 56
2022-11-28 01:24:43,802 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4456909231164239, 'Total loss': 0.4456909231164239} | train loss {'Reaction outcome loss': 0.3505425051699283, 'Total loss': 0.3505425051699283}
2022-11-28 01:24:43,802 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:43,802 INFO:     Epoch: 57
2022-11-28 01:24:44,542 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42441806332631543, 'Total loss': 0.42441806332631543} | train loss {'Reaction outcome loss': 0.3138427645390333, 'Total loss': 0.3138427645390333}
2022-11-28 01:24:44,542 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:44,542 INFO:     Epoch: 58
2022-11-28 01:24:45,281 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41599294103004714, 'Total loss': 0.41599294103004714} | train loss {'Reaction outcome loss': 0.3151509487013585, 'Total loss': 0.3151509487013585}
2022-11-28 01:24:45,281 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:45,281 INFO:     Epoch: 59
2022-11-28 01:24:46,022 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43669893965125084, 'Total loss': 0.43669893965125084} | train loss {'Reaction outcome loss': 0.31257922881045325, 'Total loss': 0.31257922881045325}
2022-11-28 01:24:46,023 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:46,023 INFO:     Epoch: 60
2022-11-28 01:24:46,763 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41704687526957557, 'Total loss': 0.41704687526957557} | train loss {'Reaction outcome loss': 0.3025570122378045, 'Total loss': 0.3025570122378045}
2022-11-28 01:24:46,763 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:46,763 INFO:     Epoch: 61
2022-11-28 01:24:47,505 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39889924160458823, 'Total loss': 0.39889924160458823} | train loss {'Reaction outcome loss': 0.30788956676055546, 'Total loss': 0.30788956676055546}
2022-11-28 01:24:47,505 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:47,505 INFO:     Epoch: 62
2022-11-28 01:24:48,250 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4138667238029567, 'Total loss': 0.4138667238029567} | train loss {'Reaction outcome loss': 0.29991584265159693, 'Total loss': 0.29991584265159693}
2022-11-28 01:24:48,250 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:48,250 INFO:     Epoch: 63
2022-11-28 01:24:48,993 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40602126548236067, 'Total loss': 0.40602126548236067} | train loss {'Reaction outcome loss': 0.31572410823241903, 'Total loss': 0.31572410823241903}
2022-11-28 01:24:48,994 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:48,994 INFO:     Epoch: 64
2022-11-28 01:24:49,738 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.403244644572789, 'Total loss': 0.403244644572789} | train loss {'Reaction outcome loss': 0.32242803927133923, 'Total loss': 0.32242803927133923}
2022-11-28 01:24:49,738 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:49,739 INFO:     Epoch: 65
2022-11-28 01:24:50,483 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41100442003120075, 'Total loss': 0.41100442003120075} | train loss {'Reaction outcome loss': 0.30444855311273233, 'Total loss': 0.30444855311273233}
2022-11-28 01:24:50,484 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:50,484 INFO:     Epoch: 66
2022-11-28 01:24:51,225 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4011656530201435, 'Total loss': 0.4011656530201435} | train loss {'Reaction outcome loss': 0.3070558710740163, 'Total loss': 0.3070558710740163}
2022-11-28 01:24:51,225 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:51,225 INFO:     Epoch: 67
2022-11-28 01:24:51,966 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39924006079408253, 'Total loss': 0.39924006079408253} | train loss {'Reaction outcome loss': 0.3231870371683737, 'Total loss': 0.3231870371683737}
2022-11-28 01:24:51,966 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:51,966 INFO:     Epoch: 68
2022-11-28 01:24:52,706 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41146718490530143, 'Total loss': 0.41146718490530143} | train loss {'Reaction outcome loss': 0.3115413869061976, 'Total loss': 0.3115413869061976}
2022-11-28 01:24:52,706 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:52,706 INFO:     Epoch: 69
2022-11-28 01:24:53,449 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4024313817816702, 'Total loss': 0.4024313817816702} | train loss {'Reaction outcome loss': 0.3044665489602185, 'Total loss': 0.3044665489602185}
2022-11-28 01:24:53,449 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:53,449 INFO:     Epoch: 70
2022-11-28 01:24:54,193 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4330856664614244, 'Total loss': 0.4330856664614244} | train loss {'Reaction outcome loss': 0.31296619205822346, 'Total loss': 0.31296619205822346}
2022-11-28 01:24:54,193 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:54,193 INFO:     Epoch: 71
2022-11-28 01:24:54,939 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40805634212764824, 'Total loss': 0.40805634212764824} | train loss {'Reaction outcome loss': 0.31017018270184876, 'Total loss': 0.31017018270184876}
2022-11-28 01:24:54,939 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:54,939 INFO:     Epoch: 72
2022-11-28 01:24:55,682 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3928658134219321, 'Total loss': 0.3928658134219321} | train loss {'Reaction outcome loss': 0.3064705971223095, 'Total loss': 0.3064705971223095}
2022-11-28 01:24:55,683 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:55,683 INFO:     Epoch: 73
2022-11-28 01:24:56,428 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41970645331523637, 'Total loss': 0.41970645331523637} | train loss {'Reaction outcome loss': 0.31113274684288966, 'Total loss': 0.31113274684288966}
2022-11-28 01:24:56,428 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:56,428 INFO:     Epoch: 74
2022-11-28 01:24:57,170 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43034387854012573, 'Total loss': 0.43034387854012573} | train loss {'Reaction outcome loss': 0.31145375442167045, 'Total loss': 0.31145375442167045}
2022-11-28 01:24:57,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:57,171 INFO:     Epoch: 75
2022-11-28 01:24:57,916 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41717855395241216, 'Total loss': 0.41717855395241216} | train loss {'Reaction outcome loss': 0.33607435654773404, 'Total loss': 0.33607435654773404}
2022-11-28 01:24:57,917 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:57,917 INFO:     Epoch: 76
2022-11-28 01:24:58,661 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4394211301749403, 'Total loss': 0.4394211301749403} | train loss {'Reaction outcome loss': 0.31376648124548706, 'Total loss': 0.31376648124548706}
2022-11-28 01:24:58,661 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:58,661 INFO:     Epoch: 77
2022-11-28 01:24:59,407 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38702043518424034, 'Total loss': 0.38702043518424034} | train loss {'Reaction outcome loss': 0.30860732599851576, 'Total loss': 0.30860732599851576}
2022-11-28 01:24:59,407 INFO:     Found new best model at epoch 77
2022-11-28 01:24:59,408 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:24:59,408 INFO:     Epoch: 78
2022-11-28 01:25:00,153 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42076519842852245, 'Total loss': 0.42076519842852245} | train loss {'Reaction outcome loss': 0.32144342028057044, 'Total loss': 0.32144342028057044}
2022-11-28 01:25:00,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:00,153 INFO:     Epoch: 79
2022-11-28 01:25:00,895 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3976296426897699, 'Total loss': 0.3976296426897699} | train loss {'Reaction outcome loss': 0.2992080463631916, 'Total loss': 0.2992080463631916}
2022-11-28 01:25:00,895 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:00,895 INFO:     Epoch: 80
2022-11-28 01:25:01,640 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38819612901319156, 'Total loss': 0.38819612901319156} | train loss {'Reaction outcome loss': 0.30217994728431047, 'Total loss': 0.30217994728431047}
2022-11-28 01:25:01,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:01,640 INFO:     Epoch: 81
2022-11-28 01:25:02,381 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45015733587470924, 'Total loss': 0.45015733587470924} | train loss {'Reaction outcome loss': 0.321623274913201, 'Total loss': 0.321623274913201}
2022-11-28 01:25:02,381 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:02,381 INFO:     Epoch: 82
2022-11-28 01:25:03,128 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41117174889553676, 'Total loss': 0.41117174889553676} | train loss {'Reaction outcome loss': 0.32619515381119996, 'Total loss': 0.32619515381119996}
2022-11-28 01:25:03,128 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:03,128 INFO:     Epoch: 83
2022-11-28 01:25:03,877 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39659538729624316, 'Total loss': 0.39659538729624316} | train loss {'Reaction outcome loss': 0.30735127540373125, 'Total loss': 0.30735127540373125}
2022-11-28 01:25:03,878 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:03,878 INFO:     Epoch: 84
2022-11-28 01:25:04,625 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4114463508806445, 'Total loss': 0.4114463508806445} | train loss {'Reaction outcome loss': 0.30818189017633485, 'Total loss': 0.30818189017633485}
2022-11-28 01:25:04,626 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:04,626 INFO:     Epoch: 85
2022-11-28 01:25:05,375 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3883262278342789, 'Total loss': 0.3883262278342789} | train loss {'Reaction outcome loss': 0.30508995294450264, 'Total loss': 0.30508995294450264}
2022-11-28 01:25:05,375 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:05,375 INFO:     Epoch: 86
2022-11-28 01:25:06,120 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40827564150094986, 'Total loss': 0.40827564150094986} | train loss {'Reaction outcome loss': 0.31094303380260585, 'Total loss': 0.31094303380260585}
2022-11-28 01:25:06,120 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:06,120 INFO:     Epoch: 87
2022-11-28 01:25:06,865 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4009593423794616, 'Total loss': 0.4009593423794616} | train loss {'Reaction outcome loss': 0.31709660673777945, 'Total loss': 0.31709660673777945}
2022-11-28 01:25:06,865 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:06,865 INFO:     Epoch: 88
2022-11-28 01:25:07,608 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38484822044318373, 'Total loss': 0.38484822044318373} | train loss {'Reaction outcome loss': 0.31217626913597707, 'Total loss': 0.31217626913597707}
2022-11-28 01:25:07,608 INFO:     Found new best model at epoch 88
2022-11-28 01:25:07,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:07,609 INFO:     Epoch: 89
2022-11-28 01:25:08,356 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40367588062178006, 'Total loss': 0.40367588062178006} | train loss {'Reaction outcome loss': 0.3127453845024471, 'Total loss': 0.3127453845024471}
2022-11-28 01:25:08,356 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:08,356 INFO:     Epoch: 90
2022-11-28 01:25:09,101 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3779909275472164, 'Total loss': 0.3779909275472164} | train loss {'Reaction outcome loss': 0.3097387134184239, 'Total loss': 0.3097387134184239}
2022-11-28 01:25:09,101 INFO:     Found new best model at epoch 90
2022-11-28 01:25:09,102 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:09,102 INFO:     Epoch: 91
2022-11-28 01:25:09,848 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40271498466079886, 'Total loss': 0.40271498466079886} | train loss {'Reaction outcome loss': 0.31760950082807465, 'Total loss': 0.31760950082807465}
2022-11-28 01:25:09,848 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:09,848 INFO:     Epoch: 92
2022-11-28 01:25:10,595 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39631869017400523, 'Total loss': 0.39631869017400523} | train loss {'Reaction outcome loss': 0.29292554363065404, 'Total loss': 0.29292554363065404}
2022-11-28 01:25:10,596 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:10,596 INFO:     Epoch: 93
2022-11-28 01:25:11,342 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40754441036419436, 'Total loss': 0.40754441036419436} | train loss {'Reaction outcome loss': 0.30429639192939045, 'Total loss': 0.30429639192939045}
2022-11-28 01:25:11,343 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:11,343 INFO:     Epoch: 94
2022-11-28 01:25:12,092 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3891471234912222, 'Total loss': 0.3891471234912222} | train loss {'Reaction outcome loss': 0.3062447250975288, 'Total loss': 0.3062447250975288}
2022-11-28 01:25:12,092 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:12,092 INFO:     Epoch: 95
2022-11-28 01:25:12,838 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48429741405627946, 'Total loss': 0.48429741405627946} | train loss {'Reaction outcome loss': 0.31142170944435876, 'Total loss': 0.31142170944435876}
2022-11-28 01:25:12,838 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:12,839 INFO:     Epoch: 96
2022-11-28 01:25:13,585 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4186565703289075, 'Total loss': 0.4186565703289075} | train loss {'Reaction outcome loss': 0.312129808582275, 'Total loss': 0.312129808582275}
2022-11-28 01:25:13,585 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:13,586 INFO:     Epoch: 97
2022-11-28 01:25:14,331 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4321723207831383, 'Total loss': 0.4321723207831383} | train loss {'Reaction outcome loss': 0.30581726980685947, 'Total loss': 0.30581726980685947}
2022-11-28 01:25:14,331 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:14,332 INFO:     Epoch: 98
2022-11-28 01:25:15,081 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3951247734102336, 'Total loss': 0.3951247734102336} | train loss {'Reaction outcome loss': 0.31202774316917065, 'Total loss': 0.31202774316917065}
2022-11-28 01:25:15,081 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:15,081 INFO:     Epoch: 99
2022-11-28 01:25:15,826 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4116446460512551, 'Total loss': 0.4116446460512551} | train loss {'Reaction outcome loss': 0.312440304983, 'Total loss': 0.312440304983}
2022-11-28 01:25:15,826 INFO:     Best model found after epoch 91 of 100.
2022-11-28 01:25:15,826 INFO:   Done with stage: TRAINING
2022-11-28 01:25:15,826 INFO:   Starting stage: EVALUATION
2022-11-28 01:25:15,946 INFO:   Done with stage: EVALUATION
2022-11-28 01:25:15,947 INFO:   Leaving out SEQ value Fold_7
2022-11-28 01:25:15,959 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 01:25:15,960 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:25:16,597 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:25:16,597 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:25:16,667 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:25:16,668 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:25:16,668 INFO:     No hyperparam tuning for this model
2022-11-28 01:25:16,668 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:25:16,668 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:25:16,669 INFO:     None feature selector for col prot
2022-11-28 01:25:16,669 INFO:     None feature selector for col prot
2022-11-28 01:25:16,669 INFO:     None feature selector for col prot
2022-11-28 01:25:16,669 INFO:     None feature selector for col chem
2022-11-28 01:25:16,670 INFO:     None feature selector for col chem
2022-11-28 01:25:16,670 INFO:     None feature selector for col chem
2022-11-28 01:25:16,670 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:25:16,670 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:25:16,671 INFO:     Number of params in model 169741
2022-11-28 01:25:16,674 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:25:16,674 INFO:   Starting stage: TRAINING
2022-11-28 01:25:16,728 INFO:     Val loss before train {'Reaction outcome loss': 1.0569246316497976, 'Total loss': 1.0569246316497976}
2022-11-28 01:25:16,728 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:16,728 INFO:     Epoch: 0
2022-11-28 01:25:17,475 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.647193272005428, 'Total loss': 0.647193272005428} | train loss {'Reaction outcome loss': 0.6242670807157934, 'Total loss': 0.6242670807157934}
2022-11-28 01:25:17,475 INFO:     Found new best model at epoch 0
2022-11-28 01:25:17,476 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:17,476 INFO:     Epoch: 1
2022-11-28 01:25:18,219 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5175440379164435, 'Total loss': 0.5175440379164435} | train loss {'Reaction outcome loss': 0.5031818508920882, 'Total loss': 0.5031818508920882}
2022-11-28 01:25:18,219 INFO:     Found new best model at epoch 1
2022-11-28 01:25:18,220 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:18,220 INFO:     Epoch: 2
2022-11-28 01:25:18,965 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5600796619599516, 'Total loss': 0.5600796619599516} | train loss {'Reaction outcome loss': 0.45308205008748087, 'Total loss': 0.45308205008748087}
2022-11-28 01:25:18,965 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:18,965 INFO:     Epoch: 3
2022-11-28 01:25:19,709 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5133043602108955, 'Total loss': 0.5133043602108955} | train loss {'Reaction outcome loss': 0.4321505241548484, 'Total loss': 0.4321505241548484}
2022-11-28 01:25:19,710 INFO:     Found new best model at epoch 3
2022-11-28 01:25:19,710 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:19,710 INFO:     Epoch: 4
2022-11-28 01:25:20,453 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5175992162390188, 'Total loss': 0.5175992162390188} | train loss {'Reaction outcome loss': 0.4211783752991603, 'Total loss': 0.4211783752991603}
2022-11-28 01:25:20,453 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:20,453 INFO:     Epoch: 5
2022-11-28 01:25:21,198 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48959100077098067, 'Total loss': 0.48959100077098067} | train loss {'Reaction outcome loss': 0.42945232154869356, 'Total loss': 0.42945232154869356}
2022-11-28 01:25:21,198 INFO:     Found new best model at epoch 5
2022-11-28 01:25:21,199 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:21,199 INFO:     Epoch: 6
2022-11-28 01:25:21,949 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4826112799346447, 'Total loss': 0.4826112799346447} | train loss {'Reaction outcome loss': 0.4106566418520352, 'Total loss': 0.4106566418520352}
2022-11-28 01:25:21,949 INFO:     Found new best model at epoch 6
2022-11-28 01:25:21,950 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:21,950 INFO:     Epoch: 7
2022-11-28 01:25:22,697 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5393805280327797, 'Total loss': 0.5393805280327797} | train loss {'Reaction outcome loss': 0.3969474198062893, 'Total loss': 0.3969474198062893}
2022-11-28 01:25:22,697 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:22,697 INFO:     Epoch: 8
2022-11-28 01:25:23,436 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4671190540221604, 'Total loss': 0.4671190540221604} | train loss {'Reaction outcome loss': 0.38923549397211327, 'Total loss': 0.38923549397211327}
2022-11-28 01:25:23,436 INFO:     Found new best model at epoch 8
2022-11-28 01:25:23,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:23,437 INFO:     Epoch: 9
2022-11-28 01:25:24,177 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4865668988363309, 'Total loss': 0.4865668988363309} | train loss {'Reaction outcome loss': 0.37222817226460103, 'Total loss': 0.37222817226460103}
2022-11-28 01:25:24,177 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:24,177 INFO:     Epoch: 10
2022-11-28 01:25:24,921 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4755531207404353, 'Total loss': 0.4755531207404353} | train loss {'Reaction outcome loss': 0.3669463543123321, 'Total loss': 0.3669463543123321}
2022-11-28 01:25:24,921 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:24,921 INFO:     Epoch: 11
2022-11-28 01:25:25,666 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47200330245223915, 'Total loss': 0.47200330245223915} | train loss {'Reaction outcome loss': 0.3630917665929447, 'Total loss': 0.3630917665929447}
2022-11-28 01:25:25,669 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:25,669 INFO:     Epoch: 12
2022-11-28 01:25:26,418 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4604251750490882, 'Total loss': 0.4604251750490882} | train loss {'Reaction outcome loss': 0.3691666544950473, 'Total loss': 0.3691666544950473}
2022-11-28 01:25:26,418 INFO:     Found new best model at epoch 12
2022-11-28 01:25:26,419 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:26,419 INFO:     Epoch: 13
2022-11-28 01:25:27,160 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4595407694578171, 'Total loss': 0.4595407694578171} | train loss {'Reaction outcome loss': 0.35064706212354574, 'Total loss': 0.35064706212354574}
2022-11-28 01:25:27,160 INFO:     Found new best model at epoch 13
2022-11-28 01:25:27,161 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:27,161 INFO:     Epoch: 14
2022-11-28 01:25:27,907 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47100252319465985, 'Total loss': 0.47100252319465985} | train loss {'Reaction outcome loss': 0.362744346622996, 'Total loss': 0.362744346622996}
2022-11-28 01:25:27,907 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:27,907 INFO:     Epoch: 15
2022-11-28 01:25:28,658 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4523527341132814, 'Total loss': 0.4523527341132814} | train loss {'Reaction outcome loss': 0.36379654156534297, 'Total loss': 0.36379654156534297}
2022-11-28 01:25:28,658 INFO:     Found new best model at epoch 15
2022-11-28 01:25:28,659 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:28,659 INFO:     Epoch: 16
2022-11-28 01:25:29,404 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4530704089186408, 'Total loss': 0.4530704089186408} | train loss {'Reaction outcome loss': 0.34093824338718404, 'Total loss': 0.34093824338718404}
2022-11-28 01:25:29,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:29,406 INFO:     Epoch: 17
2022-11-28 01:25:30,148 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44584647159684787, 'Total loss': 0.44584647159684787} | train loss {'Reaction outcome loss': 0.342958188430983, 'Total loss': 0.342958188430983}
2022-11-28 01:25:30,148 INFO:     Found new best model at epoch 17
2022-11-28 01:25:30,149 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:30,149 INFO:     Epoch: 18
2022-11-28 01:25:30,894 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.442987169731747, 'Total loss': 0.442987169731747} | train loss {'Reaction outcome loss': 0.35676999884819693, 'Total loss': 0.35676999884819693}
2022-11-28 01:25:30,894 INFO:     Found new best model at epoch 18
2022-11-28 01:25:30,894 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:30,895 INFO:     Epoch: 19
2022-11-28 01:25:31,642 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4817242876372554, 'Total loss': 0.4817242876372554} | train loss {'Reaction outcome loss': 0.3369238490676168, 'Total loss': 0.3369238490676168}
2022-11-28 01:25:31,643 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:31,643 INFO:     Epoch: 20
2022-11-28 01:25:32,385 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4808273362842473, 'Total loss': 0.4808273362842473} | train loss {'Reaction outcome loss': 0.33172011320236017, 'Total loss': 0.33172011320236017}
2022-11-28 01:25:32,385 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:32,385 INFO:     Epoch: 21
2022-11-28 01:25:33,127 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45726866444403474, 'Total loss': 0.45726866444403474} | train loss {'Reaction outcome loss': 0.3326419696724608, 'Total loss': 0.3326419696724608}
2022-11-28 01:25:33,127 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:33,127 INFO:     Epoch: 22
2022-11-28 01:25:33,867 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4674313037910245, 'Total loss': 0.4674313037910245} | train loss {'Reaction outcome loss': 0.33465291161527516, 'Total loss': 0.33465291161527516}
2022-11-28 01:25:33,867 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:33,867 INFO:     Epoch: 23
2022-11-28 01:25:34,607 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4744694883173162, 'Total loss': 0.4744694883173162} | train loss {'Reaction outcome loss': 0.3390734462964873, 'Total loss': 0.3390734462964873}
2022-11-28 01:25:34,607 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:34,607 INFO:     Epoch: 24
2022-11-28 01:25:35,349 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4641235067763112, 'Total loss': 0.4641235067763112} | train loss {'Reaction outcome loss': 0.32721766328763385, 'Total loss': 0.32721766328763385}
2022-11-28 01:25:35,349 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:35,349 INFO:     Epoch: 25
2022-11-28 01:25:36,093 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4628844474526969, 'Total loss': 0.4628844474526969} | train loss {'Reaction outcome loss': 0.321971781956228, 'Total loss': 0.321971781956228}
2022-11-28 01:25:36,094 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:36,094 INFO:     Epoch: 26
2022-11-28 01:25:36,837 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4569205272604119, 'Total loss': 0.4569205272604119} | train loss {'Reaction outcome loss': 0.328396102194844, 'Total loss': 0.328396102194844}
2022-11-28 01:25:36,837 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:36,838 INFO:     Epoch: 27
2022-11-28 01:25:37,579 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44632596556435933, 'Total loss': 0.44632596556435933} | train loss {'Reaction outcome loss': 0.34419504187997385, 'Total loss': 0.34419504187997385}
2022-11-28 01:25:37,579 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:37,579 INFO:     Epoch: 28
2022-11-28 01:25:38,324 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47764514860781754, 'Total loss': 0.47764514860781754} | train loss {'Reaction outcome loss': 0.32292200652467695, 'Total loss': 0.32292200652467695}
2022-11-28 01:25:38,324 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:38,324 INFO:     Epoch: 29
2022-11-28 01:25:39,070 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4819757914678617, 'Total loss': 0.4819757914678617} | train loss {'Reaction outcome loss': 0.31957528691904746, 'Total loss': 0.31957528691904746}
2022-11-28 01:25:39,070 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:39,070 INFO:     Epoch: 30
2022-11-28 01:25:39,815 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4606154638935219, 'Total loss': 0.4606154638935219} | train loss {'Reaction outcome loss': 0.35120523288122074, 'Total loss': 0.35120523288122074}
2022-11-28 01:25:39,815 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:39,815 INFO:     Epoch: 31
2022-11-28 01:25:40,559 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4682488651438193, 'Total loss': 0.4682488651438193} | train loss {'Reaction outcome loss': 0.33165829720707074, 'Total loss': 0.33165829720707074}
2022-11-28 01:25:40,559 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:40,559 INFO:     Epoch: 32
2022-11-28 01:25:41,305 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47129985537718644, 'Total loss': 0.47129985537718644} | train loss {'Reaction outcome loss': 0.3366092723829159, 'Total loss': 0.3366092723829159}
2022-11-28 01:25:41,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:41,305 INFO:     Epoch: 33
2022-11-28 01:25:42,054 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43864717199043796, 'Total loss': 0.43864717199043796} | train loss {'Reaction outcome loss': 0.32110313963529613, 'Total loss': 0.32110313963529613}
2022-11-28 01:25:42,054 INFO:     Found new best model at epoch 33
2022-11-28 01:25:42,054 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:42,055 INFO:     Epoch: 34
2022-11-28 01:25:42,798 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42860217053781857, 'Total loss': 0.42860217053781857} | train loss {'Reaction outcome loss': 0.31078224088798695, 'Total loss': 0.31078224088798695}
2022-11-28 01:25:42,798 INFO:     Found new best model at epoch 34
2022-11-28 01:25:42,799 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:42,799 INFO:     Epoch: 35
2022-11-28 01:25:43,541 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4323745800012892, 'Total loss': 0.4323745800012892} | train loss {'Reaction outcome loss': 0.3288869587421749, 'Total loss': 0.3288869587421749}
2022-11-28 01:25:43,541 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:43,541 INFO:     Epoch: 36
2022-11-28 01:25:44,286 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4754367352209308, 'Total loss': 0.4754367352209308} | train loss {'Reaction outcome loss': 0.3155888160954603, 'Total loss': 0.3155888160954603}
2022-11-28 01:25:44,286 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:44,286 INFO:     Epoch: 37
2022-11-28 01:25:45,036 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46185829693620856, 'Total loss': 0.46185829693620856} | train loss {'Reaction outcome loss': 0.3210924779355285, 'Total loss': 0.3210924779355285}
2022-11-28 01:25:45,036 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:45,036 INFO:     Epoch: 38
2022-11-28 01:25:45,785 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45704002339731564, 'Total loss': 0.45704002339731564} | train loss {'Reaction outcome loss': 0.3297385415825842, 'Total loss': 0.3297385415825842}
2022-11-28 01:25:45,785 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:45,785 INFO:     Epoch: 39
2022-11-28 01:25:46,533 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4291594790464098, 'Total loss': 0.4291594790464098} | train loss {'Reaction outcome loss': 0.31186301308695363, 'Total loss': 0.31186301308695363}
2022-11-28 01:25:46,533 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:46,533 INFO:     Epoch: 40
2022-11-28 01:25:47,278 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4386738000268286, 'Total loss': 0.4386738000268286} | train loss {'Reaction outcome loss': 0.32495687947220164, 'Total loss': 0.32495687947220164}
2022-11-28 01:25:47,278 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:47,278 INFO:     Epoch: 41
2022-11-28 01:25:48,024 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45052581890062854, 'Total loss': 0.45052581890062854} | train loss {'Reaction outcome loss': 0.31329300201795846, 'Total loss': 0.31329300201795846}
2022-11-28 01:25:48,024 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:48,024 INFO:     Epoch: 42
2022-11-28 01:25:48,774 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45847000046209857, 'Total loss': 0.45847000046209857} | train loss {'Reaction outcome loss': 0.31532598720667393, 'Total loss': 0.31532598720667393}
2022-11-28 01:25:48,774 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:48,774 INFO:     Epoch: 43
2022-11-28 01:25:49,516 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4719295325604352, 'Total loss': 0.4719295325604352} | train loss {'Reaction outcome loss': 0.3180714284903125, 'Total loss': 0.3180714284903125}
2022-11-28 01:25:49,516 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:49,517 INFO:     Epoch: 44
2022-11-28 01:25:50,261 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48147385669025505, 'Total loss': 0.48147385669025505} | train loss {'Reaction outcome loss': 0.3072134677758101, 'Total loss': 0.3072134677758101}
2022-11-28 01:25:50,262 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:50,262 INFO:     Epoch: 45
2022-11-28 01:25:51,009 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4923486201600595, 'Total loss': 0.4923486201600595} | train loss {'Reaction outcome loss': 0.31362540558402835, 'Total loss': 0.31362540558402835}
2022-11-28 01:25:51,009 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:51,009 INFO:     Epoch: 46
2022-11-28 01:25:51,755 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43242672153494577, 'Total loss': 0.43242672153494577} | train loss {'Reaction outcome loss': 0.32185136357903, 'Total loss': 0.32185136357903}
2022-11-28 01:25:51,755 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:51,755 INFO:     Epoch: 47
2022-11-28 01:25:52,502 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44456374137239024, 'Total loss': 0.44456374137239024} | train loss {'Reaction outcome loss': 0.3184661790200694, 'Total loss': 0.3184661790200694}
2022-11-28 01:25:52,502 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:52,502 INFO:     Epoch: 48
2022-11-28 01:25:53,250 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4618432044305585, 'Total loss': 0.4618432044305585} | train loss {'Reaction outcome loss': 0.3065754876958455, 'Total loss': 0.3065754876958455}
2022-11-28 01:25:53,250 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:53,250 INFO:     Epoch: 49
2022-11-28 01:25:53,992 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4753809029405767, 'Total loss': 0.4753809029405767} | train loss {'Reaction outcome loss': 0.3089634047610014, 'Total loss': 0.3089634047610014}
2022-11-28 01:25:53,992 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:53,992 INFO:     Epoch: 50
2022-11-28 01:25:54,737 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47311385382305493, 'Total loss': 0.47311385382305493} | train loss {'Reaction outcome loss': 0.3133638444383014, 'Total loss': 0.3133638444383014}
2022-11-28 01:25:54,737 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:54,737 INFO:     Epoch: 51
2022-11-28 01:25:55,478 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47097246145660226, 'Total loss': 0.47097246145660226} | train loss {'Reaction outcome loss': 0.30698707904892897, 'Total loss': 0.30698707904892897}
2022-11-28 01:25:55,478 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:55,478 INFO:     Epoch: 52
2022-11-28 01:25:56,218 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.439557901837609, 'Total loss': 0.439557901837609} | train loss {'Reaction outcome loss': 0.32395656850294546, 'Total loss': 0.32395656850294546}
2022-11-28 01:25:56,218 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:56,219 INFO:     Epoch: 53
2022-11-28 01:25:56,961 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4849877333776517, 'Total loss': 0.4849877333776517} | train loss {'Reaction outcome loss': 0.3026208518910022, 'Total loss': 0.3026208518910022}
2022-11-28 01:25:56,961 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:56,961 INFO:     Epoch: 54
2022-11-28 01:25:57,705 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44624294103546575, 'Total loss': 0.44624294103546575} | train loss {'Reaction outcome loss': 0.31548546710115694, 'Total loss': 0.31548546710115694}
2022-11-28 01:25:57,705 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:57,705 INFO:     Epoch: 55
2022-11-28 01:25:58,447 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4448200010440566, 'Total loss': 0.4448200010440566} | train loss {'Reaction outcome loss': 0.3065988776775507, 'Total loss': 0.3065988776775507}
2022-11-28 01:25:58,447 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:58,447 INFO:     Epoch: 56
2022-11-28 01:25:59,191 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46849128451537003, 'Total loss': 0.46849128451537003} | train loss {'Reaction outcome loss': 0.31101774357953055, 'Total loss': 0.31101774357953055}
2022-11-28 01:25:59,191 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:59,191 INFO:     Epoch: 57
2022-11-28 01:25:59,934 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4681978188455105, 'Total loss': 0.4681978188455105} | train loss {'Reaction outcome loss': 0.3093404903525283, 'Total loss': 0.3093404903525283}
2022-11-28 01:25:59,936 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:25:59,936 INFO:     Epoch: 58
2022-11-28 01:26:00,690 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4712421799247915, 'Total loss': 0.4712421799247915} | train loss {'Reaction outcome loss': 0.31069831212846794, 'Total loss': 0.31069831212846794}
2022-11-28 01:26:00,690 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:00,690 INFO:     Epoch: 59
2022-11-28 01:26:01,437 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45718944377519866, 'Total loss': 0.45718944377519866} | train loss {'Reaction outcome loss': 0.3079225188083494, 'Total loss': 0.3079225188083494}
2022-11-28 01:26:01,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:01,437 INFO:     Epoch: 60
2022-11-28 01:26:02,181 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4446859508752823, 'Total loss': 0.4446859508752823} | train loss {'Reaction outcome loss': 0.31377670633406773, 'Total loss': 0.31377670633406773}
2022-11-28 01:26:02,181 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:02,181 INFO:     Epoch: 61
2022-11-28 01:26:02,925 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44929153387519444, 'Total loss': 0.44929153387519444} | train loss {'Reaction outcome loss': 0.30676613325302143, 'Total loss': 0.30676613325302143}
2022-11-28 01:26:02,925 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:02,926 INFO:     Epoch: 62
2022-11-28 01:26:03,670 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46568297696384514, 'Total loss': 0.46568297696384514} | train loss {'Reaction outcome loss': 0.3053903057718808, 'Total loss': 0.3053903057718808}
2022-11-28 01:26:03,670 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:03,670 INFO:     Epoch: 63
2022-11-28 01:26:04,413 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47249065305699, 'Total loss': 0.47249065305699} | train loss {'Reaction outcome loss': 0.3093011699435923, 'Total loss': 0.3093011699435923}
2022-11-28 01:26:04,413 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:04,413 INFO:     Epoch: 64
2022-11-28 01:26:05,158 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4867437619038604, 'Total loss': 0.4867437619038604} | train loss {'Reaction outcome loss': 0.33537767785657874, 'Total loss': 0.33537767785657874}
2022-11-28 01:26:05,158 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:05,158 INFO:     Epoch: 65
2022-11-28 01:26:05,900 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4723176680166613, 'Total loss': 0.4723176680166613} | train loss {'Reaction outcome loss': 0.3029069772502973, 'Total loss': 0.3029069772502973}
2022-11-28 01:26:05,901 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:05,901 INFO:     Epoch: 66
2022-11-28 01:26:06,644 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4493730256164616, 'Total loss': 0.4493730256164616} | train loss {'Reaction outcome loss': 0.30258922254184056, 'Total loss': 0.30258922254184056}
2022-11-28 01:26:06,645 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:06,645 INFO:     Epoch: 67
2022-11-28 01:26:07,389 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42509026757695456, 'Total loss': 0.42509026757695456} | train loss {'Reaction outcome loss': 0.3135714446786444, 'Total loss': 0.3135714446786444}
2022-11-28 01:26:07,389 INFO:     Found new best model at epoch 67
2022-11-28 01:26:07,390 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:07,390 INFO:     Epoch: 68
2022-11-28 01:26:08,140 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46586321226575156, 'Total loss': 0.46586321226575156} | train loss {'Reaction outcome loss': 0.3127103931749398, 'Total loss': 0.3127103931749398}
2022-11-28 01:26:08,140 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:08,140 INFO:     Epoch: 69
2022-11-28 01:26:08,885 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4331763330847025, 'Total loss': 0.4331763330847025} | train loss {'Reaction outcome loss': 0.30755546514080606, 'Total loss': 0.30755546514080606}
2022-11-28 01:26:08,885 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:08,885 INFO:     Epoch: 70
2022-11-28 01:26:09,628 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.497113959017125, 'Total loss': 0.497113959017125} | train loss {'Reaction outcome loss': 0.29768776389872015, 'Total loss': 0.29768776389872015}
2022-11-28 01:26:09,628 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:09,628 INFO:     Epoch: 71
2022-11-28 01:26:10,374 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4643546888096766, 'Total loss': 0.4643546888096766} | train loss {'Reaction outcome loss': 0.319706061289378, 'Total loss': 0.319706061289378}
2022-11-28 01:26:10,374 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:10,375 INFO:     Epoch: 72
2022-11-28 01:26:11,122 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4572269774296067, 'Total loss': 0.4572269774296067} | train loss {'Reaction outcome loss': 0.3186417312515892, 'Total loss': 0.3186417312515892}
2022-11-28 01:26:11,122 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:11,122 INFO:     Epoch: 73
2022-11-28 01:26:11,868 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4384822344238108, 'Total loss': 0.4384822344238108} | train loss {'Reaction outcome loss': 0.31472643971563835, 'Total loss': 0.31472643971563835}
2022-11-28 01:26:11,869 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:11,869 INFO:     Epoch: 74
2022-11-28 01:26:12,615 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4574657135050405, 'Total loss': 0.4574657135050405} | train loss {'Reaction outcome loss': 0.3070200214743132, 'Total loss': 0.3070200214743132}
2022-11-28 01:26:12,615 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:12,615 INFO:     Epoch: 75
2022-11-28 01:26:13,359 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43096179667521606, 'Total loss': 0.43096179667521606} | train loss {'Reaction outcome loss': 0.2952413459719434, 'Total loss': 0.2952413459719434}
2022-11-28 01:26:13,359 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:13,359 INFO:     Epoch: 76
2022-11-28 01:26:14,105 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4413618950850584, 'Total loss': 0.4413618950850584} | train loss {'Reaction outcome loss': 0.30468285382397264, 'Total loss': 0.30468285382397264}
2022-11-28 01:26:14,105 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:14,106 INFO:     Epoch: 77
2022-11-28 01:26:14,851 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45157272030006756, 'Total loss': 0.45157272030006756} | train loss {'Reaction outcome loss': 0.319510228539768, 'Total loss': 0.319510228539768}
2022-11-28 01:26:14,851 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:14,852 INFO:     Epoch: 78
2022-11-28 01:26:15,595 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4346311447972601, 'Total loss': 0.4346311447972601} | train loss {'Reaction outcome loss': 0.3135944130313903, 'Total loss': 0.3135944130313903}
2022-11-28 01:26:15,595 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:15,595 INFO:     Epoch: 79
2022-11-28 01:26:16,341 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4587818252092058, 'Total loss': 0.4587818252092058} | train loss {'Reaction outcome loss': 0.3093442671804082, 'Total loss': 0.3093442671804082}
2022-11-28 01:26:16,342 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:16,342 INFO:     Epoch: 80
2022-11-28 01:26:17,084 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47224104031920433, 'Total loss': 0.47224104031920433} | train loss {'Reaction outcome loss': 0.3151223167535747, 'Total loss': 0.3151223167535747}
2022-11-28 01:26:17,084 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:17,084 INFO:     Epoch: 81
2022-11-28 01:26:17,829 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4594415446574038, 'Total loss': 0.4594415446574038} | train loss {'Reaction outcome loss': 0.32185998370094215, 'Total loss': 0.32185998370094215}
2022-11-28 01:26:17,829 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:17,829 INFO:     Epoch: 82
2022-11-28 01:26:18,574 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45009165731343354, 'Total loss': 0.45009165731343354} | train loss {'Reaction outcome loss': 0.3030325325134282, 'Total loss': 0.3030325325134282}
2022-11-28 01:26:18,574 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:18,574 INFO:     Epoch: 83
2022-11-28 01:26:19,323 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4390383284877647, 'Total loss': 0.4390383284877647} | train loss {'Reaction outcome loss': 0.31828356721261253, 'Total loss': 0.31828356721261253}
2022-11-28 01:26:19,324 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:19,324 INFO:     Epoch: 84
2022-11-28 01:26:20,076 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4700799086554484, 'Total loss': 0.4700799086554484} | train loss {'Reaction outcome loss': 0.33122076020248026, 'Total loss': 0.33122076020248026}
2022-11-28 01:26:20,076 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:20,076 INFO:     Epoch: 85
2022-11-28 01:26:20,823 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4588230573995547, 'Total loss': 0.4588230573995547} | train loss {'Reaction outcome loss': 0.2992432166102082, 'Total loss': 0.2992432166102082}
2022-11-28 01:26:20,824 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:20,824 INFO:     Epoch: 86
2022-11-28 01:26:21,571 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4798818528652191, 'Total loss': 0.4798818528652191} | train loss {'Reaction outcome loss': 0.31915498401230646, 'Total loss': 0.31915498401230646}
2022-11-28 01:26:21,571 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:21,572 INFO:     Epoch: 87
2022-11-28 01:26:22,318 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42406920953230426, 'Total loss': 0.42406920953230426} | train loss {'Reaction outcome loss': 0.3153474544446448, 'Total loss': 0.3153474544446448}
2022-11-28 01:26:22,318 INFO:     Found new best model at epoch 87
2022-11-28 01:26:22,319 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:22,319 INFO:     Epoch: 88
2022-11-28 01:26:23,067 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46135393326932733, 'Total loss': 0.46135393326932733} | train loss {'Reaction outcome loss': 0.3033936284934943, 'Total loss': 0.3033936284934943}
2022-11-28 01:26:23,067 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:23,067 INFO:     Epoch: 89
2022-11-28 01:26:23,813 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4300604452463714, 'Total loss': 0.4300604452463714} | train loss {'Reaction outcome loss': 0.2995820234523547, 'Total loss': 0.2995820234523547}
2022-11-28 01:26:23,813 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:23,813 INFO:     Epoch: 90
2022-11-28 01:26:24,558 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43820780685002153, 'Total loss': 0.43820780685002153} | train loss {'Reaction outcome loss': 0.3043847982338083, 'Total loss': 0.3043847982338083}
2022-11-28 01:26:24,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:24,558 INFO:     Epoch: 91
2022-11-28 01:26:25,306 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44659991054372356, 'Total loss': 0.44659991054372356} | train loss {'Reaction outcome loss': 0.3030168423165194, 'Total loss': 0.3030168423165194}
2022-11-28 01:26:25,306 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:25,306 INFO:     Epoch: 92
2022-11-28 01:26:26,051 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46645954285155644, 'Total loss': 0.46645954285155644} | train loss {'Reaction outcome loss': 0.3030946450194849, 'Total loss': 0.3030946450194849}
2022-11-28 01:26:26,051 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:26,051 INFO:     Epoch: 93
2022-11-28 01:26:26,796 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46154719895937224, 'Total loss': 0.46154719895937224} | train loss {'Reaction outcome loss': 0.3213645449353133, 'Total loss': 0.3213645449353133}
2022-11-28 01:26:26,796 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:26,796 INFO:     Epoch: 94
2022-11-28 01:26:27,538 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4820495681329207, 'Total loss': 0.4820495681329207} | train loss {'Reaction outcome loss': 0.30805953308517636, 'Total loss': 0.30805953308517636}
2022-11-28 01:26:27,538 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:27,538 INFO:     Epoch: 95
2022-11-28 01:26:28,281 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4356547702442516, 'Total loss': 0.4356547702442516} | train loss {'Reaction outcome loss': 0.30553927173016043, 'Total loss': 0.30553927173016043}
2022-11-28 01:26:28,281 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:28,281 INFO:     Epoch: 96
2022-11-28 01:26:29,023 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.460977609523318, 'Total loss': 0.460977609523318} | train loss {'Reaction outcome loss': 0.3076756925733104, 'Total loss': 0.3076756925733104}
2022-11-28 01:26:29,024 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:29,024 INFO:     Epoch: 97
2022-11-28 01:26:29,768 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44017074324867944, 'Total loss': 0.44017074324867944} | train loss {'Reaction outcome loss': 0.3010584303302321, 'Total loss': 0.3010584303302321}
2022-11-28 01:26:29,768 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:29,769 INFO:     Epoch: 98
2022-11-28 01:26:30,517 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4144833639941432, 'Total loss': 0.4144833639941432} | train loss {'Reaction outcome loss': 0.31798644342765153, 'Total loss': 0.31798644342765153}
2022-11-28 01:26:30,518 INFO:     Found new best model at epoch 98
2022-11-28 01:26:30,518 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:30,518 INFO:     Epoch: 99
2022-11-28 01:26:31,263 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48228578811342065, 'Total loss': 0.48228578811342065} | train loss {'Reaction outcome loss': 0.2963401583374029, 'Total loss': 0.2963401583374029}
2022-11-28 01:26:31,265 INFO:     Best model found after epoch 99 of 100.
2022-11-28 01:26:31,265 INFO:   Done with stage: TRAINING
2022-11-28 01:26:31,265 INFO:   Starting stage: EVALUATION
2022-11-28 01:26:31,385 INFO:   Done with stage: EVALUATION
2022-11-28 01:26:31,385 INFO:   Leaving out SEQ value Fold_8
2022-11-28 01:26:31,398 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 01:26:31,399 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:26:32,030 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:26:32,030 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:26:32,101 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:26:32,101 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:26:32,101 INFO:     No hyperparam tuning for this model
2022-11-28 01:26:32,101 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:26:32,101 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:26:32,102 INFO:     None feature selector for col prot
2022-11-28 01:26:32,102 INFO:     None feature selector for col prot
2022-11-28 01:26:32,102 INFO:     None feature selector for col prot
2022-11-28 01:26:32,103 INFO:     None feature selector for col chem
2022-11-28 01:26:32,103 INFO:     None feature selector for col chem
2022-11-28 01:26:32,103 INFO:     None feature selector for col chem
2022-11-28 01:26:32,103 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:26:32,103 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:26:32,105 INFO:     Number of params in model 169741
2022-11-28 01:26:32,108 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:26:32,108 INFO:   Starting stage: TRAINING
2022-11-28 01:26:32,161 INFO:     Val loss before train {'Reaction outcome loss': 0.9989291401796563, 'Total loss': 0.9989291401796563}
2022-11-28 01:26:32,161 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:32,161 INFO:     Epoch: 0
2022-11-28 01:26:32,897 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5825387343417766, 'Total loss': 0.5825387343417766} | train loss {'Reaction outcome loss': 0.6171903985812038, 'Total loss': 0.6171903985812038}
2022-11-28 01:26:32,897 INFO:     Found new best model at epoch 0
2022-11-28 01:26:32,898 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:32,898 INFO:     Epoch: 1
2022-11-28 01:26:33,634 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5214537770249122, 'Total loss': 0.5214537770249122} | train loss {'Reaction outcome loss': 0.49363428372584406, 'Total loss': 0.49363428372584406}
2022-11-28 01:26:33,634 INFO:     Found new best model at epoch 1
2022-11-28 01:26:33,635 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:33,635 INFO:     Epoch: 2
2022-11-28 01:26:34,369 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48251163162464317, 'Total loss': 0.48251163162464317} | train loss {'Reaction outcome loss': 0.4550438982541444, 'Total loss': 0.4550438982541444}
2022-11-28 01:26:34,369 INFO:     Found new best model at epoch 2
2022-11-28 01:26:34,370 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:34,370 INFO:     Epoch: 3
2022-11-28 01:26:35,103 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49239307538021443, 'Total loss': 0.49239307538021443} | train loss {'Reaction outcome loss': 0.43153591090660604, 'Total loss': 0.43153591090660604}
2022-11-28 01:26:35,103 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:35,103 INFO:     Epoch: 4
2022-11-28 01:26:35,838 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4882252140100612, 'Total loss': 0.4882252140100612} | train loss {'Reaction outcome loss': 0.40711489851113225, 'Total loss': 0.40711489851113225}
2022-11-28 01:26:35,838 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:35,838 INFO:     Epoch: 5
2022-11-28 01:26:36,572 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5141909202170927, 'Total loss': 0.5141909202170927} | train loss {'Reaction outcome loss': 0.40867749662672886, 'Total loss': 0.40867749662672886}
2022-11-28 01:26:36,572 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:36,572 INFO:     Epoch: 6
2022-11-28 01:26:37,308 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46468876614127047, 'Total loss': 0.46468876614127047} | train loss {'Reaction outcome loss': 0.40073617614927837, 'Total loss': 0.40073617614927837}
2022-11-28 01:26:37,309 INFO:     Found new best model at epoch 6
2022-11-28 01:26:37,310 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:37,310 INFO:     Epoch: 7
2022-11-28 01:26:38,043 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4539072374964869, 'Total loss': 0.4539072374964869} | train loss {'Reaction outcome loss': 0.3858858061740633, 'Total loss': 0.3858858061740633}
2022-11-28 01:26:38,043 INFO:     Found new best model at epoch 7
2022-11-28 01:26:38,044 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:38,044 INFO:     Epoch: 8
2022-11-28 01:26:38,777 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46222427175488584, 'Total loss': 0.46222427175488584} | train loss {'Reaction outcome loss': 0.3852564721811013, 'Total loss': 0.3852564721811013}
2022-11-28 01:26:38,778 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:38,778 INFO:     Epoch: 9
2022-11-28 01:26:39,513 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4372345264567885, 'Total loss': 0.4372345264567885} | train loss {'Reaction outcome loss': 0.37151756595636976, 'Total loss': 0.37151756595636976}
2022-11-28 01:26:39,513 INFO:     Found new best model at epoch 9
2022-11-28 01:26:39,514 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:39,514 INFO:     Epoch: 10
2022-11-28 01:26:40,249 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4493415262116942, 'Total loss': 0.4493415262116942} | train loss {'Reaction outcome loss': 0.37210350398157466, 'Total loss': 0.37210350398157466}
2022-11-28 01:26:40,249 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:40,249 INFO:     Epoch: 11
2022-11-28 01:26:40,985 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4579290054565252, 'Total loss': 0.4579290054565252} | train loss {'Reaction outcome loss': 0.3729521330507075, 'Total loss': 0.3729521330507075}
2022-11-28 01:26:40,985 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:40,985 INFO:     Epoch: 12
2022-11-28 01:26:41,721 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47286596720994906, 'Total loss': 0.47286596720994906} | train loss {'Reaction outcome loss': 0.3591234205504421, 'Total loss': 0.3591234205504421}
2022-11-28 01:26:41,721 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:41,721 INFO:     Epoch: 13
2022-11-28 01:26:42,456 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45866808468519255, 'Total loss': 0.45866808468519255} | train loss {'Reaction outcome loss': 0.3646858164460444, 'Total loss': 0.3646858164460444}
2022-11-28 01:26:42,457 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:42,457 INFO:     Epoch: 14
2022-11-28 01:26:43,192 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44413753841505493, 'Total loss': 0.44413753841505493} | train loss {'Reaction outcome loss': 0.35478612478272836, 'Total loss': 0.35478612478272836}
2022-11-28 01:26:43,192 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:43,192 INFO:     Epoch: 15
2022-11-28 01:26:43,929 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42587651416312816, 'Total loss': 0.42587651416312816} | train loss {'Reaction outcome loss': 0.34202552345566084, 'Total loss': 0.34202552345566084}
2022-11-28 01:26:43,929 INFO:     Found new best model at epoch 15
2022-11-28 01:26:43,930 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:43,930 INFO:     Epoch: 16
2022-11-28 01:26:44,661 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4305342650690744, 'Total loss': 0.4305342650690744} | train loss {'Reaction outcome loss': 0.3435719623001384, 'Total loss': 0.3435719623001384}
2022-11-28 01:26:44,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:44,662 INFO:     Epoch: 17
2022-11-28 01:26:45,401 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45922128925489825, 'Total loss': 0.45922128925489825} | train loss {'Reaction outcome loss': 0.35182397064493326, 'Total loss': 0.35182397064493326}
2022-11-28 01:26:45,401 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:45,401 INFO:     Epoch: 18
2022-11-28 01:26:46,138 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45049641645231914, 'Total loss': 0.45049641645231914} | train loss {'Reaction outcome loss': 0.3386793746689304, 'Total loss': 0.3386793746689304}
2022-11-28 01:26:46,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:46,138 INFO:     Epoch: 19
2022-11-28 01:26:46,875 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44256419428559235, 'Total loss': 0.44256419428559235} | train loss {'Reaction outcome loss': 0.3423991379801367, 'Total loss': 0.3423991379801367}
2022-11-28 01:26:46,875 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:46,875 INFO:     Epoch: 20
2022-11-28 01:26:47,609 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4290463889754096, 'Total loss': 0.4290463889754096} | train loss {'Reaction outcome loss': 0.3421724957765126, 'Total loss': 0.3421724957765126}
2022-11-28 01:26:47,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:47,609 INFO:     Epoch: 21
2022-11-28 01:26:48,346 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4216380916362585, 'Total loss': 0.4216380916362585} | train loss {'Reaction outcome loss': 0.3352478728247959, 'Total loss': 0.3352478728247959}
2022-11-28 01:26:48,347 INFO:     Found new best model at epoch 21
2022-11-28 01:26:48,347 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:48,348 INFO:     Epoch: 22
2022-11-28 01:26:49,084 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43669044867504475, 'Total loss': 0.43669044867504475} | train loss {'Reaction outcome loss': 0.3280423782979611, 'Total loss': 0.3280423782979611}
2022-11-28 01:26:49,085 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:49,085 INFO:     Epoch: 23
2022-11-28 01:26:49,823 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4403016435545544, 'Total loss': 0.4403016435545544} | train loss {'Reaction outcome loss': 0.3285144203205089, 'Total loss': 0.3285144203205089}
2022-11-28 01:26:49,824 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:49,824 INFO:     Epoch: 24
2022-11-28 01:26:50,560 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4362230723680452, 'Total loss': 0.4362230723680452} | train loss {'Reaction outcome loss': 0.3363869593585612, 'Total loss': 0.3363869593585612}
2022-11-28 01:26:50,560 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:50,560 INFO:     Epoch: 25
2022-11-28 01:26:51,297 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4406053780816322, 'Total loss': 0.4406053780816322} | train loss {'Reaction outcome loss': 0.3351459408820164, 'Total loss': 0.3351459408820164}
2022-11-28 01:26:51,298 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:51,298 INFO:     Epoch: 26
2022-11-28 01:26:52,034 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45905435709066167, 'Total loss': 0.45905435709066167} | train loss {'Reaction outcome loss': 0.3211892464305045, 'Total loss': 0.3211892464305045}
2022-11-28 01:26:52,035 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:52,035 INFO:     Epoch: 27
2022-11-28 01:26:52,769 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4575154427872148, 'Total loss': 0.4575154427872148} | train loss {'Reaction outcome loss': 0.31852145450281316, 'Total loss': 0.31852145450281316}
2022-11-28 01:26:52,769 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:52,769 INFO:     Epoch: 28
2022-11-28 01:26:53,505 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44213195560976515, 'Total loss': 0.44213195560976515} | train loss {'Reaction outcome loss': 0.3268749143195445, 'Total loss': 0.3268749143195445}
2022-11-28 01:26:53,505 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:53,505 INFO:     Epoch: 29
2022-11-28 01:26:54,239 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41970120647618936, 'Total loss': 0.41970120647618936} | train loss {'Reaction outcome loss': 0.3237503224556319, 'Total loss': 0.3237503224556319}
2022-11-28 01:26:54,239 INFO:     Found new best model at epoch 29
2022-11-28 01:26:54,240 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:54,240 INFO:     Epoch: 30
2022-11-28 01:26:54,972 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4477841760530028, 'Total loss': 0.4477841760530028} | train loss {'Reaction outcome loss': 0.3220997280670238, 'Total loss': 0.3220997280670238}
2022-11-28 01:26:54,972 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:54,972 INFO:     Epoch: 31
2022-11-28 01:26:55,706 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42545966422835063, 'Total loss': 0.42545966422835063} | train loss {'Reaction outcome loss': 0.3153522327603375, 'Total loss': 0.3153522327603375}
2022-11-28 01:26:55,707 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:55,707 INFO:     Epoch: 32
2022-11-28 01:26:56,436 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40852162467185843, 'Total loss': 0.40852162467185843} | train loss {'Reaction outcome loss': 0.3180358276137563, 'Total loss': 0.3180358276137563}
2022-11-28 01:26:56,437 INFO:     Found new best model at epoch 32
2022-11-28 01:26:56,437 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:56,437 INFO:     Epoch: 33
2022-11-28 01:26:57,168 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.444265024260033, 'Total loss': 0.444265024260033} | train loss {'Reaction outcome loss': 0.31877327624891627, 'Total loss': 0.31877327624891627}
2022-11-28 01:26:57,168 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:57,169 INFO:     Epoch: 34
2022-11-28 01:26:57,902 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4237222616062608, 'Total loss': 0.4237222616062608} | train loss {'Reaction outcome loss': 0.3184807036133086, 'Total loss': 0.3184807036133086}
2022-11-28 01:26:57,902 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:57,902 INFO:     Epoch: 35
2022-11-28 01:26:58,637 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45837013596712156, 'Total loss': 0.45837013596712156} | train loss {'Reaction outcome loss': 0.31777844888723045, 'Total loss': 0.31777844888723045}
2022-11-28 01:26:58,638 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:58,638 INFO:     Epoch: 36
2022-11-28 01:26:59,369 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42796179478944735, 'Total loss': 0.42796179478944735} | train loss {'Reaction outcome loss': 0.31193429669059936, 'Total loss': 0.31193429669059936}
2022-11-28 01:26:59,369 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:26:59,369 INFO:     Epoch: 37
2022-11-28 01:27:00,103 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41260306294574295, 'Total loss': 0.41260306294574295} | train loss {'Reaction outcome loss': 0.3240374059981254, 'Total loss': 0.3240374059981254}
2022-11-28 01:27:00,103 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:00,103 INFO:     Epoch: 38
2022-11-28 01:27:00,836 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4343178310366564, 'Total loss': 0.4343178310366564} | train loss {'Reaction outcome loss': 0.3128714123893468, 'Total loss': 0.3128714123893468}
2022-11-28 01:27:00,836 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:00,836 INFO:     Epoch: 39
2022-11-28 01:27:01,572 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4561613021894943, 'Total loss': 0.4561613021894943} | train loss {'Reaction outcome loss': 0.3212719437528829, 'Total loss': 0.3212719437528829}
2022-11-28 01:27:01,572 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:01,572 INFO:     Epoch: 40
2022-11-28 01:27:02,305 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44395626145739886, 'Total loss': 0.44395626145739886} | train loss {'Reaction outcome loss': 0.3132391943916923, 'Total loss': 0.3132391943916923}
2022-11-28 01:27:02,306 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:02,306 INFO:     Epoch: 41
2022-11-28 01:27:03,038 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4413803275241408, 'Total loss': 0.4413803275241408} | train loss {'Reaction outcome loss': 0.3028813602524947, 'Total loss': 0.3028813602524947}
2022-11-28 01:27:03,038 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:03,038 INFO:     Epoch: 42
2022-11-28 01:27:03,773 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41733304567115254, 'Total loss': 0.41733304567115254} | train loss {'Reaction outcome loss': 0.31461681920241136, 'Total loss': 0.31461681920241136}
2022-11-28 01:27:03,773 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:03,774 INFO:     Epoch: 43
2022-11-28 01:27:04,508 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4351869142332742, 'Total loss': 0.4351869142332742} | train loss {'Reaction outcome loss': 0.30919718702674887, 'Total loss': 0.30919718702674887}
2022-11-28 01:27:04,508 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:04,508 INFO:     Epoch: 44
2022-11-28 01:27:05,239 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4427375273649083, 'Total loss': 0.4427375273649083} | train loss {'Reaction outcome loss': 0.3058261729654719, 'Total loss': 0.3058261729654719}
2022-11-28 01:27:05,239 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:05,239 INFO:     Epoch: 45
2022-11-28 01:27:05,973 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4229478985071182, 'Total loss': 0.4229478985071182} | train loss {'Reaction outcome loss': 0.3165828667153589, 'Total loss': 0.3165828667153589}
2022-11-28 01:27:05,973 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:05,973 INFO:     Epoch: 46
2022-11-28 01:27:06,716 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4454037472605705, 'Total loss': 0.4454037472605705} | train loss {'Reaction outcome loss': 0.30633363155190085, 'Total loss': 0.30633363155190085}
2022-11-28 01:27:06,717 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:06,717 INFO:     Epoch: 47
2022-11-28 01:27:07,455 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4414454601531805, 'Total loss': 0.4414454601531805} | train loss {'Reaction outcome loss': 0.30508794055366123, 'Total loss': 0.30508794055366123}
2022-11-28 01:27:07,455 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:07,455 INFO:     Epoch: 48
2022-11-28 01:27:08,187 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44962247409099754, 'Total loss': 0.44962247409099754} | train loss {'Reaction outcome loss': 0.3039352607409485, 'Total loss': 0.3039352607409485}
2022-11-28 01:27:08,187 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:08,187 INFO:     Epoch: 49
2022-11-28 01:27:08,920 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.433162264352621, 'Total loss': 0.433162264352621} | train loss {'Reaction outcome loss': 0.3087186046921816, 'Total loss': 0.3087186046921816}
2022-11-28 01:27:08,921 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:08,921 INFO:     Epoch: 50
2022-11-28 01:27:09,653 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42131157358025395, 'Total loss': 0.42131157358025395} | train loss {'Reaction outcome loss': 0.31381744912779724, 'Total loss': 0.31381744912779724}
2022-11-28 01:27:09,653 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:09,653 INFO:     Epoch: 51
2022-11-28 01:27:10,385 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4126467850319175, 'Total loss': 0.4126467850319175} | train loss {'Reaction outcome loss': 0.31311090205047953, 'Total loss': 0.31311090205047953}
2022-11-28 01:27:10,385 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:10,385 INFO:     Epoch: 52
2022-11-28 01:27:11,122 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.419558843900991, 'Total loss': 0.419558843900991} | train loss {'Reaction outcome loss': 0.2982939761437354, 'Total loss': 0.2982939761437354}
2022-11-28 01:27:11,122 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:11,122 INFO:     Epoch: 53
2022-11-28 01:27:11,856 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4610304787408474, 'Total loss': 0.4610304787408474} | train loss {'Reaction outcome loss': 0.30603557112092367, 'Total loss': 0.30603557112092367}
2022-11-28 01:27:11,856 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:11,856 INFO:     Epoch: 54
2022-11-28 01:27:12,588 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48543391255445256, 'Total loss': 0.48543391255445256} | train loss {'Reaction outcome loss': 0.2994336968776388, 'Total loss': 0.2994336968776388}
2022-11-28 01:27:12,589 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:12,589 INFO:     Epoch: 55
2022-11-28 01:27:13,322 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46512483753437217, 'Total loss': 0.46512483753437217} | train loss {'Reaction outcome loss': 0.30419399949615117, 'Total loss': 0.30419399949615117}
2022-11-28 01:27:13,322 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:13,322 INFO:     Epoch: 56
2022-11-28 01:27:14,063 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.433915143919199, 'Total loss': 0.433915143919199} | train loss {'Reaction outcome loss': 0.30085618329829855, 'Total loss': 0.30085618329829855}
2022-11-28 01:27:14,063 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:14,063 INFO:     Epoch: 57
2022-11-28 01:27:14,797 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4666569842848667, 'Total loss': 0.4666569842848667} | train loss {'Reaction outcome loss': 0.2997597246507152, 'Total loss': 0.2997597246507152}
2022-11-28 01:27:14,798 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:14,798 INFO:     Epoch: 58
2022-11-28 01:27:15,531 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4421305555936902, 'Total loss': 0.4421305555936902} | train loss {'Reaction outcome loss': 0.3040589087138899, 'Total loss': 0.3040589087138899}
2022-11-28 01:27:15,531 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:15,532 INFO:     Epoch: 59
2022-11-28 01:27:16,270 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4012937426220539, 'Total loss': 0.4012937426220539} | train loss {'Reaction outcome loss': 0.2937534788898269, 'Total loss': 0.2937534788898269}
2022-11-28 01:27:16,271 INFO:     Found new best model at epoch 59
2022-11-28 01:27:16,271 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:16,271 INFO:     Epoch: 60
2022-11-28 01:27:17,006 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4153759264668753, 'Total loss': 0.4153759264668753} | train loss {'Reaction outcome loss': 0.3011360048148476, 'Total loss': 0.3011360048148476}
2022-11-28 01:27:17,006 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:17,006 INFO:     Epoch: 61
2022-11-28 01:27:17,737 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43182097912527795, 'Total loss': 0.43182097912527795} | train loss {'Reaction outcome loss': 0.3038748666247139, 'Total loss': 0.3038748666247139}
2022-11-28 01:27:17,737 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:17,737 INFO:     Epoch: 62
2022-11-28 01:27:18,471 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4226293238096459, 'Total loss': 0.4226293238096459} | train loss {'Reaction outcome loss': 0.29765691565441305, 'Total loss': 0.29765691565441305}
2022-11-28 01:27:18,471 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:18,471 INFO:     Epoch: 63
2022-11-28 01:27:19,200 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.440655771729558, 'Total loss': 0.440655771729558} | train loss {'Reaction outcome loss': 0.29919158256627987, 'Total loss': 0.29919158256627987}
2022-11-28 01:27:19,200 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:19,200 INFO:     Epoch: 64
2022-11-28 01:27:19,931 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43958772510983224, 'Total loss': 0.43958772510983224} | train loss {'Reaction outcome loss': 0.30438062741008937, 'Total loss': 0.30438062741008937}
2022-11-28 01:27:19,931 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:19,931 INFO:     Epoch: 65
2022-11-28 01:27:20,661 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4628731126702109, 'Total loss': 0.4628731126702109} | train loss {'Reaction outcome loss': 0.29607758005378676, 'Total loss': 0.29607758005378676}
2022-11-28 01:27:20,661 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:20,661 INFO:     Epoch: 66
2022-11-28 01:27:21,393 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4185114405875982, 'Total loss': 0.4185114405875982} | train loss {'Reaction outcome loss': 0.30423239133030666, 'Total loss': 0.30423239133030666}
2022-11-28 01:27:21,393 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:21,393 INFO:     Epoch: 67
2022-11-28 01:27:22,123 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45940176692119866, 'Total loss': 0.45940176692119866} | train loss {'Reaction outcome loss': 0.2953429005307252, 'Total loss': 0.2953429005307252}
2022-11-28 01:27:22,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:22,123 INFO:     Epoch: 68
2022-11-28 01:27:22,853 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4639385924782864, 'Total loss': 0.4639385924782864} | train loss {'Reaction outcome loss': 0.30941937259230456, 'Total loss': 0.30941937259230456}
2022-11-28 01:27:22,853 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:22,853 INFO:     Epoch: 69
2022-11-28 01:27:23,586 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5040814668633217, 'Total loss': 0.5040814668633217} | train loss {'Reaction outcome loss': 0.307239510424313, 'Total loss': 0.307239510424313}
2022-11-28 01:27:23,586 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:23,586 INFO:     Epoch: 70
2022-11-28 01:27:24,319 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42556654956451684, 'Total loss': 0.42556654956451684} | train loss {'Reaction outcome loss': 0.2986100873314455, 'Total loss': 0.2986100873314455}
2022-11-28 01:27:24,319 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:24,320 INFO:     Epoch: 71
2022-11-28 01:27:25,054 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43227920594603514, 'Total loss': 0.43227920594603514} | train loss {'Reaction outcome loss': 0.29276313425087536, 'Total loss': 0.29276313425087536}
2022-11-28 01:27:25,054 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:25,054 INFO:     Epoch: 72
2022-11-28 01:27:25,791 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44466564232526823, 'Total loss': 0.44466564232526823} | train loss {'Reaction outcome loss': 0.30213305201442514, 'Total loss': 0.30213305201442514}
2022-11-28 01:27:25,791 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:25,791 INFO:     Epoch: 73
2022-11-28 01:27:26,523 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46458971569704455, 'Total loss': 0.46458971569704455} | train loss {'Reaction outcome loss': 0.2985496839630555, 'Total loss': 0.2985496839630555}
2022-11-28 01:27:26,523 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:26,523 INFO:     Epoch: 74
2022-11-28 01:27:27,261 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42726335934428283, 'Total loss': 0.42726335934428283} | train loss {'Reaction outcome loss': 0.29997607045730607, 'Total loss': 0.29997607045730607}
2022-11-28 01:27:27,261 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:27,261 INFO:     Epoch: 75
2022-11-28 01:27:27,994 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4478707746710888, 'Total loss': 0.4478707746710888} | train loss {'Reaction outcome loss': 0.30262399064834977, 'Total loss': 0.30262399064834977}
2022-11-28 01:27:27,994 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:27,994 INFO:     Epoch: 76
2022-11-28 01:27:28,725 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42601443411305895, 'Total loss': 0.42601443411305895} | train loss {'Reaction outcome loss': 0.2939223115500368, 'Total loss': 0.2939223115500368}
2022-11-28 01:27:28,725 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:28,725 INFO:     Epoch: 77
2022-11-28 01:27:29,458 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42001534825147585, 'Total loss': 0.42001534825147585} | train loss {'Reaction outcome loss': 0.30165779465412507, 'Total loss': 0.30165779465412507}
2022-11-28 01:27:29,458 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:29,458 INFO:     Epoch: 78
2022-11-28 01:27:30,192 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5404064371142276, 'Total loss': 0.5404064371142276} | train loss {'Reaction outcome loss': 0.29579020593864996, 'Total loss': 0.29579020593864996}
2022-11-28 01:27:30,192 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:30,192 INFO:     Epoch: 79
2022-11-28 01:27:30,928 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4354621975920921, 'Total loss': 0.4354621975920921} | train loss {'Reaction outcome loss': 0.3082145695253962, 'Total loss': 0.3082145695253962}
2022-11-28 01:27:30,928 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:30,928 INFO:     Epoch: 80
2022-11-28 01:27:31,658 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4859462657640147, 'Total loss': 0.4859462657640147} | train loss {'Reaction outcome loss': 0.29950581326103604, 'Total loss': 0.29950581326103604}
2022-11-28 01:27:31,658 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:31,658 INFO:     Epoch: 81
2022-11-28 01:27:32,390 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4482354171747385, 'Total loss': 0.4482354171747385} | train loss {'Reaction outcome loss': 0.30195889225015876, 'Total loss': 0.30195889225015876}
2022-11-28 01:27:32,390 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:32,390 INFO:     Epoch: 82
2022-11-28 01:27:33,122 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45054688737835996, 'Total loss': 0.45054688737835996} | train loss {'Reaction outcome loss': 0.29988182818547626, 'Total loss': 0.29988182818547626}
2022-11-28 01:27:33,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:33,123 INFO:     Epoch: 83
2022-11-28 01:27:33,858 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45737328640250274, 'Total loss': 0.45737328640250274} | train loss {'Reaction outcome loss': 0.31036631147697813, 'Total loss': 0.31036631147697813}
2022-11-28 01:27:33,858 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:33,858 INFO:     Epoch: 84
2022-11-28 01:27:34,591 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42513229091500127, 'Total loss': 0.42513229091500127} | train loss {'Reaction outcome loss': 0.2928289780240567, 'Total loss': 0.2928289780240567}
2022-11-28 01:27:34,591 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:34,591 INFO:     Epoch: 85
2022-11-28 01:27:35,324 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49090402105519937, 'Total loss': 0.49090402105519937} | train loss {'Reaction outcome loss': 0.3004365016049782, 'Total loss': 0.3004365016049782}
2022-11-28 01:27:35,324 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:35,324 INFO:     Epoch: 86
2022-11-28 01:27:36,058 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40141749191422793, 'Total loss': 0.40141749191422793} | train loss {'Reaction outcome loss': 0.2915824090787133, 'Total loss': 0.2915824090787133}
2022-11-28 01:27:36,058 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:36,058 INFO:     Epoch: 87
2022-11-28 01:27:36,791 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41165296334859935, 'Total loss': 0.41165296334859935} | train loss {'Reaction outcome loss': 0.2917266401050032, 'Total loss': 0.2917266401050032}
2022-11-28 01:27:36,792 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:36,792 INFO:     Epoch: 88
2022-11-28 01:27:37,525 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4291402413401493, 'Total loss': 0.4291402413401493} | train loss {'Reaction outcome loss': 0.29635420875226864, 'Total loss': 0.29635420875226864}
2022-11-28 01:27:37,525 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:37,525 INFO:     Epoch: 89
2022-11-28 01:27:38,255 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41774069084677584, 'Total loss': 0.41774069084677584} | train loss {'Reaction outcome loss': 0.31597323630188334, 'Total loss': 0.31597323630188334}
2022-11-28 01:27:38,255 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:38,255 INFO:     Epoch: 90
2022-11-28 01:27:38,989 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.424520711219588, 'Total loss': 0.424520711219588} | train loss {'Reaction outcome loss': 0.2879128984374101, 'Total loss': 0.2879128984374101}
2022-11-28 01:27:38,989 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:38,990 INFO:     Epoch: 91
2022-11-28 01:27:39,724 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42515516211820203, 'Total loss': 0.42515516211820203} | train loss {'Reaction outcome loss': 0.3062470207509936, 'Total loss': 0.3062470207509936}
2022-11-28 01:27:39,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:39,725 INFO:     Epoch: 92
2022-11-28 01:27:40,456 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4446881784256114, 'Total loss': 0.4446881784256114} | train loss {'Reaction outcome loss': 0.2938092545163436, 'Total loss': 0.2938092545163436}
2022-11-28 01:27:40,457 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:40,457 INFO:     Epoch: 93
2022-11-28 01:27:41,186 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42214456789715343, 'Total loss': 0.42214456789715343} | train loss {'Reaction outcome loss': 0.2936372813142714, 'Total loss': 0.2936372813142714}
2022-11-28 01:27:41,186 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:41,186 INFO:     Epoch: 94
2022-11-28 01:27:41,915 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4405573265150536, 'Total loss': 0.4405573265150536} | train loss {'Reaction outcome loss': 0.2918394781404831, 'Total loss': 0.2918394781404831}
2022-11-28 01:27:41,915 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:41,915 INFO:     Epoch: 95
2022-11-28 01:27:42,645 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4278523048689199, 'Total loss': 0.4278523048689199} | train loss {'Reaction outcome loss': 0.303530185926156, 'Total loss': 0.303530185926156}
2022-11-28 01:27:42,645 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:42,646 INFO:     Epoch: 96
2022-11-28 01:27:43,376 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41913780396760897, 'Total loss': 0.41913780396760897} | train loss {'Reaction outcome loss': 0.30149607659607636, 'Total loss': 0.30149607659607636}
2022-11-28 01:27:43,376 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:43,376 INFO:     Epoch: 97
2022-11-28 01:27:44,105 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4135838445535926, 'Total loss': 0.4135838445535926} | train loss {'Reaction outcome loss': 0.29403651777471673, 'Total loss': 0.29403651777471673}
2022-11-28 01:27:44,105 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:44,105 INFO:     Epoch: 98
2022-11-28 01:27:44,834 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4390149842514548, 'Total loss': 0.4390149842514548} | train loss {'Reaction outcome loss': 0.2925308806455282, 'Total loss': 0.2925308806455282}
2022-11-28 01:27:44,834 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:44,834 INFO:     Epoch: 99
2022-11-28 01:27:45,562 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4219622400610946, 'Total loss': 0.4219622400610946} | train loss {'Reaction outcome loss': 0.3000433982395735, 'Total loss': 0.3000433982395735}
2022-11-28 01:27:45,563 INFO:     Best model found after epoch 60 of 100.
2022-11-28 01:27:45,563 INFO:   Done with stage: TRAINING
2022-11-28 01:27:45,563 INFO:   Starting stage: EVALUATION
2022-11-28 01:27:45,695 INFO:   Done with stage: EVALUATION
2022-11-28 01:27:45,695 INFO:   Leaving out SEQ value Fold_9
2022-11-28 01:27:45,707 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 01:27:45,707 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:27:46,352 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:27:46,352 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:27:46,422 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:27:46,422 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:27:46,422 INFO:     No hyperparam tuning for this model
2022-11-28 01:27:46,422 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:27:46,422 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:27:46,423 INFO:     None feature selector for col prot
2022-11-28 01:27:46,423 INFO:     None feature selector for col prot
2022-11-28 01:27:46,423 INFO:     None feature selector for col prot
2022-11-28 01:27:46,424 INFO:     None feature selector for col chem
2022-11-28 01:27:46,424 INFO:     None feature selector for col chem
2022-11-28 01:27:46,424 INFO:     None feature selector for col chem
2022-11-28 01:27:46,424 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:27:46,424 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:27:46,425 INFO:     Number of params in model 169741
2022-11-28 01:27:46,428 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:27:46,428 INFO:   Starting stage: TRAINING
2022-11-28 01:27:46,481 INFO:     Val loss before train {'Reaction outcome loss': 1.0503144833174618, 'Total loss': 1.0503144833174618}
2022-11-28 01:27:46,481 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:46,481 INFO:     Epoch: 0
2022-11-28 01:27:47,219 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5076324848288839, 'Total loss': 0.5076324848288839} | train loss {'Reaction outcome loss': 0.6213059214656411, 'Total loss': 0.6213059214656411}
2022-11-28 01:27:47,219 INFO:     Found new best model at epoch 0
2022-11-28 01:27:47,220 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:47,220 INFO:     Epoch: 1
2022-11-28 01:27:47,963 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.46460227194157516, 'Total loss': 0.46460227194157516} | train loss {'Reaction outcome loss': 0.49198797023911706, 'Total loss': 0.49198797023911706}
2022-11-28 01:27:47,964 INFO:     Found new best model at epoch 1
2022-11-28 01:27:47,964 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:47,964 INFO:     Epoch: 2
2022-11-28 01:27:48,709 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49401383101940155, 'Total loss': 0.49401383101940155} | train loss {'Reaction outcome loss': 0.4553042293680824, 'Total loss': 0.4553042293680824}
2022-11-28 01:27:48,710 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:48,710 INFO:     Epoch: 3
2022-11-28 01:27:49,457 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.44794893281703646, 'Total loss': 0.44794893281703646} | train loss {'Reaction outcome loss': 0.4378792732531725, 'Total loss': 0.4378792732531725}
2022-11-28 01:27:49,457 INFO:     Found new best model at epoch 3
2022-11-28 01:27:49,457 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:49,458 INFO:     Epoch: 4
2022-11-28 01:27:50,204 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46928531100804155, 'Total loss': 0.46928531100804155} | train loss {'Reaction outcome loss': 0.41140557095589425, 'Total loss': 0.41140557095589425}
2022-11-28 01:27:50,204 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:50,204 INFO:     Epoch: 5
2022-11-28 01:27:50,951 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4697649472139098, 'Total loss': 0.4697649472139098} | train loss {'Reaction outcome loss': 0.40806753939462576, 'Total loss': 0.40806753939462576}
2022-11-28 01:27:50,951 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:50,951 INFO:     Epoch: 6
2022-11-28 01:27:51,697 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44190923260016873, 'Total loss': 0.44190923260016873} | train loss {'Reaction outcome loss': 0.3981614812062337, 'Total loss': 0.3981614812062337}
2022-11-28 01:27:51,697 INFO:     Found new best model at epoch 6
2022-11-28 01:27:51,698 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:51,698 INFO:     Epoch: 7
2022-11-28 01:27:52,446 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44800760596990585, 'Total loss': 0.44800760596990585} | train loss {'Reaction outcome loss': 0.3852665745295011, 'Total loss': 0.3852665745295011}
2022-11-28 01:27:52,447 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:52,447 INFO:     Epoch: 8
2022-11-28 01:27:53,193 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4396819238635627, 'Total loss': 0.4396819238635627} | train loss {'Reaction outcome loss': 0.3983530451049689, 'Total loss': 0.3983530451049689}
2022-11-28 01:27:53,193 INFO:     Found new best model at epoch 8
2022-11-28 01:27:53,194 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:53,194 INFO:     Epoch: 9
2022-11-28 01:27:53,941 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46125215054913, 'Total loss': 0.46125215054913} | train loss {'Reaction outcome loss': 0.3962179922804176, 'Total loss': 0.3962179922804176}
2022-11-28 01:27:53,942 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:53,942 INFO:     Epoch: 10
2022-11-28 01:27:54,688 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41249735856598074, 'Total loss': 0.41249735856598074} | train loss {'Reaction outcome loss': 0.38852178323486075, 'Total loss': 0.38852178323486075}
2022-11-28 01:27:54,688 INFO:     Found new best model at epoch 10
2022-11-28 01:27:54,689 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:54,689 INFO:     Epoch: 11
2022-11-28 01:27:55,435 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45140582052144135, 'Total loss': 0.45140582052144135} | train loss {'Reaction outcome loss': 0.37056302119363177, 'Total loss': 0.37056302119363177}
2022-11-28 01:27:55,435 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:55,435 INFO:     Epoch: 12
2022-11-28 01:27:56,179 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43515788458965043, 'Total loss': 0.43515788458965043} | train loss {'Reaction outcome loss': 0.3722708285277189, 'Total loss': 0.3722708285277189}
2022-11-28 01:27:56,179 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:56,180 INFO:     Epoch: 13
2022-11-28 01:27:56,926 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47132444618777797, 'Total loss': 0.47132444618777797} | train loss {'Reaction outcome loss': 0.37033341861205543, 'Total loss': 0.37033341861205543}
2022-11-28 01:27:56,926 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:56,926 INFO:     Epoch: 14
2022-11-28 01:27:57,675 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4493771642446518, 'Total loss': 0.4493771642446518} | train loss {'Reaction outcome loss': 0.36073907974519226, 'Total loss': 0.36073907974519226}
2022-11-28 01:27:57,675 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:57,675 INFO:     Epoch: 15
2022-11-28 01:27:58,421 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4638559130782431, 'Total loss': 0.4638559130782431} | train loss {'Reaction outcome loss': 0.37627781625942663, 'Total loss': 0.37627781625942663}
2022-11-28 01:27:58,421 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:58,421 INFO:     Epoch: 16
2022-11-28 01:27:59,170 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45156120508909225, 'Total loss': 0.45156120508909225} | train loss {'Reaction outcome loss': 0.3564797588265859, 'Total loss': 0.3564797588265859}
2022-11-28 01:27:59,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:59,170 INFO:     Epoch: 17
2022-11-28 01:27:59,914 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4256554821675474, 'Total loss': 0.4256554821675474} | train loss {'Reaction outcome loss': 0.3645623661728523, 'Total loss': 0.3645623661728523}
2022-11-28 01:27:59,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:27:59,914 INFO:     Epoch: 18
2022-11-28 01:28:00,660 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4329110219735991, 'Total loss': 0.4329110219735991} | train loss {'Reaction outcome loss': 0.3564900073867578, 'Total loss': 0.3564900073867578}
2022-11-28 01:28:00,660 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:00,660 INFO:     Epoch: 19
2022-11-28 01:28:01,404 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4244264500554312, 'Total loss': 0.4244264500554312} | train loss {'Reaction outcome loss': 0.35032940884818314, 'Total loss': 0.35032940884818314}
2022-11-28 01:28:01,404 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:01,404 INFO:     Epoch: 20
2022-11-28 01:28:02,150 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4081971316852353, 'Total loss': 0.4081971316852353} | train loss {'Reaction outcome loss': 0.34811320596257683, 'Total loss': 0.34811320596257683}
2022-11-28 01:28:02,150 INFO:     Found new best model at epoch 20
2022-11-28 01:28:02,151 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:02,151 INFO:     Epoch: 21
2022-11-28 01:28:02,899 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43421777947382495, 'Total loss': 0.43421777947382495} | train loss {'Reaction outcome loss': 0.3524582230067446, 'Total loss': 0.3524582230067446}
2022-11-28 01:28:02,899 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:02,899 INFO:     Epoch: 22
2022-11-28 01:28:03,646 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42759634960781445, 'Total loss': 0.42759634960781445} | train loss {'Reaction outcome loss': 0.34736488601155124, 'Total loss': 0.34736488601155124}
2022-11-28 01:28:03,646 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:03,646 INFO:     Epoch: 23
2022-11-28 01:28:04,394 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.434993236918341, 'Total loss': 0.434993236918341} | train loss {'Reaction outcome loss': 0.3433435669372439, 'Total loss': 0.3433435669372439}
2022-11-28 01:28:04,395 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:04,395 INFO:     Epoch: 24
2022-11-28 01:28:05,143 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42123784734444186, 'Total loss': 0.42123784734444186} | train loss {'Reaction outcome loss': 0.35020391597800893, 'Total loss': 0.35020391597800893}
2022-11-28 01:28:05,144 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:05,144 INFO:     Epoch: 25
2022-11-28 01:28:05,893 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41728974506258965, 'Total loss': 0.41728974506258965} | train loss {'Reaction outcome loss': 0.34495689779065686, 'Total loss': 0.34495689779065686}
2022-11-28 01:28:05,893 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:05,893 INFO:     Epoch: 26
2022-11-28 01:28:06,639 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41926830295812, 'Total loss': 0.41926830295812} | train loss {'Reaction outcome loss': 0.3371129368661869, 'Total loss': 0.3371129368661869}
2022-11-28 01:28:06,639 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:06,639 INFO:     Epoch: 27
2022-11-28 01:28:07,388 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44562381031838333, 'Total loss': 0.44562381031838333} | train loss {'Reaction outcome loss': 0.3416632229258657, 'Total loss': 0.3416632229258657}
2022-11-28 01:28:07,388 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:07,388 INFO:     Epoch: 28
2022-11-28 01:28:08,133 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4629740748893131, 'Total loss': 0.4629740748893131} | train loss {'Reaction outcome loss': 0.3542824054536549, 'Total loss': 0.3542824054536549}
2022-11-28 01:28:08,133 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:08,133 INFO:     Epoch: 29
2022-11-28 01:28:08,882 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4582905938679522, 'Total loss': 0.4582905938679522} | train loss {'Reaction outcome loss': 0.33689522126648075, 'Total loss': 0.33689522126648075}
2022-11-28 01:28:08,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:08,882 INFO:     Epoch: 30
2022-11-28 01:28:09,625 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42791556092825805, 'Total loss': 0.42791556092825805} | train loss {'Reaction outcome loss': 0.33068520203232765, 'Total loss': 0.33068520203232765}
2022-11-28 01:28:09,625 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:09,625 INFO:     Epoch: 31
2022-11-28 01:28:10,374 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45035218955440953, 'Total loss': 0.45035218955440953} | train loss {'Reaction outcome loss': 0.33441851095028735, 'Total loss': 0.33441851095028735}
2022-11-28 01:28:10,374 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:10,374 INFO:     Epoch: 32
2022-11-28 01:28:11,121 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3946328451010314, 'Total loss': 0.3946328451010314} | train loss {'Reaction outcome loss': 0.3487186413786189, 'Total loss': 0.3487186413786189}
2022-11-28 01:28:11,122 INFO:     Found new best model at epoch 32
2022-11-28 01:28:11,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:11,123 INFO:     Epoch: 33
2022-11-28 01:28:11,870 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4145986986431209, 'Total loss': 0.4145986986431209} | train loss {'Reaction outcome loss': 0.3365301232830233, 'Total loss': 0.3365301232830233}
2022-11-28 01:28:11,870 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:11,871 INFO:     Epoch: 34
2022-11-28 01:28:12,616 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43321536074985156, 'Total loss': 0.43321536074985156} | train loss {'Reaction outcome loss': 0.33868035345492875, 'Total loss': 0.33868035345492875}
2022-11-28 01:28:12,617 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:12,617 INFO:     Epoch: 35
2022-11-28 01:28:13,365 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43754271214658563, 'Total loss': 0.43754271214658563} | train loss {'Reaction outcome loss': 0.3360517723900586, 'Total loss': 0.3360517723900586}
2022-11-28 01:28:13,365 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:13,365 INFO:     Epoch: 36
2022-11-28 01:28:14,112 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45139472592960705, 'Total loss': 0.45139472592960705} | train loss {'Reaction outcome loss': 0.35801402319539416, 'Total loss': 0.35801402319539416}
2022-11-28 01:28:14,113 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:14,113 INFO:     Epoch: 37
2022-11-28 01:28:14,864 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42464912648905406, 'Total loss': 0.42464912648905406} | train loss {'Reaction outcome loss': 0.3554722841994965, 'Total loss': 0.3554722841994965}
2022-11-28 01:28:14,865 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:14,865 INFO:     Epoch: 38
2022-11-28 01:28:15,610 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42086596312848007, 'Total loss': 0.42086596312848007} | train loss {'Reaction outcome loss': 0.3372975548178802, 'Total loss': 0.3372975548178802}
2022-11-28 01:28:15,610 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:15,610 INFO:     Epoch: 39
2022-11-28 01:28:16,358 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4067531136626547, 'Total loss': 0.4067531136626547} | train loss {'Reaction outcome loss': 0.33058879874375185, 'Total loss': 0.33058879874375185}
2022-11-28 01:28:16,358 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:16,358 INFO:     Epoch: 40
2022-11-28 01:28:17,113 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4798757034269246, 'Total loss': 0.4798757034269246} | train loss {'Reaction outcome loss': 0.3575747961759085, 'Total loss': 0.3575747961759085}
2022-11-28 01:28:17,113 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:17,113 INFO:     Epoch: 41
2022-11-28 01:28:17,865 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44398004053668544, 'Total loss': 0.44398004053668544} | train loss {'Reaction outcome loss': 0.3497135350631497, 'Total loss': 0.3497135350631497}
2022-11-28 01:28:17,865 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:17,865 INFO:     Epoch: 42
2022-11-28 01:28:18,617 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.429050549864769, 'Total loss': 0.429050549864769} | train loss {'Reaction outcome loss': 0.32822938800340723, 'Total loss': 0.32822938800340723}
2022-11-28 01:28:18,617 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:18,617 INFO:     Epoch: 43
2022-11-28 01:28:19,371 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4364009462296963, 'Total loss': 0.4364009462296963} | train loss {'Reaction outcome loss': 0.3458595957591949, 'Total loss': 0.3458595957591949}
2022-11-28 01:28:19,371 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:19,371 INFO:     Epoch: 44
2022-11-28 01:28:20,122 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4390582520176064, 'Total loss': 0.4390582520176064} | train loss {'Reaction outcome loss': 0.33794424189669403, 'Total loss': 0.33794424189669403}
2022-11-28 01:28:20,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:20,123 INFO:     Epoch: 45
2022-11-28 01:28:20,871 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46839185837994923, 'Total loss': 0.46839185837994923} | train loss {'Reaction outcome loss': 0.3364317176546826, 'Total loss': 0.3364317176546826}
2022-11-28 01:28:20,871 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:20,871 INFO:     Epoch: 46
2022-11-28 01:28:21,626 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43449219925837085, 'Total loss': 0.43449219925837085} | train loss {'Reaction outcome loss': 0.3265004848640955, 'Total loss': 0.3265004848640955}
2022-11-28 01:28:21,626 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:21,626 INFO:     Epoch: 47
2022-11-28 01:28:22,384 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44318767061287706, 'Total loss': 0.44318767061287706} | train loss {'Reaction outcome loss': 0.3182823286412533, 'Total loss': 0.3182823286412533}
2022-11-28 01:28:22,384 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:22,385 INFO:     Epoch: 48
2022-11-28 01:28:23,138 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.438021992417899, 'Total loss': 0.438021992417899} | train loss {'Reaction outcome loss': 0.32135452100863826, 'Total loss': 0.32135452100863826}
2022-11-28 01:28:23,139 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:23,139 INFO:     Epoch: 49
2022-11-28 01:28:23,887 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4549261622808196, 'Total loss': 0.4549261622808196} | train loss {'Reaction outcome loss': 0.33174518178153956, 'Total loss': 0.33174518178153956}
2022-11-28 01:28:23,887 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:23,887 INFO:     Epoch: 50
2022-11-28 01:28:24,643 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4252185043455525, 'Total loss': 0.4252185043455525} | train loss {'Reaction outcome loss': 0.3256089709339068, 'Total loss': 0.3256089709339068}
2022-11-28 01:28:24,643 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:24,643 INFO:     Epoch: 51
2022-11-28 01:28:25,395 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4655566076663407, 'Total loss': 0.4655566076663407} | train loss {'Reaction outcome loss': 0.3232187806413724, 'Total loss': 0.3232187806413724}
2022-11-28 01:28:25,395 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:25,395 INFO:     Epoch: 52
2022-11-28 01:28:26,149 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43542014197869733, 'Total loss': 0.43542014197869733} | train loss {'Reaction outcome loss': 0.3485865567920179, 'Total loss': 0.3485865567920179}
2022-11-28 01:28:26,149 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:26,149 INFO:     Epoch: 53
2022-11-28 01:28:26,899 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4737780778245492, 'Total loss': 0.4737780778245492} | train loss {'Reaction outcome loss': 0.3232967131412946, 'Total loss': 0.3232967131412946}
2022-11-28 01:28:26,899 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:26,899 INFO:     Epoch: 54
2022-11-28 01:28:27,652 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4417634582654996, 'Total loss': 0.4417634582654996} | train loss {'Reaction outcome loss': 0.346447578325928, 'Total loss': 0.346447578325928}
2022-11-28 01:28:27,652 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:27,652 INFO:     Epoch: 55
2022-11-28 01:28:28,407 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4354140379212119, 'Total loss': 0.4354140379212119} | train loss {'Reaction outcome loss': 0.33685712046616784, 'Total loss': 0.33685712046616784}
2022-11-28 01:28:28,407 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:28,407 INFO:     Epoch: 56
2022-11-28 01:28:29,157 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4269454243846915, 'Total loss': 0.4269454243846915} | train loss {'Reaction outcome loss': 0.32347088762623094, 'Total loss': 0.32347088762623094}
2022-11-28 01:28:29,157 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:29,158 INFO:     Epoch: 57
2022-11-28 01:28:29,912 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4230380749160593, 'Total loss': 0.4230380749160593} | train loss {'Reaction outcome loss': 0.32880619751960644, 'Total loss': 0.32880619751960644}
2022-11-28 01:28:29,912 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:29,912 INFO:     Epoch: 58
2022-11-28 01:28:30,666 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4294594235040925, 'Total loss': 0.4294594235040925} | train loss {'Reaction outcome loss': 0.3286547642276596, 'Total loss': 0.3286547642276596}
2022-11-28 01:28:30,666 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:30,666 INFO:     Epoch: 59
2022-11-28 01:28:31,419 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44241736355153, 'Total loss': 0.44241736355153} | train loss {'Reaction outcome loss': 0.32824286732536095, 'Total loss': 0.32824286732536095}
2022-11-28 01:28:31,420 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:31,420 INFO:     Epoch: 60
2022-11-28 01:28:32,170 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5185062451796099, 'Total loss': 0.5185062451796099} | train loss {'Reaction outcome loss': 0.317282771593646, 'Total loss': 0.317282771593646}
2022-11-28 01:28:32,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:32,170 INFO:     Epoch: 61
2022-11-28 01:28:32,923 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43056162853132596, 'Total loss': 0.43056162853132596} | train loss {'Reaction outcome loss': 0.32345521413845574, 'Total loss': 0.32345521413845574}
2022-11-28 01:28:32,923 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:32,923 INFO:     Epoch: 62
2022-11-28 01:28:33,679 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43483607640320604, 'Total loss': 0.43483607640320604} | train loss {'Reaction outcome loss': 0.32228329129185274, 'Total loss': 0.32228329129185274}
2022-11-28 01:28:33,679 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:33,679 INFO:     Epoch: 63
2022-11-28 01:28:34,430 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4204292351549322, 'Total loss': 0.4204292351549322} | train loss {'Reaction outcome loss': 0.3297663505381418, 'Total loss': 0.3297663505381418}
2022-11-28 01:28:34,430 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:34,430 INFO:     Epoch: 64
2022-11-28 01:28:35,182 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4058649218217893, 'Total loss': 0.4058649218217893} | train loss {'Reaction outcome loss': 0.32822770676632157, 'Total loss': 0.32822770676632157}
2022-11-28 01:28:35,183 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:35,183 INFO:     Epoch: 65
2022-11-28 01:28:35,934 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4615723216398196, 'Total loss': 0.4615723216398196} | train loss {'Reaction outcome loss': 0.32135461961571504, 'Total loss': 0.32135461961571504}
2022-11-28 01:28:35,934 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:35,934 INFO:     Epoch: 66
2022-11-28 01:28:36,688 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42983549731698906, 'Total loss': 0.42983549731698906} | train loss {'Reaction outcome loss': 0.315247356234616, 'Total loss': 0.315247356234616}
2022-11-28 01:28:36,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:36,688 INFO:     Epoch: 67
2022-11-28 01:28:37,442 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4202992221848531, 'Total loss': 0.4202992221848531} | train loss {'Reaction outcome loss': 0.3163664972914858, 'Total loss': 0.3163664972914858}
2022-11-28 01:28:37,443 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:37,443 INFO:     Epoch: 68
2022-11-28 01:28:38,190 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4082209992815148, 'Total loss': 0.4082209992815148} | train loss {'Reaction outcome loss': 0.31392400914346913, 'Total loss': 0.31392400914346913}
2022-11-28 01:28:38,190 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:38,190 INFO:     Epoch: 69
2022-11-28 01:28:38,938 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4300609471445734, 'Total loss': 0.4300609471445734} | train loss {'Reaction outcome loss': 0.31753656139921566, 'Total loss': 0.31753656139921566}
2022-11-28 01:28:38,938 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:38,938 INFO:     Epoch: 70
2022-11-28 01:28:39,688 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.403381674465808, 'Total loss': 0.403381674465808} | train loss {'Reaction outcome loss': 0.32587863722069543, 'Total loss': 0.32587863722069543}
2022-11-28 01:28:39,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:39,688 INFO:     Epoch: 71
2022-11-28 01:28:40,438 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4458453211594712, 'Total loss': 0.4458453211594712} | train loss {'Reaction outcome loss': 0.33438326973422816, 'Total loss': 0.33438326973422816}
2022-11-28 01:28:40,439 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:40,439 INFO:     Epoch: 72
2022-11-28 01:28:41,187 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4167421328073198, 'Total loss': 0.4167421328073198} | train loss {'Reaction outcome loss': 0.31877795640315093, 'Total loss': 0.31877795640315093}
2022-11-28 01:28:41,187 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:41,187 INFO:     Epoch: 73
2022-11-28 01:28:41,934 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44624735110185365, 'Total loss': 0.44624735110185365} | train loss {'Reaction outcome loss': 0.31318965617582384, 'Total loss': 0.31318965617582384}
2022-11-28 01:28:41,934 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:41,934 INFO:     Epoch: 74
2022-11-28 01:28:42,683 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4289376630701802, 'Total loss': 0.4289376630701802} | train loss {'Reaction outcome loss': 0.31304469770989435, 'Total loss': 0.31304469770989435}
2022-11-28 01:28:42,683 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:42,683 INFO:     Epoch: 75
2022-11-28 01:28:43,431 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4186169389973987, 'Total loss': 0.4186169389973987} | train loss {'Reaction outcome loss': 0.30296124454572615, 'Total loss': 0.30296124454572615}
2022-11-28 01:28:43,431 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:43,431 INFO:     Epoch: 76
2022-11-28 01:28:44,178 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4393256316808137, 'Total loss': 0.4393256316808137} | train loss {'Reaction outcome loss': 0.32387167947208473, 'Total loss': 0.32387167947208473}
2022-11-28 01:28:44,178 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:44,178 INFO:     Epoch: 77
2022-11-28 01:28:44,925 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45235040834681556, 'Total loss': 0.45235040834681556} | train loss {'Reaction outcome loss': 0.320881549374536, 'Total loss': 0.320881549374536}
2022-11-28 01:28:44,925 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:44,925 INFO:     Epoch: 78
2022-11-28 01:28:45,674 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42358144745230675, 'Total loss': 0.42358144745230675} | train loss {'Reaction outcome loss': 0.3224083717496734, 'Total loss': 0.3224083717496734}
2022-11-28 01:28:45,675 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:45,675 INFO:     Epoch: 79
2022-11-28 01:28:46,424 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4242936653847044, 'Total loss': 0.4242936653847044} | train loss {'Reaction outcome loss': 0.32393917041691206, 'Total loss': 0.32393917041691206}
2022-11-28 01:28:46,424 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:46,424 INFO:     Epoch: 80
2022-11-28 01:28:47,176 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4059004116464745, 'Total loss': 0.4059004116464745} | train loss {'Reaction outcome loss': 0.3197904064165436, 'Total loss': 0.3197904064165436}
2022-11-28 01:28:47,176 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:47,176 INFO:     Epoch: 81
2022-11-28 01:28:47,923 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44398291629146447, 'Total loss': 0.44398291629146447} | train loss {'Reaction outcome loss': 0.32319912585893623, 'Total loss': 0.32319912585893623}
2022-11-28 01:28:47,924 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:47,924 INFO:     Epoch: 82
2022-11-28 01:28:48,677 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43894346024502406, 'Total loss': 0.43894346024502406} | train loss {'Reaction outcome loss': 0.3197290747452844, 'Total loss': 0.3197290747452844}
2022-11-28 01:28:48,677 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:48,677 INFO:     Epoch: 83
2022-11-28 01:28:49,430 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3980375961823897, 'Total loss': 0.3980375961823897} | train loss {'Reaction outcome loss': 0.32831902669267615, 'Total loss': 0.32831902669267615}
2022-11-28 01:28:49,430 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:49,431 INFO:     Epoch: 84
2022-11-28 01:28:50,184 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41976995867761696, 'Total loss': 0.41976995867761696} | train loss {'Reaction outcome loss': 0.30492212176926226, 'Total loss': 0.30492212176926226}
2022-11-28 01:28:50,184 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:50,184 INFO:     Epoch: 85
2022-11-28 01:28:50,934 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42795914817940106, 'Total loss': 0.42795914817940106} | train loss {'Reaction outcome loss': 0.32168930980116733, 'Total loss': 0.32168930980116733}
2022-11-28 01:28:50,934 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:50,934 INFO:     Epoch: 86
2022-11-28 01:28:51,684 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3991614122959701, 'Total loss': 0.3991614122959701} | train loss {'Reaction outcome loss': 0.3019870064279766, 'Total loss': 0.3019870064279766}
2022-11-28 01:28:51,684 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:51,684 INFO:     Epoch: 87
2022-11-28 01:28:52,433 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4081788638775999, 'Total loss': 0.4081788638775999} | train loss {'Reaction outcome loss': 0.30765977194193406, 'Total loss': 0.30765977194193406}
2022-11-28 01:28:52,434 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:52,434 INFO:     Epoch: 88
2022-11-28 01:28:53,186 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42837153375148773, 'Total loss': 0.42837153375148773} | train loss {'Reaction outcome loss': 0.31374428763435136, 'Total loss': 0.31374428763435136}
2022-11-28 01:28:53,186 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:53,186 INFO:     Epoch: 89
2022-11-28 01:28:53,938 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4485827532004226, 'Total loss': 0.4485827532004226} | train loss {'Reaction outcome loss': 0.3127685538248012, 'Total loss': 0.3127685538248012}
2022-11-28 01:28:53,939 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:53,939 INFO:     Epoch: 90
2022-11-28 01:28:54,690 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4181286492808299, 'Total loss': 0.4181286492808299} | train loss {'Reaction outcome loss': 0.32400032384735855, 'Total loss': 0.32400032384735855}
2022-11-28 01:28:54,690 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:54,690 INFO:     Epoch: 91
2022-11-28 01:28:55,450 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43426941775462846, 'Total loss': 0.43426941775462846} | train loss {'Reaction outcome loss': 0.31755995001598647, 'Total loss': 0.31755995001598647}
2022-11-28 01:28:55,450 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:55,450 INFO:     Epoch: 92
2022-11-28 01:28:56,202 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45552628859877586, 'Total loss': 0.45552628859877586} | train loss {'Reaction outcome loss': 0.3118623080338174, 'Total loss': 0.3118623080338174}
2022-11-28 01:28:56,202 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:56,202 INFO:     Epoch: 93
2022-11-28 01:28:56,958 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41003120826049283, 'Total loss': 0.41003120826049283} | train loss {'Reaction outcome loss': 0.30809011040368545, 'Total loss': 0.30809011040368545}
2022-11-28 01:28:56,959 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:56,959 INFO:     Epoch: 94
2022-11-28 01:28:57,713 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4117094207216393, 'Total loss': 0.4117094207216393} | train loss {'Reaction outcome loss': 0.31389976374292183, 'Total loss': 0.31389976374292183}
2022-11-28 01:28:57,713 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:57,713 INFO:     Epoch: 95
2022-11-28 01:28:58,465 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4505111967975443, 'Total loss': 0.4505111967975443} | train loss {'Reaction outcome loss': 0.32198977624235847, 'Total loss': 0.32198977624235847}
2022-11-28 01:28:58,465 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:58,465 INFO:     Epoch: 96
2022-11-28 01:28:59,210 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42595824192870746, 'Total loss': 0.42595824192870746} | train loss {'Reaction outcome loss': 0.31638220145634793, 'Total loss': 0.31638220145634793}
2022-11-28 01:28:59,210 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:59,210 INFO:     Epoch: 97
2022-11-28 01:28:59,961 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40349277887832036, 'Total loss': 0.40349277887832036} | train loss {'Reaction outcome loss': 0.3154208398601304, 'Total loss': 0.3154208398601304}
2022-11-28 01:28:59,962 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:28:59,962 INFO:     Epoch: 98
2022-11-28 01:29:00,708 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39949178052219475, 'Total loss': 0.39949178052219475} | train loss {'Reaction outcome loss': 0.31951632365388305, 'Total loss': 0.31951632365388305}
2022-11-28 01:29:00,708 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:00,708 INFO:     Epoch: 99
2022-11-28 01:29:01,455 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42878739874471317, 'Total loss': 0.42878739874471317} | train loss {'Reaction outcome loss': 0.3051200155058012, 'Total loss': 0.3051200155058012}
2022-11-28 01:29:01,455 INFO:     Best model found after epoch 33 of 100.
2022-11-28 01:29:01,455 INFO:   Done with stage: TRAINING
2022-11-28 01:29:01,455 INFO:   Starting stage: EVALUATION
2022-11-28 01:29:01,576 INFO:   Done with stage: EVALUATION
2022-11-28 01:29:01,584 INFO:   Leaving out SEQ value Fold_0
2022-11-28 01:29:01,598 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 01:29:01,598 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:29:02,242 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:29:02,242 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:29:02,312 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:29:02,312 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:29:02,312 INFO:     No hyperparam tuning for this model
2022-11-28 01:29:02,312 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:29:02,313 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:29:02,313 INFO:     None feature selector for col prot
2022-11-28 01:29:02,313 INFO:     None feature selector for col prot
2022-11-28 01:29:02,313 INFO:     None feature selector for col prot
2022-11-28 01:29:02,314 INFO:     None feature selector for col chem
2022-11-28 01:29:02,314 INFO:     None feature selector for col chem
2022-11-28 01:29:02,314 INFO:     None feature selector for col chem
2022-11-28 01:29:02,314 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:29:02,314 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:29:02,316 INFO:     Number of params in model 169741
2022-11-28 01:29:02,319 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:29:02,319 INFO:   Starting stage: TRAINING
2022-11-28 01:29:02,373 INFO:     Val loss before train {'Reaction outcome loss': 0.95298406007615, 'Total loss': 0.95298406007615}
2022-11-28 01:29:02,373 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:02,373 INFO:     Epoch: 0
2022-11-28 01:29:03,122 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5193720331246202, 'Total loss': 0.5193720331246202} | train loss {'Reaction outcome loss': 0.6538292649183196, 'Total loss': 0.6538292649183196}
2022-11-28 01:29:03,122 INFO:     Found new best model at epoch 0
2022-11-28 01:29:03,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:03,123 INFO:     Epoch: 1
2022-11-28 01:29:03,871 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48103839599273424, 'Total loss': 0.48103839599273424} | train loss {'Reaction outcome loss': 0.5027577577211596, 'Total loss': 0.5027577577211596}
2022-11-28 01:29:03,871 INFO:     Found new best model at epoch 1
2022-11-28 01:29:03,872 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:03,872 INFO:     Epoch: 2
2022-11-28 01:29:04,619 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.450904424556277, 'Total loss': 0.450904424556277} | train loss {'Reaction outcome loss': 0.4560570354433919, 'Total loss': 0.4560570354433919}
2022-11-28 01:29:04,619 INFO:     Found new best model at epoch 2
2022-11-28 01:29:04,620 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:04,620 INFO:     Epoch: 3
2022-11-28 01:29:05,367 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4544405435973948, 'Total loss': 0.4544405435973948} | train loss {'Reaction outcome loss': 0.43886920622727166, 'Total loss': 0.43886920622727166}
2022-11-28 01:29:05,367 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:05,367 INFO:     Epoch: 4
2022-11-28 01:29:06,117 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44758240099657665, 'Total loss': 0.44758240099657665} | train loss {'Reaction outcome loss': 0.4282033169860782, 'Total loss': 0.4282033169860782}
2022-11-28 01:29:06,118 INFO:     Found new best model at epoch 4
2022-11-28 01:29:06,119 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:06,119 INFO:     Epoch: 5
2022-11-28 01:29:06,872 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4615038651973009, 'Total loss': 0.4615038651973009} | train loss {'Reaction outcome loss': 0.41193690974461405, 'Total loss': 0.41193690974461405}
2022-11-28 01:29:06,872 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:06,872 INFO:     Epoch: 6
2022-11-28 01:29:07,623 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4398139989511533, 'Total loss': 0.4398139989511533} | train loss {'Reaction outcome loss': 0.4176023468179138, 'Total loss': 0.4176023468179138}
2022-11-28 01:29:07,623 INFO:     Found new best model at epoch 6
2022-11-28 01:29:07,624 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:07,624 INFO:     Epoch: 7
2022-11-28 01:29:08,372 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47618417170914734, 'Total loss': 0.47618417170914734} | train loss {'Reaction outcome loss': 0.3967329496555483, 'Total loss': 0.3967329496555483}
2022-11-28 01:29:08,372 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:08,372 INFO:     Epoch: 8
2022-11-28 01:29:09,119 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4486792524429885, 'Total loss': 0.4486792524429885} | train loss {'Reaction outcome loss': 0.3948978118085668, 'Total loss': 0.3948978118085668}
2022-11-28 01:29:09,119 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:09,119 INFO:     Epoch: 9
2022-11-28 01:29:09,867 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43767100877382537, 'Total loss': 0.43767100877382537} | train loss {'Reaction outcome loss': 0.38061209448315353, 'Total loss': 0.38061209448315353}
2022-11-28 01:29:09,867 INFO:     Found new best model at epoch 9
2022-11-28 01:29:09,868 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:09,868 INFO:     Epoch: 10
2022-11-28 01:29:10,619 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4440334886312485, 'Total loss': 0.4440334886312485} | train loss {'Reaction outcome loss': 0.3739659598753279, 'Total loss': 0.3739659598753279}
2022-11-28 01:29:10,620 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:10,620 INFO:     Epoch: 11
2022-11-28 01:29:11,369 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41380997306921263, 'Total loss': 0.41380997306921263} | train loss {'Reaction outcome loss': 0.3737468510142222, 'Total loss': 0.3737468510142222}
2022-11-28 01:29:11,369 INFO:     Found new best model at epoch 11
2022-11-28 01:29:11,370 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:11,370 INFO:     Epoch: 12
2022-11-28 01:29:12,119 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4112061814151027, 'Total loss': 0.4112061814151027} | train loss {'Reaction outcome loss': 0.3705252708512762, 'Total loss': 0.3705252708512762}
2022-11-28 01:29:12,120 INFO:     Found new best model at epoch 12
2022-11-28 01:29:12,120 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:12,121 INFO:     Epoch: 13
2022-11-28 01:29:12,872 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.450154745104638, 'Total loss': 0.450154745104638} | train loss {'Reaction outcome loss': 0.36349229057044213, 'Total loss': 0.36349229057044213}
2022-11-28 01:29:12,872 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:12,872 INFO:     Epoch: 14
2022-11-28 01:29:13,619 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4107364978302609, 'Total loss': 0.4107364978302609} | train loss {'Reaction outcome loss': 0.3693334280177649, 'Total loss': 0.3693334280177649}
2022-11-28 01:29:13,619 INFO:     Found new best model at epoch 14
2022-11-28 01:29:13,620 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:13,620 INFO:     Epoch: 15
2022-11-28 01:29:14,372 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3947449211369861, 'Total loss': 0.3947449211369861} | train loss {'Reaction outcome loss': 0.3708650337349292, 'Total loss': 0.3708650337349292}
2022-11-28 01:29:14,372 INFO:     Found new best model at epoch 15
2022-11-28 01:29:14,373 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:14,373 INFO:     Epoch: 16
2022-11-28 01:29:15,119 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44896087693897163, 'Total loss': 0.44896087693897163} | train loss {'Reaction outcome loss': 0.35739331007727726, 'Total loss': 0.35739331007727726}
2022-11-28 01:29:15,119 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:15,119 INFO:     Epoch: 17
2022-11-28 01:29:15,867 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40092298930341547, 'Total loss': 0.40092298930341547} | train loss {'Reaction outcome loss': 0.3559011740964434, 'Total loss': 0.3559011740964434}
2022-11-28 01:29:15,867 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:15,867 INFO:     Epoch: 18
2022-11-28 01:29:16,618 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4323763468048789, 'Total loss': 0.4323763468048789} | train loss {'Reaction outcome loss': 0.3458009782484789, 'Total loss': 0.3458009782484789}
2022-11-28 01:29:16,618 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:16,618 INFO:     Epoch: 19
2022-11-28 01:29:17,366 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41665484349836, 'Total loss': 0.41665484349836} | train loss {'Reaction outcome loss': 0.35154542483781515, 'Total loss': 0.35154542483781515}
2022-11-28 01:29:17,366 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:17,367 INFO:     Epoch: 20
2022-11-28 01:29:18,114 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4030523147772659, 'Total loss': 0.4030523147772659} | train loss {'Reaction outcome loss': 0.34883359153019755, 'Total loss': 0.34883359153019755}
2022-11-28 01:29:18,114 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:18,114 INFO:     Epoch: 21
2022-11-28 01:29:18,863 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40942045978524466, 'Total loss': 0.40942045978524466} | train loss {'Reaction outcome loss': 0.35415570823822606, 'Total loss': 0.35415570823822606}
2022-11-28 01:29:18,863 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:18,863 INFO:     Epoch: 22
2022-11-28 01:29:19,610 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43126540969718585, 'Total loss': 0.43126540969718585} | train loss {'Reaction outcome loss': 0.3391771917702698, 'Total loss': 0.3391771917702698}
2022-11-28 01:29:19,610 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:19,610 INFO:     Epoch: 23
2022-11-28 01:29:20,356 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40159467540004035, 'Total loss': 0.40159467540004035} | train loss {'Reaction outcome loss': 0.3498399328546003, 'Total loss': 0.3498399328546003}
2022-11-28 01:29:20,356 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:20,356 INFO:     Epoch: 24
2022-11-28 01:29:21,104 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4282034920020537, 'Total loss': 0.4282034920020537} | train loss {'Reaction outcome loss': 0.3390773372490879, 'Total loss': 0.3390773372490879}
2022-11-28 01:29:21,104 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:21,104 INFO:     Epoch: 25
2022-11-28 01:29:21,861 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40809960527853534, 'Total loss': 0.40809960527853534} | train loss {'Reaction outcome loss': 0.3598694679466819, 'Total loss': 0.3598694679466819}
2022-11-28 01:29:21,861 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:21,861 INFO:     Epoch: 26
2022-11-28 01:29:22,611 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4088737931610508, 'Total loss': 0.4088737931610508} | train loss {'Reaction outcome loss': 0.33497072315891746, 'Total loss': 0.33497072315891746}
2022-11-28 01:29:22,611 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:22,611 INFO:     Epoch: 27
2022-11-28 01:29:23,357 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41877295110713353, 'Total loss': 0.41877295110713353} | train loss {'Reaction outcome loss': 0.35829668715294555, 'Total loss': 0.35829668715294555}
2022-11-28 01:29:23,357 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:23,358 INFO:     Epoch: 28
2022-11-28 01:29:24,101 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43099854209206323, 'Total loss': 0.43099854209206323} | train loss {'Reaction outcome loss': 0.34648496835579273, 'Total loss': 0.34648496835579273}
2022-11-28 01:29:24,101 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:24,102 INFO:     Epoch: 29
2022-11-28 01:29:24,849 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4273985857143998, 'Total loss': 0.4273985857143998} | train loss {'Reaction outcome loss': 0.3283309706973161, 'Total loss': 0.3283309706973161}
2022-11-28 01:29:24,850 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:24,850 INFO:     Epoch: 30
2022-11-28 01:29:25,596 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40179876051843166, 'Total loss': 0.40179876051843166} | train loss {'Reaction outcome loss': 0.3505788463948347, 'Total loss': 0.3505788463948347}
2022-11-28 01:29:25,596 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:25,596 INFO:     Epoch: 31
2022-11-28 01:29:26,355 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42019672793420876, 'Total loss': 0.42019672793420876} | train loss {'Reaction outcome loss': 0.3372489153614894, 'Total loss': 0.3372489153614894}
2022-11-28 01:29:26,356 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:26,356 INFO:     Epoch: 32
2022-11-28 01:29:27,120 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39513957635922864, 'Total loss': 0.39513957635922864} | train loss {'Reaction outcome loss': 0.3481394976588637, 'Total loss': 0.3481394976588637}
2022-11-28 01:29:27,120 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:27,120 INFO:     Epoch: 33
2022-11-28 01:29:27,884 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43582505275580014, 'Total loss': 0.43582505275580014} | train loss {'Reaction outcome loss': 0.333347518464573, 'Total loss': 0.333347518464573}
2022-11-28 01:29:27,884 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:27,884 INFO:     Epoch: 34
2022-11-28 01:29:28,643 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4565534378317269, 'Total loss': 0.4565534378317269} | train loss {'Reaction outcome loss': 0.33248311195235986, 'Total loss': 0.33248311195235986}
2022-11-28 01:29:28,643 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:28,643 INFO:     Epoch: 35
2022-11-28 01:29:29,406 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39925461465662176, 'Total loss': 0.39925461465662176} | train loss {'Reaction outcome loss': 0.3337106665799975, 'Total loss': 0.3337106665799975}
2022-11-28 01:29:29,406 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:29,406 INFO:     Epoch: 36
2022-11-28 01:29:30,168 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39647366191175853, 'Total loss': 0.39647366191175853} | train loss {'Reaction outcome loss': 0.34287309628507867, 'Total loss': 0.34287309628507867}
2022-11-28 01:29:30,168 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:30,168 INFO:     Epoch: 37
2022-11-28 01:29:30,928 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4214886352419853, 'Total loss': 0.4214886352419853} | train loss {'Reaction outcome loss': 0.3262113375765524, 'Total loss': 0.3262113375765524}
2022-11-28 01:29:30,928 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:30,928 INFO:     Epoch: 38
2022-11-28 01:29:31,688 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4298426366665147, 'Total loss': 0.4298426366665147} | train loss {'Reaction outcome loss': 0.31936526560952305, 'Total loss': 0.31936526560952305}
2022-11-28 01:29:31,689 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:31,689 INFO:     Epoch: 39
2022-11-28 01:29:32,449 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45893718708645215, 'Total loss': 0.45893718708645215} | train loss {'Reaction outcome loss': 0.3299708512007459, 'Total loss': 0.3299708512007459}
2022-11-28 01:29:32,449 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:32,449 INFO:     Epoch: 40
2022-11-28 01:29:33,212 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4404858106916601, 'Total loss': 0.4404858106916601} | train loss {'Reaction outcome loss': 0.32652970373268553, 'Total loss': 0.32652970373268553}
2022-11-28 01:29:33,212 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:33,212 INFO:     Epoch: 41
2022-11-28 01:29:33,980 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4066557084972208, 'Total loss': 0.4066557084972208} | train loss {'Reaction outcome loss': 0.34650890541221446, 'Total loss': 0.34650890541221446}
2022-11-28 01:29:33,980 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:33,980 INFO:     Epoch: 42
2022-11-28 01:29:34,743 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4188355840742588, 'Total loss': 0.4188355840742588} | train loss {'Reaction outcome loss': 0.3305399064351673, 'Total loss': 0.3305399064351673}
2022-11-28 01:29:34,743 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:34,743 INFO:     Epoch: 43
2022-11-28 01:29:35,506 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4262129930271344, 'Total loss': 0.4262129930271344} | train loss {'Reaction outcome loss': 0.3897232311042044, 'Total loss': 0.3897232311042044}
2022-11-28 01:29:35,507 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:35,507 INFO:     Epoch: 44
2022-11-28 01:29:36,273 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46925047818909993, 'Total loss': 0.46925047818909993} | train loss {'Reaction outcome loss': 0.34844716047106483, 'Total loss': 0.34844716047106483}
2022-11-28 01:29:36,273 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:36,273 INFO:     Epoch: 45
2022-11-28 01:29:37,039 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40214643017812207, 'Total loss': 0.40214643017812207} | train loss {'Reaction outcome loss': 0.3532543170156508, 'Total loss': 0.3532543170156508}
2022-11-28 01:29:37,040 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:37,040 INFO:     Epoch: 46
2022-11-28 01:29:37,804 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4400687048381025, 'Total loss': 0.4400687048381025} | train loss {'Reaction outcome loss': 0.3440836284927994, 'Total loss': 0.3440836284927994}
2022-11-28 01:29:37,804 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:37,804 INFO:     Epoch: 47
2022-11-28 01:29:38,570 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39941515519537707, 'Total loss': 0.39941515519537707} | train loss {'Reaction outcome loss': 0.35019270119517437, 'Total loss': 0.35019270119517437}
2022-11-28 01:29:38,570 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:38,570 INFO:     Epoch: 48
2022-11-28 01:29:39,333 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39930825849825685, 'Total loss': 0.39930825849825685} | train loss {'Reaction outcome loss': 0.33589537315040463, 'Total loss': 0.33589537315040463}
2022-11-28 01:29:39,333 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:39,333 INFO:     Epoch: 49
2022-11-28 01:29:40,099 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4868624559180303, 'Total loss': 0.4868624559180303} | train loss {'Reaction outcome loss': 0.32521283846755744, 'Total loss': 0.32521283846755744}
2022-11-28 01:29:40,099 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:40,099 INFO:     Epoch: 50
2022-11-28 01:29:40,860 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4035512635653669, 'Total loss': 0.4035512635653669} | train loss {'Reaction outcome loss': 0.3335850412244739, 'Total loss': 0.3335850412244739}
2022-11-28 01:29:40,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:40,860 INFO:     Epoch: 51
2022-11-28 01:29:41,622 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42612272399393, 'Total loss': 0.42612272399393} | train loss {'Reaction outcome loss': 0.32706852147152066, 'Total loss': 0.32706852147152066}
2022-11-28 01:29:41,622 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:41,622 INFO:     Epoch: 52
2022-11-28 01:29:42,385 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40697483108802274, 'Total loss': 0.40697483108802274} | train loss {'Reaction outcome loss': 0.3196767671045523, 'Total loss': 0.3196767671045523}
2022-11-28 01:29:42,385 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:42,385 INFO:     Epoch: 53
2022-11-28 01:29:43,147 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4170610650696538, 'Total loss': 0.4170610650696538} | train loss {'Reaction outcome loss': 0.3228204613513792, 'Total loss': 0.3228204613513792}
2022-11-28 01:29:43,148 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:43,148 INFO:     Epoch: 54
2022-11-28 01:29:43,911 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4199618087573485, 'Total loss': 0.4199618087573485} | train loss {'Reaction outcome loss': 0.32862335277593085, 'Total loss': 0.32862335277593085}
2022-11-28 01:29:43,911 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:43,911 INFO:     Epoch: 55
2022-11-28 01:29:44,673 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3959822128103538, 'Total loss': 0.3959822128103538} | train loss {'Reaction outcome loss': 0.3384171233848039, 'Total loss': 0.3384171233848039}
2022-11-28 01:29:44,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:44,673 INFO:     Epoch: 56
2022-11-28 01:29:45,435 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40461878139864316, 'Total loss': 0.40461878139864316} | train loss {'Reaction outcome loss': 0.319302170986106, 'Total loss': 0.319302170986106}
2022-11-28 01:29:45,435 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:45,435 INFO:     Epoch: 57
2022-11-28 01:29:46,197 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4029044285416603, 'Total loss': 0.4029044285416603} | train loss {'Reaction outcome loss': 0.3371676628285574, 'Total loss': 0.3371676628285574}
2022-11-28 01:29:46,197 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:46,198 INFO:     Epoch: 58
2022-11-28 01:29:46,953 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4767352948811921, 'Total loss': 0.4767352948811921} | train loss {'Reaction outcome loss': 0.32963372561854387, 'Total loss': 0.32963372561854387}
2022-11-28 01:29:46,954 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:46,954 INFO:     Epoch: 59
2022-11-28 01:29:47,695 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39405759677968244, 'Total loss': 0.39405759677968244} | train loss {'Reaction outcome loss': 0.33375289457047036, 'Total loss': 0.33375289457047036}
2022-11-28 01:29:47,695 INFO:     Found new best model at epoch 59
2022-11-28 01:29:47,696 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:47,696 INFO:     Epoch: 60
2022-11-28 01:29:48,436 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40520563315261493, 'Total loss': 0.40520563315261493} | train loss {'Reaction outcome loss': 0.33785467281153325, 'Total loss': 0.33785467281153325}
2022-11-28 01:29:48,436 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:48,436 INFO:     Epoch: 61
2022-11-28 01:29:49,177 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40587870302525436, 'Total loss': 0.40587870302525436} | train loss {'Reaction outcome loss': 0.3567158511655051, 'Total loss': 0.3567158511655051}
2022-11-28 01:29:49,177 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:49,177 INFO:     Epoch: 62
2022-11-28 01:29:49,920 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40485359643670643, 'Total loss': 0.40485359643670643} | train loss {'Reaction outcome loss': 0.3423074090609191, 'Total loss': 0.3423074090609191}
2022-11-28 01:29:49,920 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:49,920 INFO:     Epoch: 63
2022-11-28 01:29:50,662 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40943631885403936, 'Total loss': 0.40943631885403936} | train loss {'Reaction outcome loss': 0.32610120971193196, 'Total loss': 0.32610120971193196}
2022-11-28 01:29:50,662 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:50,662 INFO:     Epoch: 64
2022-11-28 01:29:51,403 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4258805935017087, 'Total loss': 0.4258805935017087} | train loss {'Reaction outcome loss': 0.3224028798370709, 'Total loss': 0.3224028798370709}
2022-11-28 01:29:51,403 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:51,403 INFO:     Epoch: 65
2022-11-28 01:29:52,147 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4197788302871314, 'Total loss': 0.4197788302871314} | train loss {'Reaction outcome loss': 0.3191857273701714, 'Total loss': 0.3191857273701714}
2022-11-28 01:29:52,147 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:52,147 INFO:     Epoch: 66
2022-11-28 01:29:52,891 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4189215292307464, 'Total loss': 0.4189215292307464} | train loss {'Reaction outcome loss': 0.3246342691513691, 'Total loss': 0.3246342691513691}
2022-11-28 01:29:52,891 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:52,891 INFO:     Epoch: 67
2022-11-28 01:29:53,636 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.422768868167292, 'Total loss': 0.422768868167292} | train loss {'Reaction outcome loss': 0.3405773234572488, 'Total loss': 0.3405773234572488}
2022-11-28 01:29:53,636 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:53,636 INFO:     Epoch: 68
2022-11-28 01:29:54,380 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41398949785666034, 'Total loss': 0.41398949785666034} | train loss {'Reaction outcome loss': 0.36714912739842526, 'Total loss': 0.36714912739842526}
2022-11-28 01:29:54,380 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:54,380 INFO:     Epoch: 69
2022-11-28 01:29:55,123 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4660930559039116, 'Total loss': 0.4660930559039116} | train loss {'Reaction outcome loss': 0.3235875909265719, 'Total loss': 0.3235875909265719}
2022-11-28 01:29:55,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:55,123 INFO:     Epoch: 70
2022-11-28 01:29:55,867 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41935905746438285, 'Total loss': 0.41935905746438285} | train loss {'Reaction outcome loss': 0.33092026698105187, 'Total loss': 0.33092026698105187}
2022-11-28 01:29:55,867 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:55,867 INFO:     Epoch: 71
2022-11-28 01:29:56,608 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42316393283280457, 'Total loss': 0.42316393283280457} | train loss {'Reaction outcome loss': 0.3151304538009183, 'Total loss': 0.3151304538009183}
2022-11-28 01:29:56,608 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:56,608 INFO:     Epoch: 72
2022-11-28 01:29:57,347 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3905477137728171, 'Total loss': 0.3905477137728171} | train loss {'Reaction outcome loss': 0.3191931878446567, 'Total loss': 0.3191931878446567}
2022-11-28 01:29:57,347 INFO:     Found new best model at epoch 72
2022-11-28 01:29:57,347 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:57,348 INFO:     Epoch: 73
2022-11-28 01:29:58,091 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4140915686095303, 'Total loss': 0.4140915686095303} | train loss {'Reaction outcome loss': 0.31740359853395084, 'Total loss': 0.31740359853395084}
2022-11-28 01:29:58,092 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:58,092 INFO:     Epoch: 74
2022-11-28 01:29:58,837 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43609146689149464, 'Total loss': 0.43609146689149464} | train loss {'Reaction outcome loss': 0.31586592520779444, 'Total loss': 0.31586592520779444}
2022-11-28 01:29:58,837 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:58,837 INFO:     Epoch: 75
2022-11-28 01:29:59,579 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39455711909315805, 'Total loss': 0.39455711909315805} | train loss {'Reaction outcome loss': 0.3268866442475724, 'Total loss': 0.3268866442475724}
2022-11-28 01:29:59,579 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:29:59,579 INFO:     Epoch: 76
2022-11-28 01:30:00,318 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47094170579856093, 'Total loss': 0.47094170579856093} | train loss {'Reaction outcome loss': 0.31386527413057413, 'Total loss': 0.31386527413057413}
2022-11-28 01:30:00,319 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:00,319 INFO:     Epoch: 77
2022-11-28 01:30:01,064 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4137468993325125, 'Total loss': 0.4137468993325125} | train loss {'Reaction outcome loss': 0.314378601774151, 'Total loss': 0.314378601774151}
2022-11-28 01:30:01,064 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:01,064 INFO:     Epoch: 78
2022-11-28 01:30:01,808 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42013192329217086, 'Total loss': 0.42013192329217086} | train loss {'Reaction outcome loss': 0.3240171840738671, 'Total loss': 0.3240171840738671}
2022-11-28 01:30:01,808 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:01,808 INFO:     Epoch: 79
2022-11-28 01:30:02,549 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42316230826757173, 'Total loss': 0.42316230826757173} | train loss {'Reaction outcome loss': 0.33029543723051363, 'Total loss': 0.33029543723051363}
2022-11-28 01:30:02,549 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:02,549 INFO:     Epoch: 80
2022-11-28 01:30:03,289 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4187735197218982, 'Total loss': 0.4187735197218982} | train loss {'Reaction outcome loss': 0.32972463637379257, 'Total loss': 0.32972463637379257}
2022-11-28 01:30:03,289 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:03,289 INFO:     Epoch: 81
2022-11-28 01:30:04,031 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4046707810326056, 'Total loss': 0.4046707810326056} | train loss {'Reaction outcome loss': 0.32703066562954713, 'Total loss': 0.32703066562954713}
2022-11-28 01:30:04,031 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:04,031 INFO:     Epoch: 82
2022-11-28 01:30:04,775 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41289751942862163, 'Total loss': 0.41289751942862163} | train loss {'Reaction outcome loss': 0.3237012704293034, 'Total loss': 0.3237012704293034}
2022-11-28 01:30:04,775 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:04,775 INFO:     Epoch: 83
2022-11-28 01:30:05,519 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42397848313505, 'Total loss': 0.42397848313505} | train loss {'Reaction outcome loss': 0.31421439889592195, 'Total loss': 0.31421439889592195}
2022-11-28 01:30:05,519 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:05,519 INFO:     Epoch: 84
2022-11-28 01:30:06,258 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41439434234052896, 'Total loss': 0.41439434234052896} | train loss {'Reaction outcome loss': 0.31121829269747986, 'Total loss': 0.31121829269747986}
2022-11-28 01:30:06,259 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:06,259 INFO:     Epoch: 85
2022-11-28 01:30:07,001 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.403808228332888, 'Total loss': 0.403808228332888} | train loss {'Reaction outcome loss': 0.32826116614737494, 'Total loss': 0.32826116614737494}
2022-11-28 01:30:07,001 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:07,001 INFO:     Epoch: 86
2022-11-28 01:30:07,744 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44213386794382875, 'Total loss': 0.44213386794382875} | train loss {'Reaction outcome loss': 0.33485673168892804, 'Total loss': 0.33485673168892804}
2022-11-28 01:30:07,745 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:07,745 INFO:     Epoch: 87
2022-11-28 01:30:08,490 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3999819609929215, 'Total loss': 0.3999819609929215} | train loss {'Reaction outcome loss': 0.32921911976846907, 'Total loss': 0.32921911976846907}
2022-11-28 01:30:08,490 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:08,490 INFO:     Epoch: 88
2022-11-28 01:30:09,236 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39518610354174266, 'Total loss': 0.39518610354174266} | train loss {'Reaction outcome loss': 0.31334489050061115, 'Total loss': 0.31334489050061115}
2022-11-28 01:30:09,236 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:09,236 INFO:     Epoch: 89
2022-11-28 01:30:09,983 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41566592251712625, 'Total loss': 0.41566592251712625} | train loss {'Reaction outcome loss': 0.32096205591431515, 'Total loss': 0.32096205591431515}
2022-11-28 01:30:09,983 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:09,983 INFO:     Epoch: 90
2022-11-28 01:30:10,732 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41144221513108775, 'Total loss': 0.41144221513108775} | train loss {'Reaction outcome loss': 0.3150243323582869, 'Total loss': 0.3150243323582869}
2022-11-28 01:30:10,732 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:10,732 INFO:     Epoch: 91
2022-11-28 01:30:11,473 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43470141223885794, 'Total loss': 0.43470141223885794} | train loss {'Reaction outcome loss': 0.3139397111317889, 'Total loss': 0.3139397111317889}
2022-11-28 01:30:11,474 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:11,474 INFO:     Epoch: 92
2022-11-28 01:30:12,219 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41248363662849774, 'Total loss': 0.41248363662849774} | train loss {'Reaction outcome loss': 0.3199325245974759, 'Total loss': 0.3199325245974759}
2022-11-28 01:30:12,219 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:12,219 INFO:     Epoch: 93
2022-11-28 01:30:12,967 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3974068530581214, 'Total loss': 0.3974068530581214} | train loss {'Reaction outcome loss': 0.31228708864947563, 'Total loss': 0.31228708864947563}
2022-11-28 01:30:12,967 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:12,967 INFO:     Epoch: 94
2022-11-28 01:30:13,710 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42460761507126416, 'Total loss': 0.42460761507126416} | train loss {'Reaction outcome loss': 0.3231592176534869, 'Total loss': 0.3231592176534869}
2022-11-28 01:30:13,711 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:13,711 INFO:     Epoch: 95
2022-11-28 01:30:14,455 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43531293455849995, 'Total loss': 0.43531293455849995} | train loss {'Reaction outcome loss': 0.31213630868408543, 'Total loss': 0.31213630868408543}
2022-11-28 01:30:14,455 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:14,456 INFO:     Epoch: 96
2022-11-28 01:30:15,197 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42063953829082573, 'Total loss': 0.42063953829082573} | train loss {'Reaction outcome loss': 0.31023443018007074, 'Total loss': 0.31023443018007074}
2022-11-28 01:30:15,198 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:15,198 INFO:     Epoch: 97
2022-11-28 01:30:15,943 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4100905545055866, 'Total loss': 0.4100905545055866} | train loss {'Reaction outcome loss': 0.3126197411765454, 'Total loss': 0.3126197411765454}
2022-11-28 01:30:15,944 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:15,944 INFO:     Epoch: 98
2022-11-28 01:30:16,687 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4237288026647134, 'Total loss': 0.4237288026647134} | train loss {'Reaction outcome loss': 0.3139650228957416, 'Total loss': 0.3139650228957416}
2022-11-28 01:30:16,687 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:16,688 INFO:     Epoch: 99
2022-11-28 01:30:17,431 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4027556956491687, 'Total loss': 0.4027556956491687} | train loss {'Reaction outcome loss': 0.3232243081167348, 'Total loss': 0.3232243081167348}
2022-11-28 01:30:17,431 INFO:     Best model found after epoch 73 of 100.
2022-11-28 01:30:17,431 INFO:   Done with stage: TRAINING
2022-11-28 01:30:17,431 INFO:   Starting stage: EVALUATION
2022-11-28 01:30:17,552 INFO:   Done with stage: EVALUATION
2022-11-28 01:30:17,552 INFO:   Leaving out SEQ value Fold_1
2022-11-28 01:30:17,565 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 01:30:17,565 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:30:18,209 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:30:18,209 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:30:18,280 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:30:18,280 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:30:18,280 INFO:     No hyperparam tuning for this model
2022-11-28 01:30:18,280 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:30:18,280 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:30:18,281 INFO:     None feature selector for col prot
2022-11-28 01:30:18,281 INFO:     None feature selector for col prot
2022-11-28 01:30:18,281 INFO:     None feature selector for col prot
2022-11-28 01:30:18,282 INFO:     None feature selector for col chem
2022-11-28 01:30:18,282 INFO:     None feature selector for col chem
2022-11-28 01:30:18,282 INFO:     None feature selector for col chem
2022-11-28 01:30:18,282 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:30:18,282 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:30:18,283 INFO:     Number of params in model 169741
2022-11-28 01:30:18,287 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:30:18,287 INFO:   Starting stage: TRAINING
2022-11-28 01:30:18,341 INFO:     Val loss before train {'Reaction outcome loss': 0.967474256049503, 'Total loss': 0.967474256049503}
2022-11-28 01:30:18,341 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:18,341 INFO:     Epoch: 0
2022-11-28 01:30:19,083 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.4945138022303581, 'Total loss': 0.4945138022303581} | train loss {'Reaction outcome loss': 0.6373968924412707, 'Total loss': 0.6373968924412707}
2022-11-28 01:30:19,083 INFO:     Found new best model at epoch 0
2022-11-28 01:30:19,084 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:19,084 INFO:     Epoch: 1
2022-11-28 01:30:19,830 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4689534865319729, 'Total loss': 0.4689534865319729} | train loss {'Reaction outcome loss': 0.5022157234580893, 'Total loss': 0.5022157234580893}
2022-11-28 01:30:19,830 INFO:     Found new best model at epoch 1
2022-11-28 01:30:19,831 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:19,831 INFO:     Epoch: 2
2022-11-28 01:30:20,573 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46520269221880217, 'Total loss': 0.46520269221880217} | train loss {'Reaction outcome loss': 0.47056635466181795, 'Total loss': 0.47056635466181795}
2022-11-28 01:30:20,573 INFO:     Found new best model at epoch 2
2022-11-28 01:30:20,574 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:20,574 INFO:     Epoch: 3
2022-11-28 01:30:21,320 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4566934935071252, 'Total loss': 0.4566934935071252} | train loss {'Reaction outcome loss': 0.4506903712747068, 'Total loss': 0.4506903712747068}
2022-11-28 01:30:21,320 INFO:     Found new best model at epoch 3
2022-11-28 01:30:21,321 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:21,321 INFO:     Epoch: 4
2022-11-28 01:30:22,066 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4615228660404682, 'Total loss': 0.4615228660404682} | train loss {'Reaction outcome loss': 0.43123037760194977, 'Total loss': 0.43123037760194977}
2022-11-28 01:30:22,066 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:22,066 INFO:     Epoch: 5
2022-11-28 01:30:22,812 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46816126426512544, 'Total loss': 0.46816126426512544} | train loss {'Reaction outcome loss': 0.4263088703457161, 'Total loss': 0.4263088703457161}
2022-11-28 01:30:22,812 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:22,812 INFO:     Epoch: 6
2022-11-28 01:30:23,557 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47821289402517403, 'Total loss': 0.47821289402517403} | train loss {'Reaction outcome loss': 0.4234429252020985, 'Total loss': 0.4234429252020985}
2022-11-28 01:30:23,557 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:23,557 INFO:     Epoch: 7
2022-11-28 01:30:24,302 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4788833951408213, 'Total loss': 0.4788833951408213} | train loss {'Reaction outcome loss': 0.4103017409562099, 'Total loss': 0.4103017409562099}
2022-11-28 01:30:24,302 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:24,302 INFO:     Epoch: 8
2022-11-28 01:30:25,054 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44618040187792346, 'Total loss': 0.44618040187792346} | train loss {'Reaction outcome loss': 0.40164867888095407, 'Total loss': 0.40164867888095407}
2022-11-28 01:30:25,054 INFO:     Found new best model at epoch 8
2022-11-28 01:30:25,054 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:25,055 INFO:     Epoch: 9
2022-11-28 01:30:25,800 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4315604604780674, 'Total loss': 0.4315604604780674} | train loss {'Reaction outcome loss': 0.3876148102133863, 'Total loss': 0.3876148102133863}
2022-11-28 01:30:25,800 INFO:     Found new best model at epoch 9
2022-11-28 01:30:25,801 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:25,801 INFO:     Epoch: 10
2022-11-28 01:30:26,547 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4580692191692916, 'Total loss': 0.4580692191692916} | train loss {'Reaction outcome loss': 0.3791897140051189, 'Total loss': 0.3791897140051189}
2022-11-28 01:30:26,548 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:26,548 INFO:     Epoch: 11
2022-11-28 01:30:27,297 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42975883050398395, 'Total loss': 0.42975883050398395} | train loss {'Reaction outcome loss': 0.3778886327912149, 'Total loss': 0.3778886327912149}
2022-11-28 01:30:27,297 INFO:     Found new best model at epoch 11
2022-11-28 01:30:27,298 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:27,298 INFO:     Epoch: 12
2022-11-28 01:30:28,044 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42311323061585426, 'Total loss': 0.42311323061585426} | train loss {'Reaction outcome loss': 0.3789109327954802, 'Total loss': 0.3789109327954802}
2022-11-28 01:30:28,044 INFO:     Found new best model at epoch 12
2022-11-28 01:30:28,045 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:28,045 INFO:     Epoch: 13
2022-11-28 01:30:28,790 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42629066041924735, 'Total loss': 0.42629066041924735} | train loss {'Reaction outcome loss': 0.3774372408023247, 'Total loss': 0.3774372408023247}
2022-11-28 01:30:28,790 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:28,790 INFO:     Epoch: 14
2022-11-28 01:30:29,537 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.430081383748488, 'Total loss': 0.430081383748488} | train loss {'Reaction outcome loss': 0.36627218466598976, 'Total loss': 0.36627218466598976}
2022-11-28 01:30:29,538 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:29,538 INFO:     Epoch: 15
2022-11-28 01:30:30,286 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4455784024162726, 'Total loss': 0.4455784024162726} | train loss {'Reaction outcome loss': 0.35974671049156653, 'Total loss': 0.35974671049156653}
2022-11-28 01:30:30,286 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:30,286 INFO:     Epoch: 16
2022-11-28 01:30:31,029 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45698460123755713, 'Total loss': 0.45698460123755713} | train loss {'Reaction outcome loss': 0.3670016360669001, 'Total loss': 0.3670016360669001}
2022-11-28 01:30:31,029 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:31,029 INFO:     Epoch: 17
2022-11-28 01:30:31,773 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41916791993108665, 'Total loss': 0.41916791993108665} | train loss {'Reaction outcome loss': 0.36957229725141755, 'Total loss': 0.36957229725141755}
2022-11-28 01:30:31,773 INFO:     Found new best model at epoch 17
2022-11-28 01:30:31,774 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:31,774 INFO:     Epoch: 18
2022-11-28 01:30:32,521 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44712031056935136, 'Total loss': 0.44712031056935136} | train loss {'Reaction outcome loss': 0.39560029627038884, 'Total loss': 0.39560029627038884}
2022-11-28 01:30:32,521 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:32,521 INFO:     Epoch: 19
2022-11-28 01:30:33,265 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4465684582563964, 'Total loss': 0.4465684582563964} | train loss {'Reaction outcome loss': 0.3619160118855928, 'Total loss': 0.3619160118855928}
2022-11-28 01:30:33,265 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:33,265 INFO:     Epoch: 20
2022-11-28 01:30:34,007 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4417711486193267, 'Total loss': 0.4417711486193267} | train loss {'Reaction outcome loss': 0.34830553334975534, 'Total loss': 0.34830553334975534}
2022-11-28 01:30:34,008 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:34,008 INFO:     Epoch: 21
2022-11-28 01:30:34,750 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4231785535812378, 'Total loss': 0.4231785535812378} | train loss {'Reaction outcome loss': 0.3630384377501754, 'Total loss': 0.3630384377501754}
2022-11-28 01:30:34,750 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:34,750 INFO:     Epoch: 22
2022-11-28 01:30:35,490 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4183870923112739, 'Total loss': 0.4183870923112739} | train loss {'Reaction outcome loss': 0.34747790795117467, 'Total loss': 0.34747790795117467}
2022-11-28 01:30:35,490 INFO:     Found new best model at epoch 22
2022-11-28 01:30:35,491 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:35,491 INFO:     Epoch: 23
2022-11-28 01:30:36,233 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42083768478848715, 'Total loss': 0.42083768478848715} | train loss {'Reaction outcome loss': 0.348450181485429, 'Total loss': 0.348450181485429}
2022-11-28 01:30:36,233 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:36,233 INFO:     Epoch: 24
2022-11-28 01:30:36,974 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4214271273125302, 'Total loss': 0.4214271273125302} | train loss {'Reaction outcome loss': 0.365289370208858, 'Total loss': 0.365289370208858}
2022-11-28 01:30:36,974 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:36,974 INFO:     Epoch: 25
2022-11-28 01:30:37,724 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4072650466960939, 'Total loss': 0.4072650466960939} | train loss {'Reaction outcome loss': 0.34034233042585704, 'Total loss': 0.34034233042585704}
2022-11-28 01:30:37,724 INFO:     Found new best model at epoch 25
2022-11-28 01:30:37,725 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:37,725 INFO:     Epoch: 26
2022-11-28 01:30:38,475 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4209225651892749, 'Total loss': 0.4209225651892749} | train loss {'Reaction outcome loss': 0.3664093751399985, 'Total loss': 0.3664093751399985}
2022-11-28 01:30:38,476 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:38,476 INFO:     Epoch: 27
2022-11-28 01:30:39,223 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4946649105034091, 'Total loss': 0.4946649105034091} | train loss {'Reaction outcome loss': 0.342663004541928, 'Total loss': 0.342663004541928}
2022-11-28 01:30:39,223 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:39,223 INFO:     Epoch: 28
2022-11-28 01:30:39,968 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4396479580212723, 'Total loss': 0.4396479580212723} | train loss {'Reaction outcome loss': 0.3403359159510507, 'Total loss': 0.3403359159510507}
2022-11-28 01:30:39,968 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:39,968 INFO:     Epoch: 29
2022-11-28 01:30:40,714 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44117805700410495, 'Total loss': 0.44117805700410495} | train loss {'Reaction outcome loss': 0.3387457459320424, 'Total loss': 0.3387457459320424}
2022-11-28 01:30:40,714 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:40,714 INFO:     Epoch: 30
2022-11-28 01:30:41,459 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4188170957971703, 'Total loss': 0.4188170957971703} | train loss {'Reaction outcome loss': 0.33913634473133664, 'Total loss': 0.33913634473133664}
2022-11-28 01:30:41,459 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:41,460 INFO:     Epoch: 31
2022-11-28 01:30:42,206 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43449782783334906, 'Total loss': 0.43449782783334906} | train loss {'Reaction outcome loss': 0.32849169887181917, 'Total loss': 0.32849169887181917}
2022-11-28 01:30:42,206 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:42,206 INFO:     Epoch: 32
2022-11-28 01:30:42,950 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.426904903894121, 'Total loss': 0.426904903894121} | train loss {'Reaction outcome loss': 0.3328747905127191, 'Total loss': 0.3328747905127191}
2022-11-28 01:30:42,950 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:42,950 INFO:     Epoch: 33
2022-11-28 01:30:43,693 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4137630184943026, 'Total loss': 0.4137630184943026} | train loss {'Reaction outcome loss': 0.32658371190127616, 'Total loss': 0.32658371190127616}
2022-11-28 01:30:43,693 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:43,693 INFO:     Epoch: 34
2022-11-28 01:30:44,434 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4048185226592151, 'Total loss': 0.4048185226592151} | train loss {'Reaction outcome loss': 0.3477805594382016, 'Total loss': 0.3477805594382016}
2022-11-28 01:30:44,434 INFO:     Found new best model at epoch 34
2022-11-28 01:30:44,435 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:44,435 INFO:     Epoch: 35
2022-11-28 01:30:45,178 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41363525221293623, 'Total loss': 0.41363525221293623} | train loss {'Reaction outcome loss': 0.32801083565844213, 'Total loss': 0.32801083565844213}
2022-11-28 01:30:45,179 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:45,179 INFO:     Epoch: 36
2022-11-28 01:30:45,921 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43782267990437423, 'Total loss': 0.43782267990437423} | train loss {'Reaction outcome loss': 0.3336603917814942, 'Total loss': 0.3336603917814942}
2022-11-28 01:30:45,921 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:45,922 INFO:     Epoch: 37
2022-11-28 01:30:46,666 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4181070707061074, 'Total loss': 0.4181070707061074} | train loss {'Reaction outcome loss': 0.35661161528063207, 'Total loss': 0.35661161528063207}
2022-11-28 01:30:46,667 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:46,667 INFO:     Epoch: 38
2022-11-28 01:30:47,412 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44433277066458354, 'Total loss': 0.44433277066458354} | train loss {'Reaction outcome loss': 0.3426289657571048, 'Total loss': 0.3426289657571048}
2022-11-28 01:30:47,412 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:47,412 INFO:     Epoch: 39
2022-11-28 01:30:48,154 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39849767309020867, 'Total loss': 0.39849767309020867} | train loss {'Reaction outcome loss': 0.3344567386727584, 'Total loss': 0.3344567386727584}
2022-11-28 01:30:48,154 INFO:     Found new best model at epoch 39
2022-11-28 01:30:48,155 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:48,155 INFO:     Epoch: 40
2022-11-28 01:30:48,900 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4209654341367158, 'Total loss': 0.4209654341367158} | train loss {'Reaction outcome loss': 0.33428707444071315, 'Total loss': 0.33428707444071315}
2022-11-28 01:30:48,900 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:48,900 INFO:     Epoch: 41
2022-11-28 01:30:49,648 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4254683777689934, 'Total loss': 0.4254683777689934} | train loss {'Reaction outcome loss': 0.3293858151505833, 'Total loss': 0.3293858151505833}
2022-11-28 01:30:49,648 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:49,649 INFO:     Epoch: 42
2022-11-28 01:30:50,388 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.427121795036576, 'Total loss': 0.427121795036576} | train loss {'Reaction outcome loss': 0.3277119728114441, 'Total loss': 0.3277119728114441}
2022-11-28 01:30:50,388 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:50,389 INFO:     Epoch: 43
2022-11-28 01:30:51,132 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4052848702465946, 'Total loss': 0.4052848702465946} | train loss {'Reaction outcome loss': 0.3277542986963623, 'Total loss': 0.3277542986963623}
2022-11-28 01:30:51,132 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:51,133 INFO:     Epoch: 44
2022-11-28 01:30:51,872 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42320779406211595, 'Total loss': 0.42320779406211595} | train loss {'Reaction outcome loss': 0.3187057135083716, 'Total loss': 0.3187057135083716}
2022-11-28 01:30:51,872 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:51,872 INFO:     Epoch: 45
2022-11-28 01:30:52,617 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4265818921002475, 'Total loss': 0.4265818921002475} | train loss {'Reaction outcome loss': 0.31965140942936604, 'Total loss': 0.31965140942936604}
2022-11-28 01:30:52,617 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:52,617 INFO:     Epoch: 46
2022-11-28 01:30:53,365 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4193196405063976, 'Total loss': 0.4193196405063976} | train loss {'Reaction outcome loss': 0.3240951288817639, 'Total loss': 0.3240951288817639}
2022-11-28 01:30:53,365 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:53,365 INFO:     Epoch: 47
2022-11-28 01:30:54,114 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4126016480678862, 'Total loss': 0.4126016480678862} | train loss {'Reaction outcome loss': 0.32256655498343684, 'Total loss': 0.32256655498343684}
2022-11-28 01:30:54,114 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:54,114 INFO:     Epoch: 48
2022-11-28 01:30:54,863 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42687920650297945, 'Total loss': 0.42687920650297945} | train loss {'Reaction outcome loss': 0.3198559388277019, 'Total loss': 0.3198559388277019}
2022-11-28 01:30:54,864 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:54,864 INFO:     Epoch: 49
2022-11-28 01:30:55,609 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41767037253488193, 'Total loss': 0.41767037253488193} | train loss {'Reaction outcome loss': 0.3296573378281434, 'Total loss': 0.3296573378281434}
2022-11-28 01:30:55,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:55,609 INFO:     Epoch: 50
2022-11-28 01:30:56,354 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5182135030627251, 'Total loss': 0.5182135030627251} | train loss {'Reaction outcome loss': 0.32790625793058126, 'Total loss': 0.32790625793058126}
2022-11-28 01:30:56,354 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:56,354 INFO:     Epoch: 51
2022-11-28 01:30:57,100 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4179457094181668, 'Total loss': 0.4179457094181668} | train loss {'Reaction outcome loss': 0.33559665509625924, 'Total loss': 0.33559665509625924}
2022-11-28 01:30:57,100 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:57,100 INFO:     Epoch: 52
2022-11-28 01:30:57,845 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4274251542308114, 'Total loss': 0.4274251542308114} | train loss {'Reaction outcome loss': 0.3213708571060316, 'Total loss': 0.3213708571060316}
2022-11-28 01:30:57,846 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:57,846 INFO:     Epoch: 53
2022-11-28 01:30:58,593 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3990449851209467, 'Total loss': 0.3990449851209467} | train loss {'Reaction outcome loss': 0.31914086124071706, 'Total loss': 0.31914086124071706}
2022-11-28 01:30:58,593 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:58,593 INFO:     Epoch: 54
2022-11-28 01:30:59,338 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4430392220277678, 'Total loss': 0.4430392220277678} | train loss {'Reaction outcome loss': 0.32573858327288857, 'Total loss': 0.32573858327288857}
2022-11-28 01:30:59,338 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:30:59,338 INFO:     Epoch: 55
2022-11-28 01:31:00,082 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46482301130890846, 'Total loss': 0.46482301130890846} | train loss {'Reaction outcome loss': 0.3282305330400042, 'Total loss': 0.3282305330400042}
2022-11-28 01:31:00,082 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:00,082 INFO:     Epoch: 56
2022-11-28 01:31:00,827 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41459244896065106, 'Total loss': 0.41459244896065106} | train loss {'Reaction outcome loss': 0.32461019131818764, 'Total loss': 0.32461019131818764}
2022-11-28 01:31:00,827 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:00,827 INFO:     Epoch: 57
2022-11-28 01:31:01,572 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4338740381327542, 'Total loss': 0.4338740381327542} | train loss {'Reaction outcome loss': 0.3208328845047275, 'Total loss': 0.3208328845047275}
2022-11-28 01:31:01,572 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:01,573 INFO:     Epoch: 58
2022-11-28 01:31:02,320 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4204870459030975, 'Total loss': 0.4204870459030975} | train loss {'Reaction outcome loss': 0.33661786610635774, 'Total loss': 0.33661786610635774}
2022-11-28 01:31:02,320 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:02,320 INFO:     Epoch: 59
2022-11-28 01:31:03,064 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41662176562981174, 'Total loss': 0.41662176562981174} | train loss {'Reaction outcome loss': 0.3101770137606362, 'Total loss': 0.3101770137606362}
2022-11-28 01:31:03,065 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:03,065 INFO:     Epoch: 60
2022-11-28 01:31:03,811 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3977118816904046, 'Total loss': 0.3977118816904046} | train loss {'Reaction outcome loss': 0.3252586215260337, 'Total loss': 0.3252586215260337}
2022-11-28 01:31:03,811 INFO:     Found new best model at epoch 60
2022-11-28 01:31:03,812 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:03,812 INFO:     Epoch: 61
2022-11-28 01:31:04,558 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4380227733742107, 'Total loss': 0.4380227733742107} | train loss {'Reaction outcome loss': 0.3097432447740665, 'Total loss': 0.3097432447740665}
2022-11-28 01:31:04,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:04,558 INFO:     Epoch: 62
2022-11-28 01:31:05,305 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4054187907921997, 'Total loss': 0.4054187907921997} | train loss {'Reaction outcome loss': 0.34483751419343445, 'Total loss': 0.34483751419343445}
2022-11-28 01:31:05,306 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:05,306 INFO:     Epoch: 63
2022-11-28 01:31:06,053 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.409877805208618, 'Total loss': 0.409877805208618} | train loss {'Reaction outcome loss': 0.3190784929734975, 'Total loss': 0.3190784929734975}
2022-11-28 01:31:06,053 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:06,053 INFO:     Epoch: 64
2022-11-28 01:31:06,800 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4173141650178216, 'Total loss': 0.4173141650178216} | train loss {'Reaction outcome loss': 0.33319694220054485, 'Total loss': 0.33319694220054485}
2022-11-28 01:31:06,801 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:06,801 INFO:     Epoch: 65
2022-11-28 01:31:07,545 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3961148492314599, 'Total loss': 0.3961148492314599} | train loss {'Reaction outcome loss': 0.3313493641165956, 'Total loss': 0.3313493641165956}
2022-11-28 01:31:07,545 INFO:     Found new best model at epoch 65
2022-11-28 01:31:07,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:07,546 INFO:     Epoch: 66
2022-11-28 01:31:08,286 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3933332757177678, 'Total loss': 0.3933332757177678} | train loss {'Reaction outcome loss': 0.3110852740169597, 'Total loss': 0.3110852740169597}
2022-11-28 01:31:08,286 INFO:     Found new best model at epoch 66
2022-11-28 01:31:08,286 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:08,287 INFO:     Epoch: 67
2022-11-28 01:31:09,033 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4017994556237351, 'Total loss': 0.4017994556237351} | train loss {'Reaction outcome loss': 0.30512765496365934, 'Total loss': 0.30512765496365934}
2022-11-28 01:31:09,033 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:09,033 INFO:     Epoch: 68
2022-11-28 01:31:09,782 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.443662034178322, 'Total loss': 0.443662034178322} | train loss {'Reaction outcome loss': 0.3155208092167793, 'Total loss': 0.3155208092167793}
2022-11-28 01:31:09,783 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:09,783 INFO:     Epoch: 69
2022-11-28 01:31:10,531 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4196702922609719, 'Total loss': 0.4196702922609719} | train loss {'Reaction outcome loss': 0.3196531709147851, 'Total loss': 0.3196531709147851}
2022-11-28 01:31:10,531 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:10,531 INFO:     Epoch: 70
2022-11-28 01:31:11,273 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42634106190367177, 'Total loss': 0.42634106190367177} | train loss {'Reaction outcome loss': 0.31760473041898885, 'Total loss': 0.31760473041898885}
2022-11-28 01:31:11,274 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:11,274 INFO:     Epoch: 71
2022-11-28 01:31:12,017 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4145146811550314, 'Total loss': 0.4145146811550314} | train loss {'Reaction outcome loss': 0.3145492034040482, 'Total loss': 0.3145492034040482}
2022-11-28 01:31:12,017 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:12,017 INFO:     Epoch: 72
2022-11-28 01:31:12,760 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4579971900040453, 'Total loss': 0.4579971900040453} | train loss {'Reaction outcome loss': 0.32180306899855254, 'Total loss': 0.32180306899855254}
2022-11-28 01:31:12,760 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:12,760 INFO:     Epoch: 73
2022-11-28 01:31:13,503 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4237148423086513, 'Total loss': 0.4237148423086513} | train loss {'Reaction outcome loss': 0.31985143896605656, 'Total loss': 0.31985143896605656}
2022-11-28 01:31:13,503 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:13,503 INFO:     Epoch: 74
2022-11-28 01:31:14,249 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4190513481470672, 'Total loss': 0.4190513481470672} | train loss {'Reaction outcome loss': 0.3096279197359299, 'Total loss': 0.3096279197359299}
2022-11-28 01:31:14,249 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:14,249 INFO:     Epoch: 75
2022-11-28 01:31:14,993 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.404017770324241, 'Total loss': 0.404017770324241} | train loss {'Reaction outcome loss': 0.31167152624856304, 'Total loss': 0.31167152624856304}
2022-11-28 01:31:14,993 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:14,993 INFO:     Epoch: 76
2022-11-28 01:31:15,735 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43326168236407364, 'Total loss': 0.43326168236407364} | train loss {'Reaction outcome loss': 0.31669215985049726, 'Total loss': 0.31669215985049726}
2022-11-28 01:31:15,735 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:15,735 INFO:     Epoch: 77
2022-11-28 01:31:16,480 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43103918179192324, 'Total loss': 0.43103918179192324} | train loss {'Reaction outcome loss': 0.30311852900560204, 'Total loss': 0.30311852900560204}
2022-11-28 01:31:16,481 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:16,481 INFO:     Epoch: 78
2022-11-28 01:31:17,226 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.442749978297136, 'Total loss': 0.442749978297136} | train loss {'Reaction outcome loss': 0.3113546883206634, 'Total loss': 0.3113546883206634}
2022-11-28 01:31:17,227 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:17,227 INFO:     Epoch: 79
2022-11-28 01:31:17,967 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3790332834151658, 'Total loss': 0.3790332834151658} | train loss {'Reaction outcome loss': 0.312874372128533, 'Total loss': 0.312874372128533}
2022-11-28 01:31:17,967 INFO:     Found new best model at epoch 79
2022-11-28 01:31:17,968 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:17,968 INFO:     Epoch: 80
2022-11-28 01:31:18,712 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.396396337246353, 'Total loss': 0.396396337246353} | train loss {'Reaction outcome loss': 0.3103415492454521, 'Total loss': 0.3103415492454521}
2022-11-28 01:31:18,712 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:18,713 INFO:     Epoch: 81
2022-11-28 01:31:19,453 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4088603200560266, 'Total loss': 0.4088603200560266} | train loss {'Reaction outcome loss': 0.3210252229546608, 'Total loss': 0.3210252229546608}
2022-11-28 01:31:19,453 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:19,454 INFO:     Epoch: 82
2022-11-28 01:31:20,197 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4013427614488385, 'Total loss': 0.4013427614488385} | train loss {'Reaction outcome loss': 0.31616429067575014, 'Total loss': 0.31616429067575014}
2022-11-28 01:31:20,197 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:20,197 INFO:     Epoch: 83
2022-11-28 01:31:20,941 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41153199124065315, 'Total loss': 0.41153199124065315} | train loss {'Reaction outcome loss': 0.3073011441420206, 'Total loss': 0.3073011441420206}
2022-11-28 01:31:20,941 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:20,941 INFO:     Epoch: 84
2022-11-28 01:31:21,685 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4211976077746261, 'Total loss': 0.4211976077746261} | train loss {'Reaction outcome loss': 0.30790783389497867, 'Total loss': 0.30790783389497867}
2022-11-28 01:31:21,685 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:21,685 INFO:     Epoch: 85
2022-11-28 01:31:22,429 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4224048734388568, 'Total loss': 0.4224048734388568} | train loss {'Reaction outcome loss': 0.32526907754632145, 'Total loss': 0.32526907754632145}
2022-11-28 01:31:22,429 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:22,429 INFO:     Epoch: 86
2022-11-28 01:31:23,172 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4406755024736578, 'Total loss': 0.4406755024736578} | train loss {'Reaction outcome loss': 0.310211186361337, 'Total loss': 0.310211186361337}
2022-11-28 01:31:23,172 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:23,172 INFO:     Epoch: 87
2022-11-28 01:31:23,913 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4259234949607741, 'Total loss': 0.4259234949607741} | train loss {'Reaction outcome loss': 0.3127426655005347, 'Total loss': 0.3127426655005347}
2022-11-28 01:31:23,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:23,914 INFO:     Epoch: 88
2022-11-28 01:31:24,654 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4201088026165962, 'Total loss': 0.4201088026165962} | train loss {'Reaction outcome loss': 0.32473511991622717, 'Total loss': 0.32473511991622717}
2022-11-28 01:31:24,655 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:24,655 INFO:     Epoch: 89
2022-11-28 01:31:25,402 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4692013951187784, 'Total loss': 0.4692013951187784} | train loss {'Reaction outcome loss': 0.3110086996907647, 'Total loss': 0.3110086996907647}
2022-11-28 01:31:25,402 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:25,403 INFO:     Epoch: 90
2022-11-28 01:31:26,150 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.434535607018254, 'Total loss': 0.434535607018254} | train loss {'Reaction outcome loss': 0.31405164521594764, 'Total loss': 0.31405164521594764}
2022-11-28 01:31:26,150 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:26,150 INFO:     Epoch: 91
2022-11-28 01:31:26,896 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4559800516475331, 'Total loss': 0.4559800516475331} | train loss {'Reaction outcome loss': 0.3322430541399519, 'Total loss': 0.3322430541399519}
2022-11-28 01:31:26,896 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:26,896 INFO:     Epoch: 92
2022-11-28 01:31:27,645 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41334273598410864, 'Total loss': 0.41334273598410864} | train loss {'Reaction outcome loss': 0.32078012397233774, 'Total loss': 0.32078012397233774}
2022-11-28 01:31:27,645 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:27,645 INFO:     Epoch: 93
2022-11-28 01:31:28,390 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3978283764286475, 'Total loss': 0.3978283764286475} | train loss {'Reaction outcome loss': 0.3005374612226358, 'Total loss': 0.3005374612226358}
2022-11-28 01:31:28,390 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:28,391 INFO:     Epoch: 94
2022-11-28 01:31:29,136 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42260236462408846, 'Total loss': 0.42260236462408846} | train loss {'Reaction outcome loss': 0.3081336694992023, 'Total loss': 0.3081336694992023}
2022-11-28 01:31:29,136 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:29,137 INFO:     Epoch: 95
2022-11-28 01:31:29,882 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40168384970589116, 'Total loss': 0.40168384970589116} | train loss {'Reaction outcome loss': 0.3268786162879838, 'Total loss': 0.3268786162879838}
2022-11-28 01:31:29,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:29,883 INFO:     Epoch: 96
2022-11-28 01:31:30,628 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41229120371016587, 'Total loss': 0.41229120371016587} | train loss {'Reaction outcome loss': 0.30454947565435264, 'Total loss': 0.30454947565435264}
2022-11-28 01:31:30,628 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:30,628 INFO:     Epoch: 97
2022-11-28 01:31:31,373 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42495148798281496, 'Total loss': 0.42495148798281496} | train loss {'Reaction outcome loss': 0.30629115994748196, 'Total loss': 0.30629115994748196}
2022-11-28 01:31:31,373 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:31,373 INFO:     Epoch: 98
2022-11-28 01:31:32,115 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41456168619069184, 'Total loss': 0.41456168619069184} | train loss {'Reaction outcome loss': 0.31131019784884173, 'Total loss': 0.31131019784884173}
2022-11-28 01:31:32,115 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:32,115 INFO:     Epoch: 99
2022-11-28 01:31:32,861 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4387070160697807, 'Total loss': 0.4387070160697807} | train loss {'Reaction outcome loss': 0.3164192812615319, 'Total loss': 0.3164192812615319}
2022-11-28 01:31:32,861 INFO:     Best model found after epoch 80 of 100.
2022-11-28 01:31:32,861 INFO:   Done with stage: TRAINING
2022-11-28 01:31:32,861 INFO:   Starting stage: EVALUATION
2022-11-28 01:31:32,983 INFO:   Done with stage: EVALUATION
2022-11-28 01:31:32,983 INFO:   Leaving out SEQ value Fold_2
2022-11-28 01:31:32,996 INFO:   examples: 20,544| examples in train: 15,422 | examples in val: 2,722| examples in test: 2,400
2022-11-28 01:31:32,996 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:31:33,632 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:31:33,632 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:31:33,701 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:31:33,701 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:31:33,701 INFO:     No hyperparam tuning for this model
2022-11-28 01:31:33,701 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:31:33,701 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:31:33,702 INFO:     None feature selector for col prot
2022-11-28 01:31:33,702 INFO:     None feature selector for col prot
2022-11-28 01:31:33,702 INFO:     None feature selector for col prot
2022-11-28 01:31:33,703 INFO:     None feature selector for col chem
2022-11-28 01:31:33,703 INFO:     None feature selector for col chem
2022-11-28 01:31:33,703 INFO:     None feature selector for col chem
2022-11-28 01:31:33,703 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:31:33,703 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:31:33,704 INFO:     Number of params in model 169741
2022-11-28 01:31:33,707 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:31:33,708 INFO:   Starting stage: TRAINING
2022-11-28 01:31:33,760 INFO:     Val loss before train {'Reaction outcome loss': 1.0083498483480409, 'Total loss': 1.0083498483480409}
2022-11-28 01:31:33,760 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:33,760 INFO:     Epoch: 0
2022-11-28 01:31:34,485 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5081728069588195, 'Total loss': 0.5081728069588195} | train loss {'Reaction outcome loss': 0.6239781321578995, 'Total loss': 0.6239781321578995}
2022-11-28 01:31:34,485 INFO:     Found new best model at epoch 0
2022-11-28 01:31:34,485 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:34,486 INFO:     Epoch: 1
2022-11-28 01:31:35,209 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49687481515629345, 'Total loss': 0.49687481515629345} | train loss {'Reaction outcome loss': 0.48615493622310924, 'Total loss': 0.48615493622310924}
2022-11-28 01:31:35,210 INFO:     Found new best model at epoch 1
2022-11-28 01:31:35,210 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:35,210 INFO:     Epoch: 2
2022-11-28 01:31:35,943 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4497171006230421, 'Total loss': 0.4497171006230421} | train loss {'Reaction outcome loss': 0.44573382532448197, 'Total loss': 0.44573382532448197}
2022-11-28 01:31:35,943 INFO:     Found new best model at epoch 2
2022-11-28 01:31:35,943 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:35,944 INFO:     Epoch: 3
2022-11-28 01:31:36,671 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4533981185319812, 'Total loss': 0.4533981185319812} | train loss {'Reaction outcome loss': 0.4291145679738017, 'Total loss': 0.4291145679738017}
2022-11-28 01:31:36,671 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:36,671 INFO:     Epoch: 4
2022-11-28 01:31:37,397 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4595448201478914, 'Total loss': 0.4595448201478914} | train loss {'Reaction outcome loss': 0.4087070885473762, 'Total loss': 0.4087070885473762}
2022-11-28 01:31:37,398 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:37,398 INFO:     Epoch: 5
2022-11-28 01:31:38,122 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45422614175219866, 'Total loss': 0.45422614175219866} | train loss {'Reaction outcome loss': 0.4055844299587966, 'Total loss': 0.4055844299587966}
2022-11-28 01:31:38,122 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:38,122 INFO:     Epoch: 6
2022-11-28 01:31:38,846 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4400334898815599, 'Total loss': 0.4400334898815599} | train loss {'Reaction outcome loss': 0.39760471132286357, 'Total loss': 0.39760471132286357}
2022-11-28 01:31:38,846 INFO:     Found new best model at epoch 6
2022-11-28 01:31:38,847 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:38,847 INFO:     Epoch: 7
2022-11-28 01:31:39,575 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4141087888978248, 'Total loss': 0.4141087888978248} | train loss {'Reaction outcome loss': 0.3880811511419126, 'Total loss': 0.3880811511419126}
2022-11-28 01:31:39,575 INFO:     Found new best model at epoch 7
2022-11-28 01:31:39,576 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:39,576 INFO:     Epoch: 8
2022-11-28 01:31:40,302 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4588670512271482, 'Total loss': 0.4588670512271482} | train loss {'Reaction outcome loss': 0.3699709465765854, 'Total loss': 0.3699709465765854}
2022-11-28 01:31:40,302 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:40,302 INFO:     Epoch: 9
2022-11-28 01:31:41,029 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42717058263545815, 'Total loss': 0.42717058263545815} | train loss {'Reaction outcome loss': 0.36832218601743216, 'Total loss': 0.36832218601743216}
2022-11-28 01:31:41,030 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:41,030 INFO:     Epoch: 10
2022-11-28 01:31:41,755 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41494999375454217, 'Total loss': 0.41494999375454217} | train loss {'Reaction outcome loss': 0.36566851587958354, 'Total loss': 0.36566851587958354}
2022-11-28 01:31:41,755 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:41,755 INFO:     Epoch: 11
2022-11-28 01:31:42,480 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4270339240861494, 'Total loss': 0.4270339240861494} | train loss {'Reaction outcome loss': 0.36096268836640716, 'Total loss': 0.36096268836640716}
2022-11-28 01:31:42,480 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:42,480 INFO:     Epoch: 12
2022-11-28 01:31:43,208 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4902058361574661, 'Total loss': 0.4902058361574661} | train loss {'Reaction outcome loss': 0.3662491819175942, 'Total loss': 0.3662491819175942}
2022-11-28 01:31:43,208 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:43,208 INFO:     Epoch: 13
2022-11-28 01:31:43,934 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5255047561124314, 'Total loss': 0.5255047561124314} | train loss {'Reaction outcome loss': 0.35132700013174556, 'Total loss': 0.35132700013174556}
2022-11-28 01:31:43,935 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:43,935 INFO:     Epoch: 14
2022-11-28 01:31:44,658 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44510618579942124, 'Total loss': 0.44510618579942124} | train loss {'Reaction outcome loss': 0.3477706351313601, 'Total loss': 0.3477706351313601}
2022-11-28 01:31:44,658 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:44,658 INFO:     Epoch: 15
2022-11-28 01:31:45,381 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44009690610475316, 'Total loss': 0.44009690610475316} | train loss {'Reaction outcome loss': 0.34342781494514574, 'Total loss': 0.34342781494514574}
2022-11-28 01:31:45,381 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:45,381 INFO:     Epoch: 16
2022-11-28 01:31:46,107 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4331429566061774, 'Total loss': 0.4331429566061774} | train loss {'Reaction outcome loss': 0.3352055733258299, 'Total loss': 0.3352055733258299}
2022-11-28 01:31:46,107 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:46,107 INFO:     Epoch: 17
2022-11-28 01:31:46,830 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43530761225278986, 'Total loss': 0.43530761225278986} | train loss {'Reaction outcome loss': 0.34753726453701983, 'Total loss': 0.34753726453701983}
2022-11-28 01:31:46,830 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:46,830 INFO:     Epoch: 18
2022-11-28 01:31:47,552 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42965289915716925, 'Total loss': 0.42965289915716925} | train loss {'Reaction outcome loss': 0.338773260008992, 'Total loss': 0.338773260008992}
2022-11-28 01:31:47,552 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:47,553 INFO:     Epoch: 19
2022-11-28 01:31:48,277 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4404191873794378, 'Total loss': 0.4404191873794378} | train loss {'Reaction outcome loss': 0.3445982069580881, 'Total loss': 0.3445982069580881}
2022-11-28 01:31:48,277 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:48,277 INFO:     Epoch: 20
2022-11-28 01:31:49,003 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4218089379543482, 'Total loss': 0.4218089379543482} | train loss {'Reaction outcome loss': 0.33313671955491003, 'Total loss': 0.33313671955491003}
2022-11-28 01:31:49,003 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:49,004 INFO:     Epoch: 21
2022-11-28 01:31:49,728 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44043495211490363, 'Total loss': 0.44043495211490363} | train loss {'Reaction outcome loss': 0.32661916847298256, 'Total loss': 0.32661916847298256}
2022-11-28 01:31:49,729 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:49,729 INFO:     Epoch: 22
2022-11-28 01:31:50,460 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4320236253877019, 'Total loss': 0.4320236253877019} | train loss {'Reaction outcome loss': 0.3318544757007563, 'Total loss': 0.3318544757007563}
2022-11-28 01:31:50,460 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:50,460 INFO:     Epoch: 23
2022-11-28 01:31:51,185 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4188667636278064, 'Total loss': 0.4188667636278064} | train loss {'Reaction outcome loss': 0.3298989454616649, 'Total loss': 0.3298989454616649}
2022-11-28 01:31:51,185 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:51,186 INFO:     Epoch: 24
2022-11-28 01:31:51,909 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.421862487876138, 'Total loss': 0.421862487876138} | train loss {'Reaction outcome loss': 0.3351777975768222, 'Total loss': 0.3351777975768222}
2022-11-28 01:31:51,909 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:51,909 INFO:     Epoch: 25
2022-11-28 01:31:52,634 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41622303322304127, 'Total loss': 0.41622303322304127} | train loss {'Reaction outcome loss': 0.3209348661647298, 'Total loss': 0.3209348661647298}
2022-11-28 01:31:52,634 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:52,634 INFO:     Epoch: 26
2022-11-28 01:31:53,358 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4452018890269967, 'Total loss': 0.4452018890269967} | train loss {'Reaction outcome loss': 0.3339475669059516, 'Total loss': 0.3339475669059516}
2022-11-28 01:31:53,358 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:53,358 INFO:     Epoch: 27
2022-11-28 01:31:54,083 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4273261136786882, 'Total loss': 0.4273261136786882} | train loss {'Reaction outcome loss': 0.3159941224945531, 'Total loss': 0.3159941224945531}
2022-11-28 01:31:54,084 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:54,084 INFO:     Epoch: 28
2022-11-28 01:31:54,809 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4250155907384185, 'Total loss': 0.4250155907384185} | train loss {'Reaction outcome loss': 0.33191531720374134, 'Total loss': 0.33191531720374134}
2022-11-28 01:31:54,809 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:54,810 INFO:     Epoch: 29
2022-11-28 01:31:55,530 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43371978402137756, 'Total loss': 0.43371978402137756} | train loss {'Reaction outcome loss': 0.32597419029078545, 'Total loss': 0.32597419029078545}
2022-11-28 01:31:55,531 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:55,531 INFO:     Epoch: 30
2022-11-28 01:31:56,252 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42148044982621835, 'Total loss': 0.42148044982621835} | train loss {'Reaction outcome loss': 0.3223893125251677, 'Total loss': 0.3223893125251677}
2022-11-28 01:31:56,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:56,253 INFO:     Epoch: 31
2022-11-28 01:31:56,979 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4760691821575165, 'Total loss': 0.4760691821575165} | train loss {'Reaction outcome loss': 0.31363228952736283, 'Total loss': 0.31363228952736283}
2022-11-28 01:31:56,979 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:56,979 INFO:     Epoch: 32
2022-11-28 01:31:57,704 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44652291716531267, 'Total loss': 0.44652291716531267} | train loss {'Reaction outcome loss': 0.3270035417309935, 'Total loss': 0.3270035417309935}
2022-11-28 01:31:57,705 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:57,705 INFO:     Epoch: 33
2022-11-28 01:31:58,427 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42019547314144845, 'Total loss': 0.42019547314144845} | train loss {'Reaction outcome loss': 0.31855366233720817, 'Total loss': 0.31855366233720817}
2022-11-28 01:31:58,427 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:58,427 INFO:     Epoch: 34
2022-11-28 01:31:59,154 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4275290016518083, 'Total loss': 0.4275290016518083} | train loss {'Reaction outcome loss': 0.3139795569772542, 'Total loss': 0.3139795569772542}
2022-11-28 01:31:59,154 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:59,154 INFO:     Epoch: 35
2022-11-28 01:31:59,879 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41243876447511274, 'Total loss': 0.41243876447511274} | train loss {'Reaction outcome loss': 0.31305787378450645, 'Total loss': 0.31305787378450645}
2022-11-28 01:31:59,880 INFO:     Found new best model at epoch 35
2022-11-28 01:31:59,881 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:31:59,881 INFO:     Epoch: 36
2022-11-28 01:32:00,605 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4439453912335773, 'Total loss': 0.4439453912335773} | train loss {'Reaction outcome loss': 0.3163144458317163, 'Total loss': 0.3163144458317163}
2022-11-28 01:32:00,605 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:00,605 INFO:     Epoch: 37
2022-11-28 01:32:01,329 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43215099982050964, 'Total loss': 0.43215099982050964} | train loss {'Reaction outcome loss': 0.3192678941297828, 'Total loss': 0.3192678941297828}
2022-11-28 01:32:01,329 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:01,329 INFO:     Epoch: 38
2022-11-28 01:32:02,053 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4211493992181711, 'Total loss': 0.4211493992181711} | train loss {'Reaction outcome loss': 0.30693163054983646, 'Total loss': 0.30693163054983646}
2022-11-28 01:32:02,054 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:02,054 INFO:     Epoch: 39
2022-11-28 01:32:02,784 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44070517808892007, 'Total loss': 0.44070517808892007} | train loss {'Reaction outcome loss': 0.3094324346523562, 'Total loss': 0.3094324346523562}
2022-11-28 01:32:02,784 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:02,784 INFO:     Epoch: 40
2022-11-28 01:32:03,510 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41937354969423873, 'Total loss': 0.41937354969423873} | train loss {'Reaction outcome loss': 0.31014320129119016, 'Total loss': 0.31014320129119016}
2022-11-28 01:32:03,510 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:03,510 INFO:     Epoch: 41
2022-11-28 01:32:04,237 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4396917683094047, 'Total loss': 0.4396917683094047} | train loss {'Reaction outcome loss': 0.3065892677460469, 'Total loss': 0.3065892677460469}
2022-11-28 01:32:04,237 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:04,237 INFO:     Epoch: 42
2022-11-28 01:32:04,960 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4308427002194316, 'Total loss': 0.4308427002194316} | train loss {'Reaction outcome loss': 0.3083114465428091, 'Total loss': 0.3083114465428091}
2022-11-28 01:32:04,961 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:04,961 INFO:     Epoch: 43
2022-11-28 01:32:05,686 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4197963710094607, 'Total loss': 0.4197963710094607} | train loss {'Reaction outcome loss': 0.30843321237079335, 'Total loss': 0.30843321237079335}
2022-11-28 01:32:05,687 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:05,687 INFO:     Epoch: 44
2022-11-28 01:32:06,412 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4210984471232392, 'Total loss': 0.4210984471232392} | train loss {'Reaction outcome loss': 0.3043632062144299, 'Total loss': 0.3043632062144299}
2022-11-28 01:32:06,412 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:06,412 INFO:     Epoch: 45
2022-11-28 01:32:07,137 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3966179309889328, 'Total loss': 0.3966179309889328} | train loss {'Reaction outcome loss': 0.3095151364679653, 'Total loss': 0.3095151364679653}
2022-11-28 01:32:07,137 INFO:     Found new best model at epoch 45
2022-11-28 01:32:07,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:07,138 INFO:     Epoch: 46
2022-11-28 01:32:07,863 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4654604196548462, 'Total loss': 0.4654604196548462} | train loss {'Reaction outcome loss': 0.3111644902911918, 'Total loss': 0.3111644902911918}
2022-11-28 01:32:07,863 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:07,863 INFO:     Epoch: 47
2022-11-28 01:32:08,586 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42152215817639993, 'Total loss': 0.42152215817639993} | train loss {'Reaction outcome loss': 0.31606615857217324, 'Total loss': 0.31606615857217324}
2022-11-28 01:32:08,586 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:08,586 INFO:     Epoch: 48
2022-11-28 01:32:09,314 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40950365919013354, 'Total loss': 0.40950365919013354} | train loss {'Reaction outcome loss': 0.30615106821678484, 'Total loss': 0.30615106821678484}
2022-11-28 01:32:09,314 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:09,315 INFO:     Epoch: 49
2022-11-28 01:32:10,038 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4363729056230811, 'Total loss': 0.4363729056230811} | train loss {'Reaction outcome loss': 0.3031071161395287, 'Total loss': 0.3031071161395287}
2022-11-28 01:32:10,038 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:10,038 INFO:     Epoch: 50
2022-11-28 01:32:10,760 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43677540192770403, 'Total loss': 0.43677540192770403} | train loss {'Reaction outcome loss': 0.2996591327874245, 'Total loss': 0.2996591327874245}
2022-11-28 01:32:10,760 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:10,761 INFO:     Epoch: 51
2022-11-28 01:32:11,483 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42678752039061035, 'Total loss': 0.42678752039061035} | train loss {'Reaction outcome loss': 0.30743813511617946, 'Total loss': 0.30743813511617946}
2022-11-28 01:32:11,483 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:11,483 INFO:     Epoch: 52
2022-11-28 01:32:12,207 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45568016656609467, 'Total loss': 0.45568016656609467} | train loss {'Reaction outcome loss': 0.30010844102415307, 'Total loss': 0.30010844102415307}
2022-11-28 01:32:12,209 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:12,209 INFO:     Epoch: 53
2022-11-28 01:32:12,931 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43819546266350634, 'Total loss': 0.43819546266350634} | train loss {'Reaction outcome loss': 0.3087080387220838, 'Total loss': 0.3087080387220838}
2022-11-28 01:32:12,931 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:12,931 INFO:     Epoch: 54
2022-11-28 01:32:13,651 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4260076419558636, 'Total loss': 0.4260076419558636} | train loss {'Reaction outcome loss': 0.3058641708738082, 'Total loss': 0.3058641708738082}
2022-11-28 01:32:13,651 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:13,651 INFO:     Epoch: 55
2022-11-28 01:32:14,372 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42333682227966396, 'Total loss': 0.42333682227966396} | train loss {'Reaction outcome loss': 0.2992335413872454, 'Total loss': 0.2992335413872454}
2022-11-28 01:32:14,372 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:14,372 INFO:     Epoch: 56
2022-11-28 01:32:15,095 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.433803329634112, 'Total loss': 0.433803329634112} | train loss {'Reaction outcome loss': 0.3022763025463864, 'Total loss': 0.3022763025463864}
2022-11-28 01:32:15,095 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:15,095 INFO:     Epoch: 57
2022-11-28 01:32:15,816 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4388489106366801, 'Total loss': 0.4388489106366801} | train loss {'Reaction outcome loss': 0.30357945546569665, 'Total loss': 0.30357945546569665}
2022-11-28 01:32:15,816 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:15,816 INFO:     Epoch: 58
2022-11-28 01:32:16,537 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4579684945733048, 'Total loss': 0.4579684945733048} | train loss {'Reaction outcome loss': 0.3062337505866878, 'Total loss': 0.3062337505866878}
2022-11-28 01:32:16,537 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:16,537 INFO:     Epoch: 59
2022-11-28 01:32:17,260 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4397724156462869, 'Total loss': 0.4397724156462869} | train loss {'Reaction outcome loss': 0.3027649082985409, 'Total loss': 0.3027649082985409}
2022-11-28 01:32:17,261 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:17,261 INFO:     Epoch: 60
2022-11-28 01:32:17,987 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.414473611948102, 'Total loss': 0.414473611948102} | train loss {'Reaction outcome loss': 0.30736348657439855, 'Total loss': 0.30736348657439855}
2022-11-28 01:32:17,987 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:17,988 INFO:     Epoch: 61
2022-11-28 01:32:18,713 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4012612846008567, 'Total loss': 0.4012612846008567} | train loss {'Reaction outcome loss': 0.3055217930451963, 'Total loss': 0.3055217930451963}
2022-11-28 01:32:18,714 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:18,714 INFO:     Epoch: 62
2022-11-28 01:32:19,441 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4175608669256055, 'Total loss': 0.4175608669256055} | train loss {'Reaction outcome loss': 0.3108775925617742, 'Total loss': 0.3108775925617742}
2022-11-28 01:32:19,441 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:19,441 INFO:     Epoch: 63
2022-11-28 01:32:20,161 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4661042236311491, 'Total loss': 0.4661042236311491} | train loss {'Reaction outcome loss': 0.30716025838589767, 'Total loss': 0.30716025838589767}
2022-11-28 01:32:20,161 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:20,162 INFO:     Epoch: 64
2022-11-28 01:32:20,886 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4059646309808243, 'Total loss': 0.4059646309808243} | train loss {'Reaction outcome loss': 0.29841775403848825, 'Total loss': 0.29841775403848825}
2022-11-28 01:32:20,886 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:20,886 INFO:     Epoch: 65
2022-11-28 01:32:21,610 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43482929086962413, 'Total loss': 0.43482929086962413} | train loss {'Reaction outcome loss': 0.2973063306813418, 'Total loss': 0.2973063306813418}
2022-11-28 01:32:21,610 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:21,610 INFO:     Epoch: 66
2022-11-28 01:32:22,335 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43800230705460835, 'Total loss': 0.43800230705460835} | train loss {'Reaction outcome loss': 0.30038998198707073, 'Total loss': 0.30038998198707073}
2022-11-28 01:32:22,335 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:22,335 INFO:     Epoch: 67
2022-11-28 01:32:23,060 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4100222518277723, 'Total loss': 0.4100222518277723} | train loss {'Reaction outcome loss': 0.2966627019816909, 'Total loss': 0.2966627019816909}
2022-11-28 01:32:23,060 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:23,060 INFO:     Epoch: 68
2022-11-28 01:32:23,781 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4228060815569966, 'Total loss': 0.4228060815569966} | train loss {'Reaction outcome loss': 0.2885276425119752, 'Total loss': 0.2885276425119752}
2022-11-28 01:32:23,781 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:23,781 INFO:     Epoch: 69
2022-11-28 01:32:24,503 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4264954858741095, 'Total loss': 0.4264954858741095} | train loss {'Reaction outcome loss': 0.2978209272274338, 'Total loss': 0.2978209272274338}
2022-11-28 01:32:24,503 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:24,503 INFO:     Epoch: 70
2022-11-28 01:32:25,227 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4255403574816016, 'Total loss': 0.4255403574816016} | train loss {'Reaction outcome loss': 0.3035159428213642, 'Total loss': 0.3035159428213642}
2022-11-28 01:32:25,227 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:25,227 INFO:     Epoch: 71
2022-11-28 01:32:25,952 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4164111097884733, 'Total loss': 0.4164111097884733} | train loss {'Reaction outcome loss': 0.30371428667509703, 'Total loss': 0.30371428667509703}
2022-11-28 01:32:25,952 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:25,952 INFO:     Epoch: 72
2022-11-28 01:32:26,677 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44419307660224827, 'Total loss': 0.44419307660224827} | train loss {'Reaction outcome loss': 0.3008797736799816, 'Total loss': 0.3008797736799816}
2022-11-28 01:32:26,677 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:26,677 INFO:     Epoch: 73
2022-11-28 01:32:27,401 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41061480967111363, 'Total loss': 0.41061480967111363} | train loss {'Reaction outcome loss': 0.29890803810348154, 'Total loss': 0.29890803810348154}
2022-11-28 01:32:27,401 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:27,402 INFO:     Epoch: 74
2022-11-28 01:32:28,123 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.440748585864555, 'Total loss': 0.440748585864555} | train loss {'Reaction outcome loss': 0.30391775436421153, 'Total loss': 0.30391775436421153}
2022-11-28 01:32:28,123 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:28,124 INFO:     Epoch: 75
2022-11-28 01:32:28,844 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43417892761008686, 'Total loss': 0.43417892761008686} | train loss {'Reaction outcome loss': 0.29881833138183933, 'Total loss': 0.29881833138183933}
2022-11-28 01:32:28,844 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:28,844 INFO:     Epoch: 76
2022-11-28 01:32:29,569 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4451731942420782, 'Total loss': 0.4451731942420782} | train loss {'Reaction outcome loss': 0.2988289933172499, 'Total loss': 0.2988289933172499}
2022-11-28 01:32:29,569 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:29,569 INFO:     Epoch: 77
2022-11-28 01:32:30,296 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4872268098731374, 'Total loss': 0.4872268098731374} | train loss {'Reaction outcome loss': 0.2903790586933308, 'Total loss': 0.2903790586933308}
2022-11-28 01:32:30,296 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:30,296 INFO:     Epoch: 78
2022-11-28 01:32:31,021 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4686176717974419, 'Total loss': 0.4686176717974419} | train loss {'Reaction outcome loss': 0.3060781575924875, 'Total loss': 0.3060781575924875}
2022-11-28 01:32:31,022 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:31,022 INFO:     Epoch: 79
2022-11-28 01:32:31,745 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4296765135124672, 'Total loss': 0.4296765135124672} | train loss {'Reaction outcome loss': 0.2979426980173192, 'Total loss': 0.2979426980173192}
2022-11-28 01:32:31,746 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:31,746 INFO:     Epoch: 80
2022-11-28 01:32:32,471 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4238153675267863, 'Total loss': 0.4238153675267863} | train loss {'Reaction outcome loss': 0.2945123553832537, 'Total loss': 0.2945123553832537}
2022-11-28 01:32:32,471 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:32,471 INFO:     Epoch: 81
2022-11-28 01:32:33,200 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43560042700102164, 'Total loss': 0.43560042700102164} | train loss {'Reaction outcome loss': 0.30679907297321374, 'Total loss': 0.30679907297321374}
2022-11-28 01:32:33,200 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:33,200 INFO:     Epoch: 82
2022-11-28 01:32:33,919 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4321712754493536, 'Total loss': 0.4321712754493536} | train loss {'Reaction outcome loss': 0.30499726935788307, 'Total loss': 0.30499726935788307}
2022-11-28 01:32:33,919 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:33,919 INFO:     Epoch: 83
2022-11-28 01:32:34,642 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.426235822917417, 'Total loss': 0.426235822917417} | train loss {'Reaction outcome loss': 0.30391292110147317, 'Total loss': 0.30391292110147317}
2022-11-28 01:32:34,642 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:34,642 INFO:     Epoch: 84
2022-11-28 01:32:35,365 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4289163543387901, 'Total loss': 0.4289163543387901} | train loss {'Reaction outcome loss': 0.2926822843578841, 'Total loss': 0.2926822843578841}
2022-11-28 01:32:35,365 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:35,365 INFO:     Epoch: 85
2022-11-28 01:32:36,088 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4367130599742712, 'Total loss': 0.4367130599742712} | train loss {'Reaction outcome loss': 0.29037120431290625, 'Total loss': 0.29037120431290625}
2022-11-28 01:32:36,088 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:36,088 INFO:     Epoch: 86
2022-11-28 01:32:36,814 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42634868656480035, 'Total loss': 0.42634868656480035} | train loss {'Reaction outcome loss': 0.3083075172426295, 'Total loss': 0.3083075172426295}
2022-11-28 01:32:36,814 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:36,814 INFO:     Epoch: 87
2022-11-28 01:32:37,540 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42052197542994524, 'Total loss': 0.42052197542994524} | train loss {'Reaction outcome loss': 0.3055015771468151, 'Total loss': 0.3055015771468151}
2022-11-28 01:32:37,540 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:37,540 INFO:     Epoch: 88
2022-11-28 01:32:38,262 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.416363580628883, 'Total loss': 0.416363580628883} | train loss {'Reaction outcome loss': 0.30533191997604253, 'Total loss': 0.30533191997604253}
2022-11-28 01:32:38,263 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:38,263 INFO:     Epoch: 89
2022-11-28 01:32:38,989 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46158816959968835, 'Total loss': 0.46158816959968835} | train loss {'Reaction outcome loss': 0.2965347575201533, 'Total loss': 0.2965347575201533}
2022-11-28 01:32:38,989 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:38,989 INFO:     Epoch: 90
2022-11-28 01:32:39,711 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42091609606909197, 'Total loss': 0.42091609606909197} | train loss {'Reaction outcome loss': 0.29712066049706887, 'Total loss': 0.29712066049706887}
2022-11-28 01:32:39,711 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:39,711 INFO:     Epoch: 91
2022-11-28 01:32:40,436 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4025312526974567, 'Total loss': 0.4025312526974567} | train loss {'Reaction outcome loss': 0.2988891105990687, 'Total loss': 0.2988891105990687}
2022-11-28 01:32:40,436 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:40,436 INFO:     Epoch: 92
2022-11-28 01:32:41,159 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4036281739556512, 'Total loss': 0.4036281739556512} | train loss {'Reaction outcome loss': 0.2936975662268049, 'Total loss': 0.2936975662268049}
2022-11-28 01:32:41,159 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:41,159 INFO:     Epoch: 93
2022-11-28 01:32:41,880 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.415848414218703, 'Total loss': 0.415848414218703} | train loss {'Reaction outcome loss': 0.29939132245620753, 'Total loss': 0.29939132245620753}
2022-11-28 01:32:41,880 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:41,880 INFO:     Epoch: 94
2022-11-28 01:32:42,603 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.435067349048548, 'Total loss': 0.435067349048548} | train loss {'Reaction outcome loss': 0.3018437350995808, 'Total loss': 0.3018437350995808}
2022-11-28 01:32:42,603 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:42,603 INFO:     Epoch: 95
2022-11-28 01:32:43,326 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4770307911689891, 'Total loss': 0.4770307911689891} | train loss {'Reaction outcome loss': 0.303995780136699, 'Total loss': 0.303995780136699}
2022-11-28 01:32:43,327 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:43,327 INFO:     Epoch: 96
2022-11-28 01:32:44,050 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4532430314047392, 'Total loss': 0.4532430314047392} | train loss {'Reaction outcome loss': 0.29979624024194307, 'Total loss': 0.29979624024194307}
2022-11-28 01:32:44,050 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:44,050 INFO:     Epoch: 97
2022-11-28 01:32:44,771 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4275320076145405, 'Total loss': 0.4275320076145405} | train loss {'Reaction outcome loss': 0.28772193995686984, 'Total loss': 0.28772193995686984}
2022-11-28 01:32:44,772 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:44,772 INFO:     Epoch: 98
2022-11-28 01:32:45,496 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4123976201165554, 'Total loss': 0.4123976201165554} | train loss {'Reaction outcome loss': 0.2950687449410001, 'Total loss': 0.2950687449410001}
2022-11-28 01:32:45,496 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:45,496 INFO:     Epoch: 99
2022-11-28 01:32:46,218 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4176505346630895, 'Total loss': 0.4176505346630895} | train loss {'Reaction outcome loss': 0.2985763739933611, 'Total loss': 0.2985763739933611}
2022-11-28 01:32:46,218 INFO:     Best model found after epoch 46 of 100.
2022-11-28 01:32:46,218 INFO:   Done with stage: TRAINING
2022-11-28 01:32:46,218 INFO:   Starting stage: EVALUATION
2022-11-28 01:32:46,361 INFO:   Done with stage: EVALUATION
2022-11-28 01:32:46,361 INFO:   Leaving out SEQ value Fold_3
2022-11-28 01:32:46,374 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-28 01:32:46,374 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:32:47,012 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:32:47,013 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:32:47,082 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:32:47,082 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:32:47,082 INFO:     No hyperparam tuning for this model
2022-11-28 01:32:47,082 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:32:47,082 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:32:47,083 INFO:     None feature selector for col prot
2022-11-28 01:32:47,083 INFO:     None feature selector for col prot
2022-11-28 01:32:47,083 INFO:     None feature selector for col prot
2022-11-28 01:32:47,084 INFO:     None feature selector for col chem
2022-11-28 01:32:47,084 INFO:     None feature selector for col chem
2022-11-28 01:32:47,084 INFO:     None feature selector for col chem
2022-11-28 01:32:47,084 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:32:47,084 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:32:47,085 INFO:     Number of params in model 169741
2022-11-28 01:32:47,088 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:32:47,089 INFO:   Starting stage: TRAINING
2022-11-28 01:32:47,141 INFO:     Val loss before train {'Reaction outcome loss': 1.000449140404546, 'Total loss': 1.000449140404546}
2022-11-28 01:32:47,141 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:47,141 INFO:     Epoch: 0
2022-11-28 01:32:47,876 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5421293405599372, 'Total loss': 0.5421293405599372} | train loss {'Reaction outcome loss': 0.6386655493349326, 'Total loss': 0.6386655493349326}
2022-11-28 01:32:47,876 INFO:     Found new best model at epoch 0
2022-11-28 01:32:47,876 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:47,877 INFO:     Epoch: 1
2022-11-28 01:32:48,608 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5072201414163723, 'Total loss': 0.5072201414163723} | train loss {'Reaction outcome loss': 0.5042898064692978, 'Total loss': 0.5042898064692978}
2022-11-28 01:32:48,609 INFO:     Found new best model at epoch 1
2022-11-28 01:32:48,609 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:48,609 INFO:     Epoch: 2
2022-11-28 01:32:49,343 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4955531473076621, 'Total loss': 0.4955531473076621} | train loss {'Reaction outcome loss': 0.4676925431875909, 'Total loss': 0.4676925431875909}
2022-11-28 01:32:49,344 INFO:     Found new best model at epoch 2
2022-11-28 01:32:49,345 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:49,345 INFO:     Epoch: 3
2022-11-28 01:32:50,077 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47901977910551913, 'Total loss': 0.47901977910551913} | train loss {'Reaction outcome loss': 0.44552460786138404, 'Total loss': 0.44552460786138404}
2022-11-28 01:32:50,077 INFO:     Found new best model at epoch 3
2022-11-28 01:32:50,078 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:50,078 INFO:     Epoch: 4
2022-11-28 01:32:50,820 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46454177866148394, 'Total loss': 0.46454177866148394} | train loss {'Reaction outcome loss': 0.43242546989292396, 'Total loss': 0.43242546989292396}
2022-11-28 01:32:50,820 INFO:     Found new best model at epoch 4
2022-11-28 01:32:50,820 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:50,821 INFO:     Epoch: 5
2022-11-28 01:32:51,562 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4521643862474796, 'Total loss': 0.4521643862474796} | train loss {'Reaction outcome loss': 0.4253645679440166, 'Total loss': 0.4253645679440166}
2022-11-28 01:32:51,562 INFO:     Found new best model at epoch 5
2022-11-28 01:32:51,563 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:51,563 INFO:     Epoch: 6
2022-11-28 01:32:52,301 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44590288296688435, 'Total loss': 0.44590288296688435} | train loss {'Reaction outcome loss': 0.4095932528620861, 'Total loss': 0.4095932528620861}
2022-11-28 01:32:52,301 INFO:     Found new best model at epoch 6
2022-11-28 01:32:52,302 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:52,302 INFO:     Epoch: 7
2022-11-28 01:32:53,042 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4516173174907995, 'Total loss': 0.4516173174907995} | train loss {'Reaction outcome loss': 0.40626323977332623, 'Total loss': 0.40626323977332623}
2022-11-28 01:32:53,042 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:53,042 INFO:     Epoch: 8
2022-11-28 01:32:53,781 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4523694244928138, 'Total loss': 0.4523694244928138} | train loss {'Reaction outcome loss': 0.3945663027221062, 'Total loss': 0.3945663027221062}
2022-11-28 01:32:53,781 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:53,781 INFO:     Epoch: 9
2022-11-28 01:32:54,518 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.457748317441275, 'Total loss': 0.457748317441275} | train loss {'Reaction outcome loss': 0.387230068323065, 'Total loss': 0.387230068323065}
2022-11-28 01:32:54,518 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:54,518 INFO:     Epoch: 10
2022-11-28 01:32:55,258 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42791081861008046, 'Total loss': 0.42791081861008046} | train loss {'Reaction outcome loss': 0.3860400376810891, 'Total loss': 0.3860400376810891}
2022-11-28 01:32:55,258 INFO:     Found new best model at epoch 10
2022-11-28 01:32:55,259 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:55,259 INFO:     Epoch: 11
2022-11-28 01:32:55,997 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4392486179983893, 'Total loss': 0.4392486179983893} | train loss {'Reaction outcome loss': 0.37826236691631254, 'Total loss': 0.37826236691631254}
2022-11-28 01:32:55,997 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:55,997 INFO:     Epoch: 12
2022-11-28 01:32:56,731 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5222653985716575, 'Total loss': 0.5222653985716575} | train loss {'Reaction outcome loss': 0.37196694155696963, 'Total loss': 0.37196694155696963}
2022-11-28 01:32:56,731 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:56,731 INFO:     Epoch: 13
2022-11-28 01:32:57,465 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4614116823257402, 'Total loss': 0.4614116823257402} | train loss {'Reaction outcome loss': 0.37117314671517393, 'Total loss': 0.37117314671517393}
2022-11-28 01:32:57,465 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:57,465 INFO:     Epoch: 14
2022-11-28 01:32:58,200 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4568036014950553, 'Total loss': 0.4568036014950553} | train loss {'Reaction outcome loss': 0.3779077417843166, 'Total loss': 0.3779077417843166}
2022-11-28 01:32:58,200 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:58,200 INFO:     Epoch: 15
2022-11-28 01:32:58,939 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42062672002370965, 'Total loss': 0.42062672002370965} | train loss {'Reaction outcome loss': 0.36169284743974445, 'Total loss': 0.36169284743974445}
2022-11-28 01:32:58,939 INFO:     Found new best model at epoch 15
2022-11-28 01:32:58,940 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:58,940 INFO:     Epoch: 16
2022-11-28 01:32:59,674 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44503296149331467, 'Total loss': 0.44503296149331467} | train loss {'Reaction outcome loss': 0.3625884112581366, 'Total loss': 0.3625884112581366}
2022-11-28 01:32:59,675 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:32:59,675 INFO:     Epoch: 17
2022-11-28 01:33:00,404 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4153324403735094, 'Total loss': 0.4153324403735094} | train loss {'Reaction outcome loss': 0.36352386404989195, 'Total loss': 0.36352386404989195}
2022-11-28 01:33:00,404 INFO:     Found new best model at epoch 17
2022-11-28 01:33:00,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:00,405 INFO:     Epoch: 18
2022-11-28 01:33:01,139 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4524857377590135, 'Total loss': 0.4524857377590135} | train loss {'Reaction outcome loss': 0.35048980552886355, 'Total loss': 0.35048980552886355}
2022-11-28 01:33:01,140 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:01,140 INFO:     Epoch: 19
2022-11-28 01:33:01,871 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4454914709163267, 'Total loss': 0.4454914709163267} | train loss {'Reaction outcome loss': 0.3591525282283298, 'Total loss': 0.3591525282283298}
2022-11-28 01:33:01,872 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:01,872 INFO:     Epoch: 20
2022-11-28 01:33:02,603 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4560207339913346, 'Total loss': 0.4560207339913346} | train loss {'Reaction outcome loss': 0.3456320892714086, 'Total loss': 0.3456320892714086}
2022-11-28 01:33:02,604 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:02,604 INFO:     Epoch: 21
2022-11-28 01:33:03,337 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44680999461994614, 'Total loss': 0.44680999461994614} | train loss {'Reaction outcome loss': 0.3466949159371071, 'Total loss': 0.3466949159371071}
2022-11-28 01:33:03,338 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:03,338 INFO:     Epoch: 22
2022-11-28 01:33:04,068 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4406279918066291, 'Total loss': 0.4406279918066291} | train loss {'Reaction outcome loss': 0.3529583958634099, 'Total loss': 0.3529583958634099}
2022-11-28 01:33:04,068 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:04,068 INFO:     Epoch: 23
2022-11-28 01:33:04,798 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.457101299665695, 'Total loss': 0.457101299665695} | train loss {'Reaction outcome loss': 0.33962380002084813, 'Total loss': 0.33962380002084813}
2022-11-28 01:33:04,798 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:04,798 INFO:     Epoch: 24
2022-11-28 01:33:05,530 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42069071427334187, 'Total loss': 0.42069071427334187} | train loss {'Reaction outcome loss': 0.3416085899425823, 'Total loss': 0.3416085899425823}
2022-11-28 01:33:05,530 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:05,531 INFO:     Epoch: 25
2022-11-28 01:33:06,258 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4555048010376997, 'Total loss': 0.4555048010376997} | train loss {'Reaction outcome loss': 0.3421463012451031, 'Total loss': 0.3421463012451031}
2022-11-28 01:33:06,258 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:06,259 INFO:     Epoch: 26
2022-11-28 01:33:06,994 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4566718929035719, 'Total loss': 0.4566718929035719} | train loss {'Reaction outcome loss': 0.34160472898453964, 'Total loss': 0.34160472898453964}
2022-11-28 01:33:06,994 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:06,994 INFO:     Epoch: 27
2022-11-28 01:33:07,732 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44905616135098214, 'Total loss': 0.44905616135098214} | train loss {'Reaction outcome loss': 0.33335439955479784, 'Total loss': 0.33335439955479784}
2022-11-28 01:33:07,732 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:07,732 INFO:     Epoch: 28
2022-11-28 01:33:08,471 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42273251261822015, 'Total loss': 0.42273251261822015} | train loss {'Reaction outcome loss': 0.33915360671941375, 'Total loss': 0.33915360671941375}
2022-11-28 01:33:08,471 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:08,471 INFO:     Epoch: 29
2022-11-28 01:33:09,209 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41320861217587496, 'Total loss': 0.41320861217587496} | train loss {'Reaction outcome loss': 0.34160609082242505, 'Total loss': 0.34160609082242505}
2022-11-28 01:33:09,209 INFO:     Found new best model at epoch 29
2022-11-28 01:33:09,210 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:09,210 INFO:     Epoch: 30
2022-11-28 01:33:09,947 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40543185936850173, 'Total loss': 0.40543185936850173} | train loss {'Reaction outcome loss': 0.3334028270462009, 'Total loss': 0.3334028270462009}
2022-11-28 01:33:09,947 INFO:     Found new best model at epoch 30
2022-11-28 01:33:09,948 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:09,948 INFO:     Epoch: 31
2022-11-28 01:33:10,680 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42459877320500305, 'Total loss': 0.42459877320500305} | train loss {'Reaction outcome loss': 0.32793419759293074, 'Total loss': 0.32793419759293074}
2022-11-28 01:33:10,680 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:10,680 INFO:     Epoch: 32
2022-11-28 01:33:11,413 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.439455219826033, 'Total loss': 0.439455219826033} | train loss {'Reaction outcome loss': 0.32942498789825403, 'Total loss': 0.32942498789825403}
2022-11-28 01:33:11,413 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:11,413 INFO:     Epoch: 33
2022-11-28 01:33:12,149 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.438843174555967, 'Total loss': 0.438843174555967} | train loss {'Reaction outcome loss': 0.34467642122238384, 'Total loss': 0.34467642122238384}
2022-11-28 01:33:12,149 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:12,149 INFO:     Epoch: 34
2022-11-28 01:33:12,883 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4734682815019475, 'Total loss': 0.4734682815019475} | train loss {'Reaction outcome loss': 0.32400792467667433, 'Total loss': 0.32400792467667433}
2022-11-28 01:33:12,883 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:12,884 INFO:     Epoch: 35
2022-11-28 01:33:13,619 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42091612136641215, 'Total loss': 0.42091612136641215} | train loss {'Reaction outcome loss': 0.32801441411625165, 'Total loss': 0.32801441411625165}
2022-11-28 01:33:13,619 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:13,620 INFO:     Epoch: 36
2022-11-28 01:33:14,354 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41528408229351044, 'Total loss': 0.41528408229351044} | train loss {'Reaction outcome loss': 0.3244753821951444, 'Total loss': 0.3244753821951444}
2022-11-28 01:33:14,356 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:14,356 INFO:     Epoch: 37
2022-11-28 01:33:15,091 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45981750914523767, 'Total loss': 0.45981750914523767} | train loss {'Reaction outcome loss': 0.3213320734803794, 'Total loss': 0.3213320734803794}
2022-11-28 01:33:15,091 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:15,091 INFO:     Epoch: 38
2022-11-28 01:33:15,825 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43917369080144303, 'Total loss': 0.43917369080144303} | train loss {'Reaction outcome loss': 0.32578506445909133, 'Total loss': 0.32578506445909133}
2022-11-28 01:33:15,825 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:15,825 INFO:     Epoch: 39
2022-11-28 01:33:16,562 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4276366722445155, 'Total loss': 0.4276366722445155} | train loss {'Reaction outcome loss': 0.3265276775985468, 'Total loss': 0.3265276775985468}
2022-11-28 01:33:16,562 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:16,562 INFO:     Epoch: 40
2022-11-28 01:33:17,301 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4478144770444826, 'Total loss': 0.4478144770444826} | train loss {'Reaction outcome loss': 0.32762317655638595, 'Total loss': 0.32762317655638595}
2022-11-28 01:33:17,301 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:17,301 INFO:     Epoch: 41
2022-11-28 01:33:18,040 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42414525220560473, 'Total loss': 0.42414525220560473} | train loss {'Reaction outcome loss': 0.3242146292182266, 'Total loss': 0.3242146292182266}
2022-11-28 01:33:18,040 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:18,041 INFO:     Epoch: 42
2022-11-28 01:33:18,777 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4421078188474788, 'Total loss': 0.4421078188474788} | train loss {'Reaction outcome loss': 0.31883315653463856, 'Total loss': 0.31883315653463856}
2022-11-28 01:33:18,777 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:18,777 INFO:     Epoch: 43
2022-11-28 01:33:19,511 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4157990466716678, 'Total loss': 0.4157990466716678} | train loss {'Reaction outcome loss': 0.3181851479362269, 'Total loss': 0.3181851479362269}
2022-11-28 01:33:19,511 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:19,511 INFO:     Epoch: 44
2022-11-28 01:33:20,248 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45724427907965903, 'Total loss': 0.45724427907965903} | train loss {'Reaction outcome loss': 0.3189719179187153, 'Total loss': 0.3189719179187153}
2022-11-28 01:33:20,248 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:20,248 INFO:     Epoch: 45
2022-11-28 01:33:20,981 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4241875063541324, 'Total loss': 0.4241875063541324} | train loss {'Reaction outcome loss': 0.31857870974135205, 'Total loss': 0.31857870974135205}
2022-11-28 01:33:20,982 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:20,982 INFO:     Epoch: 46
2022-11-28 01:33:21,720 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45648014025632727, 'Total loss': 0.45648014025632727} | train loss {'Reaction outcome loss': 0.32275077650231904, 'Total loss': 0.32275077650231904}
2022-11-28 01:33:21,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:21,720 INFO:     Epoch: 47
2022-11-28 01:33:22,455 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.431692183710808, 'Total loss': 0.431692183710808} | train loss {'Reaction outcome loss': 0.317440426923701, 'Total loss': 0.317440426923701}
2022-11-28 01:33:22,455 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:22,455 INFO:     Epoch: 48
2022-11-28 01:33:23,194 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44026686181855756, 'Total loss': 0.44026686181855756} | train loss {'Reaction outcome loss': 0.3192325302506568, 'Total loss': 0.3192325302506568}
2022-11-28 01:33:23,194 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:23,194 INFO:     Epoch: 49
2022-11-28 01:33:23,935 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42114097330459327, 'Total loss': 0.42114097330459327} | train loss {'Reaction outcome loss': 0.32327626089825007, 'Total loss': 0.32327626089825007}
2022-11-28 01:33:23,935 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:23,935 INFO:     Epoch: 50
2022-11-28 01:33:24,673 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.484524630529936, 'Total loss': 0.484524630529936} | train loss {'Reaction outcome loss': 0.32019221336870896, 'Total loss': 0.32019221336870896}
2022-11-28 01:33:24,673 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:24,673 INFO:     Epoch: 51
2022-11-28 01:33:25,413 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4257936044487842, 'Total loss': 0.4257936044487842} | train loss {'Reaction outcome loss': 0.32643185803269753, 'Total loss': 0.32643185803269753}
2022-11-28 01:33:25,413 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:25,413 INFO:     Epoch: 52
2022-11-28 01:33:26,154 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4585341041864351, 'Total loss': 0.4585341041864351} | train loss {'Reaction outcome loss': 0.3239555708819725, 'Total loss': 0.3239555708819725}
2022-11-28 01:33:26,154 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:26,154 INFO:     Epoch: 53
2022-11-28 01:33:26,892 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4491539798503698, 'Total loss': 0.4491539798503698} | train loss {'Reaction outcome loss': 0.3263662056234039, 'Total loss': 0.3263662056234039}
2022-11-28 01:33:26,892 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:26,893 INFO:     Epoch: 54
2022-11-28 01:33:27,631 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4318762376557949, 'Total loss': 0.4318762376557949} | train loss {'Reaction outcome loss': 0.3263661156362686, 'Total loss': 0.3263661156362686}
2022-11-28 01:33:27,631 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:27,631 INFO:     Epoch: 55
2022-11-28 01:33:28,366 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43566760524760845, 'Total loss': 0.43566760524760845} | train loss {'Reaction outcome loss': 0.3105778193070752, 'Total loss': 0.3105778193070752}
2022-11-28 01:33:28,366 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:28,366 INFO:     Epoch: 56
2022-11-28 01:33:29,106 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.427011773683304, 'Total loss': 0.427011773683304} | train loss {'Reaction outcome loss': 0.31760466309478047, 'Total loss': 0.31760466309478047}
2022-11-28 01:33:29,106 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:29,107 INFO:     Epoch: 57
2022-11-28 01:33:29,848 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4364432974956756, 'Total loss': 0.4364432974956756} | train loss {'Reaction outcome loss': 0.3222818519065126, 'Total loss': 0.3222818519065126}
2022-11-28 01:33:29,848 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:29,848 INFO:     Epoch: 58
2022-11-28 01:33:30,585 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4178822764823603, 'Total loss': 0.4178822764823603} | train loss {'Reaction outcome loss': 0.3178948525522576, 'Total loss': 0.3178948525522576}
2022-11-28 01:33:30,585 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:30,586 INFO:     Epoch: 59
2022-11-28 01:33:31,320 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4342957752388577, 'Total loss': 0.4342957752388577} | train loss {'Reaction outcome loss': 0.31186695970961303, 'Total loss': 0.31186695970961303}
2022-11-28 01:33:31,320 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:31,320 INFO:     Epoch: 60
2022-11-28 01:33:32,059 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4484598324742428, 'Total loss': 0.4484598324742428} | train loss {'Reaction outcome loss': 0.3163113884291932, 'Total loss': 0.3163113884291932}
2022-11-28 01:33:32,059 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:32,059 INFO:     Epoch: 61
2022-11-28 01:33:32,796 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46573894938757254, 'Total loss': 0.46573894938757254} | train loss {'Reaction outcome loss': 0.31474778144696697, 'Total loss': 0.31474778144696697}
2022-11-28 01:33:32,796 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:32,796 INFO:     Epoch: 62
2022-11-28 01:33:33,532 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4448572560105213, 'Total loss': 0.4448572560105213} | train loss {'Reaction outcome loss': 0.3265501330682977, 'Total loss': 0.3265501330682977}
2022-11-28 01:33:33,532 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:33,533 INFO:     Epoch: 63
2022-11-28 01:33:34,270 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4259329613211543, 'Total loss': 0.4259329613211543} | train loss {'Reaction outcome loss': 0.3120628556877863, 'Total loss': 0.3120628556877863}
2022-11-28 01:33:34,270 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:34,270 INFO:     Epoch: 64
2022-11-28 01:33:35,008 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44137426725653717, 'Total loss': 0.44137426725653717} | train loss {'Reaction outcome loss': 0.313753463388955, 'Total loss': 0.313753463388955}
2022-11-28 01:33:35,008 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:35,008 INFO:     Epoch: 65
2022-11-28 01:33:35,744 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4320370638093283, 'Total loss': 0.4320370638093283} | train loss {'Reaction outcome loss': 0.31735088453307503, 'Total loss': 0.31735088453307503}
2022-11-28 01:33:35,745 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:35,745 INFO:     Epoch: 66
2022-11-28 01:33:36,477 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4302284838848336, 'Total loss': 0.4302284838848336} | train loss {'Reaction outcome loss': 0.31649393492118744, 'Total loss': 0.31649393492118744}
2022-11-28 01:33:36,477 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:36,477 INFO:     Epoch: 67
2022-11-28 01:33:37,214 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4451259152833806, 'Total loss': 0.4451259152833806} | train loss {'Reaction outcome loss': 0.3219779022343335, 'Total loss': 0.3219779022343335}
2022-11-28 01:33:37,214 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:37,214 INFO:     Epoch: 68
2022-11-28 01:33:37,950 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4497861030489899, 'Total loss': 0.4497861030489899} | train loss {'Reaction outcome loss': 0.31942595972023047, 'Total loss': 0.31942595972023047}
2022-11-28 01:33:37,951 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:37,951 INFO:     Epoch: 69
2022-11-28 01:33:38,686 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45189277273277906, 'Total loss': 0.45189277273277906} | train loss {'Reaction outcome loss': 0.3177218271923236, 'Total loss': 0.3177218271923236}
2022-11-28 01:33:38,687 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:38,687 INFO:     Epoch: 70
2022-11-28 01:33:39,422 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4375867935460667, 'Total loss': 0.4375867935460667} | train loss {'Reaction outcome loss': 0.31364752028564935, 'Total loss': 0.31364752028564935}
2022-11-28 01:33:39,422 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:39,423 INFO:     Epoch: 71
2022-11-28 01:33:40,163 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4405055205489314, 'Total loss': 0.4405055205489314} | train loss {'Reaction outcome loss': 0.3236710705534845, 'Total loss': 0.3236710705534845}
2022-11-28 01:33:40,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:40,163 INFO:     Epoch: 72
2022-11-28 01:33:40,900 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4248159652532533, 'Total loss': 0.4248159652532533} | train loss {'Reaction outcome loss': 0.3119163335163574, 'Total loss': 0.3119163335163574}
2022-11-28 01:33:40,901 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:40,901 INFO:     Epoch: 73
2022-11-28 01:33:41,640 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.435118570230728, 'Total loss': 0.435118570230728} | train loss {'Reaction outcome loss': 0.3196523939488364, 'Total loss': 0.3196523939488364}
2022-11-28 01:33:41,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:41,640 INFO:     Epoch: 74
2022-11-28 01:33:42,382 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43549987188605377, 'Total loss': 0.43549987188605377} | train loss {'Reaction outcome loss': 0.31425657847010696, 'Total loss': 0.31425657847010696}
2022-11-28 01:33:42,382 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:42,382 INFO:     Epoch: 75
2022-11-28 01:33:43,125 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4577741870699927, 'Total loss': 0.4577741870699927} | train loss {'Reaction outcome loss': 0.31804195539567803, 'Total loss': 0.31804195539567803}
2022-11-28 01:33:43,125 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:43,126 INFO:     Epoch: 76
2022-11-28 01:33:43,868 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4345964425525, 'Total loss': 0.4345964425525} | train loss {'Reaction outcome loss': 0.32237368706064146, 'Total loss': 0.32237368706064146}
2022-11-28 01:33:43,868 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:43,868 INFO:     Epoch: 77
2022-11-28 01:33:44,611 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42552193548790246, 'Total loss': 0.42552193548790246} | train loss {'Reaction outcome loss': 0.30971058305413995, 'Total loss': 0.30971058305413995}
2022-11-28 01:33:44,611 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:44,611 INFO:     Epoch: 78
2022-11-28 01:33:45,353 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4467733703380407, 'Total loss': 0.4467733703380407} | train loss {'Reaction outcome loss': 0.3176935345667308, 'Total loss': 0.3176935345667308}
2022-11-28 01:33:45,354 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:45,354 INFO:     Epoch: 79
2022-11-28 01:33:46,099 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43027265092661215, 'Total loss': 0.43027265092661215} | train loss {'Reaction outcome loss': 0.31608904461513776, 'Total loss': 0.31608904461513776}
2022-11-28 01:33:46,099 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:46,099 INFO:     Epoch: 80
2022-11-28 01:33:46,836 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44692527537429055, 'Total loss': 0.44692527537429055} | train loss {'Reaction outcome loss': 0.31602029059631903, 'Total loss': 0.31602029059631903}
2022-11-28 01:33:46,836 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:46,836 INFO:     Epoch: 81
2022-11-28 01:33:47,582 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4337511410893396, 'Total loss': 0.4337511410893396} | train loss {'Reaction outcome loss': 0.32124587194230714, 'Total loss': 0.32124587194230714}
2022-11-28 01:33:47,582 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:47,582 INFO:     Epoch: 82
2022-11-28 01:33:48,322 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4264595643725506, 'Total loss': 0.4264595643725506} | train loss {'Reaction outcome loss': 0.32480854483046495, 'Total loss': 0.32480854483046495}
2022-11-28 01:33:48,322 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:48,322 INFO:     Epoch: 83
2022-11-28 01:33:49,060 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44076027010762414, 'Total loss': 0.44076027010762414} | train loss {'Reaction outcome loss': 0.3226631062380115, 'Total loss': 0.3226631062380115}
2022-11-28 01:33:49,060 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:49,060 INFO:     Epoch: 84
2022-11-28 01:33:49,800 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44176988061084305, 'Total loss': 0.44176988061084305} | train loss {'Reaction outcome loss': 0.3066508366924817, 'Total loss': 0.3066508366924817}
2022-11-28 01:33:49,800 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:49,800 INFO:     Epoch: 85
2022-11-28 01:33:50,536 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41213916415391966, 'Total loss': 0.41213916415391966} | train loss {'Reaction outcome loss': 0.30992054586588846, 'Total loss': 0.30992054586588846}
2022-11-28 01:33:50,536 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:50,537 INFO:     Epoch: 86
2022-11-28 01:33:51,275 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45366370885871177, 'Total loss': 0.45366370885871177} | train loss {'Reaction outcome loss': 0.30722210163891805, 'Total loss': 0.30722210163891805}
2022-11-28 01:33:51,275 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:51,275 INFO:     Epoch: 87
2022-11-28 01:33:52,013 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44961326898530474, 'Total loss': 0.44961326898530474} | train loss {'Reaction outcome loss': 0.32131463032765467, 'Total loss': 0.32131463032765467}
2022-11-28 01:33:52,014 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:52,014 INFO:     Epoch: 88
2022-11-28 01:33:52,748 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4471645029478295, 'Total loss': 0.4471645029478295} | train loss {'Reaction outcome loss': 0.314467331180807, 'Total loss': 0.314467331180807}
2022-11-28 01:33:52,748 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:52,748 INFO:     Epoch: 89
2022-11-28 01:33:53,484 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4367242711921071, 'Total loss': 0.4367242711921071} | train loss {'Reaction outcome loss': 0.31889082140243447, 'Total loss': 0.31889082140243447}
2022-11-28 01:33:53,485 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:53,485 INFO:     Epoch: 90
2022-11-28 01:33:54,218 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4225951544074125, 'Total loss': 0.4225951544074125} | train loss {'Reaction outcome loss': 0.31021684826519647, 'Total loss': 0.31021684826519647}
2022-11-28 01:33:54,218 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:54,219 INFO:     Epoch: 91
2022-11-28 01:33:54,957 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4024554858374041, 'Total loss': 0.4024554858374041} | train loss {'Reaction outcome loss': 0.3179906849428767, 'Total loss': 0.3179906849428767}
2022-11-28 01:33:54,957 INFO:     Found new best model at epoch 91
2022-11-28 01:33:54,958 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:54,958 INFO:     Epoch: 92
2022-11-28 01:33:55,693 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42426500486773117, 'Total loss': 0.42426500486773117} | train loss {'Reaction outcome loss': 0.31748398808670825, 'Total loss': 0.31748398808670825}
2022-11-28 01:33:55,694 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:55,694 INFO:     Epoch: 93
2022-11-28 01:33:56,426 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4606885688249455, 'Total loss': 0.4606885688249455} | train loss {'Reaction outcome loss': 0.31272371559113754, 'Total loss': 0.31272371559113754}
2022-11-28 01:33:56,426 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:56,426 INFO:     Epoch: 94
2022-11-28 01:33:57,158 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42985301655392316, 'Total loss': 0.42985301655392316} | train loss {'Reaction outcome loss': 0.3196969864981585, 'Total loss': 0.3196969864981585}
2022-11-28 01:33:57,159 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:57,159 INFO:     Epoch: 95
2022-11-28 01:33:57,896 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4257655673941901, 'Total loss': 0.4257655673941901} | train loss {'Reaction outcome loss': 0.3117818635140286, 'Total loss': 0.3117818635140286}
2022-11-28 01:33:57,896 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:57,896 INFO:     Epoch: 96
2022-11-28 01:33:58,634 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4073308245387188, 'Total loss': 0.4073308245387188} | train loss {'Reaction outcome loss': 0.3132591108623587, 'Total loss': 0.3132591108623587}
2022-11-28 01:33:58,634 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:58,634 INFO:     Epoch: 97
2022-11-28 01:33:59,372 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42481706793918167, 'Total loss': 0.42481706793918167} | train loss {'Reaction outcome loss': 0.3187698126144585, 'Total loss': 0.3187698126144585}
2022-11-28 01:33:59,372 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:33:59,372 INFO:     Epoch: 98
2022-11-28 01:34:00,106 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4328725642936174, 'Total loss': 0.4328725642936174} | train loss {'Reaction outcome loss': 0.3117439678915944, 'Total loss': 0.3117439678915944}
2022-11-28 01:34:00,106 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:00,106 INFO:     Epoch: 99
2022-11-28 01:34:00,837 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43841482664263526, 'Total loss': 0.43841482664263526} | train loss {'Reaction outcome loss': 0.32161288161868934, 'Total loss': 0.32161288161868934}
2022-11-28 01:34:00,837 INFO:     Best model found after epoch 92 of 100.
2022-11-28 01:34:00,837 INFO:   Done with stage: TRAINING
2022-11-28 01:34:00,837 INFO:   Starting stage: EVALUATION
2022-11-28 01:34:00,969 INFO:   Done with stage: EVALUATION
2022-11-28 01:34:00,969 INFO:   Leaving out SEQ value Fold_4
2022-11-28 01:34:00,982 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 01:34:00,982 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:34:01,632 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:34:01,632 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:34:01,702 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:34:01,702 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:34:01,702 INFO:     No hyperparam tuning for this model
2022-11-28 01:34:01,702 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:34:01,702 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:34:01,703 INFO:     None feature selector for col prot
2022-11-28 01:34:01,703 INFO:     None feature selector for col prot
2022-11-28 01:34:01,703 INFO:     None feature selector for col prot
2022-11-28 01:34:01,703 INFO:     None feature selector for col chem
2022-11-28 01:34:01,704 INFO:     None feature selector for col chem
2022-11-28 01:34:01,704 INFO:     None feature selector for col chem
2022-11-28 01:34:01,704 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:34:01,704 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:34:01,705 INFO:     Number of params in model 169741
2022-11-28 01:34:01,708 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:34:01,708 INFO:   Starting stage: TRAINING
2022-11-28 01:34:01,762 INFO:     Val loss before train {'Reaction outcome loss': 0.9714627008546483, 'Total loss': 0.9714627008546483}
2022-11-28 01:34:01,762 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:01,762 INFO:     Epoch: 0
2022-11-28 01:34:02,506 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5968505089933221, 'Total loss': 0.5968505089933221} | train loss {'Reaction outcome loss': 0.6351882466888018, 'Total loss': 0.6351882466888018}
2022-11-28 01:34:02,507 INFO:     Found new best model at epoch 0
2022-11-28 01:34:02,507 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:02,507 INFO:     Epoch: 1
2022-11-28 01:34:03,252 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5425732173025608, 'Total loss': 0.5425732173025608} | train loss {'Reaction outcome loss': 0.49822016051303036, 'Total loss': 0.49822016051303036}
2022-11-28 01:34:03,252 INFO:     Found new best model at epoch 1
2022-11-28 01:34:03,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:03,253 INFO:     Epoch: 2
2022-11-28 01:34:03,993 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4687279042872516, 'Total loss': 0.4687279042872516} | train loss {'Reaction outcome loss': 0.4680910175025222, 'Total loss': 0.4680910175025222}
2022-11-28 01:34:03,993 INFO:     Found new best model at epoch 2
2022-11-28 01:34:03,994 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:03,994 INFO:     Epoch: 3
2022-11-28 01:34:04,740 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4332668926905502, 'Total loss': 0.4332668926905502} | train loss {'Reaction outcome loss': 0.4362942289244308, 'Total loss': 0.4362942289244308}
2022-11-28 01:34:04,741 INFO:     Found new best model at epoch 3
2022-11-28 01:34:04,742 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:04,742 INFO:     Epoch: 4
2022-11-28 01:34:05,488 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.42938842150298034, 'Total loss': 0.42938842150298034} | train loss {'Reaction outcome loss': 0.4298276615589254, 'Total loss': 0.4298276615589254}
2022-11-28 01:34:05,488 INFO:     Found new best model at epoch 4
2022-11-28 01:34:05,489 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:05,489 INFO:     Epoch: 5
2022-11-28 01:34:06,233 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49479918960820546, 'Total loss': 0.49479918960820546} | train loss {'Reaction outcome loss': 0.40203004307019324, 'Total loss': 0.40203004307019324}
2022-11-28 01:34:06,233 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:06,233 INFO:     Epoch: 6
2022-11-28 01:34:06,986 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4416504434563897, 'Total loss': 0.4416504434563897} | train loss {'Reaction outcome loss': 0.3984142359693041, 'Total loss': 0.3984142359693041}
2022-11-28 01:34:06,986 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:06,986 INFO:     Epoch: 7
2022-11-28 01:34:07,731 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45308550176295365, 'Total loss': 0.45308550176295365} | train loss {'Reaction outcome loss': 0.39313710695094906, 'Total loss': 0.39313710695094906}
2022-11-28 01:34:07,731 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:07,731 INFO:     Epoch: 8
2022-11-28 01:34:08,476 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43304047699679027, 'Total loss': 0.43304047699679027} | train loss {'Reaction outcome loss': 0.385769546755895, 'Total loss': 0.385769546755895}
2022-11-28 01:34:08,476 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:08,476 INFO:     Epoch: 9
2022-11-28 01:34:09,221 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41585013016381045, 'Total loss': 0.41585013016381045} | train loss {'Reaction outcome loss': 0.38484710111067844, 'Total loss': 0.38484710111067844}
2022-11-28 01:34:09,221 INFO:     Found new best model at epoch 9
2022-11-28 01:34:09,222 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:09,222 INFO:     Epoch: 10
2022-11-28 01:34:09,968 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4171758995137431, 'Total loss': 0.4171758995137431} | train loss {'Reaction outcome loss': 0.36614661417177574, 'Total loss': 0.36614661417177574}
2022-11-28 01:34:09,968 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:09,968 INFO:     Epoch: 11
2022-11-28 01:34:10,716 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45311710373921826, 'Total loss': 0.45311710373921826} | train loss {'Reaction outcome loss': 0.36574625232924335, 'Total loss': 0.36574625232924335}
2022-11-28 01:34:10,716 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:10,716 INFO:     Epoch: 12
2022-11-28 01:34:11,460 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4267745688557625, 'Total loss': 0.4267745688557625} | train loss {'Reaction outcome loss': 0.3588825486871878, 'Total loss': 0.3588825486871878}
2022-11-28 01:34:11,461 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:11,461 INFO:     Epoch: 13
2022-11-28 01:34:12,211 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41527342119000177, 'Total loss': 0.41527342119000177} | train loss {'Reaction outcome loss': 0.3518371181449427, 'Total loss': 0.3518371181449427}
2022-11-28 01:34:12,211 INFO:     Found new best model at epoch 13
2022-11-28 01:34:12,211 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:12,212 INFO:     Epoch: 14
2022-11-28 01:34:12,960 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4158660837195136, 'Total loss': 0.4158660837195136} | train loss {'Reaction outcome loss': 0.35801239476938873, 'Total loss': 0.35801239476938873}
2022-11-28 01:34:12,960 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:12,960 INFO:     Epoch: 15
2022-11-28 01:34:13,710 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4297619506039403, 'Total loss': 0.4297619506039403} | train loss {'Reaction outcome loss': 0.3491194123922572, 'Total loss': 0.3491194123922572}
2022-11-28 01:34:13,710 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:13,710 INFO:     Epoch: 16
2022-11-28 01:34:14,459 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4070249785753814, 'Total loss': 0.4070249785753814} | train loss {'Reaction outcome loss': 0.35666529143508147, 'Total loss': 0.35666529143508147}
2022-11-28 01:34:14,459 INFO:     Found new best model at epoch 16
2022-11-28 01:34:14,460 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:14,460 INFO:     Epoch: 17
2022-11-28 01:34:15,202 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4201683842323043, 'Total loss': 0.4201683842323043} | train loss {'Reaction outcome loss': 0.34275265348705686, 'Total loss': 0.34275265348705686}
2022-11-28 01:34:15,202 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:15,202 INFO:     Epoch: 18
2022-11-28 01:34:15,946 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3927829258821227, 'Total loss': 0.3927829258821227} | train loss {'Reaction outcome loss': 0.34888338725561435, 'Total loss': 0.34888338725561435}
2022-11-28 01:34:15,946 INFO:     Found new best model at epoch 18
2022-11-28 01:34:15,947 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:15,947 INFO:     Epoch: 19
2022-11-28 01:34:16,690 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4294551638039676, 'Total loss': 0.4294551638039676} | train loss {'Reaction outcome loss': 0.3336522637127412, 'Total loss': 0.3336522637127412}
2022-11-28 01:34:16,691 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:16,691 INFO:     Epoch: 20
2022-11-28 01:34:17,435 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43968327478929, 'Total loss': 0.43968327478929} | train loss {'Reaction outcome loss': 0.3358735326641741, 'Total loss': 0.3358735326641741}
2022-11-28 01:34:17,435 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:17,436 INFO:     Epoch: 21
2022-11-28 01:34:18,180 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4218900047919967, 'Total loss': 0.4218900047919967} | train loss {'Reaction outcome loss': 0.34072261781531654, 'Total loss': 0.34072261781531654}
2022-11-28 01:34:18,180 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:18,180 INFO:     Epoch: 22
2022-11-28 01:34:18,924 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43458143723281945, 'Total loss': 0.43458143723281945} | train loss {'Reaction outcome loss': 0.34111603593778034, 'Total loss': 0.34111603593778034}
2022-11-28 01:34:18,924 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:18,924 INFO:     Epoch: 23
2022-11-28 01:34:19,666 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41462805528532376, 'Total loss': 0.41462805528532376} | train loss {'Reaction outcome loss': 0.3281270409170689, 'Total loss': 0.3281270409170689}
2022-11-28 01:34:19,666 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:19,666 INFO:     Epoch: 24
2022-11-28 01:34:20,408 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.472334987399253, 'Total loss': 0.472334987399253} | train loss {'Reaction outcome loss': 0.3251821455896383, 'Total loss': 0.3251821455896383}
2022-11-28 01:34:20,408 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:20,408 INFO:     Epoch: 25
2022-11-28 01:34:21,148 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4239083454012871, 'Total loss': 0.4239083454012871} | train loss {'Reaction outcome loss': 0.33570751022954703, 'Total loss': 0.33570751022954703}
2022-11-28 01:34:21,148 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:21,148 INFO:     Epoch: 26
2022-11-28 01:34:21,892 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46173653412948956, 'Total loss': 0.46173653412948956} | train loss {'Reaction outcome loss': 0.33312418109733566, 'Total loss': 0.33312418109733566}
2022-11-28 01:34:21,892 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:21,892 INFO:     Epoch: 27
2022-11-28 01:34:22,639 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41740874031727965, 'Total loss': 0.41740874031727965} | train loss {'Reaction outcome loss': 0.34883332202731354, 'Total loss': 0.34883332202731354}
2022-11-28 01:34:22,639 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:22,640 INFO:     Epoch: 28
2022-11-28 01:34:23,384 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4160813821310347, 'Total loss': 0.4160813821310347} | train loss {'Reaction outcome loss': 0.3200938111917693, 'Total loss': 0.3200938111917693}
2022-11-28 01:34:23,385 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:23,385 INFO:     Epoch: 29
2022-11-28 01:34:24,129 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41545630077069456, 'Total loss': 0.41545630077069456} | train loss {'Reaction outcome loss': 0.32093244772932306, 'Total loss': 0.32093244772932306}
2022-11-28 01:34:24,129 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:24,130 INFO:     Epoch: 30
2022-11-28 01:34:24,874 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41730528460307553, 'Total loss': 0.41730528460307553} | train loss {'Reaction outcome loss': 0.3233969429138339, 'Total loss': 0.3233969429138339}
2022-11-28 01:34:24,875 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:24,875 INFO:     Epoch: 31
2022-11-28 01:34:25,618 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41578533297235315, 'Total loss': 0.41578533297235315} | train loss {'Reaction outcome loss': 0.3326910906490165, 'Total loss': 0.3326910906490165}
2022-11-28 01:34:25,618 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:25,618 INFO:     Epoch: 32
2022-11-28 01:34:26,360 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41118685173040087, 'Total loss': 0.41118685173040087} | train loss {'Reaction outcome loss': 0.32507564441530934, 'Total loss': 0.32507564441530934}
2022-11-28 01:34:26,360 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:26,360 INFO:     Epoch: 33
2022-11-28 01:34:27,102 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38900015587833797, 'Total loss': 0.38900015587833797} | train loss {'Reaction outcome loss': 0.32029166896092265, 'Total loss': 0.32029166896092265}
2022-11-28 01:34:27,102 INFO:     Found new best model at epoch 33
2022-11-28 01:34:27,103 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:27,103 INFO:     Epoch: 34
2022-11-28 01:34:27,847 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4006804959340529, 'Total loss': 0.4006804959340529} | train loss {'Reaction outcome loss': 0.32085937455575536, 'Total loss': 0.32085937455575536}
2022-11-28 01:34:27,847 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:27,847 INFO:     Epoch: 35
2022-11-28 01:34:28,593 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4321032291786237, 'Total loss': 0.4321032291786237} | train loss {'Reaction outcome loss': 0.3203952015388893, 'Total loss': 0.3203952015388893}
2022-11-28 01:34:28,593 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:28,593 INFO:     Epoch: 36
2022-11-28 01:34:29,340 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4131985198367726, 'Total loss': 0.4131985198367726} | train loss {'Reaction outcome loss': 0.3284972117316385, 'Total loss': 0.3284972117316385}
2022-11-28 01:34:29,341 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:29,341 INFO:     Epoch: 37
2022-11-28 01:34:30,089 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40597643093629315, 'Total loss': 0.40597643093629315} | train loss {'Reaction outcome loss': 0.3419431508311376, 'Total loss': 0.3419431508311376}
2022-11-28 01:34:30,089 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:30,089 INFO:     Epoch: 38
2022-11-28 01:34:30,836 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3978578167205507, 'Total loss': 0.3978578167205507} | train loss {'Reaction outcome loss': 0.322309158504884, 'Total loss': 0.322309158504884}
2022-11-28 01:34:30,836 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:30,836 INFO:     Epoch: 39
2022-11-28 01:34:31,582 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4166520105844194, 'Total loss': 0.4166520105844194} | train loss {'Reaction outcome loss': 0.31261670346624454, 'Total loss': 0.31261670346624454}
2022-11-28 01:34:31,582 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:31,582 INFO:     Epoch: 40
2022-11-28 01:34:32,325 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4248984777791934, 'Total loss': 0.4248984777791934} | train loss {'Reaction outcome loss': 0.3205358385738091, 'Total loss': 0.3205358385738091}
2022-11-28 01:34:32,325 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:32,325 INFO:     Epoch: 41
2022-11-28 01:34:33,069 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4276223793964494, 'Total loss': 0.4276223793964494} | train loss {'Reaction outcome loss': 0.31030129472374435, 'Total loss': 0.31030129472374435}
2022-11-28 01:34:33,069 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:33,069 INFO:     Epoch: 42
2022-11-28 01:34:33,815 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4264204535971988, 'Total loss': 0.4264204535971988} | train loss {'Reaction outcome loss': 0.3197505557117795, 'Total loss': 0.3197505557117795}
2022-11-28 01:34:33,815 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:33,815 INFO:     Epoch: 43
2022-11-28 01:34:34,559 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4327972155403007, 'Total loss': 0.4327972155403007} | train loss {'Reaction outcome loss': 0.31473909832748326, 'Total loss': 0.31473909832748326}
2022-11-28 01:34:34,559 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:34,559 INFO:     Epoch: 44
2022-11-28 01:34:35,305 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40170731056820264, 'Total loss': 0.40170731056820264} | train loss {'Reaction outcome loss': 0.3201008063443156, 'Total loss': 0.3201008063443156}
2022-11-28 01:34:35,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:35,305 INFO:     Epoch: 45
2022-11-28 01:34:36,052 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4094037213786082, 'Total loss': 0.4094037213786082} | train loss {'Reaction outcome loss': 0.31189169496418495, 'Total loss': 0.31189169496418495}
2022-11-28 01:34:36,053 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:36,053 INFO:     Epoch: 46
2022-11-28 01:34:36,800 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.403538353741169, 'Total loss': 0.403538353741169} | train loss {'Reaction outcome loss': 0.3150075522707662, 'Total loss': 0.3150075522707662}
2022-11-28 01:34:36,801 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:36,801 INFO:     Epoch: 47
2022-11-28 01:34:37,543 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4380990094081922, 'Total loss': 0.4380990094081922} | train loss {'Reaction outcome loss': 0.3229680772251468, 'Total loss': 0.3229680772251468}
2022-11-28 01:34:37,543 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:37,543 INFO:     Epoch: 48
2022-11-28 01:34:38,286 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43298608030785213, 'Total loss': 0.43298608030785213} | train loss {'Reaction outcome loss': 0.30351873176730415, 'Total loss': 0.30351873176730415}
2022-11-28 01:34:38,286 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:38,286 INFO:     Epoch: 49
2022-11-28 01:34:39,032 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4387301369146867, 'Total loss': 0.4387301369146867} | train loss {'Reaction outcome loss': 0.31447037306391756, 'Total loss': 0.31447037306391756}
2022-11-28 01:34:39,032 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:39,032 INFO:     Epoch: 50
2022-11-28 01:34:39,776 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3867442726411603, 'Total loss': 0.3867442726411603} | train loss {'Reaction outcome loss': 0.31667694744280717, 'Total loss': 0.31667694744280717}
2022-11-28 01:34:39,776 INFO:     Found new best model at epoch 50
2022-11-28 01:34:39,777 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:39,777 INFO:     Epoch: 51
2022-11-28 01:34:40,520 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42051923274993896, 'Total loss': 0.42051923274993896} | train loss {'Reaction outcome loss': 0.30595057345158516, 'Total loss': 0.30595057345158516}
2022-11-28 01:34:40,520 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:40,520 INFO:     Epoch: 52
2022-11-28 01:34:41,266 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4083629266612909, 'Total loss': 0.4083629266612909} | train loss {'Reaction outcome loss': 0.3171829642411717, 'Total loss': 0.3171829642411717}
2022-11-28 01:34:41,266 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:41,266 INFO:     Epoch: 53
2022-11-28 01:34:42,012 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3964416787705638, 'Total loss': 0.3964416787705638} | train loss {'Reaction outcome loss': 0.3122927850104778, 'Total loss': 0.3122927850104778}
2022-11-28 01:34:42,012 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:42,012 INFO:     Epoch: 54
2022-11-28 01:34:42,757 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.434401309625669, 'Total loss': 0.434401309625669} | train loss {'Reaction outcome loss': 0.3143890808649391, 'Total loss': 0.3143890808649391}
2022-11-28 01:34:42,758 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:42,758 INFO:     Epoch: 55
2022-11-28 01:34:43,506 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3968112646517428, 'Total loss': 0.3968112646517428} | train loss {'Reaction outcome loss': 0.312514717777369, 'Total loss': 0.312514717777369}
2022-11-28 01:34:43,506 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:43,506 INFO:     Epoch: 56
2022-11-28 01:34:44,254 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42939556491645897, 'Total loss': 0.42939556491645897} | train loss {'Reaction outcome loss': 0.31322575449521245, 'Total loss': 0.31322575449521245}
2022-11-28 01:34:44,254 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:44,254 INFO:     Epoch: 57
2022-11-28 01:34:45,003 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4173240707340566, 'Total loss': 0.4173240707340566} | train loss {'Reaction outcome loss': 0.31316453462696603, 'Total loss': 0.31316453462696603}
2022-11-28 01:34:45,003 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:45,003 INFO:     Epoch: 58
2022-11-28 01:34:45,751 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4009230790490454, 'Total loss': 0.4009230790490454} | train loss {'Reaction outcome loss': 0.2995340052317179, 'Total loss': 0.2995340052317179}
2022-11-28 01:34:45,751 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:45,751 INFO:     Epoch: 59
2022-11-28 01:34:46,492 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4255313951183449, 'Total loss': 0.4255313951183449} | train loss {'Reaction outcome loss': 0.30533073727901167, 'Total loss': 0.30533073727901167}
2022-11-28 01:34:46,492 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:46,492 INFO:     Epoch: 60
2022-11-28 01:34:47,237 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43145691688087856, 'Total loss': 0.43145691688087856} | train loss {'Reaction outcome loss': 0.32694356270164615, 'Total loss': 0.32694356270164615}
2022-11-28 01:34:47,237 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:47,237 INFO:     Epoch: 61
2022-11-28 01:34:47,981 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39463784714991396, 'Total loss': 0.39463784714991396} | train loss {'Reaction outcome loss': 0.32959102391739475, 'Total loss': 0.32959102391739475}
2022-11-28 01:34:47,982 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:47,982 INFO:     Epoch: 62
2022-11-28 01:34:48,728 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3986136982725425, 'Total loss': 0.3986136982725425} | train loss {'Reaction outcome loss': 0.3045580236897295, 'Total loss': 0.3045580236897295}
2022-11-28 01:34:48,728 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:48,728 INFO:     Epoch: 63
2022-11-28 01:34:49,473 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4322068745439703, 'Total loss': 0.4322068745439703} | train loss {'Reaction outcome loss': 0.300183561679564, 'Total loss': 0.300183561679564}
2022-11-28 01:34:49,474 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:49,474 INFO:     Epoch: 64
2022-11-28 01:34:50,220 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37326148558746686, 'Total loss': 0.37326148558746686} | train loss {'Reaction outcome loss': 0.3098383946004908, 'Total loss': 0.3098383946004908}
2022-11-28 01:34:50,220 INFO:     Found new best model at epoch 64
2022-11-28 01:34:50,221 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:50,221 INFO:     Epoch: 65
2022-11-28 01:34:50,969 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44773672622713173, 'Total loss': 0.44773672622713173} | train loss {'Reaction outcome loss': 0.3039877713150778, 'Total loss': 0.3039877713150778}
2022-11-28 01:34:50,969 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:50,969 INFO:     Epoch: 66
2022-11-28 01:34:51,712 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3978013995696198, 'Total loss': 0.3978013995696198} | train loss {'Reaction outcome loss': 0.3020828044214493, 'Total loss': 0.3020828044214493}
2022-11-28 01:34:51,712 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:51,712 INFO:     Epoch: 67
2022-11-28 01:34:52,456 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4315577559173107, 'Total loss': 0.4315577559173107} | train loss {'Reaction outcome loss': 0.3002062822703408, 'Total loss': 0.3002062822703408}
2022-11-28 01:34:52,456 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:52,457 INFO:     Epoch: 68
2022-11-28 01:34:53,198 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4271480722183531, 'Total loss': 0.4271480722183531} | train loss {'Reaction outcome loss': 0.3226238241200505, 'Total loss': 0.3226238241200505}
2022-11-28 01:34:53,199 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:53,199 INFO:     Epoch: 69
2022-11-28 01:34:53,945 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4351798475465991, 'Total loss': 0.4351798475465991} | train loss {'Reaction outcome loss': 0.32687446841525164, 'Total loss': 0.32687446841525164}
2022-11-28 01:34:53,945 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:53,945 INFO:     Epoch: 70
2022-11-28 01:34:54,689 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3938195315951651, 'Total loss': 0.3938195315951651} | train loss {'Reaction outcome loss': 0.31738973807106136, 'Total loss': 0.31738973807106136}
2022-11-28 01:34:54,690 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:54,690 INFO:     Epoch: 71
2022-11-28 01:34:55,432 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44121669232845306, 'Total loss': 0.44121669232845306} | train loss {'Reaction outcome loss': 0.3086903151049305, 'Total loss': 0.3086903151049305}
2022-11-28 01:34:55,432 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:55,433 INFO:     Epoch: 72
2022-11-28 01:34:56,175 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4355702393434264, 'Total loss': 0.4355702393434264} | train loss {'Reaction outcome loss': 0.3063707660265297, 'Total loss': 0.3063707660265297}
2022-11-28 01:34:56,175 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:56,176 INFO:     Epoch: 73
2022-11-28 01:34:56,919 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4082438363270326, 'Total loss': 0.4082438363270326} | train loss {'Reaction outcome loss': 0.3048650857046066, 'Total loss': 0.3048650857046066}
2022-11-28 01:34:56,919 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:56,919 INFO:     Epoch: 74
2022-11-28 01:34:57,664 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39229958606037224, 'Total loss': 0.39229958606037224} | train loss {'Reaction outcome loss': 0.2965758374104133, 'Total loss': 0.2965758374104133}
2022-11-28 01:34:57,665 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:57,665 INFO:     Epoch: 75
2022-11-28 01:34:58,407 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43938175487247383, 'Total loss': 0.43938175487247383} | train loss {'Reaction outcome loss': 0.31621304609876894, 'Total loss': 0.31621304609876894}
2022-11-28 01:34:58,407 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:58,407 INFO:     Epoch: 76
2022-11-28 01:34:59,152 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41786690191789105, 'Total loss': 0.41786690191789105} | train loss {'Reaction outcome loss': 0.31113831060919683, 'Total loss': 0.31113831060919683}
2022-11-28 01:34:59,153 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:59,153 INFO:     Epoch: 77
2022-11-28 01:34:59,897 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41963201913643966, 'Total loss': 0.41963201913643966} | train loss {'Reaction outcome loss': 0.3136156969948819, 'Total loss': 0.3136156969948819}
2022-11-28 01:34:59,897 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:34:59,897 INFO:     Epoch: 78
2022-11-28 01:35:00,638 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39999701776965096, 'Total loss': 0.39999701776965096} | train loss {'Reaction outcome loss': 0.3062123311304125, 'Total loss': 0.3062123311304125}
2022-11-28 01:35:00,638 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:00,638 INFO:     Epoch: 79
2022-11-28 01:35:01,383 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40095173940062523, 'Total loss': 0.40095173940062523} | train loss {'Reaction outcome loss': 0.3036567471500322, 'Total loss': 0.3036567471500322}
2022-11-28 01:35:01,383 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:01,383 INFO:     Epoch: 80
2022-11-28 01:35:02,127 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4530599205331369, 'Total loss': 0.4530599205331369} | train loss {'Reaction outcome loss': 0.30295226089505534, 'Total loss': 0.30295226089505534}
2022-11-28 01:35:02,127 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:02,127 INFO:     Epoch: 81
2022-11-28 01:35:02,871 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4718598278070038, 'Total loss': 0.4718598278070038} | train loss {'Reaction outcome loss': 0.3178202816349292, 'Total loss': 0.3178202816349292}
2022-11-28 01:35:02,871 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:02,871 INFO:     Epoch: 82
2022-11-28 01:35:03,614 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4343426830389283, 'Total loss': 0.4343426830389283} | train loss {'Reaction outcome loss': 0.3098104810002844, 'Total loss': 0.3098104810002844}
2022-11-28 01:35:03,614 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:03,614 INFO:     Epoch: 83
2022-11-28 01:35:04,353 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42454613880677655, 'Total loss': 0.42454613880677655} | train loss {'Reaction outcome loss': 0.31552135205341253, 'Total loss': 0.31552135205341253}
2022-11-28 01:35:04,353 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:04,353 INFO:     Epoch: 84
2022-11-28 01:35:05,095 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41270813616839325, 'Total loss': 0.41270813616839325} | train loss {'Reaction outcome loss': 0.35869582413661816, 'Total loss': 0.35869582413661816}
2022-11-28 01:35:05,095 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:05,095 INFO:     Epoch: 85
2022-11-28 01:35:05,840 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3965824314139106, 'Total loss': 0.3965824314139106} | train loss {'Reaction outcome loss': 0.3105403115814514, 'Total loss': 0.3105403115814514}
2022-11-28 01:35:05,840 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:05,840 INFO:     Epoch: 86
2022-11-28 01:35:06,587 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4300748218189586, 'Total loss': 0.4300748218189586} | train loss {'Reaction outcome loss': 0.32207278141597295, 'Total loss': 0.32207278141597295}
2022-11-28 01:35:06,587 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:06,587 INFO:     Epoch: 87
2022-11-28 01:35:07,335 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40827037902040914, 'Total loss': 0.40827037902040914} | train loss {'Reaction outcome loss': 0.30372709966818934, 'Total loss': 0.30372709966818934}
2022-11-28 01:35:07,336 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:07,336 INFO:     Epoch: 88
2022-11-28 01:35:08,082 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4167156141589988, 'Total loss': 0.4167156141589988} | train loss {'Reaction outcome loss': 0.29047397540708786, 'Total loss': 0.29047397540708786}
2022-11-28 01:35:08,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:08,083 INFO:     Epoch: 89
2022-11-28 01:35:08,827 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40324556624347513, 'Total loss': 0.40324556624347513} | train loss {'Reaction outcome loss': 0.30871968858155163, 'Total loss': 0.30871968858155163}
2022-11-28 01:35:08,827 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:08,827 INFO:     Epoch: 90
2022-11-28 01:35:09,569 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40277017144994304, 'Total loss': 0.40277017144994304} | train loss {'Reaction outcome loss': 0.29816849567260034, 'Total loss': 0.29816849567260034}
2022-11-28 01:35:09,569 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:09,569 INFO:     Epoch: 91
2022-11-28 01:35:10,313 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.378601303154772, 'Total loss': 0.378601303154772} | train loss {'Reaction outcome loss': 0.30004608217883205, 'Total loss': 0.30004608217883205}
2022-11-28 01:35:10,313 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:10,313 INFO:     Epoch: 92
2022-11-28 01:35:11,058 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47863165221431037, 'Total loss': 0.47863165221431037} | train loss {'Reaction outcome loss': 0.31687284449515074, 'Total loss': 0.31687284449515074}
2022-11-28 01:35:11,058 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:11,059 INFO:     Epoch: 93
2022-11-28 01:35:11,800 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39586066149852495, 'Total loss': 0.39586066149852495} | train loss {'Reaction outcome loss': 0.3206743115657254, 'Total loss': 0.3206743115657254}
2022-11-28 01:35:11,801 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:11,801 INFO:     Epoch: 94
2022-11-28 01:35:12,545 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4111682078377767, 'Total loss': 0.4111682078377767} | train loss {'Reaction outcome loss': 0.335843138095097, 'Total loss': 0.335843138095097}
2022-11-28 01:35:12,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:12,545 INFO:     Epoch: 95
2022-11-28 01:35:13,289 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49560393477705394, 'Total loss': 0.49560393477705394} | train loss {'Reaction outcome loss': 0.31757820786734825, 'Total loss': 0.31757820786734825}
2022-11-28 01:35:13,290 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:13,290 INFO:     Epoch: 96
2022-11-28 01:35:14,033 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4003309973261573, 'Total loss': 0.4003309973261573} | train loss {'Reaction outcome loss': 0.31145665007322904, 'Total loss': 0.31145665007322904}
2022-11-28 01:35:14,034 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:14,034 INFO:     Epoch: 97
2022-11-28 01:35:14,778 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41410822759975086, 'Total loss': 0.41410822759975086} | train loss {'Reaction outcome loss': 0.31155780334824973, 'Total loss': 0.31155780334824973}
2022-11-28 01:35:14,778 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:14,778 INFO:     Epoch: 98
2022-11-28 01:35:15,526 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3981630890206857, 'Total loss': 0.3981630890206857} | train loss {'Reaction outcome loss': 0.3081329704577156, 'Total loss': 0.3081329704577156}
2022-11-28 01:35:15,526 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:15,526 INFO:     Epoch: 99
2022-11-28 01:35:16,272 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.471309382468462, 'Total loss': 0.471309382468462} | train loss {'Reaction outcome loss': 0.2936100806844862, 'Total loss': 0.2936100806844862}
2022-11-28 01:35:16,272 INFO:     Best model found after epoch 65 of 100.
2022-11-28 01:35:16,273 INFO:   Done with stage: TRAINING
2022-11-28 01:35:16,273 INFO:   Starting stage: EVALUATION
2022-11-28 01:35:16,394 INFO:   Done with stage: EVALUATION
2022-11-28 01:35:16,394 INFO:   Leaving out SEQ value Fold_5
2022-11-28 01:35:16,407 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 01:35:16,407 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:35:17,044 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:35:17,044 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:35:17,114 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:35:17,114 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:35:17,114 INFO:     No hyperparam tuning for this model
2022-11-28 01:35:17,114 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:35:17,114 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:35:17,115 INFO:     None feature selector for col prot
2022-11-28 01:35:17,115 INFO:     None feature selector for col prot
2022-11-28 01:35:17,115 INFO:     None feature selector for col prot
2022-11-28 01:35:17,116 INFO:     None feature selector for col chem
2022-11-28 01:35:17,116 INFO:     None feature selector for col chem
2022-11-28 01:35:17,116 INFO:     None feature selector for col chem
2022-11-28 01:35:17,116 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:35:17,116 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:35:17,117 INFO:     Number of params in model 169741
2022-11-28 01:35:17,120 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:35:17,120 INFO:   Starting stage: TRAINING
2022-11-28 01:35:17,173 INFO:     Val loss before train {'Reaction outcome loss': 1.0382123792713338, 'Total loss': 1.0382123792713338}
2022-11-28 01:35:17,173 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:17,174 INFO:     Epoch: 0
2022-11-28 01:35:17,916 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5640656159005382, 'Total loss': 0.5640656159005382} | train loss {'Reaction outcome loss': 0.6414808419189955, 'Total loss': 0.6414808419189955}
2022-11-28 01:35:17,916 INFO:     Found new best model at epoch 0
2022-11-28 01:35:17,917 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:17,917 INFO:     Epoch: 1
2022-11-28 01:35:18,663 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.535692310468717, 'Total loss': 0.535692310468717} | train loss {'Reaction outcome loss': 0.5074700461210389, 'Total loss': 0.5074700461210389}
2022-11-28 01:35:18,663 INFO:     Found new best model at epoch 1
2022-11-28 01:35:18,663 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:18,664 INFO:     Epoch: 2
2022-11-28 01:35:19,408 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5095190060409632, 'Total loss': 0.5095190060409632} | train loss {'Reaction outcome loss': 0.47599409538724646, 'Total loss': 0.47599409538724646}
2022-11-28 01:35:19,410 INFO:     Found new best model at epoch 2
2022-11-28 01:35:19,410 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:19,410 INFO:     Epoch: 3
2022-11-28 01:35:20,154 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4933046779849313, 'Total loss': 0.4933046779849313} | train loss {'Reaction outcome loss': 0.4511397882074359, 'Total loss': 0.4511397882074359}
2022-11-28 01:35:20,154 INFO:     Found new best model at epoch 3
2022-11-28 01:35:20,154 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:20,155 INFO:     Epoch: 4
2022-11-28 01:35:20,900 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47054037045348773, 'Total loss': 0.47054037045348773} | train loss {'Reaction outcome loss': 0.4331277992410457, 'Total loss': 0.4331277992410457}
2022-11-28 01:35:20,900 INFO:     Found new best model at epoch 4
2022-11-28 01:35:20,901 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:20,901 INFO:     Epoch: 5
2022-11-28 01:35:21,644 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4629855877296491, 'Total loss': 0.4629855877296491} | train loss {'Reaction outcome loss': 0.413998558272717, 'Total loss': 0.413998558272717}
2022-11-28 01:35:21,644 INFO:     Found new best model at epoch 5
2022-11-28 01:35:21,645 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:21,645 INFO:     Epoch: 6
2022-11-28 01:35:22,393 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46785467490553856, 'Total loss': 0.46785467490553856} | train loss {'Reaction outcome loss': 0.4072348175924799, 'Total loss': 0.4072348175924799}
2022-11-28 01:35:22,393 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:22,393 INFO:     Epoch: 7
2022-11-28 01:35:23,138 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4754725979133086, 'Total loss': 0.4754725979133086} | train loss {'Reaction outcome loss': 0.4049881305771801, 'Total loss': 0.4049881305771801}
2022-11-28 01:35:23,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:23,138 INFO:     Epoch: 8
2022-11-28 01:35:23,882 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4629177688197656, 'Total loss': 0.4629177688197656} | train loss {'Reaction outcome loss': 0.39465028644814665, 'Total loss': 0.39465028644814665}
2022-11-28 01:35:23,882 INFO:     Found new best model at epoch 8
2022-11-28 01:35:23,883 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:23,883 INFO:     Epoch: 9
2022-11-28 01:35:24,625 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4574927965348417, 'Total loss': 0.4574927965348417} | train loss {'Reaction outcome loss': 0.3972753204013172, 'Total loss': 0.3972753204013172}
2022-11-28 01:35:24,625 INFO:     Found new best model at epoch 9
2022-11-28 01:35:24,626 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:24,626 INFO:     Epoch: 10
2022-11-28 01:35:25,373 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5077168538489125, 'Total loss': 0.5077168538489125} | train loss {'Reaction outcome loss': 0.3998447935198724, 'Total loss': 0.3998447935198724}
2022-11-28 01:35:25,373 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:25,373 INFO:     Epoch: 11
2022-11-28 01:35:26,118 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4600755653598092, 'Total loss': 0.4600755653598092} | train loss {'Reaction outcome loss': 0.3972087762118713, 'Total loss': 0.3972087762118713}
2022-11-28 01:35:26,119 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:26,119 INFO:     Epoch: 12
2022-11-28 01:35:26,864 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4461160735650496, 'Total loss': 0.4461160735650496} | train loss {'Reaction outcome loss': 0.3734734166669942, 'Total loss': 0.3734734166669942}
2022-11-28 01:35:26,864 INFO:     Found new best model at epoch 12
2022-11-28 01:35:26,864 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:26,865 INFO:     Epoch: 13
2022-11-28 01:35:27,612 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4443110078573227, 'Total loss': 0.4443110078573227} | train loss {'Reaction outcome loss': 0.3765854428820161, 'Total loss': 0.3765854428820161}
2022-11-28 01:35:27,612 INFO:     Found new best model at epoch 13
2022-11-28 01:35:27,613 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:27,613 INFO:     Epoch: 14
2022-11-28 01:35:28,356 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42913858355446294, 'Total loss': 0.42913858355446294} | train loss {'Reaction outcome loss': 0.3748160765057633, 'Total loss': 0.3748160765057633}
2022-11-28 01:35:28,356 INFO:     Found new best model at epoch 14
2022-11-28 01:35:28,357 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:28,357 INFO:     Epoch: 15
2022-11-28 01:35:29,108 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44451168162578886, 'Total loss': 0.44451168162578886} | train loss {'Reaction outcome loss': 0.38506679420891077, 'Total loss': 0.38506679420891077}
2022-11-28 01:35:29,108 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:29,108 INFO:     Epoch: 16
2022-11-28 01:35:29,857 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46777032485062425, 'Total loss': 0.46777032485062425} | train loss {'Reaction outcome loss': 0.3692749715466731, 'Total loss': 0.3692749715466731}
2022-11-28 01:35:29,857 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:29,857 INFO:     Epoch: 17
2022-11-28 01:35:30,601 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4335707720707763, 'Total loss': 0.4335707720707763} | train loss {'Reaction outcome loss': 0.37217926053021116, 'Total loss': 0.37217926053021116}
2022-11-28 01:35:30,601 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:30,602 INFO:     Epoch: 18
2022-11-28 01:35:31,344 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4467973339964043, 'Total loss': 0.4467973339964043} | train loss {'Reaction outcome loss': 0.36430173282801864, 'Total loss': 0.36430173282801864}
2022-11-28 01:35:31,344 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:31,345 INFO:     Epoch: 19
2022-11-28 01:35:32,093 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4237682534889741, 'Total loss': 0.4237682534889741} | train loss {'Reaction outcome loss': 0.3579975164793281, 'Total loss': 0.3579975164793281}
2022-11-28 01:35:32,093 INFO:     Found new best model at epoch 19
2022-11-28 01:35:32,094 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:32,094 INFO:     Epoch: 20
2022-11-28 01:35:32,836 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4439588077366352, 'Total loss': 0.4439588077366352} | train loss {'Reaction outcome loss': 0.3518938273191452, 'Total loss': 0.3518938273191452}
2022-11-28 01:35:32,837 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:32,837 INFO:     Epoch: 21
2022-11-28 01:35:33,582 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4287064674903046, 'Total loss': 0.4287064674903046} | train loss {'Reaction outcome loss': 0.36416359230694983, 'Total loss': 0.36416359230694983}
2022-11-28 01:35:33,582 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:33,582 INFO:     Epoch: 22
2022-11-28 01:35:34,323 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41542184640738095, 'Total loss': 0.41542184640738095} | train loss {'Reaction outcome loss': 0.36723061786730765, 'Total loss': 0.36723061786730765}
2022-11-28 01:35:34,323 INFO:     Found new best model at epoch 22
2022-11-28 01:35:34,324 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:34,324 INFO:     Epoch: 23
2022-11-28 01:35:35,067 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4454540302130309, 'Total loss': 0.4454540302130309} | train loss {'Reaction outcome loss': 0.3648099988050427, 'Total loss': 0.3648099988050427}
2022-11-28 01:35:35,067 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:35,067 INFO:     Epoch: 24
2022-11-28 01:35:35,814 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4338113919577815, 'Total loss': 0.4338113919577815} | train loss {'Reaction outcome loss': 0.34341240438975784, 'Total loss': 0.34341240438975784}
2022-11-28 01:35:35,814 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:35,814 INFO:     Epoch: 25
2022-11-28 01:35:36,558 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4311875118450685, 'Total loss': 0.4311875118450685} | train loss {'Reaction outcome loss': 0.35229891586882867, 'Total loss': 0.35229891586882867}
2022-11-28 01:35:36,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:36,558 INFO:     Epoch: 26
2022-11-28 01:35:37,304 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43858761577443645, 'Total loss': 0.43858761577443645} | train loss {'Reaction outcome loss': 0.3544815113006333, 'Total loss': 0.3544815113006333}
2022-11-28 01:35:37,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:37,305 INFO:     Epoch: 27
2022-11-28 01:35:38,051 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41328386014158075, 'Total loss': 0.41328386014158075} | train loss {'Reaction outcome loss': 0.34933642072882126, 'Total loss': 0.34933642072882126}
2022-11-28 01:35:38,051 INFO:     Found new best model at epoch 27
2022-11-28 01:35:38,052 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:38,052 INFO:     Epoch: 28
2022-11-28 01:35:38,797 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4518220875073563, 'Total loss': 0.4518220875073563} | train loss {'Reaction outcome loss': 0.33978254887980486, 'Total loss': 0.33978254887980486}
2022-11-28 01:35:38,798 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:38,798 INFO:     Epoch: 29
2022-11-28 01:35:39,545 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41051675023680384, 'Total loss': 0.41051675023680384} | train loss {'Reaction outcome loss': 0.33859446337107224, 'Total loss': 0.33859446337107224}
2022-11-28 01:35:39,546 INFO:     Found new best model at epoch 29
2022-11-28 01:35:39,546 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:39,546 INFO:     Epoch: 30
2022-11-28 01:35:40,293 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43462281640280376, 'Total loss': 0.43462281640280376} | train loss {'Reaction outcome loss': 0.3451673023794827, 'Total loss': 0.3451673023794827}
2022-11-28 01:35:40,294 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:40,294 INFO:     Epoch: 31
2022-11-28 01:35:41,037 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44105535982684657, 'Total loss': 0.44105535982684657} | train loss {'Reaction outcome loss': 0.34251848176905986, 'Total loss': 0.34251848176905986}
2022-11-28 01:35:41,037 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:41,037 INFO:     Epoch: 32
2022-11-28 01:35:41,779 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42425416816364636, 'Total loss': 0.42425416816364636} | train loss {'Reaction outcome loss': 0.3511878255045848, 'Total loss': 0.3511878255045848}
2022-11-28 01:35:41,779 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:41,779 INFO:     Epoch: 33
2022-11-28 01:35:42,524 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41504627669399435, 'Total loss': 0.41504627669399435} | train loss {'Reaction outcome loss': 0.3478146062688789, 'Total loss': 0.3478146062688789}
2022-11-28 01:35:42,524 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:42,524 INFO:     Epoch: 34
2022-11-28 01:35:43,266 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40695896033536305, 'Total loss': 0.40695896033536305} | train loss {'Reaction outcome loss': 0.3457225703215792, 'Total loss': 0.3457225703215792}
2022-11-28 01:35:43,266 INFO:     Found new best model at epoch 34
2022-11-28 01:35:43,267 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:43,267 INFO:     Epoch: 35
2022-11-28 01:35:44,010 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43981514329260046, 'Total loss': 0.43981514329260046} | train loss {'Reaction outcome loss': 0.35874171731503385, 'Total loss': 0.35874171731503385}
2022-11-28 01:35:44,010 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:44,010 INFO:     Epoch: 36
2022-11-28 01:35:44,754 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4357572959905321, 'Total loss': 0.4357572959905321} | train loss {'Reaction outcome loss': 0.33908183744006604, 'Total loss': 0.33908183744006604}
2022-11-28 01:35:44,754 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:44,754 INFO:     Epoch: 37
2022-11-28 01:35:45,498 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4157505106519569, 'Total loss': 0.4157505106519569} | train loss {'Reaction outcome loss': 0.33730110018853443, 'Total loss': 0.33730110018853443}
2022-11-28 01:35:45,498 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:45,498 INFO:     Epoch: 38
2022-11-28 01:35:46,242 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4108840562403202, 'Total loss': 0.4108840562403202} | train loss {'Reaction outcome loss': 0.3384867586527276, 'Total loss': 0.3384867586527276}
2022-11-28 01:35:46,242 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:46,242 INFO:     Epoch: 39
2022-11-28 01:35:46,987 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43506222912533715, 'Total loss': 0.43506222912533715} | train loss {'Reaction outcome loss': 0.3363282508876642, 'Total loss': 0.3363282508876642}
2022-11-28 01:35:46,987 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:46,987 INFO:     Epoch: 40
2022-11-28 01:35:47,729 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.446448241783814, 'Total loss': 0.446448241783814} | train loss {'Reaction outcome loss': 0.34203191317225756, 'Total loss': 0.34203191317225756}
2022-11-28 01:35:47,729 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:47,729 INFO:     Epoch: 41
2022-11-28 01:35:48,471 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4839711233296178, 'Total loss': 0.4839711233296178} | train loss {'Reaction outcome loss': 0.3444965846444431, 'Total loss': 0.3444965846444431}
2022-11-28 01:35:48,472 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:48,472 INFO:     Epoch: 42
2022-11-28 01:35:49,213 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42424310134215787, 'Total loss': 0.42424310134215787} | train loss {'Reaction outcome loss': 0.3424547913706737, 'Total loss': 0.3424547913706737}
2022-11-28 01:35:49,213 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:49,213 INFO:     Epoch: 43
2022-11-28 01:35:49,957 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45017149638045917, 'Total loss': 0.45017149638045917} | train loss {'Reaction outcome loss': 0.33836555972635024, 'Total loss': 0.33836555972635024}
2022-11-28 01:35:49,957 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:49,958 INFO:     Epoch: 44
2022-11-28 01:35:50,702 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45902920175682416, 'Total loss': 0.45902920175682416} | train loss {'Reaction outcome loss': 0.33662673719378133, 'Total loss': 0.33662673719378133}
2022-11-28 01:35:50,703 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:50,703 INFO:     Epoch: 45
2022-11-28 01:35:51,448 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45149322802370245, 'Total loss': 0.45149322802370245} | train loss {'Reaction outcome loss': 0.3456896673510914, 'Total loss': 0.3456896673510914}
2022-11-28 01:35:51,448 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:51,448 INFO:     Epoch: 46
2022-11-28 01:35:52,191 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43313369527459145, 'Total loss': 0.43313369527459145} | train loss {'Reaction outcome loss': 0.33164700465114233, 'Total loss': 0.33164700465114233}
2022-11-28 01:35:52,191 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:52,191 INFO:     Epoch: 47
2022-11-28 01:35:52,931 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43468141403387894, 'Total loss': 0.43468141403387894} | train loss {'Reaction outcome loss': 0.3327324664604809, 'Total loss': 0.3327324664604809}
2022-11-28 01:35:52,931 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:52,932 INFO:     Epoch: 48
2022-11-28 01:35:53,677 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46426072445782746, 'Total loss': 0.46426072445782746} | train loss {'Reaction outcome loss': 0.3466890728787372, 'Total loss': 0.3466890728787372}
2022-11-28 01:35:53,677 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:53,677 INFO:     Epoch: 49
2022-11-28 01:35:54,420 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4610880555754358, 'Total loss': 0.4610880555754358} | train loss {'Reaction outcome loss': 0.3498206844002853, 'Total loss': 0.3498206844002853}
2022-11-28 01:35:54,420 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:54,420 INFO:     Epoch: 50
2022-11-28 01:35:55,164 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.417576267299327, 'Total loss': 0.417576267299327} | train loss {'Reaction outcome loss': 0.3293356412554137, 'Total loss': 0.3293356412554137}
2022-11-28 01:35:55,165 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:55,165 INFO:     Epoch: 51
2022-11-28 01:35:55,912 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42953175780448044, 'Total loss': 0.42953175780448044} | train loss {'Reaction outcome loss': 0.3333592972316853, 'Total loss': 0.3333592972316853}
2022-11-28 01:35:55,913 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:55,913 INFO:     Epoch: 52
2022-11-28 01:35:56,658 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41605041379278357, 'Total loss': 0.41605041379278357} | train loss {'Reaction outcome loss': 0.33424908032844425, 'Total loss': 0.33424908032844425}
2022-11-28 01:35:56,658 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:56,658 INFO:     Epoch: 53
2022-11-28 01:35:57,404 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4150061678480018, 'Total loss': 0.4150061678480018} | train loss {'Reaction outcome loss': 0.31964953679559366, 'Total loss': 0.31964953679559366}
2022-11-28 01:35:57,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:57,405 INFO:     Epoch: 54
2022-11-28 01:35:58,151 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4533716684037989, 'Total loss': 0.4533716684037989} | train loss {'Reaction outcome loss': 0.3245647953227464, 'Total loss': 0.3245647953227464}
2022-11-28 01:35:58,151 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:58,151 INFO:     Epoch: 55
2022-11-28 01:35:58,900 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43037567931142723, 'Total loss': 0.43037567931142723} | train loss {'Reaction outcome loss': 0.33106595371295566, 'Total loss': 0.33106595371295566}
2022-11-28 01:35:58,900 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:58,900 INFO:     Epoch: 56
2022-11-28 01:35:59,648 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4297550344331698, 'Total loss': 0.4297550344331698} | train loss {'Reaction outcome loss': 0.3378614461735675, 'Total loss': 0.3378614461735675}
2022-11-28 01:35:59,648 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:35:59,648 INFO:     Epoch: 57
2022-11-28 01:36:00,401 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4293624111874537, 'Total loss': 0.4293624111874537} | train loss {'Reaction outcome loss': 0.3397496338435995, 'Total loss': 0.3397496338435995}
2022-11-28 01:36:00,401 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:00,401 INFO:     Epoch: 58
2022-11-28 01:36:01,156 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42687353457916866, 'Total loss': 0.42687353457916866} | train loss {'Reaction outcome loss': 0.33602383014885523, 'Total loss': 0.33602383014885523}
2022-11-28 01:36:01,157 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:01,157 INFO:     Epoch: 59
2022-11-28 01:36:01,907 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4176847890696742, 'Total loss': 0.4176847890696742} | train loss {'Reaction outcome loss': 0.32686061918856163, 'Total loss': 0.32686061918856163}
2022-11-28 01:36:01,907 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:01,908 INFO:     Epoch: 60
2022-11-28 01:36:02,661 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44032833589748904, 'Total loss': 0.44032833589748904} | train loss {'Reaction outcome loss': 0.32666471440661776, 'Total loss': 0.32666471440661776}
2022-11-28 01:36:02,661 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:02,661 INFO:     Epoch: 61
2022-11-28 01:36:03,411 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38860378380526195, 'Total loss': 0.38860378380526195} | train loss {'Reaction outcome loss': 0.3267497912139786, 'Total loss': 0.3267497912139786}
2022-11-28 01:36:03,411 INFO:     Found new best model at epoch 61
2022-11-28 01:36:03,412 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:03,412 INFO:     Epoch: 62
2022-11-28 01:36:04,165 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40585497055541386, 'Total loss': 0.40585497055541386} | train loss {'Reaction outcome loss': 0.3284276260839783, 'Total loss': 0.3284276260839783}
2022-11-28 01:36:04,166 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:04,166 INFO:     Epoch: 63
2022-11-28 01:36:04,923 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4175939553163268, 'Total loss': 0.4175939553163268} | train loss {'Reaction outcome loss': 0.33334560731523916, 'Total loss': 0.33334560731523916}
2022-11-28 01:36:04,923 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:04,923 INFO:     Epoch: 64
2022-11-28 01:36:05,678 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4353701150552793, 'Total loss': 0.4353701150552793} | train loss {'Reaction outcome loss': 0.3348858886462474, 'Total loss': 0.3348858886462474}
2022-11-28 01:36:05,678 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:05,678 INFO:     Epoch: 65
2022-11-28 01:36:06,429 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4103536570275372, 'Total loss': 0.4103536570275372} | train loss {'Reaction outcome loss': 0.3250289039633535, 'Total loss': 0.3250289039633535}
2022-11-28 01:36:06,429 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:06,429 INFO:     Epoch: 66
2022-11-28 01:36:07,181 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4127229514150796, 'Total loss': 0.4127229514150796} | train loss {'Reaction outcome loss': 0.32548445892021655, 'Total loss': 0.32548445892021655}
2022-11-28 01:36:07,181 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:07,181 INFO:     Epoch: 67
2022-11-28 01:36:07,931 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41632410951636056, 'Total loss': 0.41632410951636056} | train loss {'Reaction outcome loss': 0.32804121002404074, 'Total loss': 0.32804121002404074}
2022-11-28 01:36:07,931 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:07,931 INFO:     Epoch: 68
2022-11-28 01:36:08,683 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44022857465527276, 'Total loss': 0.44022857465527276} | train loss {'Reaction outcome loss': 0.32499741590940034, 'Total loss': 0.32499741590940034}
2022-11-28 01:36:08,683 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:08,683 INFO:     Epoch: 69
2022-11-28 01:36:09,437 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40218317474831233, 'Total loss': 0.40218317474831233} | train loss {'Reaction outcome loss': 0.3235201850412828, 'Total loss': 0.3235201850412828}
2022-11-28 01:36:09,438 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:09,438 INFO:     Epoch: 70
2022-11-28 01:36:10,193 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45179976387457416, 'Total loss': 0.45179976387457416} | train loss {'Reaction outcome loss': 0.3427701292216386, 'Total loss': 0.3427701292216386}
2022-11-28 01:36:10,193 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:10,194 INFO:     Epoch: 71
2022-11-28 01:36:10,946 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4216225103221156, 'Total loss': 0.4216225103221156} | train loss {'Reaction outcome loss': 0.3275343452463387, 'Total loss': 0.3275343452463387}
2022-11-28 01:36:10,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:10,946 INFO:     Epoch: 72
2022-11-28 01:36:11,699 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4194485091350295, 'Total loss': 0.4194485091350295} | train loss {'Reaction outcome loss': 0.3244856462214398, 'Total loss': 0.3244856462214398}
2022-11-28 01:36:11,699 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:11,699 INFO:     Epoch: 73
2022-11-28 01:36:12,449 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4172965217043053, 'Total loss': 0.4172965217043053} | train loss {'Reaction outcome loss': 0.316196489309975, 'Total loss': 0.316196489309975}
2022-11-28 01:36:12,449 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:12,449 INFO:     Epoch: 74
2022-11-28 01:36:13,200 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4656903303482316, 'Total loss': 0.4656903303482316} | train loss {'Reaction outcome loss': 0.3309570977667927, 'Total loss': 0.3309570977667927}
2022-11-28 01:36:13,200 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:13,200 INFO:     Epoch: 75
2022-11-28 01:36:13,949 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4092065498910167, 'Total loss': 0.4092065498910167} | train loss {'Reaction outcome loss': 0.323610587520638, 'Total loss': 0.323610587520638}
2022-11-28 01:36:13,949 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:13,949 INFO:     Epoch: 76
2022-11-28 01:36:14,706 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4555500691587275, 'Total loss': 0.4555500691587275} | train loss {'Reaction outcome loss': 0.3358820688869306, 'Total loss': 0.3358820688869306}
2022-11-28 01:36:14,706 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:14,706 INFO:     Epoch: 77
2022-11-28 01:36:15,466 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4594809135252779, 'Total loss': 0.4594809135252779} | train loss {'Reaction outcome loss': 0.33097731248666024, 'Total loss': 0.33097731248666024}
2022-11-28 01:36:15,466 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:15,466 INFO:     Epoch: 78
2022-11-28 01:36:16,226 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41909807649525727, 'Total loss': 0.41909807649525727} | train loss {'Reaction outcome loss': 0.3190737651427265, 'Total loss': 0.3190737651427265}
2022-11-28 01:36:16,226 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:16,226 INFO:     Epoch: 79
2022-11-28 01:36:16,978 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4426501938565211, 'Total loss': 0.4426501938565211} | train loss {'Reaction outcome loss': 0.3307304088523996, 'Total loss': 0.3307304088523996}
2022-11-28 01:36:16,978 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:16,978 INFO:     Epoch: 80
2022-11-28 01:36:17,729 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42235392365943303, 'Total loss': 0.42235392365943303} | train loss {'Reaction outcome loss': 0.3320115983848147, 'Total loss': 0.3320115983848147}
2022-11-28 01:36:17,729 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:17,729 INFO:     Epoch: 81
2022-11-28 01:36:18,478 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4548281847753308, 'Total loss': 0.4548281847753308} | train loss {'Reaction outcome loss': 0.321660460418784, 'Total loss': 0.321660460418784}
2022-11-28 01:36:18,479 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:18,479 INFO:     Epoch: 82
2022-11-28 01:36:19,229 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40077314661307767, 'Total loss': 0.40077314661307767} | train loss {'Reaction outcome loss': 0.32192659392379797, 'Total loss': 0.32192659392379797}
2022-11-28 01:36:19,229 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:19,230 INFO:     Epoch: 83
2022-11-28 01:36:19,978 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4211684335023165, 'Total loss': 0.4211684335023165} | train loss {'Reaction outcome loss': 0.3261955411810624, 'Total loss': 0.3261955411810624}
2022-11-28 01:36:19,978 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:19,979 INFO:     Epoch: 84
2022-11-28 01:36:20,729 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4476509304209189, 'Total loss': 0.4476509304209189} | train loss {'Reaction outcome loss': 0.33429203034653837, 'Total loss': 0.33429203034653837}
2022-11-28 01:36:20,730 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:20,730 INFO:     Epoch: 85
2022-11-28 01:36:21,482 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4089133106172085, 'Total loss': 0.4089133106172085} | train loss {'Reaction outcome loss': 0.3268969268933964, 'Total loss': 0.3268969268933964}
2022-11-28 01:36:21,482 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:21,482 INFO:     Epoch: 86
2022-11-28 01:36:22,239 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4171533071520654, 'Total loss': 0.4171533071520654} | train loss {'Reaction outcome loss': 0.3251799399906068, 'Total loss': 0.3251799399906068}
2022-11-28 01:36:22,239 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:22,239 INFO:     Epoch: 87
2022-11-28 01:36:22,996 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4499353608963164, 'Total loss': 0.4499353608963164} | train loss {'Reaction outcome loss': 0.32315998985941113, 'Total loss': 0.32315998985941113}
2022-11-28 01:36:22,996 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:22,996 INFO:     Epoch: 88
2022-11-28 01:36:23,748 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4352594238113273, 'Total loss': 0.4352594238113273} | train loss {'Reaction outcome loss': 0.3175679544605049, 'Total loss': 0.3175679544605049}
2022-11-28 01:36:23,748 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:23,748 INFO:     Epoch: 89
2022-11-28 01:36:24,503 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4458815370771018, 'Total loss': 0.4458815370771018} | train loss {'Reaction outcome loss': 0.3186158170765228, 'Total loss': 0.3186158170765228}
2022-11-28 01:36:24,503 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:24,503 INFO:     Epoch: 90
2022-11-28 01:36:25,253 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4562195674939589, 'Total loss': 0.4562195674939589} | train loss {'Reaction outcome loss': 0.33702549717091174, 'Total loss': 0.33702549717091174}
2022-11-28 01:36:25,253 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:25,253 INFO:     Epoch: 91
2022-11-28 01:36:26,004 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45433850823478267, 'Total loss': 0.45433850823478267} | train loss {'Reaction outcome loss': 0.3145292865542265, 'Total loss': 0.3145292865542265}
2022-11-28 01:36:26,004 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:26,004 INFO:     Epoch: 92
2022-11-28 01:36:26,753 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4079320136119019, 'Total loss': 0.4079320136119019} | train loss {'Reaction outcome loss': 0.3181539073375314, 'Total loss': 0.3181539073375314}
2022-11-28 01:36:26,754 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:26,754 INFO:     Epoch: 93
2022-11-28 01:36:27,501 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4267767874354666, 'Total loss': 0.4267767874354666} | train loss {'Reaction outcome loss': 0.3228276965589176, 'Total loss': 0.3228276965589176}
2022-11-28 01:36:27,502 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:27,502 INFO:     Epoch: 94
2022-11-28 01:36:28,249 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44768577441573143, 'Total loss': 0.44768577441573143} | train loss {'Reaction outcome loss': 0.32256902057511605, 'Total loss': 0.32256902057511605}
2022-11-28 01:36:28,249 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:28,249 INFO:     Epoch: 95
2022-11-28 01:36:28,998 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4194883710958741, 'Total loss': 0.4194883710958741} | train loss {'Reaction outcome loss': 0.3401939775116048, 'Total loss': 0.3401939775116048}
2022-11-28 01:36:28,998 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:28,998 INFO:     Epoch: 96
2022-11-28 01:36:29,751 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4415878126905723, 'Total loss': 0.4415878126905723} | train loss {'Reaction outcome loss': 0.3395068686123681, 'Total loss': 0.3395068686123681}
2022-11-28 01:36:29,751 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:29,751 INFO:     Epoch: 97
2022-11-28 01:36:30,496 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40763058157807047, 'Total loss': 0.40763058157807047} | train loss {'Reaction outcome loss': 0.31709186103077597, 'Total loss': 0.31709186103077597}
2022-11-28 01:36:30,496 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:30,496 INFO:     Epoch: 98
2022-11-28 01:36:31,246 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4210232196545059, 'Total loss': 0.4210232196545059} | train loss {'Reaction outcome loss': 0.3110394867274699, 'Total loss': 0.3110394867274699}
2022-11-28 01:36:31,246 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:31,246 INFO:     Epoch: 99
2022-11-28 01:36:31,994 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43773212520913646, 'Total loss': 0.43773212520913646} | train loss {'Reaction outcome loss': 0.31735206401420507, 'Total loss': 0.31735206401420507}
2022-11-28 01:36:31,994 INFO:     Best model found after epoch 62 of 100.
2022-11-28 01:36:31,994 INFO:   Done with stage: TRAINING
2022-11-28 01:36:31,994 INFO:   Starting stage: EVALUATION
2022-11-28 01:36:32,116 INFO:   Done with stage: EVALUATION
2022-11-28 01:36:32,116 INFO:   Leaving out SEQ value Fold_6
2022-11-28 01:36:32,129 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 01:36:32,129 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:36:32,776 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:36:32,776 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:36:32,848 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:36:32,848 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:36:32,848 INFO:     No hyperparam tuning for this model
2022-11-28 01:36:32,848 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:36:32,848 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:36:32,849 INFO:     None feature selector for col prot
2022-11-28 01:36:32,849 INFO:     None feature selector for col prot
2022-11-28 01:36:32,849 INFO:     None feature selector for col prot
2022-11-28 01:36:32,850 INFO:     None feature selector for col chem
2022-11-28 01:36:32,850 INFO:     None feature selector for col chem
2022-11-28 01:36:32,850 INFO:     None feature selector for col chem
2022-11-28 01:36:32,850 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:36:32,850 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:36:32,852 INFO:     Number of params in model 169741
2022-11-28 01:36:32,855 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:36:32,855 INFO:   Starting stage: TRAINING
2022-11-28 01:36:32,910 INFO:     Val loss before train {'Reaction outcome loss': 1.0271601907231591, 'Total loss': 1.0271601907231591}
2022-11-28 01:36:32,910 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:32,910 INFO:     Epoch: 0
2022-11-28 01:36:33,659 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5420284762301228, 'Total loss': 0.5420284762301228} | train loss {'Reaction outcome loss': 0.625109731487417, 'Total loss': 0.625109731487417}
2022-11-28 01:36:33,659 INFO:     Found new best model at epoch 0
2022-11-28 01:36:33,660 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:33,660 INFO:     Epoch: 1
2022-11-28 01:36:34,410 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5124618746340275, 'Total loss': 0.5124618746340275} | train loss {'Reaction outcome loss': 0.48912320994896447, 'Total loss': 0.48912320994896447}
2022-11-28 01:36:34,411 INFO:     Found new best model at epoch 1
2022-11-28 01:36:34,411 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:34,412 INFO:     Epoch: 2
2022-11-28 01:36:35,161 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4782839288765734, 'Total loss': 0.4782839288765734} | train loss {'Reaction outcome loss': 0.45590372275003055, 'Total loss': 0.45590372275003055}
2022-11-28 01:36:35,161 INFO:     Found new best model at epoch 2
2022-11-28 01:36:35,162 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:35,162 INFO:     Epoch: 3
2022-11-28 01:36:35,915 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5229987596923654, 'Total loss': 0.5229987596923654} | train loss {'Reaction outcome loss': 0.43500558422644614, 'Total loss': 0.43500558422644614}
2022-11-28 01:36:35,915 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:35,915 INFO:     Epoch: 4
2022-11-28 01:36:36,668 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4636528380215168, 'Total loss': 0.4636528380215168} | train loss {'Reaction outcome loss': 0.42344570084501376, 'Total loss': 0.42344570084501376}
2022-11-28 01:36:36,668 INFO:     Found new best model at epoch 4
2022-11-28 01:36:36,669 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:36,669 INFO:     Epoch: 5
2022-11-28 01:36:37,416 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46827212890440767, 'Total loss': 0.46827212890440767} | train loss {'Reaction outcome loss': 0.402520601023064, 'Total loss': 0.402520601023064}
2022-11-28 01:36:37,416 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:37,416 INFO:     Epoch: 6
2022-11-28 01:36:38,164 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45096421309492807, 'Total loss': 0.45096421309492807} | train loss {'Reaction outcome loss': 0.3978775108632771, 'Total loss': 0.3978775108632771}
2022-11-28 01:36:38,164 INFO:     Found new best model at epoch 6
2022-11-28 01:36:38,165 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:38,165 INFO:     Epoch: 7
2022-11-28 01:36:38,922 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4384882558475841, 'Total loss': 0.4384882558475841} | train loss {'Reaction outcome loss': 0.3921541674175726, 'Total loss': 0.3921541674175726}
2022-11-28 01:36:38,923 INFO:     Found new best model at epoch 7
2022-11-28 01:36:38,923 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:38,923 INFO:     Epoch: 8
2022-11-28 01:36:39,675 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4537413628263907, 'Total loss': 0.4537413628263907} | train loss {'Reaction outcome loss': 0.388166946950953, 'Total loss': 0.388166946950953}
2022-11-28 01:36:39,675 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:39,675 INFO:     Epoch: 9
2022-11-28 01:36:40,421 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47853784263134, 'Total loss': 0.47853784263134} | train loss {'Reaction outcome loss': 0.3923973816971065, 'Total loss': 0.3923973816971065}
2022-11-28 01:36:40,421 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:40,421 INFO:     Epoch: 10
2022-11-28 01:36:41,170 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.441021474247629, 'Total loss': 0.441021474247629} | train loss {'Reaction outcome loss': 0.3853631546864143, 'Total loss': 0.3853631546864143}
2022-11-28 01:36:41,170 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:41,170 INFO:     Epoch: 11
2022-11-28 01:36:41,921 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4900607700374993, 'Total loss': 0.4900607700374993} | train loss {'Reaction outcome loss': 0.3716249052993199, 'Total loss': 0.3716249052993199}
2022-11-28 01:36:41,921 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:41,921 INFO:     Epoch: 12
2022-11-28 01:36:42,670 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4364023110405965, 'Total loss': 0.4364023110405965} | train loss {'Reaction outcome loss': 0.3736183903055635, 'Total loss': 0.3736183903055635}
2022-11-28 01:36:42,670 INFO:     Found new best model at epoch 12
2022-11-28 01:36:42,671 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:42,671 INFO:     Epoch: 13
2022-11-28 01:36:43,415 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4149971218271689, 'Total loss': 0.4149971218271689} | train loss {'Reaction outcome loss': 0.3727522256523974, 'Total loss': 0.3727522256523974}
2022-11-28 01:36:43,415 INFO:     Found new best model at epoch 13
2022-11-28 01:36:43,416 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:43,416 INFO:     Epoch: 14
2022-11-28 01:36:44,163 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4590424031696536, 'Total loss': 0.4590424031696536} | train loss {'Reaction outcome loss': 0.37022136363694785, 'Total loss': 0.37022136363694785}
2022-11-28 01:36:44,163 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:44,163 INFO:     Epoch: 15
2022-11-28 01:36:44,912 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45232127979397774, 'Total loss': 0.45232127979397774} | train loss {'Reaction outcome loss': 0.35584719476067583, 'Total loss': 0.35584719476067583}
2022-11-28 01:36:44,912 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:44,912 INFO:     Epoch: 16
2022-11-28 01:36:45,657 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4525599760765379, 'Total loss': 0.4525599760765379} | train loss {'Reaction outcome loss': 0.34675596886680193, 'Total loss': 0.34675596886680193}
2022-11-28 01:36:45,657 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:45,657 INFO:     Epoch: 17
2022-11-28 01:36:46,405 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4514402472837405, 'Total loss': 0.4514402472837405} | train loss {'Reaction outcome loss': 0.3479554464942531, 'Total loss': 0.3479554464942531}
2022-11-28 01:36:46,405 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:46,405 INFO:     Epoch: 18
2022-11-28 01:36:47,155 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.430226267400113, 'Total loss': 0.430226267400113} | train loss {'Reaction outcome loss': 0.35687561737192486, 'Total loss': 0.35687561737192486}
2022-11-28 01:36:47,155 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:47,155 INFO:     Epoch: 19
2022-11-28 01:36:47,902 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43068786744366994, 'Total loss': 0.43068786744366994} | train loss {'Reaction outcome loss': 0.35512073003208106, 'Total loss': 0.35512073003208106}
2022-11-28 01:36:47,903 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:47,903 INFO:     Epoch: 20
2022-11-28 01:36:48,652 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4356224574148655, 'Total loss': 0.4356224574148655} | train loss {'Reaction outcome loss': 0.3524652082390088, 'Total loss': 0.3524652082390088}
2022-11-28 01:36:48,652 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:48,653 INFO:     Epoch: 21
2022-11-28 01:36:49,400 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42514977942813525, 'Total loss': 0.42514977942813525} | train loss {'Reaction outcome loss': 0.33604809982694595, 'Total loss': 0.33604809982694595}
2022-11-28 01:36:49,400 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:49,401 INFO:     Epoch: 22
2022-11-28 01:36:50,150 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44665512679652736, 'Total loss': 0.44665512679652736} | train loss {'Reaction outcome loss': 0.3491992222575041, 'Total loss': 0.3491992222575041}
2022-11-28 01:36:50,150 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:50,150 INFO:     Epoch: 23
2022-11-28 01:36:50,895 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45785972916267137, 'Total loss': 0.45785972916267137} | train loss {'Reaction outcome loss': 0.3393951171202216, 'Total loss': 0.3393951171202216}
2022-11-28 01:36:50,895 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:50,895 INFO:     Epoch: 24
2022-11-28 01:36:51,643 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4277563792738048, 'Total loss': 0.4277563792738048} | train loss {'Reaction outcome loss': 0.33036643859406234, 'Total loss': 0.33036643859406234}
2022-11-28 01:36:51,644 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:51,644 INFO:     Epoch: 25
2022-11-28 01:36:52,391 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41470650481906807, 'Total loss': 0.41470650481906807} | train loss {'Reaction outcome loss': 0.3406752622139599, 'Total loss': 0.3406752622139599}
2022-11-28 01:36:52,392 INFO:     Found new best model at epoch 25
2022-11-28 01:36:52,392 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:52,392 INFO:     Epoch: 26
2022-11-28 01:36:53,138 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4403086125173352, 'Total loss': 0.4403086125173352} | train loss {'Reaction outcome loss': 0.3327788738797792, 'Total loss': 0.3327788738797792}
2022-11-28 01:36:53,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:53,139 INFO:     Epoch: 27
2022-11-28 01:36:53,883 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4414528086781502, 'Total loss': 0.4414528086781502} | train loss {'Reaction outcome loss': 0.33196217246704285, 'Total loss': 0.33196217246704285}
2022-11-28 01:36:53,883 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:53,883 INFO:     Epoch: 28
2022-11-28 01:36:54,632 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4287372966381637, 'Total loss': 0.4287372966381637} | train loss {'Reaction outcome loss': 0.33716170123291883, 'Total loss': 0.33716170123291883}
2022-11-28 01:36:54,632 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:54,632 INFO:     Epoch: 29
2022-11-28 01:36:55,380 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4446355786851861, 'Total loss': 0.4446355786851861} | train loss {'Reaction outcome loss': 0.3515985822267378, 'Total loss': 0.3515985822267378}
2022-11-28 01:36:55,380 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:55,380 INFO:     Epoch: 30
2022-11-28 01:36:56,128 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44462020559744403, 'Total loss': 0.44462020559744403} | train loss {'Reaction outcome loss': 0.3299228777347306, 'Total loss': 0.3299228777347306}
2022-11-28 01:36:56,128 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:56,128 INFO:     Epoch: 31
2022-11-28 01:36:56,872 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41805725917220116, 'Total loss': 0.41805725917220116} | train loss {'Reaction outcome loss': 0.3307021589957268, 'Total loss': 0.3307021589957268}
2022-11-28 01:36:56,872 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:56,873 INFO:     Epoch: 32
2022-11-28 01:36:57,616 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4353043196553534, 'Total loss': 0.4353043196553534} | train loss {'Reaction outcome loss': 0.3249360447832447, 'Total loss': 0.3249360447832447}
2022-11-28 01:36:57,616 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:57,616 INFO:     Epoch: 33
2022-11-28 01:36:58,360 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.462199331684546, 'Total loss': 0.462199331684546} | train loss {'Reaction outcome loss': 0.3257557655484811, 'Total loss': 0.3257557655484811}
2022-11-28 01:36:58,361 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:58,361 INFO:     Epoch: 34
2022-11-28 01:36:59,102 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46163914996114647, 'Total loss': 0.46163914996114647} | train loss {'Reaction outcome loss': 0.3231034878837435, 'Total loss': 0.3231034878837435}
2022-11-28 01:36:59,102 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:59,102 INFO:     Epoch: 35
2022-11-28 01:36:59,843 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4034505638886582, 'Total loss': 0.4034505638886582} | train loss {'Reaction outcome loss': 0.3349570211490639, 'Total loss': 0.3349570211490639}
2022-11-28 01:36:59,843 INFO:     Found new best model at epoch 35
2022-11-28 01:36:59,844 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:36:59,844 INFO:     Epoch: 36
2022-11-28 01:37:00,583 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4189257330515168, 'Total loss': 0.4189257330515168} | train loss {'Reaction outcome loss': 0.3385556540810145, 'Total loss': 0.3385556540810145}
2022-11-28 01:37:00,583 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:00,583 INFO:     Epoch: 37
2022-11-28 01:37:01,325 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.492005239833485, 'Total loss': 0.492005239833485} | train loss {'Reaction outcome loss': 0.3185406434934149, 'Total loss': 0.3185406434934149}
2022-11-28 01:37:01,325 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:01,325 INFO:     Epoch: 38
2022-11-28 01:37:02,067 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4386286451057954, 'Total loss': 0.4386286451057954} | train loss {'Reaction outcome loss': 0.36116086139611386, 'Total loss': 0.36116086139611386}
2022-11-28 01:37:02,067 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:02,068 INFO:     Epoch: 39
2022-11-28 01:37:02,817 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4387248605489731, 'Total loss': 0.4387248605489731} | train loss {'Reaction outcome loss': 0.3156129503698062, 'Total loss': 0.3156129503698062}
2022-11-28 01:37:02,817 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:02,817 INFO:     Epoch: 40
2022-11-28 01:37:03,564 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4367843354967507, 'Total loss': 0.4367843354967507} | train loss {'Reaction outcome loss': 0.3263638556316525, 'Total loss': 0.3263638556316525}
2022-11-28 01:37:03,564 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:03,564 INFO:     Epoch: 41
2022-11-28 01:37:04,305 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4485590183599429, 'Total loss': 0.4485590183599429} | train loss {'Reaction outcome loss': 0.32151287293385883, 'Total loss': 0.32151287293385883}
2022-11-28 01:37:04,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:04,305 INFO:     Epoch: 42
2022-11-28 01:37:05,046 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40153514830903575, 'Total loss': 0.40153514830903575} | train loss {'Reaction outcome loss': 0.3268027435611134, 'Total loss': 0.3268027435611134}
2022-11-28 01:37:05,046 INFO:     Found new best model at epoch 42
2022-11-28 01:37:05,047 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:05,047 INFO:     Epoch: 43
2022-11-28 01:37:05,793 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44658372415737674, 'Total loss': 0.44658372415737674} | train loss {'Reaction outcome loss': 0.3170229522926122, 'Total loss': 0.3170229522926122}
2022-11-28 01:37:05,793 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:05,793 INFO:     Epoch: 44
2022-11-28 01:37:06,540 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48406061631712044, 'Total loss': 0.48406061631712044} | train loss {'Reaction outcome loss': 0.31977581193572596, 'Total loss': 0.31977581193572596}
2022-11-28 01:37:06,540 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:06,540 INFO:     Epoch: 45
2022-11-28 01:37:07,291 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4488178508525545, 'Total loss': 0.4488178508525545} | train loss {'Reaction outcome loss': 0.31203928282145066, 'Total loss': 0.31203928282145066}
2022-11-28 01:37:07,291 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:07,291 INFO:     Epoch: 46
2022-11-28 01:37:08,036 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4689708189530806, 'Total loss': 0.4689708189530806} | train loss {'Reaction outcome loss': 0.31598642209039524, 'Total loss': 0.31598642209039524}
2022-11-28 01:37:08,036 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:08,036 INFO:     Epoch: 47
2022-11-28 01:37:08,785 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4275959139181809, 'Total loss': 0.4275959139181809} | train loss {'Reaction outcome loss': 0.3267904477503136, 'Total loss': 0.3267904477503136}
2022-11-28 01:37:08,785 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:08,785 INFO:     Epoch: 48
2022-11-28 01:37:09,533 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4703670150854371, 'Total loss': 0.4703670150854371} | train loss {'Reaction outcome loss': 0.3248662393849328, 'Total loss': 0.3248662393849328}
2022-11-28 01:37:09,534 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:09,534 INFO:     Epoch: 49
2022-11-28 01:37:10,274 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45512372153726494, 'Total loss': 0.45512372153726494} | train loss {'Reaction outcome loss': 0.3242035650229647, 'Total loss': 0.3242035650229647}
2022-11-28 01:37:10,274 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:10,274 INFO:     Epoch: 50
2022-11-28 01:37:11,017 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42998291044072673, 'Total loss': 0.42998291044072673} | train loss {'Reaction outcome loss': 0.33488650402800757, 'Total loss': 0.33488650402800757}
2022-11-28 01:37:11,018 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:11,018 INFO:     Epoch: 51
2022-11-28 01:37:11,764 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4332315156405622, 'Total loss': 0.4332315156405622} | train loss {'Reaction outcome loss': 0.32041068240031145, 'Total loss': 0.32041068240031145}
2022-11-28 01:37:11,764 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:11,764 INFO:     Epoch: 52
2022-11-28 01:37:12,513 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44977261227640236, 'Total loss': 0.44977261227640236} | train loss {'Reaction outcome loss': 0.31052773626830416, 'Total loss': 0.31052773626830416}
2022-11-28 01:37:12,514 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:12,514 INFO:     Epoch: 53
2022-11-28 01:37:13,260 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44526188244873827, 'Total loss': 0.44526188244873827} | train loss {'Reaction outcome loss': 0.3210516768217328, 'Total loss': 0.3210516768217328}
2022-11-28 01:37:13,260 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:13,260 INFO:     Epoch: 54
2022-11-28 01:37:14,003 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4190693475644697, 'Total loss': 0.4190693475644697} | train loss {'Reaction outcome loss': 0.31287692433698217, 'Total loss': 0.31287692433698217}
2022-11-28 01:37:14,004 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:14,004 INFO:     Epoch: 55
2022-11-28 01:37:14,747 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4335170963948423, 'Total loss': 0.4335170963948423} | train loss {'Reaction outcome loss': 0.3050681898136612, 'Total loss': 0.3050681898136612}
2022-11-28 01:37:14,748 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:14,748 INFO:     Epoch: 56
2022-11-28 01:37:15,493 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46272794902324677, 'Total loss': 0.46272794902324677} | train loss {'Reaction outcome loss': 0.31318717989561556, 'Total loss': 0.31318717989561556}
2022-11-28 01:37:15,493 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:15,493 INFO:     Epoch: 57
2022-11-28 01:37:16,238 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43498874150893907, 'Total loss': 0.43498874150893907} | train loss {'Reaction outcome loss': 0.30471849390249023, 'Total loss': 0.30471849390249023}
2022-11-28 01:37:16,238 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:16,238 INFO:     Epoch: 58
2022-11-28 01:37:16,980 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42045107382265007, 'Total loss': 0.42045107382265007} | train loss {'Reaction outcome loss': 0.31391933845423975, 'Total loss': 0.31391933845423975}
2022-11-28 01:37:16,980 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:16,980 INFO:     Epoch: 59
2022-11-28 01:37:17,720 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45684126764535904, 'Total loss': 0.45684126764535904} | train loss {'Reaction outcome loss': 0.30508105598601254, 'Total loss': 0.30508105598601254}
2022-11-28 01:37:17,720 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:17,721 INFO:     Epoch: 60
2022-11-28 01:37:18,462 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4752578491514379, 'Total loss': 0.4752578491514379} | train loss {'Reaction outcome loss': 0.31176446486822507, 'Total loss': 0.31176446486822507}
2022-11-28 01:37:18,463 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:18,463 INFO:     Epoch: 61
2022-11-28 01:37:19,205 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4529211145233024, 'Total loss': 0.4529211145233024} | train loss {'Reaction outcome loss': 0.30974237850079167, 'Total loss': 0.30974237850079167}
2022-11-28 01:37:19,205 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:19,205 INFO:     Epoch: 62
2022-11-28 01:37:19,948 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.445912051607262, 'Total loss': 0.445912051607262} | train loss {'Reaction outcome loss': 0.31247252755259214, 'Total loss': 0.31247252755259214}
2022-11-28 01:37:19,949 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:19,949 INFO:     Epoch: 63
2022-11-28 01:37:20,690 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41670586134899745, 'Total loss': 0.41670586134899745} | train loss {'Reaction outcome loss': 0.30177567826832835, 'Total loss': 0.30177567826832835}
2022-11-28 01:37:20,690 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:20,691 INFO:     Epoch: 64
2022-11-28 01:37:21,433 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4617281871085817, 'Total loss': 0.4617281871085817} | train loss {'Reaction outcome loss': 0.3103527410430947, 'Total loss': 0.3103527410430947}
2022-11-28 01:37:21,433 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:21,433 INFO:     Epoch: 65
2022-11-28 01:37:22,179 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4247755895961415, 'Total loss': 0.4247755895961415} | train loss {'Reaction outcome loss': 0.313632017959226, 'Total loss': 0.313632017959226}
2022-11-28 01:37:22,179 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:22,179 INFO:     Epoch: 66
2022-11-28 01:37:22,923 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4448948312889446, 'Total loss': 0.4448948312889446} | train loss {'Reaction outcome loss': 0.3148935916814727, 'Total loss': 0.3148935916814727}
2022-11-28 01:37:22,924 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:22,924 INFO:     Epoch: 67
2022-11-28 01:37:23,676 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42757287655364384, 'Total loss': 0.42757287655364384} | train loss {'Reaction outcome loss': 0.30982122289748326, 'Total loss': 0.30982122289748326}
2022-11-28 01:37:23,676 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:23,676 INFO:     Epoch: 68
2022-11-28 01:37:24,419 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4042895033278249, 'Total loss': 0.4042895033278249} | train loss {'Reaction outcome loss': 0.3064372538012049, 'Total loss': 0.3064372538012049}
2022-11-28 01:37:24,420 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:24,420 INFO:     Epoch: 69
2022-11-28 01:37:25,164 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4447192664850842, 'Total loss': 0.4447192664850842} | train loss {'Reaction outcome loss': 0.3086621987554226, 'Total loss': 0.3086621987554226}
2022-11-28 01:37:25,164 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:25,164 INFO:     Epoch: 70
2022-11-28 01:37:25,905 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45808322659947653, 'Total loss': 0.45808322659947653} | train loss {'Reaction outcome loss': 0.3078982178498859, 'Total loss': 0.3078982178498859}
2022-11-28 01:37:25,905 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:25,905 INFO:     Epoch: 71
2022-11-28 01:37:26,650 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4284882193261927, 'Total loss': 0.4284882193261927} | train loss {'Reaction outcome loss': 0.313898255211501, 'Total loss': 0.313898255211501}
2022-11-28 01:37:26,650 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:26,650 INFO:     Epoch: 72
2022-11-28 01:37:27,395 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4178340560333295, 'Total loss': 0.4178340560333295} | train loss {'Reaction outcome loss': 0.2993620269694309, 'Total loss': 0.2993620269694309}
2022-11-28 01:37:27,395 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:27,395 INFO:     Epoch: 73
2022-11-28 01:37:28,140 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43730386634441937, 'Total loss': 0.43730386634441937} | train loss {'Reaction outcome loss': 0.30029270440308936, 'Total loss': 0.30029270440308936}
2022-11-28 01:37:28,140 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:28,140 INFO:     Epoch: 74
2022-11-28 01:37:28,883 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41505344449119136, 'Total loss': 0.41505344449119136} | train loss {'Reaction outcome loss': 0.3050406193624624, 'Total loss': 0.3050406193624624}
2022-11-28 01:37:28,883 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:28,883 INFO:     Epoch: 75
2022-11-28 01:37:29,627 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4470003548670899, 'Total loss': 0.4470003548670899} | train loss {'Reaction outcome loss': 0.3088994857662844, 'Total loss': 0.3088994857662844}
2022-11-28 01:37:29,627 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:29,628 INFO:     Epoch: 76
2022-11-28 01:37:30,372 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44344749047674914, 'Total loss': 0.44344749047674914} | train loss {'Reaction outcome loss': 0.3077608699559683, 'Total loss': 0.3077608699559683}
2022-11-28 01:37:30,373 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:30,373 INFO:     Epoch: 77
2022-11-28 01:37:31,113 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4508256455036727, 'Total loss': 0.4508256455036727} | train loss {'Reaction outcome loss': 0.31141478268180783, 'Total loss': 0.31141478268180783}
2022-11-28 01:37:31,113 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:31,113 INFO:     Epoch: 78
2022-11-28 01:37:31,855 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42555955187840894, 'Total loss': 0.42555955187840894} | train loss {'Reaction outcome loss': 0.31198490332616, 'Total loss': 0.31198490332616}
2022-11-28 01:37:31,855 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:31,856 INFO:     Epoch: 79
2022-11-28 01:37:32,601 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42160682109269226, 'Total loss': 0.42160682109269226} | train loss {'Reaction outcome loss': 0.35908198944172304, 'Total loss': 0.35908198944172304}
2022-11-28 01:37:32,601 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:32,601 INFO:     Epoch: 80
2022-11-28 01:37:33,345 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4267150285569104, 'Total loss': 0.4267150285569104} | train loss {'Reaction outcome loss': 0.30973254259570165, 'Total loss': 0.30973254259570165}
2022-11-28 01:37:33,345 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:33,345 INFO:     Epoch: 81
2022-11-28 01:37:34,089 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4673484187911857, 'Total loss': 0.4673484187911857} | train loss {'Reaction outcome loss': 0.30594722222280407, 'Total loss': 0.30594722222280407}
2022-11-28 01:37:34,089 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:34,089 INFO:     Epoch: 82
2022-11-28 01:37:34,832 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4406394934789701, 'Total loss': 0.4406394934789701} | train loss {'Reaction outcome loss': 0.3017343363389071, 'Total loss': 0.3017343363389071}
2022-11-28 01:37:34,832 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:34,832 INFO:     Epoch: 83
2022-11-28 01:37:35,573 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5333789641206915, 'Total loss': 0.5333789641206915} | train loss {'Reaction outcome loss': 0.3085749282045403, 'Total loss': 0.3085749282045403}
2022-11-28 01:37:35,573 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:35,573 INFO:     Epoch: 84
2022-11-28 01:37:36,315 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43815033611926163, 'Total loss': 0.43815033611926163} | train loss {'Reaction outcome loss': 0.3331595681577559, 'Total loss': 0.3331595681577559}
2022-11-28 01:37:36,315 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:36,315 INFO:     Epoch: 85
2022-11-28 01:37:37,057 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4271768798882311, 'Total loss': 0.4271768798882311} | train loss {'Reaction outcome loss': 0.3228008446428804, 'Total loss': 0.3228008446428804}
2022-11-28 01:37:37,057 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:37,057 INFO:     Epoch: 86
2022-11-28 01:37:37,802 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4549084955995733, 'Total loss': 0.4549084955995733} | train loss {'Reaction outcome loss': 0.2966888342429752, 'Total loss': 0.2966888342429752}
2022-11-28 01:37:37,802 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:37,802 INFO:     Epoch: 87
2022-11-28 01:37:38,545 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4356865032830022, 'Total loss': 0.4356865032830022} | train loss {'Reaction outcome loss': 0.3090012277879937, 'Total loss': 0.3090012277879937}
2022-11-28 01:37:38,545 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:38,545 INFO:     Epoch: 88
2022-11-28 01:37:39,286 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.469804525714029, 'Total loss': 0.469804525714029} | train loss {'Reaction outcome loss': 0.2961175502145942, 'Total loss': 0.2961175502145942}
2022-11-28 01:37:39,286 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:39,286 INFO:     Epoch: 89
2022-11-28 01:37:40,030 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42328404635190964, 'Total loss': 0.42328404635190964} | train loss {'Reaction outcome loss': 0.3081307133380701, 'Total loss': 0.3081307133380701}
2022-11-28 01:37:40,030 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:40,030 INFO:     Epoch: 90
2022-11-28 01:37:40,771 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.433343362740495, 'Total loss': 0.433343362740495} | train loss {'Reaction outcome loss': 0.3067005864987414, 'Total loss': 0.3067005864987414}
2022-11-28 01:37:40,771 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:40,772 INFO:     Epoch: 91
2022-11-28 01:37:41,516 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43917572498321533, 'Total loss': 0.43917572498321533} | train loss {'Reaction outcome loss': 0.2885319202608591, 'Total loss': 0.2885319202608591}
2022-11-28 01:37:41,516 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:41,516 INFO:     Epoch: 92
2022-11-28 01:37:42,262 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.425663848830895, 'Total loss': 0.425663848830895} | train loss {'Reaction outcome loss': 0.3047329730048836, 'Total loss': 0.3047329730048836}
2022-11-28 01:37:42,263 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:42,263 INFO:     Epoch: 93
2022-11-28 01:37:43,007 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4230296571146358, 'Total loss': 0.4230296571146358} | train loss {'Reaction outcome loss': 0.31303441322404846, 'Total loss': 0.31303441322404846}
2022-11-28 01:37:43,007 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:43,007 INFO:     Epoch: 94
2022-11-28 01:37:43,757 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4344141446053982, 'Total loss': 0.4344141446053982} | train loss {'Reaction outcome loss': 0.3309353667533832, 'Total loss': 0.3309353667533832}
2022-11-28 01:37:43,757 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:43,757 INFO:     Epoch: 95
2022-11-28 01:37:44,501 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4441626759415323, 'Total loss': 0.4441626759415323} | train loss {'Reaction outcome loss': 0.32330806486413205, 'Total loss': 0.32330806486413205}
2022-11-28 01:37:44,501 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:44,501 INFO:     Epoch: 96
2022-11-28 01:37:45,241 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4626374395394867, 'Total loss': 0.4626374395394867} | train loss {'Reaction outcome loss': 0.3095337708559837, 'Total loss': 0.3095337708559837}
2022-11-28 01:37:45,241 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:45,241 INFO:     Epoch: 97
2022-11-28 01:37:45,984 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4529610733416947, 'Total loss': 0.4529610733416947} | train loss {'Reaction outcome loss': 0.3230903461002387, 'Total loss': 0.3230903461002387}
2022-11-28 01:37:45,984 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:45,984 INFO:     Epoch: 98
2022-11-28 01:37:46,730 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42836174301125785, 'Total loss': 0.42836174301125785} | train loss {'Reaction outcome loss': 0.3316499325729575, 'Total loss': 0.3316499325729575}
2022-11-28 01:37:46,730 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:46,730 INFO:     Epoch: 99
2022-11-28 01:37:47,476 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4596178565513004, 'Total loss': 0.4596178565513004} | train loss {'Reaction outcome loss': 0.3098217118305233, 'Total loss': 0.3098217118305233}
2022-11-28 01:37:47,476 INFO:     Best model found after epoch 43 of 100.
2022-11-28 01:37:47,476 INFO:   Done with stage: TRAINING
2022-11-28 01:37:47,476 INFO:   Starting stage: EVALUATION
2022-11-28 01:37:47,597 INFO:   Done with stage: EVALUATION
2022-11-28 01:37:47,597 INFO:   Leaving out SEQ value Fold_7
2022-11-28 01:37:47,609 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 01:37:47,610 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:37:48,256 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:37:48,256 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:37:48,327 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:37:48,328 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:37:48,328 INFO:     No hyperparam tuning for this model
2022-11-28 01:37:48,328 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:37:48,328 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:37:48,328 INFO:     None feature selector for col prot
2022-11-28 01:37:48,329 INFO:     None feature selector for col prot
2022-11-28 01:37:48,329 INFO:     None feature selector for col prot
2022-11-28 01:37:48,329 INFO:     None feature selector for col chem
2022-11-28 01:37:48,329 INFO:     None feature selector for col chem
2022-11-28 01:37:48,329 INFO:     None feature selector for col chem
2022-11-28 01:37:48,329 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:37:48,329 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:37:48,331 INFO:     Number of params in model 169741
2022-11-28 01:37:48,334 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:37:48,334 INFO:   Starting stage: TRAINING
2022-11-28 01:37:48,388 INFO:     Val loss before train {'Reaction outcome loss': 0.9511159617792476, 'Total loss': 0.9511159617792476}
2022-11-28 01:37:48,388 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:48,388 INFO:     Epoch: 0
2022-11-28 01:37:49,137 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5116975652900609, 'Total loss': 0.5116975652900609} | train loss {'Reaction outcome loss': 0.6330295752493604, 'Total loss': 0.6330295752493604}
2022-11-28 01:37:49,137 INFO:     Found new best model at epoch 0
2022-11-28 01:37:49,138 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:49,138 INFO:     Epoch: 1
2022-11-28 01:37:49,888 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4712026644159447, 'Total loss': 0.4712026644159447} | train loss {'Reaction outcome loss': 0.500736071457786, 'Total loss': 0.500736071457786}
2022-11-28 01:37:49,888 INFO:     Found new best model at epoch 1
2022-11-28 01:37:49,889 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:49,889 INFO:     Epoch: 2
2022-11-28 01:37:50,638 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.44022527811202133, 'Total loss': 0.44022527811202133} | train loss {'Reaction outcome loss': 0.46180380084702083, 'Total loss': 0.46180380084702083}
2022-11-28 01:37:50,638 INFO:     Found new best model at epoch 2
2022-11-28 01:37:50,639 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:50,639 INFO:     Epoch: 3
2022-11-28 01:37:51,385 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.42259413173252885, 'Total loss': 0.42259413173252885} | train loss {'Reaction outcome loss': 0.43320122724699395, 'Total loss': 0.43320122724699395}
2022-11-28 01:37:51,385 INFO:     Found new best model at epoch 3
2022-11-28 01:37:51,386 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:51,386 INFO:     Epoch: 4
2022-11-28 01:37:52,137 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.472364121878689, 'Total loss': 0.472364121878689} | train loss {'Reaction outcome loss': 0.4206633372532745, 'Total loss': 0.4206633372532745}
2022-11-28 01:37:52,137 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:52,137 INFO:     Epoch: 5
2022-11-28 01:37:52,890 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43353054198351776, 'Total loss': 0.43353054198351776} | train loss {'Reaction outcome loss': 0.4058111338245292, 'Total loss': 0.4058111338245292}
2022-11-28 01:37:52,890 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:52,890 INFO:     Epoch: 6
2022-11-28 01:37:53,636 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4389618235555562, 'Total loss': 0.4389618235555562} | train loss {'Reaction outcome loss': 0.3906319247738969, 'Total loss': 0.3906319247738969}
2022-11-28 01:37:53,637 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:53,637 INFO:     Epoch: 7
2022-11-28 01:37:54,382 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43837715431370516, 'Total loss': 0.43837715431370516} | train loss {'Reaction outcome loss': 0.38567568725275414, 'Total loss': 0.38567568725275414}
2022-11-28 01:37:54,382 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:54,382 INFO:     Epoch: 8
2022-11-28 01:37:55,134 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3814814065329053, 'Total loss': 0.3814814065329053} | train loss {'Reaction outcome loss': 0.3811203764691468, 'Total loss': 0.3811203764691468}
2022-11-28 01:37:55,135 INFO:     Found new best model at epoch 8
2022-11-28 01:37:55,135 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:55,135 INFO:     Epoch: 9
2022-11-28 01:37:55,882 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41310016878626565, 'Total loss': 0.41310016878626565} | train loss {'Reaction outcome loss': 0.3727245618619265, 'Total loss': 0.3727245618619265}
2022-11-28 01:37:55,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:55,882 INFO:     Epoch: 10
2022-11-28 01:37:56,628 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.403142071921717, 'Total loss': 0.403142071921717} | train loss {'Reaction outcome loss': 0.3654687035107805, 'Total loss': 0.3654687035107805}
2022-11-28 01:37:56,628 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:56,628 INFO:     Epoch: 11
2022-11-28 01:37:57,375 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3991410115903074, 'Total loss': 0.3991410115903074} | train loss {'Reaction outcome loss': 0.36906955961979204, 'Total loss': 0.36906955961979204}
2022-11-28 01:37:57,375 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:57,376 INFO:     Epoch: 12
2022-11-28 01:37:58,128 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4121056825599887, 'Total loss': 0.4121056825599887} | train loss {'Reaction outcome loss': 0.3592383549698899, 'Total loss': 0.3592383549698899}
2022-11-28 01:37:58,128 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:58,128 INFO:     Epoch: 13
2022-11-28 01:37:58,876 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4099592481824485, 'Total loss': 0.4099592481824485} | train loss {'Reaction outcome loss': 0.3584130108356476, 'Total loss': 0.3584130108356476}
2022-11-28 01:37:58,876 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:58,876 INFO:     Epoch: 14
2022-11-28 01:37:59,629 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43589947440407495, 'Total loss': 0.43589947440407495} | train loss {'Reaction outcome loss': 0.35605908383525187, 'Total loss': 0.35605908383525187}
2022-11-28 01:37:59,629 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:37:59,630 INFO:     Epoch: 15
2022-11-28 01:38:00,377 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41181705925952306, 'Total loss': 0.41181705925952306} | train loss {'Reaction outcome loss': 0.3498688803895587, 'Total loss': 0.3498688803895587}
2022-11-28 01:38:00,378 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:00,378 INFO:     Epoch: 16
2022-11-28 01:38:01,125 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43774758922782814, 'Total loss': 0.43774758922782814} | train loss {'Reaction outcome loss': 0.3479681717712552, 'Total loss': 0.3479681717712552}
2022-11-28 01:38:01,125 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:01,125 INFO:     Epoch: 17
2022-11-28 01:38:01,871 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39897938072681427, 'Total loss': 0.39897938072681427} | train loss {'Reaction outcome loss': 0.35035121125439483, 'Total loss': 0.35035121125439483}
2022-11-28 01:38:01,871 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:01,872 INFO:     Epoch: 18
2022-11-28 01:38:02,623 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3641670417379249, 'Total loss': 0.3641670417379249} | train loss {'Reaction outcome loss': 0.33321321596421544, 'Total loss': 0.33321321596421544}
2022-11-28 01:38:02,623 INFO:     Found new best model at epoch 18
2022-11-28 01:38:02,623 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:02,624 INFO:     Epoch: 19
2022-11-28 01:38:03,373 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3905511373146014, 'Total loss': 0.3905511373146014} | train loss {'Reaction outcome loss': 0.34169504850832444, 'Total loss': 0.34169504850832444}
2022-11-28 01:38:03,373 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:03,373 INFO:     Epoch: 20
2022-11-28 01:38:04,120 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40987036343325267, 'Total loss': 0.40987036343325267} | train loss {'Reaction outcome loss': 0.33292113010200763, 'Total loss': 0.33292113010200763}
2022-11-28 01:38:04,120 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:04,120 INFO:     Epoch: 21
2022-11-28 01:38:04,866 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.390389643270861, 'Total loss': 0.390389643270861} | train loss {'Reaction outcome loss': 0.34048147682821556, 'Total loss': 0.34048147682821556}
2022-11-28 01:38:04,866 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:04,866 INFO:     Epoch: 22
2022-11-28 01:38:05,614 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3997490280731158, 'Total loss': 0.3997490280731158} | train loss {'Reaction outcome loss': 0.3328716834225962, 'Total loss': 0.3328716834225962}
2022-11-28 01:38:05,614 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:05,614 INFO:     Epoch: 23
2022-11-28 01:38:06,365 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39270339567552914, 'Total loss': 0.39270339567552914} | train loss {'Reaction outcome loss': 0.33217231296904143, 'Total loss': 0.33217231296904143}
2022-11-28 01:38:06,365 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:06,365 INFO:     Epoch: 24
2022-11-28 01:38:07,112 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41726010309701617, 'Total loss': 0.41726010309701617} | train loss {'Reaction outcome loss': 0.32891612495445915, 'Total loss': 0.32891612495445915}
2022-11-28 01:38:07,112 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:07,112 INFO:     Epoch: 25
2022-11-28 01:38:07,857 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4060451225800948, 'Total loss': 0.4060451225800948} | train loss {'Reaction outcome loss': 0.3356056616551453, 'Total loss': 0.3356056616551453}
2022-11-28 01:38:07,857 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:07,857 INFO:     Epoch: 26
2022-11-28 01:38:08,600 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3987967270341786, 'Total loss': 0.3987967270341786} | train loss {'Reaction outcome loss': 0.333014183136965, 'Total loss': 0.333014183136965}
2022-11-28 01:38:08,601 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:08,601 INFO:     Epoch: 27
2022-11-28 01:38:09,347 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4017486921088262, 'Total loss': 0.4017486921088262} | train loss {'Reaction outcome loss': 0.32528636926004, 'Total loss': 0.32528636926004}
2022-11-28 01:38:09,347 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:09,347 INFO:     Epoch: 28
2022-11-28 01:38:10,093 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40431566671891644, 'Total loss': 0.40431566671891644} | train loss {'Reaction outcome loss': 0.3256311472805758, 'Total loss': 0.3256311472805758}
2022-11-28 01:38:10,093 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:10,093 INFO:     Epoch: 29
2022-11-28 01:38:10,840 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42034895887429063, 'Total loss': 0.42034895887429063} | train loss {'Reaction outcome loss': 0.3279207588263577, 'Total loss': 0.3279207588263577}
2022-11-28 01:38:10,840 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:10,840 INFO:     Epoch: 30
2022-11-28 01:38:11,588 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3917119357396256, 'Total loss': 0.3917119357396256} | train loss {'Reaction outcome loss': 0.32594032399356365, 'Total loss': 0.32594032399356365}
2022-11-28 01:38:11,589 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:11,589 INFO:     Epoch: 31
2022-11-28 01:38:12,337 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4060246893628077, 'Total loss': 0.4060246893628077} | train loss {'Reaction outcome loss': 0.3176235447547609, 'Total loss': 0.3176235447547609}
2022-11-28 01:38:12,337 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:12,338 INFO:     Epoch: 32
2022-11-28 01:38:13,084 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41782073744318704, 'Total loss': 0.41782073744318704} | train loss {'Reaction outcome loss': 0.3288819944756406, 'Total loss': 0.3288819944756406}
2022-11-28 01:38:13,085 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:13,085 INFO:     Epoch: 33
2022-11-28 01:38:13,840 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41172662885351613, 'Total loss': 0.41172662885351613} | train loss {'Reaction outcome loss': 0.3298610985098827, 'Total loss': 0.3298610985098827}
2022-11-28 01:38:13,840 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:13,840 INFO:     Epoch: 34
2022-11-28 01:38:14,589 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4112439433282072, 'Total loss': 0.4112439433282072} | train loss {'Reaction outcome loss': 0.31516436397308306, 'Total loss': 0.31516436397308306}
2022-11-28 01:38:14,589 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:14,590 INFO:     Epoch: 35
2022-11-28 01:38:15,340 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4111024581573226, 'Total loss': 0.4111024581573226} | train loss {'Reaction outcome loss': 0.32283453979799825, 'Total loss': 0.32283453979799825}
2022-11-28 01:38:15,340 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:15,340 INFO:     Epoch: 36
2022-11-28 01:38:16,090 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4234147711910985, 'Total loss': 0.4234147711910985} | train loss {'Reaction outcome loss': 0.3231447680943435, 'Total loss': 0.3231447680943435}
2022-11-28 01:38:16,090 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:16,090 INFO:     Epoch: 37
2022-11-28 01:38:16,842 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4034710834649476, 'Total loss': 0.4034710834649476} | train loss {'Reaction outcome loss': 0.3208977966118724, 'Total loss': 0.3208977966118724}
2022-11-28 01:38:16,843 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:16,843 INFO:     Epoch: 38
2022-11-28 01:38:17,591 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4441378153860569, 'Total loss': 0.4441378153860569} | train loss {'Reaction outcome loss': 0.3209209047227858, 'Total loss': 0.3209209047227858}
2022-11-28 01:38:17,591 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:17,592 INFO:     Epoch: 39
2022-11-28 01:38:18,341 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39883140508424153, 'Total loss': 0.39883140508424153} | train loss {'Reaction outcome loss': 0.3154048447407061, 'Total loss': 0.3154048447407061}
2022-11-28 01:38:18,341 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:18,341 INFO:     Epoch: 40
2022-11-28 01:38:19,089 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4121656936000694, 'Total loss': 0.4121656936000694} | train loss {'Reaction outcome loss': 0.31940993600555007, 'Total loss': 0.31940993600555007}
2022-11-28 01:38:19,090 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:19,090 INFO:     Epoch: 41
2022-11-28 01:38:19,840 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40787731923840265, 'Total loss': 0.40787731923840265} | train loss {'Reaction outcome loss': 0.32076389144264883, 'Total loss': 0.32076389144264883}
2022-11-28 01:38:19,840 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:19,840 INFO:     Epoch: 42
2022-11-28 01:38:20,587 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43021360683170234, 'Total loss': 0.43021360683170234} | train loss {'Reaction outcome loss': 0.323315724159681, 'Total loss': 0.323315724159681}
2022-11-28 01:38:20,587 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:20,588 INFO:     Epoch: 43
2022-11-28 01:38:21,334 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41627661646767095, 'Total loss': 0.41627661646767095} | train loss {'Reaction outcome loss': 0.31243074743918353, 'Total loss': 0.31243074743918353}
2022-11-28 01:38:21,334 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:21,335 INFO:     Epoch: 44
2022-11-28 01:38:22,083 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4040477875281464, 'Total loss': 0.4040477875281464} | train loss {'Reaction outcome loss': 0.3200353370498746, 'Total loss': 0.3200353370498746}
2022-11-28 01:38:22,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:22,083 INFO:     Epoch: 45
2022-11-28 01:38:22,829 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4096032863652164, 'Total loss': 0.4096032863652164} | train loss {'Reaction outcome loss': 0.32112032866045354, 'Total loss': 0.32112032866045354}
2022-11-28 01:38:22,829 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:22,829 INFO:     Epoch: 46
2022-11-28 01:38:23,578 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4159490909766067, 'Total loss': 0.4159490909766067} | train loss {'Reaction outcome loss': 0.30775208961999706, 'Total loss': 0.30775208961999706}
2022-11-28 01:38:23,578 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:23,578 INFO:     Epoch: 47
2022-11-28 01:38:24,326 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3936586349525235, 'Total loss': 0.3936586349525235} | train loss {'Reaction outcome loss': 0.31359218009897777, 'Total loss': 0.31359218009897777}
2022-11-28 01:38:24,326 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:24,326 INFO:     Epoch: 48
2022-11-28 01:38:25,076 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39480093866586685, 'Total loss': 0.39480093866586685} | train loss {'Reaction outcome loss': 0.3153922924952161, 'Total loss': 0.3153922924952161}
2022-11-28 01:38:25,078 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:25,078 INFO:     Epoch: 49
2022-11-28 01:38:25,831 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41448538953607733, 'Total loss': 0.41448538953607733} | train loss {'Reaction outcome loss': 0.3266086671200971, 'Total loss': 0.3266086671200971}
2022-11-28 01:38:25,831 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:25,831 INFO:     Epoch: 50
2022-11-28 01:38:26,584 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43482850830663333, 'Total loss': 0.43482850830663333} | train loss {'Reaction outcome loss': 0.30361458077846515, 'Total loss': 0.30361458077846515}
2022-11-28 01:38:26,584 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:26,584 INFO:     Epoch: 51
2022-11-28 01:38:27,336 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4472359727052125, 'Total loss': 0.4472359727052125} | train loss {'Reaction outcome loss': 0.30786359385256806, 'Total loss': 0.30786359385256806}
2022-11-28 01:38:27,336 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:27,336 INFO:     Epoch: 52
2022-11-28 01:38:28,089 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40272501009431755, 'Total loss': 0.40272501009431755} | train loss {'Reaction outcome loss': 0.318311108005864, 'Total loss': 0.318311108005864}
2022-11-28 01:38:28,089 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:28,089 INFO:     Epoch: 53
2022-11-28 01:38:28,836 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3986596211113713, 'Total loss': 0.3986596211113713} | train loss {'Reaction outcome loss': 0.3100158157908628, 'Total loss': 0.3100158157908628}
2022-11-28 01:38:28,837 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:28,837 INFO:     Epoch: 54
2022-11-28 01:38:29,587 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4026654596355828, 'Total loss': 0.4026654596355828} | train loss {'Reaction outcome loss': 0.31221021237152236, 'Total loss': 0.31221021237152236}
2022-11-28 01:38:29,588 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:29,588 INFO:     Epoch: 55
2022-11-28 01:38:30,333 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38575161654840817, 'Total loss': 0.38575161654840817} | train loss {'Reaction outcome loss': 0.30898836276103414, 'Total loss': 0.30898836276103414}
2022-11-28 01:38:30,333 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:30,334 INFO:     Epoch: 56
2022-11-28 01:38:31,082 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.382246365940029, 'Total loss': 0.382246365940029} | train loss {'Reaction outcome loss': 0.3180837894699747, 'Total loss': 0.3180837894699747}
2022-11-28 01:38:31,083 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:31,083 INFO:     Epoch: 57
2022-11-28 01:38:31,829 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40576566688039084, 'Total loss': 0.40576566688039084} | train loss {'Reaction outcome loss': 0.31168602623285785, 'Total loss': 0.31168602623285785}
2022-11-28 01:38:31,829 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:31,829 INFO:     Epoch: 58
2022-11-28 01:38:32,575 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3978575569662181, 'Total loss': 0.3978575569662181} | train loss {'Reaction outcome loss': 0.31163759148048775, 'Total loss': 0.31163759148048775}
2022-11-28 01:38:32,575 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:32,575 INFO:     Epoch: 59
2022-11-28 01:38:33,322 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40997660397128627, 'Total loss': 0.40997660397128627} | train loss {'Reaction outcome loss': 0.3152572099540022, 'Total loss': 0.3152572099540022}
2022-11-28 01:38:33,322 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:33,322 INFO:     Epoch: 60
2022-11-28 01:38:34,070 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4024344032460993, 'Total loss': 0.4024344032460993} | train loss {'Reaction outcome loss': 0.3088545757195642, 'Total loss': 0.3088545757195642}
2022-11-28 01:38:34,070 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:34,070 INFO:     Epoch: 61
2022-11-28 01:38:34,817 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40787146596068685, 'Total loss': 0.40787146596068685} | train loss {'Reaction outcome loss': 0.31064447129686035, 'Total loss': 0.31064447129686035}
2022-11-28 01:38:34,817 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:34,817 INFO:     Epoch: 62
2022-11-28 01:38:35,567 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43206827105446294, 'Total loss': 0.43206827105446294} | train loss {'Reaction outcome loss': 0.30274952533504657, 'Total loss': 0.30274952533504657}
2022-11-28 01:38:35,567 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:35,567 INFO:     Epoch: 63
2022-11-28 01:38:36,319 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44448151337829506, 'Total loss': 0.44448151337829506} | train loss {'Reaction outcome loss': 0.3142835594293091, 'Total loss': 0.3142835594293091}
2022-11-28 01:38:36,319 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:36,319 INFO:     Epoch: 64
2022-11-28 01:38:37,067 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39059149473905563, 'Total loss': 0.39059149473905563} | train loss {'Reaction outcome loss': 0.30695010105808895, 'Total loss': 0.30695010105808895}
2022-11-28 01:38:37,067 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:37,067 INFO:     Epoch: 65
2022-11-28 01:38:37,815 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44111713902516797, 'Total loss': 0.44111713902516797} | train loss {'Reaction outcome loss': 0.3018548719645027, 'Total loss': 0.3018548719645027}
2022-11-28 01:38:37,815 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:37,815 INFO:     Epoch: 66
2022-11-28 01:38:38,563 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.38309422778812324, 'Total loss': 0.38309422778812324} | train loss {'Reaction outcome loss': 0.3033572252268993, 'Total loss': 0.3033572252268993}
2022-11-28 01:38:38,563 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:38,563 INFO:     Epoch: 67
2022-11-28 01:38:39,310 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39541007442907855, 'Total loss': 0.39541007442907855} | train loss {'Reaction outcome loss': 0.31872608855126366, 'Total loss': 0.31872608855126366}
2022-11-28 01:38:39,310 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:39,310 INFO:     Epoch: 68
2022-11-28 01:38:40,058 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.37937718866900966, 'Total loss': 0.37937718866900966} | train loss {'Reaction outcome loss': 0.30752984556039015, 'Total loss': 0.30752984556039015}
2022-11-28 01:38:40,058 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:40,058 INFO:     Epoch: 69
2022-11-28 01:38:40,806 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.410517120225863, 'Total loss': 0.410517120225863} | train loss {'Reaction outcome loss': 0.3090113789263752, 'Total loss': 0.3090113789263752}
2022-11-28 01:38:40,806 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:40,806 INFO:     Epoch: 70
2022-11-28 01:38:41,557 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3816098833287304, 'Total loss': 0.3816098833287304} | train loss {'Reaction outcome loss': 0.31339058766682304, 'Total loss': 0.31339058766682304}
2022-11-28 01:38:41,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:41,558 INFO:     Epoch: 71
2022-11-28 01:38:42,311 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39684560149908066, 'Total loss': 0.39684560149908066} | train loss {'Reaction outcome loss': 0.30757621414358577, 'Total loss': 0.30757621414358577}
2022-11-28 01:38:42,311 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:42,311 INFO:     Epoch: 72
2022-11-28 01:38:43,062 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39495466581799765, 'Total loss': 0.39495466581799765} | train loss {'Reaction outcome loss': 0.3072263276534936, 'Total loss': 0.3072263276534936}
2022-11-28 01:38:43,062 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:43,062 INFO:     Epoch: 73
2022-11-28 01:38:43,810 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39333853261037305, 'Total loss': 0.39333853261037305} | train loss {'Reaction outcome loss': 0.3023580163416843, 'Total loss': 0.3023580163416843}
2022-11-28 01:38:43,811 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:43,811 INFO:     Epoch: 74
2022-11-28 01:38:44,558 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4064237778498368, 'Total loss': 0.4064237778498368} | train loss {'Reaction outcome loss': 0.3020527669709296, 'Total loss': 0.3020527669709296}
2022-11-28 01:38:44,558 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:44,558 INFO:     Epoch: 75
2022-11-28 01:38:45,308 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40192260940305213, 'Total loss': 0.40192260940305213} | train loss {'Reaction outcome loss': 0.3041043534965044, 'Total loss': 0.3041043534965044}
2022-11-28 01:38:45,308 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:45,308 INFO:     Epoch: 76
2022-11-28 01:38:46,056 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3918711587109349, 'Total loss': 0.3918711587109349} | train loss {'Reaction outcome loss': 0.30773065438974767, 'Total loss': 0.30773065438974767}
2022-11-28 01:38:46,056 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:46,056 INFO:     Epoch: 77
2022-11-28 01:38:46,807 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3804848942567002, 'Total loss': 0.3804848942567002} | train loss {'Reaction outcome loss': 0.310490807788747, 'Total loss': 0.310490807788747}
2022-11-28 01:38:46,807 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:46,807 INFO:     Epoch: 78
2022-11-28 01:38:47,559 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41092450510371814, 'Total loss': 0.41092450510371814} | train loss {'Reaction outcome loss': 0.31162149116637244, 'Total loss': 0.31162149116637244}
2022-11-28 01:38:47,560 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:47,560 INFO:     Epoch: 79
2022-11-28 01:38:48,304 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3843869495798241, 'Total loss': 0.3843869495798241} | train loss {'Reaction outcome loss': 0.3117529129789722, 'Total loss': 0.3117529129789722}
2022-11-28 01:38:48,305 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:48,305 INFO:     Epoch: 80
2022-11-28 01:38:49,051 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38736432638357987, 'Total loss': 0.38736432638357987} | train loss {'Reaction outcome loss': 0.305175147484988, 'Total loss': 0.305175147484988}
2022-11-28 01:38:49,051 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:49,052 INFO:     Epoch: 81
2022-11-28 01:38:49,806 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4170138236473907, 'Total loss': 0.4170138236473907} | train loss {'Reaction outcome loss': 0.3091296230352694, 'Total loss': 0.3091296230352694}
2022-11-28 01:38:49,806 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:49,806 INFO:     Epoch: 82
2022-11-28 01:38:50,554 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4160906377841126, 'Total loss': 0.4160906377841126} | train loss {'Reaction outcome loss': 0.3081296712100025, 'Total loss': 0.3081296712100025}
2022-11-28 01:38:50,555 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:50,555 INFO:     Epoch: 83
2022-11-28 01:38:51,305 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3951355356045745, 'Total loss': 0.3951355356045745} | train loss {'Reaction outcome loss': 0.3089122352220358, 'Total loss': 0.3089122352220358}
2022-11-28 01:38:51,306 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:51,306 INFO:     Epoch: 84
2022-11-28 01:38:52,056 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4104972518980503, 'Total loss': 0.4104972518980503} | train loss {'Reaction outcome loss': 0.3045688904972086, 'Total loss': 0.3045688904972086}
2022-11-28 01:38:52,056 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:52,056 INFO:     Epoch: 85
2022-11-28 01:38:52,807 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3966238708658652, 'Total loss': 0.3966238708658652} | train loss {'Reaction outcome loss': 0.2983485976864974, 'Total loss': 0.2983485976864974}
2022-11-28 01:38:52,807 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:52,807 INFO:     Epoch: 86
2022-11-28 01:38:53,557 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40302982790903613, 'Total loss': 0.40302982790903613} | train loss {'Reaction outcome loss': 0.3051473820401776, 'Total loss': 0.3051473820401776}
2022-11-28 01:38:53,557 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:53,558 INFO:     Epoch: 87
2022-11-28 01:38:54,301 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4229149608449502, 'Total loss': 0.4229149608449502} | train loss {'Reaction outcome loss': 0.306827474092584, 'Total loss': 0.306827474092584}
2022-11-28 01:38:54,301 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:54,301 INFO:     Epoch: 88
2022-11-28 01:38:55,047 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40252750129862264, 'Total loss': 0.40252750129862264} | train loss {'Reaction outcome loss': 0.30420937743638793, 'Total loss': 0.30420937743638793}
2022-11-28 01:38:55,048 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:55,048 INFO:     Epoch: 89
2022-11-28 01:38:55,791 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3990327234972607, 'Total loss': 0.3990327234972607} | train loss {'Reaction outcome loss': 0.30410778896522617, 'Total loss': 0.30410778896522617}
2022-11-28 01:38:55,791 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:55,791 INFO:     Epoch: 90
2022-11-28 01:38:56,536 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3974242836914279, 'Total loss': 0.3974242836914279} | train loss {'Reaction outcome loss': 0.3012512804820172, 'Total loss': 0.3012512804820172}
2022-11-28 01:38:56,537 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:56,537 INFO:     Epoch: 91
2022-11-28 01:38:57,285 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39691230857914145, 'Total loss': 0.39691230857914145} | train loss {'Reaction outcome loss': 0.299950001070336, 'Total loss': 0.299950001070336}
2022-11-28 01:38:57,285 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:57,285 INFO:     Epoch: 92
2022-11-28 01:38:58,034 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4125168987295844, 'Total loss': 0.4125168987295844} | train loss {'Reaction outcome loss': 0.30554248587859256, 'Total loss': 0.30554248587859256}
2022-11-28 01:38:58,035 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:58,035 INFO:     Epoch: 93
2022-11-28 01:38:58,781 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4058364060792056, 'Total loss': 0.4058364060792056} | train loss {'Reaction outcome loss': 0.3000707342740028, 'Total loss': 0.3000707342740028}
2022-11-28 01:38:58,782 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:58,782 INFO:     Epoch: 94
2022-11-28 01:38:59,529 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39463473873382265, 'Total loss': 0.39463473873382265} | train loss {'Reaction outcome loss': 0.3122087913084655, 'Total loss': 0.3122087913084655}
2022-11-28 01:38:59,529 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:38:59,529 INFO:     Epoch: 95
2022-11-28 01:39:00,280 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4140717993405732, 'Total loss': 0.4140717993405732} | train loss {'Reaction outcome loss': 0.30168866567433844, 'Total loss': 0.30168866567433844}
2022-11-28 01:39:00,281 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:00,281 INFO:     Epoch: 96
2022-11-28 01:39:01,027 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4168422967195511, 'Total loss': 0.4168422967195511} | train loss {'Reaction outcome loss': 0.2950016598427488, 'Total loss': 0.2950016598427488}
2022-11-28 01:39:01,027 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:01,027 INFO:     Epoch: 97
2022-11-28 01:39:01,779 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4335409098050811, 'Total loss': 0.4335409098050811} | train loss {'Reaction outcome loss': 0.2974133415508174, 'Total loss': 0.2974133415508174}
2022-11-28 01:39:01,779 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:01,779 INFO:     Epoch: 98
2022-11-28 01:39:02,527 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37138382701033895, 'Total loss': 0.37138382701033895} | train loss {'Reaction outcome loss': 0.31576311347946046, 'Total loss': 0.31576311347946046}
2022-11-28 01:39:02,527 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:02,528 INFO:     Epoch: 99
2022-11-28 01:39:03,277 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.415115912868218, 'Total loss': 0.415115912868218} | train loss {'Reaction outcome loss': 0.31188585029374205, 'Total loss': 0.31188585029374205}
2022-11-28 01:39:03,278 INFO:     Best model found after epoch 19 of 100.
2022-11-28 01:39:03,278 INFO:   Done with stage: TRAINING
2022-11-28 01:39:03,278 INFO:   Starting stage: EVALUATION
2022-11-28 01:39:03,393 INFO:   Done with stage: EVALUATION
2022-11-28 01:39:03,393 INFO:   Leaving out SEQ value Fold_8
2022-11-28 01:39:03,406 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-28 01:39:03,406 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:39:04,050 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:39:04,050 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:39:04,121 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:39:04,121 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:39:04,122 INFO:     No hyperparam tuning for this model
2022-11-28 01:39:04,122 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:39:04,122 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:39:04,122 INFO:     None feature selector for col prot
2022-11-28 01:39:04,123 INFO:     None feature selector for col prot
2022-11-28 01:39:04,123 INFO:     None feature selector for col prot
2022-11-28 01:39:04,123 INFO:     None feature selector for col chem
2022-11-28 01:39:04,123 INFO:     None feature selector for col chem
2022-11-28 01:39:04,123 INFO:     None feature selector for col chem
2022-11-28 01:39:04,123 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:39:04,123 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:39:04,125 INFO:     Number of params in model 169741
2022-11-28 01:39:04,128 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:39:04,128 INFO:   Starting stage: TRAINING
2022-11-28 01:39:04,182 INFO:     Val loss before train {'Reaction outcome loss': 1.049263479357416, 'Total loss': 1.049263479357416}
2022-11-28 01:39:04,183 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:04,183 INFO:     Epoch: 0
2022-11-28 01:39:04,935 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5320430452173407, 'Total loss': 0.5320430452173407} | train loss {'Reaction outcome loss': 0.6521052331813881, 'Total loss': 0.6521052331813881}
2022-11-28 01:39:04,935 INFO:     Found new best model at epoch 0
2022-11-28 01:39:04,936 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:04,936 INFO:     Epoch: 1
2022-11-28 01:39:05,687 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4992180209268223, 'Total loss': 0.4992180209268223} | train loss {'Reaction outcome loss': 0.49888564964696286, 'Total loss': 0.49888564964696286}
2022-11-28 01:39:05,687 INFO:     Found new best model at epoch 1
2022-11-28 01:39:05,688 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:05,688 INFO:     Epoch: 2
2022-11-28 01:39:06,439 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4630712545053525, 'Total loss': 0.4630712545053525} | train loss {'Reaction outcome loss': 0.470077877203303, 'Total loss': 0.470077877203303}
2022-11-28 01:39:06,439 INFO:     Found new best model at epoch 2
2022-11-28 01:39:06,440 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:06,440 INFO:     Epoch: 3
2022-11-28 01:39:07,192 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45965707539157435, 'Total loss': 0.45965707539157435} | train loss {'Reaction outcome loss': 0.4422055107331084, 'Total loss': 0.4422055107331084}
2022-11-28 01:39:07,192 INFO:     Found new best model at epoch 3
2022-11-28 01:39:07,193 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:07,193 INFO:     Epoch: 4
2022-11-28 01:39:07,946 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44803857430815697, 'Total loss': 0.44803857430815697} | train loss {'Reaction outcome loss': 0.43089023641040247, 'Total loss': 0.43089023641040247}
2022-11-28 01:39:07,947 INFO:     Found new best model at epoch 4
2022-11-28 01:39:07,947 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:07,947 INFO:     Epoch: 5
2022-11-28 01:39:08,698 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45260267196731135, 'Total loss': 0.45260267196731135} | train loss {'Reaction outcome loss': 0.4151970330745943, 'Total loss': 0.4151970330745943}
2022-11-28 01:39:08,698 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:08,698 INFO:     Epoch: 6
2022-11-28 01:39:09,456 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43645131757313554, 'Total loss': 0.43645131757313554} | train loss {'Reaction outcome loss': 0.4020282609328147, 'Total loss': 0.4020282609328147}
2022-11-28 01:39:09,456 INFO:     Found new best model at epoch 6
2022-11-28 01:39:09,457 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:09,457 INFO:     Epoch: 7
2022-11-28 01:39:10,209 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4671445719220422, 'Total loss': 0.4671445719220422} | train loss {'Reaction outcome loss': 0.4009925202136078, 'Total loss': 0.4009925202136078}
2022-11-28 01:39:10,210 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:10,210 INFO:     Epoch: 8
2022-11-28 01:39:10,957 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44342085041783075, 'Total loss': 0.44342085041783075} | train loss {'Reaction outcome loss': 0.38830346869485033, 'Total loss': 0.38830346869485033}
2022-11-28 01:39:10,957 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:10,957 INFO:     Epoch: 9
2022-11-28 01:39:11,711 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4249120005829768, 'Total loss': 0.4249120005829768} | train loss {'Reaction outcome loss': 0.3873176191663069, 'Total loss': 0.3873176191663069}
2022-11-28 01:39:11,711 INFO:     Found new best model at epoch 9
2022-11-28 01:39:11,712 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:11,712 INFO:     Epoch: 10
2022-11-28 01:39:12,459 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46006544814868405, 'Total loss': 0.46006544814868405} | train loss {'Reaction outcome loss': 0.37832717459288334, 'Total loss': 0.37832717459288334}
2022-11-28 01:39:12,460 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:12,460 INFO:     Epoch: 11
2022-11-28 01:39:13,205 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4297382503070615, 'Total loss': 0.4297382503070615} | train loss {'Reaction outcome loss': 0.37695187459429425, 'Total loss': 0.37695187459429425}
2022-11-28 01:39:13,205 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:13,205 INFO:     Epoch: 12
2022-11-28 01:39:13,952 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43213157999244606, 'Total loss': 0.43213157999244606} | train loss {'Reaction outcome loss': 0.3773093088079364, 'Total loss': 0.3773093088079364}
2022-11-28 01:39:13,952 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:13,952 INFO:     Epoch: 13
2022-11-28 01:39:14,701 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43028863045302307, 'Total loss': 0.43028863045302307} | train loss {'Reaction outcome loss': 0.3606638937227188, 'Total loss': 0.3606638937227188}
2022-11-28 01:39:14,701 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:14,702 INFO:     Epoch: 14
2022-11-28 01:39:15,451 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44400114633820276, 'Total loss': 0.44400114633820276} | train loss {'Reaction outcome loss': 0.3667713280977501, 'Total loss': 0.3667713280977501}
2022-11-28 01:39:15,452 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:15,452 INFO:     Epoch: 15
2022-11-28 01:39:16,199 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4197852465916764, 'Total loss': 0.4197852465916764} | train loss {'Reaction outcome loss': 0.35384311220578607, 'Total loss': 0.35384311220578607}
2022-11-28 01:39:16,199 INFO:     Found new best model at epoch 15
2022-11-28 01:39:16,200 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:16,200 INFO:     Epoch: 16
2022-11-28 01:39:16,951 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4286906841126355, 'Total loss': 0.4286906841126355} | train loss {'Reaction outcome loss': 0.3567513316389053, 'Total loss': 0.3567513316389053}
2022-11-28 01:39:16,951 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:16,952 INFO:     Epoch: 17
2022-11-28 01:39:17,704 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.449187771840529, 'Total loss': 0.449187771840529} | train loss {'Reaction outcome loss': 0.350512447917173, 'Total loss': 0.350512447917173}
2022-11-28 01:39:17,704 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:17,705 INFO:     Epoch: 18
2022-11-28 01:39:18,455 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4095647692341696, 'Total loss': 0.4095647692341696} | train loss {'Reaction outcome loss': 0.350370479837781, 'Total loss': 0.350370479837781}
2022-11-28 01:39:18,455 INFO:     Found new best model at epoch 18
2022-11-28 01:39:18,456 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:18,456 INFO:     Epoch: 19
2022-11-28 01:39:19,204 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43910179659724236, 'Total loss': 0.43910179659724236} | train loss {'Reaction outcome loss': 0.34181802611677875, 'Total loss': 0.34181802611677875}
2022-11-28 01:39:19,204 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:19,204 INFO:     Epoch: 20
2022-11-28 01:39:19,950 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4315337630158121, 'Total loss': 0.4315337630158121} | train loss {'Reaction outcome loss': 0.346735249363607, 'Total loss': 0.346735249363607}
2022-11-28 01:39:19,950 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:19,950 INFO:     Epoch: 21
2022-11-28 01:39:20,698 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39448085901412094, 'Total loss': 0.39448085901412094} | train loss {'Reaction outcome loss': 0.34096368381212794, 'Total loss': 0.34096368381212794}
2022-11-28 01:39:20,698 INFO:     Found new best model at epoch 21
2022-11-28 01:39:20,699 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:20,699 INFO:     Epoch: 22
2022-11-28 01:39:21,447 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4427108365026387, 'Total loss': 0.4427108365026387} | train loss {'Reaction outcome loss': 0.34147264685241446, 'Total loss': 0.34147264685241446}
2022-11-28 01:39:21,447 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:21,447 INFO:     Epoch: 23
2022-11-28 01:39:22,196 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4082601730796424, 'Total loss': 0.4082601730796424} | train loss {'Reaction outcome loss': 0.3413684027449739, 'Total loss': 0.3413684027449739}
2022-11-28 01:39:22,196 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:22,196 INFO:     Epoch: 24
2022-11-28 01:39:22,945 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4135923930867152, 'Total loss': 0.4135923930867152} | train loss {'Reaction outcome loss': 0.32937959245135706, 'Total loss': 0.32937959245135706}
2022-11-28 01:39:22,945 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:22,946 INFO:     Epoch: 25
2022-11-28 01:39:23,693 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44219392097809096, 'Total loss': 0.44219392097809096} | train loss {'Reaction outcome loss': 0.34853861719790485, 'Total loss': 0.34853861719790485}
2022-11-28 01:39:23,693 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:23,693 INFO:     Epoch: 26
2022-11-28 01:39:24,438 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40583780204707925, 'Total loss': 0.40583780204707925} | train loss {'Reaction outcome loss': 0.3439647094046156, 'Total loss': 0.3439647094046156}
2022-11-28 01:39:24,438 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:24,438 INFO:     Epoch: 27
2022-11-28 01:39:25,188 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43287223899229005, 'Total loss': 0.43287223899229005} | train loss {'Reaction outcome loss': 0.32594351010817674, 'Total loss': 0.32594351010817674}
2022-11-28 01:39:25,188 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:25,188 INFO:     Epoch: 28
2022-11-28 01:39:25,943 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4312324405393817, 'Total loss': 0.4312324405393817} | train loss {'Reaction outcome loss': 0.3313658241963675, 'Total loss': 0.3313658241963675}
2022-11-28 01:39:25,943 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:25,943 INFO:     Epoch: 29
2022-11-28 01:39:26,693 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42177623408761894, 'Total loss': 0.42177623408761894} | train loss {'Reaction outcome loss': 0.33500686987874007, 'Total loss': 0.33500686987874007}
2022-11-28 01:39:26,693 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:26,693 INFO:     Epoch: 30
2022-11-28 01:39:27,443 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41906394775618205, 'Total loss': 0.41906394775618205} | train loss {'Reaction outcome loss': 0.3293753843604317, 'Total loss': 0.3293753843604317}
2022-11-28 01:39:27,444 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:27,444 INFO:     Epoch: 31
2022-11-28 01:39:28,195 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42111101611094043, 'Total loss': 0.42111101611094043} | train loss {'Reaction outcome loss': 0.3355871253316441, 'Total loss': 0.3355871253316441}
2022-11-28 01:39:28,195 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:28,195 INFO:     Epoch: 32
2022-11-28 01:39:28,946 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4049383608455008, 'Total loss': 0.4049383608455008} | train loss {'Reaction outcome loss': 0.32948321789022417, 'Total loss': 0.32948321789022417}
2022-11-28 01:39:28,946 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:28,946 INFO:     Epoch: 33
2022-11-28 01:39:29,695 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4325357641686093, 'Total loss': 0.4325357641686093} | train loss {'Reaction outcome loss': 0.33591429165173925, 'Total loss': 0.33591429165173925}
2022-11-28 01:39:29,695 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:29,695 INFO:     Epoch: 34
2022-11-28 01:39:30,446 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4181752496144988, 'Total loss': 0.4181752496144988} | train loss {'Reaction outcome loss': 0.3289625739618655, 'Total loss': 0.3289625739618655}
2022-11-28 01:39:30,446 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:30,446 INFO:     Epoch: 35
2022-11-28 01:39:31,192 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4316804845902053, 'Total loss': 0.4316804845902053} | train loss {'Reaction outcome loss': 0.32563895020153255, 'Total loss': 0.32563895020153255}
2022-11-28 01:39:31,192 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:31,192 INFO:     Epoch: 36
2022-11-28 01:39:31,937 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41163531894033606, 'Total loss': 0.41163531894033606} | train loss {'Reaction outcome loss': 0.3251631089275883, 'Total loss': 0.3251631089275883}
2022-11-28 01:39:31,937 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:31,937 INFO:     Epoch: 37
2022-11-28 01:39:32,683 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4287134642628106, 'Total loss': 0.4287134642628106} | train loss {'Reaction outcome loss': 0.3189206618154722, 'Total loss': 0.3189206618154722}
2022-11-28 01:39:32,683 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:32,683 INFO:     Epoch: 38
2022-11-28 01:39:33,432 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45130121436986054, 'Total loss': 0.45130121436986054} | train loss {'Reaction outcome loss': 0.32876588214909835, 'Total loss': 0.32876588214909835}
2022-11-28 01:39:33,432 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:33,432 INFO:     Epoch: 39
2022-11-28 01:39:34,183 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43407458236271684, 'Total loss': 0.43407458236271684} | train loss {'Reaction outcome loss': 0.3210594755627455, 'Total loss': 0.3210594755627455}
2022-11-28 01:39:34,184 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:34,184 INFO:     Epoch: 40
2022-11-28 01:39:34,935 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4234926341609521, 'Total loss': 0.4234926341609521} | train loss {'Reaction outcome loss': 0.32535581314756024, 'Total loss': 0.32535581314756024}
2022-11-28 01:39:34,935 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:34,935 INFO:     Epoch: 41
2022-11-28 01:39:35,680 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41117491691627284, 'Total loss': 0.41117491691627284} | train loss {'Reaction outcome loss': 0.3234138901405517, 'Total loss': 0.3234138901405517}
2022-11-28 01:39:35,680 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:35,680 INFO:     Epoch: 42
2022-11-28 01:39:36,430 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3920840753073042, 'Total loss': 0.3920840753073042} | train loss {'Reaction outcome loss': 0.3190956762240779, 'Total loss': 0.3190956762240779}
2022-11-28 01:39:36,430 INFO:     Found new best model at epoch 42
2022-11-28 01:39:36,430 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:36,431 INFO:     Epoch: 43
2022-11-28 01:39:37,178 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4263532994823022, 'Total loss': 0.4263532994823022} | train loss {'Reaction outcome loss': 0.32267267836798585, 'Total loss': 0.32267267836798585}
2022-11-28 01:39:37,178 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:37,178 INFO:     Epoch: 44
2022-11-28 01:39:37,922 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41337788274342363, 'Total loss': 0.41337788274342363} | train loss {'Reaction outcome loss': 0.3137803533444962, 'Total loss': 0.3137803533444962}
2022-11-28 01:39:37,923 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:37,923 INFO:     Epoch: 45
2022-11-28 01:39:38,669 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42463982850313187, 'Total loss': 0.42463982850313187} | train loss {'Reaction outcome loss': 0.331805438644463, 'Total loss': 0.331805438644463}
2022-11-28 01:39:38,669 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:38,669 INFO:     Epoch: 46
2022-11-28 01:39:39,420 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43007988144050946, 'Total loss': 0.43007988144050946} | train loss {'Reaction outcome loss': 0.3115352304321864, 'Total loss': 0.3115352304321864}
2022-11-28 01:39:39,420 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:39,420 INFO:     Epoch: 47
2022-11-28 01:39:40,166 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41063921492208133, 'Total loss': 0.41063921492208133} | train loss {'Reaction outcome loss': 0.33300327593761103, 'Total loss': 0.33300327593761103}
2022-11-28 01:39:40,166 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:40,166 INFO:     Epoch: 48
2022-11-28 01:39:40,913 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3828632709654895, 'Total loss': 0.3828632709654895} | train loss {'Reaction outcome loss': 0.3235895283550264, 'Total loss': 0.3235895283550264}
2022-11-28 01:39:40,913 INFO:     Found new best model at epoch 48
2022-11-28 01:39:40,914 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:40,914 INFO:     Epoch: 49
2022-11-28 01:39:41,664 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42133932933211327, 'Total loss': 0.42133932933211327} | train loss {'Reaction outcome loss': 0.3074472812755454, 'Total loss': 0.3074472812755454}
2022-11-28 01:39:41,664 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:41,665 INFO:     Epoch: 50
2022-11-28 01:39:42,413 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4183244989676909, 'Total loss': 0.4183244989676909} | train loss {'Reaction outcome loss': 0.31846016492213935, 'Total loss': 0.31846016492213935}
2022-11-28 01:39:42,413 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:42,413 INFO:     Epoch: 51
2022-11-28 01:39:43,158 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4059989999302409, 'Total loss': 0.4059989999302409} | train loss {'Reaction outcome loss': 0.3288205585051929, 'Total loss': 0.3288205585051929}
2022-11-28 01:39:43,158 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:43,158 INFO:     Epoch: 52
2022-11-28 01:39:43,904 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39683826521716337, 'Total loss': 0.39683826521716337} | train loss {'Reaction outcome loss': 0.31948851872115364, 'Total loss': 0.31948851872115364}
2022-11-28 01:39:43,904 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:43,904 INFO:     Epoch: 53
2022-11-28 01:39:44,652 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4110555655576966, 'Total loss': 0.4110555655576966} | train loss {'Reaction outcome loss': 0.3196745146546633, 'Total loss': 0.3196745146546633}
2022-11-28 01:39:44,652 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:44,652 INFO:     Epoch: 54
2022-11-28 01:39:45,401 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4306808274916627, 'Total loss': 0.4306808274916627} | train loss {'Reaction outcome loss': 0.3113550414451428, 'Total loss': 0.3113550414451428}
2022-11-28 01:39:45,401 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:45,401 INFO:     Epoch: 55
2022-11-28 01:39:46,148 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4398039582778107, 'Total loss': 0.4398039582778107} | train loss {'Reaction outcome loss': 0.31330848332013816, 'Total loss': 0.31330848332013816}
2022-11-28 01:39:46,148 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:46,148 INFO:     Epoch: 56
2022-11-28 01:39:46,894 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4065707288682461, 'Total loss': 0.4065707288682461} | train loss {'Reaction outcome loss': 0.3210198000644244, 'Total loss': 0.3210198000644244}
2022-11-28 01:39:46,895 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:46,895 INFO:     Epoch: 57
2022-11-28 01:39:47,642 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.394586596976627, 'Total loss': 0.394586596976627} | train loss {'Reaction outcome loss': 0.3104154404493109, 'Total loss': 0.3104154404493109}
2022-11-28 01:39:47,643 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:47,643 INFO:     Epoch: 58
2022-11-28 01:39:48,390 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.36970913071524014, 'Total loss': 0.36970913071524014} | train loss {'Reaction outcome loss': 0.30853447666571987, 'Total loss': 0.30853447666571987}
2022-11-28 01:39:48,390 INFO:     Found new best model at epoch 58
2022-11-28 01:39:48,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:48,391 INFO:     Epoch: 59
2022-11-28 01:39:49,137 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40803384069692006, 'Total loss': 0.40803384069692006} | train loss {'Reaction outcome loss': 0.3150802400083311, 'Total loss': 0.3150802400083311}
2022-11-28 01:39:49,137 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:49,137 INFO:     Epoch: 60
2022-11-28 01:39:49,884 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39711072092706506, 'Total loss': 0.39711072092706506} | train loss {'Reaction outcome loss': 0.31783795227567035, 'Total loss': 0.31783795227567035}
2022-11-28 01:39:49,884 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:49,884 INFO:     Epoch: 61
2022-11-28 01:39:50,633 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.414273891936649, 'Total loss': 0.414273891936649} | train loss {'Reaction outcome loss': 0.30879067788801845, 'Total loss': 0.30879067788801845}
2022-11-28 01:39:50,633 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:50,633 INFO:     Epoch: 62
2022-11-28 01:39:51,377 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42699749632315204, 'Total loss': 0.42699749632315204} | train loss {'Reaction outcome loss': 0.3121576341049325, 'Total loss': 0.3121576341049325}
2022-11-28 01:39:51,377 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:51,377 INFO:     Epoch: 63
2022-11-28 01:39:52,125 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3870770243758505, 'Total loss': 0.3870770243758505} | train loss {'Reaction outcome loss': 0.3056122133989007, 'Total loss': 0.3056122133989007}
2022-11-28 01:39:52,125 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:52,126 INFO:     Epoch: 64
2022-11-28 01:39:52,875 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.419822558760643, 'Total loss': 0.419822558760643} | train loss {'Reaction outcome loss': 0.30965670704421017, 'Total loss': 0.30965670704421017}
2022-11-28 01:39:52,875 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:52,875 INFO:     Epoch: 65
2022-11-28 01:39:53,621 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4097231863574548, 'Total loss': 0.4097231863574548} | train loss {'Reaction outcome loss': 0.3059912226162851, 'Total loss': 0.3059912226162851}
2022-11-28 01:39:53,621 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:53,622 INFO:     Epoch: 66
2022-11-28 01:39:54,366 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3938792838969014, 'Total loss': 0.3938792838969014} | train loss {'Reaction outcome loss': 0.3112883609569361, 'Total loss': 0.3112883609569361}
2022-11-28 01:39:54,367 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:54,367 INFO:     Epoch: 67
2022-11-28 01:39:55,114 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43754461814056744, 'Total loss': 0.43754461814056744} | train loss {'Reaction outcome loss': 0.3086289740017345, 'Total loss': 0.3086289740017345}
2022-11-28 01:39:55,114 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:55,114 INFO:     Epoch: 68
2022-11-28 01:39:55,860 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41558929617432033, 'Total loss': 0.41558929617432033} | train loss {'Reaction outcome loss': 0.30679072853508255, 'Total loss': 0.30679072853508255}
2022-11-28 01:39:55,860 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:55,860 INFO:     Epoch: 69
2022-11-28 01:39:56,607 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41776320507580583, 'Total loss': 0.41776320507580583} | train loss {'Reaction outcome loss': 0.31426815385179174, 'Total loss': 0.31426815385179174}
2022-11-28 01:39:56,607 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:56,607 INFO:     Epoch: 70
2022-11-28 01:39:57,357 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41103689914399927, 'Total loss': 0.41103689914399927} | train loss {'Reaction outcome loss': 0.3176948092877865, 'Total loss': 0.3176948092877865}
2022-11-28 01:39:57,357 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:57,357 INFO:     Epoch: 71
2022-11-28 01:39:58,103 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4302249081771482, 'Total loss': 0.4302249081771482} | train loss {'Reaction outcome loss': 0.3124287443445815, 'Total loss': 0.3124287443445815}
2022-11-28 01:39:58,104 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:58,105 INFO:     Epoch: 72
2022-11-28 01:39:58,850 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38855411806567147, 'Total loss': 0.38855411806567147} | train loss {'Reaction outcome loss': 0.32815886321928234, 'Total loss': 0.32815886321928234}
2022-11-28 01:39:58,850 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:58,850 INFO:     Epoch: 73
2022-11-28 01:39:59,598 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39086813919923524, 'Total loss': 0.39086813919923524} | train loss {'Reaction outcome loss': 0.304563915326951, 'Total loss': 0.304563915326951}
2022-11-28 01:39:59,598 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:39:59,598 INFO:     Epoch: 74
2022-11-28 01:40:00,347 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4075163684108041, 'Total loss': 0.4075163684108041} | train loss {'Reaction outcome loss': 0.3130004573463192, 'Total loss': 0.3130004573463192}
2022-11-28 01:40:00,347 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:00,347 INFO:     Epoch: 75
2022-11-28 01:40:01,097 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3970593393526294, 'Total loss': 0.3970593393526294} | train loss {'Reaction outcome loss': 0.311648303192229, 'Total loss': 0.311648303192229}
2022-11-28 01:40:01,097 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:01,097 INFO:     Epoch: 76
2022-11-28 01:40:01,846 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40612975050779904, 'Total loss': 0.40612975050779904} | train loss {'Reaction outcome loss': 0.303881217545319, 'Total loss': 0.303881217545319}
2022-11-28 01:40:01,846 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:01,846 INFO:     Epoch: 77
2022-11-28 01:40:02,592 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4093349081548778, 'Total loss': 0.4093349081548778} | train loss {'Reaction outcome loss': 0.32006457721393916, 'Total loss': 0.32006457721393916}
2022-11-28 01:40:02,592 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:02,592 INFO:     Epoch: 78
2022-11-28 01:40:03,340 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.461642227050933, 'Total loss': 0.461642227050933} | train loss {'Reaction outcome loss': 0.3022667623815998, 'Total loss': 0.3022667623815998}
2022-11-28 01:40:03,340 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:03,340 INFO:     Epoch: 79
2022-11-28 01:40:04,089 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5591226281090216, 'Total loss': 0.5591226281090216} | train loss {'Reaction outcome loss': 0.30879845878770273, 'Total loss': 0.30879845878770273}
2022-11-28 01:40:04,089 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:04,089 INFO:     Epoch: 80
2022-11-28 01:40:04,833 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41462667828256433, 'Total loss': 0.41462667828256433} | train loss {'Reaction outcome loss': 0.3159824625378655, 'Total loss': 0.3159824625378655}
2022-11-28 01:40:04,833 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:04,833 INFO:     Epoch: 81
2022-11-28 01:40:05,578 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4034416689114137, 'Total loss': 0.4034416689114137} | train loss {'Reaction outcome loss': 0.31064103979377017, 'Total loss': 0.31064103979377017}
2022-11-28 01:40:05,578 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:05,578 INFO:     Epoch: 82
2022-11-28 01:40:06,325 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4424535483121872, 'Total loss': 0.4424535483121872} | train loss {'Reaction outcome loss': 0.30504680351324137, 'Total loss': 0.30504680351324137}
2022-11-28 01:40:06,325 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:06,326 INFO:     Epoch: 83
2022-11-28 01:40:07,074 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41697413491254504, 'Total loss': 0.41697413491254504} | train loss {'Reaction outcome loss': 0.31268977995721564, 'Total loss': 0.31268977995721564}
2022-11-28 01:40:07,074 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:07,075 INFO:     Epoch: 84
2022-11-28 01:40:07,821 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3892954405058514, 'Total loss': 0.3892954405058514} | train loss {'Reaction outcome loss': 0.30211426134431557, 'Total loss': 0.30211426134431557}
2022-11-28 01:40:07,822 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:07,822 INFO:     Epoch: 85
2022-11-28 01:40:08,568 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40074251321229065, 'Total loss': 0.40074251321229065} | train loss {'Reaction outcome loss': 0.30984461562888277, 'Total loss': 0.30984461562888277}
2022-11-28 01:40:08,569 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:08,569 INFO:     Epoch: 86
2022-11-28 01:40:09,315 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4333451972766356, 'Total loss': 0.4333451972766356} | train loss {'Reaction outcome loss': 0.3038886489286538, 'Total loss': 0.3038886489286538}
2022-11-28 01:40:09,315 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:09,315 INFO:     Epoch: 87
2022-11-28 01:40:10,060 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4277046346528964, 'Total loss': 0.4277046346528964} | train loss {'Reaction outcome loss': 0.30167650748344677, 'Total loss': 0.30167650748344677}
2022-11-28 01:40:10,061 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:10,061 INFO:     Epoch: 88
2022-11-28 01:40:10,806 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45367154919288377, 'Total loss': 0.45367154919288377} | train loss {'Reaction outcome loss': 0.29915624060818263, 'Total loss': 0.29915624060818263}
2022-11-28 01:40:10,806 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:10,806 INFO:     Epoch: 89
2022-11-28 01:40:11,555 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3954982432452115, 'Total loss': 0.3954982432452115} | train loss {'Reaction outcome loss': 0.3086021039184303, 'Total loss': 0.3086021039184303}
2022-11-28 01:40:11,555 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:11,556 INFO:     Epoch: 90
2022-11-28 01:40:12,303 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39882686497135594, 'Total loss': 0.39882686497135594} | train loss {'Reaction outcome loss': 0.30467506278786927, 'Total loss': 0.30467506278786927}
2022-11-28 01:40:12,303 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:12,303 INFO:     Epoch: 91
2022-11-28 01:40:13,050 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40795411508191715, 'Total loss': 0.40795411508191715} | train loss {'Reaction outcome loss': 0.3088077150826012, 'Total loss': 0.3088077150826012}
2022-11-28 01:40:13,050 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:13,050 INFO:     Epoch: 92
2022-11-28 01:40:13,799 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4179840727963231, 'Total loss': 0.4179840727963231} | train loss {'Reaction outcome loss': 0.3139388841246405, 'Total loss': 0.3139388841246405}
2022-11-28 01:40:13,799 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:13,799 INFO:     Epoch: 93
2022-11-28 01:40:14,543 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39936344427141274, 'Total loss': 0.39936344427141274} | train loss {'Reaction outcome loss': 0.2987085620632335, 'Total loss': 0.2987085620632335}
2022-11-28 01:40:14,543 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:14,543 INFO:     Epoch: 94
2022-11-28 01:40:15,283 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41150077838789334, 'Total loss': 0.41150077838789334} | train loss {'Reaction outcome loss': 0.3024053395455403, 'Total loss': 0.3024053395455403}
2022-11-28 01:40:15,283 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:15,283 INFO:     Epoch: 95
2022-11-28 01:40:16,029 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4583814645355398, 'Total loss': 0.4583814645355398} | train loss {'Reaction outcome loss': 0.30948327633462125, 'Total loss': 0.30948327633462125}
2022-11-28 01:40:16,029 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:16,029 INFO:     Epoch: 96
2022-11-28 01:40:16,771 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3934290060265498, 'Total loss': 0.3934290060265498} | train loss {'Reaction outcome loss': 0.3057777573985438, 'Total loss': 0.3057777573985438}
2022-11-28 01:40:16,772 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:16,772 INFO:     Epoch: 97
2022-11-28 01:40:17,521 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4102303114804355, 'Total loss': 0.4102303114804355} | train loss {'Reaction outcome loss': 0.3078504741312035, 'Total loss': 0.3078504741312035}
2022-11-28 01:40:17,522 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:17,522 INFO:     Epoch: 98
2022-11-28 01:40:18,265 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41486197523772717, 'Total loss': 0.41486197523772717} | train loss {'Reaction outcome loss': 0.29795544152899134, 'Total loss': 0.29795544152899134}
2022-11-28 01:40:18,266 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:18,266 INFO:     Epoch: 99
2022-11-28 01:40:19,010 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42488604157485743, 'Total loss': 0.42488604157485743} | train loss {'Reaction outcome loss': 0.31421226365191324, 'Total loss': 0.31421226365191324}
2022-11-28 01:40:19,010 INFO:     Best model found after epoch 59 of 100.
2022-11-28 01:40:19,011 INFO:   Done with stage: TRAINING
2022-11-28 01:40:19,011 INFO:   Starting stage: EVALUATION
2022-11-28 01:40:19,125 INFO:   Done with stage: EVALUATION
2022-11-28 01:40:19,125 INFO:   Leaving out SEQ value Fold_9
2022-11-28 01:40:19,137 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-28 01:40:19,137 INFO:   Starting stage: FEATURE SCALING
2022-11-28 01:40:19,779 INFO:   Done with stage: FEATURE SCALING
2022-11-28 01:40:19,780 INFO:   Starting stage: SCALING TARGETS
2022-11-28 01:40:19,850 INFO:   Done with stage: SCALING TARGETS
2022-11-28 01:40:19,850 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:40:19,850 INFO:     No hyperparam tuning for this model
2022-11-28 01:40:19,851 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-28 01:40:19,851 INFO:   Starting stage: FEATURE SELECTION
2022-11-28 01:40:19,851 INFO:     None feature selector for col prot
2022-11-28 01:40:19,851 INFO:     None feature selector for col prot
2022-11-28 01:40:19,851 INFO:     None feature selector for col prot
2022-11-28 01:40:19,852 INFO:     None feature selector for col chem
2022-11-28 01:40:19,852 INFO:     None feature selector for col chem
2022-11-28 01:40:19,852 INFO:     None feature selector for col chem
2022-11-28 01:40:19,852 INFO:   Done with stage: FEATURE SELECTION
2022-11-28 01:40:19,852 INFO:   Starting stage: BUILD MODEL
2022-11-28 01:40:19,854 INFO:     Number of params in model 169741
2022-11-28 01:40:19,857 INFO:   Done with stage: BUILD MODEL
2022-11-28 01:40:19,857 INFO:   Starting stage: TRAINING
2022-11-28 01:40:19,910 INFO:     Val loss before train {'Reaction outcome loss': 0.9923939677802, 'Total loss': 0.9923939677802}
2022-11-28 01:40:19,910 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:19,910 INFO:     Epoch: 0
2022-11-28 01:40:20,651 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5457871996543624, 'Total loss': 0.5457871996543624} | train loss {'Reaction outcome loss': 0.6509791131806277, 'Total loss': 0.6509791131806277}
2022-11-28 01:40:20,651 INFO:     Found new best model at epoch 0
2022-11-28 01:40:20,652 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:20,652 INFO:     Epoch: 1
2022-11-28 01:40:21,390 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4675437035885724, 'Total loss': 0.4675437035885724} | train loss {'Reaction outcome loss': 0.524512376862499, 'Total loss': 0.524512376862499}
2022-11-28 01:40:21,390 INFO:     Found new best model at epoch 1
2022-11-28 01:40:21,391 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:21,391 INFO:     Epoch: 2
2022-11-28 01:40:22,137 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47089608589356596, 'Total loss': 0.47089608589356596} | train loss {'Reaction outcome loss': 0.49095643528921884, 'Total loss': 0.49095643528921884}
2022-11-28 01:40:22,137 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:22,138 INFO:     Epoch: 3
2022-11-28 01:40:22,879 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4474608068439094, 'Total loss': 0.4474608068439094} | train loss {'Reaction outcome loss': 0.4499417290332829, 'Total loss': 0.4499417290332829}
2022-11-28 01:40:22,879 INFO:     Found new best model at epoch 3
2022-11-28 01:40:22,880 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:22,880 INFO:     Epoch: 4
2022-11-28 01:40:23,620 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44304016533053736, 'Total loss': 0.44304016533053736} | train loss {'Reaction outcome loss': 0.4432678624001607, 'Total loss': 0.4432678624001607}
2022-11-28 01:40:23,621 INFO:     Found new best model at epoch 4
2022-11-28 01:40:23,621 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:23,621 INFO:     Epoch: 5
2022-11-28 01:40:24,363 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45083763179453934, 'Total loss': 0.45083763179453934} | train loss {'Reaction outcome loss': 0.43694172537157894, 'Total loss': 0.43694172537157894}
2022-11-28 01:40:24,364 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:24,364 INFO:     Epoch: 6
2022-11-28 01:40:25,105 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45117712732065807, 'Total loss': 0.45117712732065807} | train loss {'Reaction outcome loss': 0.4272053918164027, 'Total loss': 0.4272053918164027}
2022-11-28 01:40:25,105 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:25,105 INFO:     Epoch: 7
2022-11-28 01:40:25,844 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4151411816816438, 'Total loss': 0.4151411816816438} | train loss {'Reaction outcome loss': 0.4007723255852154, 'Total loss': 0.4007723255852154}
2022-11-28 01:40:25,844 INFO:     Found new best model at epoch 7
2022-11-28 01:40:25,845 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:25,845 INFO:     Epoch: 8
2022-11-28 01:40:26,587 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4141882143237374, 'Total loss': 0.4141882143237374} | train loss {'Reaction outcome loss': 0.40235180144154875, 'Total loss': 0.40235180144154875}
2022-11-28 01:40:26,587 INFO:     Found new best model at epoch 8
2022-11-28 01:40:26,587 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:26,588 INFO:     Epoch: 9
2022-11-28 01:40:27,324 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4613969610496001, 'Total loss': 0.4613969610496001} | train loss {'Reaction outcome loss': 0.3913774623305571, 'Total loss': 0.3913774623305571}
2022-11-28 01:40:27,325 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:27,325 INFO:     Epoch: 10
2022-11-28 01:40:28,067 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4153880537910895, 'Total loss': 0.4153880537910895} | train loss {'Reaction outcome loss': 0.38982119121652864, 'Total loss': 0.38982119121652864}
2022-11-28 01:40:28,067 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:28,067 INFO:     Epoch: 11
2022-11-28 01:40:28,806 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39668063311414287, 'Total loss': 0.39668063311414287} | train loss {'Reaction outcome loss': 0.38830159619631555, 'Total loss': 0.38830159619631555}
2022-11-28 01:40:28,807 INFO:     Found new best model at epoch 11
2022-11-28 01:40:28,808 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:28,808 INFO:     Epoch: 12
2022-11-28 01:40:29,546 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4165916280312972, 'Total loss': 0.4165916280312972} | train loss {'Reaction outcome loss': 0.3779365409783989, 'Total loss': 0.3779365409783989}
2022-11-28 01:40:29,547 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:29,547 INFO:     Epoch: 13
2022-11-28 01:40:30,289 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42100478065284813, 'Total loss': 0.42100478065284813} | train loss {'Reaction outcome loss': 0.3789426243980886, 'Total loss': 0.3789426243980886}
2022-11-28 01:40:30,289 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:30,289 INFO:     Epoch: 14
2022-11-28 01:40:31,031 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4146891791712154, 'Total loss': 0.4146891791712154} | train loss {'Reaction outcome loss': 0.38771180144929696, 'Total loss': 0.38771180144929696}
2022-11-28 01:40:31,031 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:31,031 INFO:     Epoch: 15
2022-11-28 01:40:31,768 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40233325687321747, 'Total loss': 0.40233325687321747} | train loss {'Reaction outcome loss': 0.38058969571522855, 'Total loss': 0.38058969571522855}
2022-11-28 01:40:31,768 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:31,769 INFO:     Epoch: 16
2022-11-28 01:40:32,505 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4359691630710255, 'Total loss': 0.4359691630710255} | train loss {'Reaction outcome loss': 0.36991504296238126, 'Total loss': 0.36991504296238126}
2022-11-28 01:40:32,505 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:32,505 INFO:     Epoch: 17
2022-11-28 01:40:33,242 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39801186695694923, 'Total loss': 0.39801186695694923} | train loss {'Reaction outcome loss': 0.3713335699518682, 'Total loss': 0.3713335699518682}
2022-11-28 01:40:33,242 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:33,242 INFO:     Epoch: 18
2022-11-28 01:40:33,985 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4175932448018681, 'Total loss': 0.4175932448018681} | train loss {'Reaction outcome loss': 0.35673489469868935, 'Total loss': 0.35673489469868935}
2022-11-28 01:40:33,985 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:33,985 INFO:     Epoch: 19
2022-11-28 01:40:34,723 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3834717593748461, 'Total loss': 0.3834717593748461} | train loss {'Reaction outcome loss': 0.3595656471153503, 'Total loss': 0.3595656471153503}
2022-11-28 01:40:34,723 INFO:     Found new best model at epoch 19
2022-11-28 01:40:34,724 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:34,724 INFO:     Epoch: 20
2022-11-28 01:40:35,464 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3826250630346211, 'Total loss': 0.3826250630346211} | train loss {'Reaction outcome loss': 0.3571592917447148, 'Total loss': 0.3571592917447148}
2022-11-28 01:40:35,464 INFO:     Found new best model at epoch 20
2022-11-28 01:40:35,465 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:35,465 INFO:     Epoch: 21
2022-11-28 01:40:36,206 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3909741196442734, 'Total loss': 0.3909741196442734} | train loss {'Reaction outcome loss': 0.35528903596314343, 'Total loss': 0.35528903596314343}
2022-11-28 01:40:36,206 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:36,206 INFO:     Epoch: 22
2022-11-28 01:40:36,946 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3773235087706284, 'Total loss': 0.3773235087706284} | train loss {'Reaction outcome loss': 0.3596049589123803, 'Total loss': 0.3596049589123803}
2022-11-28 01:40:36,946 INFO:     Found new best model at epoch 22
2022-11-28 01:40:36,947 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:36,947 INFO:     Epoch: 23
2022-11-28 01:40:37,687 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4030686039477587, 'Total loss': 0.4030686039477587} | train loss {'Reaction outcome loss': 0.3527343903596585, 'Total loss': 0.3527343903596585}
2022-11-28 01:40:37,687 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:37,687 INFO:     Epoch: 24
2022-11-28 01:40:38,427 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39616091786460444, 'Total loss': 0.39616091786460444} | train loss {'Reaction outcome loss': 0.35478713055733246, 'Total loss': 0.35478713055733246}
2022-11-28 01:40:38,427 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:38,427 INFO:     Epoch: 25
2022-11-28 01:40:39,165 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3985745818777518, 'Total loss': 0.3985745818777518} | train loss {'Reaction outcome loss': 0.3579117301926922, 'Total loss': 0.3579117301926922}
2022-11-28 01:40:39,165 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:39,165 INFO:     Epoch: 26
2022-11-28 01:40:39,901 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4171851416203109, 'Total loss': 0.4171851416203109} | train loss {'Reaction outcome loss': 0.3679866413114525, 'Total loss': 0.3679866413114525}
2022-11-28 01:40:39,901 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:39,901 INFO:     Epoch: 27
2022-11-28 01:40:40,640 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38988725942644203, 'Total loss': 0.38988725942644203} | train loss {'Reaction outcome loss': 0.3545974782302312, 'Total loss': 0.3545974782302312}
2022-11-28 01:40:40,640 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:40,640 INFO:     Epoch: 28
2022-11-28 01:40:41,378 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3928318226879293, 'Total loss': 0.3928318226879293} | train loss {'Reaction outcome loss': 0.35533584817218394, 'Total loss': 0.35533584817218394}
2022-11-28 01:40:41,378 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:41,378 INFO:     Epoch: 29
2022-11-28 01:40:42,124 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42128217457370326, 'Total loss': 0.42128217457370326} | train loss {'Reaction outcome loss': 0.34910658011149315, 'Total loss': 0.34910658011149315}
2022-11-28 01:40:42,124 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:42,124 INFO:     Epoch: 30
2022-11-28 01:40:42,866 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39228453216227616, 'Total loss': 0.39228453216227616} | train loss {'Reaction outcome loss': 0.3403926490229151, 'Total loss': 0.3403926490229151}
2022-11-28 01:40:42,866 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:42,866 INFO:     Epoch: 31
2022-11-28 01:40:43,610 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38567533411762933, 'Total loss': 0.38567533411762933} | train loss {'Reaction outcome loss': 0.34915939097100424, 'Total loss': 0.34915939097100424}
2022-11-28 01:40:43,611 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:43,611 INFO:     Epoch: 32
2022-11-28 01:40:44,350 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3846730701625347, 'Total loss': 0.3846730701625347} | train loss {'Reaction outcome loss': 0.35817635646052204, 'Total loss': 0.35817635646052204}
2022-11-28 01:40:44,350 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:44,350 INFO:     Epoch: 33
2022-11-28 01:40:45,090 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40431341393427417, 'Total loss': 0.40431341393427417} | train loss {'Reaction outcome loss': 0.33597817436484656, 'Total loss': 0.33597817436484656}
2022-11-28 01:40:45,090 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:45,090 INFO:     Epoch: 34
2022-11-28 01:40:45,828 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.409298106350682, 'Total loss': 0.409298106350682} | train loss {'Reaction outcome loss': 0.33917007581726744, 'Total loss': 0.33917007581726744}
2022-11-28 01:40:45,828 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:45,828 INFO:     Epoch: 35
2022-11-28 01:40:46,569 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.37329055775295605, 'Total loss': 0.37329055775295605} | train loss {'Reaction outcome loss': 0.34992899597897703, 'Total loss': 0.34992899597897703}
2022-11-28 01:40:46,569 INFO:     Found new best model at epoch 35
2022-11-28 01:40:46,570 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:46,570 INFO:     Epoch: 36
2022-11-28 01:40:47,310 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4007807658477263, 'Total loss': 0.4007807658477263} | train loss {'Reaction outcome loss': 0.35034353298093623, 'Total loss': 0.35034353298093623}
2022-11-28 01:40:47,310 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:47,310 INFO:     Epoch: 37
2022-11-28 01:40:48,055 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41952489011666994, 'Total loss': 0.41952489011666994} | train loss {'Reaction outcome loss': 0.34284085257031655, 'Total loss': 0.34284085257031655}
2022-11-28 01:40:48,056 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:48,056 INFO:     Epoch: 38
2022-11-28 01:40:48,798 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3975779214365916, 'Total loss': 0.3975779214365916} | train loss {'Reaction outcome loss': 0.3578519850728, 'Total loss': 0.3578519850728}
2022-11-28 01:40:48,799 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:48,799 INFO:     Epoch: 39
2022-11-28 01:40:49,540 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40007110380313615, 'Total loss': 0.40007110380313615} | train loss {'Reaction outcome loss': 0.3350204008552227, 'Total loss': 0.3350204008552227}
2022-11-28 01:40:49,540 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:49,540 INFO:     Epoch: 40
2022-11-28 01:40:50,282 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3915674510327252, 'Total loss': 0.3915674510327252} | train loss {'Reaction outcome loss': 0.3361804998651343, 'Total loss': 0.3361804998651343}
2022-11-28 01:40:50,282 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:50,282 INFO:     Epoch: 41
2022-11-28 01:40:51,021 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39747282219204033, 'Total loss': 0.39747282219204033} | train loss {'Reaction outcome loss': 0.3330236743637907, 'Total loss': 0.3330236743637907}
2022-11-28 01:40:51,022 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:51,022 INFO:     Epoch: 42
2022-11-28 01:40:51,759 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.35957273332910106, 'Total loss': 0.35957273332910106} | train loss {'Reaction outcome loss': 0.3501345632477147, 'Total loss': 0.3501345632477147}
2022-11-28 01:40:51,760 INFO:     Found new best model at epoch 42
2022-11-28 01:40:51,760 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:51,760 INFO:     Epoch: 43
2022-11-28 01:40:52,500 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.37128590724684973, 'Total loss': 0.37128590724684973} | train loss {'Reaction outcome loss': 0.32963495989620445, 'Total loss': 0.32963495989620445}
2022-11-28 01:40:52,500 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:52,500 INFO:     Epoch: 44
2022-11-28 01:40:53,244 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38113773156973446, 'Total loss': 0.38113773156973446} | train loss {'Reaction outcome loss': 0.32649126698485453, 'Total loss': 0.32649126698485453}
2022-11-28 01:40:53,244 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:53,244 INFO:     Epoch: 45
2022-11-28 01:40:53,988 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39889243041927164, 'Total loss': 0.39889243041927164} | train loss {'Reaction outcome loss': 0.3271578067106757, 'Total loss': 0.3271578067106757}
2022-11-28 01:40:53,988 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:53,988 INFO:     Epoch: 46
2022-11-28 01:40:54,728 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3939554217186841, 'Total loss': 0.3939554217186841} | train loss {'Reaction outcome loss': 0.3326730874898704, 'Total loss': 0.3326730874898704}
2022-11-28 01:40:54,728 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:54,728 INFO:     Epoch: 47
2022-11-28 01:40:55,472 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.37466763434084976, 'Total loss': 0.37466763434084976} | train loss {'Reaction outcome loss': 0.32850758096713173, 'Total loss': 0.32850758096713173}
2022-11-28 01:40:55,472 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:55,472 INFO:     Epoch: 48
2022-11-28 01:40:56,216 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.35651498795910314, 'Total loss': 0.35651498795910314} | train loss {'Reaction outcome loss': 0.332107892523893, 'Total loss': 0.332107892523893}
2022-11-28 01:40:56,217 INFO:     Found new best model at epoch 48
2022-11-28 01:40:56,217 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:56,217 INFO:     Epoch: 49
2022-11-28 01:40:56,958 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3811437426642938, 'Total loss': 0.3811437426642938} | train loss {'Reaction outcome loss': 0.33541788512592013, 'Total loss': 0.33541788512592013}
2022-11-28 01:40:56,958 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:56,958 INFO:     Epoch: 50
2022-11-28 01:40:57,698 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39432336864146317, 'Total loss': 0.39432336864146317} | train loss {'Reaction outcome loss': 0.32126291014766883, 'Total loss': 0.32126291014766883}
2022-11-28 01:40:57,698 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:57,698 INFO:     Epoch: 51
2022-11-28 01:40:58,441 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3865998819131743, 'Total loss': 0.3865998819131743} | train loss {'Reaction outcome loss': 0.3393626434178005, 'Total loss': 0.3393626434178005}
2022-11-28 01:40:58,442 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:58,442 INFO:     Epoch: 52
2022-11-28 01:40:59,185 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3956096897071058, 'Total loss': 0.3956096897071058} | train loss {'Reaction outcome loss': 0.3377628677980861, 'Total loss': 0.3377628677980861}
2022-11-28 01:40:59,186 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:59,186 INFO:     Epoch: 53
2022-11-28 01:40:59,927 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3864415838298472, 'Total loss': 0.3864415838298472} | train loss {'Reaction outcome loss': 0.3247907068504978, 'Total loss': 0.3247907068504978}
2022-11-28 01:40:59,928 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:40:59,928 INFO:     Epoch: 54
2022-11-28 01:41:00,670 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4045568005266515, 'Total loss': 0.4045568005266515} | train loss {'Reaction outcome loss': 0.32523165200554166, 'Total loss': 0.32523165200554166}
2022-11-28 01:41:00,670 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:00,670 INFO:     Epoch: 55
2022-11-28 01:41:01,412 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4164459210905162, 'Total loss': 0.4164459210905162} | train loss {'Reaction outcome loss': 0.32173514773367873, 'Total loss': 0.32173514773367873}
2022-11-28 01:41:01,412 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:01,413 INFO:     Epoch: 56
2022-11-28 01:41:02,156 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37151624126867816, 'Total loss': 0.37151624126867816} | train loss {'Reaction outcome loss': 0.3292486888435688, 'Total loss': 0.3292486888435688}
2022-11-28 01:41:02,156 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:02,156 INFO:     Epoch: 57
2022-11-28 01:41:02,899 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3787766420705752, 'Total loss': 0.3787766420705752} | train loss {'Reaction outcome loss': 0.3264388332769335, 'Total loss': 0.3264388332769335}
2022-11-28 01:41:02,899 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:02,899 INFO:     Epoch: 58
2022-11-28 01:41:03,638 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4260940758342093, 'Total loss': 0.4260940758342093} | train loss {'Reaction outcome loss': 0.32264727717529423, 'Total loss': 0.32264727717529423}
2022-11-28 01:41:03,638 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:03,638 INFO:     Epoch: 59
2022-11-28 01:41:04,383 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44738825410604477, 'Total loss': 0.44738825410604477} | train loss {'Reaction outcome loss': 0.34010979569392646, 'Total loss': 0.34010979569392646}
2022-11-28 01:41:04,383 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:04,383 INFO:     Epoch: 60
2022-11-28 01:41:05,129 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.403715178031813, 'Total loss': 0.403715178031813} | train loss {'Reaction outcome loss': 0.316934315035278, 'Total loss': 0.316934315035278}
2022-11-28 01:41:05,129 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:05,129 INFO:     Epoch: 61
2022-11-28 01:41:05,871 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43452794375744735, 'Total loss': 0.43452794375744735} | train loss {'Reaction outcome loss': 0.3349587950508604, 'Total loss': 0.3349587950508604}
2022-11-28 01:41:05,871 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:05,871 INFO:     Epoch: 62
2022-11-28 01:41:06,610 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3904015665704554, 'Total loss': 0.3904015665704554} | train loss {'Reaction outcome loss': 0.3274478992138073, 'Total loss': 0.3274478992138073}
2022-11-28 01:41:06,611 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:06,611 INFO:     Epoch: 63
2022-11-28 01:41:07,353 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41041782396760856, 'Total loss': 0.41041782396760856} | train loss {'Reaction outcome loss': 0.3281263340460627, 'Total loss': 0.3281263340460627}
2022-11-28 01:41:07,354 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:07,354 INFO:     Epoch: 64
2022-11-28 01:41:08,095 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3870571276003664, 'Total loss': 0.3870571276003664} | train loss {'Reaction outcome loss': 0.3353668827759592, 'Total loss': 0.3353668827759592}
2022-11-28 01:41:08,095 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:08,095 INFO:     Epoch: 65
2022-11-28 01:41:08,835 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41144578192721715, 'Total loss': 0.41144578192721715} | train loss {'Reaction outcome loss': 0.3142198051518274, 'Total loss': 0.3142198051518274}
2022-11-28 01:41:08,835 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:08,835 INFO:     Epoch: 66
2022-11-28 01:41:09,579 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4159521782262759, 'Total loss': 0.4159521782262759} | train loss {'Reaction outcome loss': 0.32076089247035594, 'Total loss': 0.32076089247035594}
2022-11-28 01:41:09,579 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:09,579 INFO:     Epoch: 67
2022-11-28 01:41:10,323 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4047427969900044, 'Total loss': 0.4047427969900044} | train loss {'Reaction outcome loss': 0.3243339423178356, 'Total loss': 0.3243339423178356}
2022-11-28 01:41:10,323 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:10,323 INFO:     Epoch: 68
2022-11-28 01:41:11,065 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44394469396634534, 'Total loss': 0.44394469396634534} | train loss {'Reaction outcome loss': 0.3131719738271404, 'Total loss': 0.3131719738271404}
2022-11-28 01:41:11,065 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:11,065 INFO:     Epoch: 69
2022-11-28 01:41:11,807 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43067286925559695, 'Total loss': 0.43067286925559695} | train loss {'Reaction outcome loss': 0.32220449657575323, 'Total loss': 0.32220449657575323}
2022-11-28 01:41:11,807 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:11,807 INFO:     Epoch: 70
2022-11-28 01:41:12,551 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.36911615153605287, 'Total loss': 0.36911615153605287} | train loss {'Reaction outcome loss': 0.3249991759959503, 'Total loss': 0.3249991759959503}
2022-11-28 01:41:12,551 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:12,551 INFO:     Epoch: 71
2022-11-28 01:41:13,295 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3948926983231848, 'Total loss': 0.3948926983231848} | train loss {'Reaction outcome loss': 0.32451925318130115, 'Total loss': 0.32451925318130115}
2022-11-28 01:41:13,295 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:13,295 INFO:     Epoch: 72
2022-11-28 01:41:14,037 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3853112142533064, 'Total loss': 0.3853112142533064} | train loss {'Reaction outcome loss': 0.32270483968228947, 'Total loss': 0.32270483968228947}
2022-11-28 01:41:14,037 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:14,037 INFO:     Epoch: 73
2022-11-28 01:41:14,779 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3752398910847577, 'Total loss': 0.3752398910847577} | train loss {'Reaction outcome loss': 0.3432921566340605, 'Total loss': 0.3432921566340605}
2022-11-28 01:41:14,779 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:14,779 INFO:     Epoch: 74
2022-11-28 01:41:15,522 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37986106594855135, 'Total loss': 0.37986106594855135} | train loss {'Reaction outcome loss': 0.35053295310330296, 'Total loss': 0.35053295310330296}
2022-11-28 01:41:15,522 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:15,522 INFO:     Epoch: 75
2022-11-28 01:41:16,263 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4068275215950879, 'Total loss': 0.4068275215950879} | train loss {'Reaction outcome loss': 0.33161634788942723, 'Total loss': 0.33161634788942723}
2022-11-28 01:41:16,263 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:16,263 INFO:     Epoch: 76
2022-11-28 01:41:17,005 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3790311169895259, 'Total loss': 0.3790311169895259} | train loss {'Reaction outcome loss': 0.3266482630151512, 'Total loss': 0.3266482630151512}
2022-11-28 01:41:17,005 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:17,005 INFO:     Epoch: 77
2022-11-28 01:41:17,748 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4295681301843036, 'Total loss': 0.4295681301843036} | train loss {'Reaction outcome loss': 0.3186063762859777, 'Total loss': 0.3186063762859777}
2022-11-28 01:41:17,748 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:17,748 INFO:     Epoch: 78
2022-11-28 01:41:18,492 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41273470053618605, 'Total loss': 0.41273470053618605} | train loss {'Reaction outcome loss': 0.31636184692262154, 'Total loss': 0.31636184692262154}
2022-11-28 01:41:18,492 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:18,492 INFO:     Epoch: 79
2022-11-28 01:41:19,232 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4411255751143802, 'Total loss': 0.4411255751143802} | train loss {'Reaction outcome loss': 0.33778098436743625, 'Total loss': 0.33778098436743625}
2022-11-28 01:41:19,233 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:19,233 INFO:     Epoch: 80
2022-11-28 01:41:19,976 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3574245656755837, 'Total loss': 0.3574245656755837} | train loss {'Reaction outcome loss': 0.3237661643609827, 'Total loss': 0.3237661643609827}
2022-11-28 01:41:19,976 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:19,976 INFO:     Epoch: 81
2022-11-28 01:41:20,718 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4574142958630215, 'Total loss': 0.4574142958630215} | train loss {'Reaction outcome loss': 0.3191574838781646, 'Total loss': 0.3191574838781646}
2022-11-28 01:41:20,718 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:20,718 INFO:     Epoch: 82
2022-11-28 01:41:21,463 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4102549397132613, 'Total loss': 0.4102549397132613} | train loss {'Reaction outcome loss': 0.3289849780168128, 'Total loss': 0.3289849780168128}
2022-11-28 01:41:21,463 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:21,463 INFO:     Epoch: 83
2022-11-28 01:41:22,207 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3707352270456878, 'Total loss': 0.3707352270456878} | train loss {'Reaction outcome loss': 0.33151601953431964, 'Total loss': 0.33151601953431964}
2022-11-28 01:41:22,208 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:22,208 INFO:     Epoch: 84
2022-11-28 01:41:22,949 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40231361307881097, 'Total loss': 0.40231361307881097} | train loss {'Reaction outcome loss': 0.3189210700934474, 'Total loss': 0.3189210700934474}
2022-11-28 01:41:22,950 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:22,950 INFO:     Epoch: 85
2022-11-28 01:41:23,695 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43555626848881895, 'Total loss': 0.43555626848881895} | train loss {'Reaction outcome loss': 0.3265863194277412, 'Total loss': 0.3265863194277412}
2022-11-28 01:41:23,695 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:23,695 INFO:     Epoch: 86
2022-11-28 01:41:24,441 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4248053929345174, 'Total loss': 0.4248053929345174} | train loss {'Reaction outcome loss': 0.3314125678136281, 'Total loss': 0.3314125678136281}
2022-11-28 01:41:24,441 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:24,441 INFO:     Epoch: 87
2022-11-28 01:41:25,184 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4251135052605109, 'Total loss': 0.4251135052605109} | train loss {'Reaction outcome loss': 0.33455985790563497, 'Total loss': 0.33455985790563497}
2022-11-28 01:41:25,184 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:25,184 INFO:     Epoch: 88
2022-11-28 01:41:25,928 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.37801833721724426, 'Total loss': 0.37801833721724426} | train loss {'Reaction outcome loss': 0.3313065566544832, 'Total loss': 0.3313065566544832}
2022-11-28 01:41:25,928 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:25,928 INFO:     Epoch: 89
2022-11-28 01:41:26,670 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3765872662717646, 'Total loss': 0.3765872662717646} | train loss {'Reaction outcome loss': 0.3261276010559638, 'Total loss': 0.3261276010559638}
2022-11-28 01:41:26,670 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:26,670 INFO:     Epoch: 90
2022-11-28 01:41:27,413 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39550914107398555, 'Total loss': 0.39550914107398555} | train loss {'Reaction outcome loss': 0.37435599347116494, 'Total loss': 0.37435599347116494}
2022-11-28 01:41:27,413 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:27,413 INFO:     Epoch: 91
2022-11-28 01:41:28,158 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39816893671046605, 'Total loss': 0.39816893671046605} | train loss {'Reaction outcome loss': 0.3364456450408287, 'Total loss': 0.3364456450408287}
2022-11-28 01:41:28,158 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:28,158 INFO:     Epoch: 92
2022-11-28 01:41:28,903 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4532222639430653, 'Total loss': 0.4532222639430653} | train loss {'Reaction outcome loss': 0.3675557889557078, 'Total loss': 0.3675557889557078}
2022-11-28 01:41:28,903 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:28,904 INFO:     Epoch: 93
2022-11-28 01:41:29,648 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39534549008716235, 'Total loss': 0.39534549008716235} | train loss {'Reaction outcome loss': 0.3386926793376444, 'Total loss': 0.3386926793376444}
2022-11-28 01:41:29,649 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:29,649 INFO:     Epoch: 94
2022-11-28 01:41:30,391 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.433770274404775, 'Total loss': 0.433770274404775} | train loss {'Reaction outcome loss': 0.32818963147910984, 'Total loss': 0.32818963147910984}
2022-11-28 01:41:30,392 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:30,392 INFO:     Epoch: 95
2022-11-28 01:41:31,135 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.34499581869352947, 'Total loss': 0.34499581869352947} | train loss {'Reaction outcome loss': 0.3273269153135991, 'Total loss': 0.3273269153135991}
2022-11-28 01:41:31,137 INFO:     Found new best model at epoch 95
2022-11-28 01:41:31,137 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:31,137 INFO:     Epoch: 96
2022-11-28 01:41:31,881 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3949945867061615, 'Total loss': 0.3949945867061615} | train loss {'Reaction outcome loss': 0.3250935839881238, 'Total loss': 0.3250935839881238}
2022-11-28 01:41:31,882 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:31,882 INFO:     Epoch: 97
2022-11-28 01:41:32,626 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38816188072616403, 'Total loss': 0.38816188072616403} | train loss {'Reaction outcome loss': 0.32497520688996623, 'Total loss': 0.32497520688996623}
2022-11-28 01:41:32,626 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:32,626 INFO:     Epoch: 98
2022-11-28 01:41:33,368 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3906600292433392, 'Total loss': 0.3906600292433392} | train loss {'Reaction outcome loss': 0.3237449350476506, 'Total loss': 0.3237449350476506}
2022-11-28 01:41:33,368 INFO:     Current learning rate [0.0015553873022161448]
2022-11-28 01:41:33,368 INFO:     Epoch: 99
2022-11-28 01:41:34,114 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3594581794671037, 'Total loss': 0.3594581794671037} | train loss {'Reaction outcome loss': 0.320374184593498, 'Total loss': 0.320374184593498}
2022-11-28 01:41:34,114 INFO:     Best model found after epoch 96 of 100.
2022-11-28 01:41:34,115 INFO:   Done with stage: TRAINING
2022-11-28 01:41:34,115 INFO:   Starting stage: EVALUATION
2022-11-28 01:41:34,236 INFO:   Done with stage: EVALUATION
2022-11-28 01:41:34,237 INFO: Done with stage: RUNNING SPLITS
2022-11-28 01:41:34,237 INFO: Starting stage: COMPUTE METRICS
2022-11-28 01:41:35,411 INFO: Done with stage: COMPUTE METRICS
2022-11-28 01:41:35,411 INFO: Starting stage: EXPORT RESULTS
2022-11-28 01:41:35,429 INFO:   Final results averaged over 50 folds: 
2022-11-28 01:41:35,433 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.171759           NaN  0.303889       NaN
2022-11-28 01:41:37,076 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-11-28 01:41:37,082 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-11-28 01:41:37,083 DEBUG:   interactive is False
2022-11-28 01:41:37,083 DEBUG:   platform is linux
2022-11-28 01:41:37,083 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.sql.naming', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-11-28 01:41:37,263 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-11-28 01:41:37,265 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-11-28 01:41:37,716 DEBUG:   Loaded backend agg version unknown.
2022-11-28 01:41:37,718 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-28 01:41:37,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 01:41:37,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 01:41:37,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 01:41:37,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 01:41:37,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 01:41:37,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 01:41:37,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 01:41:37,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-28 01:41:37,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 01:41:37,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 01:41:37,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,721 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,721 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,721 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,721 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,721 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-28 01:41:37,721 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,721 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,721 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,721 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,721 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 01:41:37,721 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 01:41:37,721 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,721 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,721 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,721 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 01:41:37,721 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,721 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-28 01:41:37,758 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-11-28 01:41:37,758 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,758 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,758 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,758 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 01:41:37,758 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 01:41:37,758 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 01:41:37,758 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,758 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 01:41:37,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 01:41:37,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 01:41:37,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 01:41:37,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-28 01:41:37,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 01:41:37,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 01:41:37,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-28 01:41:37,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 01:41:37,760 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 01:41:37,760 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,760 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,761 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,761 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 01:41:37,761 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,761 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-28 01:41:37,769 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-28 01:41:37,769 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,769 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,769 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,769 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 01:41:37,770 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 01:41:37,770 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 01:41:37,770 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,770 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,770 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,770 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,770 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 01:41:37,770 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 01:41:37,770 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,770 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,770 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,770 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 01:41:37,770 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,770 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 01:41:37,770 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,770 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,770 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-28 01:41:37,771 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 01:41:37,771 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-28 01:41:37,771 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,771 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,771 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,771 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,771 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,771 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,771 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,771 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,771 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,771 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-28 01:41:37,771 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,771 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,771 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,771 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,771 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-28 01:41:37,772 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-28 01:41:37,772 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,772 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,772 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-28 01:41:37,772 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-28 01:41:37,772 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-28 01:41:37,772 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-28 01:41:38,184 INFO: Done with stage: EXPORT RESULTS
2022-11-28 01:41:38,184 INFO: Starting stage: SAVE MODEL
2022-11-28 01:41:38,248 INFO: Done with stage: SAVE MODEL
2022-11-28 01:41:38,248 INFO: Wall time for program:  3774.64 seconds
